<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d6" for="edge" attr.name="source_id" attr.type="string" />
  <key id="d5" for="edge" attr.name="description" attr.type="string" />
  <key id="d4" for="edge" attr.name="weight" attr.type="double" />
  <key id="d3" for="node" attr.name="entity_type" attr.type="string" />
  <key id="d2" for="node" attr.name="source_id" attr.type="string" />
  <key id="d1" for="node" attr.name="description" attr.type="string" />
  <key id="d0" for="node" attr.name="type" attr.type="string" />
  <graph edgedefault="undirected">
    <node id="GRAPH RAG">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Graph RAG is an approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed. It uses an LLM to build a graph-based text index in two stages: deriving an entity knowledge graph from source documents and pre-generating community summaries for groups of closely-related entities.
A new approach based on global summarization of an LLM-derived knowledge graph, focusing on the modularity of graphs and community detection algorithms.
A method using graph communities at different levels to answer user queries, compared against other conditions in the analysis.
A method used to generate comprehensive and detailed lists of public figures from various entertainment sectors.
Graph RAG is an approach that uses graph indexing to improve the comprehensiveness and diversity of answers in datasets like Podcast transcripts and News articles. It outperforms naive RAG in these metrics.
Graph RAG is an advanced RAG system that uses a self-generated graph index to facilitate efficient iterative question answering and summarization, requiring fewer context tokens compared to source text summarization.
Graph RAG is an approach that uses the natural modularity of graphs to partition data for global summarization. It combines knowledge graph generation, retrieval-augmented generation (RAG), and query-focused summarization (QFS) to support human sensemaking over entire text corpora.
A technique for retrieval-augmented generation with large language models based on knowledge graphs, launched by NebulaGraph.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7,ac21ebe9a9d70d691c717f961d3f10c8,c8e8019de153e439d6a79dcf209b943b,df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="RAG">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Retrieval-augmented generation (RAG) is an established approach to answering user questions over entire datasets by retrieving relevant information from an external knowledge source. It is designed for situations where answers are contained locally within regions of text whose retrieval provides sufficient grounding for the generation task.
Retrieval-Augmented Generation (RAG) is a method that involves retrieving text chunks to aid in generating summaries, though it may be inadequate for query-focused summarization tasks.
RAG stands for Retrieval-Augmented Generation, a method that involves retrieving relevant information from external data sources and adding it to the context window of an LLM.
RAG (Retrieval-Augmented Generation) is a tool that can be used within the LangChain framework to enhance agentic systems.
RAG (Retrieval-Augmented Generation) is an important building block for agentic systems, used to enhance the agent's performance by retrieving relevant information.
RAG (Retrieval-Augmented Generation) is a method referenced as a potential building block for ADAS, allowing for the integration of retrieval mechanisms in agentic systems.
RAG (Retrieval-Augmented Generation) is a skill that can be taught to AI models using the data generated by AgentInstruct.
Retrieval Augmented Generation (RAG) is a skill that boosts the capacity of language models to generate informed, contextually precise responses.
RAG (Retrieval-Augmented Generation) is a technique used to enhance the performance of language models by incorporating retrieved documents into their responses.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,0c932f7def033fa2b1bf210fbb771e7d,4884e8429ca1e567dadf5e22b4b68274,64476a39d7d8b87b399e3bd3cead79c7,6bdf681c0bd9e401ac72344a6a0ae479,8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="LLM">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Large Language Models (LLMs) are advanced models used to automate human-like sensemaking in complex domains. They are used in Graph RAG to build a graph-based text index and generate community summaries.
LLM stands for Large Language Model, which is used to extract descriptions of entities, relationships, and claims from source texts. It is capable of abstractive summarization and understanding implied relationships.
Large Language Model used to generate questions, evaluate answers, and perform various tasks related to natural language processing.
Large Language Models used to generate assessments and answers based on data inputs.
LLM stands for Large Language Model, a type of advanced AI model used for various natural language processing tasks, including reasoning and summarization.
LLM (Large Language Model) powers agents and can optionally use tools to perform specific tasks.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,26b2dad01a219bc034ac7d6a32d07582,c8e8019de153e439d6a79dcf209b943b,e66ed885a08f92cc69f4895302c33047,edab4014b8f55e5b25bd7f396314be1f,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="QFS">
      <data key="d0">TASK, METHOD</data>
      <data key="d1">Query-focused summarization (QFS) is a task that generates natural language summaries based on user queries. It is more appropriate for global questions directed at an entire text corpus, rather than explicit retrieval tasks.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="MICROSOFT RESEARCH">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">Microsoft Research is a division of Microsoft involved in the development of the Graph RAG approach and other advanced technologies.
Microsoft Research is the organization where the authors of the paper are affiliated. They focus on advancing the development of language models and synthetic data generation techniques.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">A division of Microsoft involved in the development of the Graph RAG approach.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="MICROSOFT OFFICE OF THE CTO">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">A division of Microsoft involved in the development of the Graph RAG approach.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="DAREN EDGE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Daren Edge is one of the authors of the paper on Graph RAG.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="HA TRINH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ha Trinh is one of the authors of the paper on Graph RAG.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="NEWMAN CHENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Newman Cheng is one of the authors of the paper on Graph RAG.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="JOSHUA BRADLEY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Joshua Bradley is one of the authors of the paper on Graph RAG.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="ALEX CHAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alex Chao is one of the authors of the paper on Graph RAG.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="APURVA MODY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Apurva Mody is one of the authors of the paper on Graph RAG.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="STEVEN TRUITT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Steven Truitt is one of the authors of the paper on Graph RAG.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="JONATHAN LARSON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jonathan Larson is one of the authors of the paper on Graph RAG.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="HUMAN SENSEMAKING">
      <data key="d0">CONCEPT, TASK</data>
      <data key="d1">Human sensemaking is the process of understanding connections among people, places, and events to anticipate their trajectories and act effectively. It is a key concept in the development of Graph RAG.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="COMMUNITY DETECTION">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Community detection is a technique used to partition a graph index into groups of elements (nodes, edges, covariates) that can be summarized in parallel at both indexing time and query time.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="LEIDEN">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Leiden is a community detection algorithm used in the Graph RAG approach to partition the graph index into groups of elements.
A community detection algorithm developed by Traag et al., used to partition graphs into modular communities.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="QUERY-FOCUSED SUMMARIZATION">
      <data key="d0">TASK, METHOD</data>
      <data key="d1">Query-focused summarization (QFS) is a task that generates natural language summaries based on user queries. It is more appropriate for global questions directed at an entire text corpus, rather than explicit retrieval tasks.Query-focused summarization is a task that generates summaries based on user queries, used in the final round of the Graph RAG approach to produce a global answer.
Query-focused summarization is a method of summarizing information in a way that is aligned with specific queries or questions, often used in the context of graph-based indexing.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">TASK, METHOD</data>
    </node>
    <node id="EXTERNAL KNOWLEDGE SOURCE">
      <data key="d0">RESOURCE, DATA</data>
      <data key="d1">An external knowledge source is used in RAG to retrieve relevant information for answering user questions.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">RESOURCE, DATA</data>
    </node>
    <node id="SOURCE DOCUMENTS">
      <data key="d0">RESOURCE, DATA</data>
      <data key="d1">Source documents are the original texts from which information is extracted and indexed in the Graph RAG approach.
Original documents from which text chunks are extracted for processing in the Graph RAG approach.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7</data>
      <data key="d3">RESOURCE, DATA</data>
    </node>
    <node id="TEXT CHUNKS">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Text chunks are segments of source documents that are extracted and processed in the Graph RAG approach.
Segments of text extracted from source documents, used in the Graph RAG approach for processing and entity extraction.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="ELEMENT INSTANCES">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Element instances are specific pieces of information extracted from text chunks in the Graph RAG approach.
Element instances are the initial extracted descriptions of entities, relationships, and claims from source texts, which are then summarized into single blocks of descriptive text for each graph element.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="ELEMENT SUMMARIES">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Element summaries are domain-tailored summaries of element instances in the Graph RAG approach.
Element summaries are the result of summarizing instance-level descriptions into single blocks of descriptive text for each graph element, such as entity nodes, relationship edges, and claim covariates.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="GRAPH COMMUNITIES">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Graph communities are groups of closely-related elements detected in the Graph RAG approach.
Graph communities are groups of nodes in a graph that are more strongly connected to each other than to other nodes. These communities are detected using algorithms like Leiden and are used for global summarization.
Different levels of community summaries (C0, C1, C2, C3) used in the Graph RAG method to answer user queries.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,26b2dad01a219bc034ac7d6a32d07582,e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="COMMUNITY SUMMARIES">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Community summaries are domain-tailored summaries of graph communities in the Graph RAG approach.
Community summaries are report-like summaries of each community detected in the graph. They provide an understanding of the global structure and semantics of the dataset and are useful for answering global queries.
Community summaries are generated for different levels of the community structure and used to answer user queries. They are prepared by shuffling and dividing into chunks of pre-specified token size.
Summaries generated at different levels of a graph community hierarchy, used to improve answer comprehensiveness and diversity in Graph RAG.
Community summaries are summaries generated from community-level data, used in Graph RAG for efficient summarization and question answering.
Community summaries are summaries of root-level communities in the entity-based graph index, providing a data index for global queries.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,4930fce6da868f894757a9da465807ba,ac21ebe9a9d70d691c717f961d3f10c8,e66ed885a08f92cc69f4895302c33047,edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="COMMUNITY ANSWERS">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Community answers are partial responses generated from community summaries in the Graph RAG approach.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="GLOBAL ANSWER">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">The global answer is the final response generated from summarizing all community answers in the Graph RAG approach.
The global answer is the final answer generated for a user query by combining intermediate community answers, sorted by helpfulness score, until the token limit is reached.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,4930fce6da868f894757a9da465807ba</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="INDEXING TIME">
      <data key="d0">TIME, STAGE</data>
      <data key="d1">Indexing time is the stage in the Graph RAG approach when the graph index is built and community summaries are generated.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">TIME, STAGE</data>
    </node>
    <node id="QUERY TIME">
      <data key="d0">TIME, STAGE</data>
      <data key="d1">Query time is the stage in the Graph RAG approach when community summaries are used to generate partial responses and a final global answer.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">TIME, STAGE</data>
    </node>
    <node id="PIPELINE STAGE">
      <data key="d0">STAGE, PROCESS</data>
      <data key="d1">Pipeline stage refers to the different stages in the Graph RAG approach, including indexing time and query time.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">STAGE, PROCESS</data>
    </node>
    <node id="SENSEMAKING">
      <data key="d0">CONCEPT, TASK</data>
      <data key="d1">Sensemaking is the process of understanding connections among people, places, and events to anticipate their trajectories and act effectively. It is a key concept in the development of Graph RAG.
The process of understanding and making informed judgments about a topic, often evaluated using specific metrics.
Sensemaking is the process of understanding and making sense of complex information, often facilitated by methods like Graph RAG.
Sensemaking is the process of understanding and making sense of large text corpora, supported by methods like Graph RAG.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,26b2dad01a219bc034ac7d6a32d07582,ac21ebe9a9d70d691c717f961d3f10c8,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, TASK</data>
    </node>
    <node id="TRANSFORMER ARCHITECTURE">
      <data key="d0">TECHNOLOGY, MODEL</data>
      <data key="d1">Transformer architecture is a type of model that has shown substantial improvements in summarization tasks and is used in modern LLMs.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">TECHNOLOGY, MODEL</data>
    </node>
    <node id="GPT">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">GPT is a series of advanced language models used for various tasks, including summarization and sensemaking.
A series of large language models developed by OpenAI, capable of in-context learning for summarization tasks.
GPT is a Foundation Model developed by OpenAI, used as a general-purpose agent for agentic tasks.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7,c3d0436082aada237ee4bee645f16059</data>
      <data key="d3">TECHNOLOGY, LANGUAGE MODEL</data>
    </node>
    <node id="LLAMA">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Llama is an advanced language model used for various tasks, including summarization and sensemaking.
A series of large language models developed by Touvron et al., capable of in-context learning for summarization tasks.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7</data>
      <data key="d3">TECHNOLOGY, LANGUAGE MODEL</data>
    </node>
    <node id="GEMINI">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Gemini is an advanced language model used for various tasks, including summarization and sensemaking.
A series of large language models developed by Anil et al., capable of in-context learning for summarization tasks.
Gemini is a family of highly capable multimodal models, referenced in the document.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7,ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">TECHNOLOGY, LANGUAGE MODEL</data>
    </node>
    <node id="RETRIEVAL-AUGMENTED GENERATION">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Retrieval-augmented generation (RAG) is an established approach to answering user questions over entire datasets by retrieving relevant information from an external knowledge source. It is designed for situations where answers are contained locally within regions of text whose retrieval provides sufficient grounding for the generation task.
A technique for enhancing knowledge-intensive NLP tasks by combining retrieval and generation processes.
Retrieval-augmented generation is a method for knowledge-intensive NLP tasks discussed in a paper published in Advances in Neural Information Processing Systems in 2020.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,6109537356a2ce2339f77c827aa3668e,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SUMMARIZATION TASKS">
      <data key="d0">TASK, ACTIVITY</data>
      <data key="d1">Summarization tasks involve condensing large volumes of text into shorter, coherent summaries. These tasks are now trivialized by modern LLMs.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="LLMS">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Large Language Models (LLMs) like GPT, Llama, and Gemini, which can use in-context learning to summarize content provided in their context window.
Large Language Models (LLMs) are advanced language models trained on vast amounts of data to perform various natural language processing tasks.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION">
      <data key="d0">TASK, ACTIVITY</data>
      <data key="d1">A type of summarization that focuses on generating summaries based on specific queries over an entire corpus.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="KNOWLEDGE GRAPH">
      <data key="d0">DATA STRUCTURE</data>
      <data key="d1">A graph-based representation of knowledge, used in the Graph RAG approach for summarization tasks.
Knowledge graph is a data structure used in advanced RAG systems for organizing and retrieving information, as seen in KAPING and other systems.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="COMMUNITY DETECTION ALGORITHMS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Algorithms like Louvain and Leiden that partition graphs into modular communities of closely-related nodes.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="LOUVAIN">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">A community detection algorithm developed by Blondel et al., used to partition graphs into modular communities.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="MAP-REDUCE">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A technique used in the Graph RAG approach to summarize query-focused information by first summarizing each community independently and then combining the partial answers.
A method used in text summarization (TS) where source texts are shuffled and chunked for summarization stages.
Map-Reduce is a technique used for global summarization of source texts, which performed competitively against Graph RAG in evaluations.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7,ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="HOTPOTQA">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset used to evaluate the performance of entity extraction prompts, varying with chunk size and gleanings.
HotPotQA is a benchmark dataset for open-domain question answering, targeting explicit fact retrieval.
A dataset for diverse, explainable multi-hop question answering, presented at the Conference on Empirical Methods in Natural Language Processing (EMNLP) in 2018.
HotPotQA is a benchmark used to empirically evaluate the performance of LATS in reasoning and decision-making tasks.
HotPotQA is a benchmark for interactive question-answering tasks. LATS doubles the performance of ReAct on this benchmark when used with GPT-3.5.
A benchmark used to evaluate the reasoning-based prompting results of the LATS algorithm, achieving the highest exact match (EM) score.
HotPotQA is a multi-hop question-answering benchmark that requires retrieval over two or more Wikipedia passages.
HotPotQA is a benchmark used to evaluate the performance of algorithms on tasks requiring both internal reasoning and external retrieval strategies.
HotPotQA is a benchmark used to compare the cost and performance of different methods like LATS, ToT, and RAP.
HotpotQA is a dataset for diverse, explainable multi-hop question answering, mentioned in the document in the context of research by Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W. Cohen, Ruslan Salakhutdinov, and Christopher D. Manning.
HotPotQA is a benchmark used to evaluate the performance of algorithms like LATS, particularly in reasoning tasks.
HotPotQA is a question-answering dataset that requires reasoning over multiple supporting documents to answer questions. It contains 113k Wikipedia-based question-answer pairs crafted by crowdworkers to be diverse, multi-hop, and explainable.
HotpotQA is a benchmark used to evaluate the performance of algorithms like LATS, measured by Exact Match (EM) scores.
A dataset used for question answering tasks, involving interleaving Thought, Action, and Observation steps</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,4930fce6da868f894757a9da465807ba,64476a39d7d8b87b399e3bd3cead79c7,8180bf20b7577f3eee40df5991e2886d,93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,b8dd0300033963bb4a3e1bad37f8e7b9,d4c8ce26fd0f9a7bc6dad0efa1ce98e3,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="ENTITY EXTRACTION">
      <data key="d0">TASK, ACTIVITY</data>
      <data key="d1">The process of identifying and extracting entities from text, used in the Graph RAG approach to build a knowledge graph.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="ACTIVITY-CENTERED SENSE-MAKING QUESTIONS">
      <data key="d0">TASK, ACTIVITY</data>
      <data key="d1">Questions generated by an LLM to evaluate the Graph RAG approach, focusing on comprehensiveness, diversity, and empowerment.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="COMPREHENSIVENESS">
      <data key="d0">QUALITY METRIC</data>
      <data key="d1">A target quality for evaluating summarization approaches, indicating the extent to which all relevant information is covered.
A metric capturing how much detail an answer provides to cover all aspects and details of the question.
A measure of how complete and detailed an answer or report is.
A metric used to evaluate the completeness and thoroughness of the answers provided by different summarization approaches.
Comprehensiveness is a measure of how thoroughly a method or system covers the necessary information, with Graph RAG showing a 72% win rate in this aspect.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7,c8e8019de153e439d6a79dcf209b943b,edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="DIVERSITY">
      <data key="d0">QUALITY METRIC</data>
      <data key="d1">A target quality for evaluating summarization approaches, indicating the variety of information covered.
A metric capturing how varied and rich an answer is in providing different perspectives and insights on the question.
A measure of the variety and range of perspectives or elements included in an answer or report.
A metric used to evaluate the variety and range of the answers provided by different summarization approaches.
Diversity is a measure of the variety of information or perspectives provided by a method or system, with Graph RAG showing a 62% win rate in this aspect.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7,c8e8019de153e439d6a79dcf209b943b,edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="EMPOWERMENT">
      <data key="d0">QUALITY METRIC</data>
      <data key="d1">A target quality for evaluating summarization approaches, indicating the extent to which the approach helps develop understanding of broad issues and themes.
A metric capturing how well an answer helps the reader understand and make informed judgments about the topic.
A measure of how well an answer or report enables the reader to understand and make informed judgments.
A metric used to evaluate the degree to which the answers provided by different summarization approaches empower the user.
Empowerment is a measure used to evaluate the effectiveness of RAG approaches in helping users reach an informed understanding by providing specific examples, quotes, and citations.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7,c8e8019de153e439d6a79dcf209b943b,edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="PODCAST TRANSCRIPTS">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset containing transcripts of podcasts, used to evaluate the Graph RAG approach.
Podcast transcripts are compiled conversations between Kevin Scott, Microsoft CTO, and other technology leaders, used as a dataset for evaluation.
Written records of spoken content from podcasts, often used for analysis and reference.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,64476a39d7d8b87b399e3bd3cead79c7,c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="NEWS ARTICLES">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset containing news articles, used to evaluate the Graph RAG approach.
News articles are a benchmark dataset comprising articles published from September 2013 to December 2023 in various categories, used for evaluation.
Written pieces in media outlets that report on current events, public figures, and other topics of interest.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,64476a39d7d8b87b399e3bd3cead79c7,c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="TOKEN COSTS">
      <data key="d0">RESOURCE METRIC</data>
      <data key="d1">The computational cost associated with processing tokens in LLMs, relevant for evaluating the efficiency of summarization approaches.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="GOODWIN ET AL., 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Goodwin et al. are researchers who have contributed to the state-of-the-art in summarization tasks, as cited in the document.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="LASKAR ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Laskar et al. are researchers who have contributed to the state-of-the-art in summarization tasks, as cited in the document.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="LIU AND LAPATA, 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liu and Lapata are researchers who have contributed to the state-of-the-art in summarization tasks, as cited in the document.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="ACHIAM ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Achiam et al. are researchers who have contributed to the development of the GPT series, as cited in the document.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="BROWN ET AL., 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Brown et al. are researchers who have contributed to the development of the GPT series, as cited in the document.
Brown et al. are the authors of a study from 2020 that provided examples for in-context learning for LLMs.
Brown et al. are the authors of a significant paper on language models, published in 2020.
Brown et al. are researchers who contributed to the development of in-context learning abilities of language models in 2020.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,93cb0d0456e0822b5fe30a3e627405f8,c95e02c0dca4a4a36b701cbc7dd14da6,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="TOUVRON ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Touvron et al. are researchers who have contributed to the development of the Llama series, as cited in the document.
Touvron et al. are the authors of a significant paper on language models, published in 2023.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="ANIL ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Anil et al. are researchers who have contributed to the development of the Gemini series, as cited in the document.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="KURATOV ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kuratov et al. are researchers who have studied the limitations of LLM context windows, as cited in the document.
Researchers who studied the potential for information to be "lost in the middle" of longer contexts in language models.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="LIU ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liu et al. are researchers who have studied the limitations of LLM context windows, as cited in the document.
Researchers who studied the potential for information to be "lost in the middle" of longer contexts in language models.
Liu et al. are researchers who explored combining search algorithms with language model agents in 2023.
Liu et al. are the authors mentioned in relation to previous search approaches using LMs as world models.
Liu et al. are the authors of works exploring search spaces using feed-forward networks in ADAS, published in 2023.
Liu et al. are the authors of the DyLAN algorithm, published in 2023.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,4884e8429ca1e567dadf5e22b4b68274,64476a39d7d8b87b399e3bd3cead79c7,c95e02c0dca4a4a36b701cbc7dd14da6,dc55f071b95dec721a9820d39cdb3ccd,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="NEW YORK TIMES">
      <data key="d0">DATA SOURCE</data>
      <data key="d1">A source of news articles used in the evaluation of the Graph RAG approach.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="PODCASTS">
      <data key="d0">DATA SOURCE</data>
      <data key="d1">A source of podcast transcripts used in the evaluation of the Graph RAG approach.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="NA&#207;VE RAG">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A basic form of Retrieval-Augmented Generation that is likely inadequate for query-focused summarization tasks.
A method used to generate lists of public figures, focusing on specific individuals and their frequent mentions in media.
Na&#239;ve RAG is a basic RAG approach that converts documents to text, splits text into chunks, and embeds these chunks into a vector space for retrieval and context addition in LLMs.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,c8e8019de153e439d6a79dcf209b943b,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="GLOBAL SUMMARIZATION">
      <data key="d0">TASK, ACTIVITY</data>
      <data key="d1">The process of summarizing an entire corpus of text, as opposed to focusing on specific queries.
Global summarization is the process of creating comprehensive summaries from large datasets, as facilitated by Graph RAG.
Global summarization is a technique used to summarize data across an entire dataset, as opposed to local summarization.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,ac21ebe9a9d70d691c717f961d3f10c8,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="INTERMEDIATE-LEVEL COMMUNITY SUMMARIES">
      <data key="d0">DATA UNIT</data>
      <data key="d1">Summaries generated at an intermediate hierarchical level within a knowledge graph, used in the Graph RAG approach.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="LOW-LEVEL COMMUNITY SUMMARIES">
      <data key="d0">DATA UNIT</data>
      <data key="d1">Summaries generated at a low hierarchical level within a knowledge graph, used in the Graph RAG approach.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="HIERARCHICAL LEVEL">
      <data key="d0">QUALITY METRIC</data>
      <data key="d1">The level of detail at which community summaries are generated, impacting the performance of the Graph RAG approach.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="FEW-SHOT EXAMPLES">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Examples provided to an LLM for in-context learning to tailor the entity extraction prompt to the domain of the document corpus.
Examples provided to the model to guide its responses, used in the evaluation of LATS.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="GLEANINGS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The process of extracting additional information from text chunks, used to improve entity extraction performance.
Gleanings refer to multiple rounds of entity extraction to ensure that no entities are missed. This process involves assessing whether all entities were extracted and encouraging the LLM to detect any additional entities in subsequent rounds.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="NAMED ENTITIES">
      <data key="d0">CONCEPT, DATA TYPE</data>
      <data key="d1">Named entities refer to specific categories like people, places, and organizations that are extracted from text documents.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="COVARIATES">
      <data key="d0">CONCEPT, DATA TYPE</data>
      <data key="d1">Covariates are additional variables or attributes associated with extracted node instances, such as claims linked to detected entities, including subject, object, type, description, source text span, and start and end dates.
Covariates are linked elements within a community structure that are described and prioritized in leaf-level communities.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="LEIDEN ALGORITHM">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">The Leiden algorithm is used for community detection in large-scale graphs. It efficiently recovers hierarchical community structures and is used to partition graphs into mutually-exclusive, collectively-exhaustive communities.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="MULTIHOP-RAG">
      <data key="d0">DATASET</data>
      <data key="d1">MultiHop-RAG is a dataset used for indexing and graph community detection. It is visualized using tools like OpenORD and Force Atlas 2 to show hierarchical clustering of entity nodes.
MultiHop-RAG is a benchmark dataset used for evaluating news articles, published by Tang and Yang in 2024.
A research paper focused on benchmarking retrieval-augmented generation for multi-hop queries, published in 2024.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,d4c8ce26fd0f9a7bc6dad0efa1ce98e3,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="OPENORD">
      <data key="d0">TOOL, SOFTWARE</data>
      <data key="d1">OpenORD is a tool used for node layout in graph visualizations, helping to display the structure of graph communities.
An open-source toolbox for large graph layout developed by Martin, S., Brown, W. M., Klavans, R., and Boyack, K.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="FORCE ATLAS 2">
      <data key="d0">TOOL, SOFTWARE</data>
      <data key="d1">Force Atlas 2 is a tool used for node layout in graph visualizations, helping to display the structure of graph communities.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="FORTUNATO, 2010">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fortunato is the author of a survey from 2010 on community detection algorithms.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="JIN ET AL., 2021">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jin et al. are the authors of a survey from 2021 on community detection algorithms.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="TRAAG ET AL., 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Traag et al. are the authors of the Leiden algorithm, published in 2019.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="TANG AND YANG, 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tang and Yang are the authors of a study from 2024 that indexed the MultiHop-RAG dataset.
Tang and Yang are researchers who published the MultiHop-RAG benchmark dataset in 2024.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="MARTIN ET AL., 2011">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Martin et al. are the authors of the OpenORD tool, published in 2011.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="JACOMY ET AL., 2014">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jacomy et al. are the authors of the Force Atlas 2 tool, published in 2014.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="DEFAULT PROMPT">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">The default prompt is used to extract a broad class of named entities like people, places, and organizations. It is generally applicable across various domains.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="SECONDARY EXTRACTION PROMPT">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">The secondary extraction prompt is used to extract additional covariates associated with the detected entities, such as claims linked to these entities.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="LOGIT BIAS">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Logit bias is a technique used to force a yes/no decision from the LLM during the entity extraction process, ensuring that all entities are detected.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="HOMOGENEOUS NODES">
      <data key="d0">CONCEPT, DATA TYPE</data>
      <data key="d1">Homogeneous nodes refer to nodes in a graph that are similar in nature, often used in the context of creating rich descriptive text for summarization.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="NOISE">
      <data key="d0">CONCEPT, DATA TYPE</data>
      <data key="d1">Noise refers to irrelevant or extraneous information that can be introduced during the extraction process, potentially affecting the quality of the extracted data.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="HIERARCHICAL COMMUNITY STRUCTURE">
      <data key="d0">CONCEPT, DATA TYPE</data>
      <data key="d1">Hierarchical community structure refers to the organization of graph communities in a hierarchical manner, where communities are nested within larger communities.
Hierarchical community structure is an organizational framework that groups data into nested communities, used in Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="ROOT COMMUNITIES">
      <data key="d0">CONCEPT, DATA TYPE</data>
      <data key="d1">Root communities are the top-level communities in a hierarchical community structure, representing the highest level of modularity in the graph.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="SUB-COMMUNITIES">
      <data key="d0">CONCEPT, DATA TYPE</data>
      <data key="d1">Sub-communities are lower-level communities within a hierarchical community structure, revealing internal structure within root-level communities.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="LEAF-LEVEL COMMUNITIES">
      <data key="d0">CONCEPT, DATA TYPE</data>
      <data key="d1">Leaf-level communities are the smallest units in a hierarchical community structure, containing the most detailed element summaries of nodes, edges, and covariates.
Leaf-level communities are the lowest hierarchical level in a community structure, where element summaries of nodes, edges, and covariates are prioritized and added to the LLM context window until the token limit is reached.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="NODE DEGREE">
      <data key="d0">CONCEPT, DATA TYPE</data>
      <data key="d1">Node degree refers to the number of connections a node has in a graph, often used to prioritize elements during the summarization process.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="ROOT-LEVEL COMMUNITIES">
      <data key="d0">COMMUNITY STRUCTURE</data>
      <data key="d1">Root-level communities represent the highest hierarchical level in a community structure, revealing internal structures within them.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="HIGHER-LEVEL COMMUNITIES">
      <data key="d0">COMMUNITY STRUCTURE</data>
      <data key="d1">Higher-level communities are above leaf-level communities in the hierarchy. If all element summaries fit within the token limit, they are summarized similarly to leaf-level communities; otherwise, sub-community summaries are used.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="USER QUERY">
      <data key="d0">QUERY</data>
      <data key="d1">A user query is a question posed by the user that the system aims to answer using community summaries from different levels of the hierarchical community structure.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="TECH JOURNALIST">
      <data key="d0">USER</data>
      <data key="d1">A tech journalist is a potential user looking for insights and trends in the tech industry, particularly regarding the role of policy and regulation.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="EDUCATOR">
      <data key="d0">USER</data>
      <data key="d1">An educator is a potential user incorporating current affairs into curricula, particularly focusing on health and wellness.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="MT-BENCH">
      <data key="d0">DATASET, BENCHMARK</data>
      <data key="d1">MT-Bench is a benchmark dataset for open-domain question answering, targeting explicit fact retrieval, published by Zheng et al. in 2024.
A benchmark used to evaluate models, with Orca-3 scoring 8.20, which is a 9% improvement over Orca-2.5.
MT-Bench is a benchmark designed to assess the competence of chat assistants in multi-turn conversations using GPT-4 as the evaluator.
MT-Bench is a benchmarking tool developed by LM-Sys, published in 2023.
MT-Bench is a benchmark consisting of a first-turn query and a second-turn query, evaluated by GPT-4, which provides a score from 1 to 10 for each turn's response.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,3d1f6634f93f8a4c296dc8df7e59859e,4930fce6da868f894757a9da465807ba,86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="RAG SYSTEMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">RAG systems are used for global sensemaking tasks, requiring questions that convey a high-level understanding of dataset contents.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="KOESTEN ET AL., 2021">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Koesten et al. are researchers who discussed the process of data sensemaking in 2021.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="XU AND LAPATA, 2021">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xu and Lapata are researchers who developed methods for extracting latent summarization queries from source texts in 2021.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="NODES">
      <data key="d0">ELEMENT</data>
      <data key="d1">Nodes are elements within a community structure that are described and prioritized in leaf-level communities.
Nodes are components in search algorithms that store and retrieve external feedback, playing a crucial role in the search process of LATS.
Elements sampled during the expansion phase in LATS evaluation.
Nodes refer to individual points or states in a search algorithm that are expanded or explored to find a solution.
Nodes refer to the points in the search tree expanded during the exploration process in algorithms like LATS, used in tasks like Game of 24.
Nodes are components in the LATS algorithm that are stored explicitly in memory and expanded during the search process.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,4930fce6da868f894757a9da465807ba,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="EDGES">
      <data key="d0">ELEMENT</data>
      <data key="d1">Edges are elements within a community structure that connect nodes and are described and prioritized in leaf-level communities.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="TOKEN LIMIT">
      <data key="d0">CONSTRAINT</data>
      <data key="d1">The token limit is a constraint that determines how many tokens can be included in the LLM context window or final context for generating answers.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="LLM CONTEXT WINDOW">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The LLM context window is the space within which tokens are added and processed by the language model to generate summaries and answers.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="INTERMEDIATE ANSWERS">
      <data key="d0">ANSWER</data>
      <data key="d1">Intermediate answers are generated for each chunk of community summaries and are scored for helpfulness before being combined into the global answer.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="HELPFULNESS SCORE">
      <data key="d0">METRIC</data>
      <data key="d1">The helpfulness score is a metric between 0-100 that indicates how helpful an intermediate answer is in answering the target question.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="KEVIN SCOTT">
      <data key="d0">PERSON</data>
      <data key="d1">Kevin Scott is the CTO of Microsoft and a participant in the podcast transcripts dataset.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="TECHNOLOGY LEADERS">
      <data key="d0">PERSON</data>
      <data key="d1">Technology leaders are participants in the podcast transcripts dataset, engaging in conversations with Kevin Scott.</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="ZHENG ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zheng et al. are researchers who published the MT-Bench benchmark dataset in 2024.
Researchers who have demonstrated the effectiveness of LLMs in head-to-head comparison of competing outputs.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,4930fce6da868f894757a9da465807ba</data>
    </node>
    <node id="DATASET">
      <data key="d0">DATA, COLLECTION</data>
      <data key="d1">A collection of data used for analysis and evaluation, often described in terms of its contents and structure.
A collection of data used for training and evaluating models, such as Orca-Bench and the data synthesized by AgentInstruct.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="USER">
      <data key="d0">PERSON, ROLE</data>
      <data key="d1">Individuals or entities that interact with the dataset or system, performing specific tasks or queries.
The individual who interacts with the AI assistant, providing input and requesting actions such as creating a meal plan, tracking meals, and updating food items.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="TASK">
      <data key="d0">ACTIVITY, OPERATION</data>
      <data key="d1">Specific activities or operations performed by users, often involving interaction with the dataset or system.
A task is an activity or job that an agent is designed to perform or solve.
A task in the Meta Agent Search algorithm refers to the specific problem or objective that the meta agent aims to solve by programming new agents.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,26b2dad01a219bc034ac7d6a32d07582,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="QUESTION">
      <data key="d0">QUERY, INQUIRY</data>
      <data key="d1">Questions generated to evaluate understanding of the dataset, requiring comprehensive knowledge of the entire corpus.
A query that initiates a question-answering task, requiring analysis and reasoning to find the correct answer.
A query or prompt provided to a student, which requires a response that is evaluated for accuracy or understanding.
A problem or query presented to the student, often requiring a solution or answer.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,26b2dad01a219bc034ac7d6a32d07582,357f3442ba581c9d2bdf84d90509056f,5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TEXT SUMMARIZATION (TS)">
      <data key="d0">METHOD, ALGORITHM</data>
      <data key="d1">A method applying a map-reduce approach directly to source texts for summarization purposes.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="SEMANTIC SEARCH (SS)">
      <data key="d0">METHOD, ALGORITHM</data>
      <data key="d1">A naive RAG approach where text chunks are retrieved and added to the context window until the token limit is reached.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="CONTEXT WINDOW">
      <data key="d0">TECHNICAL TERM, PARAMETER</data>
      <data key="d1">The size of the text window used for generating answers, consistent across all conditions except for minor modifications.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="ENTITY">
      <data key="d0">CONCEPT, ELEMENT</data>
      <data key="d1">Basic units identified in the dataset, used for creating the graph index in the Graph RAG method.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="RELATIONSHIP">
      <data key="d0">CONCEPT, CONNECTION</data>
      <data key="d1">Connections between entities, used for creating the graph index in the Graph RAG method.
The current romantic involvement of Alex, which complicates Elliot's confession.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="PODCAST DATASET">
      <data key="d0">DATASET, COLLECTION</data>
      <data key="d1">A specific dataset used in the evaluation, with a context window size of 600 tokens and 1 gleaning.
A dataset consisting of Podcast transcripts used to evaluate the performance of different summarization approaches.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="NEWS DATASET">
      <data key="d0">DATASET, COLLECTION</data>
      <data key="d1">A specific dataset used in the evaluation, with a context window size of 600 tokens and 0 gleanings.
A dataset consisting of News articles used to evaluate the performance of different summarization approaches.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="DIRECTNESS">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">A control metric capturing how specifically and clearly an answer addresses the question.
A measure of how straightforward and specific an answer or report is in addressing the question.
A metric used to evaluate the straightforwardness and clarity of the answers provided by different summarization approaches.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,c8e8019de153e439d6a79dcf209b943b,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="LLM EVALUATOR">
      <data key="d0">TECHNOLOGY, TOOL</data>
      <data key="d1">A Large Language Model used to evaluate answers based on specific metrics, performing head-to-head comparisons of competing outputs.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="PUBLIC FIGURES">
      <data key="d0">PERSON, ENTITY</data>
      <data key="d1">Individuals repeatedly mentioned across various entertainment articles, reflecting their impact and presence within the industry.
Individuals who are well-known in society and often covered in media, including celebrities, politicians, and other influential people.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="ENTERTAINMENT INDUSTRY">
      <data key="d0">SECTOR, FIELD</data>
      <data key="d1">A diverse industry encompassing film, television, music, sports, and digital media, influenced by prominent public figures.
The sector of the economy that produces and distributes entertainment content, including film, television, music, sports, and digital media.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="ACTIVITY-CENTERED APPROACH">
      <data key="d0">METHOD, STRATEGY</data>
      <data key="d1">An approach used to automate the generation of questions by focusing on activities related to the dataset.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="N">
      <data key="d0">PARAMETER, VARIABLE</data>
      <data key="d1">A variable representing the number of potential users, tasks per user, or questions generated per (user, task) combination.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="EVALUATION">
      <data key="d0">PROCESS, ASSESSMENT</data>
      <data key="d1">The process of assessing the performance or effectiveness of different methods or conditions using specific metrics.
Evaluation is the third operation in LATS where a scalar value is assigned to each new child node to quantify the agent&#8217;s progress in task completion.
The third operation in the LATS algorithm that assigns a scalar value to each new child node for selection and backpropagation, quantifying the agent&#8217;s progress in task completion.
Evaluation refers to the process of assessing the performance and effectiveness of discovered agents, a critical step in Meta Agent Search.
Evaluation in Meta Agent Search involves assessing the performance of discovered agents on validation and test sets.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,1a6353c9d196dc2debad7c27c902bcd7,26b2dad01a219bc034ac7d6a32d07582,81c504ffbcc5ed882e234802135295ba,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="CONDITION">
      <data key="d0">PARAMETER, VARIABLE</data>
      <data key="d1">Different settings or methods (e.g., C0, C1, C2, C3, TS, SS) compared in the analysis to evaluate their performance.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="ANSWER GENERATION">
      <data key="d0">PROCESS, ACTIVITY</data>
      <data key="d1">The process of generating answers to user queries, influenced by the size of the context window and the prompts used.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="PROMPT">
      <data key="d0">TECHNICAL TERM, PARAMETER</data>
      <data key="d1">Instructions or questions given to the LLM to generate answers or perform specific tasks.
Prompts are specific instructions or few-shot input-output examples provided along with the input to improve reasoning in language models.
A set of instructions or examples provided to guide the language model in performing a task
A prompt is an instruction or input provided to the meta agent in the Meta Agent Search algorithm to guide the programming of new agents.
A set of instructions provided to the meta agent to guide its thought process, design, and implementation of the next function or agent architecture.
The initial input or question used to condition the response during the training of the Orca-3 model.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,24d7b89ae9522ae60d2317984951355b,26b2dad01a219bc034ac7d6a32d07582,282313a8340c6792e8c35f53ed157cd0,b8dd0300033963bb4a3e1bad37f8e7b9,c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="GLEANING">
      <data key="d0">PROCESS, ACTIVITY</data>
      <data key="d1">The process of extracting information from the dataset, used in the context window size for the Podcast and News datasets.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="RAGAS">
      <data key="d0">METHOD, ALGORITHM</data>
      <data key="d1">A method for automatically evaluating the performance of RAG systems, focusing on qualities like context relevance, faithfulness, and answer relevance.
RAGAS is a method for automated evaluation of retrieval augmented generation, described in a paper by Es et al. (2023).</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HEAD-TO-HEAD COMPARISON">
      <data key="d0">METHOD, EVALUATION</data>
      <data key="d1">A method of comparing competing outputs directly against each other using specific metrics.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="WANG ET AL., 2023A">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Researchers who have shown that LLMs can achieve state-of-the-art or competitive results in evaluating natural language generation.
Wang et al. are the authors who contributed to the development of new skills for embodied agents, published in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="ES ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Researchers who have contributed to the development of RAGAS for evaluating RAG systems.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="PROMINENT PUBLIC FIGURES">
      <data key="d0">PERSON, ENTITY</data>
      <data key="d1">Key individuals repeatedly mentioned in various entertainment articles, reflecting their significant contributions and influence.</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="DIRECTORS">
      <data key="d0">PROFESSION, ROLE</data>
      <data key="d1">Individuals who oversee the creative aspects of film, television, or other media productions.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="MUSICIANS">
      <data key="d0">PROFESSION, ROLE</data>
      <data key="d1">Individuals who create, perform, and record music.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="EXECUTIVES">
      <data key="d0">PROFESSION, ROLE</data>
      <data key="d1">Individuals who hold senior management positions in organizations, making high-level decisions.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="ATHLETES">
      <data key="d0">PROFESSION, ROLE</data>
      <data key="d1">Individuals who compete in sports and physical activities at professional or amateur levels.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="COACHES">
      <data key="d0">PROFESSION, ROLE</data>
      <data key="d1">Individuals who train and guide athletes or teams in sports.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="INFLUENCERS">
      <data key="d0">PROFESSION, ROLE</data>
      <data key="d1">Individuals who have the power to affect the purchasing decisions of others because of their authority, knowledge, position, or relationship with their audience.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="ENTREPRENEURS">
      <data key="d0">PROFESSION, ROLE</data>
      <data key="d1">Individuals who start and run businesses, taking on financial risks in the hope of profit.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="TAYLOR SWIFT">
      <data key="d0">PERSON, MUSICIAN</data>
      <data key="d1">A well-known musician and public figure frequently mentioned in entertainment articles for her professional achievements and personal life.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="TRAVIS KELCE">
      <data key="d0">PERSON, ATHLETE</data>
      <data key="d1">A professional athlete frequently mentioned in entertainment articles for his sports achievements and personal life.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="BRITNEY SPEARS">
      <data key="d0">PERSON, MUSICIAN</data>
      <data key="d1">A well-known musician and public figure frequently mentioned in entertainment articles for her professional achievements and personal life.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="JUSTIN TIMBERLAKE">
      <data key="d0">PERSON, MUSICIAN</data>
      <data key="d1">A well-known musician and public figure frequently mentioned in entertainment articles for his professional achievements and personal life.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="MEDIA COVERAGE">
      <data key="d0">ACTIVITY, PROCESS</data>
      <data key="d1">The reporting and discussion of events, people, and topics in various media outlets.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">ACTIVITY, PROCESS</data>
    </node>
    <node id="CULTURAL NARRATIVES">
      <data key="d0">CONCEPT, IDEA</data>
      <data key="d1">The stories and ideas that are prevalent in a culture, often shaped by influential figures in entertainment.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="DIGITAL MEDIA">
      <data key="d0">MEDIUM, TECHNOLOGY</data>
      <data key="d1">Platforms and technologies used for digital communication, including social media, websites, and streaming services.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">MEDIUM, TECHNOLOGY</data>
    </node>
    <node id="CONTROVERSIES">
      <data key="d0">EVENT, ISSUE</data>
      <data key="d1">Public disputes or debates that attract widespread attention and often involve public figures.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="CONTROVERSY">
      <data key="d0">EVENT, ISSUE</data>
      <data key="d1">A public dispute or debate that attracts widespread attention, often involving public figures.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="FILM">
      <data key="d0">MEDIUM, CONTENT</data>
      <data key="d1">A form of visual storytelling that involves the production of movies.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="TELEVISION">
      <data key="d0">MEDIUM, CONTENT</data>
      <data key="d1">A medium for broadcasting visual content, including shows, series, and news.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="MUSIC">
      <data key="d0">MEDIUM, CONTENT</data>
      <data key="d1">An art form and cultural activity involving the creation and performance of sound organized in time.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="SPORTS">
      <data key="d0">MEDIUM, CONTENT</data>
      <data key="d1">Physical activities and games that involve competition and skill.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="GAMING">
      <data key="d0">MEDIUM, CONTENT</data>
      <data key="d1">The activity of playing electronic games, often involving interaction with a user interface to generate visual feedback.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="TRENDS">
      <data key="d0">CONCEPT, IDEA</data>
      <data key="d1">General directions in which something is developing or changing, often influenced by public figures.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="CULTURAL LANDSCAPE">
      <data key="d0">CONCEPT, IDEA</data>
      <data key="d1">The cultural environment shaped by the activities and influences of public figures and media.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="SOCIAL DISCUSSIONS">
      <data key="d0">ACTIVITY, PROCESS</data>
      <data key="d1">Public conversations and debates about various topics, often influenced by public figures.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="PUBLIC DISCOURSE">
      <data key="d0">ACTIVITY, PROCESS</data>
      <data key="d1">The exchange of ideas and information in the public sphere, often involving public figures.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="PROFESSIONAL ACHIEVEMENTS">
      <data key="d0">ACTIVITY, PROCESS</data>
      <data key="d1">Notable accomplishments in one's career or profession.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="PERSONAL LIVES">
      <data key="d0">ACTIVITY, PROCESS</data>
      <data key="d1">Aspects of individuals' lives that are private or related to their personal relationships.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="CULTURAL AND ECONOMIC IMPACTS">
      <data key="d0">CONCEPT, IDEA</data>
      <data key="d1">The effects that public figures and their activities have on culture and the economy.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="ENTERTAINMENT ARTICLES">
      <data key="d0">MEDIUM, CONTENT</data>
      <data key="d1">Written pieces in media outlets that focus on topics related to entertainment and public figures.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="DATA REPORTS">
      <data key="d0">MEDIUM, CONTENT</data>
      <data key="d1">Documents that provide detailed information and analysis on specific topics, often used as references.</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
    </node>
    <node id="NAIVE RAG">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Naive RAG is a baseline approach for text summarization that is outperformed by global approaches in terms of comprehensiveness and diversity.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="CONTEXT WINDOW SIZE">
      <data key="d0">PARAMETER</data>
      <data key="d1">The size of the context window used in language models, tested at 8k, 16k, 32k, and 64k tokens to determine its effect on comprehensiveness, diversity, and empowerment.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="GPT-4-TURBO">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">An advanced language model with a large context size of 128k tokens, used to explore the effects of varying context window sizes.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="ROOT-LEVEL SUMMARIES">
      <data key="d0">DATA, METHOD</data>
      <data key="d1">Summaries generated at the root level of a graph community hierarchy, requiring dramatically fewer tokens per query.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="INTERMEDIATE-LEVEL SUMMARIES">
      <data key="d0">DATA, METHOD</data>
      <data key="d1">Summaries generated at intermediate levels of a graph community hierarchy, providing consistent improvement in answer comprehensiveness and diversity.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="LOW-LEVEL SUMMARIES">
      <data key="d0">DATA, METHOD</data>
      <data key="d1">Summaries generated at low levels of a graph community hierarchy, providing consistent improvement in answer comprehensiveness and diversity.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="MAP-REDUCE SUMMARIZATION">
      <data key="d0">METHOD</data>
      <data key="d1">A resource-intensive approach to summarizing source texts, requiring the highest number of context tokens.
Map-reduce summarization is a technique that uses the map-reduce framework to summarize large datasets, compared to Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="SS">
      <data key="d0">METHOD</data>
      <data key="d1">SS is a baseline condition used in the evaluation of different context window sizes and summarization approaches.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="TS">
      <data key="d0">METHOD</data>
      <data key="d1">TS stands for global text summarization without a graph index, used as a comparison condition in the evaluation.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C0">
      <data key="d0">METHOD</data>
      <data key="d1">C0 represents root-level community summaries in the graph community hierarchy, requiring dramatically fewer tokens per query.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C1">
      <data key="d0">METHOD</data>
      <data key="d1">C1 represents intermediate-level community summaries in the graph community hierarchy, providing consistent improvement in answer comprehensiveness and diversity.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C2">
      <data key="d0">METHOD</data>
      <data key="d1">C2 represents low-level community summaries in the graph community hierarchy, providing consistent improvement in answer comprehensiveness and diversity.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C3">
      <data key="d0">METHOD</data>
      <data key="d1">C3 represents the lowest level of community summaries in the graph community hierarchy, providing consistent improvement in answer comprehensiveness and diversity.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="WIN RATE">
      <data key="d0">METRIC</data>
      <data key="d1">Win rate is a metric used to evaluate the performance of different summarization approaches in terms of comprehensiveness, diversity, and empowerment.</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="CONTEXT TOKENS">
      <data key="d0">DATA</data>
      <data key="d1">Context tokens refer to the number of tokens used in different summarization approaches, with Graph RAG requiring fewer tokens compared to source text summarization.
Context tokens are units of information used in the context window of an LLM, with Graph RAG requiring fewer tokens compared to other methods.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="ROOT-LEVEL COMMUNITY SUMMARIES">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">Root-level community summaries are high-level summaries that require significantly fewer context tokens in Graph RAG compared to other methods.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="GAO ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gao et al. are researchers who have contributed to the development of Na&#239;ve RAG and advanced RAG systems, published in 2023.
Gao et al. are the authors of a significant paper on language models, published in 2023.
Gao et al. are the authors of a study in 2023 discussing the GSM-Hard math task benchmark.
Gao et al. are the authors of the GSM-Hard dataset, published in 2023, which is used to evaluate the transferability of discovered agents from MGSM math tasks to more challenging math tasks.
Gao et al. are the authors of the GSM-Hard benchmark, published in 2023.
Gao et al. are the authors of the GSM-Hard dataset, published in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,81c504ffbcc5ed882e234802135295ba,93cb0d0456e0822b5fe30a3e627405f8,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CHENG ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cheng et al. are researchers who have contributed to the concept of self-memory (Selfmem) for generation-augmented retrieval, published in 2024.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="MAO ET AL., 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mao et al. are researchers who have contributed to the concept of generation-augmented retrieval (GAR), published in 2020.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SHAO ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shao et al. are researchers who have contributed to the concept of iterative retrieval-generation (Iter-RetGen), published in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="WANG ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang et al. are researchers who have contributed to the concept of federated retrieval-generation (FeB4RAG), published in 2024.
Wang et al. are authors cited in the paper, contributing to the research on agentic systems and their applications.
Wang et al. are the authors of the study that discusses the effectiveness of Meta Agent Search in various domains, published in 2024.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71,c3d0436082aada237ee4bee645f16059,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CAIRE-COVID">
      <data key="d0">SYSTEM, APPLICATION</data>
      <data key="d1">CAiRE-COVID is a system that combines multiple concepts for multi-document summarization, developed in 2020.
CAIRE-COVID is a question answering and query-focused multi-document summarization technique developed by Su, D., Xu, Y., Yu, T., Siddique, F. B., Barezi, E. J., and Fung, P. in 2020.
A question answering and query-focused multi-document summarization system for managing covid-19 scholarly information, published in 2020.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="FENG ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Feng et al. are researchers who have contributed to the concept of multi-hop question answering (ITRG), published in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="TRIVEDI ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Trivedi et al. are researchers who have contributed to the concept of multi-hop question answering (IR-CoT), published in 2022.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="KHATTAB ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Khattab et al. are researchers who have contributed to the concept of multi-hop question answering (DSP), published in 2022.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SARTHI ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sarthi et al. are researchers who have contributed to the concept of generating a hierarchical index of text chunks (RAPTOR), published in 2024.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="KIM ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kim et al. are researchers who have contributed to the concept of generating a "tree of clarifications" for answering multiple interpretations of ambiguous questions, published in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="TRAJANOSKA ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Trajanoska et al. are researchers who have contributed to the use of LLMs for knowledge graph creation and completion, published in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YAO ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yao et al. are researchers who have contributed to the use of LLMs for knowledge graph creation and completion, published in 2023.
Yao et al. are authors cited in the paper, contributing to the research on chain-of-thought planning and reasoning.
Yao et al. are the authors who contributed to the development of chain-of-thought-based planning and reasoning methods, published in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,c3d0436082aada237ee4bee645f16059,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="BAN ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ban et al. are researchers who have contributed to the extraction of causal graphs from source texts, published in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ZHANG ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhang et al. are researchers who have contributed to the extraction of causal graphs from source texts, published in 2024.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="BAEK ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Baek et al. are researchers who have contributed to the development of advanced RAG systems where the index is a knowledge graph (KAPING), published in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="HE ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">He et al. are researchers who have contributed to the development of advanced RAG systems where subsets of the graph structure are the objects of enquiry (G-Retriever), published in 2024.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="KANG ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kang et al. are researchers who have contributed to the development of advanced RAG systems where narrative outputs are grounded in the facts of retrieved subgraphs (SURGE), published in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="RANADE AND JOSHI, 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ranade and Joshi are researchers who have contributed to the development of advanced RAG systems where retrieved event-plot subgraphs are serialized using narrative templates (FABULA), published in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="WANG ET AL., 2023B">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang et al. are researchers who have contributed to the development of systems that support both creation and traversal of text-relationship graphs for multi-hop question answering, published in 2023.
Wang et al. are researchers who developed the Self-Consistency with Chain-of-Thought (COT-SC) method in 2023.
Wang et al. are the authors of the COT-SC algorithm, published in 2023.
Wang et al. are the authors of the COT-SC algorithm, published in 2023.
Wang et al. are the authors of the COT-SC algorithm, published in 2023.
Wang et al. are the authors of research on COT-SC, published in 2023.
Wang et al. are the authors of the Self-Consistency with Chain-of-Thought (COT-SC) algorithm, published in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="LANGCHAIN">
      <data key="d0">SOFTWARE, LIBRARY</data>
      <data key="d1">LangChain is an open-source software library that supports various graph databases for RAG applications, developed in 2024.
LangChain is a framework for building applications with language models, including features like LangChain Graphs.
LangChain is an open-source agent framework that can be used within the code search space of ADAS to build upon existing building blocks like RAG and search engine tools.
LangChain is an existing agent framework that can be used as a building block in ADAS to support multi-modal capabilities and flexible use of different foundational models (FMs).
Langchain is a tool for building context-aware reasoning applications, developed by LangChainAI and available on GitHub since 2022.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,6109537356a2ce2339f77c827aa3668e,6bdf681c0bd9e401ac72344a6a0ae479,df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SOFTWARE, LIBRARY</data>
    </node>
    <node id="LLAMAINDEX">
      <data key="d0">SOFTWARE, LIBRARY</data>
      <data key="d1">LlamaIndex is an open-source software library that supports various graph databases for RAG applications, developed in 2024.
LlamaIndex is a framework for building knowledge graph indexes for language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SOFTWARE, LIBRARY</data>
    </node>
    <node id="NEO4J">
      <data key="d0">SOFTWARE, DATABASE</data>
      <data key="d1">Neo4J is a graph database supported by LangChain and LlamaIndex for creating and reasoning over knowledge graphs in RAG applications.
Neo4J is a graph database management system that can create and reason over knowledge graphs. It is used in the NaLLM system.
Neo4J is a technology framework that developed Project NaLLM.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8,df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SOFTWARE, DATABASE</data>
    </node>
    <node id="NEBULAGRAPH">
      <data key="d0">SOFTWARE, DATABASE</data>
      <data key="d1">NebulaGraph is a graph database supported by LangChain and LlamaIndex for creating and reasoning over knowledge graphs in RAG applications.
NebulaGraph is a graph database management system that can create and reason over knowledge graphs. It is used in the GraphRAG system.
NebulaGraph is a technology framework that launched the industry-first graph RAG: Retrieval-augmented generation with LLM based on knowledge graphs.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8,df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SOFTWARE, DATABASE</data>
    </node>
    <node id="NALLM">
      <data key="d0">SYSTEM, APPLICATION</data>
      <data key="d1">NaLLM is a system that can create and reason over knowledge graphs in Neo4J format, developed in 2024.
NaLLM is a system that creates and reasons over knowledge graphs in Neo4J format.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SYSTEM, APPLICATION</data>
    </node>
    <node id="GRAPHRAG">
      <data key="d0">SYSTEM, APPLICATION</data>
      <data key="d1">GraphRAG is a system that can create and reason over knowledge graphs in NebulaGraph format, developed in 2024.
GraphRAG is a system that creates and reasons over knowledge graphs in NebulaGraph format.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SYSTEM, APPLICATION</data>
    </node>
    <node id="RAM ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ram et al. are researchers who have contributed to the understanding of RAG approaches and systems, published in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SU ET AL., 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Su et al. are researchers who have contributed to the development of CAiRE-COVID for multi-document summarization, published in 2020.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SENSEMAKING ACTIVITY">
      <data key="d0">CONCEPT, TASK</data>
      <data key="d1">Sensemaking activity refers to the iterative process of understanding and making sense of complex information, often facilitated by methods like Graph RAG.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, TASK</data>
    </node>
    <node id="SCALABILITY">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">Scalability refers to the ability of a system or method to handle increasing amounts of work or data efficiently, as demonstrated by Graph RAG's use of fewer context tokens.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METRIC</data>
    </node>
    <node id="ITERATIVE QUESTION ANSWERING">
      <data key="d0">CONCEPT, TASK</data>
      <data key="d1">Iterative question answering is a process where questions are answered through multiple cycles of retrieval and generation, as facilitated by Graph RAG.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, TASK</data>
    </node>
    <node id="MODULAR RAG">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Modular RAG is an advanced RAG system that includes patterns for iterative and dynamic cycles of interleaved retrieval and generation.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="SELF-MEMORY (SELFMEM)">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Self-memory (Selfmem) is a concept for generation-augmented retrieval that facilitates future generation cycles, contributed by Cheng et al. in 2024.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="GENERATION-AUGMENTED RETRIEVAL (GAR)">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Generation-augmented retrieval (GAR) is a concept that facilitates future generation cycles, contributed by Mao et al. in 2020.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="ITERATIVE RETRIEVAL-GENERATION (ITER-RETGEN)">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Iterative retrieval-generation (Iter-RetGen) is a concept for iterative cycles of retrieval and generation, contributed by Shao et al. in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="FEDERATED RETRIEVAL-GENERATION (FEB4RAG)">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Federated retrieval-generation (FeB4RAG) is a concept for federated cycles of retrieval and generation, contributed by Wang et al. in 2024.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="MULTI-DOCUMENT SUMMARIZATION">
      <data key="d0">CONCEPT, TASK</data>
      <data key="d1">Multi-document summarization is the process of creating summaries from multiple documents, as facilitated by systems like CAiRE-COVID.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, TASK</data>
    </node>
    <node id="MULTI-HOP QUESTION ANSWERING">
      <data key="d0">CONCEPT, TASK</data>
      <data key="d1">Multi-hop question answering is a process where questions are answered by traversing multiple pieces of information, as facilitated by systems like ITRG, IR-CoT, and DSP.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, TASK</data>
    </node>
    <node id="HIERARCHICAL INDEX">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Hierarchical index is a method of organizing text chunks by clustering the vectors of text embeddings, as seen in RAPTOR.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="TREE OF CLARIFICATIONS">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Tree of clarifications is a method for answering multiple interpretations of ambiguous questions, contributed by Kim et al. in 2023.
A method for answering ambiguous questions with retrieval-augmented large language models, described in a paper by Kim et al. (2023).</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="CAUSAL GRAPHS">
      <data key="d0">CONCEPT, DATA STRUCTURE</data>
      <data key="d1">CCausal graphs are data structures that represent causal relationships, extracted from source texts by researchers like Ban et al. and Zhang et al.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, DATA STRUCTURE</data>
    </node>
    <node id="G-RETRIEVER">
      <data key="d0">SYSTEM, APPLICATION</data>
      <data key="d1">G-Retriever is a system where subsets of the graph structure are the objects of enquiry, developed by He et al. in 2024.
G-retriever is a method for retrieval-augmented generation for textual graph understanding and question answering, described in a paper by He et al. (2024).</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SYSTEM, APPLICATION</data>
    </node>
    <node id="GRAPH-TOOLFORMER">
      <data key="d0">SYSTEM, APPLICATION</data>
      <data key="d1">Graph-ToolFormer is a system where derived graph metrics are the objects of enquiry, developed by Zhang in 2023.
A research paper focused on empowering large language models with graph reasoning ability via prompts augmented by ChatGPT, published in 2023.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SYSTEM, APPLICATION</data>
    </node>
    <node id="SURGE">
      <data key="d0">SYSTEM, APPLICATION</data>
      <data key="d1">SURGE is a system where narrative outputs are grounded in the facts of retrieved subgraphs, developed by Kang et al. in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SYSTEM, APPLICATION</data>
    </node>
    <node id="FABULA">
      <data key="d0">SYSTEM, APPLICATION</data>
      <data key="d1">FABULA is a system where retrieved event-plot subgraphs are serialized using narrative templates, developed by Ranade and Joshi in 2023.
A technique for intelligence report generation using retrieval-augmented narrative construction.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SYSTEM, APPLICATION</data>
    </node>
    <node id="TEXT-RELATIONSHIP GRAPHS">
      <data key="d0">CONCEPT, DATA STRUCTURE</data>
      <data key="d1">Text-relationship graphs are data structures that support both creation and traversal for multi-hop question answering, as seen in systems developed by Wang et al. in 2023.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, DATA STRUCTURE</data>
    </node>
    <node id="NEO4J FORMAT">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">Neo4J format is a data format used for creating and reasoning over knowledge graphs in systems like NaLLM.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">DATA FORMAT</data>
    </node>
    <node id="NEBULAGRAPH FORMAT">
      <data key="d0">DATA FORMAT</data>
      <data key="d1">NebulaGraph format is a data format used for creating and reasoning over knowledge graphs in systems like GraphRAG.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">DATA FORMAT</data>
    </node>
    <node id="ITERATIVE CYCLES">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Iterative cycles refer to repeated processes of retrieval and generation, as seen in methods like Iter-RetGen and FeB4RAG.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="NARRATIVE TEMPLATES">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Narrative templates are predefined structures used to serialize event-plot subgraphs, as seen in the FABULA system.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="PARTITION DATA">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Partition data refers to the division of data into segments for more efficient processing, as seen in Graph RAG's use of graph modularity.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="MODULARITY">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Modularity refers to the natural division of graphs into modules or segments, used in Graph RAG for efficient data partitioning and summarization.
A property of the LATS algorithm that allows its components, such as the base LM agent, reflection generator, and value function, to be independently altered and adapted.
The ability to independently alter and adapt components like the base LM agent, reflection generator, and value function in LATS.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,edab4014b8f55e5b25bd7f396314be1f,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="EXTERNAL DATA SOURCES">
      <data key="d0">CONCEPT, RESOURCE</data>
      <data key="d1">External data sources are sources of information outside the LLM's initial dataset, used in RAG methods for retrieval and context addition.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, RESOURCE</data>
    </node>
    <node id="VECTOR SPACE">
      <data key="d0">CONCEPT, DATA STRUCTURE</data>
      <data key="d1">Vector space is a mathematical space where text chunks and queries are embedded for retrieval in RAG methods.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, DATA STRUCTURE</data>
    </node>
    <node id="TEXT EMBEDDINGS">
      <data key="d0">CONCEPT, DATA STRUCTURE</data>
      <data key="d1">Text embeddings are vector representations of text chunks used in RAG methods for retrieval and context addition.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, DATA STRUCTURE</data>
    </node>
    <node id="SEMANTICS">
      <data key="d0">CONCEPT, FIELD</data>
      <data key="d1">Semantics refers to the meaning of text, with similar positions in a vector space representing similar semantics in RAG methods.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, FIELD</data>
    </node>
    <node id="QUERY">
      <data key="d0">CONCEPT, TASK</data>
      <data key="d1">Query refers to the original question or request for information that is augmented with retrieved data in RAG methods.
A term or phrase entered by the user to search for specific products in the web shop</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, TASK</data>
    </node>
    <node id="PRE-RETRIEVAL STRATEGIES">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Pre-retrieval strategies are methods used before the retrieval process to enhance the efficiency and effectiveness of RAG systems.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="POST-RETRIEVAL STRATEGIES">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Post-retrieval strategies are methods used after the retrieval process to enhance the efficiency and effectiveness of RAG systems.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="INTERLEAVED RETRIEVAL AND GENERATION">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Interleaved retrieval and generation refers to the dynamic cycles of retrieval and generation in Modular RAG systems.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="PODCAST INTERMEDIATE-LEVEL SUMMARIES">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">Podcast intermediate-level summaries are summaries generated from podcast data, used in Graph RAG for efficient summarization and question answering.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="NEWS LOW-LEVEL COMMUNITY SUMMARIES">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">News low-level community summaries are summaries generated from news data at a low level, used in Graph RAG for efficient summarization and question answering.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="TABLE 3">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">Table 3 illustrates the scalability advantages of Graph RAG compared to source text summarization, showing the reduction in context tokens required for different types of summaries.
Table 3 presents the performance of Orca-3 and other baseline models on various benchmarks, showing relative improvements over Mistral-7b-Instruct.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="AD-HOC LLM USE">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Ad-hoc LLM use refers to the spontaneous or on-the-fly use of large language models to analyze reasoning and provide specific examples, quotes, and citations.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="TUNING ELEMENT EXTRACTION PROMPTS">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Tuning element extraction prompts refers to the process of adjusting prompts to retain more details in the Graph RAG index, enhancing the quality of summaries and answers.</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="SELF CHECK GPT">
      <data key="d0">TOOL, METHOD</data>
      <data key="d1">SelfCheckGPT is an approach used to compare fabrication rates in analysis, developed by Manakul et al. in 2023.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SENSEMAKING QUESTIONS">
      <data key="d0">CONCEPT, EVALUATION METRIC</data>
      <data key="d1">Sensemaking questions are a class of questions used to evaluate the performance of Graph RAG and other methods in understanding and summarizing large text corpora.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="EMBEDDING-BASED MATCHING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Embedding-based matching is a technique that matches user queries with graph annotations, proposed as a refinement for Graph RAG approaches.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="ALONSO GUEVARA FERN&#193;NDEZ">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Alonso Guevara Fern&#225;ndez is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="AMBER HOAK">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Amber Hoak is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="ANDR&#201;S MORALES ESQUIVEL">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Andr&#233;s Morales Esquivel is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="BEN CUTLER">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Ben Cutler is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="BILLIE RINALDI">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Billie Rinaldi is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="CHRIS SANCHEZ">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Chris Sanchez is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="CHRIS TREVINO">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Chris Trevino is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="CHRISTINE CAGGIANO">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Christine Caggiano is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="DAVID TITTSWORTH">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">David Tittsworth is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="DAYENNE DE SOUZA">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Dayenne de Souza is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="DOUGLAS ORBAKER">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Douglas Orbaker is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="ED CLARK">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Ed Clark is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="GABRIEL NIEVES-PONCE">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Gabriel Nieves-Ponce is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="GAUDY BLANCO MENESES">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Gaudy Blanco Meneses is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="KATE LYTVYNETS">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Kate Lytvynets is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="KATY SMITH">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Katy Smith is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="M&#211;NICA CARVAJAL">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">M&#243;nica Carvajal is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="NATHAN EVANS">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Nathan Evans is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="RICHARD ORTEGA">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Richard Ortega is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="RODRIGO RACANICCI">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Rodrigo Racanicci is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SARAH SMITH">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Sarah Smith is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SHANE SOLOMON">
      <data key="d0">PERSON, CONTRIBUTOR</data>
      <data key="d1">Shane Solomon is one of the contributors to the work on Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="GRAPH-BASED RAG APPLICATIONS">
      <data key="d0">SYSTEM, APPLICATION</data>
      <data key="d1">Graph-based RAG applications are systems that create and reason over knowledge graphs, including formats like Neo4J and NebulaGraph.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="KNOWLEDGE GRAPHS">
      <data key="d0">CONCEPT, DATA STRUCTURE</data>
      <data key="d1">Knowledge graphs are structured representations of knowledge that can be created and reasoned over in systems like Neo4J and NebulaGraph.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="DATA PARTITIONING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Data partitioning is a technique used to divide data into smaller, more manageable parts, utilized in Graph RAG for global summarization.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="CORPORA">
      <data key="d0">DATASET, COLLECTION</data>
      <data key="d1">Corpora are large collections of text used for evaluation in methods like Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="FABRICATION RATES">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">Fabrication rates are metrics used to measure the accuracy and reliability of generated content, compared using tools like SelfCheckGPT.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="COMPUTE BUDGET">
      <data key="d0">RESOURCE, CONSTRAINT</data>
      <data key="d1">Compute budget refers to the computational resources allocated for a task, influencing decisions like building a graph index.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="LIFETIME QUERIES">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">Lifetime queries refer to the total number of queries expected to be made over the lifetime of a dataset, affecting the decision to build a graph index.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="RICH TEXT ANNOTATIONS">
      <data key="d0">DATA STRUCTURE, CONCEPT</data>
      <data key="d1">Rich text annotations are detailed notes and comments added to text data, supporting methods like Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="QUERY-FOCUSED SUMMARIZATION (QFS)">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Query-focused summarization (QFS) is a technique that generates summaries based on specific user queries, used in Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="RETRIEVAL-AUGMENTED GENERATION (RAG)">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Retrieval-augmented generation (RAG) is a technique that combines retrieval of relevant information with generation of new content, used in Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="TOKEN COST">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">Token cost refers to the computational cost measured in tokens, used to evaluate the efficiency of methods like Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="OPEN-SOURCE IMPLEMENTATION">
      <data key="d0">SOFTWARE, TOOL</data>
      <data key="d1">An open-source implementation is a publicly available version of software, such as the forthcoming Python-based implementation of Graph RAG.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="PYTHON">
      <data key="d0">TECHNOLOGY, PROGRAMMING LANGUAGE</data>
      <data key="d1">Python is a programming language used to implement both global and local Graph RAG approaches.
Python is a Turing Complete programming language used in the implementation of ADAS algorithms.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="J. ACHIAM">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">J. Achiam is one of the authors referenced in the document, contributing to the GPT-4 technical report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="S. ADLER">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">S. Adler is one of the authors referenced in the document, contributing to the GPT-4 technical report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="S. AGARWAL">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">S. Agarwal is one of the authors referenced in the document, contributing to the GPT-4 technical report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="L. AHMAD">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">L. Ahmad is one of the authors referenced in the document, contributing to the GPT-4 technical report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="I. AKKAYA">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">I. Akkaya is one of the authors referenced in the document, contributing to the GPT-4 technical report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="F. L. ALEMAN">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">F. L. Aleman is one of the authors referenced in the document, contributing to the GPT-4 technical report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="D. ALMEIDA">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">D. Almeida is one of the authors referenced in the document, contributing to the GPT-4 technical report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="J. ALTENSCHMIDT">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">J. Altenschmidt is one of the authors referenced in the document, contributing to the GPT-4 technical report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="S. ALTMAN">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">S. Altman is one of the authors referenced in the document, contributing to the GPT-4 technical report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="S. ANADKAT">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">S. Anadkat is one of the authors referenced in the document, contributing to the GPT-4 technical report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="J. B. ALAYRAC">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">J. B. Alayrac is one of the authors referenced in the document, contributing to the Gemini model report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON, AUTHOR</data>
    </node>
    <node id="R. ANIL">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">R. Anil is one of the authors referenced in the document, contributing to the Gemini model report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="S. BORGEAUD">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">S. Borgeaud is one of the authors referenced in the document, contributing to the Gemini model report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="Y. WU">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">Y. Wu is one of the authors referenced in the document, contributing to the Gemini model report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="R. SORICUT">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">R. Soricut is one of the authors referenced in the document, contributing to the Gemini model report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="J. SCHALKWYK">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">J. Schalkwyk is one of the authors referenced in the document, contributing to the Gemini model report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="A. M. DAI">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">A. M. Dai is one of the authors referenced in the document, contributing to the Gemini model report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="A. HAUTH">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">A. Hauth is one of the authors referenced in the document, contributing to the Gemini model report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="J. BAEK">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">J. Baek is one of the authors referenced in the document, contributing to the knowledge-augmented language model prompting report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="A. F. AJI">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">A. F. Aji is one of the authors referenced in the document, contributing to the knowledge-augmented language model prompting report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="A. SAFFARI">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">A. Saffari is one of the authors referenced in the document, contributing to the knowledge-augmented language model prompting report.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="T. BAN">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">T. Ban is one of the authors referenced in the document, contributing to the report on harnessing large language models for causal discovery.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="L. CHEN">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">L. Chen is one of the authors referenced in the document, contributing to the report on harnessing large language models for causal discovery.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="X. WANG">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">X. Wang is one of the authors referenced in the document, contributing to the report on harnessing large language models for causal discovery.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="H. CHEN">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">H. Chen is one of the authors referenced in the document, contributing to the report on harnessing large language models for causal discovery.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="T. BAUMEL">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">T. Baumel is one of the authors referenced in the document, contributing to the report on query-focused abstractive summarization.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="M. EYAL">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">M. Eyal is one of the authors referenced in the document, contributing to the report on query-focused abstractive summarization.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="M. ELHADAD">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">M. Elhadad is one of the authors referenced in the document, contributing to the report on query-focused abstractive summarization.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="V. D. BLONDEL">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">V. D. Blondel is one of the authors referenced in the document, contributing to the report on fast unfolding of communities in large networks.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="J. L. GUILLAUME">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">J. L. Guillaume is one of the authors referenced in the document, contributing to the report on fast unfolding of communities in large networks.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="R. LAMBIOTTE">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">R. Lambiotte is one of the authors referenced in the document, contributing to the report on fast unfolding of communities in large networks.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="E. LEFEBVRE">
      <data key="d0">PERSON, AUTHOR</data>
      <data key="d1">E. Lefebvre is one of the authors referenced in the document, contributing to the report on fast unfolding of communities in large networks.</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="GPT-4">
      <data key="d0" />
      <data key="d1">
GPT-4 is an advanced language model used with LATS to achieve state-of-the-art pass@1 accuracy for programming on HumanEval.
GPT-4 is an advanced language model that, when used with LATS, achieves a 92.7 Pass@1 rate on HumanEval, setting the state of the art.
GPT-4 is an advanced language model that, when used with LATS, sets the state of the art for HumanEval.
GPT-4 is a language model used in experiments with HumanEval, involving four internal tests for evaluation.
GPT-4 is a language model used to evaluate the transferability of discovered agents from GPT-3.5, showing significant improvement in accuracy rate on ARC tasks.
GPT-4 is an advanced language model used by the meta agent in Meta Agent Search to discover high-performance agents.
GPT-4 (OpenAI, 2024) is an advanced language model used by the meta agent in Meta Agent Search.
GPT-4 is an advanced foundational model used to evaluate the performance of agents discovered by Meta Agent Search on the ARC benchmark.
GPT-4 is an advanced language model discussed in the context of achieving 50% SOTA on ARC-AGI in a technical report by Ryan Greenblatt.
GPT-4 is a powerful language model used in conjunction with AgentInstruct to generate high-quality data for teaching AI models various skills.
An advanced language model used as a benchmark for scoring the performance of other models on the Orca-Bench dataset.
An advanced language model used as a benchmark with a score of 10 in the Orca-Bench dataset. It serves as the teacher in multi-turn interactions.
GPT-4 is an advanced language model used as a benchmark for evaluating the performance of other models in reading comprehension and multi-turn conversations.
GPT-4 is an advanced language model that serves as a benchmark for evaluating the performance of other models like Orca-3.
GPT-4 is an advanced language model used as an evaluator for summarization abilities and other tasks.
GPT-4 is an advanced language model evaluated on the MIRAGE datasets, showing high performance in RAG tasks.
An advanced language model used for extracting the option selected by the model from its response in multiple choice questions.
An advanced language model used in various benchmarks like FOFO, MT-Bench, AlpacaEval, and InfoBench for evaluation purposes.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,0cf2e43f324fa4175b9b00b90e5e90ba,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,5819b66e04fd77fa705574edc49395bb,6109537356a2ce2339f77c827aa3668e,86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,93cb0d0456e0822b5fe30a3e627405f8,ab04427ae0415a1c812a35cf8d3ee1a2,ac21ebe9a9d70d691c717f961d3f10c8,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bc26e68b0b2783ba912b9e5606d9eb0b,bd4eb9459bc29b4c2da4658914fd4635,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="KNOWLEDGE-AUGMENTED LANGUAGE MODEL PROMPTING">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="HARNESSING LARGE LANGUAGE MODELS FOR CAUSAL DISCOVERY">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="SEQ2SEQ MODELS">
      <data key="d0">TECHNOLOGY, MACHINE LEARNING</data>
      <data key="d1">Seq2seq models are a type of machine learning model used for sequence-to-sequence tasks, such as translation and summarization.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ARXIV">
      <data key="d0">PLATFORM, REPOSITORY</data>
      <data key="d1">arXiv is an open-access repository where researchers can publish preprints of their scientific papers.
An open-access repository where researchers can share preprints of their scientific papers, including "Mastering diverse domains through world models" published in 2023.
arXiv is a platform where several preprints, including "A survey on the memory mechanism of large language model based agents," "Take a step back: Evoking reasoning via abstraction in large language models," "Self-discover: Large language models self-compose reasoning structures," and "Symbolic learning enables self-evolving agents," were published.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,aa79049289e6532592eec17b9e76adfb,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="BLONDEL, V. D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Blondel, V. D. is one of the authors of the paper on fast unfolding of communities in large networks.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GUILLAUME, J.-L.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Guillaume, J.-L. is one of the authors of the paper on fast unfolding of communities in large networks.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LAMBIOTTE, R.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lambiotte, R. is one of the authors of the paper on fast unfolding of communities in large networks.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LEFEBVRE, E.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lefebvre, E. is one of the authors of the paper on fast unfolding of communities in large networks.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FAST UNFOLDING OF COMMUNITIES">
      <data key="d0">METHOD, ALGORITHM</data>
      <data key="d1">A method for detecting communities in large networks, described in a paper by Blondel et al. (2008).</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JOURNAL OF STATISTICAL MECHANICS: THEORY AND EXPERIMENT">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">A scientific journal where the paper on fast unfolding of communities in large networks was published.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="BROWN, T.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Brown, T. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="MANN, B.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mann, B. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RYDER, N.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ryder, N. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SUBBIAH, M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Subbiah, M. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KAPLAN, J. D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kaplan, J. D. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DHARIWAL, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dhariwal, P. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="NEELAKANTAN, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Neelakantan, A. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SHYAM, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shyam, P. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SASTRY, G.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sastry, G. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ASKELL, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Askell, A. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper published in Advances in Neural Information Processing Systems, discussing the capabilities of language models in few-shot learning.
A research paper presented at NeurIPS in 2020, authored by Amodei, discussing the capabilities of language models as few-shot learners.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS">
      <data key="d0">CONFERENCE, PUBLICATION</data>
      <data key="d1">A conference and publication venue where the paper on language models being few-shot learners was published.
An academic conference where the paper "Thought Cloning: Learning to think while acting by imitating human thinking" was presented in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="CHENG, X.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cheng, X. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LUO, D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Luo, D. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="CHEN, X.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chen, X. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LIU, L.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liu, L. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ZHAO, D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhao, D. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="YAN, R.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yan, R. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LIFT YOURSELF UP: RETRIEVAL-AUGMENTED TEXT GENERATION WITH SELF-MEMORY">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper published in Advances in Neural Information Processing Systems, discussing retrieval-augmented text generation with self-memory.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DANG, H. T.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dang, H. T. is the author of the paper on the evaluation of question-focused summarization systems.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DUC 2005">
      <data key="d0">CONFERENCE, WORKSHOP</data>
      <data key="d1">A conference where the evaluation of question-focused summarization systems was discussed.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="EVALUATION OF QUESTION-FOCUSED SUMMARIZATION SYSTEMS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper presented at the DUC 2005 conference, evaluating question-focused summarization systems.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ES, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Es, S. is one of the authors of the paper on automated evaluation of retrieval augmented generation.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JAMES, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">James, J. is one of the authors of the paper on automated evaluation of retrieval augmented generation.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ESPINOSA-ANKE, L.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Espinosa-Anke, L. is one of the authors of the paper on automated evaluation of retrieval augmented generation.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SCHOCKAERT, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Schockaert, S. is one of the authors of the paper on automated evaluation of retrieval augmented generation.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FENG, Z.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Feng, Z. is one of the authors of the paper on retrieval-generation synergy augmented large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FENG, X.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Feng, X. is one of the authors of the paper on retrieval-generation synergy augmented large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="YANG, M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yang, M. is one of the authors of the paper on retrieval-generation synergy augmented large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="QIN, B.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qin, B. is one of the authors of the paper on retrieval-generation synergy augmented large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RETRIEVAL-GENERATION SYNERGY AUGMENTED LARGE LANGUAGE MODELS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper discussing the synergy between retrieval and generation in large language models, published in 2023.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FORTUNATO, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fortunato, S. is the author of the paper on community detection in graphs.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="COMMUNITY DETECTION IN GRAPHS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper by Fortunato (2010) discussing methods for detecting communities in graphs.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PHYSICS REPORTS">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">A scientific journal where the paper on community detection in graphs was published.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GAO, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gao, Y. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="XIONG, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiong, Y. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GAO, X.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gao, X. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JIA, K.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jia, K. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PAN, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Pan, J. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="BI, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bi, Y. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DAI, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dai, Y. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SUN, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sun, J. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="WANG, H.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang, H. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RETRIEVAL-AUGMENTED GENERATION FOR LARGE LANGUAGE MODELS: A SURVEY">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A survey paper discussing retrieval-augmented generation for large language models, published in 2023.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GOODWIN, T. R.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Goodwin, T. R. is one of the authors of the paper comparing transformers on few-shot and zero-shot multi-document abstractive summarization.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SAVERY, M. E.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Savery, M. E. is one of the authors of the paper comparing transformers on few-shot and zero-shot multi-document abstractive summarization.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DEMNER-FUSHMAN, D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Demner-Fushman, D. is one of the authors of the paper comparing transformers on few-shot and zero-shot multi-document abstractive summarization.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FLIGHT OF THE PEGASUS?">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper comparing transformers on few-shot and zero-shot multi-document abstractive summarization, presented at COLING 2020.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="COLING">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">The International Conference on Computational Linguistics, where the paper on comparing transformers was presented.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HE, X.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">He, X. is one of the authors of the paper on G-retriever for textual graph understanding and question answering.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="TIAN, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tian, Y. is one of the authors of the paper on G-retriever for textual graph understanding and question answering.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SUN, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sun, Y. is one of the authors of the paper on G-retriever for textual graph understanding and question answering.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="CHAWLA, N. V.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chawla, N. V. is one of the authors of the paper on G-retriever for textual graph understanding and question answering.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LAURENT, T.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Laurent, T. is one of the authors of the paper on G-retriever for textual graph understanding and question answering.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LECUN, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">LeCun, Y. is one of the authors of the paper on G-retriever for textual graph understanding and question answering.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="BRESSON, X.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bresson, X. is one of the authors of the paper on G-retriever for textual graph understanding and question answering.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HOOI, B.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hooi, B. is one of the authors of the paper on G-retriever for textual graph understanding and question answering.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JACOMY, M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jacomy, M. is one of the authors of the paper on ForceAtlas2, a continuous graph layout algorithm.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="VENTURINI, T.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Venturini, T. is one of the authors of the paper on ForceAtlas2, a continuous graph layout algorithm.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HEYMANN, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Heymann, S. is one of the authors of the paper on ForceAtlas2, a continuous graph layout algorithm.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="BASTIAN, M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bastian, M. is one of the authors of the paper on ForceAtlas2, a continuous graph layout algorithm.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FORCEATLAS2">
      <data key="d0">METHOD, ALGORITHM</data>
      <data key="d1">ForceAtlas2 is a continuous graph layout algorithm designed for handy network visualization, described in a paper by Jacomy et al. (2014).</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PLOS ONE">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">A scientific journal where the paper on ForceAtlas2 was published.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JIN, D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jin, D. is one of the authors of the survey on community detection approaches.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="YU, Z.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yu, Z. is one of the authors of the survey on community detection approaches.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JIAO, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jiao, P. is one of the authors of the survey on community detection approaches.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PAN, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Pan, S. is one of the authors of the survey on community detection approaches.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HE, D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">He, D. is one of the authors of the survey on community detection approaches.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="WU, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wu, J. is one of the authors of the survey on community detection approaches.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PHILIP, S. Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Philip, S. Y. is one of the authors of the survey on community detection approaches.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ZHANG, W.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhang, W. is one of the authors of the survey on community detection approaches.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="A SURVEY OF COMMUNITY DETECTION APPROACHES">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A survey paper discussing various approaches to community detection, published in IEEE Transactions on Knowledge and Data Engineering.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">A scientific journal where the survey on community detection approaches was published.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KANG, M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kang, M. is one of the authors of the paper on knowledge graph-augmented language models for knowledge-grounded dialogue generation.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KWAK, J. M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kwak, J. M. is one of the authors of the paper on knowledge graph-augmented language models for knowledge-grounded dialogue generation.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="BAEK, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Baek, J. is one of the authors of the paper on knowledge graph-augmented language models for knowledge-grounded dialogue generation.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HWANG, S. J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hwang, S. J. is one of the authors of the paper on knowledge graph-augmented language models for knowledge-grounded dialogue generation.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KNOWLEDGE GRAPH-AUGMENTED LANGUAGE MODELS">
      <data key="d0">METHOD, ALGORITHM</data>
      <data key="d1">A method for knowledge-grounded dialogue generation</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KHATTAB, O.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Khattab, O. is one of the authors of the paper on demonstrate-search-predict: composing retrieval and language models for knowledge-intensive NLP.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SANTHANAM, K.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Santhanam, K. is one of the authors of the paper on demonstrate-search-predict: composing retrieval and language models for knowledge-intensive NLP.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LI, X. L.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Li, X. L. is one of the authors of the paper on demonstrate-search-predict: composing retrieval and language models for knowledge-intensive NLP.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HALL, D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hall, D. is one of the authors of the paper on demonstrate-search-predict: composing retrieval and language models for knowledge-intensive NLP.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LIANG, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liang, P. is one of the authors of the paper on demonstrate-search-predict: composing retrieval and language models for knowledge-intensive NLP.
Liang, P. is an author and researcher who contributed to the study on how language models use long contexts.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="POTTS, C.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Potts, C. is one of the authors of the paper on demonstrate-search-predict: composing retrieval and language models for knowledge-intensive NLP.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ZAHARIA, M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zaharia, M. is one of the authors of the paper on demonstrate-search-predict: composing retrieval and language models for knowledge-intensive NLP.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DEMONSTRATE-SEARCH-PREDICT">
      <data key="d0">METHOD, ALGORITHM</data>
      <data key="d1">A method for composing retrieval and language models for knowledge-intensive NLP, described in a paper by Khattab et al. (2022).</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KIM, G.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kim, G. is one of the authors of the paper on tree of clarifications: answering ambiguous questions with retrieval-augmented large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KIM, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kim, S. is one of the authors of the paper on tree of clarifications: answering ambiguous questions with retrieval-augmented large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JEON, B.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jeon, B. is one of the authors of the paper on tree of clarifications: answering ambiguous questions with retrieval-augmented large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PARK, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Park, J. is one of the authors of the paper on tree of clarifications: answering ambiguous questions with retrieval-augmented large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KANG, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kang, J. is one of the authors of the paper on tree of clarifications: answering ambiguous questions with retrieval-augmented large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KLEIN, G.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Klein, G. is one of the authors of the papers on making sense of sensemaking.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="MOON, B.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Moon, B. is one of the authors of the papers on making sense of sensemaking.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HOFFMAN, R. R.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hoffman, R. R. is one of the authors of the papers on making sense of sensemaking.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="MAKING SENSE OF SENSEMAKING 1">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper discussing alternative perspectives on sensemaking, authored by Klein, Moon, and Hoffman (2006).</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="MAKING SENSE OF SENSEMAKING 2">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper discussing a macrocognitive model of sensemaking, authored by Klein, Moon, and Hoffman (2006).</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="IEEE INTELLIGENT SYSTEMS">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">A scientific journal where the papers on making sense of sensemaking were published.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KOESTEN, L.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Koesten, L. is one of the authors of the paper on understanding data sensemaking behaviours.
Koesten, L. is an author and researcher who contributed to the study on understanding data sensemaking behaviors.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GREGORY, K.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gregory, K. is one of the authors of the paper on understanding data sensemaking behaviours.
Gregory, K. is an author and researcher who contributed to the study on understanding data sensemaking behaviors.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GROTH, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Groth, P. is one of the authors of the paper on understanding data sensemaking behaviours.
Groth, P. is an author and researcher who contributed to the study on understanding data sensemaking behaviors.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SIMPERL, E.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Simperl, E. is one of the authors of the paper on understanding data sensemaking behaviours.
Simperl, E. is an author and researcher who contributed to the study on understanding data sensemaking behaviors.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="TALKING DATASETS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper discussing data sensemaking behaviours, authored by Koesten et al. (2021).
A study titled "Talking datasets&#8211;understanding data sensemaking behaviours" published in the International Journal of Human-Computer Studies in 2021.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">A scientific journal where the paper on understanding data sensemaking behaviours was published.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KURATOV, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kuratov, Y. is one of the authors of the paper on knowledge-grounded dialogue generation.
Kuratov, Y. is an author and researcher who contributed to the study on recurrent memory in large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="BULATOV, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bulatov, A. is one of the authors of the paper on knowledge-grounded dialogue generation.
Bulatov, A. is an author and researcher who contributed to the study on recurrent memory in large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="ANOKHIN, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Anokhin, P. is one of the authors of the paper on knowledge-grounded dialogue generation.
Anokhin, P. is an author and researcher who contributed to the study on recurrent memory in large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SOROKIN, D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sorokin, D. is one of the authors of the paper on knowledge-grounded dialogue generation.
Sorokin, D. is an author and researcher who contributed to the study on recurrent memory in large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SOROKIN, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sorokin, A. is one of the authors of the paper on knowledge-grounded dialogue generation.
Sorokin, A. is an author and researcher who contributed to the study on recurrent memory in large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="BURTSEV, M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Burtsev, M. is one of the authors of the paper on knowledge-grounded dialogue generation.
Burtsev, M. is an author and researcher who contributed to the study on recurrent memory in large language models.</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="KNOWLEDGE-GROUNDED DIALOGUE GENERATION">
      <data key="d0">METHOD, ALGORITHM</data>
      <data key="d1">A method for dialogue generation that is grounded in knowledge, described in a paper by Kuratov et al. (2022).</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="IN SEARCH OF NEEDLES IN A 11M HAYSTACK">
      <data key="d0">STUDY, PAPER</data>
      <data key="d1">A study titled "In search of needles in a 11m haystack: Recurrent memory finds what llms miss" published in 2024.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LANGCHAIN GRAPHS">
      <data key="d0">FEATURE, TECHNOLOGY</data>
      <data key="d1">A feature of LangChain that allows for the creation and use of graphs in language model applications.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LASKAR, M. T. R.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Laskar, M. T. R. is an author and researcher who contributed to studies on query-focused abstractive summarization and domain adaptation with pre-trained transformers.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="HOQUE, E.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hoque, E. is an author and researcher who contributed to studies on query-focused abstractive summarization and domain adaptation with pre-trained transformers.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="HUANG, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Huang, J. is an author and researcher who contributed to studies on query-focused abstractive summarization and domain adaptation with pre-trained transformers.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="QUERY FOCUSED ABSTRACTIVE SUMMARIZATION">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A technique for summarizing text by focusing on the relevance of the query, incorporating transfer learning with transformer models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="DOMAIN ADAPTATION WITH PRE-TRAINED TRANSFORMERS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A technique for adapting pre-trained transformer models to specific domains for query-focused abstractive text summarization.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LEWIS, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lewis, P. is an author and researcher who contributed to the study on retrieval-augmented generation for knowledge-intensive NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="PEREZ, E.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Perez, E. is an author and researcher who contributed to the study on retrieval-augmented generation for knowledge-intensive NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="PIKTUS, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Piktus, A. is an author and researcher who contributed to the study on retrieval-augmented generation for knowledge-intensive NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="PETRONI, F.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Petroni, F. is an author and researcher who contributed to the study on retrieval-augmented generation for knowledge-intensive NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="KARPUKHIN, V.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Karpukhin, V. is an author and researcher who contributed to the study on retrieval-augmented generation for knowledge-intensive NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GOYAL, N.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Goyal, N. is an author and researcher who contributed to the study on retrieval-augmented generation for knowledge-intensive NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="K&#220;TTLER, H.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">K&#252;ttler, H. is an author and researcher who contributed to the study on retrieval-augmented generation for knowledge-intensive NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LEWIS, M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lewis, M. is an author and researcher who contributed to the study on retrieval-augmented generation for knowledge-intensive NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="YIH, W.-T.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yih, W.-T. is an author and researcher who contributed to the study on retrieval-augmented generation for knowledge-intensive NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="ROCKT&#196;SCHEL, T.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rockt&#228;schel, T. is an author and researcher who contributed to the study on retrieval-augmented generation for knowledge-intensive NLP tasks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LIU, N. F.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liu, N. F. is an author and researcher who contributed to the study on how language models use long contexts.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LIN, K.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lin, K. is an author and researcher who contributed to the study on how language models use long contexts.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="HEWITT, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hewitt, J. is an author and researcher who contributed to the study on how language models use long contexts.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="PARANJAPE, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Paranjape, A. is an author and researcher who contributed to the study on how language models use long contexts.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="BEVILACQUA, M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bevilacqua, M. is an author and researcher who contributed to the study on how language models use long contexts.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LOST IN THE MIDDLE">
      <data key="d0">STUDY, PAPER</data>
      <data key="d1">A study titled "Lost in the middle: How language models use long contexts" published in 2023.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LIU, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liu, Y. is an author and researcher who contributed to the study on hierarchical transformers for multi-document summarization.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LAPATA, M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lapata, M. is an author and researcher who contributed to the study on hierarchical transformers for multi-document summarization.
Lapata, M. is one of the authors of the paper titled "Text summarization with latent queries."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="HIERARCHICAL TRANSFORMERS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A technique for multi-document summarization using hierarchical transformer models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LLAMAINDEX KNOWLEDGE GRAPH INDEX">
      <data key="d0">FEATURE, TECHNOLOGY</data>
      <data key="d1">A feature of LlamaIndex that allows for the creation and use of knowledge graph indexes in language model applications.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="MANAKUL, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Manakul, P. is an author and researcher who contributed to the study on zero-resource black-box hallucination detection for generative large language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LIUSIE, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liusie, A. is an author and researcher who contributed to the study on zero-resource black-box hallucination detection for generative large language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GALES, M. J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gales, M. J. is an author and researcher who contributed to the study on zero-resource black-box hallucination detection for generative large language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SELFCHECKGPT">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A technique for zero-resource black-box hallucination detection in generative large language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="MAO, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mao, Y. is an author and researcher who contributed to the study on generation-augmented retrieval for open-domain question answering.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="HE, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">He, P. is an author and researcher who contributed to the study on generation-augmented retrieval for open-domain question answering.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LIU, X.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liu, X. is an author and researcher who contributed to the study on generation-augmented retrieval for open-domain question answering.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SHEN, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shen, Y. is an author and researcher who contributed to the study on generation-augmented retrieval for open-domain question answering.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GAO, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gao, J. is an author and researcher who contributed to the study on generation-augmented retrieval for open-domain question answering.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="HAN, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Han, J. is an author and researcher who contributed to the study on generation-augmented retrieval for open-domain question answering.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="CHEN, W.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chen, W. is an author and researcher who contributed to the study on generation-augmented retrieval for open-domain question answering.
Chen, W. is one of the authors of the paper titled "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GENERATION-AUGMENTED RETRIEVAL">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A technique for enhancing open-domain question answering by combining generation and retrieval processes.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="MARTIN, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Martin, S. is an author and researcher who contributed to the development of OpenOrd, an open-source toolbox for large graph layout.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="BROWN, W. M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Brown, W. M. is an author and researcher who contributed to the development of OpenOrd, an open-source toolbox for large graph layout.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="KLAVANS, R.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Klavans, R. is an author and researcher who contributed to the development of OpenOrd, an open-source toolbox for large graph layout.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="BOYACK, K.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Boyack, K. is an author and researcher who contributed to the development of OpenOrd, an open-source toolbox for large graph layout.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="MICROSOFT">
      <data key="d0">COMPANY, ORGANIZATION</data>
      <data key="d1">Microsoft is a technology company that conducted a preliminary study on the impact of large language models on scientific discovery using GPT-4.
Microsoft is a technology company that provides Azure, a cloud computing service offering various tools and resources for AI and machine learning.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="THE IMPACT OF LARGE LANGUAGE MODELS ON SCIENTIFIC DISCOVERY">
      <data key="d0">STUDY, PAPER</data>
      <data key="d1">A preliminary study conducted by Microsoft on the impact of large language models on scientific discovery using GPT-4, published in 2023.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="PROJECT NALLM">
      <data key="d0">PROJECT, INITIATIVE</data>
      <data key="d1">An initiative by Neo4J focused on developing advanced language model applications.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="NEWMAN, M. E.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Newman, M. E. is an author and researcher who contributed to the study on modularity and community structure in networks.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="MODULARITY AND COMMUNITY STRUCTURE IN NETWORKS">
      <data key="d0">STUDY, PAPER</data>
      <data key="d1">A study titled "Modularity and community structure in networks" published in the Proceedings of the National Academy of Sciences in 2006.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="RAM, O.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ram, O. is an author and researcher who contributed to the study on in-context retrieval-augmented language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LEVINE, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Levine, Y. is an author and researcher who contributed to the study on in-context retrieval-augmented language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="DALMEDIGOS, I.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dalmedigos, I. is an author and researcher who contributed to the study on in-context retrieval-augmented language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="MUHLGAY, D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Muhlgay, D. is an author and researcher who contributed to the study on in-context retrieval-augmented language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SHASHUA, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shashua, A. is an author and researcher who contributed to the study on in-context retrieval-augmented language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="LEYTON-BROWN, K.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Leyton-Brown, K. is an author and researcher who contributed to the study on in-context retrieval-augmented language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SHOHAM, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shoham, Y. is an author and researcher who contributed to the study on in-context retrieval-augmented language models.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="IN-CONTEXT RETRIEVAL-AUGMENTED LANGUAGE MODELS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A technique for enhancing language models by incorporating in-context retrieval-augmented processes.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="RANADE, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ranade, P. is an author and researcher who contributed to the study on intelligence report generation using retrieval-augmented narrative construction.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="JOSHI, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Joshi, A. is an author and researcher who contributed to the study on intelligence report generation using retrieval-augmented narrative construction.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SARTHI, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sarthi, P. is an author and researcher who contributed to the study on recursive abstractive processing for tree-organized retrieval.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="ABDULLAH, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Abdullah, S. is an author and researcher who contributed to the study on recursive abstractive processing for tree-organized retrieval.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="TULI, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tuli, A. is an author and researcher who contributed to the study on recursive abstractive processing for tree-organized retrieval.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="KHANNA, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Khanna, S. is an author and researcher who contributed to the study on recursive abstractive processing for tree-organized retrieval.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="GOLDIE, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Goldie, A. is an author and researcher who contributed to the study on recursive abstractive processing for tree-organized retrieval.</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="MANNING, C. D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Manning, C. D. is an author and researcher who contributed to the study on recursive abstractive processing for tree-organized retrieval.
Manning, C. D. is one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SU, D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Su, D. is an author and researcher who contributed to the development of CAIRE-COVID, a question answering and query-focused multi-document summarization technique.
Su, D. is one of the authors of the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="XU, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xu, Y. is an author and researcher who contributed to the development of CAIRE-COVID, a question answering and query-focused multi-document summarization technique.
Xu, Y. is one of the authors of the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management."Xu, Y. is one of the authors of the paper titled "Text summarization with latent queries."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="YU, T.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yu, T. is an author and researcher who contributed to the development of CAIRE-COVID, a question answering and query-focused multi-document summarization technique.
Yu, T. is one of the authors of the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="SIDDIQUE, F. B.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Siddique, F. B. is an author and researcher who contributed to the development of CAIRE-COVID, a question answering and query-focused multi-document summarization technique.
Siddique, F. B. is one of the authors of the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="BAREZI, E. J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Barezi, E. J. is an author and researcher who contributed to the development of CAIRE-COVID, a question answering and query-focused multi-document summarization technique.
Barezi, E. J. is one of the authors of the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="FUNG, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fung, P. is an author and researcher who contributed to the development of CAIRE-COVID, a question answering and query-focused multi-document summarization technique.
Fung, P. is one of the authors of the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="DUAN, N.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Duan, N. is one of the authors of the paper titled "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ENHANCING RETRIEVAL-AUGMENTED LARGE LANGUAGE MODELS WITH ITERATIVE RETRIEVAL-GENERATION SYNERGY">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper focused on improving retrieval-augmented large language models through iterative retrieval-generation synergy, published in 2023.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="TANG, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tang, Y. is one of the authors of the paper titled "MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="YANG, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yang, Y. is one of the authors of the paper titled "MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="TOUVRON, H.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Touvron, H. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="MARTIN, L.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Martin, L. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="STONE, K.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Stone, K. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ALBERT, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Albert, P. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ALMAHAIRI, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Almahairi, A. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="BABAEI, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Babaei, Y. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="BASHLYKOV, N.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bashlykov, N. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="BATRA, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Batra, S. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="BHARGAVA, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bhargava, P. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="BHOSALE, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bhosale, S. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LLAMA 2">
      <data key="d0">MODEL, RESEARCH</data>
      <data key="d1">Llama 2 is a set of open foundation and fine-tuned chat models, published in 2023.
Llama 2 is an open foundation and fine-tuned chat model mentioned in the document, used for various applications in language processing.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="TRAAG, V. A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Traag, V. A. is one of the authors of the paper titled "From Louvain to Leiden: guaranteeing well-connected communities."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="WALTMAN, L.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Waltman, L. is one of the authors of the paper titled "From Louvain to Leiden: guaranteeing well-connected communities."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="VAN ECK, N. J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Van Eck, N. J. is one of the authors of the paper titled "From Louvain to Leiden: guaranteeing well-connected communities."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="FROM LOUVAIN TO LEIDEN: GUARANTEEING WELL-CONNECTED COMMUNITIES">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper focused on guaranteeing well-connected communities, published in Scientific Reports in 2019.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="TRAJANOSKA, M.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Trajanoska, M. is one of the authors of the paper titled "Enhancing knowledge graph construction using large language models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="STOJANOV, R.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Stojanov, R. is one of the authors of the paper titled "Enhancing knowledge graph construction using large language models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="TRAJANOV, D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Trajanov, D. is one of the authors of the paper titled "Enhancing knowledge graph construction using large language models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ENHANCING KNOWLEDGE GRAPH CONSTRUCTION USING LARGE LANGUAGE MODELS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper focused on improving knowledge graph construction using large language models, published in 2023.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="TRIVEDI, H.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Trivedi, H. is one of the authors of the paper titled "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="BALASUBRAMANIAN, N.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Balasubramanian, N. is one of the authors of the paper titled "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="KHOT, T.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Khot, T. is one of the authors of the paper titled "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="SABHARWAL, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sabharwal, A. is one of the authors of the paper titled "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="INTERLEAVING RETRIEVAL WITH CHAIN-OF-THOUGHT REASONING FOR KNOWLEDGE-INTENSIVE MULTI-STEP QUESTIONS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper focused on interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions, published in 2022.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="WANG, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang, J. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LIANG, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liang, Y. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="MENG, F.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Meng, F. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="SUN, Z.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sun, Z. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="SHI, H.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shi, H. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LI, Z.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Li, Z. is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena."Li, Z. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="XU, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xu, J. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="QU, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qu, J. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHOU, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhou, J. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="IS CHATGPT A GOOD NLG EVALUATOR? A PRELIMINARY STUDY">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper investigating whether ChatGPT is a good natural language generation evaluator, published in 2023.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="WANG, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang, S. is one of the authors of the paper titled "Feb4rag: Evaluating federated search in the context of retrieval augmented generation."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="KHRAMTSOVA, E.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Khramtsova, E. is one of the authors of the paper titled "Feb4rag: Evaluating federated search in the context of retrieval augmented generation."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHUANG, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhuang, S. is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena."Zhuang, S. is one of the authors of the paper titled "Feb4rag: Evaluating federated search in the context of retrieval augmented generation."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ZUCCON, G.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zuccon, G. is one of the authors of the paper titled "Feb4rag: Evaluating federated search in the context of retrieval augmented generation."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="FEB4RAG">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper evaluating federated search in the context of retrieval-augmented generation, published in 2024.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="WANG, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang, Y. is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LIPKA, N.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lipka, N. is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ROSSI, R. A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rossi, R. A. is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="SIU, A.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Siu, A. is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHANG, R.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhang, R. is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="DERR, T.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Derr, T. is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="KNOWLEDGE GRAPH PROMPTING FOR MULTI-DOCUMENT QUESTION ANSWERING">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper focused on using knowledge graph prompting for multi-document question answering, published in 2023.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="TEXT SUMMARIZATION WITH LATENT QUERIES">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper focused on text summarization using latent queries, published in 2021.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="YANG, Z.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yang, Z. is one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="QI, P.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qi, P. is one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHANG, S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhang, S. is one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="BENGIO, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bengio, Y. is one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="COHEN, W. W.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cohen, W. W. is one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="SALAKHUTDINOV, R.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Salakhutdinov, R. is one of the authors of the paper titled "HotpotQA: A dataset for diverse, explainable multi-hop question answering."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="YAO, J.-G.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yao, J.-G. is one of the authors of the paper titled "Recent advances in document summarization."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="WAN, X.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wan, X. is one of the authors of the paper titled "Recent advances in document summarization."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="XIAO, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiao, J. is one of the authors of the paper titled "Recent advances in document summarization."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="RECENT ADVANCES IN DOCUMENT SUMMARIZATION">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper discussing recent advances in document summarization, published in Knowledge and Information Systems in 2017.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="YAO, L.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yao, L. is one of the authors of the paper titled "Causal graph discovery with retrieval-augmented generation based large language models."Yao, L. is one of the authors of the paper titled "Exploring large language models for knowledge graph completion."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="PENG, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Peng, J. is one of the authors of the paper titled "Exploring large language models for knowledge graph completion."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="MAO, C.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mao, C. is one of the authors of the paper titled "Exploring large language models for knowledge graph completion."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LUO, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Luo,</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHANG, J.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhang, J. is one of the authors of the paper titled "Graph-toolformer: To empower llms with graph reasoning ability via prompt augmented by chatgpt."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHANG, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhang, Y. is one of the authors of the paper titled "Causal graph discovery with retrieval-augmented generation based large language models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="GAN, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gan, Y. is one of the authors of the paper titled "Causal graph discovery with retrieval-augmented generation based large language models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="WANG, C.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang, C. is one of the authors of the paper titled "Causal graph discovery with retrieval-augmented generation based large language models."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="CAUSAL GRAPH DISCOVERY WITH RETRIEVAL-AUGMENTED GENERATION BASED LARGE LANGUAGE MODELS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper focused on discovering causal graphs using retrieval-augmented generation based large language models, published in 2024.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHENG, L.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zheng, L. is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="CHIANG, W.-L.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chiang, W.-L. is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="SHENG, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sheng, Y. is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="WU, Z.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wu, Z. is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ZHUANG, Y.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhuang, Y. is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LIN, Z.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lin, Z. is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LI, D.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Li, D. is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="XING, E.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xing, E. is one of the authors of the paper titled "Judging llm-as-a-judge with mt-bench and chatbot arena."</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="JUDGING LLM-AS-A-JUDGE WITH MT-BENCH AND CHATBOT ARENA">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper focused on evaluating large language models as judges using MT-Bench and Chatbot Arena, published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="LANGUAGE AGENT TREE SEARCH (LATS)">
      <data key="d0">ALGORITHM, FRAMEWORK</data>
      <data key="d1">LATS is a general framework that synergizes the capabilities of language models (LMs) in reasoning, acting, and planning. It integrates Monte Carlo Tree Search, LM-powered value functions, and self-reflections to enable proficient exploration and enhanced decision-making.
Language Agent Tree Search (LATS) is an algorithm that unifies reasoning, acting, and planning in language models. It is discussed in the appendix, which includes pseudocode, limitations, experimental results, and environment details.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">ALGORITHM, FRAMEWORK</data>
    </node>
    <node id="LANGUAGE MODELS (LMS)">
      <data key="d0">TECHNOLOGY, ARTIFICIAL INTELLIGENCE</data>
      <data key="d1">Language models are AI systems capable of understanding and generating human language. They have shown potential across a range of decision-making tasks and are used in LATS for reasoning, acting, and planning.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">TECHNOLOGY, ARTIFICIAL INTELLIGENCE</data>
    </node>
    <node id="MONTE CARLO TREE SEARCH (MCTS)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">MCTS is a search algorithm integrated into LATS to enable language models as agents, enhancing their decision-making capabilities through proficient exploration.
MCTS is a search algorithm used in model-based reinforcement learning, known for its success in planning and decision-making tasks. It is adapted in LATS to enhance language model performance.
Monte Carlo Tree Search (MCTS) is a heuristic search algorithm used in decision-making environments, building a decision tree where nodes are states and edges are actions.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="EXTERNAL FEEDBACK">
      <data key="d0">CONCEPT, MECHANISM</data>
      <data key="d1">External feedback is a key feature in LATS, offering a more deliberate and adaptive problem-solving mechanism that surpasses the constraints of existing techniques.
External feedback is information from the environment that is used in LATS to improve decision-making and problem-solving capabilities of language models.
External feedback refers to the use of feedback from external sources to improve the reasoning and decision-making of language models.
Feedback from the environment used in the LATS algorithm to improve the agent's responses and value assignment.
Information from external sources used to enhance reasoning in LATS.
External feedback is a concept used in methods like LATS to improve performance by leveraging feedback from the environment.
External feedback refers to input from outside sources used to improve the performance and reliability of models like LATS in difficult reasoning tasks.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,93cb0d0456e0822b5fe30a3e627405f8,c95e02c0dca4a4a36b701cbc7dd14da6,dd9a46950237e49ef9b1c7ef08e08d42,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">CONCEPT, MECHANISM</data>
    </node>
    <node id="PROGRAMMING">
      <data key="d0">DOMAIN, TASK</data>
      <data key="d1">Programming is one of the diverse domains where LATS has been experimentally evaluated, achieving state-of-the-art pass@1 accuracy on HumanEval with GPT-4.
A domain used to evaluate the LATS algorithm, involving reasoning and acting tasks.
Programming is one of the tasks for which LATS is recommended, especially when performance is prioritized over efficiency.
Programming involves writing code to create software applications, often evaluated through benchmarks like HumanEval and MBPP.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,42de130f5b6144472a86a4c8260a87c7,93cb0d0456e0822b5fe30a3e627405f8,fb2b4544aedd793e4d4ec3147320a51c</data>
      <data key="d3">DOMAIN, TASK</data>
    </node>
    <node id="INTERACTIVE QUESTION-ANSWERING (QA)">
      <data key="d0">DOMAIN, TASK</data>
      <data key="d1">Interactive question-answering is another domain where LATS has been validated for its effectiveness and generality in decision-making.
Interactive question-answering is a task where language models answer questions based on interaction with the environment. LATS enhances performance in this task.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">DOMAIN, TASK</data>
    </node>
    <node id="WEB NAVIGATION">
      <data key="d0">DOMAIN, TASK</data>
      <data key="d1">Web navigation is a domain where LATS demonstrates gradient-free performance comparable to gradient-based fine-tuning, evaluated with GPT-3.5.
Web navigation is a task where language models interact with web environments to retrieve information. LATS improves performance in this task.
A domain used to evaluate the LATS algorithm, involving tasks such as finalizing a purchase.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,93cb0d0456e0822b5fe30a3e627405f8,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">DOMAIN, TASK</data>
    </node>
    <node id="MATH">
      <data key="d0">DOMAIN, TASK</data>
      <data key="d1">Math is one of the diverse domains where LATS has been experimentally evaluated, validating its effectiveness in decision-making.
Math is a domain where language models solve mathematical problems. LATS demonstrates versatility by enhancing performance in this domain.
Math is a domain tested by Meta Agent Search using the MGSM benchmark to evaluate mathematical problem-solving capabilities.
Math is a domain where foundational models possess adequate knowledge to solve questions, and errors are mainly due to hallucinations or calculation mistakes.
Math is a skill that can be taught to AI models using the data generated by AgentInstruct.
Math is a benchmark used to evaluate the mathematical problem-solving capabilities of language models.
</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71,86f77e15d41cbd0cb33f635ccb2cb66b,93cb0d0456e0822b5fe30a3e627405f8,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bc26e68b0b2783ba912b9e5606d9eb0b,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">DOMAIN, TASK</data>
    </node>
    <node id="GPT-3.5">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">GPT-3.5 is a language model used with LATS to demonstrate gradient-free performance for web navigation on WebShop.
GPT-3.5 is a language model that, when used with LATS, significantly improves performance on tasks such as WebShop and HotPotQA.
An advanced language model used in the LATS algorithm for reasoning-based prompting results on HotpotQA.
GPT-3.5 is a language model used in various experiments, including those involving LATS, ReAct, Reflexion, ToT, and RAP.
GPT-3.5 is an advanced language model used in various tasks, including programming and decision-making, to evaluate the performance of different algorithms.
GPT-3.5 is a language model used in conjunction with algorithms like ReAct and LATS to evaluate performance in environments like WebShop and reasoning tasks like Game of 24 and HotPotQA.
GPT-3.5 is a language model used in experiments with HumanEval, involving six internal tests for evaluation.
An advanced language model used in conjunction with LATS for tasks like the Game of 24
GPT-3.5 is a language model used as a baseline for transferring discovered agents to GPT-4, showing significant improvement in accuracy rate on ARC tasks.
GPT-3.5 is a language model used to evaluate discovered agents and baselines in Meta Agent Search to reduce compute cost.
GPT-3.5 (OpenAI, 2022) is a language model used to evaluate the discovered agents and baselines in Meta Agent Search.
GPT-3.5 is a foundational model used to evaluate the performance of agents discovered by Meta Agent Search on the ARC benchmark.
GPT-3.5 is a language model that involves a complex feedback mechanism for better refinement, but simpler feedback mechanisms work better with more advanced models.
GPT-3.5 is an AI model that was outperformed by Orca-3 on multiple benchmarks.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,594449768ae2dea9b2efbe677075096b,7de66b94cf868b37b1df51dc545c415f,93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,b88745a13b69cecbc0ee9c3af41389bf,b8dd0300033963bb4a3e1bad37f8e7b9,bc26e68b0b2783ba912b9e5606d9eb0b,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNOLOGY, LANGUAGE MODEL</data>
    </node>
    <node id="HUMANEVAL">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">HumanEval is a benchmark used to evaluate the performance of algorithms like LATS, consisting of programming tasks.
HumanEval is a benchmark consisting of questions used to evaluate the performance of algorithms like LATS. LATS achieves a 92.7 Pass@1 rate on this benchmark when used with GPT-4.
HumanEval is a benchmark consisting of questions used to evaluate the performance of algorithms like LATS.
HumanEval is a benchmark consisting of 164 questions used to evaluate the performance of algorithms like LATS on programming tasks.
HumanEval is a benchmark consisting of questions used to evaluate the performance of algorithms like LATS in programming tasks.
HumanEval is a benchmark used to evaluate the performance of algorithms, consisting of a set of questions that test various aspects of reasoning and programming tasks.
HumanEval is a dataset of 164 handwritten programming problems used to evaluate the functional correctness of models for synthesizing programs from natural language descriptions.
A benchmark consisting of questions used to evaluate the performance of algorithms like LATS
A benchmark consisting of questions used to evaluate the performance of algorithms in programming and reasoning tasks.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,b8dd0300033963bb4a3e1bad37f8e7b9,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">BENCHMARK, DATASET</data>
    </node>
    <node id="WEB SHOP">
      <data key="d0">PLATFORM, APPLICATION</data>
      <data key="d1">WebShop is a platform used to evaluate the performance of LATS in web navigation tasks with GPT-3.5.
WebShop is a benchmark used to evaluate the performance of language models in web navigation tasks. LATS raises the average score by 22.1 when used with GPT-3.5.
An online platform where users can search for and purchase products, evaluated using LATS.
WebShop is an online shopping environment composed of a website with 1.18M real-world products and 12k human instructions. Agents navigate the website through various commands to purchase items matching user specifications.
Web Shop is a platform for scalable real-world web interaction with grounded language agents, mentioned in the document in the context of research by Shunyu Yao, Howard Chen, John Yang, and Karthik R. Narasimhan.
WebShop is an interactive web-based environment designed to evaluate agents on grounded language understanding and decision-making, simulating an e-commerce shopping task with over 1 million real-world products.
An online platform where users can search for and purchase products
An online platform where users can search for and purchase products
An online platform where users can search for and purchase products</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,594449768ae2dea9b2efbe677075096b,6f486e20e3102c7a285e357d356417ad,8180bf20b7577f3eee40df5991e2886d,93cb0d0456e0822b5fe30a3e627405f8,b8dd0300033963bb4a3e1bad37f8e7b9,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">PLATFORM, APPLICATION</data>
    </node>
    <node id="ANDY ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Andy Zhou is one of the authors of the paper introducing LATS, affiliated with the University of Illinois Urbana-Champaign and Lapis Labs.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN">
      <data key="d0">INSTITUTION, UNIVERSITY</data>
      <data key="d1">The University of Illinois Urbana-Champaign is one of the institutions affiliated with the authors of the paper introducing LATS.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="LAPIS LABS">
      <data key="d0">ORGANIZATION, RESEARCH LAB</data>
      <data key="d1">Lapis Labs is one of the organizations affiliated with the authors of the paper introducing LATS.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="REACT">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">ReAct is an algorithm that augments language models with feedback or observations from an external environment, serving as a basis for LATS.
ReAct is an algorithm used for reasoning, acting, and planning in language models. It has been outperformed by LATS on benchmarks like HotPotQA and WebShop.
ReAct is an acting-based prompting technique developed by Yao et al. in 2023. It is used for reasoning and acting but is limited by its simplicity and inability to adapt to environment conditions.
ReAct is a technique that extends language models to tasks requiring interactions with an external environment, constructing an action space that includes both permissible actions and reasoning traces.
ReAct is an algorithm with different performance scores, including a best-of-k variant, used for reasoning, acting, and planning in language models.
ReAct is an algorithm that combines reasoning and acting, used for tasks requiring both internal reasoning and external retrieval. It has different performance scores and can be used in various settings.
ReAct is an algorithm used for reasoning, acting, and planning in language models. It has different performance scores and is used as a base prompt in various experiments.
ReAct is a method evaluated for performance, sample complexity, and token consumption in the text. It has different variants and is used for reasoning, acting, and planning in language models.
ReAct is a technique for synergizing reasoning and acting in language models, mentioned in the document in the context of research by Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.
ReAct is a simpler prompting method compared to LATS, used for reasoning, acting, and planning in language models.
ReAct is an algorithm used for reasoning, acting, and planning in language models. It is evaluated on benchmarks like HumanEval and HotPotQA.
An algorithm used for reasoning, acting, and planning in language models</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,594449768ae2dea9b2efbe677075096b,8180bf20b7577f3eee40df5991e2886d,93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,9bb90746134619cad9a3e649b8b35f24,b8dd0300033963bb4a3e1bad37f8e7b9,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="YA0 ET AL., 2023B">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yao et al. are the authors of the ReAct algorithm, published in 2023.
Yao et al. are researchers who developed the ReAct algorithm in 2023.
Yao et al. are the authors of the ReAct algorithm, published in 2023.
Yao et al. are the authors mentioned in relation to the ReAct algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,93cb0d0456e0822b5fe30a3e627405f8,c95e02c0dca4a4a36b701cbc7dd14da6,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="CHOWDHERY ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chowdhery et al. are the authors of a significant paper on language models, published in 2023.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="OPENAI, 2023">
      <data key="d0">ORGANIZATION, RESEARCH LAB</data>
      <data key="d1">OpenAI is an organization that has published significant research on language models in 2023.
OpenAI is the organization mentioned in the context of the practice followed for one-shot style questions in DROP (Reading Comprehension).</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">ORGANIZATION, RESEARCH LAB</data>
    </node>
    <node id="NALLAPATI ET AL., 2016">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nallapati et al. are the authors of a significant paper on summarization, published in 2016.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="BOWMAN ET AL., 2015">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bowman et al. are the authors of a significant paper on language inference, published in 2015.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="COBBE ET AL., 2021">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cobbe et al. are the authors of a significant paper on language models, published in 2021.
Cobbe et al. are researchers who have contributed to the understanding of reasoning in language models, published in 2021.
Cobbe et al. are the authors of a study in 2021 discussing the GSM8K math task benchmark.
Cobbe et al. are the authors of the GSM8K dataset, published in 2021, which is used to evaluate the transferability of discovered agents from MGSM math tasks to held-out math tasks.
Cobbe et al. are the authors of the GSM8K benchmark, published in 2021.
Cobbe et al. are the authors of the GSM8K dataset, published in 2021.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,81c504ffbcc5ed882e234802135295ba,93cb0d0456e0822b5fe30a3e627405f8,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SAPAROV AND HE, 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Saparov and He are the authors of a significant paper on language models, published in 2023.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YAO ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yao et al. are the authors of a significant paper on web navigation, published in 2022.
Yao et al. are the authors of studies published in 2022 that involve algorithms like ReAct and IL+RL for performance evaluation.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="DENG ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Deng et al. are the authors of a significant paper on web navigation, published in 2023.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SCHICK ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Schick et al. are the authors of a significant paper on tool-use, published in 2023.
Schick et al. are researchers who contributed to the development of external tools for language models in 2023.
Schick et al. are authors cited in the paper, contributing to the research on tool use in agentic systems.
Schick et al. are the authors who contributed to the development of tool use techniques, published in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,93cb0d0456e0822b5fe30a3e627405f8,c3d0436082aada237ee4bee645f16059,c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="FAN ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fan et al. are the authors of a significant paper on open-ended games, published in 2022.
Fan et al. are researchers who have worked on complex multimodal games like Minecraft, published in 2022.
Fan et al. are the authors mentioned in relation to using planning-based prompting methods in environments like Minecraft.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,93cb0d0456e0822b5fe30a3e627405f8,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SHINN ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shinn et al. are the authors of a significant paper on language models, published in 2023.
Shinn et al. are researchers who have developed the Reflexion algorithm, published in 2023.
Shinn et al. are researchers who developed the Reflexion algorithm in 2023.
Authors of research that leverages self-reflection to refine decision-making in language models, contributing to the LATS algorithm.
Shinn et al. are the authors of the Reflexion algorithm, published in 2023.
Shinn et al. are the authors of the Reflexion algorithm, published in 2023.
Shinn et al. are the authors of the Reflexion algorithm, published in 2023.
The authors of the Reflexion algorithm, published in 2023
Shinn et al. are authors cited in the paper, contributing to the research on self-reflection in agentic systems.
Shinn et al. are the authors of the Self-Refine strategy, published in 2023, which is used in the Meta Agent Search algorithm.
Shinn et al. are researchers who contributed to the development of the Self-Refine method in 2023.
Shinn et al. are the authors who contributed to the development of reflection techniques, published in 2023.
Authors who contributed to the process of self-reflection to make the generated agent novel and error-free.
Shinn et al. are the authors of the Self-Refine algorithm, published in 2023.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,282313a8340c6792e8c35f53ed157cd0,594449768ae2dea9b2efbe677075096b,93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,b8dd0300033963bb4a3e1bad37f8e7b9,c3d0436082aada237ee4bee645f16059,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SLOMAN, 1996">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sloman is the author of a significant paper on decision-making, published in 1996.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="EVANS, 2010">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Evans is the author of a significant paper on decision-making, published in 2010.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="XIE ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xie et al. are the authors of a significant paper on search-guided language models, published in 2023.
Xie et al. are researchers who contributed to the development of the Beam Search algorithm in 2023.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YAO ET AL., 2023A">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yao et al. are the authors of a significant paper on search-guided language models, published in 2023.
Yao et al. are researchers who developed the Tree-of-Thought (ToT) algorithm in 2023.
Yao et al. are the authors of the ToT method, published in 2023.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8,99d90aededb61e04241516ed9ec656cc,c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="HAO ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hao et al. are the authors of a significant paper on search-guided language models, published in 2023.
Hao et al. are researchers who have developed reasoning via planning (RAP) using MCTS, published in 2023.
Hao et al. are researchers who contributed to the development of planning and search algorithms in 2023.
Hao et al. are the authors who developed the RAP technique, which relies on internal representations of the language model.
Hao et al. are the authors of the RAP algorithm, published in 2023, which relies on internal dynamics models for simulation.
Hao et al. are researchers who have contributed to the development of the RAP algorithm.
Hao et al. are the authors mentioned in relation to the RAP algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,93cb0d0456e0822b5fe30a3e627405f8,9bb90746134619cad9a3e649b8b35f24,c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="WOOLDRIDGE AND JENNINGS, 1995">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wooldridge and Jennings are the authors of a significant paper on autonomous agents, published in 1995.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="KAI YAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kai Yan is one of the authors of the paper introducing LATS, affiliated with the University of Illinois Urbana-Champaign.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="MICHAL SHLAPENTOKH-ROTHMAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Michal Shlapentokh-Rothman is one of the authors of the paper introducing LATS, affiliated with the University of Illinois Urbana-Champaign.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="HAOHAN WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Haohan Wang is one of the authors of the paper introducing LATS, affiliated with the University of Illinois Urbana-Champaign.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="YU-XIONG WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yu-Xiong Wang is one of the authors of the paper introducing LATS, affiliated with the University of Illinois Urbana-Champaign.</data>
      <data key="d2">93cb0d0456e0822b5fe30a3e627405f8</data>
    </node>
    <node id="LATS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">LATS is an algorithm that adapts Monte Carlo Tree Search (MCTS) to language agents, incorporating reasoning, acting, and planning to enhance language model performance. It leverages external feedback and self-reflection to improve decision-making and problem-solving across various domains.
Language Agent Tree Search (LATS) is an algorithm that unifies reasoning, acting, and planning in language models. It incorporates designs from all three domains, allowing broad applicability in corresponding tasks.
LATS is a technique that aims to address the shortcomings of existing prompting techniques by improving flexibility, sensibility, and adaptability in language models.
LATS (Language Agent Tree Search) is a search algorithm that unifies reasoning, acting, and planning in language models. It adapts MCTS for language agents and does not require a world model.
LATS is an algorithm that unifies reasoning, acting, and planning in language models. It does not involve training and uses a novel value function based on a self-generated LM score and a self-consistency score. It is designed to improve value assignment by incorporating environmental feedback and self-reflection.
LATS is an algorithm that reveals the importance of external feedback for difficult reasoning tasks such as programming. It sets the state of the art for HumanEval when used with GPT-4, validating its use with more advanced language models for higher performance.
LATS is an algorithm that combines internal reasoning and external retrieval strategies to perform well on tasks like HotPotQA and programming. It surpasses other methods by expanding more nodes with principled search and incorporating external feedback.
LATS is an algorithm that improves both score and success rate (SR) in complex decision-making environments like WebShop. It uses self-reflection and a value function incorporating self-consistency as an additional heuristic.
LATS (Language Agent Tree Search) is a framework that unifies reasoning, acting, and planning for enhanced LM problem-solving. It incorporates external feedback and constructs trajectories with search algorithms.
LATS is a framework that enhances language model (LM) performance through interactions with an environment. It achieves better performance and efficiency compared to similar methods and involves high-level linguistic reasoning and actions through several rounds of decision-making and reflection.
LATS is an algorithm that unifies reasoning, acting, and planning in language models. It is discussed in the appendix, which includes pseudocode, limitations, experimental results, and environment details.
LATS (Language Agent Tree Search) is an algorithm that unifies reasoning, acting, and planning in language models. It uses various parameters like exploration weight, depth, and value functions to optimize performance in tasks like HumanEval and HotPotQA.
LATS is an algorithm used for reasoning, acting, and planning in language models, evaluated on benchmarks like HotpotQA and HumanEval.
An algorithm used for reasoning, acting, and planning in language models, evaluated in tasks like the Game of 24</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,4ae237a491bc8a84cc720e40c59a7464,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,9bb90746134619cad9a3e649b8b35f24,b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="SELF-REFLECTION">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Self-reflection is a technique used in LATS to incorporate external feedback and improve decision-making and problem-solving capabilities of language models.
Self-reflection refers to the use of language model-generated feedback to improve reasoning and decision-making.
A method in the LATS algorithm where the agent reflects on unsuccessful terminal nodes to summarize errors and propose superior alternatives, refining decision-making.
Self-reflection is a technique used in LATS to provide additional semantic signals for the agent, improving its performance in reasoning tasks.
The process of analyzing the previous implementation of a function to identify errors and areas for improvement.
Self-Reflection is a technique used in agentic systems to enable agents to reflect on their actions and improve their performance.
A process where the meta agent reviews its proposed architecture and implementation to identify mistakes, assess interestingness, and suggest improvements. This process is repeated up to five times if errors persist.
A method implemented using the framework to enable an agent to reflect on previous attempts and feedback to improve task performance.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,282313a8340c6792e8c35f53ed157cd0,594449768ae2dea9b2efbe677075096b,785ad59c6a37896a4676ec5c1689735f,c3d0436082aada237ee4bee645f16059,c95e02c0dca4a4a36b701cbc7dd14da6,d66dc9ce4a9545b44f7486ea057b5937,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="SELF-CONSISTENCY">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Self-consistency is a technique that employs majority voting over sampled chains to mitigate error propagation in reasoning tasks. It is used in LATS to enhance performance.
Self-consistency is a technique that improves chain of thought reasoning in language models, mentioned in the document in the context of research by Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="CHAIN-OF-THOUGHT (COT) PROMPTING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">CoT prompting is a method for decomposing complex inputs into sequential intermediate steps towards a final answer. It is often used in language models for reasoning tasks.
Chain-of-thought (CoT) prompting is a technique that creates intermediate thoughts to bridge the gap between input and output, especially useful for intricate tasks like mathematical queries or challenging questions.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="TREE-OF-THOUGHT (TOT) PROMPTING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">ToT prompting is a method that uses depth-first or breadth-first search guided by an LM-generated heuristic to sample trajectories more effectively in reasoning tasks.
Tree-of-thought (ToT) prompting extends CoT prompting by exploring multiple reasoning paths over thoughts, framing problems as a search over a tree.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="REASONING VIA PLANNING (RAP)">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">RAP is a method that uses MCTS with rollouts simulated by language models for reasoning tasks. It relies solely on LM internal knowledge and does not adapt to external feedback.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="YAO ET AL., 2023B">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yao et al. are the authors of the ReAct algorithm, published in 2023.
Yao et al. are the authors of the ReAct method, published in 2023.
Yao et al. are the authors of a study published in 2023 that proposed the Wikipedia web API and conducted experiments on algorithms like LATS and ReAct.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="YANG ET AL., 2018">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yang et al. are the authors of the HotPotQA benchmark, published in 2018.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="WEI ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wei et al. are researchers who have contributed to the development of chain-of-thought prompting and its variants, published in 2022.
Wei et al. are researchers who developed the Chain-of-Thought (CoT) prompting technique in 2022.
Wei et al. are researchers who have contributed to the development of the CoT algorithm.
Wei et al. are the authors of the CoT and ReAct methods, published in 2022.
Wei et al. are authors cited in the paper, contributing to the research on chain-of-thought planning and reasoning.
Wei et al. are researchers who developed the Chain-of-Thought (COT) method in 2022.
Wei et al. are the authors of the Chain-of-Thought algorithm, published in 2022.
Wei et al. are the authors of the Chain-of-Thought algorithm, published in 2022.
Wei et al. are the authors of the Chain-of-Thought algorithm, published in 2022.
Wei et al. are the authors of research on Chain-of-Thought, published in 2022.
Wei et al. are the authors of the Chain-of-Thought (COT) algorithm, published in 2022.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,99d90aededb61e04241516ed9ec656cc,bc26e68b0b2783ba912b9e5606d9eb0b,c3d0436082aada237ee4bee645f16059,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="KOJIMA ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kojima et al. are researchers who have contributed to the development of chain-of-thought prompting variants, published in 2022.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="WANG ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang et al. are researchers who have contributed to the development of self-consistency and other techniques to improve reasoning in language models, published in 2022.
Wang et al. are researchers who have contributed to the development of the CoT-SC algorithm.
Wang et al. are the authors mentioned in relation to the CoT-SC algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="GUO ET AL., 2018">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Guo et al. are researchers who have studied error propagation in reasoning tasks, published in 2018.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="CHEN ET AL., 2023B">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chen et al. are researchers who have studied error propagation in reasoning tasks, published in 2023.
Chen et al. are the authors of the AgentVerse algorithm, published in 2023b.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="ZHOU ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhou et al. are researchers who have developed least-to-most prompting for multi-step decomposition in reasoning tasks, published in 2022.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="BESTA ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Besta et al. are researchers who have contributed to the development of search algorithms for chain-of-thought prompting, published in 2023.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="MADAAN ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Madaan et al. are researchers who have developed self-refine techniques for improving language model performance, published in 2023.
Madaan et al. are researchers who developed the Self-Refine algorithm in 2023.
Authors of research that leverages self-reflection to refine decision-making in language models, contributing to the LATS algorithm.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="SILVER ET AL., 2017">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Silver et al. are researchers known for their work in model-based reinforcement learning, published in 2017.
Authors of research on learned heuristics, referenced in the context of the LATS algorithm.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="AHN ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ahn et al. are researchers who have employed language models as high-level controllers in robotics, published in 2022.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="HUANG ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Huang et al. are researchers who have employed language models as high-level controllers in robotics, published in 2022.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="DRIESS ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Driess et al. are researchers who have employed language models as high-level controllers in robotics, published in 2023.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="BAKER ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Baker et al. are researchers who have adapted language model agents to complex multimodal games, published in 2022.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="WANG ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang et al. are researchers who have adapted language model agents to complex multimodal games, published in 2023.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="GUSS ET AL., 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Guss et al. are researchers who have worked on complex multimodal games like Minecraft, published in 2019.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="LIU ET AL., 2018">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liu et al. are researchers who have employed language models in text-based environments, published in 2018.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="SHRIDHAR ET AL., 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shridhar et al. are researchers who have employed language models in text-based environments, published in 2020.
Shridhar et al. are the authors mentioned in relation to Alfworld, an environment for text-based manipulation tasks.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="LIU ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liu et al. are researchers who have employed language models in text-based environments, published in 2024.
Liu et al. are the authors of research on EoH, published in 2024.
Liu et al. are authors referenced in the text, known for their work published in 2024 related to balancing exploration and exploitation in search algorithms.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="ERROR PROPAGATION">
      <data key="d0" />
      <data key="d1">Error propagation is an issue in reasoning tasks where errors accumulate over multiple steps. Techniques like self-consistency and self-refinement aim to mitigate this issue.
Error propagation is the accumulation of errors in reasoning-based methods, which can lead to incorrect final outputs.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">ISSUE, CHALLENGE</data>
    </node>
    <node id="LEAST-TO-MOST PROMPTING">
      <data key="d0" />
      <data key="d1">Least-to-most prompting is a method that decomposes problems from the simplest to the most complex steps, improving reasoning in language models.
Least-to-most prompting is a method that enables complex reasoning in large language models, as discussed in the paper by Olivier Bousquet, Quoc Le, and Ed Chi.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="SEARCH ALGORITHMS">
      <data key="d0" />
      <data key="d1">Search algorithms are methods used to explore and find solutions in various domains. They are adapted in LATS to enhance language model performance.
Search algorithms like DFS and BFS are used to systematically explore the tree in ToT prompting.
Algorithms used to search for solutions in decision-making tasks, integrated with LM agents in LATS.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="SELF-REFINE">
      <data key="d0" />
      <data key="d1">
Self-Refine is an extension proposed by Madaan et al. in 2023 to enhance reasoning and decision-making through self-improvement.
Self-refine is an iterative refinement method with self-feedback, discussed in a paper published in NeurIPS, 2023.
Self-Refine is a strategy used in Meta Agent Search where the meta agent performs iterations of refinement on the novelty and correctness of the proposal, and up to three refinements when errors occur while running the code.
Self-Refine is a method that allows iterative self-reflection to correct mistakes made in previous attempts.
Self-Refine (Madaan et al., 2024) is a state-of-the-art hand-designed agent used for reasoning and problem-solving tasks.
Self-Refine is a manually designed agent used for planning and reasoning in various domains, including math.
Self-Refine is a manually designed agent used for tasks like math, reading comprehension, multi-tasking, and science, with specific accuracy and F1 scores reported.
A research paper titled "Self-refine: Iterative refinement with self-feedback," published in Advances in Neural Information Processing Systems in 2024.
Self-Refine is a state-of-the-art hand-designed agent baseline used for experiments on ARC and other domains, developed by Madaan et al. (2024) and Shinn et al. (2023).
Self-Refine is a method that allows up to five refinement iterations, with an early stop if the critic deems the answer correct.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,1b1399c76420a477c0c97893d258ae69,24d7b89ae9522ae60d2317984951355b,2d4672dfb7bd4283f0b5f23ab4f26653,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="REFLEXION">
      <data key="d0" />
      <data key="d1">
Reflexion is an extension proposed by Shinn et al. in 2023 to enhance reasoning and decision-making through self-improvement.
Reflexion is a technique similar to ReAct, focusing on decision-making tasks where reverting between iterations is feasible.
Reflexion is an algorithm developed by Shinn et al. in 2023, used for reasoning, acting, and planning in language models.
Reflexion is an algorithm developed by Shinn et al. in 2023, used for reasoning, acting, and planning in language models.
Reflexion is an algorithm developed by Shinn et al. in 2023, used for reasoning, acting, and planning in language models. It provides semantic feedback but may not be as effective in complex environments like WebShop.

Reflexion is a method involving language agents with verbal reinforcement learning, discussed in a paper published in NeurIPS, 2023.
Reflexion is a simpler prompting method compared to LATS, used for reasoning, acting, and planning in language models.
An algorithm developed by Shinn et al. in 2023, used for reasoning, acting, and planning in language models</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,9bb90746134619cad9a3e649b8b35f24,b8dd0300033963bb4a3e1bad37f8e7b9,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="HIGH-LEVEL CONTROLLERS">
      <data key="d0" />
      <data key="d1">High-level controllers are components that oversee and guide lower-level control policies. Language models are used as high-level controllers in robotics and other applications.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">COMPONENT, ELEMENT</data>
    </node>
    <node id="COMPLEX MULTIMODAL GAMES">
      <data key="d0" />
      <data key="d1">Complex multimodal games are games that involve multiple types of inputs and outputs, such as visual and textual information. Language models are adapted to these games for decision-making tasks.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">TASK, APPLICATION</data>
    </node>
    <node id="MINECRAFT">
      <data key="d0" />
      <data key="d1">Minecraft is a complex multimodal game where language models are used to control agents and make decisions based on the game environment.
Minecraft is mentioned as a potential environment for future work using planning-based prompting methods like LATS.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">TASK, APPLICATION</data>
    </node>
    <node id="TEXT-BASED ENVIRONMENTS">
      <data key="d0" />
      <data key="d1">Text-based environments are interactive settings where language models process and generate text to perform tasks. LATS and other algorithms are used to enhance performance in these environments.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
      <data key="d3">TASK, APPLICATION</data>
    </node>
    <node id="PROMPTS">
      <data key="d0">COMPONENT, ELEMENT</data>
      <data key="d1">Prompts are elements used in language models to guide the generation of responses. In LATS, prompts are designed to store and retrieve external feedback effectively.
Prompts are specific instructions or few-shot input-output examples provided along with the input to improve reasoning.
Prompts are inputs used in the LATS algorithm for different environments like HotPotQA, Programming, and WebShop.
Guidelines or examples provided to guide the agent in performing tasks
Prompts are predefined inputs or instructions used to guide the behavior of AI systems, often designed in ADAS methods.
Prompts are used in the Meta Agent to design new agents based on the archive of previously discovered agents, as described in the supplementary material of the paper "Automated Design of Agentic Systems."
Prompts are initial inputs or questions used to generate responses from a language model. They are often used as seeds for generating synthetic data.
Prompts are initial inputs or questions used to generate responses in data generation workflows. They can be new or existing and are used as seeds for generating more instructions.
Prompts are dataset-specific instructions used to evaluate the summarization, grounding, and data transformation abilities of language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,6fe27f9eb76cf2ddf712a2cee5783d1c,81c504ffbcc5ed882e234802135295ba,8ee9617c145e19fa95f1f9349bfbe69b,9bb90746134619cad9a3e649b8b35f24,b88745a13b69cecbc0ee9c3af41389bf,b8dd0300033963bb4a3e1bad37f8e7b9,cc802d9b841fde55e9c0c2ba0ef7869d,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="VALUE FUNCTION">
      <data key="d0">COMPONENT, ELEMENT</data>
      <data key="d1">A value function is a component in LATS that guides the search process by incorporating successful heuristics such as self-refinement and self-consistency.
A value function is used in reinforcement learning to estimate the expected reward of a given state or action.
The value function is used to estimate the expected return of a node in the search tree. It is updated during backpropagation.
A function in the LATS algorithm that assigns values to nodes based on a combination of self-generated LM scores and self-consistency scores.A function in the LATS algorithm that assigns values to nodes based on a combination of self
A component in LATS that can be independently altered and adapted to individual language model properties.
The value function in LATS incorporates self-consistency as an additional heuristic, contributing to its superior performance in reasoning tasks.
Value function is a component of search algorithms that assigns values to nodes based on their potential to lead to a successful outcome.
A function used to evaluate the performance of an agent in a task, often configured with hyperparameters</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,594449768ae2dea9b2efbe677075096b,b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="SELF-REFINEMENT">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Self-refinement is a technique used in LATS to improve the performance of language models by allowing them to learn from their own outputs and make adjustments.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="INTERNAL REASONING PERFORMANCE">
      <data key="d0">METRIC, PERFORMANCE</data>
      <data key="d1">Internal reasoning performance refers to the ability of a language model to reason and solve problems without external feedback. LATS aims to surpass this performance by incorporating external feedback.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="MODEL-BASED REINFORCEMENT LEARNING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Model-based reinforcement learning is a technique that uses models to simulate and plan actions. MCTS, used in LATS, is inspired by its success in this field.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="IN-CONTEXT LEARNING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">In-context learning is a capability of modern language models that allows them to learn and adapt from the context provided in the input. LATS leverages this capability to enhance performance.
In-context learning is a technique that leverages the abilities of language models to learn from the context provided in the input.
A method used in the LATS algorithm to refine the agent and value function by integrating failed trajectories and reflections as additional context.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="AUTONOMOUS REASONING">
      <data key="d0">CAPABILITY, FUNCTION</data>
      <data key="d1">Autonomous reasoning is the ability of a language model to reason and make decisions independently. LATS enhances this capability through its framework.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="DECISION-MAKING">
      <data key="d0">CAPABILITY, FUNCTION</data>
      <data key="d1">Decision-making is the process of making choices or reaching conclusions. LATS improves decision-making in language models by incorporating reasoning, acting, and planning.
Decision-making refers to the process of making choices or determining actions based on reasoning and external feedback.
A task supported by the LATS algorithm, involving the process of selecting options with high value while exploring promising alternatives.
The process of making choices based on reasoning and information retrieval, evaluated in LATS.
Decision-making refers to tasks or settings where the model must choose between different options or actions based on available information.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,99d90aededb61e04241516ed9ec656cc,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="CHAIN-OF-THOUGHT (COT) PROMPTING VARIANTS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Variants of chain-of-thought prompting are methods that build on the original CoT technique to improve reasoning in language models. These variants are used to address error propagation issues.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="MAJORITY VOTING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Majority voting is a technique used in self-consistency where the most common answer among multiple samples is chosen to reduce errors.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="MULTI-STEP DECOMPOSITION">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Multi-step decomposition is a technique where complex problems are broken down into smaller, manageable steps. It is used in methods like least-to-most prompting.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="DEPTH-FIRST SEARCH (DFS)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Depth-first search is a search algorithm that explores as far as possible along each branch before backtracking. It is used in tree-of-thought prompting.
Depth-first search (DFS) is a search algorithm used to systematically explore the tree in ToT prompting, guided by heuristics.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="BREADTH-FIRST SEARCH (BFS)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Breadth-first search is a search algorithm that explores all nodes at the present depth level before moving on to the nodes at the next depth level. It is used in tree-of-thought prompting.
Breadth-first search (BFS) is a search algorithm used to systematically explore the tree in ToT prompting, guided by heuristics.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="ROLL-OUTS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Roll-outs are simulations used in planning algorithms like MCTS to evaluate the potential outcomes of actions. They are used in reasoning via planning (RAP).
Roll-outs refer to the process of simulating future actions and states to evaluate their potential outcomes in the LATS algorithm.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="POLICY MODEL">
      <data key="d0">COMPONENT, ELEMENT</data>
      <data key="d1">A policy model is a component in decision-making tasks that determines the actions to be taken based on the current state. Language models are used as policy models in interactive environments.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="CONTROL POLICIES">
      <data key="d0">COMPONENT, ELEMENT</data>
      <data key="d1">Control policies are rules or strategies that determine the actions to be taken in a given state. They are used in robotics and other decision-making tasks.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="ACTING-BASED PROMPTING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Acting-based prompting is a technique where language models generate actions based on prompts to interact with the environment. ReAct is an example of this technique.</data>
      <data key="d2">f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="SELF-IMPROVEMENT">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Self-improvement is a technique where language models learn from their own outputs and make adjustments to improve performance. It is used in methods like self-refine and Reflexion.
Self-improvement refers to the ability of larger, more capable models to enhance their own performance by generating new prompts and high-quality responses.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf,f8e7ed806916bf15245bcb4d52570c26</data>
    </node>
    <node id="LANGUAGE MODELS">
      <data key="d0" />
      <data key="d1">
Advanced models like GPT-3.5 and GPT-4 used for reasoning, acting, and planning in LATS.
Advanced models used for natural language processing tasks, such as GPT-3.5 and GPT-4</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9,f8e7ed806916bf15245bcb4d52570c26,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="COT">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Chain-of-Thought (CoT) prompting is a technique that caters to scenarios where the direct mapping from input to output is intricate. It is used for reasoning tasks in language models.
CoT (Chain of Thought) is a base prompting framework used in environments without feedback, such as reasoning tasks.
CoT is an internal reasoning strategy that relies solely on the agent&#8217;s existing knowledge to answer questions.
CoT (Chain of Thought) is a prompting technique that can slightly enhance performance on questions requiring reasoning by guiding the model through a step-by-step thought process.
CoT (Chain of Thought) is a prompting design used as a base in reasoning tasks like Game of 24, employed in LATS experiments.
A technique used in conjunction with LATS in the Game of 24, involving chain-of-thought reasoning
COT (Chain of Thought) is a method where the FM is prompted to think step by step before answering the question.
CoT (Chain-of-Thought) is a technique used to evaluate the performance of language models by answering directly without using RAG.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,97457e990eb6e3c88c11c862f9e3265b,99d90aededb61e04241516ed9ec656cc,ab04427ae0415a1c812a35cf8d3ee1a2,b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="ADAPLANNER">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">AdaPlanner is an extension proposed by Sun et al. in 2023 that incorporates both positive and negative feedback to improve decision-making.
AdaPlanner is a method for adaptive planning from feedback with language models, discussed in a paper published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="HUANG ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Huang et al. are researchers who suggested in 2024 that language models cannot self-correct their internal reasoning, making external feedback critical.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="EXTERNAL TOOLS">
      <data key="d0">TECHNOLOGY, RESOURCE</data>
      <data key="d1">External tools such as APIs, search engines, calculators, and other models are used to enhance the reasoning and practical abilities of language models.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="TREE-BASED SEARCH">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Tree-based search is a planning algorithm where multiple branches of outcomes are explored. It is widely used in planning and reinforcement learning for its good exploration-exploitation trade-off.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="MCTS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Monte Carlo Tree Search (MCTS) is a tree-based search algorithm used to unlock the potential of language models by exploring multiple branches of outcomes.
MCTS (Monte Carlo Tree Search) is a search algorithm that requires an environment model to undo previous steps and form a searching tree. It is used for decision-making and planning tasks.
Monte Carlo Tree Search, a method leveraged in the LATS algorithm to ensure a principled search that selects options with high value.
MCTS (Monte Carlo Tree Search) is a search algorithm used in LATS for principled exploration, leading to observed performance gains over other search variants like A* and DFS.
MCTS (Monte Carlo Tree Search) is a principled search algorithm that is the basis for observed performance gains. It is compared to other search algorithms like A* and DFS.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,594449768ae2dea9b2efbe677075096b,c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="LM">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Language Models (LMs) are pre-trained models used for reasoning or decision-making tasks. They generate outputs based on given inputs and prompts.
LM (Language Model) refers to models that generate or understand human language. They are used in various tasks such as reasoning, acting, and planning.
LM (Language Model) is a technology used in various methods like LATS, ToT, and RAP for reasoning, acting, and planning.</data>
      <data key="d2">c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="SUN ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sun et al. are researchers who developed the AdaPlanner algorithm in 2023.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </node>
    <node id="SWIECHOWSKI ET AL., 2021">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Swiechowski et al. are researchers who contributed to the development of tree-based search algorithms in 2021.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="LAVALLE, 1998">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">LaValle is a researcher who contributed to the development of tree-based search algorithms in 1998.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="HAFNER ET AL., 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hafner et al. are researchers who contributed to the development of reinforcement learning algorithms in 2019.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="DU ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Du et al. are researchers who contributed to the development of reinforcement learning algorithms in 2023.
Du et al. are researchers who developed the LLM-Debate method in 2023.
Du et al. are the authors of the LLM Debate algorithm, published in 2023.
Du et al. are the authors of the LLM Debate algorithm, published in 2023.
Du et al. are the authors of the LLM Debate algorithm, published in 2023.
Du et al. are the authors of research on LLM Debate, published in 2023.
Du et al. are the authors of the LLM-Debate algorithm, published in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b,c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="WU ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wu et al. are researchers who contributed to the development of reinforcement learning algorithms in 2023.
Wu et al. are the authors who contributed to the development of techniques for assigning FM modules in agentic systems, published in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="VODOPIVEC ET AL., 2017">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Vodopivec et al. are researchers who contributed to the development of tree-based search algorithms in 2017.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SHEN ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shen et al. are researchers who contributed to the development of external tools for language models in 2023.
Shen et al. are the authors of a study in 2023 discussing Neural Architecture Search (NAS).</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SURIS ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Suris et al. are researchers who contributed to the development of external tools for language models in 2023.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="TOT">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Tree-of-Thought (ToT) is an algorithm developed by Yao et al. in 2023 that incorporates reasoning, planning, and self-reflection in language models.
ToT is an algorithm used for reasoning and acting in language models, evaluated using benchmarks like HotPotQA and HumanEval.
ToT (Tree of Thoughts) is a search method that can sample and explore more outputs, showing larger gains in performance on reasoning tasks.
ToT is an algorithm used in reasoning tasks like Game of 24 and HotPotQA, evaluated for its performance in comparison to LATS and other methods.
ToT (Tree of Thoughts) is a method that uses LM-based heuristics to prune branches with low values, removing selection and backpropagation operations.
ToT is an algorithm mentioned as having the same sample complexity as LATS but achieving better performance and efficiency.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,c95e02c0dca4a4a36b701cbc7dd14da6,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="RAP">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">RAP is an algorithm developed by Hao et al. in 2023 that incorporates reasoning, planning, and external feedback in language models.
RAP is a reasoning-based method that relies solely on the internal representations of the language model, which can lead to fact hallucination and error propagation.
RAP (Reinforcement Learning with Augmented Planning) is an algorithm that relies on internal dynamics models for simulation, developed by Hao et al. in 2023.
RAP is an algorithm used for reasoning and acting in language models, evaluated using benchmarks like HotPotQA and HumanEval.
RAP is a search method that can sample and explore more outputs, similar to ToT, and is used for reasoning and decision-making tasks.
RAP is an algorithm used in reasoning tasks like Game of 24 and HotPotQA, evaluated for its performance in comparison to LATS and other methods.
RAP is a method evaluated for performance, sample complexity, and token consumption in the text. It is compared to LATS and ToT.
RAP is an algorithm mentioned as having the same sample complexity as LATS but achieving better performance and efficiency.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,9bb90746134619cad9a3e649b8b35f24,c234cb83764b899335af0950677ad024,c95e02c0dca4a4a36b701cbc7dd14da6,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="BEAM SEARCH">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Beam Search is an algorithm developed by Xie et al. in 2023 that incorporates reasoning and self-reflection in language models.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="PLANNING">
      <data key="d0">TASK, FUNCTION</data>
      <data key="d1">Planning refers to the use of a search algorithm to determine a sequence of actions or decisions in language models.
The process of strategizing actions to achieve a goal, integrated into LATS.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TASK, FUNCTION</data>
    </node>
    <node id="REASONING">
      <data key="d0">TASK, FUNCTION</data>
      <data key="d1">Reasoning refers to the internal process of language models to generate logical conclusions or answers based on given inputs.
A task supported by the LATS algorithm, involving the process of making decisions based on a shared space of thoughts and actions.
The process of thinking through problems and generating solutions, a key component of LATS.
Reasoning is one of the domains where experiments were conducted using various methods and algorithms.
Reasoning is a skill that can be taught to AI models using the data generated by AgentInstruct.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,97457e990eb6e3c88c11c862f9e3265b,b88745a13b69cecbc0ee9c3af41389bf,c95e02c0dca4a4a36b701cbc7dd14da6,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TASK, FUNCTION</data>
    </node>
    <node id="ACTING">
      <data key="d0">TASK, FUNCTION</data>
      <data key="d1">Acting refers to the external decision-making process of language models based on given inputs and reasoning.
The process of taking actions based on reasoning, a key component of LATS.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TASK, FUNCTION</data>
    </node>
    <node id="EXTERNAL MEMORY">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">External memory refers to storing past text context for future updates of the solution in language models.
External memory is an important building block for agentic systems, used to store information outside the agent's immediate processing capabilities.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="SEARCH ALGORITHM">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Search algorithms are techniques used to explore multiple branches of outcomes to find the optimal solution in planning tasks.
An algorithm used in the LATS framework to explore and select the most promising regions of the tree based on heuristic values.
Search algorithm refers to the methods used to explore possible solutions in decision-making tasks, such as MCTS, A*, and DFS.
The search algorithm in ADAS specifies how the method explores the search space. It aims to quickly discover high-performance agentic systems while avoiding local optima.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,4884e8429ca1e567dadf5e22b4b68274,c95e02c0dca4a4a36b701cbc7dd14da6,faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="REINFORCEMENT LEARNING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Reinforcement learning is a technique used to train models by rewarding desired behaviors and penalizing undesired ones.
A learning technique that the LATS algorithm aims to avoid by using self-reflection and in-context learning for optimization.
Reinforcement Learning is a type of machine learning where an agent learns to make decisions by taking actions in an environment to maximize cumulative reward.
Reinforcement learning is a method in which agents learn to make decisions by receiving rewards or penalties for their actions, used in robotics and other applications.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,8180bf20b7577f3eee40df5991e2886d,c95e02c0dca4a4a36b701cbc7dd14da6,dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="ENVIRONMENT MODEL">
      <data key="d0">TECHNOLOGY, RESOURCE</data>
      <data key="d1">An environment model is a representation of the environment in which a planning or reinforcement learning algorithm operates.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">TECHNOLOGY, RESOURCE</data>
    </node>
    <node id="INTERNAL REASONING">
      <data key="d0">TASK, FUNCTION</data>
      <data key="d1">Internal reasoning refers to the process within language models to generate logical conclusions or answers based on given inputs.
A strategy that relies solely on the agent&#8217;s existing knowledge to answer questions, evaluated in LATS.
Internal reasoning refers to the process of using the model's pre-existing knowledge to answer questions or solve problems without external input.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc,c95e02c0dca4a4a36b701cbc7dd14da6,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TASK, FUNCTION</data>
    </node>
    <node id="INPUT">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Input refers to the natural language sequences provided to language models for reasoning or decision-making tasks.
Input refers to the data or information provided to an agent to perform a task or solve a problem.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059,c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="OUTPUT">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Output refers to the final language sequences generated by language models based on given inputs and prompts.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="TOKENS">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Tokens are the basic elements of natural language, often words, that comprise the input and output sequences in language models.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="AUTOREGRESSIVE DECODING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Autoregressive decoding is a technique where language models generate text sequentially, predicting each token based on the previous ones.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="PROBABILITY">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Probability refers to the likelihood of a language model generating a specific sequence of tokens based on given inputs.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="FEW-SHOT LEARNING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Few-shot learning is a technique where language models are provided with a few input-output examples to improve their performance on specific tasks.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="PROMPT IO(X)">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Prompt IO(x) refers to the process where an input prompt is transformed into an output by a language model.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="OURS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ours refers to the authors of the Language Agent Tree Search (LATS) algorithm.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="HAFNER ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hafner et al. are researchers who contributed to the development of reinforcement learning algorithms in 2023.</data>
      <data key="d2">c95e02c0dca4a4a36b701cbc7dd14da6</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="UPPER CONFIDENCE BOUNDS APPLIED TO TREES (UCT)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Upper Confidence bounds applied to Trees (UCT) is a value used in MCTS to select the best child node for expansion based on a combination of exploration and exploitation.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="LANGUAGE MODELS (LM)">
      <data key="d0">TECHNOLOGY, MODEL</data>
      <data key="d1">Language models (LM) are advanced models used for various tasks, including reasoning, acting, and planning, often enhanced by techniques like CoT, ToT, and ReAct.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="ENVIRONMENTAL FEEDBACK">
      <data key="d0">CONCEPT, INPUT</data>
      <data key="d1">Environmental feedback refers to observations from the environment that are used to improve reasoning and acting in techniques like ReAct and Reflexion.
Feedback obtained from the environment after a trajectory is completed, used to improve value assignment in the LATS algorithm.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="HEURISTICS">
      <data key="d0">CONCEPT, STRATEGY</data>
      <data key="d1">Heuristics are strategies or guidelines used to guide search algorithms like DFS or BFS in exploring the tree of thoughts in ToT prompting.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="FLEXIBILITY">
      <data key="d0">ATTRIBUTE, QUALITY</data>
      <data key="d1">Flexibility refers to the ability of a technique to consider alternative continuations from specific states, which is a limitation in base prompting designs like CoT or ReAct.
A property of the LATS algorithm that allows it to accommodate different scenarios, environments, and resource stipulations by modifying state design and tree dimensions.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="SENSIBILITY">
      <data key="d0">ATTRIBUTE, QUALITY</data>
      <data key="d1">Sensibility refers to the reliance on internal representations of the language model, which can lead to fact hallucination and error propagation in reasoning-based methods like CoT and RAP.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="ADAPTABILITY">
      <data key="d0">ATTRIBUTE, QUALITY</data>
      <data key="d1">Adaptability refers to the ability to leverage environmental feedback and reuse previous experience, which is a limitation in current planning strategies like RAP or ToT.
A property of the LATS algorithm that allows it to incorporate external feedback and self-reflection for greater adaptation during problem-solving.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="KOCSIS AND SZEPESV&#193;RI, 2006">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kocsis and Szepesv&#225;ri are the authors who developed the UCT value used in MCTS for selecting the best child node for expansion.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="YE ET AL., 2021">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ye et al. are the authors who demonstrated the success of MCTS in decision-making environments like Atari.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="SILVER ET AL., 2016">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Silver et al. are the authors who demonstrated the success of MCTS in decision-making environments like Go.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="INPUT X">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Input x is the initial data or query provided to the language model for processing.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="OUTPUT Y">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">Output y is the final result produced by the language model after processing the input x.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="THOUGHTS Z">
      <data key="d0">DATA, INTERMEDIATE OUTPUT</data>
      <data key="d1">Thoughts z are intermediate language sequences generated during the reasoning process in CoT and ToT prompting.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="PROPOSAL">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Proposal is a method used in ToT prompting to generate thoughts zi by sampling with CoT.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="SAMPLING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Sampling is a method used in ToT prompting to generate thoughts zi by sampling with CoT.
A technique used in LATS and other algorithms to sample trajectories for evaluation.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="DECISION-MAKING TASKS">
      <data key="d0">TASK, ACTIVITY</data>
      <data key="d1">Decision-making tasks are complex problems that require reasoning, acting, and planning, often involving interactions with an external environment.
Decision-making tasks refer to problems that require selecting the best course of action from multiple options, addressed by methods like LATS, ToT, and RAP.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="PERFORMANCE CEILING">
      <data key="d0">CONCEPT, LIMITATION</data>
      <data key="d1">Performance ceiling refers to the maximum performance level that can be achieved by a technique, beyond which improvements are not possible.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="FACT HALLUCINATION">
      <data key="d0">CONCEPT, ISSUE</data>
      <data key="d1">Fact hallucination is the generation of incorrect or fabricated information by a language model, often due to reliance on internal representations.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="TRIAL AND ERROR">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Trial and error is a method of learning and improving by making mistakes and learning from them, which is limited in current planning strategies.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="WORLD MODEL">
      <data key="d0">CONCEPT, MODEL</data>
      <data key="d1">World model is a concept where the language model can accurately predict states and outcomes in a given environment.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="RETURN R">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">Return r is the reward or feedback used for updating the value function V(s) in MCTS during backpropagation.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="VALUE FUNCTION V(S)">
      <data key="d0">CONCEPT, FUNCTION</data>
      <data key="d1">Value function V(s) is the expected return from the subtree of a node s in MCTS, used to guide the search process.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="EXPLORATION WEIGHT W">
      <data key="d0">CONCEPT, PARAMETER</data>
      <data key="d1">Exploration weight w is a parameter in the UCT formula that balances exploration and exploitation in MCTS.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="PARENT NODE P">
      <data key="d0">DATA, NODE</data>
      <data key="d1">Parent node p is the node from which child nodes are expanded in the decision tree of MCTS.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="CHILD NODE S">
      <data key="d0">DATA, NODE</data>
      <data key="d1">Child node s is a node that is expanded from a parent node in the decision tree of MCTS.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="BACKPROPAGATION">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Backpropagation is a method used in MCTS to update the value function V(s) along the path after reaching the end of an episode.
Backpropagation is an operation in LATS where the resulting value from a terminal node is used to update the values of nodes along the path.
An operation in the LATS algorithm that updates the values of the tree based on the outcome of a trajectory, using the UCT formula to guide the selection of the next node.
Backpropagation refers to the process of updating the search tree based on the outcomes of explored paths, used in algorithms like LATS and MCTS.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,594449768ae2dea9b2efbe677075096b,9bb90746134619cad9a3e649b8b35f24,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="EPISODES">
      <data key="d0">DATA, ITERATION</data>
      <data key="d1">Episodes are iterations in MCTS where the decision tree is expanded and updated to improve decision-making.</data>
      <data key="d2">9bb90746134619cad9a3e649b8b35f24</data>
    </node>
    <node id="AGENT">
      <data key="d0">ACTOR, SYSTEM</data>
      <data key="d1">An agent in this context is an entity that receives observations from the environment and takes actions based on a policy. It is initialized with a language model to leverage useful language representations.
The entity in the LATS algorithm that performs reasoning, acting, and planning tasks based on the value function and search algorithm.
An agent is powered by an LLM and can optionally use tools such as search APIs, code interpreters, or calculators. Each agent has a specific role and set of instructions.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,c234cb83764b899335af0950677ad024,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="ENVIRONMENT">
      <data key="d0">CONTEXT, SYSTEM</data>
      <data key="d1">The environment is the context in which the agent operates. It provides observations based on the agent's actions and can vary depending on the task.
The setting in which the agent operates, providing feedback and observations in benchmarks like HotPotQA.</data>
      <data key="d2">c234cb83764b899335af0950677ad024,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="UCT ALGORITHM">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">UCT (Upper Confidence bounds applied to Trees) is an algorithm used to balance exploration and exploitation in tree search methods like MCTS.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="P&#920;">
      <data key="d0">MODEL, FUNCTION</data>
      <data key="d1">P&#952; is a probabilistic model used within LATS to sample actions and generate language representations. It is wrapped within the search algorithm to construct the best trajectory from sampled actions.
A component of the LATS algorithm that is repurposed into a value function by prompting it to reason about a given state and end its reasoning trace with a score indicating the correctness of the trajectory.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="SELECTION">
      <data key="d0">OPERATION, PROCESS</data>
      <data key="d1">Selection is the first operation in LATS where the algorithm identifies a segment of the current tree most suitable for subsequent expansion.
Selection refers to the process of choosing the most promising nodes to expand during the search process in algorithms like LATS and MCTS.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="EXPANSION">
      <data key="d0">OPERATION, PROCESS</data>
      <data key="d1">Expansion is the second operation in LATS where the tree is expanded by sampling actions from P&#952;, resulting in new child nodes added to the tree.
The phase in LATS where nodes are sampled during evaluation.
Expansion refers to the process of exploring new nodes or states in a search algorithm to find a solution.
Expansion is a text modification task that involves adding more information to a given piece of text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,99d90aededb61e04241516ed9ec656cc,c234cb83764b899335af0950677ad024,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="SIMULATION">
      <data key="d0">OPERATION, PROCESS</data>
      <data key="d1">Simulation is an operation in LATS where the algorithm simulates actions until a terminal node is reached, helping to explore potential trajectories.
The operation in the LATS algorithm that expands the currently selected node until a terminal state is reached, providing objective feedback on the correctness of a trajectory.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="REFLECTION">
      <data key="d0">OPERATION, PROCESS</data>
      <data key="d1">Reflection is an operation in LATS where a reflection is generated if the trajectory fails, and this reflection is used as additional context for future trials.
An operation in the LATS algorithm that leverages self-reflection to refine the decision-making process by summarizing errors and proposing superior alternatives, storing failed trajectories and reflections in memory.
A reasoning step that involves analyzing past attempts to improve future performance
An action where the user evaluates their previous actions and outcomes to improve future searches
The process of thinking back on an attempt or action to evaluate its success and consider improvements for future attempts.
Reflection is an important building block for agentic systems, used for improving the performance of agents through self-assessment.
Reflection is a process where agents look back at solutions, generate critiques, and improve solutions to create higher quality data.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,0b6b4880e77d40e284702da16be4ef64,4ed5aa10872b585d02aa2daf4ff8f7fd,5d356b8ff719763a38cecff22c4e17b7,6fe27f9eb76cf2ddf712a2cee5783d1c,b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="EXPLORATION WEIGHT">
      <data key="d0">PARAMETER, METRIC</data>
      <data key="d1">Exploration weight is a parameter used in the MCTS algorithm to balance exploration and exploitation during the search process.
Exploration weight is a parameter in the LATS algorithm that affects the effectiveness of the search. Different values are used for different tasks like HotPotQA and Programming.
Exploration weight is a parameter in the LATS algorithm that affects the effectiveness of the search. Different values of this parameter can lead to variations in performance and convergence speed.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="PARENT NODE">
      <data key="d0">NODE, COMPONENT</data>
      <data key="d1">The parent node is a node in the search tree that has one or more child nodes. It is used in the backpropagation process to update values.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="EPISODE">
      <data key="d0">EVENT, PROCESS</data>
      <data key="d1">An episode refers to a sequence of actions and observations in a task, ending when a terminal state is reached.
An episode in WebShop is a complete interaction session where an agent performs actions to purchase a product based on given instructions.
A complete interaction session with the web shop, from search to purchase</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024,fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="RETURN">
      <data key="d0">METRIC, VALUE</data>
      <data key="d1">Return is a value used in the backpropagation process to update the value function of nodes in the search tree.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="VOLD(S)">
      <data key="d0">VALUE, FUNCTION</data>
      <data key="d1">Vold(s) is the old value function of a node before it is updated with the new return value during backpropagation.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="N(S)">
      <data key="d0">METRIC, VALUE</data>
      <data key="d1">N(s) is the number of times a node has been visited in the search tree. It is used in the value function update formula.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="RESET">
      <data key="d0">ACTION, PROCESS</data>
      <data key="d1">Reset refers to the action of returning to a previous state or step in the task, often used in language model tasks to facilitate exploration.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="HISTORICAL TEXT INPUT">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Historical text input refers to previously entered text that can be used to reset to any step in language model tasks.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="BASE PROMPTING FRAMEWORK">
      <data key="d0">FRAMEWORK, METHOD</data>
      <data key="d1">The base prompting framework is the initial design used to guide the agent's actions and decisions in a task.
The initial set of prompts used to guide the language model, such as CoT in LATS.</data>
      <data key="d2">c234cb83764b899335af0950677ad024,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="OBSERVATION">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Observation is the information received by the agent from the environment at each time step.
Information obtained as a result of an Action, used to inform the next Thought or Action
Environmental data or information about the current situation in a question-answering task, used to inform thoughts and actions.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="ACTION">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">Action is the decision or move made by the agent based on the policy and observations.
An operation performed in response to a Thought, such as searching for an entity or finishing with an answer
An operation performed in a question-answering task, which can be searching for an entity, looking up a keyword, or finishing with an answer.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="POLICY">
      <data key="d0">RULE, STRATEGY</data>
      <data key="d1">Policy is the strategy or rule that the agent follows to decide on actions based on observations and previous actions.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="INITIAL STATE">
      <data key="d0">STATE, CONDITION</data>
      <data key="d1">The initial state is the starting point of the search tree or task, from which the agent begins its actions.
Initial state refers to the starting point or configuration from which the LATS algorithm begins its search process.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="ROOT NODE">
      <data key="d0">NODE, COMPONENT</data>
      <data key="d1">The root node is the topmost node in the search tree, representing the initial state of the task.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="LEAF NODE">
      <data key="d0">NODE, COMPONENT</data>
      <data key="d1">A leaf node is a node in the search tree that does not have any child nodes. It represents a terminal state or end of a trajectory.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="CHILD NODE">
      <data key="d0">NODE, COMPONENT</data>
      <data key="d1">A child node is a node in the search tree that is connected to a parent node and represents a subsequent state in the task.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="LONG-TERM MEMORY STRUCTURE">
      <data key="d0">MEMORY, STORAGE</data>
      <data key="d1">Long-term memory structure is an external storage used to keep track of the expanded search tree and its nodes.
A structure used to store failed trajectories and corresponding reflections in the memory, which are integrated as additional context to the agent and value function in subsequent iterations.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="SCALAR VALUE">
      <data key="d0">VALUE, METRIC</data>
      <data key="d1">Scalar value is a numerical value assigned to each node during the evaluation process to quantify the agent's progress.
A value assigned to each new child node in the LATS algorithm to quantify the agent&#8217;s progress in task completion.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="HEURISTIC">
      <data key="d0">METHOD, STRATEGY</data>
      <data key="d1">Heuristic is a strategy used to guide the search algorithm towards the most promising regions of the search tree.
A method used to steer the search algorithm towards the most promising regions of the tree in the LATS algorithm. It includes both programmed heuristics and learned heuristics.
Heuristic refers to the method used to guide the search process in algorithms like LATS, incorporating self-consistency and other factors to improve performance.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,594449768ae2dea9b2efbe677075096b,c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="LM SCORE">
      <data key="d0">METRIC, VALUE</data>
      <data key="d1">LM score is a self-generated score by the language model used as part of the value function in LATS.</data>
      <data key="d2">c234cb83764b899335af0950677ad024</data>
    </node>
    <node id="SELF-GENERATED LM SCORE">
      <data key="d0">METRIC, COMPONENT</data>
      <data key="d1">A score generated by the language model itself to quantify the correctness of a trajectory in the LATS algorithm.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="SELF-CONSISTENCY SCORE">
      <data key="d0">METRIC, COMPONENT</data>
      <data key="d1">A score based on the principle that actions sampled multiple times at the same state tend to be more accurate, used in the LATS value function.
A score that improves the performance of LATS by ensuring consistent results across iterations</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="TERMINAL STATE">
      <data key="d0">CONCEPT, STATE</data>
      <data key="d1">A state in the LATS algorithm where the task is either completed successfully or not, providing objective feedback on the correctness of a trajectory.
Terminal state refers to a state in the search process where no further actions can be taken, often indicating the end of a trajectory.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="COT (WEI ET AL., 2022)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">An algorithm used for reasoning, with a self-consistency variant (CoT - SC) that is evaluated on HotpotQA.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="TOT (YAO ET AL., 2023A)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">An algorithm used for reasoning, evaluated on HotpotQA, and achieving a high exact match (EM) score.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="RAP (HAO ET AL., 2023)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">An algorithm used for reasoning, evaluated on HotpotQA, and achieving a high exact match (EM) score.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="CAMPBELL ET AL., 2002">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Authors of research on programmed heuristics, referenced in the context of the LATS algorithm.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="CHEN ET AL., 2021">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Authors of research on programming, referenced in the context of evaluating the LATS algorithm.
Chen et al. are researchers who have contributed to the field of programming and reasoning tasks.
Chen et al. are the authors of the HumanEval benchmark, published in 2021.
Chen et al. are the authors mentioned in relation to HumanEval, a benchmark for programming tasks.
Chen et al. are the authors of a work published in 2021 that discusses safety considerations for executing model-generated code.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,42de130f5b6144472a86a4c8260a87c7,99d90aededb61e04241516ed9ec656cc,dc55f071b95dec721a9820d39cdb3ccd,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="AUSTIN ET AL.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Authors of research on programming, referenced in the context of evaluating the LATS algorithm.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="UCT FORMULA">
      <data key="d0">FORMULA, METHOD</data>
      <data key="d1">A formula used in the LATS algorithm to guide the selection of the next node based on updated values from backpropagation.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="REWARD">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">A metric used in the LATS algorithm to update the value of nodes during backpropagation, reflecting the outcome of a trajectory.
A measure of success based on the number of attributes satisfied by the selected item</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="HYPERPARAMETER">
      <data key="d0">CONCEPT, PARAMETER</data>
      <data key="d1">A parameter in the LATS algorithm that controls the balance between the self-generated LM score and the self-consistency score in the value function.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="EXACT MATCH (EM)">
      <data key="d0">METRIC, SCORE</data>
      <data key="d1">A metric used to evaluate the performance of the LATS algorithm on HotpotQA, indicating the highest exact match score for reasoning.
Exact Match (EM) is a performance measure used to evaluate the accuracy of algorithms like LATS on benchmarks like HotPotQA.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">METRIC, SCORE</data>
    </node>
    <node id="REASONING-BASED PROMPTING">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">A technique used in the LATS algorithm to achieve high exact match scores on benchmarks like HotpotQA.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">METHOD, TECHNIQUE</data>
    </node>
    <node id="TRAJECTORY">
      <data key="d0">CONCEPT, PATH</data>
      <data key="d1">A sequence of states from the root to a terminal state in the LATS algorithm, used to evaluate and update the agent's performance.
A sequence of steps in a question-answering task, labeled by observations, thoughts, and actions, used to evaluate the correctness of the solution.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,357f3442ba581c9d2bdf84d90509056f</data>
      <data key="d3">CONCEPT, PATH</data>
    </node>
    <node id="NODE">
      <data key="d0">COMPONENT, ELEMENT</data>
      <data key="d1">An element in the search tree of the LATS algorithm, representing a state in the trajectory from root to terminal state.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">COMPONENT, ELEMENT</data>
    </node>
    <node id="STATE">
      <data key="d0">CONCEPT, CONDITION</data>
      <data key="d1">A condition or situation represented by a node in the search tree of the LATS algorithm, used to evaluate the agent's progress.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">CONCEPT, CONDITION</data>
    </node>
    <node id="SEARCH TREE">
      <data key="d0">STRUCTURE, COMPONENT</data>
      <data key="d1">A tree structure used in the LATS algorithm to represent different states and trajectories, guiding the search process.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">STRUCTURE, COMPONENT</data>
    </node>
    <node id="REASONING TRACE">
      <data key="d0">CONCEPT, PATH</data>
      <data key="d1">A sequence of reasoning steps taken by the agent in the LATS algorithm, ending with a score indicating the correctness of the trajectory.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">CONCEPT, PATH</data>
    </node>
    <node id="PRINCIPLED SEARCH">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">A method used in the LATS algorithm to ensure that the search process selects options with high value while exploring promising alternatives.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="PROMISING REGIONS">
      <data key="d0">CONCEPT, AREA</data>
      <data key="d1">Areas of the search tree in the LATS algorithm that are likely to yield successful outcomes, prioritized based on heuristic values.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">CONCEPT, AREA</data>
    </node>
    <node id="FAILED TRAJECTORIES">
      <data key="d0">CONCEPT, PATH</data>
      <data key="d1">Sequences of states that did not lead to successful task completion in the LATS algorithm, stored in memory for future reference.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">CONCEPT, PATH</data>
    </node>
    <node id="SEMANTIC GRADIENT SIGNAL">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">A signal used in the LATS algorithm to provide more useful feedback than a scalar value, enabling the agent to learn from trial and error.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">CONCEPT, METRIC</data>
    </node>
    <node id="OBSERVATIONS">
      <data key="d0">CONCEPT, DATA</data>
      <data key="d1">Data collected from the environment in the LATS algorithm, used to incorporate external feedback and improve problem-solving.
Information gathered from the environment, used in the evaluation of LATS and other algorithms.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">CONCEPT, DATA</data>
    </node>
    <node id="PROBLEM-SOLVING">
      <data key="d0">CONCEPT, TASK</data>
      <data key="d1">A task supported by the LATS algorithm, involving reasoning, acting, and planning to achieve successful outcomes.
Problem-Solving is one of the domains where experiments were conducted using various methods and algorithms.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,97457e990eb6e3c88c11c862f9e3265b</data>
      <data key="d3">CONCEPT, TASK</data>
    </node>
    <node id="RESOURCE STIPULATIONS">
      <data key="d0">CONCEPT, CONSTRAINT</data>
      <data key="d1">Constraints related to resources that the LATS algorithm can accommodate by modifying state design and tree dimensions.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">CONCEPT, CONSTRAINT</data>
    </node>
    <node id="STATE DESIGN">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">The design of states in the LATS algorithm, which can be modified to accommodate different scenarios and environments.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">CONCEPT, METHOD</data>
    </node>
    <node id="TREE DIMENSIONS">
      <data key="d0">CONCEPT, STRUCTURE</data>
      <data key="d1">The dimensions of the search tree in the LATS algorithm, which can be modified to accommodate different scenarios and environments.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">CONCEPT, STRUCTURE</data>
    </node>
    <node id="BASE LM AGENT">
      <data key="d0">COMPONENT, ENTITY</data>
      <data key="d1">The fundamental language model agent in the LATS algorithm, which can be independently altered and adapted to individual LM properties.
A component in LATS that can be independently altered and adapted to individual language model properties.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">COMPONENT, ENTITY</data>
    </node>
    <node id="REFLECTION GENERATOR">
      <data key="d0">COMPONENT, ENTITY</data>
      <data key="d1">A component in the LATS algorithm that generates reflections on failed trajectories, proposing superior alternatives for future iterations.
A component in LATS that generates reflections to enhance reasoning and acting capabilities.
Reflection generator is a component in the LATS algorithm that generates reflections or adjustments based on the current context and state.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf,48e423e2baf2ed485872756f5b4d87d8,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">COMPONENT, ENTITY</data>
    </node>
    <node id="DELIBERATION">
      <data key="d0">CONCEPT, PROCESS</data>
      <data key="d1">A process in the LATS algorithm that leverages MCTS and the LM value function to ensure a principled search that selects options with high value while exploring promising alternatives.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">CONCEPT, PROCESS</data>
    </node>
    <node id="GENERALITY">
      <data key="d0">CONCEPT, PROPERTY</data>
      <data key="d1">A property of the LATS algorithm that supports both reasoning and decision-making tasks by defining a shared space of thoughts and actions.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
      <data key="d3">CONCEPT, PROPERTY</data>
    </node>
    <node id="NOVEL VALUE FUNCTION">
      <data key="d0">FUNCTION, COMPONENT</data>
      <data key="d1">A new value function proposed for the LATS algorithm, based on a self-generated LM score and a self-consistency score, to improve value assignment.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="TASK COMPLETION">
      <data key="d0">CONCEPT, GOAL</data>
      <data key="d1">The objective of the LATS algorithm, where the agent's progress is quantified and evaluated to determine the success of a trajectory.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="HEURISTIC VALUE">
      <data key="d0">METRIC, COMPONENT</data>
      <data key="d1">A value used in the LATS algorithm to steer the search algorithm towards the most promising regions of the tree.</data>
      <data key="d2">02ef0185bbeaaef92c3a8ee18b7a38cf</data>
    </node>
    <node id="COT-SC">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">CoT-SC is a variant of the CoT internal reasoning strategy.
CoT-SC is another method evaluated for performance, sample complexity, and token consumption in the text.
CoT-SC is an algorithm mentioned as having similar efficiency to LATS when the number of nodes is set to one.
COT-SC (Chain-of-Thought with Self-Critique) is a strategy used in Meta Agent Search to enhance the refinement of generated agents by using multiple critics.
COT-SC (Wang et al., 2023b) is a state-of-the-art hand-designed agent used for reasoning and problem-solving tasks.
COT-SC is a manually designed agent used for planning and reasoning in various domains, including math.
COT-SC is a variant of Chain-of-Thought, used for similar tasks with specific accuracy and F1 scores reported.
COT-SC is a variant of COT where 5 answers are sampled and then an ensemble is performed using either majority voting or an FM query.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,42de130f5b6144472a86a4c8260a87c7,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
    </node>
    <node id="AUSTIN ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Austin et al. are researchers who have contributed to the field of programming and reasoning tasks.
Austin et al. are the authors of the MBPP dataset, published in 2022.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="GAME OF 24">
      <data key="d0">GAME, BENCHMARK</data>
      <data key="d1">Game of 24 is a game used to evaluate reasoning and acting algorithms like LATS.
Game of 24 is a mathematical reasoning task where the agent must construct the number 24 out of a set of numbers and basic operations. It is used to evaluate the reasoning ability of algorithms like LATS.
Game of 24 is a task for which the LATS algorithm uses a self-consistency weight of 0.5.
A mathematical reasoning challenge where the goal is to use basic arithmetic operations to construct the number 24 from four given numbers</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,b8dd0300033963bb4a3e1bad37f8e7b9,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">GAME, BENCHMARK</data>
    </node>
    <node id="API CALLS">
      <data key="d0">TECHNOLOGY, TOOL</data>
      <data key="d1">API calls are used to search and retrieve information in the HotPotQA benchmark, forming part of the observation space.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNOLOGY, TOOL</data>
    </node>
    <node id="ORACLE SETUP">
      <data key="d0">EXPERIMENTAL SETUP</data>
      <data key="d1">An experimental setup in HotPotQA where the environment provides feedback about the answer&#8217;s correctness upon receiving an answer.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">EXPERIMENTAL SETUP</data>
    </node>
    <node id="DFS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">DFS is a base search algorithm used in the ToT method.
DFS (Depth-First Search) is a search algorithm used as a variant in LATS experiments to observe its effects on performance.
DFS (Depth-First Search) is another search algorithm mentioned as a variant compared to MCTS in the text.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="PASS@1">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">Pass@1 is a performance measure used to evaluate the accuracy of algorithms like LATS on benchmarks like HumanEval.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">METRIC, PERFORMANCE MEASURE</data>
    </node>
    <node id="TRAJECTORIES">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Paths or sequences of actions sampled during the evaluation of algorithms like LATS.
Trajectories refer to the paths or sequences of actions taken by a model during the search process in algorithms like LATS.
Trajectories refer to the paths taken by agents during the exploration process in algorithms like LATS, used in tasks like Game of 24 and HotPotQA.
Trajectories refer to the paths constructed by search algorithms like LATS, ToT, and RAP to solve decision-making tasks.
Trajectories are paths or sequences of states and actions evaluated in the LATS algorithm during experiments.
Labeled sequences of environmental observations, thoughts, and actions used to solve a question answering task</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,b8dd0300033963bb4a3e1bad37f8e7b9,faa2bd677c7f052136479e0175da3e5b,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">DATA, INPUT</data>
    </node>
    <node id="PROMPTING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A technique used to guide language models in generating responses, used in LATS with CoT and ReAct prompts.
Prompting refers to the method of guiding language models like GPT-3.5 in tasks such as WebShop, Game of 24, and HotPotQA, using algorithms like ReAct and LATS.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="EXTERNAL RETRIEVAL">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A strategy that involves retrieving information from external sources, evaluated in LATS.
External retrieval involves using tools or methods to gather additional information from external sources when the model's internal knowledge is insufficient.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="FEEDBACK">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Information provided about the correctness of an answer, used to enhance reasoning in LATS.
Feedback in Meta Agent Search involves incorporating diverse feedback, evaluating for various specific traits, and simulating human-like feedback to refine answers more effectively.
Feedback is the response generated after running examples to evaluate the correctness of the initial solution.
Comments and suggestions provided to improve the code, including human-like and expert feedback.
Suggestions and comments provided by the verification module to improve the visual representation of a problem.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,449db721e37968e073e3579b59e023b2,84317ae35cc75d612287186d93461447,ef75d2c866bee783577ed9f65707cf13,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">DATA, INPUT</data>
    </node>
    <node id="REASONING-ONLY VERSION">
      <data key="d0">VARIANT, METHOD</data>
      <data key="d1">A version of LATS that focuses solely on internal reasoning without external feedback.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">VARIANT, METHOD</data>
    </node>
    <node id="INTEGRATION OF SEARCH ALGORITHMS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Combining search algorithms with LM agents to handle external observations, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="EXPERIMENTS">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">Tests conducted to demonstrate the general applicability of LATS across various domains.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">PROCESS, METHOD</data>
    </node>
    <node id="DOMAINS">
      <data key="d0">CATEGORY, FIELD</data>
      <data key="d1">Areas that require reasoning and acting, such as programming, HotPotQA, WebShop, and Game of 24, used to evaluate LATS.
Domains refer to different areas or fields in which agents can be applied and tested.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">CATEGORY, FIELD</data>
    </node>
    <node id="RETRIEVAL">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The process of obtaining information from external sources, used in benchmarks like HotPotQA.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="MULTI-HOP QUESTION-ANSWERING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A type of question-answering that requires retrieval over multiple passages, used in HotPotQA.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="WIKIPEDIA PASSAGES">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Text from Wikipedia used in the HotPotQA benchmark for multi-hop question-answering.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">DATA, INPUT</data>
    </node>
    <node id="FAILURE">
      <data key="d0">EVENT, OUTCOME</data>
      <data key="d1">An outcome where the initial prompt does not lead to a correct answer, prompting a switch to a different strategy in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">EVENT, OUTCOME</data>
    </node>
    <node id="TOOLS">
      <data key="d0">TECHNOLOGY, RESOURCE</data>
      <data key="d1">Resources used to retrieve additional information when the answer is not already known, integrated into LATS.
Tools are specific functionalities or resources that agents can use to perform tasks, which can be learned and optimized within agentic systems.
Tools refer to technological resources like search engines and code interpreters used in conjunction with models like GPT-4 to generate high-quality data.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf,dc55f071b95dec721a9820d39cdb3ccd,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNOLOGY, RESOURCE</data>
    </node>
    <node id="LARGE-SCALE TRAINING CORPUS">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Extensive datasets used to train modern language models, enabling them to encode factual information.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">DATA, INPUT</data>
    </node>
    <node id="FACTUAL INFORMATION">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Accurate data encoded in modern language models, used in reasoning and retrieval tasks.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">DATA, INPUT</data>
    </node>
    <node id="SEARCH">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The process of looking for information or solutions, a key component of LATS and other algorithms.
An action that returns the first 5 sentences from the corresponding entity's wiki page or suggests top-5 similar entities from the Wikipedia search engine.
An action performed by the user to find specific products in the web shop
An action to look for specific products on the web shop
The action of looking for specific products or information within a system or platform.
Search is an application of reading comprehension that involves finding relevant information within a text or across multiple texts.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,4ed5aa10872b585d02aa2daf4ff8f7fd,5d356b8ff719763a38cecff22c4e17b7,b8dd0300033963bb4a3e1bad37f8e7b9,fb2b4544aedd793e4d4ec3147320a51c,fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="INFORMATION RETRIEVAL">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The process of obtaining information from external sources, a key component of LATS and other algorithms.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="INTERACTIVE API ENVIRONMENT">
      <data key="d0">TECHNOLOGY, TOOL</data>
      <data key="d1">An environment that allows the agent to interact with APIs to retrieve information, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNOLOGY, TOOL</data>
    </node>
    <node id="SELF-GENERATED REFLECTIONS">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Reflections generated by the agent itself, forming part of the observation space in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">DATA, INPUT</data>
    </node>
    <node id="ORACLE">
      <data key="d0">TECHNOLOGY, TOOL</data>
      <data key="d1">A setup that provides feedback about the correctness of an answer, used in HotPotQA.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNOLOGY, TOOL</data>
    </node>
    <node id="BASE SEARCH ALGORITHM">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The fundamental algorithm used for searching, such as DFS in ToT.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="SAMPLING TRAJECTORIES">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The process of sampling paths or sequences of actions for evaluation, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="REASONING-BASED STRATEGIES">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Approaches that rely on internal reasoning to solve tasks, evaluated in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="ACTING-BASED STRATEGIES">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Approaches that involve taking actions based on reasoning, evaluated in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="INTERNAL AND EXTERNAL REASONING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Combining internal knowledge and external information retrieval to solve tasks, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="PROMPTING DESIGNS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Different ways of structuring prompts to guide language models, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="CO-T BASED PROMPT">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A prompt based on the CoT framework, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="REACT-BASED PROMPT">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A prompt based on the ReAct framework, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="FAILURE SWITCH">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Switching from one prompting strategy to another upon failure, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="TOOLS FOR RETRIEVAL">
      <data key="d0">TECHNOLOGY, RESOURCE</data>
      <data key="d1">Resources used to retrieve additional information when the answer is not already known, integrated into LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNOLOGY, RESOURCE</data>
    </node>
    <node id="LARGE-SCALE TRAINING">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">Training language models on extensive datasets to encode factual information.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">PROCESS, METHOD</data>
    </node>
    <node id="ENCODING FACTUAL INFORMATION">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">The process of embedding accurate data into language models during training.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">PROCESS, METHOD</data>
    </node>
    <node id="REASONING AND ACTING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The combined process of thinking through problems and taking actions, a key component of LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="PLANNING IN LANGUAGE MODELS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The process of strategizing actions to achieve a goal, integrated into LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="SEARCHING FOR SOLUTIONS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The process of looking for information or solutions, a key component of LATS and other algorithms.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="DECISION-MAKING IN LATS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The process of making choices based on reasoning and information retrieval, evaluated in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="INFORMATION RETRIEVAL IN LATS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The process of obtaining information from external sources, a key component of LATS and other algorithms.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="INTERACTIVE API ENVIRONMENT IN LATS">
      <data key="d0">TECHNOLOGY, TOOL</data>
      <data key="d1">An environment that allows the agent to interact with APIs to retrieve information, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNOLOGY, TOOL</data>
    </node>
    <node id="SELF-GENERATED REFLECTIONS IN LATS">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Reflections generated by the agent itself, forming part of the observation space in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">DATA, INPUT</data>
    </node>
    <node id="ORACLE SETUP IN HOTPOTQA">
      <data key="d0">EXPERIMENTAL SETUP</data>
      <data key="d1">An experimental setup in HotPotQA where the environment provides feedback about the answer&#8217;s correctness upon receiving an answer.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">EXPERIMENTAL SETUP</data>
    </node>
    <node id="BASE SEARCH ALGORITHM IN TOT">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The fundamental algorithm used for searching, such as DFS in ToT.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="SAMPLING TRAJECTORIES IN LATS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The process of sampling paths or sequences of actions for evaluation, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="EXPANSION PHASE IN LATS">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">The phase in LATS where nodes are sampled during evaluation.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">PROCESS, METHOD</data>
    </node>
    <node id="EXTERNAL FEEDBACK IN LATS">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Information from external sources used to enhance reasoning in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">DATA, INPUT</data>
    </node>
    <node id="REASONING-BASED STRATEGIES IN LATS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Approaches that rely on internal reasoning to solve tasks, evaluated in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="ACTING-BASED STRATEGIES IN LATS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Approaches that involve taking actions based on reasoning, evaluated in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="INTERNAL AND EXTERNAL REASONING IN LATS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Combining internal knowledge and external information retrieval to solve tasks, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="PROMPTING DESIGNS IN LATS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Different ways of structuring prompts to guide language models, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="CO-T BASED PROMPT IN LATS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A prompt based on the CoT framework, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="REACT-BASED PROMPT IN LATS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A prompt based on the ReAct framework, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="FAILURE SWITCH IN LATS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Switching from one prompting strategy to another upon failure, used in LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="TOOLS FOR RETRIEVAL IN LATS">
      <data key="d0">TECHNOLOGY, RESOURCE</data>
      <data key="d1">Resources used to retrieve additional information when the answer is not already known, integrated into LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNOLOGY, RESOURCE</data>
    </node>
    <node id="LARGE-SCALE TRAINING IN LATS">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">Training language models on extensive datasets to encode factual information.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">PROCESS, METHOD</data>
    </node>
    <node id="ENCODING FACTUAL INFORMATION IN LATS">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">The process of embedding accurate data into language models during training.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">PROCESS, METHOD</data>
    </node>
    <node id="REASONING AND ACTING IN LATS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">The combined process of thinking through problems and taking actions, a key component of LATS.</data>
      <data key="d2">fb9cb0c0984d44c3da881886ed637e55</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="MBPP">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">MBPP (Mostly Basic Python Programming) is a dataset used to measure the correctness of synthesized programs in Python from natural language docstrings.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="FURUTA ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Furuta et al. are the authors of a fine-tuning method, published in 2024.
Furuta et al. are the authors of a study published in 2024 that involves fine-tuning methods for performance evaluation.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="EXPERT">
      <data key="d0">HUMAN, BENCHMARK</data>
      <data key="d1">Expert refers to human performance benchmarks used for comparison in various tasks.
Expert refers to human performance benchmarks used to compare the effectiveness of algorithms like LATS, ReAct, and Reflexion in tasks like WebShop.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="FINE-TUNING">
      <data key="d0" />
      <data key="d1">
Fine-tuning is a technique used to improve the performance of language models and algorithms, as studied by Furuta et al. in 2024.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="SEARCH METHODS">
      <data key="d0">METHOD, STRATEGY</data>
      <data key="d1">Search methods like ToT and RAP involve sampling and exploring multiple outputs to improve performance on reasoning tasks.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="REASONING SETTING">
      <data key="d0">TASK, SETTING</data>
      <data key="d1">Reasoning setting refers to tasks or environments where the primary focus is on logical reasoning and problem-solving.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="ACTING-BASED METHODS">
      <data key="d0">METHOD, STRATEGY</data>
      <data key="d1">Acting-based methods involve incorporating observations and external feedback into the decision-making process to improve performance.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="COMPUTATIONAL COSTS">
      <data key="d0">ATTRIBUTE, CONSTRAINT</data>
      <data key="d1">Computational costs refer to the resources, such as time and processing power, required to run an algorithm or model.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="INFERENCE COSTS">
      <data key="d0">ATTRIBUTE, CONSTRAINT</data>
      <data key="d1">Inference costs refer to the resources required to make predictions or decisions using a trained model.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="PASS@1 ACCURACY">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">Pass@1 accuracy is a metric used to evaluate the correctness of the first solution generated by a model in programming tasks.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="SYNTHETIC TEST SUITE">
      <data key="d0">COMPONENT, TOOL</data>
      <data key="d1">A synthetic test suite consists of automatically generated test cases used to evaluate the correctness of solutions in programming tasks.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="ASSERT STATEMENTS">
      <data key="d0">COMPONENT, TOOL</data>
      <data key="d1">Assert statements are syntactically valid test cases used in a synthetic test suite to check the correctness of a program.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="ACTION SPACE">
      <data key="d0">COMPONENT, ELEMENT</data>
      <data key="d1">Action space refers to the set of all possible actions or solutions that a model can choose from during the decision-making process.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="COMPILER FEEDBACK">
      <data key="d0">COMPONENT, TOOL</data>
      <data key="d1">Compiler feedback includes the results of compiling and running a program, such as successful and failed tests, which are used as external observations.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="BACKPROPAGATED REWARD">
      <data key="d0">COMPONENT, ELEMENT</data>
      <data key="d1">Backpropagated reward refers to the feedback signal used to update the model's parameters based on the success or failure of actions taken during the search process.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="SOLUTION SELECTION">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">Solution selection involves choosing the best solution from a set of generated solutions based on evaluation metrics like pass@1 accuracy.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="REAL TEST SUITE">
      <data key="d0">COMPONENT, TOOL</data>
      <data key="d1">A real test suite consists of actual test cases used to evaluate the final solution generated by a model in programming tasks.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="BASELINE">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">Baseline refers to the standard or reference performance against which new methods or models are compared.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="RL-BASED TRAINING">
      <data key="d0">METHOD, STRATEGY</data>
      <data key="d1">RL-based training involves using reinforcement learning techniques to train models for better performance on specific tasks.
RL-based training (Reinforcement Learning) is a method used to train agents in environments like WebShop, compared against LATS for performance metrics.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="HUMAN PERFORMANCE">
      <data key="d0">BENCHMARK, METRIC</data>
      <data key="d1">Human performance serves as a benchmark for evaluating the effectiveness of models and algorithms in various tasks.</data>
      <data key="d2">99d90aededb61e04241516ed9ec656cc</data>
    </node>
    <node id="HOT POT QA">
      <data key="d0">TASK, BENCHMARK</data>
      <data key="d1">HotPotQA is a question-answering task used to evaluate the performance of algorithms like LATS and its variants. It involves reasoning and requires multiple components for optimal performance.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="IMPROVEMENT">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">Improvement refers to the enhancement in performance metrics such as score and success rate (SR) when using algorithms like LATS in various tasks and environments.
Suggestions and actions taken to refine and optimize the existing implementation of the proposed architecture to increase its performance or effectiveness.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,594449768ae2dea9b2efbe677075096b</data>
      <data key="d3">CONCEPT, METRIC</data>
    </node>
    <node id="A*">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">A* is a search algorithm mentioned as a variant in LATS experiments, compared to MCTS for performance gains.
A* is a search algorithm mentioned as a variant compared to MCTS in the text.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="TOKEN CONSUMPTION">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">Token consumption refers to the number of tokens used in language model operations, evaluated in LATS experiments for efficiency.
Token consumption is a metric used to evaluate the computational cost of different methods like LATS, ToT, and RAP.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,faa2bd677c7f052136479e0175da3e5b</data>
      <data key="d3">CONCEPT, METRIC</data>
    </node>
    <node id="SEMANTIC FEEDBACK">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Semantic feedback refers to the meaningful information provided to the agent to improve its performance, used in algorithms like Reflexion and LATS.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
      <data key="d3">CONCEPT, TECHNIQUE</data>
    </node>
    <node id="LOCAL MINIMA">
      <data key="d0">CONCEPT, CHALLENGE</data>
      <data key="d1">Local minima refer to suboptimal points where the agent may get stuck during exploration, a challenge observed in Reflexion and addressed by LATS.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
      <data key="d3">CONCEPT, CHALLENGE</data>
    </node>
    <node id="EXPLORATION">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Exploration refers to the process of searching through possible actions to find optimal solutions, a key component in algorithms like LATS and MCTS.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
      <data key="d3">CONCEPT, TECHNIQUE</data>
    </node>
    <node id="ITERATIONS">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">Iterations refer to the number of times an algorithm processes data to improve performance, used as a metric in LATS experiments.
The number of times an algorithm or agent repeats a process to achieve a result</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">CONCEPT, METRIC</data>
    </node>
    <node id="SUCCESS RATE">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">Success rate (SR) is a performance metric indicating the frequency with which the chosen product or solution fulfills all given conditions, used to evaluate algorithms like LATS in WebShop and other tasks.
The rate at which the agent successfully completes the Game of 24 by constructing the correct equation
Success rate is a performance metric used to evaluate the effectiveness of the generated agents in the Meta Agent Search algorithm.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,594449768ae2dea9b2efbe677075096b,b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">CONCEPT, METRIC</data>
    </node>
    <node id="SCORE">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">Score is a performance metric reflecting the percentage of user-specified attributes met by the selected product or solution, used to evaluate algorithms like LATS in WebShop and other tasks.
A numeric value representing the performance of models, ranging from 0 to 10, with GPT-4 scoring a perfect 10.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">CONCEPT, METRIC</data>
    </node>
    <node id="IL+RL">
      <data key="d0" />
      <data key="d1">IL+RL is a combined approach of imitation learning and reinforcement learning, used to train agents in environments like WebShop, evaluated for its performance in comparison to other methods.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="PROMPT METHOD">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Prompt method refers to the specific way in which prompts are designed and used to guide language models in tasks like Game of 24 and HotPotQA.
A method that guides the agent in performing tasks like the Game of 24 using specific prompts</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="SUCCESS RATE (SR)">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">Success rate (SR) is a performance metric indicating the frequency with which the chosen product or solution fulfills all given conditions, used to evaluate algorithms like LATS in WebShop and other tasks.
A metric used in WebShop to capture the portion of successful episodes.
The portion of instructions where the reward equals 1, indicating successful completion of the task</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b,b8dd0300033963bb4a3e1bad37f8e7b9,fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="AVERAGE SCORE">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">Average score is a performance metric reflecting the percentage of user-specified attributes met by the selected product or solution, used to evaluate algorithms like LATS in WebShop and other tasks.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="BROWSER FEEDBACK">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Browser feedback refers to the information provided by the web interface during navigation, used by agents to make decisions in environments like WebShop.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="SEARCH AND CLICK COMMANDS">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Search and click commands are actions used by agents to navigate and interact with the web interface in environments like WebShop.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="PRECONSTRUCTED ACTION SPACE">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Preconstructed action space refers to the predefined set of actions available to agents for navigation and decision-making in environments like WebShop.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="CHILDREN">
      <data key="d0">CONCEPT, COMPONENT</data>
      <data key="d1">Children refer to the expanded nodes in the search tree during the exploration process in algorithms like LATS, used in tasks like Game of 24 and HotPotQA.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="PRUNING">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Pruning refers to the method of removing low-value branches from the search tree to focus on more promising paths, used in algorithms like LATS and ToT.</data>
      <data key="d2">594449768ae2dea9b2efbe677075096b</data>
    </node>
    <node id="ZHUANG ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhuang et al. are the authors mentioned in the context of the A* algorithm, published in 2023.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="SAMPLE COMPLEXITY">
      <data key="d0">METRIC, PERFORMANCE INDICATOR</data>
      <data key="d1">Sample complexity is a metric used to evaluate the asymptotic token cost of different methods like LATS, ToT, and RAP.
Sample complexity is a metric indicating the number of samples needed for an algorithm to achieve a certain level of performance. LATS has the same sample complexity as ToT and RAP but achieves better performance.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="NODES EXPANDED">
      <data key="d0">METRIC, PERFORMANCE INDICATOR</data>
      <data key="d1">Nodes expanded is a metric used to evaluate the number of nodes expanded by different methods like LATS, ToT, and RAP upon successful search.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="REVERSION PROPERTY">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Reversion property is the ability to revert to earlier states in decision-making environments, assumed by LATS for its application.
The reversion property in LATS allows the system to revert to previous states, making it feasible for many real-world applications.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="SYSTEM-2 LM APPROACHES">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">System-2 LM approaches refer to advanced language model techniques that involve more complex reasoning and decision-making processes, like LATS.
System-2 LM approaches refer to advanced language model techniques that involve high-level reasoning and decision-making processes, as opposed to simple autoregressive generation.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="PERFORMANCE">
      <data key="d0">METRIC, PERFORMANCE INDICATOR</data>
      <data key="d1">Performance is a metric used to evaluate the effectiveness of different methods like LATS, ToT, and RAP.
Performance is a measure of how well an agent completes a task or solves a problem, often used to evaluate and refine agents.
Performance refers to the effectiveness and efficiency of agentic systems in completing tasks, often measured against benchmarks and baselines.
Performance is an objective used in the evaluation function of ADAS to assess the effectiveness of agentic systems.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="COMPUTATIONAL COST">
      <data key="d0">METRIC, PERFORMANCE INDICATOR</data>
      <data key="d1">Computational cost is a metric used to evaluate the resource consumption of different methods like LATS, ToT, and RAP.
Computational cost is a limitation of the LATS algorithm, indicating that it requires more computational resources compared to simpler prompting methods like ReAct or Reflexion.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="SELECTION OPERATION">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Selection operation is a process in search algorithms where the next node to explore is chosen based on certain criteria.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="BACKPROPAGATION OPERATION">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Backpropagation operation is a process in search algorithms where the results of a search are propagated back through the tree to update the values of nodes.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="GROUND-TRUTH FEEDBACK">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Ground-truth feedback refers to accurate and reliable information used to improve the performance of methods like LATS, ToT, and RAP.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="INFERENCE-TIME COMPUTE COSTS">
      <data key="d0">METRIC, PERFORMANCE INDICATOR</data>
      <data key="d1">Inference-time compute costs refer to the computational resources required during the inference phase of methods like LATS.
Inference-time compute costs refer to the computational resources required during the inference phase of a language model's operation. These costs are expected to decrease over time, increasing the usefulness of advanced LM approaches like LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="TRADE-OFF BETWEEN PERFORMANCE AND EFFICIENCY">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Trade-off between performance and efficiency refers to the balance between achieving high performance and maintaining low computational costs in methods like LATS.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="AUTONOMOUS DECISION-MAKING">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Autonomous decision-making refers to the ability of methods like LATS to make decisions without human intervention.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="PROMPTING TECHNIQUES">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Prompting techniques refer to methods used to guide language models in generating responses, such as ReAct and Reflexion.
Prompting techniques are important building blocks for agentic systems, used to guide the behavior of agents.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="REASONING ABILITY">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Reasoning ability refers to the capability of methods like LATS to perform logical and analytical thinking to solve problems.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="EXPERIENCE LEARNING">
      <data key="d0">CONCEPT, TECHNIQUE</data>
      <data key="d1">Experience learning refers to the process of improving performance by learning from past actions and outcomes, used in methods like LATS.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="SYSTEM-2 LM">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">System-2 LM refers to advanced language models that involve complex reasoning and decision-making processes, like LATS.</data>
      <data key="d2">faa2bd677c7f052136479e0175da3e5b</data>
    </node>
    <node id="REAL-WORLD APPLICATIONS">
      <data key="d0">APPLICATION, USE CASE</data>
      <data key="d1">Real-world applications refer to practical scenarios where LATS and similar algorithms can be applied, potentially opening up new opportunities in the LM decision-making community.
Real-world applications refer to the practical use of agentic systems in various domains and industries, demonstrating their effectiveness and utility.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="LM DECISION-MAKING COMMUNITY">
      <data key="d0">COMMUNITY, FIELD</data>
      <data key="d1">The LM decision-making community consists of researchers and practitioners focused on improving the decision-making capabilities of language models.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="DANIEL CAMPOS">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Daniel Campos is a researcher who provided useful feedback on earlier versions of the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NSF GRANT 2106825">
      <data key="d0">FUNDING, GRANT</data>
      <data key="d1">NSF Grant 2106825 is a funding source that supported the research work on LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NIFA AWARD 2020-67021-32799">
      <data key="d0">FUNDING, AWARD</data>
      <data key="d1">NIFA Award 2020-67021-32799 is a funding source that supported the research work on LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="JUMP ARCHES ENDOWMENT">
      <data key="d0">FUNDING, ENDOWMENT</data>
      <data key="d1">The Jump ARCHES endowment is a funding source through the Health Care Engineering Systems Center at Illinois and the OSF Foundation that supported the research work on LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="IBM-ILLINOIS DISCOVERY ACCELERATOR INSTITUTE">
      <data key="d0">ORGANIZATION, INSTITUTE</data>
      <data key="d1">The IBM-Illinois Discovery Accelerator Institute is an organization that supported the research work on LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NVIDIA GPUS">
      <data key="d0">TECHNOLOGY, HARDWARE</data>
      <data key="d1">NVIDIA GPUs are graphical processing units used at NCSA Delta through allocations from the ACCESS program to support the research work on LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NCSA DELTA">
      <data key="d0">ORGANIZATION, FACILITY</data>
      <data key="d1">NCSA Delta is a facility that provided NVIDIA GPUs through allocations from the ACCESS program to support the research work on LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="ACCESS PROGRAM">
      <data key="d0">PROGRAM, INITIATIVE</data>
      <data key="d1">The ACCESS program provided allocations of NVIDIA GPUs at NCSA Delta to support the research work on LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="MICHAEL AHN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Michael Ahn is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="ANTHONY BROHAN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Anthony Brohan is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="NOAH BROWN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Noah Brown is one of the authors referenced in the paper discussing LATS.
A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="YEVGEN CHEBOTAR">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Yevgen Chebotar is one of the authors referenced in the paper discussing LATS.
A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="OMAR CORTES">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Omar Cortes is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="BYRON DAVID">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Byron David is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="CHELSEA FINN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Chelsea Finn is one of the authors referenced in the paper discussing LATS.
Chelsea Finn is one of the authors of the paper "Direct preference optimization: Your language model is secretly a reward model" published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="CHUYUAN FU">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Chuyuan Fu is one of the authors referenced in the paper discussing LATS.
Chuyuan Fu is an author who contributed to the paper "Language to rewards for robotic skill synthesis."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="KEERTHANA GOPALAKRISHNAN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Keerthana Gopalakrishnan is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="KAROL HAUSMAN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Karol Hausman is one of the authors referenced in the paper discussing LATS.
A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="ALEX HERZOG">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Alex Herzog is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="DANIEL HO">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Daniel Ho is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="JASMINE HSU">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Jasmine Hsu is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="JULIAN IBARZ">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Julian Ibarz is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="BRIAN ICHTER">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Brian Ichter is one of the authors referenced in the paper discussing LATS.
A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="ALEX IRPAN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Alex Irpan is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="ROSARIO JAUREGUI RUANO">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Rosario Jauregui Ruano is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="KYLE JEFFREY">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Kyle Jeffrey is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="SALLY JESMONTH">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Sally Jesmonth is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="NIKHIL J JOSHI">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Nikhil J Joshi is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="RYAN JULIAN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Ryan Julian is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="DMITRY KALASHNIKOV">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Dmitry Kalashnikov is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="YUHENG KUANG">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Yuheng Kuang is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="KUANG-HUEI LEE">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Kuang-Huei Lee is one of the authors referenced in the paper discussing LATS.
A researcher and co-author of the paper "Multimodal web navigation with instruction-finetuned foundation models" presented at ICLR 2024.
Kuang-Huei Lee is an author who contributed to the paper "Language to rewards for robotic skill synthesis."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="SERGEY LEVINE">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Sergey Levine is one of the authors referenced in the paper discussing LATS.
A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.
Sergey Levine is one of the authors of the paper on the false promise of imitating proprietary LLMs, published in 2023.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="YAO LU">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Yao Lu is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="LINDA LUU">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Linda Luu is one of the authors referenced in the paper discussing LATS.
A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="CAROLINA PARADA">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Carolina Parada is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="PETER PASTOR">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Peter Pastor is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="JORNELL QUIAMBAO">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Jornell Quiambao is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="KANISHKA RAO">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Kanishka Rao is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="JAREK RETTINGHOUSE">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Jarek Rettinghouse is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="DIEGO REYES">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Diego Reyes is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="PIERRE SERMANET">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Pierre Sermanet is one of the authors referenced in the paper discussing LATS.
A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="NICOLAS SIEVERS">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Nicolas Sievers is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="CLAYTON TAN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Clayton Tan is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="ALEXANDER TOSHEV">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Alexander Toshev is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="VINCENT VANHOUCKE">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Vincent Vanhoucke is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="FEI XIA">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Fei Xia is one of the authors referenced in the paper discussing LATS.
Fei Xia is an author who contributed to the paper "Chain-of-thought prompting elicits reasoning in large language models."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="TED XIAO">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Ted Xiao is one of the authors referenced in the paper discussing LATS.
A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="PENG XU">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Peng Xu is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="SICHUN XU">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Sichun Xu is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="MENGYUAN YAN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Mengyuan Yan is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="ANDY ZENG">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Andy Zeng is one of the authors referenced in the paper discussing LATS.
A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="JACOB AUSTIN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Jacob Austin is one of the authors referenced in the paper discussing LATS.
Jacob Austin is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="AUGUSTUS ODENA">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Augustus Odena is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="MAXWELL NYE">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Maxwell Nye is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="MAARTEN BOSMA">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Maarten Bosma is one of the authors referenced in the paper discussing LATS.
Maarten Bosma is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.
Maarten Bosma is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.
Maarten Bosma is an author who contributed to the paper "Chain-of-thought prompting elicits reasoning in large language models."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,4ae237a491bc8a84cc720e40c59a7464,7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="HENRYK MICHALEWSKI">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Henryk Michalewski is one of the authors referenced in the paper discussing LATS.
Henryk Michalewski is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="DAVID DOHAN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">David Dohan is one of the authors referenced in the paper discussing LATS.
David Dohan is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="ELLEN JIANG">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Ellen Jiang is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="CARRIE CAI">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Carrie Cai is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="MICHAEL TERRY">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Michael Terry is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="QUOC LE">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Quoc Le is one of the authors referenced in the paper discussing LATS.
Quoc Le is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.
Quoc Le is one of the authors of the paper "Least-to-most prompting enables complex reasoning in large language models" presented at ICLR 2022.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,4ae237a491bc8a84cc720e40c59a7464,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="CHARLES SUTTON">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Charles Sutton is one of the authors referenced in the paper discussing LATS.
Charles Sutton is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,7a48515e86161237c03c9a8373197126</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="BOWEN BAKER">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Bowen Baker is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="ILGE AKKAYA">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Ilge Akkaya is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="PETER ZHOKHOV">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Peter Zhokhov is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="JOOST HUIZINGA">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Joost Huizinga is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="JIE TANG">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Jie Tang is one of the authors referenced in the paper discussing LATS.
A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="ADRIEN ECOFFET">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Adrien Ecoffet is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="BRANDON HOUGHTON">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Brandon Houghton is one of the authors referenced in the paper discussing LATS.
A researcher and co-author of the paper "MineRL: A large-scale dataset of Minecraft demonstrations" presented at IJCAI 2019.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,68e5573b596d253a03047b1e41988598</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="RAUL SAMPEDRO">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Raul Sampedro is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="JEFF CLUNE">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Jeff Clune is one of the authors referenced in the paper discussing LATS.
Jeff Clune is one of the authors of the paper on Automated Design of Agentic Systems and is affiliated with the University of British Columbia, the Vector Institute, and holds a Canada CIFAR AI Chair.
The author of the paper "Ai-gas: Ai-generating algorithms, an alternate paradigm for producing general artificial intelligence" published as an arXiv preprint in 2019.
Jeff Clune is one of the authors of the paper titled "Thought Cloning: Learning to think while acting by imitating human thinking" published in Advances in Neural Information Processing Systems in 2024.
One of the authors of the paper "Intelligent go-explore: Standing on the shoulders of giant foundation models," published as an arXiv preprint in 2024.
Jeff Clune is one of the authors of the paper "Designing neural networks through neuroevolution" published in Nature Machine Intelligence in 2019.
Jeff Clune is an author who contributed to the papers "Poet: open-ended coevolution of environments and their optimized solutions" and "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."Jeff Clune is an author who contributed to the paper "OMNI: Open-endedness via models of human notions of interestingness."
Jeff Clune is one of the authors of the paper titled "OMNI: Open-endedness via models of human notions of interestingness" presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,1b1399c76420a477c0c97893d258ae69,2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,4ae237a491bc8a84cc720e40c59a7464,6109537356a2ce2339f77c827aa3668e,c3d0436082aada237ee4bee645f16059,cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="MACIEJ BESTA">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Maciej Besta is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="NILS BLACH">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Nils Blach is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="ALES KUBICEK">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Ales Kubicek is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="ROBERT GERSTENBERGER">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Robert Gerstenberger is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="LUKAS GIANINAZZI">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Lukas Gianinazzi is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="JOANNA GAJDA">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Joanna Gajda is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="TOMASZ LEHMANN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Tomasz Lehmann is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="MICHAL PODSTAWSKI">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Michal Podstawski is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="HUBERT NIEWIADOMSKI">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Hubert Niewiadomski is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="PIOTR NYCZYK">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Piotr Nyczyk is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="TORSTEN HOEFLER">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Torsten Hoefler is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="SAMUEL R BOWMAN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Samuel R Bowman is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="GABOR ANGELI">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Gabor Angeli is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="CHRISTOPHER POTTS">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Christopher Potts is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="CHRISTOPHER D MANNING">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Christopher D Manning is one of the authors referenced in the paper discussing LATS.
Christopher D Manning is one of the authors of the paper "Direct preference optimization: Your language model is secretly a reward model" published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="TOM B BROWN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Tom B Brown is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="BENJAMIN MANN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Benjamin Mann is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
      <data key="d3">PERSON, RESEARCHER</data>
    </node>
    <node id="NICK RYDER">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Nick Ryder is one of the authors referenced in the paper discussing LATS.
Nick Ryder is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MELANIE SUBBIAH">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Melanie Subbiah is one of the authors referenced in the paper discussing LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="JARED KAPLAN">
      <data key="d0">PERSON, RESEARCHER</data>
      <data key="d1">Jared Kaplan is one of the authors referenced in the paper discussing LATS.
Jared Kaplan is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.
Jared Kaplan is one of the authors of the paper on evaluating large language models trained on code, published in 2021.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,7a48515e86161237c03c9a8373197126,7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="EFFICIENCY">
      <data key="d0">ATTRIBUTE, METRIC</data>
      <data key="d1">Efficiency refers to the ability of LATS to perform tasks with minimal resource usage, balancing performance and computational cost.
Efficiency refers to the ability of agentic systems to achieve their goals with minimal resources and time, a key advantage of automated design in ADAS.
Efficiency is a specific trait evaluated by experts in the feedback mechanism of ADAS, focusing on how effectively a task is performed.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464,81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="TRADE-OFF">
      <data key="d0">CONCEPT, PRINCIPLE</data>
      <data key="d1">Trade-off refers to the balance between performance and efficiency in LATS, where increasing one may decrease the other.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="SCALING">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">Scaling refers to the process of expanding LATS to handle more complex environments or multi-agent frameworks.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="COSTS">
      <data key="d0">RESOURCE, METRIC</data>
      <data key="d1">Costs refer to the computational and financial resources required to run LATS and similar algorithms.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="APPENDIX SEC. B">
      <data key="d0">DOCUMENT, SECTION</data>
      <data key="d1">Appendix Sec. B is a section in the paper that provides a more detailed discussion about the limitations of LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="IMPACT STATEMENT">
      <data key="d0">DOCUMENT, SECTION</data>
      <data key="d1">The Impact Statement is a section in the paper that discusses the potential positive and negative consequences of using LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="INTERPRETABILITY">
      <data key="d0">ATTRIBUTE, FEATURE</data>
      <data key="d1">Interpretability refers to the ability to understand and explain the decisions made by LATS, enhancing its alignment with human reasoning.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="ALIGNMENT">
      <data key="d0">ATTRIBUTE, FEATURE</data>
      <data key="d1">Alignment refers to the degree to which LATS' actions and decisions are consistent with human values and goals.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="SECURITY RISKS">
      <data key="d0">CONCERN, ISSUE</data>
      <data key="d1">Security risks refer to the potential dangers associated with enhancing the capabilities of LM agents, such as executing malware.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="RISKS">
      <data key="d0">CONCERN, ISSUE</data>
      <data key="d1">Risks refer to the potential negative consequences of using LATS, including harmful uses and security threats.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="RESEARCH">
      <data key="d0">ACTIVITY, FIELD</data>
      <data key="d1">Research refers to the systematic investigation into and study of materials and sources to establish facts and reach new conclusions, particularly in understanding and mitigating the risks of LMs.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="NIFA">
      <data key="d0">ORGANIZATION, FUNDING AGENCY</data>
      <data key="d1">NIFA (National Institute of Food and Agriculture) is an organization that provided funding for the research work on LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="HEALTH CARE ENGINEERING SYSTEMS CENTER">
      <data key="d0">ORGANIZATION, CENTER</data>
      <data key="d1">The Health Care Engineering Systems Center at Illinois is an organization that supported the research work on LATS through the Jump ARCHES endowment.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="OSF FOUNDATION">
      <data key="d0">ORGANIZATION, FOUNDATION</data>
      <data key="d1">The OSF Foundation is an organization that supported the research work on LATS through the Jump ARCHES endowment.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="CIS220014">
      <data key="d0">ALLOCATION, RESOURCE</data>
      <data key="d1">CIS220014 is an allocation from the ACCESS program that provided NVIDIA GPUs at NCSA Delta to support the research work on LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="CIS230012">
      <data key="d0">ALLOCATION, RESOURCE</data>
      <data key="d1">CIS230012 is an allocation from the ACCESS program that provided NVIDIA GPUs at NCSA Delta to support the research work on LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="CIS230218">
      <data key="d0">ALLOCATION, RESOURCE</data>
      <data key="d1">CIS230218 is an allocation from the ACCESS program that provided NVIDIA GPUs at NCSA Delta to support the research work on LATS.</data>
      <data key="d2">4ae237a491bc8a84cc720e40c59a7464</data>
    </node>
    <node id="AMODEI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Amodei is an author who contributed to the paper "Language models are few-shot learners" presented at NeurIPS in 2020.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="NEURIPS">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">NeurIPS (Neural Information Processing Systems) is a prominent conference where research papers like "Language models are few-shot learners" are presented.
NeurIPS is a conference where the paper "Self-refine: Iterative refinement with self-feedback" was published in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MURRAY CAMPBELL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Murray Campbell is an author who contributed to the paper "Deep blue" on artificial intelligence in 2002.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="A JOSEPH HOANE JR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A Joseph Hoane Jr is an author who contributed to the paper "Deep blue" on artificial intelligence in 2002.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="FENG-HSIUNG HSU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Feng-hsiung Hsu is an author who contributed to the paper "Deep blue" on artificial intelligence in 2002.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DEEP BLUE">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper on artificial intelligence authored by Murray Campbell, A Joseph Hoane Jr, and Feng-hsiung Hsu in 2002.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ARTIFICIAL INTELLIGENCE">
      <data key="d0">FIELD, TECHNOLOGY</data>
      <data key="d1">A field of study and technology focused on creating intelligent agents and systems, discussed in the paper "Deep blue."</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BEI CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bei Chen is an author who contributed to the paper "CodeT: Code generation with generated tests" presented at ICLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="FENGJI ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fengji Zhang is an author who contributed to the paper "CodeT: Code generation with generated tests" presented at ICLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ANH NGUYEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Anh Nguyen is an author who contributed to the paper "CodeT: Code generation with generated tests" presented at ICLR in 2023.
Anh Nguyen is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DAOGUANG ZAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Daoguang Zan is an author who contributed to the paper "CodeT: Code generation with generated tests" presented at ICLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ZEQI LIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zeqi Lin is an author who contributed to the paper "CodeT: Code generation with generated tests" presented at ICLR in 2023.
Zeqi Lin is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JIAN-GUANG LOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jian-Guang Lou is an author who contributed to the paper "CodeT: Code generation with generated tests" presented at ICLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="WEIZHU CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Weizhu Chen is an author who contributed to the paper "CodeT: Code generation with generated tests" presented at ICLR in 2023.
Weizhu Chen is one of the authors of the Phi-3 technical report.
Weizhu Chen is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models," published in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,dd9a46950237e49ef9b1c7ef08e08d42,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CODET: CODE GENERATION WITH GENERATED TESTS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper presented at ICLR in 2023, authored by Bei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi Lin, Jian-Guang Lou, and Weizhu Chen, discussing code generation with generated tests.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ICLR">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">ICLR (International Conference on Learning Representations) is a prominent conference where research papers like "CodeT: Code generation with generated tests" are presented.
ICLR is a conference where the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" was published in 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MARK CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mark Chen is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.
Mark Chen is one of the authors of the paper on evaluating large language models trained on code, published in 2021.
Mark Chen is one of the authors of the paper on training verifiers to solve math word problems, published in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,7de66b94cf868b37b1df51dc545c415f,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JERRY TWOREK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jerry Tworek is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.
Jerry Tworek is one of the authors of the paper on evaluating large language models trained on code, published in 2021.
Jerry Tworek is one of the authors of the paper on training verifiers to solve math word problems, published in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,7de66b94cf868b37b1df51dc545c415f,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HEEWOO JUN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Heewoo Jun is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.
Heewoo Jun is one of the authors of the paper on evaluating large language models trained on code, published in 2021.
Heewoo Jun is one of the authors of the paper on training verifiers to solve math word problems, published in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,7de66b94cf868b37b1df51dc545c415f,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="QIMING YUAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qiming Yuan is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.
Qiming Yuan is one of the authors of the paper on evaluating large language models trained on code, published in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="HENRIQUE PONDE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Henrique Ponde is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HARRISON EDWARDS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Harrison Edwards is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="YURA BURDA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yura Burda is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="NICHOLAS JOSEPH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nicholas Joseph is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.
Nicholas Joseph is one of the authors of the paper on evaluating large language models trained on code, published in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="GREG BROCKMAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Greg Brockman is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.
Greg Brockman is one of the authors of the paper on evaluating large language models trained on code, published in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="ALEX RAY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alex Ray is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="RAUL PURI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Raul Puri is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="GRETCHEN KRUEGER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gretchen Krueger is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MICHAEL PETROV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Michael Petrov is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HEIDY KHLAAF">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Heidy Khlaaf is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="GIRISH SASTRY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Girish Sastry is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PAMELA MISHKIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Pamela Mishkin is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BROOKE CHAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Brooke Chan is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SCOTT GRAY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Scott Gray is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MIKHAIL PAVLOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mikhail Pavlov is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ALETHEA POWER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alethea Power is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="LUKASZ KAISER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lukasz Kaiser is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.
Lukasz Kaiser is one of the authors of the paper on training verifiers to solve math word problems, published in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MOHAMMAD BAVARIAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mohammad Bavarian is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.
Mohammad Bavarian is one of the authors of the paper on training verifiers to solve math word problems, published in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CLEMENS WINTER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Clemens Winter is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PHILIPPE TILLET">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Philippe Tillet is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="FELIPE PETROSKI SUCH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Felipe Petroski Such is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DAVID W. CUMMINGS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">David W. Cummings is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MATTHIAS PLAPPERT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Matthias Plappert is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.
Matthias Plappert is one of the authors of the paper on training verifiers to solve math word problems, published in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="FOTIOS CHANTZIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fotios Chantzis is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ELIZABETH BARNES">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Elizabeth Barnes is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ARIEL HERBERT-VOSS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ariel Herbert-Voss is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="WILLIAM H. GUSS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">William H. Guss is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.
A researcher and co-author of the paper "MineRL: A large-scale dataset of Minecraft demonstrations" presented at IJCAI 2019.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ALEX NICHOL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alex Nichol is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="IGOR BABUSCHKIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Igor Babuschkin is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SUCHIR BALAJI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Suchir Balaji is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.
One of the authors of the paper "WebGPT: Browser-assisted question-answering with human feedback," published as an arXiv preprint in 2021.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SHANTANU JAIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shantanu Jain is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.
One of the authors of the paper "WebGPT: Browser-assisted question-answering with human feedback," published as an arXiv preprint in 2021.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ANDREW CARR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Andrew Carr is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JAN LEIKE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jan Leike is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JOSHUA ACHIAM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Joshua Achiam is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="VEDANT MISRA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Vedant Misra is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.Vedant Misra is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="EVAN MORIKAWA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Evan Morikawa is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ALEC RADFORD">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alec Radford is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MATTHEW M. KNIGHT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Matthew M. Knight is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MILES BRUNDAGE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Miles Brundage is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MIRA MURATI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mira Murati is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="KATIE MAYER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Katie Mayer is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PETER WELINDER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Peter Welinder is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BOB MCGREW">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bob McGrew is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DARIO AMODEI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dario Amodei is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SAM MCCANDLISH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sam McCandlish is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ILYA SUTSKEVER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ilya Sutskever is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.
Ilya Sutskever is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.
Ilya Sutskever is one of the authors of the paper titled "Imagenet classification with deep convolutional neural networks" published in Advances in Neural Information Processing Systems in 2012.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,6109537356a2ce2339f77c827aa3668e,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="WOJCIECH ZAREMBA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wojciech Zaremba is an author who contributed to the paper "Evaluating large language models trained on code" published on arXiv in 2021.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="EVALUATING LARGE LANGUAGE MODELS TRAINED ON CODE">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper published on arXiv in 2021, authored by Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde, Jared Kaplan, Harrison Edwards, Yura Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, David W. Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William H. Guss, Alex Nichol, Igor Babuschkin, Suchir Balaji, Shantanu Jain, Andrew Carr, Jan Leike, Joshua Achiam, Vedant Misra,</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="WENHU CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wenhu Chen is an author who contributed to the paper "Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks" published in TMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="XUEGUANG MA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xueguang Ma is an author who contributed to the paper "Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks" published in TMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="XINYI WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xinyi Wang is an author who contributed to the paper "Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks" published in TMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="WILLIAM W. COHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">William W. Cohen is an author who contributed to the paper "Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks" published in TMLR in 2023.
William W. Cohen is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PROGRAM OF THOUGHTS PROMPTING: DISENTANGLING COMPUTATION FROM REASONING FOR NUMERICAL REASONING TASKS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper published in TMLR in 2023, authored by Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W. Cohen, discussing the separation of computation from reasoning in numerical reasoning tasks.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="TMLR">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">TMLR (Transactions on Machine Learning Research) is a journal where research papers like "Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks" are published.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="AAKANKSHA CHOWDHERY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Aakanksha Chowdhery is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.
Aakanksha Chowdhery is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SHARAN NARANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sharan Narang is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.
Sharan Narang is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JACOB DEVLIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jacob Devlin is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="GAURAV MISHRA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gaurav Mishra is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ADAM ROBERTS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Adam Roberts is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PAUL BARHAM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Paul Barham is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HYUNG WON CHUNG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hyung Won Chung is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.
Hyung Won Chung is one of the authors of the paper "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023.
Hyung Won Chung is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,7a48515e86161237c03c9a8373197126,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SEBASTIAN GEHRMANN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sebastian Gehrmann is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.
Sebastian Gehrmann is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="PARKER SCHUH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Parker Schuh is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="KENSEN SHI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kensen Shi is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SASHA TSVYASHCHENKO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sasha Tsvyashchenko is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JOSHUA MAYNEZ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Joshua Maynez is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ABHISHEK RAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Abhishek Rao is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PARKER BARNES">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Parker Barnes is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="YI TAY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yi Tay is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.
Yi Tay is one of the authors of the paper "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023.
Yi Tay is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,7a48515e86161237c03c9a8373197126,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NOAM SHAZEER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Noam Shazeer is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="VINODKUMAR PRABHAKARAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Vinodkumar Prabhakaran is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="EMILY REIF">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Emily Reif is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="NAN DU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nan Du is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.
Nan Du is an author who contributed to the paper "React: Synergizing reasoning and acting in language models."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BEN HUTCHINSON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ben Hutchinson is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="REINER POPE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Reiner Pope is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JAMES BRADBURY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">James Bradbury is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MICHAEL ISARD">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Michael Isard is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="GUY GUR-ARI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Guy Gur-Ari is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="PENGCHENG YIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Pengcheng Yin is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="TOJU DUKE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Toju Duke is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ANSELM LEVSKAYA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Anselm Levskaya is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SANJAY GHEMAWAT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sanjay Ghemawat is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SUNIPA DEV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sunipa Dev is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="XAVIER GARCIA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xavier Garcia is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="KEVIN ROBINSON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kevin Robinson is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="LIAM FEDUS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liam Fedus is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DENNY ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Denny Zhou is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.
A researcher and co-author of the paper "Large language models cannot self-correct reasoning yet" presented at ICLR 2024.
Denny Zhou is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.
Denny Zhou is one of the authors of the paper "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023.
Denny Zhou is an author who contributed to the papers "Self-consistency improves chain of thought reasoning in language models" and "Chain-of-thought prompting elicits reasoning in large language models."
Denny Zhou is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models" published as an arXiv preprint in 2023.Denny Zhou is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures" published as an arXiv preprint in 2024.
Denny Zhou is one of the authors of the paper titled "Instruction-following evaluation for large language models," published in 2023.Denny Zhou is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598,7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="DAPHNE IPPOLITO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Daphne Ippolito is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DAVID LUAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">David Luan is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="HYEONTAEK LIM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hyeontaek Lim is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="BARRET ZOPH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Barret Zoph is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ALEXANDER SPIRIDONOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alexander Spiridonov is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="RYAN SEPASSI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ryan Sepassi is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SHIVANI AGRAWAL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shivani Agrawal is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MARK OMERNICK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mark Omernick is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ANDREW M. DAI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Andrew M. Dai is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="THANUMALAYAN SANKARANARAYANA PILLAI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Thanumalayan Sankaranarayana Pillai is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MARIE PELLAT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Marie Pellat is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="AITOR LEWKOWYCZ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Aitor Lewkowycz is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ERICA MOREIRA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Erica Moreira is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="REWON CHILD">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rewon Child is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="OLEKSANDR POLOZOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Oleksandr Polozov is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="KATHERINE LEE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Katherine Lee is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ZONGWEI ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zongwei Zhou is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="XUEZHI WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xuezhi Wang is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.
Xuezhi Wang is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.
Xuezhi Wang is one of the authors of the paper "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023.
Xuezhi Wang is an author who contributed to the papers "Self-consistency improves chain of thought reasoning in language models" and "Chain-of-thought prompting elicits reasoning in large language models."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="BRENNAN SAETA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Brennan Saeta is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MARK DIAZ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mark Diaz is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="ORHAN FIRAT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Orhan Firat is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="MICHELE CATASTA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Michele Catasta is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JASON WEI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jason Wei is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.
Jason Wei is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.
Jason Wei is one of the authors of the paper "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023.
Jason Wei is an author who contributed to the papers "Self-consistency improves chain of thought reasoning in language models" and "Chain-of-thought prompting elicits reasoning in large language models."
Jason Wei is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,7a48515e86161237c03c9a8373197126,8180bf20b7577f3eee40df5991e2886d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="KATHY MEIER-HELLSTERN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kathy Meier-Hellstern is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="DOUGLAS ECK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Douglas Eck is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="JEFF DEAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jeff Dean is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in JMLR in 2023.</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="SLAV PETROV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Slav Petrov is an author who contributed to the paper "PaLM: Scaling language modeling with pathways" published in</data>
      <data key="d2">7a48515e86161237c03c9a8373197126</data>
    </node>
    <node id="EMBODIED MULTI-MODAL LANGUAGE MODEL">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">An advanced language model that integrates multiple modalities and is designed to be embodied, presented at ICML 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ICML 2023">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">The International Conference on Machine Learning held in 2023, where various research papers and advancements in machine learning are presented.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YILUN DU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and author of the paper "Learning universal policies via text-guided video generation" presented at NeurIPS 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="MENGJIAO YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Learning universal policies via text-guided video generation" presented at NeurIPS 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="BO DAI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Learning universal policies via text-guided video generation" presented at NeurIPS 2023.
Bo Dai is one of the authors of the paper "AdaPlanner: Adaptive planning from feedback with language models" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HANJUN DAI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Learning universal policies via text-guided video generation" presented at NeurIPS 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="OFIR NACHUM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Multimodal web navigation with instruction-finetuned foundation models" presented at ICLR 2024.A researcher and co-author of the paper "Learning universal policies via text-guided video generation" presented at NeurIPS 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="JOSHUA B. TENENBAUM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Learning universal policies via text-guided video generation" presented at NeurIPS 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="DALE SCHUURMANS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Learning universal policies via text-guided video generation" presented at NeurIPS 2023.
Dale Schuurmans is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.
Dale Schuurmans is an author who contributed to the papers "Self-consistency improves chain of thought reasoning in language models" and "Chain-of-thought prompting elicits reasoning in large language models."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PIETER ABBEEL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Learning universal policies via text-guided video generation" presented at NeurIPS 2023.
Pieter Abbeel is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.
Pieter Abbeel is one of the authors of the paper on managing extreme AI risks, published in 2024.
Pieter Abbeel is one of the authors of the paper on the false promise of imitating proprietary LLMs, published in 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,7de66b94cf868b37b1df51dc545c415f,8180bf20b7577f3eee40df5991e2886d,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="LEARNING UNIVERSAL POLICIES VIA TEXT-GUIDED VIDEO GENERATION">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at NeurIPS 2023 that discusses learning universal policies through the generation of videos guided by text.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="NEURIPS 2023">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">The Conference on Neural Information Processing Systems held in 2023, where various research papers and advancements in neural information processing are presented.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JONATHAN ST BT EVANS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and author of the paper "Intuition and reasoning: A dual-process perspective" published in Psychological Inquiry in 2010.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="INTUITION AND REASONING: A DUAL-PROCESS PERSPECTIVE">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper by Jonathan St BT Evans that discusses the dual-process perspective on intuition and reasoning, published in Psychological Inquiry in 2010.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="PSYCHOLOGICAL INQUIRY">
      <data key="d0">JOURNAL</data>
      <data key="d1">A journal that published the paper "Intuition and reasoning: A dual-process perspective" by Jonathan St BT Evans in 2010.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="LINXI FAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "MineDojo: Building open-ended embodied agents with internet-scale knowledge" presented at NeurIPS Datasets and Benchmarks Track 2022.
Linxi Fan is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.
One of the authors of the paper "Eureka: Human-level reward design via coding large language models," published in the Twelfth International Conference on Learning Representations in 2023.
Linxi Fan is one of the authors of the paper "Voyager: An open-ended embodied agent with large language models" published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="GUANZHI WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "MineDojo: Building open-ended embodied agents with internet-scale knowledge" presented at NeurIPS Datasets and Benchmarks Track 2022.
Guanzhi Wang is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.
One of the authors of the paper "Eureka: Human-level reward design via coding large language models," published in the Twelfth International Conference on Learning Representations in 2023.
Guanzhi Wang is one of the authors of the paper "Voyager: An open-ended embodied agent with large language models" published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YUNFAN JIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "MineDojo: Building open-ended embodied agents with internet-scale knowledge" presented at NeurIPS Datasets and Benchmarks Track 2022.
Yunfan Jiang is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.
Yunfan Jiang is one of the authors of the paper "Voyager: An open-ended embodied agent with large language models" published as an arXiv preprint in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="AJAY MANDLEKAR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "MineDojo: Building open-ended embodied agents with internet-scale knowledge" presented at NeurIPS Datasets and Benchmarks Track 2022.
Ajay Mandlekar is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.
Ajay Mandlekar is one of the authors of the paper "Voyager: An open-ended embodied agent with large language models" published as an arXiv preprint in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YUNCONG YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "MineDojo: Building open-ended embodied agents with internet-scale knowledge" presented at NeurIPS Datasets and Benchmarks Track 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HAOYI ZHU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "MineDojo: Building open-ended embodied agents with internet-scale knowledge" presented at NeurIPS Datasets and Benchmarks Track 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ANDREW TANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "MineDojo: Building open-ended embodied agents with internet-scale knowledge" presented at NeurIPS Datasets and Benchmarks Track 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="DE-AN HUANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "MineDojo: Building open-ended embodied agents with internet-scale knowledge" presented at NeurIPS Datasets and Benchmarks Track 2022.
One of the authors of the paper "Eureka: Human-level reward design via coding large language models," published in the Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YUKE ZHU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "MineDojo: Building open-ended embodied agents with internet-scale knowledge" presented at NeurIPS Datasets and Benchmarks Track 2022.
Yuke Zhu is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.
One of the authors of the paper "Eureka: Human-level reward design via coding large language models," published in the Twelfth International Conference on Learning Representations in 2023.
Yuke Zhu is one of the authors of the paper "Voyager: An open-ended embodied agent with large language models" published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ANIMA ANANDKUMAR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "MineDojo: Building open-ended embodied agents with internet-scale knowledge" presented at NeurIPS Datasets and Benchmarks Track 2022.
Anima Anandkumar is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.
One of the authors of the paper "Eureka: Human-level reward design via coding large language models," published in the Twelfth International Conference on Learning Representations in 2023.
Anima Anandkumar is one of the authors of the paper "Voyager: An open-ended embodied agent with large language models" published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,34d0bb2211fc795fe1096442e086a2b3,68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MINEDOJO">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at NeurIPS Datasets and Benchmarks Track 2022 that discusses building open-ended embodied agents with internet-scale knowledge.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="NEURIPS DATASETS AND BENCHMARKS TRACK 2022">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">A track at the NeurIPS conference in 2022 focused on datasets and benchmarks, where various research papers are presented.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HIROKI FURUTA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Multimodal web navigation with instruction-finetuned foundation models" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YUTAKA MATSUO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Large language models are zero-shot reasoners" presented at NeurIPS 2022.A researcher and co-author of the paper "Multimodal web navigation with instruction-finetuned foundation models" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SHIXIANG SHANE GU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Large language models are zero-shot reasoners" presented at NeurIPS 2022.A researcher and co-author of the paper "Multimodal web navigation with instruction-finetuned foundation models" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="IZZEDDIN GUR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Multimodal web navigation with instruction-finetuned foundation models" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="MULTIMODAL WEB NAVIGATION WITH INSTRUCTION-FINETUNED FOUNDATION MODELS">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at ICLR 2024 that discusses multimodal web navigation using instruction-finetuned foundation models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ICLR 2024">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">The International Conference on Learning Representations held in 2024, where various research papers and advancements in learning representations are presented.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="LUYU GAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "PAL: Program-aided language models" presented at ICML 2023.
Luyu Gao is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS, 2023.
One of the authors of the paper "Self-refine: Iterative refinement with self-feedback," published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="AMAN MADAAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "PAL: Program-aided language models" presented at ICML 2023.
Aman Madaan is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS, 2023.
One of the authors of the paper "Self-refine: Iterative refinement with self-feedback," published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="SHUYAN ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "PAL: Program-aided language models" presented at ICML 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="URI ALON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "PAL: Program-aided language models" presented at ICML 2023.
Uri Alon is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS, 2023.
One of the authors of the paper "Self-refine: Iterative refinement with self-feedback," published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="PENGFEI LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "PAL: Program-aided language models" presented at ICML 2023.
Pengfei Liu is one of the authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YIMING YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "PAL: Program-aided language models" presented at ICML 2023.
Yiming Yang is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS, 2023.
Yiming Yang is one of the authors of the paper titled "Program-aided language models" presented at the International Conference on Machine Learning in 2023.
One of the authors of the paper "Self-refine: Iterative refinement with self-feedback," published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,6109537356a2ce2339f77c827aa3668e,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JAMIE CALLAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "PAL: Program-aided language models" presented at ICML 2023.
Jamie Callan is one of the authors of the paper titled "Program-aided language models" presented at the International Conference on Machine Learning in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="GRAHAM NEUBIG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "PAL: Program-aided language models" presented at ICML 2023.
Graham Neubig is one of the authors of the paper titled "Program-aided language models" presented at the International Conference on Machine Learning in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="PAL: PROGRAM-AIDED LANGUAGE MODELS">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at ICML 2023 that discusses program-aided language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JIAXIAN GUO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Long text generation via adversarial training with leaked information" presented at AAAI 2018.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="SIDI LU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Long text generation via adversarial training with leaked information" presented at AAAI 2018.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HAN CAI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Long text generation via adversarial training with leaked information" presented at AAAI 2018.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="WEINAN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Long text generation via adversarial training with leaked information" presented at AAAI 2018.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YONG YU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Long text generation via adversarial training with leaked information" presented at AAAI 2018.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JUN WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Long text generation via adversarial training with leaked information" presented at AAAI 2018.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="LONG TEXT GENERATION VIA ADVERSARIAL TRAINING WITH LEAKED INFORMATION">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at AAAI 2018 that discusses long text generation using adversarial training with leaked information.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="AAAI 2018">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">The Association for the Advancement of Artificial Intelligence conference held in 2018, where various research papers and advancements in artificial intelligence are presented.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="NICHOLAY TOPIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "MineRL: A large-scale dataset of Minecraft demonstrations" presented at IJCAI 2019.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="PHILLIP WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "MineRL: A large-scale dataset of Minecraft demonstrations" presented at IJCAI 2019.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="CAYDEN CODEL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "MineRL: A large-scale dataset of Minecraft demonstrations" presented at IJCAI 2019.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="MANUELA VELOSO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "MineRL: A large-scale dataset of Minecraft demonstrations" presented at IJCAI 2019.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="RUSLAN SALAKHUTDINOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "MineRL: A large-scale dataset of Minecraft demonstrations" presented at IJCAI 2019.
Ruslan Salakhutdinov is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MINERL">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at IJCAI 2019 that discusses a large-scale dataset of Minecraft demonstrations.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="IJCAI 2019">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">The International Joint Conference on Artificial Intelligence held in 2019, where various research papers and advancements in artificial intelligence are presented.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="DANIJAR HAFNER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Mastering diverse domains through world models" published on arXiv in 2023.A researcher and co-author of the paper "Learning latent dynamics for planning from pixels" presented at ICML 2019.
Danijar Hafner is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="TIMOTHY LILLICRAP">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Mastering diverse domains through world models" published on arXiv in 2023.A researcher and co-author of the paper "Learning latent dynamics for planning from pixels" presented at ICML 2019.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="IAN FISCHER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Learning latent dynamics for planning from pixels" presented at ICML 2019.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="RUBEN VILLEGAS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Learning latent dynamics for planning from pixels" presented at ICML 2019.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="DAVID HA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Learning latent dynamics for planning from pixels" presented at ICML 2019.
David Ha is one of the authors of the paper titled "The AI Scientist: Towards fully automated open-ended scientific discovery" published as an arXiv preprint in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HONGLAK LEE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Learning latent dynamics for planning from pixels" presented at ICML 2019.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JAMES DAVIDSON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Learning latent dynamics for planning from pixels" presented at ICML 2019.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="LEARNING LATENT DYNAMICS FOR PLANNING FROM PIXELS">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at ICML 2019 that discusses learning latent dynamics for planning from pixel data.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JURGIS PASUKONIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Mastering diverse domains through world models" published on arXiv in 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JIMMY BA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Mastering diverse domains through world models" published on arXiv in 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="MASTERING DIVERSE DOMAINS THROUGH WORLD MODELS">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper published on arXiv in 2023 that discusses mastering diverse domains through the use of world models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="SHIBO HAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reasoning with language model is planning with world model" presented at EMNLP 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YI GU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reasoning with language model is planning with world model" presented at EMNLP 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HAODI MA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reasoning with language model is planning with world model" presented at EMNLP 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JOSHUA JIAHUA HONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reasoning with language model is planning with world model" presented at EMNLP 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ZHEN WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reasoning with language model is planning with world model" presented at EMNLP 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="DAISY ZHE WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reasoning with language model is planning with world model" presented at EMNLP 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ZHTING HU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reasoning with language model is planning with world model" presented at EMNLP 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="REASONING WITH LANGUAGE MODEL IS PLANNING WITH WORLD MODEL">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at EMNLP 2023 that discusses how reasoning with language models is akin to planning with world models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="EMNLP 2023">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">The Conference on Empirical Methods in Natural Language Processing held in 2023, where various research papers and advancements in natural language processing are presented.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JIE HUANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Large language models cannot self-correct reasoning yet" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="XINYUN CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Large language models cannot self-correct reasoning yet" presented at ICLR 2024.
Xinyun Chen is an author who contributed to the paper "Large language models as optimizers."
Xinyun Chen is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures" published as an arXiv preprint in 2024.Xinyun Chen is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models" published as an arXiv preprint in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,68e5573b596d253a03047b1e41988598,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SWAROOP MISHRA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Large language models cannot self-correct reasoning yet" presented at ICLR 2024.
Swaroop Mishra is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models" published as an arXiv preprint in 2023.Swaroop Mishra is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures" published as an arXiv preprint in 2024.
Swaroop Mishra is one of the authors of the paper titled "Instruction-following evaluation for large language models," published in 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="HUAIXIU STEVEN ZHENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Large language models cannot self-correct reasoning yet" presented at ICLR 2024.
Huaixiu Steven Zheng is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models" published as an arXiv preprint in 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="ADAMS WEI YU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Large language models cannot self-correct reasoning yet" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="XINYING SONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Large language models cannot self-correct reasoning yet" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="LARGE LANGUAGE MODELS CANNOT SELF-CORRECT REASONING YET">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at ICLR 2024 that discusses the limitations of large language models in self-correcting their reasoning.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="WENLONG HUANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="F. XIA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HARRIS CHAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JACKY LIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="PETER R. FLORENCE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="JONATHAN TOMPSON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="IGOR MORDATCH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="TOMAS JACKSON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Inner monologue: Embodied reasoning through planning with language models" presented at CoRL 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="INNER MONOLOGUE: EMBODIED REASONING THROUGH PLANNING WITH LANGUAGE MODELS">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at CoRL 2022 that discusses embodied reasoning through planning with language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="CORL 2022">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">The Conference on Robot Learning held in 2022, where various research papers and advancements in robot learning are presented.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="LEVENTE KOCSIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Bandit based monte-carlo planning" presented at ECML 2006.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="CSABA SZEPESV&#193;RI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Bandit based monte-carlo planning" presented at ECML 2006.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="BANDIT BASED MONTE-CARLO PLANNING">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at ECML 2006 that discusses bandit-based Monte Carlo planning.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ECML 2006">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">The European Conference on Machine Learning held in 2006, where various research papers and advancements in machine learning are presented.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="TAKESHI KOJIMA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Large language models are zero-shot reasoners" presented at NeurIPS 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="MACHEL REID">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Large language models are zero-shot reasoners" presented at NeurIPS 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YUSUKE IWASAWA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Large language models are zero-shot reasoners" presented at NeurIPS 2022.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="LARGE LANGUAGE MODELS ARE ZERO-SHOT REASONERS">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at NeurIPS 2022 that discusses the zero-shot reasoning capabilities of large language models.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="STEVEN M. LAVALLE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and author of the paper "Rapidly-exploring random trees: A new tool for path planning" published in The Annual Research Report in 1998.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="RAPIDLY-EXPLORING RANDOM TREES: A NEW TOOL FOR PATH PLANNING">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper by Steven M. LaValle that discusses rapidly-exploring random trees as a new tool for path planning, published in The Annual Research Report in 1998.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="THE ANNUAL RESEARCH REPORT">
      <data key="d0">JOURNAL</data>
      <data key="d1">A journal that published the paper "Rapidly-exploring random trees: A new tool for path planning" by Steven M. LaValle in 1998.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="EVAN ZHERAN LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reinforcement learning on web interfaces using workflow-guided exploration" presented at ICLR 2018.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="KELVIN GUU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reinforcement learning on web interfaces using workflow-guided exploration" presented at ICLR 2018.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="PANUPONG PASUPAT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reinforcement learning on web interfaces using workflow-guided exploration" presented at ICLR 2018.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="TIANLIN SHI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reinforcement learning on web interfaces using workflow-guided exploration" presented at ICLR 2018.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="PERCY LIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reinforcement learning on web interfaces using workflow-guided exploration" presented at ICLR 2018.
Percy Liang is one of the authors of the AlpacaEval project, an automatic evaluator of instruction-following models, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="REINFORCEMENT LEARNING ON WEB INTERFACES USING WORKFLOW-GUIDED EXPLORATION">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at ICLR 2018 that discusses reinforcement learning on web interfaces using workflow-guided exploration.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="XIAO LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HAO YU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HANCHEN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YIFAN XU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="XUANYU LEI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HANYU LAI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YU GU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HANGLIANG DING">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="KAIWEN MEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="KEJUAN YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="SHUDAN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="XIANG DENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="AOHAN ZENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ZHENGXIAO DU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="CHENHUI ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="SHENG SHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="TIANJUN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YU SU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HUAN SUN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="MINLIE HUANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="YUXIAO DONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "AgentBench: Evaluating LLMs as agents" presented at ICLR 2024.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="AGENTBENCH: EVALUATING LLMS AS AGENTS">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper presented at ICLR 2024 that discusses the evaluation of large language models as agents.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="ZHIHAN LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reason for future, act for now: A principled framework for autonomous LLM agents with provable sample efficiency" published on arXiv in 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="HAO HU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher and co-author of the paper "Reason for future, act for now: A principled framework for autonomous LLM agents with provable sample efficiency" published on arXiv in 2023.</data>
      <data key="d2">68e5573b596d253a03047b1e41988598</data>
    </node>
    <node id="NIKET TANDON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Niket Tandon is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS, 2023.
One of the authors of the paper "Self-refine: Iterative refinement with self-feedback," published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="PRAKHAR GUPTA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Prakhar Gupta is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS, 2023.
One of the authors of the paper "Self-refine: Iterative refinement with self-feedback," published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SKYLER HALLINAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Skyler Hallinan is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS, 2023.
One of the authors of the paper "Self-refine: Iterative refinement with self-feedback," published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SARAH WIEGREFFE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sarah Wiegreffe is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS, 2023.
One of the authors of the paper "Self-refine: Iterative refinement with self-feedback," published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="NOUHA DZIRI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nouha Dziri is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS, 2023.
One of the authors of the paper "Self-refine: Iterative refinement with self-feedback," published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SHRIMAI PRABHUMOYE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shrimai Prabhumoye is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS, 2023.
One of the authors of the paper "Self-refine: Iterative refinement with self-feedback," published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SHASHANK GUPTA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shashank Gupta is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BODHISATTWA PRASAD MAJUMDER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bodhisattwa Prasad Majumder is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="KATHERINE HERMANN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Katherine Hermann is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SEAN WELLECK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sean Welleck is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="AMIR YAZDANBAKHSH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Amir Yazdanbakhsh is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="PETER CLARK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Peter Clark is one of the authors of the paper "Self-refine: Iterative refinement with self-feedback" published in NeurIPS, 2023.
Peter Clark is one of the authors of the paper on the AI2 Reasoning Challenge (ARC), published in 2018.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="RAMESH NALLAPATI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ramesh Nallapati is one of the authors of the paper "Abstractive text summarization using sequence-to-sequence RNNs and beyond" published in the Special Interest Group on Natural Language Learning, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BOWEN ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bowen Zhou is one of the authors of the paper "Abstractive text summarization using sequence-to-sequence RNNs and beyond" published in the Special Interest Group on Natural Language Learning, 2016.
Bowen Zhou is one of the authors of the paper on enhancing chat language models by scaling high-quality instructional conversations, published in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CICERO DOS SANTOS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cicero dos Santos is one of the authors of the paper "Abstractive text summarization using sequence-to-sequence RNNs and beyond" published in the Special Interest Group on Natural Language Learning, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="CAGLAR GULCEHRE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Caglar Gulcehre is one of the authors of the paper "Abstractive text summarization using sequence-to-sequence RNNs and beyond" published in the Special Interest Group on Natural Language Learning, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BING XIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bing Xiang is one of the authors of the paper "Abstractive text summarization using sequence-to-sequence RNNs and beyond" published in the Special Interest Group on Natural Language Learning, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ABSTRACTIVE TEXT SUMMARIZATION USING SEQUENCE-TO-SEQUENCE RNNS AND BEYOND">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper discussing abstractive text summarization using sequence-to-sequence RNNs and other methods, published in the Special Interest Group on Natural Language Learning, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SPECIAL INTEREST GROUP ON NATURAL LANGUAGE LEARNING">
      <data key="d0">CONFERENCE, PUBLICATION</data>
      <data key="d1">A conference where the paper "Abstractive text summarization using sequence-to-sequence RNNs and beyond" was published in 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="OPENAI">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">OpenAI is the organization that published the GPT-4 technical report in 2023.
OpenAI is the organization that developed the GPT Foundation Model.
OpenAI is the organization that developed GPT-4 and GPT-3.5, which are used in Meta Agent Search for evaluating agents and baselines.
The company that published the blog post "Introducing ChatGPT" in November 2022 and the paper "Simple evals" in 2023.
The organization that provides the GPT model used in the get_json_response_from_gpt function.
The organization responsible for developing models like GPT-4 and GPT-3.5-turbo, and for conducting various experiments.
OpenAI is the organization responsible for developing the GPT-4o-2024-05-13 and GPT-3.5-turbo-0125 language models.
OpenAI is the organization behind the GPT-4 technical report, published in 2023.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e,84317ae35cc75d612287186d93461447,bc26e68b0b2783ba912b9e5606d9eb0b,c3d0436082aada237ee4bee645f16059,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="GPT-4 TECHNICAL REPORT">
      <data key="d0">DOCUMENT, REPORT</data>
      <data key="d1">A technical report on GPT-4 published by OpenAI in 2023.
A technical report on GPT-4 published by OpenAI in 2024.
The GPT-4 technical report is a document published by OpenAI in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="YUJIA QIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yujia Qin is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.
Yujia Qin is one of the authors of the paper on enhancing chat language models by scaling high-quality instructional conversations, published in 2023.
Yujia Qin is one of the authors of the ToolLLM project, which facilitates large language models to master over 16,000 real-world APIs, published in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SHIHAO LIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shihao Liang is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.
Shihao Liang is one of the authors of the ToolLLM project, which facilitates large language models to master over 16,000 real-world APIs, published in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="YINING YE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yining Ye is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.
Yining Ye is one of the authors of the ToolLLM project, which facilitates large language models to master over 16,000 real-world APIs, published in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="KUNLUN ZHU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kunlun Zhu is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.
Kunlun Zhu is one of the authors of the ToolLLM project, which facilitates large language models to master over 16,000 real-world APIs, published in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="LAN YAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lan Yan is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.
Lan Yan is one of the authors of the ToolLLM project, which facilitates large language models to master over 16,000 real-world APIs, published in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="YAXI LU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yaxi Lu is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.
Yaxi Lu is one of the authors of the paper on multi-agent collaboration and emergent behaviors, published in 2023.
Yaxi Lu is</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,3d1f6634f93f8a4c296dc8df7e59859e,7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="YANKAI LIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yankai Lin is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.
Yankai Lin is an author who contributed to the paper "A survey on large language model based autonomous agents."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="XIN CONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xin Cong is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="XIANGRU TANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiangru Tang is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BILL QIAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bill Qian is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SIHAN ZHAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sihan Zhao is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="RUNCHU TIAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Runchu Tian is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="RUOBING XIE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ruobing Xie is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="JIE ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jie Zhou is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MARK GERSTEIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mark Gerstein is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="DAHAI LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dahai Li is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ZHIYUAN LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhiyuan Liu is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.
Zhiyuan Liu is one of the authors of the paper on enhancing chat language models by scaling high-quality instructional conversations, published in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MAOSONG SUN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Maosong Sun is one of the authors of the paper "ToolLLM: Facilitating large language models to master 16000+ real-world APIs" published in ICLR, 2024.
Maosong Sun is one of the authors of the paper on enhancing chat language models by scaling high-quality instructional conversations, published in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TOOLLLM">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">ToolLLM is a method facilitating large language models to master over 16000 real-world APIs, discussed in a paper published in ICLR, 2024.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ABULHAIR SAPAROV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Abulhair Saparov is one of the authors of the paper "Language models are greedy reasoners: A systematic formal analysis of chain-of-thought" published in ICLR, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="HE HE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">He He is one of the authors of the paper "Language models are greedy reasoners: A systematic formal analysis of chain-of-thought" published in ICLR, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="LANGUAGE MODELS ARE GREEDY REASONERS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Language models are greedy reasoners: A systematic formal analysis of chain-of-thought" published in ICLR, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="TIMO SCHICK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Timo Schick is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools" published in NeurIPS, 2023.
Timo Schick is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools" published in the Thirty-seventh Conference on Neural Information Processing Systems in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JANE DWIVEDI-YU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jane Dwivedi-Yu is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools" published in NeurIPS, 2023.
Jane Dwivedi-Yu is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools" published in the Thirty-seventh Conference on Neural Information Processing Systems in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ROBERTO DESSI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Roberto Dessi is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools" published in NeurIPS, 2023.
Roberto Dessi is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools" published in the Thirty-seventh Conference on Neural Information Processing Systems in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ROBERTA RAILEANU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Roberta Raileanu is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools" published in NeurIPS, 2023.
Roberta Raileanu is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools" published in the Thirty-seventh Conference on Neural Information Processing Systems in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MARIA LOMELI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Maria Lomeli is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools" published in NeurIPS, 2023.
Maria Lomeli is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools" published in the Thirty-seventh Conference on Neural Information Processing Systems in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="LUKE ZETTLEMOYER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Luke Zettlemoyer is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools" published in NeurIPS, 2023.
Luke Zettlemoyer is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools" published in the Thirty-seventh Conference on Neural Information Processing Systems in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="NICOLA CANCEDDA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nicola Cancedda is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools" published in NeurIPS, 2023.
Nicola Cancedda is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools" published in the Thirty-seventh Conference on Neural Information Processing Systems in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="THOMAS SCIALOM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Thomas Scialom is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools" published in NeurIPS, 2023.
Thomas Scialom is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.
Thomas Scialom is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools" published in the Thirty-seventh Conference on Neural Information Processing Systems in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="TOOLFORMER">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Toolformer is a method where language models can teach themselves to use tools, discussed in a paper published in NeurIPS, 2023.
Toolformer is a technique used in agentic systems to enable agents to use external tools such as search engines, code execution, and database queries.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="YONGLIANG SHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yongliang Shen is one of the authors of the paper "HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="KAITAO SONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kaitao Song is one of the authors of the paper "HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face" published in NeurIPS, 2023.
Kaitao Song is an author who contributed to the paper "Evoagent: Towards automatic multi-agent generation via evolutionary algorithms."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="XU TAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xu Tan is one of the authors of the paper "HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face" published in NeurIPS, 2023.
Xu Tan is an author who contributed to the paper "Evoagent: Towards automatic multi-agent generation via evolutionary algorithms."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="DONGSHENG LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dongsheng Li is one of the authors of the paper "HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face" published in NeurIPS, 2023.
Dongsheng Li is an author who contributed to the paper "Evoagent: Towards automatic multi-agent generation via evolutionary algorithms."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="WEIMING LU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Weiming Lu is one of the authors of the paper "HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="YUETING ZHUANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yueting Zhuang is one of the authors of the paper "HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="HUGGINGGPT">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">HuggingGPT is a method for solving AI tasks with ChatGPT and its friends in Hugging Face, discussed in a paper published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="NOAH SHINN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Noah Shinn is one of the authors of the paper "Reflexion: Language agents with verbal reinforcement learning" published in NeurIPS, 2023.
Noah Shinn is one of the authors of the paper "Reflexion: Language agents with verbal reinforcement learning" published in Advances in Neural Information Processing Systems in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="FEDERICO CASSANO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Federico Cassano is one of the authors of the paper "Reflexion: Language agents with verbal reinforcement learning" published in NeurIPS, 2023.
Federico Cassano is one of the authors of the paper "Reflexion: Language agents with verbal reinforcement learning" published in Advances in Neural Information Processing Systems in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="BECK LABASH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Beck Labash is one of the authors of the paper "Reflexion: Language agents with verbal reinforcement learning" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ASHWIN GOPINATH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ashwin Gopinath is one of the authors of the paper "Reflexion: Language agents with verbal reinforcement learning" published in NeurIPS, 2023.
Ashwin Gopinath is one of the authors of the paper "Reflexion: Language agents with verbal reinforcement learning" published in Advances in Neural Information Processing Systems in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="KARTHIK NARASIMHAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Karthik Narasimhan is one of the authors of the paper "Reflexion: Language agents with verbal reinforcement learning" published in NeurIPS, 2023.
Karthik Narasimhan is one of the authors of the paper "Reflexion: Language agents with verbal reinforcement learning" published in Advances in Neural Information Processing Systems in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SHUNYU YAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shunyu Yao is one of the authors of the paper "Reflexion: Language agents with verbal reinforcement learning" published in NeurIPS, 2023.
Shunyu Yao is one of the authors of the paper "Reflexion: Language agents with verbal reinforcement learning" published in Advances in Neural Information Processing Systems in 2023.
Shunyu Yao is an author who contributed to the paper "React: Synergizing reasoning and acting in language models."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,2d4672dfb7bd4283f0b5f23ab4f26653,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MOHIT SHRIDHAR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mohit Shridhar is one of the authors of the paper "ALFWorld: Aligning text and embodied environments for interactive learning" published in ICLR, 2020.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="XINGDI YUAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xingdi Yuan is one of the authors of the paper "ALFWorld: Aligning text and embodied environments for interactive learning" published in ICLR, 2020.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MARC-ALEXANDRE C&#212;T&#201;">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Marc-Alexandre C&#244;t&#233; is one of the authors of the paper "ALFWorld: Aligning text and embodied environments for interactive learning" published in ICLR, 2020.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="YONATAN BISK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yonatan Bisk is one of the authors of the paper "ALFWorld: Aligning text and embodied environments for interactive learning" published in ICLR, 2020.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ADAM TRISCHLER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Adam Trischler is one of the authors of the paper "ALFWorld: Aligning text and embodied environments for interactive learning" published in ICLR, 2020.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MATTHEW HAUSKNECHT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Matthew Hausknecht is one of the authors of the paper "ALFWorld: Aligning text and embodied environments for interactive learning" published in ICLR, 2020.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ALFWORLD">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">ALFWorld is a method for aligning text and embodied environments for interactive learning, discussed in a paper published in ICLR, 2020.
Alfworld is an environment used for text-based manipulation tasks, mentioned in the context of LATS.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="DAVID SILVER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">David Silver is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="AJA HUANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Aja Huang is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="CHRIS J. MADDISON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chris J. Maddison is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ARTHUR GUEZ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Arthur Guez is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="L. SIFRE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">L. Sifre is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="GEORGE VAN DEN DRIESSCHE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">George van den Driessche is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="JULIAN SCHRITTWIESER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Julian Schrittwieser is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="IOANNIS ANTONOGLOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ioannis Antonoglou is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="VEDAVYAS PANNEERSHELVAM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Vedavyas Panneershelvam is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MARC LANCTOT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Marc Lanctot is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SANDER DIELEMAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sander Dieleman is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="DOMINIK GREWE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dominik Grewe is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="JOHN NHAM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">John Nham is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="NAL KALCHBRENNER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nal Kalchbrenner is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="TIMOTHY P. LILLICRAP">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Timothy P. Lillicrap is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MADELEINE LEACH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Madeleine Leach is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="KORAY KAVUKCUOGLU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Koray Kavukcuoglu is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="THORE GRAEPEL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Thore Graepel is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="DEMIS HASSABIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Demis Hassabis is one of the authors of the paper "Mastering the game of Go with deep neural networks and tree search" published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MASTERING THE GAME OF GO WITH DEEP NEURAL NETWORKS AND TREE SEARCH">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper discussing the mastery of the game of Go using deep neural networks and tree search, published in Nature, 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="NATURE">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">Nature is a journal where the paper "Mastering the game of Go with deep neural networks and tree search" was published in 2016.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MASTERING CHESS AND SHOGI BY SELF-PLAY WITH A GENERAL REINFORCEMENT LEARNING ALGORITHM">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper discussing the mastery of chess and Shogi by self-play using a general reinforcement learning algorithm, published in arXiv, 2017.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="STEVEN A. SLOMAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Steven A. Sloman is the author of the paper "The empirical case for two systems of reasoning" published in Psychological Bulletin, 1996.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="THE EMPIRICAL CASE FOR TWO SYSTEMS OF REASONING">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper discussing the empirical case for two systems of reasoning, published in Psychological Bulletin, 1996.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="PSYCHOLOGICAL BULLETIN">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">Psychological Bulletin is a journal where the paper "The empirical case for two systems of reasoning" was published in 1996.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="HAOTIAN SUN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Haotian Sun is one of the authors of the paper "AdaPlanner: Adaptive planning from feedback with language models" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="YUCHEN ZHUANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuchen Zhuang is one of the authors of the paper "AdaPlanner: Adaptive planning from feedback with language models" published in NeurIPS, 2023.
Yuchen Zhuang is one of the authors of the paper "ToolChain*: Efficient action space navigation in large language models with A* search" presented at ICLR 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="LINGKAI KONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lingkai Kong is one of the authors of the paper "AdaPlanner: Adaptive planning from feedback with language models" published in NeurIPS, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="CHAO ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chao Zhang is one of the authors of the paper "AdaPlanner: Adaptive planning from feedback with language models" published in NeurIPS, 2023.
Chao Zhang is one of the authors of the paper "ToolChain*: Efficient action space navigation in large language models with A* search" presented at ICLR 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="DIDAC SURIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">D&#237;dac Sur&#237;s is one of the authors of the paper "ViperGPT: Visual inference via Python execution for reasoning" published in ICCV, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="SACHIT MENON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sachit Menon is one of the authors of the paper "ViperGPT: Visual inference via Python execution for reasoning" published in ICCV, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="CARL VONDRICK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Carl Vondrick is one of the authors of the paper "ViperGPT: Visual inference via Python execution for reasoning" published in ICCV, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="VIPERGPT">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">ViperGPT is a method for visual inference via Python execution for reasoning, discussed in a paper published in ICCV, 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="ICCV">
      <data key="d0">CONFERENCE, PUBLICATION</data>
      <data key="d1">ICCV is a conference where the paper "ViperGPT: Visual inference via Python execution for reasoning" was published in 2023.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MACIEJ SWIECHOWSKI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Maciej Swiechowski is one of the authors of the paper "Monte Carlo tree search: A review of recent modifications and applications" published in Artificial Intelligence Review, 2021.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="KONRAD GODLEWSKI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Konrad Godlewski is one of the authors of the paper "Monte Carlo tree search: A review of recent modifications and applications" published in Artificial Intelligence Review, 2021.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="BARTOSZ SAWICKI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bartosz Sawicki is one of the authors of the paper "Monte Carlo tree search: A review of recent modifications and applications" published in Artificial Intelligence Review, 2021.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="JACEK MA&#8217;NDZIUK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jacek Ma&#8217;ndziuk is one of the authors of the paper "Monte Carlo tree search: A review of recent modifications and applications" published in Artificial Intelligence Review, 2021.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="MONTE CARLO TREE SEARCH">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Monte Carlo tree search is a method reviewed in the paper "Monte Carlo tree search: A review of recent modifications and applications" published in Artificial Intelligence Review, 2021.
Monte Carlo Tree Search is an algorithm used in reinforcement learning, mentioned in the document in the context of research by Tom Vodopivec, Spyridon Samothrakis, and Branko Ster.
Monte Carlo Tree Search is a model-free method used in LATS for decision-making tasks, requiring the ability to revert to earlier states in the environment.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ARTIFICIAL INTELLIGENCE REVIEW">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">Artificial Intelligence Review is a journal where the paper "Monte Carlo tree search: A review of recent modifications and applications" was published in 2021.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653</data>
    </node>
    <node id="HUGO TOUVRON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hugo Touvron is one of the authors of the paper "LLaMA: Open and efficient foundation language models" published in arXiv, 2023.
Hugo Touvron is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="LOUIS MARTIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Louis Martin is one of the authors of the paper "LLaMA: Open and efficient foundation language models" published in arXiv, 2023.
Louis Martin is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KEVIN R. STONE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kevin R. Stone is one of the authors of the paper "LLaMA: Open and efficient foundation language models" published in arXiv, 2023.
Kevin R. Stone is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PETER ALBERT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Peter Albert is one of the authors of the paper "LLaMA: Open and efficient foundation language models" published in arXiv, 2023.
Peter Albert is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="AMJAD ALMAHAIRI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Amjad Almahairi is one of the authors of the paper "LLaMA: Open and efficient foundation language models" published in arXiv, 2023.
Amjad Almahairi is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YASMINE BABAEI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yasmine Babaei is one of the authors of the paper "LLaMA: Open and efficient foundation language models" published in arXiv, 2023.
Yasmine Babaei is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="NIKOLAY BASHLYKOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nikolay Bashlykov is one of the authors of the paper "LLaMA: Open and efficient foundation language models" published in arXiv, 2023.
Nikolay Bashlykov is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SOUMYA BATRA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Soumya Batra is one of the authors of the paper "LLaMA: Open and efficient foundation language models" published in arXiv, 2023.
Soumya Batra is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PRAJJWAL BHARGAVA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Prajjwal Bhargava is one of the authors of the paper "LLaMA: Open and efficient foundation language models" published in arXiv, 2023.
Prajjwal Bhargava is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SHRUTI BHOSALE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shruti Bhosale is one of the authors of the paper "LLaMA: Open and efficient foundation language models" published in arXiv, 2023.
Shruti Bhosale is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DANIEL M. BIKEL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Daniel M. Bikel is one of the authors of the paper "LLaMA: Open and efficient foundation language models" published in arXiv, 2023.
Daniel M. Bikel is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="LUKAS BLECHER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lukas Blecher is one of the authors of the paper "LLaMA: Open and efficient foundation language models" published in arXiv, 2023.
Lukas Blecher is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CRISTIAN CANTON FERRER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cristian Canton Ferrer is one of the authors of the paper "LLaMA: Open and efficient foundation language models" published in arXiv, 2023.
Cristian Canton Ferrer is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">2d4672dfb7bd4283f0b5f23ab4f26653,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MOYA CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Moya Chen is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="GUILLEM CUCURULL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Guillem Cucurull is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DAVID ESIOBU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">David Esiobu is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JUDE FERNANDES">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jude Fernandes is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JEREMY FU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jeremy Fu is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="WENYIN FU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wenyin Fu is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="BRIAN FULLER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Brian Fuller is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CYNTHIA GAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cynthia Gao is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="VEDANUJ GOSWAMI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Vedanuj Goswami is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="NAMAN GOYAL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Naman Goyal is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.
Naman Goyal is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ANTHONY S. HARTSHORN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Anthony S. Hartshorn is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SAGHAR HOSSEINI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Saghar Hosseini is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="RUI HOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rui Hou is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="HAKAN INAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hakan Inan is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MARCIN KARDAS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Marcin Kardas is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="VIKTOR KERKEZ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Viktor Kerkez is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MADIAN KHABSA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Madian Khabsa is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ISABEL M. KLOUMANN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Isabel M. Kloumann is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="A. V. KORENEV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A. V. Korenev is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PUNIT SINGH KOURA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Punit Singh Koura is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MARIE-ANNE LACHAUX">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Marie-Anne Lachaux is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="THIBAUT LAVRIL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Thibaut Lavril is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JENYA LEE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jenya Lee is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DIANA LISKOVICH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Diana Liskovich is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YINGHAI LU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yinghai Lu is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YUNING MAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuning Mao is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="XAVIER MARTINET">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xavier Martinet is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="TODOR MIHAYLOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Todor Mihaylov is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PUSHKAR MISHRA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Pushkar Mishra is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="IGOR MOLYBOG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Igor Molybog is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YIXIN NIE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yixin Nie is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ANDREW POULTON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Andrew Poulton is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JEREMY REIZENSTEIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jeremy Reizenstein is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="RASHI RUNGTA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rashi Rungta is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KALYAN SALADI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kalyan Saladi is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ALAN SCHELTEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alan Schelten is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="RUAN SILVA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ruan Silva is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ERIC MICHAEL SMITH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Eric Michael Smith is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="R. SUBRAMANIAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">R. Subramanian is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="XIA TAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xia Tan is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="BINH TANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Binh Tang is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ROSS TAYLOR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ross Taylor is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ADINA WILLIAMS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Adina Williams is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JIAN XIANG KUAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jian Xiang Kuan is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PUXIN XU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Puxin Xu is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ZHENGXU YAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhengxu Yan is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ILIYAN ZAROV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Iliyan Zarov is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YUCHEN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuchen Zhang is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ANGELA FAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Angela Fan is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MELANIE KAMBADUR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Melanie Kambadur is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="AURELIEN RODRIGUEZ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Aurelien Rodriguez is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ROBERT STOJNIC">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Robert Stojnic is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SERGEY EDUNOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sergey Edunov is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="VOYAGER">
      <data key="d0">TECHNOLOGY, AGENT</data>
      <data key="d1">Voyager is an open-ended embodied agent with large language models, mentioned in the document in the context of research by Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CHAIN OF THOUGHT PROMPTING">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Chain of Thought Prompting is a technique that elicits reasoning in large language models, mentioned in the document in the context of research by Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny Zhou.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="INTELLIGENT AGENTS">
      <data key="d0">TECHNOLOGY, CONCEPT</data>
      <data key="d1">Intelligent Agents are systems that perceive their environment and take actions to achieve specific goals, mentioned in the document in the context of research by Michael Wooldridge and Nicholas R. Jennings.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DAYDREAMER">
      <data key="d0">TECHNOLOGY, AGENT</data>
      <data key="d1">Daydreamer is a world model for physical robot learning, mentioned in the document in the context of research by Philipp Wu, Alejandro Escontrela, Danijar Hafner, Pieter Abbeel, and Ken Goldberg.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="DECOMPOSITION">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Decomposition is a technique that enhances reasoning via self-evaluation guided decoding, mentioned in the document in the context of research by Yuxi Xie, Kenji Kawaguchi,</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="TOM VODOPIVEC">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tom Vodopivec is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SPYRIDON SAMOTHRAKIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Spyridon Samothrakis is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="BRANKO STER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Branko Ster is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YUQI XIE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuqi Xie is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.
Yuqi Xie is one of the authors of the paper "Voyager: An open-ended embodied agent with large language models" published as an arXiv preprint in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CHAOWEI XIAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chaowei Xiao is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.
Chaowei Xiao is one of the authors of the paper "Voyager: An open-ended embodied agent with large language models" published as an arXiv preprint in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ED CHI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ed Chi is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.
Ed Chi is one of the authors of the paper "Least-to-most prompting enables complex reasoning in large language models" presented at ICLR 2022.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="MICHAEL WOOLDRIDGE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Michael Wooldridge is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="NICHOLAS R. JENNINGS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nicholas R. Jennings is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PHILIPP WU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Philipp Wu is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ALEJANDRO ESCONTRELA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alejandro Escontrela is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KEN GOLDBERG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ken Goldberg is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YUXI XIE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuxi Xie is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="KENJI KAWAGUCHI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kenji Kawaguchi is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YIRAN ZHAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yiran Zhao is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="XU ZHAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xu Zhao is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="MIN-YEN KAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Min-Yen Kan is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="JUNXIAN HE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Junxian He is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="QIZHE XIE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qizhe Xie is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ZHILIN YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhilin Yang is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="PENG QI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Peng Qi is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SAIZHENG ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Saizheng Zhang is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YOSHUA BENGIO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yoshua Bengio is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.
Yoshua Bengio is one of the authors of the paper on managing extreme AI risks, published in 2024.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="CHRISTOPHER D. MANNING">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Christopher D. Manning is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="TREE OF THOUGHTS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Tree of Thoughts is a technique for deliberate problem solving with large language models, mentioned in the document in the context of research by Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="WEIRUI YE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Weirui Ye is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="SHAOHUAI LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shaohuai Liu is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="THANARD KURUTACH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Thanard Kurutach is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="YANG GAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yang Gao is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="NATHANAEL SCHARLI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nathanael Sch&#228;rli is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="LE HOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Le Hou is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.
Le Hou is one of the authors of the paper titled "Instruction-following evaluation for large language models," published in 2023.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NATHAN SCALES">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nathan Scales is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.
Nathan Scales is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022.</data>
      <data key="d2">8180bf20b7577f3eee40df5991e2886d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="OLIVIER BOUSQUET">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Olivier Bousquet is one of the authors mentioned in the document, contributing to research in the field of artificial intelligence and language models.
Olivier Bousquet is one of the authors of the paper "Least-to-most prompting enables complex reasoning in large language models" presented at ICLR 2022.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="TOOLCHAIN*">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">ToolChain* is a method for efficient action space navigation in large language models with A* search, mentioned in the document in the context of research by Yuchen Zhuang, Xiang Chen, Tong Yu, Saayan Mitra, Victor Bursztyn, Ryan A. Rossi, Somdeb Sarkhel, and Chao Zhang.
ToolChain* is a method for efficient action space navigation in large language models using A* search, as discussed in the paper by Yuchen Zhuang, Xiang Chen, Tong Yu, Saayan Mitra, Victor Bursztyn, Ryan A. Rossi, Somdeb Sarkhel, and Chao Zhang.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,8180bf20b7577f3eee40df5991e2886d</data>
    </node>
    <node id="ICLR 2022">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">ICLR 2022 is the conference where the paper "Least-to-most prompting enables complex reasoning in large language models" was presented.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="XIANG CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiang Chen is one of the authors of the paper "ToolChain*: Efficient action space navigation in large language models with A* search" presented at ICLR 2023.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="TONG YU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tong Yu is one of the authors of the paper "ToolChain*: Efficient action space navigation in large language models with A* search" presented at ICLR 2023.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SAAYAN MITRA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Saayan Mitra is one of the authors of the paper "ToolChain*: Efficient action space navigation in large language models with A* search" presented at ICLR 2023.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="VICTOR BURSZTYN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Victor Bursztyn is one of the authors of the paper "ToolChain*: Efficient action space navigation in large language models with A* search" presented at ICLR 2023.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="RYAN A. ROSSI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ryan A. Rossi is one of the authors of the paper "ToolChain*: Efficient action space navigation in large language models with A* search" presented at ICLR 2023.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SOMDEB SARKHEL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Somdeb Sarkhel is one of the authors of the paper "ToolChain*: Efficient action space navigation in large language models with A* search" presented at ICLR 2023.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="ICLR 2023">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">ICLR 2023 is the conference where the paper "ToolChain*: Efficient action space navigation in large language models with A* search" was presented.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="WEBSHOP">
      <data key="d0">TASK, DOMAIN</data>
      <data key="d1">WebShop is one of the environments used to evaluate LATS, focusing on web search tasks.
An online platform where users can search for and purchase products, such as deodorants.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="TOOLBENCH">
      <data key="d0">ENVIRONMENT, APPLICATION</data>
      <data key="d1">ToolBench is an environment involving LM-based tools, mentioned in the context of LATS.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="QIN ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qin et al. are the authors mentioned in relation to ToolBench, an environment involving LM-based tools.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YA0 ET AL., 2023A">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yao et al. are the authors mentioned in relation to the ToT algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SEARCH APPROACHES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="PSEUDOCODE">
      <data key="d0">DOCUMENTATION, CODE</data>
      <data key="d1">Pseudocode is a detailed, readable description of what a computer program or algorithm must do, expressed in a formally-styled natural language rather than in a programming language.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SELF-CONSISTENCY WEIGHT">
      <data key="d0">PARAMETER, ATTRIBUTE</data>
      <data key="d1">Self-consistency weight is a parameter in the LATS algorithm that affects the consistency of the search results. Different values are used for different tasks like HotPotQA and Programming.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="ENVIRONMENT REVERSION">
      <data key="d0">FEATURE, ATTRIBUTE</data>
      <data key="d1">Environment reversion is a feature required by the LATS algorithm for decision-making tasks, allowing the agent to revert to earlier states in the environment.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="API-BASED TOOLS">
      <data key="d0">TECHNOLOGY, TOOL</data>
      <data key="d1">API-based tools are used in LM-based environments and are mentioned as being inexpensive and fast to use in the context of LATS.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="TEXT-BASED MANIPULATION TASKS">
      <data key="d0">TASK, DOMAIN</data>
      <data key="d1">Text-based manipulation tasks are a type of task evaluated using environments like Alfworld, mentioned in the context of LATS.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="ROLLBACKS">
      <data key="d0">FEATURE, ATTRIBUTE</data>
      <data key="d1">Rollbacks are a feature that allows reverting to previous states in an environment, mentioned as a limitation for some environments in the context of LATS.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="RESOURCE CONSTRAINTS">
      <data key="d0">LIMITATION, ATTRIBUTE</data>
      <data key="d1">Resource constraints are limitations that can affect the design and implementation of the LATS algorithm in various environments.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="PLANNING-BASED PROMPTING METHODS">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">Planning-based prompting methods are techniques like LATS that are used for reasoning and decision-making in language models.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="ADDITIONAL ABLATIONS">
      <data key="d0">EXPERIMENT, ANALYSIS</data>
      <data key="d1">Additional ablations are experiments conducted to analyze various designs of the LATS algorithm, including different parameters and settings.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SAMPLING SIZE">
      <data key="d0">PARAMETER, ATTRIBUTE</data>
      <data key="d1">Sampling size is a parameter in the LATS algorithm that affects the number of samples taken during the search process.
Sampling size is a parameter in the LATS algorithm that determines the number of samples or trajectories to be considered during the search process.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="TAB. 8">
      <data key="d0">DOCUMENTATION, TABLE</data>
      <data key="d1">Tab. 8 is a table in the appendix that shows the results of experiments conducted on HotPotQA using the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="FIG. 3">
      <data key="d0">DOCUMENTATION, FIGURE</data>
      <data key="d1">Fig. 3 is a figure in the appendix that shows the results of experiments conducted on HumanEval using the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="TAB. 9">
      <data key="d0">DOCUMENTATION, TABLE</data>
      <data key="d1">Tab. 9 is a table in the appendix that provides a full analysis of the computational cost of the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SEC. A">
      <data key="d0">DOCUMENTATION, SECTION</data>
      <data key="d1">Sec. A is a section in the appendix that shows the pseudocode of the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SEC. B">
      <data key="d0">DOCUMENTATION, SECTION</data>
      <data key="d1">Sec. B is a section in the appendix that provides further discussion of the limitations of the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SEC. C">
      <data key="d0">DOCUMENTATION, SECTION</data>
      <data key="d1">Sec. C is a section in the appendix that presents additional experimental results of the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SEC. D">
      <data key="d0">DOCUMENTATION, SECTION</data>
      <data key="d1">Sec. D is a section in the appendix that specifies the environment details in the experiments conducted using the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SEC. E">
      <data key="d0">DOCUMENTATION, SECTION</data>
      <data key="d1">Sec. E is a section in the appendix that lists the prompts used for the HotPotQA environment in the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SEC. F">
      <data key="d0">DOCUMENTATION, SECTION</data>
      <data key="d1">Sec. F is a section in the appendix that lists the prompts used for the Programming environment in the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="SEC. G">
      <data key="d0">DOCUMENTATION, SECTION</data>
      <data key="d1">Sec. G is a section in the appendix that lists the prompts used for the WebShop environment in the LATS algorithm.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7</data>
    </node>
    <node id="YA0 ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yao et al. are the authors mentioned in relation to the WebShop environment.
Yao et al. are the authors of the WebShop environment, published in 2022.</data>
      <data key="d2">42de130f5b6144472a86a4c8260a87c7,fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="DEPTH">
      <data key="d0">PARAMETER</data>
      <data key="d1">Depth is a parameter in the LATS algorithm that determines the maximum number of steps or layers in the search process. It affects the performance and success rate of the algorithm in tasks like HotPotQA.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="LM VALUE FUNCTION">
      <data key="d0">COMPONENT, FUNCTION</data>
      <data key="d1">The LM value function scores states based on expected future rewards. It is a heuristic used in the LATS algorithm to guide the search process more effectively.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="WIKIPEDIA WEB API">
      <data key="d0">TECHNOLOGY, TOOL</data>
      <data key="d1">The Wikipedia web API is used in the LATS algorithm for interactive information retrieval. It supports actions like searching for entities and looking up strings to retrieve relevant information from Wikipedia.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="STATE SPACE">
      <data key="d0">CONCEPT</data>
      <data key="d1">State space refers to the set of all possible states or configurations that the algorithm can explore during the search process.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="VALUE FUNCTION WEIGHT">
      <data key="d0">PARAMETER</data>
      <data key="d1">Value function weight is a parameter in the LATS algorithm that balances the contributions of different components in the value function, such as the LM score and self-consistency score.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="ACTION GENERATOR">
      <data key="d0">COMPONENT, FUNCTION</data>
      <data key="d1">Action generator is a component in the LATS algorithm that generates possible actions based on the current state.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="VISIT COUNTER">
      <data key="d0">COMPONENT, FUNCTION</data>
      <data key="d1">Visit counter is a component in the LATS algorithm that keeps track of the number of times each state has been visited during the search process.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="CONTEXT">
      <data key="d0">CONCEPT</data>
      <data key="d1">Context refers to the additional information or conditions that influence the search process in the LATS algorithm.
Background information provided to help the agent answer a question</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ENVIRONMENT REWARDS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Environment rewards are the feedback or scores received from the environment based on the actions taken and states reached during the search process.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="CROWDWORKERS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Crowdworkers are individuals who contributed to the creation of the HotPotQA dataset by crafting diverse, multi-hop, and explainable question-answer pairs.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="SUPPORTING FACTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Supporting facts are pieces of information provided in the HotPotQA dataset that justify the answers to the questions, helping in the reasoning process.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="WIKIPEDIA PARAGRAPHS">
      <data key="d0">DATA SOURCE</data>
      <data key="d1">Wikipedia paragraphs are the text segments used in the HotPotQA dataset to provide the necessary information for answering the questions.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="SEARCH [ENTITY]">
      <data key="d0">ACTION</data>
      <data key="d1">Search [entity] is an action in the LATS algorithm that retrieves the first 5 sentences from the corresponding entity's Wikipedia page or suggests top-5 similar entities if the page does not exist.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="LOOKUP [STRING]">
      <data key="d0">ACTION</data>
      <data key="d1">Lookup [string] is an action in the LATS algorithm that returns the next sentence in the context of the search process.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="EM (EXACT MATCH)">
      <data key="d0">METRIC</data>
      <data key="d1">EM (Exact Match) is a performance metric used to evaluate the accuracy of answers in the HotPotQA dataset, indicating the percentage of answers that exactly match the ground truth.</data>
      <data key="d2">48e423e2baf2ed485872756f5b4d87d8</data>
    </node>
    <node id="INTERACTIVE INFORMATION RETRIEVAL">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A method involving search, lookup, and finish actions to retrieve and interact with information from Wikipedia or other sources.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="LOOKUP">
      <data key="d0">ACTION, COMMAND</data>
      <data key="d1">An action that returns the next sentence in the page containing the specified string.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="FINISH">
      <data key="d0">ACTION, COMMAND</data>
      <data key="d1">An action that finishes the current task with the provided answer.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="MOSTLY BASIC PROGRAMMING PROBLEMS (MBPP)">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">MBPP is a benchmark containing 974 short Python functions designed to evaluate program synthesis techniques, with an additional set of 426 manually verified problems.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="TASK SCORE">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">A metric used in WebShop to capture the average reward obtained across episodes, defined as (100&#215;avg. reward).</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="NATURAL LANGUAGE DESCRIPTIONS">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Natural language descriptions are used to describe programming tasks in datasets like HumanEval and MBPP.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="FUNCTION SIGNATURE">
      <data key="d0">DATA, COMPONENT</data>
      <data key="d1">A function signature is part of a programming problem, specifying the function's name, parameters, and return type.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="DOCSTRING DESCRIPTION">
      <data key="d0">DATA, COMPONENT</data>
      <data key="d1">A docstring description provides a detailed explanation of a function's purpose and behavior in programming problems.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="REFERENCE IMPLEMENTATION">
      <data key="d0">DATA, COMPONENT</data>
      <data key="d1">A reference implementation is a sample solution provided for programming problems to demonstrate the expected functionality.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="UNIT TESTS">
      <data key="d0">DATA, COMPONENT</data>
      <data key="d1">Unit tests are used to verify the correctness of a function's implementation by running predefined test cases.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="PASS@K METRIC">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">Pass@k is a metric used to evaluate the success rate of generated solutions in programming tasks, where a problem is considered solved if any of the k samples pass all tests.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="VALUE FUNCTION HYPERPARAMETERS">
      <data key="d0">PARAMETER, CONFIGURATION</data>
      <data key="d1">Value function hyperparameters are settings used to configure the evaluation function in algorithms like LATS, including parameters like &#955; for the LM score and self-consistency score.
Settings used to configure the value function in experiments, such as &#955; for the LM score and self-consistency score</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9,fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="INTERNAL TESTS">
      <data key="d0">DATA, EVALUATION</data>
      <data key="d1">Internal tests are used to evaluate the performance of language models like GPT-3.5 and GPT-4 on programming tasks.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="CROWDSOURCING">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">Crowdsourcing is a method used to gather data, such as the natural language descriptions and solutions in the MBPP dataset, from a large group of people with basic Python knowledge.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="PYTHON STANDARD LIBRARY">
      <data key="d0">TECHNOLOGY, TOOL</data>
      <data key="d1">The Python standard library is a collection of modules and functions included with Python, used in programming tasks for operations like list processing and string manipulation.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="HTML MODE">
      <data key="d0">MODE, CONFIGURATION</data>
      <data key="d1">HTML mode is a rendering mode in WebShop that provides pixel-level observations with interactive elements for training agents.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="SIMPLE MODE">
      <data key="d0">MODE, CONFIGURATION</data>
      <data key="d1">Simple mode is a rendering mode in WebShop that converts raw HTML into structured text observations for easier training of agents.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="QUERY SEARCHES">
      <data key="d0">ACTION, COMMAND</data>
      <data key="d1">Query searches are actions in WebShop that allow agents to search for products based on specified attributes and options.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="BUTTON CLICKS">
      <data key="d0">ACTION, COMMAND</data>
      <data key="d1">Button clicks are actions in WebShop that allow agents to navigate between different page types like search, results, item, and item detail.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="LEXICAL MATCHING">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">Lexical matching is a method used in WebShop to compare the product purchased by the agent against the specified attributes and options based on exact word matches.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="SEMANTIC SIMILARITY METRICS">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">Semantic similarity metrics are methods used in WebShop to compare the product purchased by the agent against the specified attributes and options based on meaning and context.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="SEARCH PAGE">
      <data key="d0">PAGE TYPE, COMPONENT</data>
      <data key="d1">The search page in WebShop is where agents can perform query searches to find products.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="RESULTS PAGE">
      <data key="d0">PAGE TYPE, COMPONENT</data>
      <data key="d1">The results page in WebShop displays the search results based on the agent's query.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="ITEM PAGE">
      <data key="d0">PAGE TYPE, COMPONENT</data>
      <data key="d1">The item page in WebShop provides detailed information about a specific product selected from the search results.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="ITEM DETAIL PAGE">
      <data key="d0">PAGE TYPE, COMPONENT</data>
      <data key="d1">The item detail page in WebShop provides additional details and options for a specific product.</data>
      <data key="d2">fb2b4544aedd793e4d4ec3147320a51c</data>
    </node>
    <node id="RESULTS">
      <data key="d0">OUTPUT, SEARCH RESULT</data>
      <data key="d1">The list of products returned by the web shop in response to a query</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="PRODUCT TITLE">
      <data key="d0">PRODUCT ATTRIBUTE, IDENTIFIER</data>
      <data key="d1">The name or title of a product listed in the search results</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="OPTION">
      <data key="d0">PRODUCT ATTRIBUTE, CHOICE</data>
      <data key="d1">A selectable feature or variant of a product, such as size or color</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="DESC/OVERVIEW">
      <data key="d0">PRODUCT ATTRIBUTE, DESCRIPTION</data>
      <data key="d1">A detailed description or overview of a product's features and specifications</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ITEM">
      <data key="d0">PRODUCT</data>
      <data key="d1">A specific product listed in the search results</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ITEM-DETAIL">
      <data key="d0">PRODUCT ATTRIBUTE, DETAIL</data>
      <data key="d1">Detailed information about a specific product, including its description, options, and price</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="EPISODE END">
      <data key="d0">EVENT, TERMINATION</data>
      <data key="d1">The conclusion of a user's interaction session with the web shop</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ENVIRONMENTS">
      <data key="d0">SETTING, CONTEXT</data>
      <data key="d1">The different scenarios or contexts in which experiments are conducted</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="DEPTH LIMIT">
      <data key="d0">CONSTRAINT, PARAMETER</data>
      <data key="d1">The maximum number of steps or actions allowed in an experiment or task</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="THOUGHT">
      <data key="d0">STEP, REASONING</data>
      <data key="d1">A reasoning step in the process of solving a question answering task
Reasoning about the current situation in a question-answering task, used to determine the next action.
A section in the output where the meta agent captures its thought process for designing the next function, including reasoning, overall concept, and implementation steps.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="FINISH[ANSWER]">
      <data key="d0">STEP, OPERATION</data>
      <data key="d1">An action that returns the final answer and concludes the task
An action that returns the answer and finishes the task in a question-answering scenario.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">STEP, OPERATION</data>
    </node>
    <node id="SEARCH[ENTITY]">
      <data key="d0">STEP, OPERATION</data>
      <data key="d1">An action that searches for a specific entity on Wikipedia and returns relevant information
An action that searches for the exact entity on Wikipedia and returns the first paragraph if it exists, or similar entities if it does not.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">STEP, OPERATION</data>
    </node>
    <node id="LOOKUP[KEYWORD]">
      <data key="d0">STEP, OPERATION</data>
      <data key="d1">An action that returns the next sentence containing a specified keyword in the current passage
An action that returns the next sentence containing the specified keyword in the current passage.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">STEP, OPERATION</data>
    </node>
    <node id="ARTHUR'S MAGAZINE">
      <data key="d0">PUBLICATION, ENTITY</data>
      <data key="d1">An American literary periodical published in the 19th century, edited by Timothy Shay Arthur
An American literary periodical published in Philadelphia in the 19th century, edited by Timothy Shay Arthur, and featuring work by notable authors.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="FIRST FOR WOMEN">
      <data key="d0">PUBLICATION, ENTITY</data>
      <data key="d1">A woman's magazine published by Bauer Media Group in the USA, started in 1989
A magazine that is part of a question-answering task to determine which magazine was started first.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="COLORADO OROGENY">
      <data key="d0">GEOLOGICAL EVENT, ENTITY</data>
      <data key="d1">A geological event that extends into the High Plains, with an elevation range from 1,800 to 7,000 ft</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="HIGH PLAINS">
      <data key="d0">GEOGRAPHICAL REGION, ENTITY</data>
      <data key="d1">A region that rises in elevation from around 1,800 to 7,000 ft</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="VALUE FUNCTION PROMPT">
      <data key="d0">INSTRUCTION, INPUT</data>
      <data key="d1">A prompt that instructs the analysis of solution trajectories in a question answering task
A prompt that instructs the analysis of trajectories in a question-answering task, focusing on thoughts, actions, and observations to evaluate correctness and provide a score from 1 to 10.
A prompt that asks for analysis of a purchase trajectory to determine a correctness score</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,6f486e20e3102c7a285e357d356417ad,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="TIMOTHY SHAY ARTHUR">
      <data key="d0">AUTHOR, EDITOR</data>
      <data key="d1">The editor of Arthur's Magazine, an American literary periodical published in the 19th century
Timothy Shay Arthur was the editor of Arthur's Magazine, an American literary periodical published in the 19th century.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="BAUER MEDIA GROUP">
      <data key="d0">ORGANIZATION, PUBLISHER</data>
      <data key="d1">The publisher of First for Women, a woman's magazine in the USA</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="GODEY'S LADY'S BOOK">
      <data key="d0">PUBLICATION, ENTITY</data>
      <data key="d1">A publication into which Arthur's Magazine was merged in May 1846
Godey's Lady's Book was a magazine into which Arthur's Magazine was merged in May 1846.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="EDGAR A. POE">
      <data key="d0">AUTHOR, WRITER</data>
      <data key="d1">A contributor to Arthur's Magazine, known for his literary works
Edgar A. Poe was one of the contributors to Arthur's Magazine.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="J.H. INGRAHAM">
      <data key="d0">AUTHOR, WRITER</data>
      <data key="d1">A contributor to Arthur's Magazine, known for his literary works
J.H. Ingraham was one of the contributors to Arthur's Magazine.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="SARAH JOSEPHA HALE">
      <data key="d0">AUTHOR, WRITER</data>
      <data key="d1">A contributor to Arthur's Magazine, known for her literary works
Sarah Josepha Hale was one of the contributors to Arthur's Magazine.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="THOMAS G. SPEAR">
      <data key="d0">AUTHOR, WRITER</data>
      <data key="d1">A contributor to Arthur's Magazine, known for his literary works
Thomas G. Spear was one of the contributors to Arthur's Magazine.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="PREV/NEXT PAGE">
      <data key="d0">ACTION, OPERATION</data>
      <data key="d1">An action to navigate through the pages of search results</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="CHOOSE">
      <data key="d0">ACTION, OPERATION</data>
      <data key="d1">An action to select a specific product, option, or detail from the search results</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="BACK TO SEARCH">
      <data key="d0">ACTION, OPERATION</data>
      <data key="d1">An action to return to the search page from the results or item detail page
The action of returning to the search page or search results.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ATTRIBUTE">
      <data key="d0">PRODUCT ATTRIBUTE, FEATURE</data>
      <data key="d1">A characteristic or feature of a product that can influence the reward calculation</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="INSTRUCTIONS">
      <data key="d0">INPUT, GUIDELINE</data>
      <data key="d1">Guidelines provided to the user or agent to perform specific tasks in the web shop</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="NUMBER OF ATTRIBUTES SATISFIED">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">A measure used to calculate the reward based on how many product attributes match the user's criteria</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="MAXIMUM DEPTH LIMIT">
      <data key="d0">CONSTRAINT, PARAMETER</data>
      <data key="d1">The maximum number of steps allowed in a task or experiment</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="HYPERPARAMETERS">
      <data key="d0">PARAMETER, CONFIGURATION</data>
      <data key="d1">Settings used to configure algorithms like the value function, including parameters like &#955;</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ARITHMETIC OPERATIONS">
      <data key="d0">OPERATION, METHOD</data>
      <data key="d1">Basic mathematical operations used in the Game of 24 to construct the number 24 from four given numbers</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="EQUATION">
      <data key="d0">RESULT, OUTPUT</data>
      <data key="d1">A mathematical statement that represents the solution in the Game of 24</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="BASE ACTING PROMPT">
      <data key="d0">INSTRUCTION, INPUT</data>
      <data key="d1">A prompt that guides the agent in performing actions and reasoning steps in a question answering task</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="BASE REASONING PROMPT">
      <data key="d0">INSTRUCTION, INPUT</data>
      <data key="d1">A prompt that guides the agent in reasoning through a question answering task step by step</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="THOUGHT 1">
      <data key="d0">STEP, REASONING</data>
      <data key="d1">The first reasoning step in a question answering task, often involving initial analysis or search</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="THOUGHT 2">
      <data key="d0">STEP, REASONING</data>
      <data key="d1">The second reasoning step in a question answering task, often involving further analysis or search</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="THOUGHT 3">
      <data key="d0">STEP, REASONING</data>
      <data key="d1">The third reasoning step in a question answering task, often leading to the final answer</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="EXAMPLES">
      <data key="d0">INPUT, GUIDELINE</data>
      <data key="d1">Sample questions and answers provided to guide the agent in performing tasks</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">INPUT, GUIDELINE</data>
    </node>
    <node id="PREVIOUS TRIAL">
      <data key="d0">EVENT, SESSION</data>
      <data key="d1">A past attempt at solving a question answering task, used for reflection and improvement</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">EVENT, SESSION</data>
    </node>
    <node id="STRATEGY">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">A plan or method used to improve performance in a task based on reflections from previous trials</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">METHOD, TECHNIQUE</data>
    </node>
    <node id="ELEVATION RANGE">
      <data key="d0">ATTRIBUTE, FEATURE</data>
      <data key="d1">The range of elevation for a geographical region, such as the High Plains</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">ATTRIBUTE, FEATURE</data>
    </node>
    <node id="AREA">
      <data key="d0">ATTRIBUTE, FEATURE</data>
      <data key="d1">A specific geographical region or sector, such as the eastern sector of the Colorado orogeny</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">ATTRIBUTE, FEATURE</data>
    </node>
    <node id="SOLUTION">
      <data key="d0">RESULT, OUTPUT</data>
      <data key="d1">The final answer or outcome of a question answering task
A solution is the final answer or outcome of a question-answering task, evaluated for correctness.
A solution is a method or approach that effectively addresses a problem or task, often developed through automated design in ADAS.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,81c504ffbcc5ed882e234802135295ba,b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">RESULT, OUTPUT</data>
    </node>
    <node id="ANALYSIS">
      <data key="d0">STEP, REASONING</data>
      <data key="d1">The process of examining trajectories or solutions to understand and improve performance</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">STEP, REASONING</data>
    </node>
    <node id="SITUATION">
      <data key="d0">CONTEXT, SETTING</data>
      <data key="d1">The current state or scenario in which a task is being performed</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">CONTEXT, SETTING</data>
    </node>
    <node id="ENVIRONMENTAL OBSERVATIONS">
      <data key="d0">INPUT, FEEDBACK</data>
      <data key="d1">Information about the environment or context that informs the agent's reasoning and actions</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">INPUT, FEEDBACK</data>
    </node>
    <node id="THOUGHT, ACTION, OBSERVATION STEPS">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">A structured approach to solving tasks by interleaving reasoning, actions, and feedback</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">METHOD, TECHNIQUE</data>
    </node>
    <node id="ARTHUR'S MAGAZINE START DATE">
      <data key="d0">ATTRIBUTE, FEATURE</data>
      <data key="d1">The year Arthur's Magazine was started, which is 1844</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">ATTRIBUTE, FEATURE</data>
    </node>
    <node id="FIRST FOR WOMEN START DATE">
      <data key="d0">ATTRIBUTE, FEATURE</data>
      <data key="d1">The year First for Women was started, which is 1989</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">ATTRIBUTE, FEATURE</data>
    </node>
    <node id="MAGAZINE">
      <data key="d0">PUBLICATION, ENTITY</data>
      <data key="d1">A type of publication, such as Arthur's Magazine or First for Women</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
      <data key="d3">PUBLICATION, ENTITY</data>
    </node>
    <node id="PUBLISHER">
      <data key="d0">ORGANIZATION, ENTITY</data>
      <data key="d1">An organization that publishes magazines or other publications, such as Bauer Media Group</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="LITERARY PERIODICAL">
      <data key="d0">PUBLICATION, ENTITY</data>
      <data key="d1">A type of magazine focused on literary content, such as Arthur's Magazine</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="AMERICAN LITERARY PERIODICAL">
      <data key="d0">PUBLICATION, ENTITY</data>
      <data key="d1">A literary periodical published in the United States, such as Arthur's Magazine</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="PHILADELPHIA">
      <data key="d0">LOCATION, CITY</data>
      <data key="d1">The city where Arthur's Magazine was published</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="19TH CENTURY">
      <data key="d0">TIME PERIOD, ERA</data>
      <data key="d1">The century during which Arthur's Magazine was published</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="MERGER">
      <data key="d0">EVENT, ACTION</data>
      <data key="d1">The combining of two publications, such as the merger of Arthur's Magazine into Godey's Lady's Book</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="CONTRIBUTOR">
      <data key="d0">ROLE, PERSON</data>
      <data key="d1">An individual who contributes content to a publication, such as Edgar A. Poe or Sarah Josepha Hale</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="WOMAN'S MAGAZINE">
      <data key="d0">PUBLICATION, ENTITY</data>
      <data key="d1">A type of magazine targeted at women, such as First for Women</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="BASED IN ENGLEWOOD CLIFFS, NEW JERSEY">
      <data key="d0">LOCATION, ATTRIBUTE</data>
      <data key="d1">The location where First for Women is based</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="CIRCULATION">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">The number of copies of a magazine distributed, such as the 1,310,696 copies of First for Women in 2011</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="2011">
      <data key="d0">TIME PERIOD, YEAR</data>
      <data key="d1">The year in which the circulation of First for Women was 1,310,696 copies</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="HIGH PLAINS ELEVATION">
      <data key="d0">ATTRIBUTE, FEATURE</data>
      <data key="d1">The elevation range of the High Plains, from 1,800 to 7,000 ft</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="EASTERN SECTOR">
      <data key="d0">AREA, REGION</data>
      <data key="d1">A specific part of a larger geographical region, such as the eastern sector of the Colorado orogeny</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="COLORADO OROGENY EXTENSION">
      <data key="d0">ATTRIBUTE, FEATURE</data>
      <data key="d1">The area into which the Colorado orogeny extends, such as the High Plains</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="HIGH PLAINS RISE">
      <data key="d0">ATTRIBUTE, FEATURE</data>
      <data key="d1">The increase in elevation of the High Plains, from around 1,800 to 7,000 ft</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ANSWER">
      <data key="d0">RESULT, OUTPUT</data>
      <data key="d1">The final response to a question in a question answering task
An answer is the result or solution provided by an agent after performing a task.
The final output or answer produced by the system after evaluating the final code.
The final answer to the original problem, obtained by integrating the sub-problem solutions.</data>
      <data key="d2">84317ae35cc75d612287186d93461447,b8dd0300033963bb4a3e1bad37f8e7b9,c3d0436082aada237ee4bee645f16059,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="FINISH[1,800 TO 7,000 FT]">
      <data key="d0">STEP, OPERATION</data>
      <data key="d1">An action that returns the answer "1,800 to 7,000 ft" and concludes the task</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="THOUGHT, THEN FINISH">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">A structured approach to solving tasks by reasoning first and then providing the final answer</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="TRAJECTORY ANALYSIS">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">The process of examining the sequence of steps taken to solve a task</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="LABELED TRAJECTORIES">
      <data key="d0">SEQUENCE, PATH</data>
      <data key="d1">Sequences of steps that are labeled with observations, thoughts, and actions</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="SOLUTION TRAJECTORIES">
      <data key="d0">SEQUENCE, PATH</data>
      <data key="d1">The paths taken to arrive at a solution in a question answering task</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="LANGUAGE AGENT TREE SEARCH">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">A method that unifies reasoning, acting, and planning in language models</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="UNIFIES REASONING, ACTING, AND PLANNING">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">A technique that combines reasoning, acting, and planning in a cohesive approach</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="STATE OF THE ART">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">The highest level of performance achieved in a specific task or benchmark</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="VALIDATION">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">The process of confirming the effectiveness or accuracy of a method or algorithm
Validation is a limitation related to the difficulty of ensuring that synthetic data accurately represents the desired scenarios.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="ADVANCED LANGUAGE MODELS">
      <data key="d0">TECHNOLOGY, MODEL</data>
      <data key="d1">Highly developed models used for complex natural language processing tasks</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="HIGHER PERFORMANCE">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">A level of performance that exceeds previous benchmarks or standards</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="BASELINES">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">Standard measures or references used for comparison in experiments
Baselines are the initial set of agents in the Discovered Agent Archive, which are updated at every iteration in the Meta Agent Search, as described in the supplementary material of the paper "Automated Design of Agentic Systems."
Standard agents used for comparison in evaluations, often using models like GPT-3.5-turbo-0125.Baseline agents used for comparison in evaluations.

A group of models used for comparison in the evaluation process, including Orca-2.5, Mistral-Instruct-7B, and ChatGPT.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,84317ae35cc75d612287186d93461447,b8dd0300033963bb4a3e1bad37f8e7b9,bd4eb9459bc29b4c2da4658914fd4635,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="QUESTIONS">
      <data key="d0">INPUT, QUERY</data>
      <data key="d1">Items or prompts used to evaluate the performance of algorithms in benchmarks like HumanEval
Questions are used in reading comprehension tests and open domain question answering to assess understanding and generate responses.</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="MINIMAL PERFORMANCE DIFFERENCES">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">Small or negligible variations in performance between different settings or conditions</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="REPORT BASELINES">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">The process of documenting standard measures or references used for comparison</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="SETTINGS">
      <data key="d0">CONTEXT, CONFIGURATION</data>
      <data key="d1">Different conditions or configurations used in experiments</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="METHOD SCORE">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">A measure of the effectiveness of a specific method or algorithm</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="SR">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">Success Rate, a measure of the portion of instructions where the reward equals 1</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="BEST OF K">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">A variant of the ReAct algorithm that selects the best result out of k iterations</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="IL">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">An abbreviation for an algorithm or method mentioned in the context of the document</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="CO-T">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">An abbreviation for a technique or method mentioned in the context of the document</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="&#923;">
      <data key="d0">PARAMETER, CONFIGURATION</data>
      <data key="d1">A hyperparameter used in the value function and self-consistency score</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="0.8">
      <data key="d0">VALUE, PARAMETER</data>
      <data key="d1">A specific value for the hyperparameter &#955; used in the experiments</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="0.5">
      <data key="d0">VALUE, PARAMETER</data>
      <data key="d1">A specific value for the hyperparameter &#955; used in the Game of 24 experiments</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="1">
      <data key="d0">VALUE, PARAMETER</data>
      <data key="d1">A specific value for the hyperparameter &#955; used in the Game of 24 experiments</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="0.40">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">A success rate achieved by LATS (CoT, &#955;= 1) in the Game of 24</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="0.44">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">A success rate achieved by LATS (CoT) in the Game of 24</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="50 GAMES">
      <data key="d0">METRIC, PERFORMANCE MEASURE</data>
      <data key="d1">The number of games used to report the success rate in the Game of 24</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="K= 30 ITERATIONS">
      <data key="d0">PARAMETER, CONFIGURATION</data>
      <data key="d1">The number of iterations used in the Game of 24 experiments</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="VALIDATES">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">The process of confirming the effectiveness or accuracy of a method or algorithm</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="DESIGN">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">The structure or setup of a method or experiment, such as the design of the self-consistency term</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="SELF-CONSISTENCY TERM">
      <data key="d0">PARAMETER, CONFIGURATION</data>
      <data key="d1">A component of the value function that ensures consistent results across iterations</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="HOT POTQA PROMPTS">
      <data key="d0">INSTRUCTION, INPUT</data>
      <data key="d1">Prompts used in the HotPotQA dataset for question answering tasks</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="INTERLEAVING THOUGHT, ACTION, OBSERVATION STEPS">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">A structured approach to solving tasks by alternating between reasoning, actions, and feedback</data>
      <data key="d2">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </node>
    <node id="PLAINS">
      <data key="d0">GEOGRAPHICAL FEATURE</data>
      <data key="d1">Plains are large areas of flat or gently rolling land that rise in elevation from around 1,800 to 7,000 feet.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="REFLECTION PROMPT">
      <data key="d0">INSTRUCTION, TASK</data>
      <data key="d1">A prompt that instructs the analysis of trajectories in a question-answering task, focusing on thoughts, actions, and observations to evaluate correctness and provide a score from 1 to 10.
A prompt that instructs the AI assistant to explain why a function implementation is wrong based on unit test results, to guide future improvements.
A prompt that asks for self-reflection to diagnose reasons for failure and devise a new plan to improve future performance</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,6f486e20e3102c7a285e357d356417ad,785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="PROGRAMMING PROMPT">
      <data key="d0">INSTRUCTION, TASK</data>
      <data key="d1">A prompt that provides instructions for implementing a function in a programming task, often including sample function signatures and examples.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="MINSUBARRAYSUM">
      <data key="d0">FUNCTION, ALGORITHM</data>
      <data key="d1">A function that finds the minimum sum of any non-empty sub-array of integers in a given array.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="UNIT TEST">
      <data key="d0">TEST, VALIDATION</data>
      <data key="d1">A test that validates the correctness of a function implementation by checking its output against expected results.
A specific test case used to validate the correctness of a function implementation, such as checking if add(1, 2) equals 3.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="ELEVATION">
      <data key="d0">ATTRIBUTE, MEASUREMENT</data>
      <data key="d1">Elevation refers to the height above sea level, in this context ranging from 1,800 to 7,000 feet for the plains.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="CORRECTNESS SCORE">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">A score ranging from 1 to 10 that evaluates the correctness of a solution in a question-answering task.
A score ranging from 1 to 10 that evaluates the correctness of a purchase decision based on specified criteria</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="QUESTION-ANSWERING TASK">
      <data key="d0">TASK, ACTIVITY</data>
      <data key="d1">A task that involves answering a question by analyzing trajectories, thoughts, actions, and observations.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="SAMPLE FUNCTION SIGNATURE">
      <data key="d0">CODE, EXAMPLE</data>
      <data key="d1">A sample function signature is an example of how to define a function in a programming task.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="SAMPLE FUNCTION BODY">
      <data key="d0">CODE, EXAMPLE</data>
      <data key="d1">A sample function body is an example of how to implement a function in a programming task.</data>
      <data key="d2">357f3442ba581c9d2bdf84d90509056f</data>
    </node>
    <node id="AI PYTHON ASSISTANT">
      <data key="d0">ROLE, SOFTWARE</data>
      <data key="d1">An AI assistant designed to help with Python programming tasks, including implementing functions, running unit tests, and reflecting on code performance.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="FUNCTION IMPLEMENTATION">
      <data key="d0">CODE, PROGRAMMING</data>
      <data key="d1">A specific implementation of a function in Python, provided by the AI assistant or user, which includes the function signature and body.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="UNIT TEST RESULTS">
      <data key="d0">TESTING, VALIDATION</data>
      <data key="d1">The results of running unit tests on a function implementation, indicating which tests passed and which failed.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="IMPROVED IMPLEMENTATION">
      <data key="d0">CODE, PROGRAMMING</data>
      <data key="d1">A revised version of a function implementation that addresses issues identified in the self-reflection process.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="TEST CASE GENERATION PROMPT">
      <data key="d0">INSTRUCTION, GUIDANCE</data>
      <data key="d1">A prompt that instructs the AI assistant to generate unique, diverse, and intuitive unit tests for a given function signature and docstring.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="BRIGHT CITRUS DEODORANT">
      <data key="d0">PRODUCT</data>
      <data key="d1">A type of deodorant with a bright citrus scent, suitable for sensitive skin, and available in a 3-ounce bottle.
A deodorant by Earth Mama that is natural and safe for sensitive skin, pregnancy, and breastfeeding, containing organic calendula, available in a 3-ounce size</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad,785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="PRICE LOWER THAN 50.00 DOLLARS">
      <data key="d0">PRICE CONSTRAINT</data>
      <data key="d1">A price limit set by the user for the products they are searching for, specifically less than 50.00 dollars.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="EARTH MAMA">
      <data key="d0">BRAND</data>
      <data key="d1">A brand that produces natural and safe deodorants for sensitive skin, including the Bright Citrus Deodorant and Ginger Fresh Deodorant.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="GINGER FRESH DEODORANT">
      <data key="d0">PRODUCT</data>
      <data key="d1">A type of deodorant with a ginger fresh scent, suitable for sensitive skin, and available in a 3-ounce bottle.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="BARREL AND OAK">
      <data key="d0">BRAND</data>
      <data key="d1">A brand that produces aluminum-free deodorants for men, with essential oil-based scents and 24-hour odor protection.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="CEDAR &amp; PATCHOULI DEODORANT">
      <data key="d0">PRODUCT</data>
      <data key="d1">A type of deodorant with a cedar and patchouli blend scent, suitable for sensitive skin, and available in a 2.7-ounce bottle.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="MIN SUM">
      <data key="d0">VARIABLE, PROGRAMMING</data>
      <data key="d1">A variable used in a function to keep track of the minimum sum encountered during the execution of the function.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="CURRENT SUM">
      <data key="d0">VARIABLE, PROGRAMMING</data>
      <data key="d1">A variable used in a function to keep track of the current sum of elements in a list during the execution of the function.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="ADD FUNCTION">
      <data key="d0">FUNCTION IMPLEMENTATION, CODE</data>
      <data key="d1">A function in Python that takes two integers, a and b, and returns their sum. The initial implementation had an error where it subtracted b from a instead of adding them.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="ERROR">
      <data key="d0">ISSUE, BUG</data>
      <data key="d1">A mistake in the function implementation where the code does not perform the intended operation, such as using the wrong operator.
An error is a mistake or incorrect result produced by an agent, which needs to be refined or corrected.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="OPERATOR">
      <data key="d0">SYMBOL, PROGRAMMING</data>
      <data key="d1">A symbol used in programming to perform operations on variables, such as '+' for addition and '-' for subtraction.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="DOCSTRING">
      <data key="d0">DOCUMENTATION, PROGRAMMING</data>
      <data key="d1">A string literal in Python used to document the purpose and behavior of a function, typically placed right after the function signature.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="SIGNATURE">
      <data key="d0">SYNTAX, PROGRAMMING</data>
      <data key="d1">The declaration of a function in Python, including its name, parameters, and return type.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="BRIGHT CITRUS DEODORANT BY EARTH MAMA">
      <data key="d0">PRODUCT, BRAND</data>
      <data key="d1">A specific product by Earth Mama that is a natural and safe deodorant for sensitive skin, available in a 3-ounce bottle.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="GINGER FRESH DEODORANT BY EARTH MAMA">
      <data key="d0">PRODUCT, BRAND</data>
      <data key="d1">A specific product by Earth Mama that is a natural and safe deodorant for sensitive skin, available in a 3-ounce bottle.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="BARREL AND OAK DEODORANT">
      <data key="d0">PRODUCT, BRAND</data>
      <data key="d1">A specific product by Barrel and Oak that is an aluminum-free deodorant for men, with essential oil-based scents and 24-hour odor protection.</data>
      <data key="d2">785ad59c6a37896a4676ec5c1689735f</data>
    </node>
    <node id="DAIRY FREE">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A characteristic of a product indicating it does not contain dairy
A characteristic of a product indicating it does not contain dairy</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="APPLE VARIETY PACK OF CHIPS">
      <data key="d0">PRODUCT</data>
      <data key="d1">A pack of chips that includes different varieties of apple flavors
A pack of chips that includes different varieties of apple flavors</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="PRICE LOWER THAN 30.00 DOLLARS">
      <data key="d0">PRICE CONSTRAINT</data>
      <data key="d1">A price limit set by the user for the products they are searching for
A price limit set by the user for the products they are searching for</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="ENJOY LIFE FOODS SOFT BAKED OVALS">
      <data key="d0">PRODUCT</data>
      <data key="d1">A type of breakfast bar that is nut-free, soy-free, dairy-free, non-GMO, gluten-free, and vegan, available in a variety pack
A type of breakfast bar that is nut-free, soy-free, dairy-free, non-GMO, gluten-free, and vegan, available in a variety pack</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="ENJOY LIFE SOFT BAKED CHEWY BARS">
      <data key="d0">PRODUCT</data>
      <data key="d1">A type of chewy bar that is nut-free, soy-free, dairy-free, gluten-free, available in a variety pack
A type of chewy bar that is nut-free, soy-free, dairy-free, and gluten-free, available in a variety pack</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="ENJOY LIFE LENTIL CHIPS VARIETY PACK">
      <data key="d0">PRODUCT</data>
      <data key="d1">A variety pack of lentil chips that are dairy-free, soy-free, nut-free, non-GMO, vegan, and gluten-free
A variety pack of lentil chips that are dairy-free, soy-free, nut-free, non-GMO, vegan, and gluten-free</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="SENSITIVE SKIN">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A characteristic of a product indicating it is suitable for sensitive skin</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="PREGNANCY AND BREASTFEEDING">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A characteristic of a product indicating it is safe for use during pregnancy and breastfeeding</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="ORGANIC CALENDULA">
      <data key="d0">INGREDIENT</data>
      <data key="d1">An ingredient in the Bright Citrus Deodorant, known for its soothing properties</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="VARIETY PACK">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">An option for products that includes multiple varieties or flavors
An option for a product that includes multiple varieties or flavors</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="0.8 OUNCE (PACK OF 24)">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A size option for products, specifically a pack of 24 with each item being 0.8 ounces
A specific size option for a product, indicating 0.8 ounces per pack and 24 packs in total</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="3 OUNCE (PACK OF 1)">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A size option for products, specifically a single item of 3 ounces</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="ASSORTED SCENTS">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A variety of scent options available for a product, including bright citrus, calming lavender, ginger fresh, and simply non-scents</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="BRIGHT CITRUS">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A specific scent option for a product, such as deodorant</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="CALMING LAVENDER">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A specific scent option for a product, such as deodorant</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="GINGER FRESH">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A specific scent option for a product, such as deodorant</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="SIMPLY NON-SCENTS">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A specific scent option for a product, such as deodorant, that is unscented</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="TRAVEL SET (4-PACK)">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A size option for products, specifically a travel set containing 4 items</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="3 OUNCE (2-PACK)">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A size option for products, specifically a pack of 2 with each item being 3 ounces</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="DILL AND SOUR CREAM">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A specific flavor option for a product, such as chips</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="GARLIC &amp; PARMESAN">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A specific flavor option for a product, such as chips</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="LIGHT SEA SALT">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A specific flavor option for a product, such as chips</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="MARGHERITA PIZZA">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A specific flavor option for a product, such as chips</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="THAI CHILI LIME">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A specific flavor option for a product, such as chips</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="4 OUNCE (PACK OF 12)">
      <data key="d0">PRODUCT OPTION</data>
      <data key="d1">A size option for products, specifically a pack of 12 with each item being 4 ounces</data>
      <data key="d2">6f486e20e3102c7a285e357d356417ad</data>
    </node>
    <node id="BUY NOW">
      <data key="d0">ACTION</data>
      <data key="d1">An action to purchase a product immediately</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
      <data key="d3">ACTION</data>
    </node>
    <node id="GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON">
      <data key="d0">PRODUCT</data>
      <data key="d1">A type of vegetarian bacon that is gluten-free and smoked with pepper, available in a 4-ounce pack of 2</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
      <data key="d3">PRODUCT</data>
    </node>
    <node id="PRICE LOWER THAN 40.00 DOLLARS">
      <data key="d0">PRICE CONSTRAINT</data>
      <data key="d1">A price limit set by the user for the products they are searching for</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
      <data key="d3">PRICE CONSTRAINT</data>
    </node>
    <node id="SMOKED BACON SEA SALT 3-PACK">
      <data key="d0">PRODUCT</data>
      <data key="d1">A pack of three smoked bacon sea salts, including chipotle, onion, and peppered bacon flavors, all gluten-free, non-GMO, and without MSG</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
      <data key="d3">PRODUCT</data>
    </node>
    <node id="LOUISVILLE VEGAN JERKY">
      <data key="d0">PRODUCT</data>
      <data key="d1">A variety pack of vegan jerky with flavors like black pepper, buffalo dill, pepperoni, maple bacon, and Carolina BBQ, non-GMO and gluten-free
A variety pack of vegan jerky with five flavors: Black Pepper, Buffalo Dill, Pepperoni, Maple Bacon, and Carolina BBQ. It is made from non-GMO soy protein and is gluten-free, with each pack weighing 3 ounces.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,5d356b8ff719763a38cecff22c4e17b7</data>
      <data key="d3">PRODUCT</data>
    </node>
    <node id="THINK">
      <data key="d0">ACTION</data>
      <data key="d1">An action where the user reflects on the suitability of a product</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
      <data key="d3">ACTION</data>
    </node>
    <node id="CLICK">
      <data key="d0">ACTION</data>
      <data key="d1">An action to select or interact with a product or option on the web shop</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
      <data key="d3">ACTION</data>
    </node>
    <node id="FLAVOR NAME">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Different flavor options available for a product, such as dill and sour cream, garlic &amp; parmesan, light sea salt, margherita pizza, thai chili lime, and variety pack</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="SIZE">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Different size options available for a product, such as 0.8 ounce (pack of 24) and 4 ounce (pack of 12)</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="RATING">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A measure of customer satisfaction or quality, often represented numerically or as stars
The process of evaluating student responses against teacher responses, scored on a scale from 0 to 10.</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="DESCRIPTION">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A detailed explanation of the product's features and benefits</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="FEATURES">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Specific characteristics or functionalities of a product</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="REVIEWS">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">Customer feedback and opinions about a product</data>
      <data key="d2">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </node>
    <node id="SPICY HOT PEPPER SEA SALT 3-PACK">
      <data key="d0">PRODUCT</data>
      <data key="d1">A pack of three different spicy hot pepper sea salts, including Ghost Pepper, Jalapeno, and Habanero. It is all-natural, gluten-free, kosher, non-GMO, and contains no MSG, with a total weight of 12 ounces.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="NON-GMO">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A characteristic indicating that the product does not contain genetically modified organisms.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="GLUTEN-FREE">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A characteristic indicating that the product does not contain gluten.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="KOSHER">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A characteristic indicating that the product meets the dietary standards of Jewish law.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="NO MSG">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A characteristic indicating that the product does not contain monosodium glutamate (MSG).</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="REFINE SEARCH">
      <data key="d0">ACTION</data>
      <data key="d1">The action of adjusting search parameters to better match desired results.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="VEGETARIAN BACON">
      <data key="d0">PRODUCT</data>
      <data key="d1">A type of bacon alternative made from vegetarian ingredients.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="4 OUNCE PACK OF 2">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A packaging characteristic indicating that the product comes in two packs, each weighing 4 ounces.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="FAIL">
      <data key="d0">STATUS</data>
      <data key="d1">An indication that the attempt or action was unsuccessful.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="JALAPENO">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A type of hot pepper used in the Spicy Hot Pepper Sea Salt 3-Pack.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="HABANERO">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A type of hot pepper used in the Spicy Hot Pepper Sea Salt 3-Pack.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="BLACK PEPPER">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A flavor of the Louisville Vegan Jerky variety pack.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="BUFFALO DILL">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A flavor of the Louisville Vegan Jerky variety pack.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="PEPPERONI">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A flavor of the Louisville Vegan Jerky variety pack.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="MAPLE BACON">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A flavor of the Louisville Vegan Jerky variety pack.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="CAROLINA BBQ">
      <data key="d0">PRODUCT ATTRIBUTE</data>
      <data key="d1">A flavor of the Louisville Vegan Jerky variety pack.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="INVALID ACTION">
      <data key="d0">STATUS</data>
      <data key="d1">An indication that the attempted action was not recognized or allowed by the system.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="NEXT">
      <data key="d0">ACTION</data>
      <data key="d1">The action of moving to the next page or set of results in a search or navigation process.</data>
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="GHOST PEPPER">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">5d356b8ff719763a38cecff22c4e17b7</data>
    </node>
    <node id="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d0">RESEARCH AREA, METHODOLOGY</data>
      <data key="d1">ADAS is a research area focused on automatically creating powerful agentic system designs, including inventing novel building blocks and/or combining them in new ways.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="SHENGRAN HU">
      <data key="d0">RESEARCHER, AUTHOR</data>
      <data key="d1">Shengran Hu is one of the authors of the paper on Automated Design of Agentic Systems and is affiliated with the University of British Columbia and the Vector Institute.
Shengran Hu is one of the authors of the paper titled "Thought Cloning: Learning to think while acting by imitating human thinking" published in Advances in Neural Information Processing Systems in 2024.
One of the authors of the paper "Intelligent go-explore: Standing on the shoulders of giant foundation models," published as an arXiv preprint in 2024.
Shengran Hu is one of the authors of the paper titled "Automated Design of Agentic Systems."
The author of the framework code available at the provided GitHub link.
Shengran Hu is the author mentioned in the context of providing detailed implementations of all baselines.
Shengran Hu is an author and researcher associated with the implementation of various baselines and methods, as well as the repository at https://github.com/ShengranHu/ADAS.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e,97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059,cc802d9b841fde55e9c0c2ba0ef7869d,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="CONG LU">
      <data key="d0">RESEARCHER, AUTHOR</data>
      <data key="d1">Cong Lu is one of the authors of the paper on Automated Design of Agentic Systems and is affiliated with the University of British Columbia and the Vector Institute.
Cong Lu is one of the authors of the paper titled "The AI Scientist: Towards fully automated open-ended scientific discovery" published as an arXiv preprint in 2024.
One of the authors of the paper "Intelligent go-explore: Standing on the shoulders of giant foundation models," published as an arXiv preprint in 2024.
Cong Lu is one of the authors of the paper titled "Varibad: Variational bayes-adaptive deep RL via meta-learning" published in the Journal of Machine Learning Research in 2021.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e,c3d0436082aada237ee4bee645f16059,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="META AGENT SEARCH">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Meta Agent Search is an algorithm that iteratively programs new agents, tests their performance on tasks, and adds them to an archive of discovered agents to inform subsequent iterations.
Meta Agent Search is an algorithm in ADAS that enables the complete design of agentic systems in code space, iteratively creating and evaluating new agents.
Meta Agent Search is an algorithm that demonstrates the approach of defining and searching for agents within the ADAS framework. It is designed to discover agentic systems that perform well across different domains.
Meta Agent Search is an algorithm designed to iteratively program new agents based on an archive of previous discoveries. It uses foundational models (FMs) as meta agents to create new agentic systems by leveraging basic functions like FM query APIs and formatting prompts.
Meta Agent Search is a method that progressively discovers high-performance agents based on an ever-growing archive of previous discoveries. It is used to outperform existing state-of-the-art hand-designed agents in the Abstraction and Reasoning Corpus (ARC) challenge.
Meta Agent Search is a method used to progressively discover agents that outperform state-of-the-art hand-designed baselines across multiple domains such as reading comprehension, math, multi-task problem solving, and science.
Meta Agent Search is a method that outperforms baselines in various domains, including Multi-task and Science, by optimizing agentic systems. It is particularly effective in domains where foundational models (FMs) possess adequate knowledge, such as Reading Comprehension and Math.
Meta Agent Search is an algorithm that improves accuracy in various domains, including math and non-math, by discovering generalizable design patterns and agentic systems.
Meta Agent Search is a method used to discover top agents in the math domain, which can be transferred to non-math domains with high performance.
Meta Agent Search is a method that involves executing model-generated code, with safety considerations advised due to potential destructive actions from untrusted code.
Meta Agent Search is an algorithm used in ADAS to program new agents in code, with the potential to be improved through higher-order meta-learning.
Meta Agent Search is a proposed method where a meta agent iteratively builds on previous discoveries to program new agents, outperforming state-of-the-art hand-designed agents.
Meta Agent Search is a method used to design new agents based on the archive of previously discovered agents, as described in the supplementary material of the paper "Automated Design of Agentic Systems."
Meta Agent Search is a method used to discover the best performing agents on the ARC benchmark.
Meta Agent Search is a method used to discover agents in various domains, such as Reading Comprehension and Math.
A method that could achieve improved results at a lower cost when using the GPT-4o-mini model.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,449db721e37968e073e3579b59e023b2,4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb,7de66b94cf868b37b1df51dc545c415f,81c504ffbcc5ed882e234802135295ba,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b,c3d0436082aada237ee4bee645f16059,cc802d9b841fde55e9c0c2ba0ef7869d,dc55f071b95dec721a9820d39cdb3ccd,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="FOUNDATION MODELS (FMS)">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Foundation Models such as GPT and Claude are powerful general-purpose agents used for agentic tasks that require flexible reasoning and planning.
Foundation Models (FMs) are used as modules in the control flow of agentic systems to solve tasks by planning, using tools, and carrying out multiple, iterative steps of processing.
Foundation Models are advanced language models that can write code to discover better optimization algorithms, program loss functions for preference learning, and create robotics learning environments.
Models that the meta agent queries as part of its framework to generate and improve code.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CHAIN-OF-THOUGHT">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Chain-of-Thought is a planning and reasoning technique used as a building block in agentic systems.
Chain-of-Thought (Wei et al., 2022) is a state-of-the-art hand-designed agent used for reasoning and problem-solving tasks.
Chain-of-Thought is a manually designed agent used for planning and reasoning in various domains, including math.
Chain-of-Thought is a manually designed agent used for tasks like math, reading comprehension, multi-tasking, and science, with specific accuracy and F1 scores reported.
A method used in the FM Module for step-by-step reasoning and solving tasks, including initial reasoning and reflecting on previous attempts.
A method used to solve tasks by breaking down the problem into a series of thought processes.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,4b43decac6833d1515992f8869ecada7,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b,c3d0436082aada237ee4bee645f16059,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="UNIVERSITY OF BRITISH COLUMBIA">
      <data key="d0">ORGANIZATION, INSTITUTION</data>
      <data key="d1">The University of British Columbia is an academic institution where some of the authors of the paper are affiliated.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="VECTOR INSTITUTE">
      <data key="d0">ORGANIZATION, INSTITUTION</data>
      <data key="d1">The Vector Institute is a research institution where some of the authors of the paper are affiliated.
The Vector Institute is one of the organizations that supported the work on Automated Design of Agentic Systems.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CANADA CIFAR AI CHAIR">
      <data key="d0">TITLE, POSITION</data>
      <data key="d1">The Canada CIFAR AI Chair is a prestigious position held by Jeff Clune, one of the authors of the paper.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="MULTI-STEP PEER REVIEW AGENT">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">The Multi-Step Peer Review Agent is an example of an agent discovered by the Meta Agent Search algorithm, designed to perform multi-step peer reviews.
The Multi-Step Peer Review Agent is an agent discovered by Meta Agent Search in the Reading Comprehension domain. It involves multiple steps including initial instruction, critique, refinement, and final decision.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="VERIFIED MULTIMODAL AGENT">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">The Verified Multimodal Agent is an example of an agent discovered by the Meta Agent Search algorithm, designed to handle tasks involving multiple modalities.
The Verified Multimodal Agent is an agent discovered by Meta Agent Search in the Math domain.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="DIVIDE AND CONQUER AGENT">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">The Divide and Conquer Agent is an example of an agent discovered by the Meta Agent Search algorithm, designed to divide tasks into sub-problems and solve them iteratively.
The Divide and Conquer Agent is an agent discovered by Meta Agent Search. It involves decomposing a problem into sub-problems and assigning each sub-problem to a specialized expert.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CLAUDE">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Claude is a Foundation Model developed by Anthropic, used as a general-purpose agent for agentic tasks.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="HOG">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">HOG (Histogram of Oriented Gradients) is a hand-designed feature used in computer vision, eventually replaced by learned features from Convolutional Neural Networks.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CONVOLUTIONAL NEURAL NETWORKS (CNNS)">
      <data key="d0">TECHNOLOGY, MODEL</data>
      <data key="d1">Convolutional Neural Networks are a type of neural network used in computer vision, known for their ability to learn features from data.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="NEURAL ARCHITECTURE SEARCH">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Neural Architecture Search is a method used to automatically design neural network architectures, leading to high-performing models.
Neural Architecture Search (NAS) is a method for automating the design of neural network architectures, as discussed by Elsken et al. in 2019 and Shen et al. in 2023.
Neural Architecture Search is a method within AutoML that involves searching for the best neural network architecture for a given task.
Neural Architecture Search is a method to automate the design of neural network architectures, falling under the first pillar of AI-GAs.
Neural Architecture Search is a technique used to gain insights into neural networks by observing their emerged architecture, as shown in works by Huang et al., 2023.
A research paper titled "Neural architecture search: A survey" authored by Thomas Elsken et al., published in the Journal of Machine Learning Research in 2019.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb,7de66b94cf868b37b1df51dc545c415f,81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="AUTO ML">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">AutoML (Automated Machine Learning) refers to methods that automate the process of applying machine learning to real-world problems.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="AI-GENERATING ALGORITHMS (AI-GAS)">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">AI-Generating Algorithms are methods that automatically generate AI systems, demonstrating the superiority of learned AI systems over hand-designed ones.
AI-GAs are algorithms that aim to learn more components in AI systems to replace handcrafted ones, focusing on meta-learning architectures, learning algorithms, and generating effective learning environments and training data.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="ROCKT&#196;SCHEL, 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rockt&#228;schel is an author cited in the paper, contributing to the research on agentic systems.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="ZAHARIA ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zaharia et al. are authors cited in the paper, contributing to the research on agentic systems.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="HU &amp; CLUNE, 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hu &amp; Clune are authors cited in the paper, contributing to the research on chain-of-thought planning and reasoning.
Hu &amp; Clune are the authors who contributed to the development of chain-of-thought-based planning and reasoning methods, published in 2024.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="LEWIS ET AL., 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lewis et al. are authors cited in the paper, contributing to the research on memory structures in agentic systems.
Lewis et al. are the authors who contributed to the development of external memory and RAG techniques, published in 2020.
Lewis et al. are authors referenced in the text, known for their work published in 2020 related to Retrieval-Augmented Generation (RAG).</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,6bdf681c0bd9e401ac72344a6a0ae479,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="ZHANG ET AL., 2024C">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhang et al. are authors cited in the paper, contributing to the research on memory structures in agentic systems.
Zhang et al. are the authors who contributed to the development of external memory and RAG techniques, published in 2024.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="QU ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qu et al. are authors cited in the paper, contributing to the research on tool use in agentic systems.
Qu et al. are the authors who contributed to the development of tool use techniques, published in 2024.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="MADAAN ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Madaan et al. are authors cited in the paper, contributing to the research on self-reflection in agentic systems.
Madaan et al. are the authors of the Self-Refine strategy, published in 2024, which is used in the Meta Agent Search algorithm.
Madaan et al. are researchers who developed the Self-Refine method in 2024.
Madaan et al. are the authors of the Self-Refine algorithm, published in 2024.
Madaan et al. are the authors of the Self-Refine algorithm, published in 2024.
Madaan et al. are the authors who contributed to the development of reflection techniques, published in 2024.Madaan et al. are the authors of the Self-Refine algorithm, published in 2024.
Madaan et al. are the authors of research on Self-Refine, published in 2024.
Authors who contributed to the process of self-reflection to make the generated agent novel and error-free.
Madaan et al. are the authors of the Self-Refine algorithm, published in 2024.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,282313a8340c6792e8c35f53ed157cd0,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="ANTHROPIC">
      <data key="d0" />
      <data key="d1">Anthropic is the organization that developed the Claude Foundation Model.
Anthropic is a company that introduced the next generation of Claude, including Claude 3 and Claude 3.5 Sonnet, in 2024.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f,c3d0436082aada237ee4bee645f16059</data>
      <data key="d3">ORGANIZATION, COMPANY</data>
    </node>
    <node id="MEMORY STRUCTURES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="TOOL USE">
      <data key="d0" />
      <data key="d1">
Tool use refers to the ability of agentic systems to utilize external tools or resources to achieve their goals, a component that can be discovered in ADAS.
Tool use is an important building block for agentic systems, enabling agents to interact with and manipulate tools to achieve their goals.
Tool use is a skill that can be taught to AI models using the data generated by AgentInstruct.
Tool use involves the manipulation of tools to achieve goals. In AI, this refers to the ability of an AI system to use available resources or auxiliary systems to solve complex tasks.
The task of enabling models to interact with external tools or services via APIs, extending their functionality and accessing external data.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,0c212c1467564ad33330b1f655a8e27e,427e98b00e49b6a8f8649054122dd45b,81c504ffbcc5ed882e234802135295ba,b88745a13b69cecbc0ee9c3af41389bf,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="VISUAL PARADIGM">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Visual Paradigm is a method or approach used by the Verified Multimodal Agent to handle tasks involving visual data.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="VISUAL ANALYZER">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">Visual Analyzer is a component of the Verified Multimodal Agent that analyzes visual data to provide answers.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="EXPERTS">
      <data key="d0">CONCEPT, ROLE</data>
      <data key="d1">Experts are individuals or systems with specialized knowledge used by agents like the Multi-Step Peer Review Agent to review tasks and provide answers.
Experts in Meta Agent Search provide feedback on various specific traits such as efficiency, readability, and simplicity to refine answers more effectively.
Experts are individuals who evaluate various specific traits such as efficiency and simplicity in the feedback mechanism of ADAS.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,bc26e68b0b2783ba912b9e5606d9eb0b,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="REVIEWERS">
      <data key="d0">CONCEPT, ROLE</data>
      <data key="d1">Reviewers are individuals or systems that evaluate the answers provided by agents like the Multi-Step Peer Review Agent.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="SUB-PROBLEM">
      <data key="d0">CONCEPT, ACTIVITY</data>
      <data key="d1">A sub-problem is a smaller, more manageable part of a larger task, often used in the Divide and Conquer Agent's approach.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="ENSEMBLE ANSWER">
      <data key="d0">CONCEPT, RESULT</data>
      <data key="d1">An ensemble answer is a combined result from multiple experts or agents, used to provide a more accurate solution to a task.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="META AGENT">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">A meta agent is an agent that programs other agents, tests their performance, and refines them iteratively to discover new, effective agents.
A meta agent is an agent that programs other agents, used in Meta Agent Search to create new agentic systems in an automated manner.
A meta agent is an entity in the Meta Agent Search algorithm that iteratively programs new agents based on an archive of previous discoveries. It uses foundational models to create new agentic systems.
The meta agent is an agent used in ADAS to program new agents in code, with the potential for improvement through higher-order meta-learning.
A meta agent is an agent that programs other agents by iteratively building on previous discoveries, as proposed in the Meta Agent Search method.
The Meta Agent is a system designed to propose new agentic systems by using prompts and control flows to solve complex tasks, as described in the supplementary material of the paper "Automated Design of Agentic Systems."
A system designed to generate and improve code through iterative self-reflection and debugging. It uses prompts to guide its thought process and implementation steps.
An agent designed to generate other agents that can solve tasks by generating code solutions rather than directly outputting answers.
An agent that uses advanced models like GPT-4o-2024-05-13 for evaluation in various domains.
The meta agent is an agent that uses GPT-4o-2024-05-13 to find optimal agents for various benchmarks.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,24d7b89ae9522ae60d2317984951355b,282313a8340c6792e8c35f53ed157cd0,4b43decac6833d1515992f8869ecada7,6bdf681c0bd9e401ac72344a6a0ae479,7de66b94cf868b37b1df51dc545c415f,81c504ffbcc5ed882e234802135295ba,84317ae35cc75d612287186d93461447,c3d0436082aada237ee4bee645f16059,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="AGENT ARCHIVE">
      <data key="d0">CONCEPT, STORAGE</data>
      <data key="d1">An agent archive is a storage of discovered agents used by the meta agent to inform subsequent iterations and improve performance.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CODE">
      <data key="d0">CONCEPT, DATA</data>
      <data key="d1">Code refers to the programming instructions used to define the behavior and functionality of agents.
A section in the output where the meta agent provides the complete Python code for the "forward()" function of the proposed agent architecture.
The code generated or refined during the problem-solving process.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,84317ae35cc75d612287186d93461447,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="TURING COMPLETE">
      <data key="d0">CONCEPT, PROPERTY</data>
      <data key="d1">Turing Complete refers to the capability of a programming language to perform any computation that can be described algorithmically.
Turing Complete refers to a system of data-manipulation rules (such as a programming language) that can simulate any Turing machine, indicating its computational universality.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="COMPUTE">
      <data key="d0">CONCEPT, RESOURCE</data>
      <data key="d1">Compute refers to the computational power available for running algorithms and training models.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="DATA">
      <data key="d0">CONCEPT, RESOURCE</data>
      <data key="d1">Data refers to the information used to train models and inform the behavior of agents.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="HISTORY OF MACHINE LEARNING">
      <data key="d0">CONCEPT, FIELD</data>
      <data key="d1">The history of machine learning refers to the development and evolution of machine learning techniques and methodologies over time.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="HAND-DESIGNED SOLUTIONS">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Hand-designed solutions are manually created methods or systems, often replaced by more efficient learned solutions in machine learning.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="LEARNED SOLUTIONS">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Learned solutions are methods or systems developed through machine learning, often more efficient than hand-designed solutions.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="COMPUTER VISION">
      <data key="d0">FIELD, APPLICATION</data>
      <data key="d1">Computer vision is a field of study focused on enabling machines to interpret and understand visual information from the world.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="HUTTER ET AL., 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hutter et al. are authors cited in the paper for contributions to the research on AutoML methods.
Hutter et al. are the authors of a study in 2019 discussing AutoML methods.
Hutter et al. are authors who contributed to the research area of AutoML, published in 2019.
Hutter et al. are the authors of research on AutoML, published in 2019.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="CLUNE, 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Clune is an author cited in the paper for contributions to the research on AI-Generating Algorithms and the history of machine learning.
Clune is the author of a study in 2019 discussing AI-Generating Algorithms (AI-GAs).
Clune is an author who contributed to the research area of AI-GAs, published in 2019.
Clune is the author of research on AI-Generating Algorithms, published in 2019.
Clune is the author of a work published in 2019 that discusses the potential of AI-GA and AGI.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="DALAL &amp; TRIGGS, 2005">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dalal &amp; Triggs are authors cited in the paper for contributions to the research on HOG features in computer vision.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="KRIZHEVSKY ET AL., 2012">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Krizhevsky et al. are authors cited in the paper for contributions to the research on Convolutional Neural Networks.
Krizhevsky et al. are the authors of a study in 2012 introducing Convolutional Neural Networks (CNNs).</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="ELSKEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Elsken is an author cited in the paper for contributions to the research on Neural Architecture Search.</data>
      <data key="d2">c3d0436082aada237ee4bee645f16059</data>
    </node>
    <node id="APPENDIX F">
      <data key="d0">DOCUMENT SECTION</data>
      <data key="d1">Appendix F contains the detailed code of example agents.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="CNN">
      <data key="d0">TECHNOLOGY, NEURAL NETWORK</data>
      <data key="d1">Convolutional Neural Networks (CNNs) are a type of neural network used primarily in image recognition and processing, introduced by Krizhevsky et al. in 2012.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="AUTOML">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">AutoML methods, as discussed by Hutter et al. in 2019, are techniques for automating the process of applying machine learning to real-world problems.
AutoML (Automated Machine Learning) is a research area similar to ADAS, focusing on the automation of machine learning model design and optimization.
AutoML stands for Automated Machine Learning, which aims to automate the process of applying machine learning to real-world problems, including the design of neural network architectures and learning algorithms.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="AI-GA">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">AI-Generating Algorithms (AI-GAs), introduced by Clune in 2019, are methods that automatically generate AI systems, demonstrating superiority over hand-designed systems.
AI-GA (Artificial Intelligence-Generative Algorithms) is a research area that includes ADAS and focuses on advancing AI capabilities through generative algorithms.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="LLM ALIGNMENT">
      <data key="d0">RESEARCH AREA</data>
      <data key="d1">LLM alignment involves aligning large language models with specific goals or behaviors, often using learned loss functions as discussed by Lu et al. in 2024a.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="LEARNED LOSS FUNCTIONS">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">Learned loss functions are functions that are automatically learned to optimize the performance of models, outperforming hand-designed ones like DPO, as discussed by Lu et al. in 2024a.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="DPO">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">DPO is a hand-designed loss function used in LLM alignment, discussed by Rafailov et al. in 2024.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="AI SCIENTIST">
      <data key="d0">TECHNOLOGY, SYSTEM</data>
      <data key="d1">The AI Scientist, introduced by Lu et al. in 2024b, is an automated research pipeline that develops novel machine learning algorithms.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="OMNI-EPIC">
      <data key="d0">TECHNOLOGY, SYSTEM</data>
      <data key="d1">OMNI-EPIC, developed by Faldor et al. in 2024, is a system that automatically generates robotics learning environments, demonstrating creativity and efficiency.
OMNI-EPIC is an algorithm that aims to generate learning environments in an open-ended manner, enabling Foundation Models to create robotics learning environments by programming in code.
OMNI-EPIC is an algorithm developed by Faldor et al., 2024, that enables FMs to create robotics learning environments by programming in code.
A research paper titled "Omni-epic: Open-endedness via models of human notions of interestingness with environments programmed in code" authored by Maxence Faldor et al., published as an arXiv preprint in 2024.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="ADAS">
      <data key="d0">RESEARCH AREA</data>
      <data key="d1">Automated Design of Agentic Systems (ADAS) is a research area focused on automatically inventing and designing powerful agentic systems.
Automated Design of Agentic Systems (ADAS) is a new research area that involves using a search algorithm to discover agentic systems across a search space that optimize an evaluation function. It is similar to research areas in AI-GAs and AutoML.
Automated Design of Agentic Systems (ADAS) is a research area that focuses on using programming languages as the search space for defining and searching for agents. It aims to leverage existing expertise from foundational models during the search process.
ADAS (Automated Design of Agentic Systems) is an algorithm that showcases the potential to progressively discover agents that outperform state-of-the-art hand-designed baselines and invent novel design patterns through the innovation and combination of various stepping stones.
ADAS (Automated Design of Agentic Systems) is a proposed research area aimed at inventing novel building blocks and designing powerful agentic systems in an automated manner.
ADAS stands for Automated Design of Agentic Systems, a proposed research area aimed at inventing novel building blocks and designing powerful agentic systems in an automated manner.
Automated Design of Agentic Systems (ADAS) is a new area in AI-GA research that involves learning more components in agentic systems beyond just prompts, potentially contributing to the creation of Artificial General Intelligence (AGI).
ADAS (Automated Design of Agentic Systems) is an algorithm that demonstrates the ease of programming powerful agentic systems using available API access to powerful foundational models (FMs) without expensive hardware like GPUs.
ADAS stands for Automated Design of Agentic Systems, a research problem aimed at automatically inventing novel building blocks and designing powerful agentic systems.
ADAS (Automated Design of Agentic Systems) is a framework used for designing and testing various agentic systems, as described in the supplementary material of the paper "Automated Design of Agentic Systems."
</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb,7de66b94cf868b37b1df51dc545c415f,81c504ffbcc5ed882e234802135295ba,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b,cc802d9b841fde55e9c0c2ba0ef7869d,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="ARC">
      <data key="d0">BENCHMARK, TASK</data>
      <data key="d1">The ARC logic puzzle task, introduced by Chollet in 2019, is a benchmark designed to test the general intelligence of AI systems.
ARC (Abstraction and Reasoning Corpus) is a challenging logic puzzle task used to evaluate the performance of discovered agents in the experiments.
ARC is a benchmark used to evaluate the performance of agents discovered by Meta Agent Search and other foundational models like GPT-3.5, GPT-4, Claude-Haiku, and Claude-Sonnet.
ARC (Abstraction and Reasoning Corpus) is a benchmark used to evaluate the performance of AI agents in solving reasoning tasks.
ARC (AI2 Reasoning Challenge) is a benchmark used for evaluating reasoning and problem-solving abilities in AI models.
A dataset used for search and evaluation in experiments, with a cost of approximately $500 USD per run.
A benchmark used to evaluate models, with Orca-3 scoring 92.47, which is a 12% improvement over Orca-2.5.
The AI2 Reasoning Challenge (ARC) is a benchmark developed by AllenAI to measure the reasoning, commonsense knowledge, and deep comprehension abilities of language models.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,449db721e37968e073e3579b59e023b2,81c504ffbcc5ed882e234802135295ba,86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="DROP">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">DROP is a reading comprehension benchmark dataset, discussed by Dua et al. in 2019.
DROP (Discrete Reasoning Over Paragraphs) is a benchmark used to assess the reading comprehension abilities of the discovered agents, showing significant improvement in F1 score.
DROP (Dua et al., 2019) is a benchmark used for evaluating reading comprehension capabilities of agents.
A research paper titled "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs" authored by Dheeru Dua et al., presented at the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.
A dataset used for evaluating agents in the Reading Comprehension domain, using one-shot style questions.
DROP (Reading Comprehension) is a benchmark that assesses the ability to perform discrete reasoning and comprehend detailed information across multiple paragraphs.
A benchmark used to evaluate models, with Orca-3 scoring 71.14, which is a 22% improvement over Orca-2.5.
Discrete Reasoning over Paragraphs (DROP) is a reading comprehension benchmark requiring models to resolve references in questions and perform discrete operations over them such as sorting, counting, and addition.
A dataset used for evaluating models on problems where a ground-truth answer value is given.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,103d98395c393552cc954c89d4e59f50,10fda605f670bcfccfc13c2ca0dde959,24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba,84317ae35cc75d612287186d93461447,86f77e15d41cbd0cb33f635ccb2cb66b,bc26e68b0b2783ba912b9e5606d9eb0b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="MGSM">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">MGSM is a math task benchmark dataset, discussed by Shi et al. in 2023.
MGSM (Math Generalization and Symbolic Manipulation) is a benchmark used to evaluate the math abilities of the discovered agents, showing significant improvement in accuracy rate.
MGSM (Shi et al., 2023) is a benchmark used for evaluating math capabilities under a multi-lingual setting.
MGSM is a math domain used to evaluate the performance of agents discovered by Meta Agent Search and their transferability to other math domains.
MGSM is a benchmark used to evaluate the performance of agents in the math domain, relevant to the Meta Agent Search method.
MGSM (Multilingual Grade School Math Benchmark) evaluates mathematical problem-solving abilities across various languages to ensure broad and effective multilingual performance.
MGSM is the Math domain where the Verified Multimodal Agent was discovered by Meta Agent Search.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="GSM8K">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">GSM8K is a math task benchmark dataset, discussed by Cobbe et al. in 2021.
GSM8K is a dataset used to evaluate the transferability of discovered agents from MGSM math tasks to held-out math tasks, showing significant improvement in accuracy rate.
GSM8K is a dataset used for evaluating the performance of algorithms in math-related tasks.
GSM8K is a benchmark used to evaluate the performance of language models. Orca-3 shows a 54% improvement on this benchmark compared to Mistral-7b-Instruct.
GSM8K is a benchmark used to evaluate the performance of AI models. Orca-3 showed a 54% improvement on GSM8K compared to Mistral-Instruct-7B.
A benchmark used to evaluate models, with Orca-3 scoring 83.09, which is a 54% improvement over Orca-2.5.
Grade School Math 8K (GSM8K) is a dataset of high-quality diverse grade school math word problems, requiring between 2 and 8 steps to solve using basic arithmetic operations.
GSM8K is a benchmark used to evaluate the performance of AI models on math problems, particularly in the context of generative teaching.
A dataset used for evaluating models on math-based questions.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,103d98395c393552cc954c89d4e59f50,24d7b89ae9522ae60d2317984951355b,6fe27f9eb76cf2ddf712a2cee5783d1c,81c504ffbcc5ed882e234802135295ba,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="GSM-HARD">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">GSM-Hard is a math task benchmark dataset, discussed by Gao et al. in 2023.
GSM-Hard is a dataset used to evaluate the transferability of discovered agents from MGSM math tasks to more challenging math tasks, showing significant improvement in accuracy rate.
GSM-Hard is a dataset used for evaluating the performance of algorithms in more challenging math-related tasks.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="FM">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Foundation Models (FMs) are large language models increasingly proficient in coding, used as meta agents in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="LU ET AL., 2024A">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lu et al. are the authors of a study in 2024a discussing learned loss functions in LLM alignment.
Lu et al. are the authors of research on DiscoPOP, published in 2024.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="LU ET AL., 2024B">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lu et al. are the authors of a study in 2024b introducing the AI Scientist.
Lu et al. are authors referenced in the text, known for their work published in 2024 related to subjective answer evaluations in ADAS.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="LU ET AL., 2024C">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lu et al. are the authors of a study in 2024c discussing open-endedness algorithms that leverage human notions of interestingness.
Lu et al. are the authors of an open-endedness algorithm that leverages human notions of interestingness, published in 2024, which is referenced in the Meta Agent Search algorithm.
Lu et al. are researchers who developed the Quality-Diversity method in 2024.
Lu et al. are the authors of the Quality-Diversity algorithm, published in 2024.
Lu et al. are the authors of the Quality-Diversity algorithm, published in 2024.
Lu et al. are the authors of the Quality-Diversity algorithm, published in 2024.
Lu et al. are the authors of research on Quality-Diversity, published in 2024.
Lu et al. are the authors of the Quality-Diversity algorithm, published in 2024.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="ZHANG ET AL., 2024A">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhang et al. are the authors of a study in 2024a discussing open-endedness algorithms that leverage human notions of interestingness.
Zhang et al. are the authors of an open-endedness algorithm that leverages human notions of interestingness, published in 2024, which is referenced in the Meta Agent Search algorithm.
Zhang et al. are researchers who have contributed to prior works on open-endedness and AI-GAs, which are critical in Meta Agent Search.
Zhang et al. are authors referenced in the text, known for their work published in 2024 related to open-ended algorithms.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,6bdf681c0bd9e401ac72344a6a0ae479,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="FERNANDO ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fernando et al. are the authors of a study in 2024 focusing on designing prompts in ADAS methods.
Fernando et al. are the authors of works like PromptBreeder and other contributions to the ADAS research area, published in 2024.
Fernando et al. are the authors of the PromptBreeder algorithm, published in 2024.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="YANG ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yang et al. are the authors of a study in 2024 focusing on designing prompts in ADAS methods.
Yang et al. are the authors of the OPRO algorithm, published in 2024.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="BOYER &amp; MOORE, 1983">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Boyer and Moore are the authors of a study in 1983 discussing the Turing Completeness of programming languages.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="LADHA, 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ladha is the author of a study in 2024 discussing the Turing Completeness of programming languages.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="ELSKEN ET AL., 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Elsken et al. are the authors of a study in 2019 discussing Neural Architecture Search (NAS).
Elsken et al. are authors who contributed to the method of Neural Architecture Search, published in 2019.
Elsken et al. are the authors of research on Neural Architecture Search, published in 2019.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="RAFAILOV ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rafailov et al. are the authors of a study in 2024 discussing DPO, a hand-designed loss function.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="FALDOR ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Faldor et al. are the authors of a study in 2024 discussing OMNI-EPIC, a system for generating robotics learning environments.
Faldor et al. are researchers who have worked on open-endedness and AI-GAs, which are critical in prior works related to Meta Agent Search.
Faldor et al. are the authors of research on OMNI-EPIC, published in 2024.
Faldor et al. are the authors of the OMNI-EPIC algorithm, published in 2024.
Faldor et al. are authors referenced in the text, known for their work published in 2024 related to open-ended algorithms.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="CHOLLET, 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chollet is the author of a study in 2019 introducing the ARC logic puzzle task.
Chollet is the author of the ARC logic puzzle task, published in 2019, which is used as a benchmark in the experiments.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="DUA ET AL., 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dua et al. are the authors of a study in 2019 discussing the DROP reading comprehension benchmark.
Dua et al. are the authors of the DROP benchmark, published in 2019, which is used to assess the reading comprehension abilities of the discovered agents.
Dua et al. are the authors of the DROP benchmark, published in 2019.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="SHI ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shi et al. are the authors of a study in 2023 discussing the MGSM math task benchmark.
Shi et al. are the authors of the MGSM benchmark, published in 2023, which is used to evaluate the math abilities of the discovered agents.
Shi et al. are the authors of the MGSM benchmark, published in 2023.
Shi et al. are the authors associated with the discovery of the Verified Multimodal Agent in the Math domain, published in 2023.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="AGENTIC SYSTEMS">
      <data key="d0">SYSTEM, TECHNOLOGY</data>
      <data key="d1">Agentic systems are systems designed to perform tasks autonomously, often involving complex decision-making and interactions.
Agentic systems involve Foundation Models (FMs) as modules in the control flow to solve tasks by planning, using tools, and carrying out multiple, iterative steps of processing.
Agentic systems are machine learning systems that operate primarily over natural language, designed to perform tasks and interact with environments in a manner interpretable to humans.
Agentic Systems refer to systems designed to perform tasks autonomously, as discussed in the context of automated design.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="BUILDING BLOCKS">
      <data key="d0">COMPONENT, TECHNOLOGY</data>
      <data key="d1">Building blocks are fundamental components used to construct agentic systems, which can be automatically discovered and combined in ADAS.
Building blocks are fundamental components or design patterns that can be combined and optimized to create more complex agentic systems.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="FOUNDATION MODELS">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Foundation Models (FMs) are large language models that are proficient in coding and can be used as meta agents in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="ARC LOGIC PUZZLE TASK">
      <data key="d0">BENCHMARK, TASK</data>
      <data key="d1">The ARC logic puzzle task is a benchmark designed to test the general intelligence of AI systems, introduced by Chollet in 2019.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="READING COMPREHENSION">
      <data key="d0">TASK, BENCHMARK</data>
      <data key="d1">Reading comprehension tasks are benchmarks used to evaluate the understanding and interpretation of text by AI systems.
Reading comprehension is a domain in which agentic systems can be applied and evaluated for performance.
Reading comprehension is a domain tested by Meta Agent Search using the DROP benchmark to evaluate the understanding of written text.
Reading Comprehension is a domain where foundational models possess adequate knowledge to solve questions, and errors are mainly due to hallucinations or calculation mistakes.
Reading Comprehension is a non-math domain where the performance of agents is evaluated.
Reading comprehension is a skill that involves understanding and interpreting written text. It is one of the skills taught to language models using synthetic data generated by AgentInstruct.
Reading comprehension involves processing and understanding text, necessary for learning and encompassing decoding, fluency, and vocabulary knowledge.
Reading comprehension is a critical skill involving processing and understanding text, which is necessary for learning and encompasses decoding, fluency, and vocabulary knowledge. It enables scenarios like question answering, search, and grounded reasoning.
Reading comprehension is a crucial capability for language models, especially Small Language Models (SLMs), and is evaluated through targeted training with AgentInstruct.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,0c212c1467564ad33330b1f655a8e27e,2901d5e2711fa4f32d39cd8eea36cd71,4884e8429ca1e567dadf5e22b4b68274,6fe27f9eb76cf2ddf712a2cee5783d1c,81c504ffbcc5ed882e234802135295ba,86f77e15d41cbd0cb33f635ccb2cb66b,bc26e68b0b2783ba912b9e5606d9eb0b,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="MATH TASKS">
      <data key="d0">TASK, BENCHMARK</data>
      <data key="d1">Math tasks are benchmarks used to evaluate the mathematical problem-solving abilities of AI systems.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="SCIENCE QUESTIONS">
      <data key="d0">TASK, BENCHMARK</data>
      <data key="d1">Science questions are benchmarks used to evaluate the scientific knowledge and reasoning abilities of AI systems.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="MULTI-TASK PROBLEM SOLVING">
      <data key="d0">TASK, BENCHMARK</data>
      <data key="d1">Multi-task problem solving involves benchmarks that test the ability of AI systems to solve a variety of tasks across different domains.
Multi-task problem solving is a domain tested by Meta Agent Search using the MMLU benchmark to evaluate the ability to solve various types of problems.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="TRANSFERABILITY">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">Transferability refers to the ability of discovered agents to perform well across different domains and tasks, demonstrating robustness and adaptability.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="F1 SCORE">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">F1 score is a metric used to evaluate the accuracy of a model, particularly in reading comprehension tasks.
F1 score is a performance metric used to evaluate the effectiveness of the generated agents in the Meta Agent Search algorithm, particularly in reading comprehension tasks.
F1 Score is a metric used to evaluate the performance of agents in tasks such as reading comprehension and math, representing the balance between precision and recall.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="ACCURACY RATE">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">Accuracy rate is a metric used to evaluate the correctness of a model's predictions, particularly in math tasks.
Accuracy rate is a performance metric used to evaluate the effectiveness of the generated agents in the Meta Agent Search algorithm, particularly in math tasks.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="BENCHMARK">
      <data key="d0">CONCEPT, EVALUATION</data>
      <data key="d1">A benchmark is a standard or set of standards used to evaluate the performance of AI systems across various tasks and domains.
A benchmark is a standard or metric used to evaluate the performance of the Meta Agent Search algorithm. Examples include ARC, DROP, and MGSM.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="HAND-DESIGNED BASELINES">
      <data key="d0">CONCEPT, EVALUATION</data>
      <data key="d1">Hand-designed baselines are manually created models or algorithms used as a reference point to evaluate the performance of automated systems like those in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="OPEN-ENDEDNESS ALGORITHMS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Open-endedness algorithms are methods that encourage the exploration of novel and interesting solutions, often leveraging human notions of interestingness.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="INTERESTINGNESS">
      <data key="d0">CONCEPT, EVALUATION</data>
      <data key="d1">Interestingness refers to the quality of being novel or worthwhile, used as a criterion in open-endedness algorithms to guide the exploration of new agents.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="ARCHIVE">
      <data key="d0">COMPONENT, SYSTEM</data>
      <data key="d1">An archive is a storage system used in Meta Agent Search to keep discovered agents, aiding the meta agent in creating more interesting agents in subsequent iterations.
The archive is a storage system in the Meta Agent Search algorithm that holds previous discoveries and evaluation metrics. It is updated at every iteration with new agents and their performance metrics.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="ITERATION">
      <data key="d0">CONCEPT, PROCESS</data>
      <data key="d1">Iteration refers to the repeated process of creating, evaluating, and refining agents in Meta Agent Search to discover more effective agentic systems.
Iteration is a process in the Meta Agent Search algorithm where the meta agent continuously programs new agents, evaluates them, and updates the archive until the maximum number of iterations is reached.
Iteration in Meta Agent Search refers to the repeated cycles of discovering and refining agents to improve performance.
Iteration is a process where agents repeatedly refine and improve solutions to create higher quality data.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,6fe27f9eb76cf2ddf712a2cee5783d1c,81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="CODE SPACE">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">Code space refers to the domain of possible programs that can be generated and explored by ADAS algorithms to discover new agentic systems.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="CONTROL FLOWS">
      <data key="d0">COMPONENT, TECHNOLOGY</data>
      <data key="d1">Control flows are the sequences of operations or decisions within a program, a component that can be discovered in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="AGENTIC SYSTEM DESIGN">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">Agentic system design involves the creation and optimization of systems that can perform tasks autonomously, a key focus of ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="RESEARCH COMMUNITY">
      <data key="d0">GROUP, ORGANIZATION</data>
      <data key="d1">The research community refers to the collective group of researchers and scientists working on advancing the field of AI and agentic systems.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="EXISTING WORKS">
      <data key="d0">CONCEPT, RESEARCH</data>
      <data key="d1">Existing works refer to previous studies and methods that have contributed to the field of ADAS, often focusing on specific components like prompts.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, RESEARCH</data>
    </node>
    <node id="FLEXIBLE DESIGN PATTERNS">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">Flexible design patterns refer to adaptable and reusable solutions in agentic system design, which can be automatically discovered in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, TECHNOLOGY</data>
    </node>
    <node id="META AGENT PROGRAMMING">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">Meta agent programming involves the use of a meta agent to create and optimize other agents in an automated manner, a key approach in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, TECHNOLOGY</data>
    </node>
    <node id="NOVEL AGENTS">
      <data key="d0">COMPONENT, TECHNOLOGY</data>
      <data key="d1">Novel agents are newly discovered or created agents that exhibit unique or improved behaviors, often generated by meta agents in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">COMPONENT, TECHNOLOGY</data>
    </node>
    <node id="ROBUSTNESS">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">Robustness refers to the ability of agentic systems to maintain performance across different and challenging domains, demonstrating their reliability and adaptability.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, METRIC</data>
    </node>
    <node id="DOMAIN TRANSFER">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">Domain transfer involves the ability of agentic systems to apply learned knowledge and skills from one domain to another, a key aspect of ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, TECHNOLOGY</data>
    </node>
    <node id="SIMILAR DOMAINS">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">Similar domains refer to areas or tasks that share common characteristics, making it easier for agentic systems to transfer knowledge and skills between them.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, TECHNOLOGY</data>
    </node>
    <node id="DISSIMILAR DOMAINS">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">Dissimilar domains refer to areas or tasks that are significantly different, posing a greater challenge for agentic systems to transfer knowledge and skills between them.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, TECHNOLOGY</data>
    </node>
    <node id="MATHEMATICS">
      <data key="d0">DOMAIN, TASK</data>
      <data key="d1">Mathematics is a domain involving numerical and logical problem-solving tasks, often used as a benchmark for evaluating agentic systems.
Mathematics is a domain in which agentic systems can be applied and evaluated for performance.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">DOMAIN, TASK</data>
    </node>
    <node id="READING COMPREHENSION TASKS">
      <data key="d0">TASK, BENCHMARK</data>
      <data key="d1">Reading comprehension tasks are benchmarks used to evaluate the understanding and interpretation of text by AI systems.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">TASK, BENCHMARK</data>
    </node>
    <node id="SCIENCE">
      <data key="d0">DOMAIN, TASK</data>
      <data key="d1">Science is a domain involving the study of the natural world, often used as a benchmark for evaluating agentic systems.
Science is a domain tested by Meta Agent Search using the GPQA benchmark to evaluate the ability to solve complex scientific questions.
Science is a domain where Meta Agent Search outperforms baselines, although the gap is smaller compared to other domains.
Science is a non-math domain where the performance of agents is evaluated.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71,81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
      <data key="d3">DOMAIN, TASK</data>
    </node>
    <node id="MULTI-TASKING">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">Multi-tasking refers to the ability of agentic systems to handle multiple tasks simultaneously or in sequence, demonstrating their versatility and efficiency.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, TECHNOLOGY</data>
    </node>
    <node id="GENERAL INTELLIGENCE">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">General intelligence refers to the overall cognitive ability of AI systems to understand, learn, and apply knowledge across a wide range of tasks and domains.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, TECHNOLOGY</data>
    </node>
    <node id="AI SYSTEMS">
      <data key="d0">SYSTEM, TECHNOLOGY</data>
      <data key="d1">AI systems are computational systems designed to perform tasks that typically require human intelligence, such as learning, reasoning, and problem-solving.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">SYSTEM, TECHNOLOGY</data>
    </node>
    <node id="HAND-DESIGNED AGENTS">
      <data key="d0">COMPONENT, TECHNOLOGY</data>
      <data key="d1">Hand-designed agents are manually created AI systems, often used as baselines to compare the performance of automated systems like those in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">COMPONENT, TECHNOLOGY</data>
    </node>
    <node id="LEARNED AGENTS">
      <data key="d0">COMPONENT, TECHNOLOGY</data>
      <data key="d1">Learned agents are AI systems that are automatically discovered and optimized through methods like ADAS, often outperforming hand-designed agents.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">COMPONENT, TECHNOLOGY</data>
    </node>
    <node id="RESEARCH QUESTION">
      <data key="d0">CONCEPT, RESEARCH</data>
      <data key="d1">A research question is a specific query that guides the investigation and exploration of new ideas and methods in a study, such as the automation of agentic system design in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, RESEARCH</data>
    </node>
    <node id="EVIDENCE">
      <data key="d0">CONCEPT, RESEARCH</data>
      <data key="d1">Evidence refers to the data and findings that support the effectiveness and validity of a proposed method or approach, such as the performance of learned agents in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, RESEARCH</data>
    </node>
    <node id="DISCOVERY">
      <data key="d0">CONCEPT, PROCESS</data>
      <data key="d1">Discovery refers to the process of finding new and useful components or agents in ADAS, often through automated methods and meta agent programming.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, PROCESS</data>
    </node>
    <node id="COMBINATION">
      <data key="d0">CONCEPT, PROCESS</data>
      <data key="d1">Combination refers to the process of integrating different building blocks to create effective agentic systems, a key challenge in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, PROCESS</data>
    </node>
    <node id="INTERACTION">
      <data key="d0">CONCEPT, PROCESS</data>
      <data key="d1">Interaction refers to the ways in which different components or agents work together within an agentic system, influencing its overall performance and effectiveness.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, PROCESS</data>
    </node>
    <node id="CREATIVITY">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">Creativity refers to the ability of AI systems to generate novel and valuable ideas or solutions, demonstrated by systems like OMNI-EPIC in generating robotics learning environments.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, METRIC</data>
    </node>
    <node id="HUMAN EFFORT">
      <data key="d0">CONCEPT, METRIC</data>
      <data key="d1">Human effort refers to the manual work required to design and develop agentic systems, which ADAS aims to reduce through automation.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, METRIC</data>
    </node>
    <node id="CHALLENGE">
      <data key="d0">CONCEPT, TASK</data>
      <data key="d1">A challenge is a difficult task or problem that requires innovative solutions, often addressed through the discovery and combination of building blocks in ADAS.A challenge is a difficult task or problem that requires innovative solutions, often addressed through the discovery and combination</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
      <data key="d3">CONCEPT, TASK</data>
    </node>
    <node id="RESEARCH AREA">
      <data key="d0">CONCEPT, RESEARCH</data>
      <data key="d1">A research area is a field of study focused on exploring and advancing specific topics, such as the Automated Design of Agentic Systems (ADAS).</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="INITIAL EVIDENCE">
      <data key="d0">CONCEPT, RESEARCH</data>
      <data key="d1">Initial evidence refers to the preliminary data and findings that suggest the potential effectiveness of a proposed method or approach, such as the performance of learned agents in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="USEFUL BUILDING BLOCKS">
      <data key="d0">COMPONENT, TECHNOLOGY</data>
      <data key="d1">Useful building blocks are fundamental components that are effective in constructing agentic systems, often discovered through automated methods in ADAS.</data>
      <data key="d2">81c504ffbcc5ed882e234802135295ba</data>
    </node>
    <node id="SEARCH SPACE">
      <data key="d0">COMPONENT</data>
      <data key="d1">The search space in ADAS defines which agentic systems can be represented and thus discovered. It can include various structures like text prompts, graph structures, and feed-forward networks.
Search space refers to the range of possible configurations and components that can be explored and optimized in agentic systems.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="EVALUATION FUNCTION">
      <data key="d0">COMPONENT</data>
      <data key="d1">The evaluation function in ADAS defines how to evaluate a candidate agent on target objectives such as performance, cost, latency, or safety.
A function used to evaluate the performance of discovered agents, which can be optimized to reduce costs and improve efficiency.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="PROMPTBREEDER">
      <data key="d0">ALGORITHM</data>
      <data key="d1">PromptBreeder is an algorithm that mutates the text prompts of an agent while keeping other components, such as control flow, the same. It is used within the search space of ADAS.
PromptBreeder is an algorithm developed by Fernando et al., 2024, that adopts FMs to automate prompt engineering for agents, focusing on the phrasing of instructions in the prompt to enhance reasoning capability.
A research paper titled "Promptbreeder: Self-referential self-improvement via prompt evolution" authored by Chrisantha Fernando et al., published in 2024.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,4884e8429ca1e567dadf5e22b4b68274,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="ZHUGE ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhuge et al. are the authors of works exploring search spaces such as graph structures and using reinforcement learning as search algorithms in ADAS, published in 2024.
Zhuge et al. are the authors of the GPT-Swarm algorithm, published in 2024.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="SUTTON &amp; BARTO, 2018">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sutton &amp; Barto are the authors who discussed the exploration-exploitation trade-off, which is considered in the search algorithms of ADAS, published in 2018.
Sutton &amp; Barto are authors referenced in the text, known for their work published in 2018 related to balancing exploration and exploitation in search algorithms.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="AI-GAS">
      <data key="d0">RESEARCH AREA</data>
      <data key="d1">AI-GAs (Artificial Intelligence-Generative Algorithms) is a research area similar to ADAS, focusing on the automated design and optimization of algorithms.
A research paper titled "Ai-gas: Ai-generating algorithms, an alternate paradigm for producing general artificial intelligence" authored by Jeff Clune, published as an arXiv preprint in 2019.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="CHASE, 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chase is an author who contributed to the definitions and terminologies of agentic systems, published in 2024.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="NG, 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ng is an author who contributed to the definitions and terminologies of agentic systems, published in 2024.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="SEARCH ENGINE TOOLS">
      <data key="d0">TECHNOLOGY, TOOL</data>
      <data key="d1">Search engine tools are components that can be used within the LangChain framework to enhance agentic systems.
Search engine tools are existing human efforts that can be used as building blocks in ADAS to improve efficiency and performance.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="COST">
      <data key="d0">OBJECTIVE</data>
      <data key="d1">Cost is an objective used in the evaluation function of ADAS to assess the economic efficiency of agentic systems.
Cost is a limitation referring to the resource-intensive nature of generating synthetic data with multiple agents using large language models and tools.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274,ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="LATENCY">
      <data key="d0">OBJECTIVE</data>
      <data key="d1">Latency is an objective used in the evaluation function of ADAS to assess the response time of agentic systems.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="SAFETY">
      <data key="d0">OBJECTIVE</data>
      <data key="d1">Safety is an objective used in the evaluation function of ADAS to assess the reliability and security of agentic systems.</data>
      <data key="d2">4884e8429ca1e567dadf5e22b4b68274</data>
    </node>
    <node id="FMS">
      <data key="d0">TECHNOLOGY, TOOL</data>
      <data key="d1">Foundational Models (FMs) are used as meta agents in the Meta Agent Search algorithm to program new agents. They provide essential functions such as querying and formatting prompts.
Foundation Models (FMs) are advanced language models used for various tasks, including programming loss functions for preference learning, writing reward functions for reinforcement learning, and creating robotics learning environments.
FMs (Foundational Models) are powerful models used in ADAS to program agentic systems without the need for expensive hardware like GPUs.
FMs refer to foundational models, which are large-scale machine learning models that can be adapted to a wide range of tasks.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,6bdf681c0bd9e401ac72344a6a0ae479,7de66b94cf868b37b1df51dc545c415f,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="FUNSEARCH">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">FunSearch is an algorithm mentioned as a reference for the practice of defining a "forward" function to create new agentic systems. It is used as a comparison point for Meta Agent Search.
FunSearch is an algorithm where Foundation Models write code to discover better optimization algorithms.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="CHAIN-OF-THOUGHT (COT)">
      <data key="d0">METHOD, STRATEGY</data>
      <data key="d1">Chain-of-Thought (COT) is a strategy used in Meta Agent Search to generate possible answers, refine them, and ensemble the best answers. It involves using multiple COTs for enhanced refinement.
Chain-of-Thought (COT) is a method that instructs the agent to output the reasoning before answering to improve complex problem-solving through intermediate steps.
Chain-of-Thought (COT) is a state-of-the-art hand-designed agent baseline used for experiments on ARC.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="LLM DEBATE">
      <data key="d0">METHOD, STRATEGY</data>
      <data key="d1">LLM Debate is a strategy mentioned in the context of Meta Agent Search, involving the use of multiple critics for enhanced refinement of generated agents.
LLM Debate (Du et al., 2023) is a state-of-the-art hand-designed agent used for reasoning and problem-solving tasks.
LLM Debate is a manually designed agent used for planning and reasoning in various domains, including math.
LLM Debate is a manually designed agent used for tasks like math, reading comprehension, multi-tasking, and science, with specific accuracy and F1 scores reported.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="QUALITY-DIVERSITY">
      <data key="d0">METHOD, STRATEGY</data>
      <data key="d1">Quality-Diversity is a strategy used in Meta Agent Search to encourage the exploration of novel or worthwhile agents based on an ever-growing archive of previous discoveries.
Quality-Diversity is a simplified version of Intelligent Go-Explore that produces and ensembles diverse answers to better explore potential solutions.
Quality-Diversity (Lu et al., 2024c) is a state-of-the-art hand-designed agent used for reasoning and problem-solving tasks.
Quality-Diversity is a manually designed agent used for planning and reasoning in various domains, including math.
Quality-Diversity is a manually designed agent used for tasks like math, reading comprehension, multi-tasking, and science, with specific accuracy and F1 scores reported.
Quality-Diversity is a concept in search algorithms that aims to balance the exploration of diverse solutions with the quality of those solutions.
Quality-Diversity is a simplified version of Intelligent Go-Explore, used as a state-of-the-art hand-designed agent baseline for experiments on ARC, developed by Lu et al. (2024c).
Quality-Diversity is a method that conducts three iterations to collect diverse answers based on previously proposed ones.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="ROMERA-PAREDES ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Romera-Paredes et al. are the authors of the FunSearch algorithm, published in 2024, which is referenced in the Meta Agent Search algorithm.
Romera-Paredes et al. are the authors of research on FunSearch, published in 2024.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="FORWARD FUNCTION">
      <data key="d0">FUNCTION, METHOD</data>
      <data key="d1">The forward function is a component in the Meta Agent Search algorithm that defines a new agentic system. It takes in task information and outputs the agent&#8217;s response to the task.
A function in the Agent System that processes task information and returns either a namedtuple Info or a string as the answer.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="VALIDATION DATA">
      <data key="d0">DATA, METRIC</data>
      <data key="d1">Validation data is used to evaluate the performance of the generated agents in the Meta Agent Search algorithm. Metrics such as success rate or F1 score are calculated to assess performance.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="BOOTSTRAP CONFIDENCE INTERVAL">
      <data key="d0">METRIC, STATISTIC</data>
      <data key="d1">The bootstrap confidence interval is a statistical measure used to evaluate the performance of the generated agents in the Meta Agent Search algorithm.
The bootstrap confidence interval is used to report the median accuracy and variability of agent performance in Meta Agent Search.
Bootstrap confidence interval is a statistical method used to report the test accuracy and confidence in the performance results of Meta Agent Search.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="EXPERIMENT">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">Experiments are conducted to evaluate the performance of the Meta Agent Search algorithm on various benchmarks and tasks, such as ARC, reading comprehension, and math tasks.
</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="DYNAMIC MEMORY">
      <data key="d0">TECHNOLOGY, TOOL</data>
      <data key="d1">Dynamic memory is a feature introduced in Meta Agent Search to allow for more refinements during the programming of new agents.
Dynamic memory is introduced for doing more refinements in the Meta Agent Search process.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="ENSEMBLING">
      <data key="d0">METHOD, STRATEGY</data>
      <data key="d1">Ensembling is a strategy used in Meta Agent Search to combine multiple answers generated by the Chain-of-Thought strategy to produce the best answer.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="CRITIC">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">A critic is an entity in the Meta Agent Search algorithm used to provide feedback and enhance the refinement of generated agents. Multiple critics can be used for better results.
A method used to review and criticize answers to ensure their correctness.
Critic is a role assigned to modules in methods like Self-Refine to review answers and provide feedback on their correctness.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,4b43decac6833d1515992f8869ecada7,97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="EFFICIENCY EXPERT">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">An efficiency expert is a type of critic in the Meta Agent Search algorithm that focuses on improving the efficiency of the generated agents.
An efficiency expert provides feedback on the efficiency of answers in the Meta Agent Search process.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="READABILITY EXPERT">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">A readability expert is a type of critic in the Meta Agent Search algorithm that focuses on improving the readability of the generated agents.
A readability expert provides feedback on the readability of answers in the Meta Agent Search process.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b</data>
    </node>
    <node id="SIMPLICITY">
      <data key="d0">ATTRIBUTE, QUALITY</data>
      <data key="d1">Simplicity is an attribute or quality that the Meta Agent Search algorithm aims to achieve in the generated agents, often evaluated by critics like the readability expert.
Simplicity is a specific trait evaluated by experts in the feedback mechanism of ADAS, focusing on how straightforward and uncomplicated a task or solution is.</data>
      <data key="d2">24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="ARC CHALLENGE">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">The Abstraction and Reasoning Corpus (ARC) challenge aims to evaluate the general intelligence of AI systems through their ability to efficiently acquire new skills. It involves tasks such as learning transformation rules of grid patterns from examples and predicting output grid patterns given test input grid patterns.
The ARC Challenge is a benchmark used to demonstrate the proficiency of agentic systems in in-context learning, relevant to the ADAS research area.
The ARC Challenge is a benchmark used for evaluating the performance of agentic systems in reasoning and problem-solving domains.
A challenge that involves learning transformation rules from input-output grid examples to predict the output grid for a test example.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,4b43decac6833d1515992f8869ecada7,7c08d98f503d722d7de13be55375c8cb,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SELF-CONSISTENCY WITH CHAIN-OF-THOUGHT (COT-SC)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Self-Consistency with Chain-of-Thought (COT-SC) is a method that ensembles multiple parallel answers from COT to produce a more accurate answer.
Self-Consistency with Chain-of-Thought (COT-SC) is a state-of-the-art hand-designed agent baseline used for experiments on ARC.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="LLM-DEBATE">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">LLM-Debate is a method that enables different language models to debate with each other, leveraging diverse perspectives to find better answers.
LLM-Debate is a state-of-the-art hand-designed agent baseline used for experiments on ARC, developed by Du et al. (2023).
LLM-Debate is a method where each debate module is assigned a unique role, such as Physics Expert or Chemistry Expert, and the debate lasts for two rounds.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="ENSEMBLE">
      <data key="d0">PROCESS, MECHANISM</data>
      <data key="d1">Ensemble in Meta Agent Search refers to the process of combining multiple answers to produce a final, more accurate answer.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="TRANSFORMATION RULE">
      <data key="d0">CONCEPT, TASK</data>
      <data key="d1">A transformation rule in the ARC challenge is the rule that the AI system learns from examples to transform input grid patterns into output grid patterns.
A rule learned from example input-output grids to predict the output grid for a test example in the ARC challenge.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="GREENBLATT, 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Greenblatt is a researcher who followed common practice in requiring the agent to write code for the transformation rule instead of answering directly in the ARC challenge.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="LEHMAN &amp; STANLEY, 2011">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lehman &amp; Stanley are researchers who have contributed to prior works on open-endedness and AI-GAs, which are critical in Meta Agent Search.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="WANG ET AL., 2019, 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang et al. are researchers who have contributed to prior works on open-endedness and AI-GAs, which are critical in Meta Agent Search.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="MULTIPLE CRITICS">
      <data key="d0">ROLE, FUNCTION</data>
      <data key="d1">Multiple critics are introduced for enhanced refinement in the Meta Agent Search process.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="META-AGENT">
      <data key="d0">ROLE, FUNCTION</data>
      <data key="d1">The meta-agent in Meta Agent Search is responsible for discovering high-performance agents based on an archive of previous discoveries.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="HUMAN-LIKE CRITIC">
      <data key="d0">ROLE, FUNCTION</data>
      <data key="d1">A human-like critic provides feedback in the Meta Agent Search process to simulate human evaluation.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="SIMPLICITY EXPERT">
      <data key="d0">ROLE, FUNCTION</data>
      <data key="d1">A simplicity expert provides feedback on the simplicity of answers in the Meta Agent Search process.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="FEEDBACK EFFICIENCY">
      <data key="d0">PROCESS, MECHANISM</data>
      <data key="d1">Feedback efficiency refers to the effectiveness of feedback in refining answers in the Meta Agent Search process.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="REFINEMENT">
      <data key="d0">PROCESS, MECHANISM</data>
      <data key="d1">Refinement in Meta Agent Search involves improving answers through iterative feedback and evaluation.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="HELD-OUT TEST SET">
      <data key="d0">DATASET, BENCHMARK</data>
      <data key="d1">The held-out test set is used to evaluate the performance of discovered agents in Meta Agent Search.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="PUBLIC TRAINING SET (EASY)">
      <data key="d0">DATASET, BENCHMARK</data>
      <data key="d1">The Public Training Set (Easy) is a dataset with grid dimensions &#8804;5&#215;5 used for training agents in the ARC challenge.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="VALIDATION SET">
      <data key="d0">DATASET, BENCHMARK</data>
      <data key="d1">The validation set is used to assess the performance of agents during the Meta Agent Search process.
A subset of data used to validate the performance of agents and models.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="TEST SET">
      <data key="d0">DATASET, BENCHMARK</data>
      <data key="d1">The test set is used to evaluate the final performance of agents discovered in Meta Agent Search.
A subset of data used to test the performance of agents and models.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="STOCHASTIC SAMPLING">
      <data key="d0">PROCESS, MECHANISM</data>
      <data key="d1">Stochastic sampling is used to reduce variance in the evaluation of agents in Meta Agent Search.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="TOOL FUNCTIONS">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">Tool functions are provided in the framework to evaluate the generated transformation code in the ARC challenge.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="ARC QUESTIONS">
      <data key="d0">DATASET, BENCHMARK</data>
      <data key="d1">ARC questions involve tasks such as learning transformation rules of grid patterns and predicting output grid patterns given test input grid patterns.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="APPENDIX C">
      <data key="d0">DOCUMENT, SECTION</data>
      <data key="d1">Appendix C contains detailed implementation of the best-discovered agent and more algorithmic details and examples of ARC questions.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7</data>
    </node>
    <node id="APPENDIX E">
      <data key="d0">DOCUMENT, SECTION</data>
      <data key="d1">Appendix E contains more details about the baselines used in Meta Agent Search.
Appendix E contains more details about the baselines used in Meta Agent Search.</data>
      <data key="d2">1a6353c9d196dc2debad7c27c902bcd7,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="STEPPING STONES">
      <data key="d0">CONCEPT, COMPONENT</data>
      <data key="d1">Stepping stones refer to intermediate innovations or ideas that contribute to the final sophisticated feedback mechanism in ADAS, including diverse feedback, efficiency and simplicity evaluation, and human-like feedback simulation.</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="MEYERSON ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Meyerson et al. are researchers who contributed to the concept of combining different stepping stones, resembling crossover in evolution via LLMs.</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="MMLU">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">MMLU (Hendrycks et al., 2021) is a benchmark used for evaluating multi-task problem solving capabilities of agents.
MMLU (Massive Multitask Language Understanding) is a benchmark that assesses a model&#8217;s ability to answer questions across a wide range of subjects and difficulty levels.
MMLU is a benchmark used to evaluate the performance of language models. Orca-3 shows a 19% improvement on this benchmark compared to Mistral-7b-Instruct.
MMLU is a benchmark used to evaluate the performance of AI models. Orca-3 showed a 19% improvement on MMLU compared to Mistral-Instruct-7B.
A benchmark used to evaluate models, with Orca-3 scoring 69.95, which is a 19% improvement over Orca-2.5.
Massive Multitask Language Understanding (MMLU) is a benchmark that measures a model&#8217;s multitask understanding across 57 academic subjects with approximately 16000 multiple-choice questions.
MMLU is a benchmark used to evaluate AI models on various levels of mathematics, including abstract algebra, college mathematics, and high-school mathematics.
MMLU is one of the datasets included in the MIRAGE benchmark, used to evaluate model performance.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bc26e68b0b2783ba912b9e5606d9eb0b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="GPQA">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">GPQA (Rein et al., 2023) is a benchmark used for evaluating the capability of solving hard (graduate-level) questions in science.
A dataset used for evaluating agents in the Science domain, consisting of validation and test sets.
GPQA (Graduate-Level Google-Proof Q&amp;A Benchmark) is a benchmark consisting of challenging multiple-choice questions across the domains of biology, physics, and chemistry.
GPQA is the Reading Comprehension domain where the Multi-Step Peer Review Agent was discovered by Meta Agent Search.
A benchmark used to evaluate models, with Orca-3 scoring 28.12, which is a 4% decrease compared to Orca-2.5.
Graduate-level Google-Proof Q&amp;A (GPQA) is a challenging benchmark of 448 high-quality and extremely difficult multiple-choice questions created by domain experts in biology, chemistry, and physics.
GPQA is a graduate-level google-proof Q&amp;A benchmark, published in 2023.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,3d1f6634f93f8a4c296dc8df7e59859e,84317ae35cc75d612287186d93461447,86f77e15d41cbd0cb33f635ccb2cb66b,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="STEP-BACK ABSTRACTION">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Step-back Abstraction (Zheng et al., 2023) is a state-of-the-art hand-designed agent that instructs agents to first consider the principles involved in solving the task for better reasoning.
Step-back Abstraction is a manually designed agent used for planning and reasoning in various domains, including math.
Step-back Abstraction is a manually designed agent used for tasks like math, reading comprehension, multi-tasking, and science, with specific accuracy and F1 scores reported.
Step-back Abstraction is a state-of-the-art hand-designed agent baseline used for experiments on Reasoning and Problem-Solving domains, developed by Zheng et al. (2023).
Step-back Abstraction is a method implemented for experiments on Reasoning and Problem-Solving domains, as described by Zheng et al., 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="ROLE ASSIGNMENT">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Role Assignment (Xu et al., 2023) is a state-of-the-art hand-designed agent that assigns different roles to FMs to obtain better answers.
Role Assignment is a manually designed agent used for planning and reasoning in various domains, including math.
Role Assignment is a manually designed agent used for tasks like math, reading comprehension, multi-tasking, and science, with specific accuracy and F1 scores reported.
Role Assignment is a state-of-the-art hand-designed agent baseline used for experiments on Reasoning and Problem-Solving domains, developed by Xu et al. (2023).
Role Assignment is a method implemented for experiments on Reasoning and Problem-Solving domains, as described by Xu et al., 2023. It involves using an FM query to choose a role from a predefined set and then answering the question by acting within the chosen role.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="HENDRYCKS ET AL., 2021">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hendrycks et al. are the authors of the MMLU benchmark, published in 2021.</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="REIN ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rein et al. are the authors of the GPQA benchmark, published in 2023.
Rein et al. are the authors associated with the discovery of the Multi-Step Peer Review Agent in the Reading Comprehension domain, published in 2023.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="ZHENG ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zheng et al. are the authors of the Step-back Abstraction algorithm, published in 2023.
Zheng et al. are the authors of the Step-back Abstraction algorithm, published in 2023.
Zheng et al. are the authors of research on Step-back Abstraction, published in 2023.
Zheng et al. are the authors of the Step-back Abstraction algorithm, published in 2023.
Zheng et al. are the authors of the Step-back Abstraction method, published in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="XU ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xu et al. are the authors of the Role Assignment algorithm, published in 2023.
Xu et al. are the authors of the Role Assignment algorithm, published in 2023.
Xu et al. are the authors of research on Role Assignment, published in 2023.
Xu et al. are the authors of the Role Assignment algorithm, published in 2023.
Xu et al. are the authors of the Role Assignment method, published in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="HUMAN-LIKE FEEDBACK">
      <data key="d0">FEEDBACK, MECHANISM</data>
      <data key="d1">Human-like feedback is a type of feedback simulated in the ADAS mechanism to resemble feedback given by humans.</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="ACCURACY">
      <data key="d0">METRIC, MEASUREMENT</data>
      <data key="d1">Accuracy is a metric used to evaluate the performance of agents in various domains, representing the proportion of correct predictions out of total predictions.
Accuracy is a limitation concerning the potential inaccuracies in synthetic data, which may not perfectly replicate the complexity and nuances of real-world data.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="EXPERIMENT SETTINGS">
      <data key="d0">CONFIGURATION, SETUP</data>
      <data key="d1">Experiment settings refer to the specific configurations and conditions under which Meta Agent Search and its baselines are tested, detailed in Appendix D and E.</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="APPENDIX D">
      <data key="d0">DOCUMENT, SECTION</data>
      <data key="d1">Appendix D contains more details about the datasets and experiment settings used in Meta Agent Search.</data>
      <data key="d2">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </node>
    <node id="FOUNDATIONAL MODELS (FMS)">
      <data key="d0">TECHNOLOGY, MODEL</data>
      <data key="d1">Foundational Models (FMs) are advanced models used to solve questions in various domains. Their effectiveness can be limited by the knowledge they possess, which impacts the performance of agentic systems like Meta Agent Search.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="CLAUDE-HAIKU">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Claude-Haiku is a foundational model developed by Anthropic, used to evaluate the performance of agents discovered by Meta Agent Search on the ARC benchmark.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="CLAUDE-SONNET">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Claude-Sonnet is a foundational model developed by Anthropic, noted for its high performance in evaluating agents discovered by Meta Agent Search on the ARC benchmark.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="CHAIN-OF-THOUGHT (WEI ET AL., 2022)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Chain-of-Thought is a manually designed agent developed by Wei et al. in 2022, used for reasoning tasks and evaluated on the ARC benchmark.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="COT-SC (WANG ET AL., 2023B)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">COT-SC is a manually designed agent developed by Wang et al. in 2023, used for reasoning tasks and evaluated on the ARC benchmark.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="LLM DEBATE (DU ET AL., 2023)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">LLM Debate is a manually designed agent developed by Du et al. in 2023, used for reasoning tasks and evaluated on the ARC benchmark.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="SELF-REFINE (MADAAN ET AL., 2024)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Self-Refine is a manually designed agent developed by Madaan et al. in 2024, used for reasoning tasks and evaluated on the ARC benchmark.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="QUALITY-DIVERSITY (LU ET AL., 2024C)">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Quality-Diversity is a manually designed agent developed by Lu et al. in 2024, used for reasoning tasks and evaluated on the ARC benchmark.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="STRUCTURED FEEDBACK AND ENSEMBLE AGENT">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Structured Feedback and Ensemble Agent is a top-performing agent discovered by Meta Agent Search, evaluated on the ARC benchmark and transferred to other foundational models.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="HIERARCHICAL COMMITTEE REINFORCEMENT AGENT">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Hierarchical Committee Reinforcement Agent is a top-performing agent discovered by Meta Agent Search, evaluated on the ARC benchmark and transferred to other foundational models.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="DYNAMIC MEMORY AND REFINEMENT AGENT">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Dynamic Memory and Refinement Agent is a top-performing agent discovered by Meta Agent Search, evaluated on the ARC benchmark and transferred to other foundational models.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="GSM8K (COBBE ET AL., 2021)">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">GSM8K is a math benchmark developed by Cobbe et al. in 2021, used to evaluate the performance of agents discovered by Meta Agent Search.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="GSM-HARD (GAO ET AL., 2023)">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">GSM-Hard is a math benchmark developed by Gao et al. in 2023, used to evaluate the performance of agents discovered by Meta Agent Search.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="SVAMP (PATEL ET AL., 2021)">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">SVAMP is a math benchmark developed by Patel et al. in 2021, used to evaluate the performance of agents discovered by Meta Agent Search.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="ASDIV (MIAO ET AL., 2020)">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">ASDiv is a math benchmark developed by Miao et al. in 2020, used to evaluate the performance of agents discovered by Meta Agent Search.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="MULTI-TASK">
      <data key="d0">DOMAIN, TASK</data>
      <data key="d1">Multi-task is a domain where Meta Agent Search outperforms baselines, although the gap is smaller compared to other domains.
Multi-task is a non-math domain where the performance of agents is evaluated.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="HALLUCINATIONS">
      <data key="d0">ERROR, ISSUE</data>
      <data key="d1">Hallucinations are errors that occur in foundational models, particularly in domains like Reading Comprehension and Math, which can be mitigated through well-designed agentic systems.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="CALCULATION MISTAKES">
      <data key="d0">ERROR, ISSUE</data>
      <data key="d1">Calculation mistakes are errors that occur in foundational models, particularly in domains like Reading Comprehension and Math, which can be mitigated through well-designed agentic systems.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="OPENAI, 2022">
      <data key="d0">AUTHOR, ORGANIZATION</data>
      <data key="d1">OpenAI is the organization that developed GPT-3.5, a foundational model used to evaluate the performance of agents discovered by Meta Agent Search.
OpenAI is the organization mentioned in the context of using GPT-3.5-turbo-0125 to evaluate discovered agents and baselines.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="ANTHROPIC, 2024A">
      <data key="d0">AUTHOR, ORGANIZATION</data>
      <data key="d1">Anthropic is the organization that developed Claude-Haiku, a foundational model used to evaluate the performance of agents discovered by Meta Agent Search.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="ANTHROPIC, 2024B">
      <data key="d0">AUTHOR, ORGANIZATION</data>
      <data key="d1">Anthropic is the organization that developed Claude-Sonnet, a foundational model used to evaluate the performance of agents discovered by Meta Agent Search.</data>
      <data key="d2">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="PATEL ET AL., 2021">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Patel et al. are the authors of the SVAMP benchmark, published in 2021.
Patel et al. are the authors of the SVAMP dataset, published in 2021.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="MIAO ET AL., 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Miao et al. are the authors of the ASDiv benchmark, published in 2020.
Miao et al. are the authors of the ASDiv dataset, published in 2020.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </node>
    <node id="SVAMP">
      <data key="d0">DATASET, BENCHMARK</data>
      <data key="d1">SVAMP is a dataset used for evaluating the performance of algorithms in various domains, particularly in math.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="ASDIV">
      <data key="d0">DATASET, BENCHMARK</data>
      <data key="d1">ASDiv is a dataset used for evaluating the performance of algorithms in various domains, particularly in math.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="DYNAMIC ROLE-PLAYING ARCHITECTURE">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Dynamic Role-Playing Architecture is a top agent discovered by Meta Agent Search, used for planning and reasoning in various math domains.
Dynamic Role-Playing Architecture is a top agent discovered by Meta Agent Search in the math domain, transferred to non-math domains with specific accuracy and F1 scores reported.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="STRUCTURED MULTIMODAL FEEDBACK LOOP">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Structured Multimodal Feedback Loop is a top agent discovered by Meta Agent Search, used for planning and reasoning in various math domains.
Structured Multimodal Feedback Loop is a top agent discovered by Meta Agent Search in the math domain, transferred to non-math domains with specific accuracy and F1 scores reported.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="INTERACTIVE MULTIMODAL FEEDBACK LOOP">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Interactive Multimodal Feedback Loop is a top agent discovered by Meta Agent Search, used for planning and reasoning in various math domains.
Interactive Multimodal Feedback Loop is a top agent discovered by Meta Agent Search in the math domain, transferred to non-math domains with specific accuracy and F1 scores reported.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="CHEN ET AL., 2023A">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chen et al. are the authors who contributed to the development of prompting techniques, published in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="SCHULHOFF ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Schulhoff et al. are the authors who contributed to the development of prompting techniques, published in 2024.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="CHAIN-OF-THOUGHT-BASED PLANNING AND REASONING METHODS">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Chain-of-thought-based planning and reasoning methods are important building blocks for agentic systems, used for planning and reasoning.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="EMBODIED AGENTS">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">Embodied agents are agents that interact with the physical world, often requiring the development of new skills.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="VEMPRALA ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Vemprala et al. are the authors who contributed to the development of new skills for embodied agents, published in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="NAKANO ET AL., 2021">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nakano et al. are the authors who contributed to the development of tool use techniques, published in 2021.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="FM MODULES">
      <data key="d0">COMPONENT, SYSTEM</data>
      <data key="d1">FM modules are components in agentic systems assigned with different roles to enable collaboration among agents.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="HONG ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hong et al. are the authors who contributed to the development of techniques for assigning FM modules in agentic systems, published in 2023.
Hong et al. are authors referenced in the text, known for their work published in 2023 related to incorporating organizational structures for human companies in agents.
Hong et al. are researchers who have incorporated organizational structures of human companies into agents in their work published in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64,6bdf681c0bd9e401ac72344a6a0ae479,7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="QIAN ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qian et al. are the authors who contributed to the development of techniques for assigning FM modules in agentic systems, published in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="QIAN ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qian et al. are the authors who contributed to the development of techniques for assigning FM modules in agentic systems, published in 2024.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="SELF-INSTRUCTION">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">Self-instruction is an important building block for agentic systems, enabling agents to instruct themselves for the next action.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="RICHARDS, 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Richards is the author who contributed to the development of self-instruction techniques, published in 2023.</data>
      <data key="d2">0b6b4880e77d40e284702da16be4ef64</data>
    </node>
    <node id="MAML">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">MAML stands for Model-Agnostic Meta-Learning, an algorithm that allows "learning to learn" for better sample efficiency, generalizability, and continuous learning of multiple tasks.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="META-RL">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Meta-RL stands for Meta-Reinforcement Learning, an algorithm that allows "learning to learn" for better sample efficiency, generalizability, and continuous learning of multiple tasks.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="POET">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">POET stands for Paired Open-Ended Trailblazer, an algorithm that aims to generate learning environments in an open-ended manner.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="EOH">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">EoH is an algorithm where Foundation Models write code to discover better optimization algorithms.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="DISCOPOP">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">DiscoPOP is an algorithm where Foundation Models program the loss function for preference learning in FM alignment training.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="EUREKA">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Eureka is an algorithm that enables Foundation Models to write reward functions for reinforcement learning in robotics.
Eureka is an algorithm developed by Ma et al., 2023, that enables FMs to write reward functions for reinforcement learning in robotics.
A research paper titled "Eureka: Human-level reward design via coding large language models," published in the Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,7c08d98f503d722d7de13be55375c8cb,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="LANGUAGE-TO-REWARD">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Language-to-Reward is an algorithm that enables Foundation Models to write reward functions for reinforcement learning in robotics.
Language-to-reward is an algorithm developed by Yu et al., 2023, that enables FMs to write reward functions for reinforcement learning in robotics.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="MANUALLY DESIGNED AGENTS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="HU ET AL., 2021">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hu et al. are the authors of research on Neural Architecture Search, published in 2021.
Hu et al. are authors referenced in the text, known for their work published in 2021 related to multi-objective optimization in agentic systems.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479,7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="LU ET AL., 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lu et al. are the authors of research on Neural Architecture Search, published in 2019.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="FINN ET AL., 2017">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Finn et al. are the authors of research on MAML, published in 2017.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="DUAN ET AL., 2017">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Duan et al. are the authors of research on Meta-RL, published in 2017.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="NORMAN &amp; CLUNE, 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Norman and Clune are the authors of research on Meta-RL, published in 2023.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="WANG ET AL., 2016">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang et al. are the authors of research on Meta-RL, published in 2016.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="ZINTGRAF ET AL., 2021A">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zintgraf et al. are the authors of research on Meta-RL, published in 2021.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="ZINTGRAF ET AL., 2021B">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zintgraf et al. are the authors of research on Meta-RL, published in 2021.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="DHARNA ET AL., 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dharna et al. are the authors of research on POET, published in 2020.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="WANG ET AL., 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang et al. are the authors of research on POET, published in 2019.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="WANG ET AL., 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang et al. are the authors of research on POET, published in 2020.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="RAFALIOV ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rafailov et al. are the authors of research on FM alignment training, published in 2024.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="MA ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ma et al. are the authors of research on Eureka, published in 2023.
Ma et al. are the authors of the Eureka algorithm, published in 2023.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="YU ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yu et al. are the authors of research on language-to-reward, published in 2023.
Yu et al. are the authors of the language-to-reward algorithm, published in 2023.</data>
      <data key="d2">7c08d98f503d722d7de13be55375c8cb,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="FM ALIGNMENT TRAINING">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">7c08d98f503d722d7de13be55375c8cb</data>
    </node>
    <node id="LOSS FUNCTION">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">A loss function is programmed for preference learning in FM alignment training, as mentioned in the work by Rafailov et al., 2024.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="OPRO">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">OPRO is an algorithm developed by Yang et al., 2024, that adopts FMs to automate prompt engineering for agents, focusing on the phrasing of instructions in the prompt to enhance reasoning capability.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="SELF-DISCOVER">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Self-Discover is an algorithm developed by Zhou et al., 2024a, that adopts FMs to automate prompt engineering for agents, focusing on the phrasing of instructions in the prompt to enhance reasoning capability.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="EVOAGENT">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">EvoAgent is an algorithm developed by Yuan et al., 2024, that optimizes role definition in the prompt, assigning personas or roles to agents to improve performance.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="AGENTVERSE">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">AgentVerse is an algorithm developed by Chen et al., 2023b, that optimizes role definition in the prompt, assigning personas or roles to agents to improve performance.
A research paper titled "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" presented at The Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="DYLAN">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">DyLAN is an algorithm developed by Liu et al., 2023, that uses FMs to score the response quality of nodes in a fully connected feed-forward network and prunes the connections accordingly.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="DSPY">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">DSPy is an algorithm developed by Khattab et al., 2024, that generates a set of possible nodes and optimizes across the Cartesian product of these nodes while optimizing the few-shot examples for nodes.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="GPT-SWARM">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">GPT-Swarm is an algorithm developed by Zhuge et al., 2024, that represents an agentic system in a graph with a predefined set of nodes and uses a Reinforcement Learning algorithm to optimize the connections between nodes while optimizing the prompt for each node.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="AGENTOPTIMIZER">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">AgentOptimizer is an algorithm developed by Zhang et al., 2024b, that learns the tools used in agents.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="AGENT SYMBOLIC LEARNING">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Agent Symbolic Learning is an algorithm developed by Zhou et al., 2024b, that learns prompts, tools, and control flow together, but manually designs the search space for each component separately.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="AGI">
      <data key="d0">CONCEPT, RESEARCH AREA</data>
      <data key="d1">Artificial General Intelligence (AGI) is a concept in AI research that involves creating AI systems with general cognitive abilities, potentially accelerated by ADAS.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="SAFETY CONSIDERATIONS">
      <data key="d0">CONCEPT, GUIDELINE</data>
      <data key="d1">Safety considerations involve being aware of the potential risks when executing untrusted model-generated code, with recommendations for using sandbox environments to mitigate these risks.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">CONCEPT, GUIDELINE</data>
    </node>
    <node id="SANDBOX ENVIRONMENTS">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">Sandbox environments are controlled settings used to safely run untrusted model-generated code to prevent destructive actions.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">TECHNOLOGY, METHOD</data>
    </node>
    <node id="RAFALOV ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rafailov et al. are the authors of a work in 2024 that involves programming the loss function for preference learning in FM alignment training.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ZHOU ET AL., 2024A">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhou et al. are the authors of the Self-Discover algorithm, published in 2024a.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YUAN ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuan et al. are the authors of the EvoAgent algorithm, published in 2024.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="KHATTAB ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Khattab et al. are the authors of the DSPy algorithm, published in 2024.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ZHANG ET AL., 2024B">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhang et al. are the authors of the AgentOptimizer algorithm, published in 2024b.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ZHOU ET AL., 2024B">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhou et al. are the authors of the Agent Symbolic Learning algorithm, published in 2024b.
Zhou et al. are authors referenced in the text, known for their work published in 2024 related to intelligent evaluation functions in ADAS.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479,dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ROKON ET AL., 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rokon et al. are the authors of a work published in 2020 that discusses safety considerations for executing model-generated code.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YEE ET AL., 2010">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yee et al. are the authors of a work published in 2010 that discusses safety considerations for executing model-generated code.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="BENGIO ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bengio et al. are the authors of a work published in 2024 that discusses the ethical considerations of advancing AI capabilities.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="BOSTROM, 2002">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bostrom is the author of a work published in 2002 that discusses the ethical considerations of advancing AI capabilities.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ECOFFET ET AL., 2020">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ecoffet et al. are the authors of a work published in 2020 that discusses the ethical considerations of advancing AI capabilities.
Ecoffet et al. are authors referenced in the text, known for their work published in 2020 related to AI and agentic systems.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479,dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YUDKOWSKY ET AL., 2008">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yudkowsky et al. are the authors of a work published in 2008 that discusses the ethical considerations of advancing AI capabilities.
Yudkowsky et al. are authors referenced in the text, known for their work published in 2008 related to AI and its implications.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479,dc55f071b95dec721a9820d39cdb3ccd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="PREFERENCE LEARNING">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Preference learning is a method used in FM alignment training to optimize the performance of models based on user preferences.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="ROBOTICS LEARNING ENVIRONMENTS">
      <data key="d0">CONCEPT, TECHNOLOGY</data>
      <data key="d1">Robotics learning environments are simulated or real-world settings where robots can learn and practice tasks, often created using FMs and programming in code.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="PROMPT ENGINEERING">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Prompt engineering is the process of designing and optimizing prompts to improve the performance and reasoning capabilities of agents.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="ROLE DEFINITION">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Role definition involves assigning specific personas or roles to agents within prompts to enhance their performance and reasoning capabilities.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="CONTROL FLOW">
      <data key="d0">CONCEPT, METHOD</data>
      <data key="d1">Control flow refers to the optimization of the sequence and connections between nodes or components in agentic systems, often represented as networks or graphs.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="DESIGN PATTERNS">
      <data key="d0">CONCEPT, COMPONENT</data>
      <data key="d1">Design patterns are recurring solutions or structures that can be used to solve common problems in agentic systems, emerging from basic agent designs.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="API ACCESS">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">API access allows users to interact with and utilize the functionalities of powerful FMs for programming and optimizing agentic systems.
API access refers to the ability to interact with and use the functionalities of powerful foundational models (FMs) through application programming interfaces.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479,dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="ARTIFICIAL GENERAL INTELLIGENCE (AGI)">
      <data key="d0">CONCEPT, RESEARCH AREA</data>
      <data key="d1">Artificial General Intelligence (AGI) is a concept in AI research that involves creating AI systems with general cognitive abilities, potentially accelerated by ADAS.</data>
      <data key="d2">dc55f071b95dec721a9820d39cdb3ccd</data>
    </node>
    <node id="BOSTROM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bostrom is an author referenced in the text, known for contributions to discussions on AI and its implications.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="CLUNE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Clune is an author referenced in the text, known for contributions to AI research, particularly in the context of AI-generating algorithms and open-ended algorithms.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="GPUS">
      <data key="d0">HARDWARE, TECHNOLOGY</data>
      <data key="d1">GPUs (Graphics Processing Units) are hardware components often used for processing complex computations, particularly in AI and machine learning tasks.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="SAFE-ADAS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Safe-ADAS refers to algorithms designed to conduct ADAS safely, ensuring that no harmful code is run and that only honest, helpful, and harmless agents are created.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="CONSTITUTIONAL AI">
      <data key="d0">CONCEPT, METHODOLOGY</data>
      <data key="d1">Constitutional AI is a concept that involves designing AI systems to adhere to ethical guidelines and principles, ensuring they are helpful, harmless, and honest.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="HIGHER-ORDER ADAS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Higher-order ADAS refers to the concept of improving the meta agent used in ADAS through self-referential meta-learning, allowing for the learning of the meta agent and even the meta-meta agent.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="MULTI-OBJECTIVE ADAS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Multi-objective ADAS refers to the integration of multiple objectives, such as cost, latency, and robustness, in the optimization process of ADAS algorithms.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="NOVELTY SEARCH ALGORITHMS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Novelty search algorithms are a type of search algorithm focused on exploring interesting new designs, potentially incorporating ideas from Quality-Diversity, AI-generating, and Open-ended Algorithms.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="AI-GENERATING ALGORITHMS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">AI-generating algorithms are methods focused on creating new AI systems, often through open-ended and exploratory approaches.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="OPEN-ENDED ALGORITHMS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Open-ended algorithms are methods that continuously explore and generate new solutions without a predefined endpoint, often used in AI research.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">ALGORITHM, METHOD</data>
    </node>
    <node id="EVALUATION FUNCTIONS">
      <data key="d0">TECHNOLOGY, METHOD</data>
      <data key="d1">Evaluation functions are methods used to assess the performance of discovered agents, potentially incorporating detailed running logs and subjective answer evaluations.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">TECHNOLOGY, METHOD</data>
    </node>
    <node id="SINGLE-STEP QA TASKS">
      <data key="d0">TASK, DOMAIN</data>
      <data key="d1">Single-step QA tasks are a type of task used to evaluate Meta Agent Search, involving simple question-answering interactions.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">TASK, DOMAIN</data>
    </node>
    <node id="MULTI-STEP INTERACTION">
      <data key="d0">TASK, DOMAIN</data>
      <data key="d1">Multi-step interaction refers to more complex tasks involving multiple steps and interactions with complex environments, proposed as a future direction for Meta Agent Search.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">TASK, DOMAIN</data>
    </node>
    <node id="HUMAN ORGANIZATIONS">
      <data key="d0">CONCEPT, ENTITY</data>
      <data key="d1">Human organizations refer to the structured groups and societies formed by humans, which are closely connected to agentic systems in terms of complexity and operation.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">CONCEPT, ENTITY</data>
    </node>
    <node id="CALDWELL, 2011">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Caldwell is an author referenced in the text, known for contributions to discussions on AI and its implications, published in 2011.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="META, 2024">
      <data key="d0">ORGANIZATION, RESEARCHER</data>
      <data key="d1">Meta is an organization referenced in the text, known for contributions to AI research, with work published in 2024.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">ORGANIZATION, RESEARCHER</data>
    </node>
    <node id="BAI ET AL., 2022">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bai et al. are authors referenced in the text, known for their work published in 2022 related to Constitutional AI.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="LU ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lu et al. are authors referenced in the text, known for their work published in 2023 related to higher-order meta-learning in ADAS.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="LANGCHAINAI, 2022">
      <data key="d0">ORGANIZATION, RESEARCHER</data>
      <data key="d1">LangChainAI is an organization referenced in the text, known for contributions to AI research, with work published in 2022 related to the LangChain framework.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">ORGANIZATION, RESEARCHER</data>
    </node>
    <node id="HUANG ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Huang et al. are authors referenced in the text, known for their work published in 2023 related to multi-objective optimization in agentic systems.
Huang et al. are researchers who have shown that observing the emerged architecture of neural networks can provide insights, as published in 2023.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479,7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="DEB ET AL., 2002">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Deb et al. are authors referenced in the text, known for their work published in 2002 related to multi-objective search algorithms.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CULLY &amp; DEMIRIS, 2017">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cully &amp; Demiris are authors referenced in the text, known for their work published in 2017 related to Quality-Diversity in search algorithms.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="MOURET &amp; CLUNE, 2015">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mouret &amp; Clune are authors referenced in the text, known for their work published in 2015 related to AI-generating algorithms and open-ended algorithms.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="STANLEY &amp; LEHMAN, 2015">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Stanley &amp; Lehman are authors referenced in the text, known for their work published in 2015 related to open-ended algorithms.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="STANLEY ET AL., 2019">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Stanley et al. are authors referenced in the text, known for their work published in 2019 related to open-ended algorithms.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CHIANG ET AL., 2024">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chiang et al. are authors referenced in the text, known for their work published in 2024 related to subjective answer evaluations in ADAS.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="COMPLEX DOMAINS">
      <data key="d0">TASK, DOMAIN</data>
      <data key="d1">Complex domains refer to real-world applications involving multi-step interactions with complex environments, proposed as a future direction for Meta Agent Search.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">TASK, DOMAIN</data>
    </node>
    <node id="HUMAN ORGANIZATION AND SOCIETY">
      <data key="d0">CONCEPT, ENTITY</data>
      <data key="d1">Human organization and society refer to the structured groups and societies formed by humans, which are closely connected to agentic systems in terms of complexity and operation.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">CONCEPT, ENTITY</data>
    </node>
    <node id="ORGANIZATIONAL STRUCTURE">
      <data key="d0">CONCEPT, METHODOLOGY</data>
      <data key="d1">Organizational structure refers to the way human companies and organizations are structured, which can be incorporated into agentic systems to improve their design and operation.</data>
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
      <data key="d3">CONCEPT, METHODOLOGY</data>
    </node>
    <node id="BALANCING EXPLORATION AND EXPLOITATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="SUBJECTIVE ANSWER EVALUATIONS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </node>
    <node id="AS">
      <data key="d0">CONCEPT, SYSTEM</data>
      <data key="d1">AS refers to an agentic system that operates primarily over natural language, shedding light on the origins of complexity emerging from human organization and society.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="HUMAN ORGANIZATION">
      <data key="d0">CONCEPT, ENTITY</data>
      <data key="d1">Human organization refers to the structured arrangement of individuals and groups in society, which agentic systems aim to simulate and understand.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="AGENTIC SYSTEM">
      <data key="d0">SYSTEM, TECHNOLOGY</data>
      <data key="d1">An agentic system is a machine learning system that operates over natural language and is used to simulate human organizations and societies.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="PARK ET AL., 2023">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Park et al. are researchers who have simulated a human town with agents in their work published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="CANADA CIFAR AI CHAIRS PROGRAM">
      <data key="d0">PROGRAM, FUNDING</data>
      <data key="d1">The Canada CIFAR AI Chairs program is a funding program that supported the work on Automated Design of Agentic Systems.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">PROGRAM, FUNDING</data>
    </node>
    <node id="SCHMIDT FUTURES">
      <data key="d0">ORGANIZATION, FUNDING</data>
      <data key="d1">Schmidt Futures is an organization that provided grants to support the work on Automated Design of Agentic Systems.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">ORGANIZATION, FUNDING</data>
    </node>
    <node id="OPEN PHILANTHROPY">
      <data key="d0">ORGANIZATION, FUNDING</data>
      <data key="d1">Open Philanthropy is an organization that provided grants to support the work on Automated Design of Agentic Systems.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">ORGANIZATION, FUNDING</data>
    </node>
    <node id="NSERC DISCOVERY GRANT">
      <data key="d0">GRANT, FUNDING</data>
      <data key="d1">The NSERC Discovery Grant is a funding source that supported the work on Automated Design of Agentic Systems.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">GRANT, FUNDING</data>
    </node>
    <node id="RAFAEL COSMAN">
      <data key="d0">INDIVIDUAL, DONOR</data>
      <data key="d1">Rafael Cosman is an individual who made a generous donation to support the work on Automated Design of Agentic Systems.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">INDIVIDUAL, DONOR</data>
    </node>
    <node id="JENNY ZHANG">
      <data key="d0">INDIVIDUAL, RESEARCHER</data>
      <data key="d1">Jenny Zhang is one of the individuals acknowledged for providing insightful discussions and feedback on the work on Automated Design of Agentic Systems.
Jenny Zhang is an author who contributed to the paper "OMNI: Open-endedness via models of human notions of interestingness."
Jenny Zhang is one of the authors of the paper titled "OMNI: Open-endedness via models of human notions of interestingness" presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,7de66b94cf868b37b1df51dc545c415f,cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">INDIVIDUAL, RESEARCHER</data>
    </node>
    <node id="RACH PRADHAN">
      <data key="d0">INDIVIDUAL, RESEARCHER</data>
      <data key="d1">Rach Pradhan is one of the individuals acknowledged for providing insightful discussions and feedback on the work on Automated Design of Agentic Systems.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">INDIVIDUAL, RESEARCHER</data>
    </node>
    <node id="RUIYU GOU">
      <data key="d0">INDIVIDUAL, RESEARCHER</data>
      <data key="d1">Ruiyu Gou is one of the individuals acknowledged for providing insightful discussions and feedback on the work on Automated Design of Agentic Systems.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">INDIVIDUAL, RESEARCHER</data>
    </node>
    <node id="NICHOLAS IOANNIDIS">
      <data key="d0">INDIVIDUAL, RESEARCHER</data>
      <data key="d1">Nicholas Ioannidis is one of the individuals acknowledged for providing insightful discussions and feedback on the work on Automated Design of Agentic Systems.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">INDIVIDUAL, RESEARCHER</data>
    </node>
    <node id="EUNJEONG HWANG">
      <data key="d0">INDIVIDUAL, RESEARCHER</data>
      <data key="d1">Eunjeong Hwang is one of the individuals acknowledged for providing insightful discussions and feedback on the work on Automated Design of Agentic Systems.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">INDIVIDUAL, RESEARCHER</data>
    </node>
    <node id="YUNTAO BAI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuntao Bai is one of the authors of the paper on Constitutional AI, published in 2022.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SAURAV KADAVATH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Saurav Kadavath is one of the authors of the paper on Constitutional AI, published in 2022.
Saurav Kadavath is one of the authors of the paper on measuring mathematical problem solving with the math dataset, published in 2021.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SANDIPAN KUNDU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sandipan Kundu is one of the authors of the paper on Constitutional AI, published in 2022.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="AMANDA ASKELL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Amanda Askell is one of the authors of the paper on Constitutional AI, published in 2022.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="JACKSON KERNION">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jackson Kernion is one of the authors of the paper on Constitutional AI, published in 2022.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ANDY JONES">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Andy Jones is one of the authors of the paper on Constitutional AI, published in 2022.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ANNA CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Anna Chen is one of the authors of the paper on Constitutional AI, published in 2022.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ANNA GOLDIE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Anna Goldie is one of the authors of the paper on Constitutional AI, published in 2022.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="AZALIA MIRHOSEINI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Azalia Mirhoseini is one of the authors of the paper on Constitutional AI, published in 2022.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CAMERON MCKINNON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cameron McKinnon is one of the authors of the paper on Constitutional AI, published in 2022.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="GEOFFREY HINTON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Geoffrey Hinton is one of the authors of the paper on managing extreme AI risks, published in 2024.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ANDREW YAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Andrew Yao is one of the authors of the paper on managing extreme AI risks, published in 2024.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="DAWN SONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dawn Song is one of the authors of the paper on managing extreme AI risks, published in 2024.
Dawn Song is one of the authors of the paper titled "Measuring massive multitask language understanding" presented at the International Conference on Learning Representations in 2021.
Dawn Song is one of the authors of the paper on the false promise of imitating proprietary LLMs, published in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,7de66b94cf868b37b1df51dc545c415f,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="TREVOR DARRELL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Trevor Darrell is one of the authors of the paper on managing extreme AI risks, published in 2024.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YUVAL NOAH HARARI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuval Noah Harari is one of the authors of the paper on managing extreme AI risks, published in 2024.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YA-QIN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ya-Qin Zhang is one of the authors of the paper on managing extreme AI risks, published in 2024.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="LAN XUE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lan Xue is one of the authors of the paper on managing extreme AI risks, published in 2024.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SHAI SHALEV-SHWARTZ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shai Shalev-Shwartz is one of the authors of the paper on managing extreme AI risks, published in 2024.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="N BOSTROM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">N Bostrom is the author of the paper on existential risks, published in 2002.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ROBERT S BOYER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Robert S Boyer is one of the authors of the mechanical proof of the Turing completeness of pure LISP, published in 1983.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="J STROTHER MOORE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">J Strother Moore is one of the authors of the mechanical proof of the Turing completeness of pure LISP, published in 1983.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="TRACEY CALDWELL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tracey Caldwell is the author of the paper on ethical hackers, published in 2011.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="HARRISON CHASE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Harrison Chase is the author of the blog post "What is an agent?" published in June 2024.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="BANGHAO CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Banghao Chen is one of the authors of the paper on prompt engineering in large language models, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ZHAOFENG ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhaofeng Zhang is one of the authors of the paper on prompt engineering in large language models, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="NICOLAS LANGREN&#201;">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nicolas Langren&#233; is one of the authors of the paper on prompt engineering in large language models, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="SHENGXIN ZHU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shengxin Zhu is one of the authors of the paper on prompt engineering in large language models, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="HENRIQUE PONDE DE OLIVEIRA PINTO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Henrique Ponde De Oliveira Pinto is one of the authors of the paper on evaluating large language models trained on code, published in 2021.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="HARRI EDWARDS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Harri Edwards is one of the authors of the paper on evaluating large language models trained on code, published in 2021.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YURI BURDA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuri Burda is one of the authors of the paper on evaluating large language models trained on code, published in 2021.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="WEIZE CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Weize Chen is one of the authors of the paper on multi-agent collaboration and emergent behaviors, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YUSHENG SU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yusheng Su is one of the authors of the paper on multi-agent collaboration and emergent behaviors, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="JINGWEI ZUO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jingwei Zuo is one of the authors of the paper on multi-agent collaboration and emergent behaviors, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CHENG YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cheng Yang is one of the authors of the paper on multi-agent collaboration and emergent behaviors, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CHENFEI YUAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chenfei Yuan is one of the authors of the paper on multi-agent collaboration and emergent behaviors, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CHI-MIN CHAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chi-Min Chan is one of the authors of the paper on multi-agent collaboration and emergent behaviors, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="HEYANG YU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Heyang Yu is one of the authors of the paper on multi-agent collaboration and emergent behaviors, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="YI-HSIN HUNG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yi-Hsin Hung is one of the authors of the paper on multi-agent collaboration and emergent behaviors, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CHEN QIAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chen Qian is one of the authors of the paper on multi-agent collaboration and emergent behaviors, published in 2023.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="NEURAL NETWORKS">
      <data key="d0">TECHNOLOGY, SYSTEM</data>
      <data key="d1">Neural networks are a type of machine learning model that can learn to perform tasks by considering examples, generally without task-specific programming.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="INSIGHTS">
      <data key="d0">CONCEPT, RESULT</data>
      <data key="d1">Insights refer to the understanding gained from observing the results of experiments or studies, such as those involving neural networks or agentic systems.
A part of the "thought" section where the meta agent provides insights on what should be the next interesting agent.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="SECTION 4.3">
      <data key="d0">DOCUMENT SECTION, REFERENCE</data>
      <data key="d1">Section 4.3 is a part of the paper that discusses the performance of agents with different feedback mechanisms when using GPT-3.5 and other advanced models.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="STATE-OF-THE-ART HAND-DESIGNED AGENTS">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">State-of-the-art hand-designed agents are manually created agents that represent the current best practices in agent design.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="MODELS">
      <data key="d0">CONCEPT, SYSTEM</data>
      <data key="d1">Models refer to machine learning models, including language models like GPT-3.5, that can be used to evaluate the performance of agents.</data>
      <data key="d2">7de66b94cf868b37b1df51dc545c415f</data>
    </node>
    <node id="CHEN, YUSHENG SU, JINGWEI ZUO, CHENG YANG, CHENFEI YUAN, CHI-MIN CHAN, HEYANG YU, YAXI LU, YI-HSIN HUNG, CHEN QIAN, ET AL.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A group of researchers who authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" presented at The Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">An academic conference where the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" was presented in 2023.
An academic conference where the paper "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" was presented in 2024.
The Twelfth International Conference on Learning Representations is an event where the paper "OMNI: Open-endedness via models of human notions of interestingness" was presented in 2024.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,6109537356a2ce2339f77c827aa3668e,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="WEI-LIN CHIANG, LIANMIN ZHENG, YING SHENG, ANASTASIOS NIKOLAS ANGELOPOULOS, TIANLE LI, DACHENG LI, HAO ZHANG, BANGHUA ZHU, MICHAEL JORDAN, JOSEPH E. GONZALEZ, AND ION STOICA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A group of researchers who authored the paper "Chatbot arena: An open platform for evaluating llms by human preference" in 2024.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="CHATBOT ARENA">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper titled "Chatbot arena: An open platform for evaluating llms by human preference" authored by Wei-Lin Chiang et al. in 2024.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="FRAN&#199;OIS CHOLLET">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The author of the paper "On the measure of intelligence" published as an arXiv preprint in 2019.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="ON THE MEASURE OF INTELLIGENCE">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Fran&#231;ois Chollet, published as an arXiv preprint in 2019.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="KARL COBBE, VINEET KOSARAJU, MOHAMMAD BAVARIAN, MARK CHEN, HEEWOO JUN, LUKASZ KAISER, MATTHIAS PLAPPERT, JERRY TWOREK, JACOB HILTON, REIICHIRO NAKANO, ET AL.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A group of researchers who authored the paper "Training verifiers to solve math word problems" published as an arXiv preprint in 2021.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="TRAINING VERIFIERS TO SOLVE MATH WORD PROBLEMS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper titled "Training verifiers to solve math word problems" authored by Karl Cobbe et al., published as an arXiv preprint in 2021.
</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ANTOINE CULLY AND YIANNIS DEMIRIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "Quality and diversity optimization: A unifying modular framework" published in IEEE Transactions on Evolutionary Computation in 2017.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="QUALITY AND DIVERSITY OPTIMIZATION">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper titled "Quality and diversity optimization: A unifying modular framework" authored by Antoine Cully and Yiannis Demiris, published in IEEE Transactions on Evolutionary Computation in 2017.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="N. DALAL AND B. TRIGGS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "Histograms of oriented gradients for human detection" presented at the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="HISTOGRAMS OF ORIENTED GRADIENTS FOR HUMAN DETECTION">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper titled "Histograms of oriented gradients for human detection" authored by N. Dalal and B. Triggs, presented at the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="KALYANMOY DEB, AMRIT PRATAP, SAMEER AGARWAL, AND TAMT MEYARIVAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "A fast and elitist multiobjective genetic algorithm: Nsga-ii" published in IEEE Transactions on Evolutionary Computation in 2002.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="NSGA-II">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper titled "A fast and elitist multiobjective genetic algorithm: Nsga-ii" authored by Kalyanmoy Deb et al., published in IEEE Transactions on Evolutionary Computation in 2002.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="AARON DHARNA, JULIAN TOGELIUS, AND LISA B SOROS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "Co-generation of game levels and game-playing agents" presented at the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment in 2020.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="CO-GENERATION OF GAME LEVELS AND GAME-PLAYING AGENTS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper titled "Co-generation of game levels and game-playing agents" authored by Aaron Dharna et al., presented at the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment in 2020.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="YILUN DU, SHUANG LI, ANTONIO TORRALBA, JOSHUA B TENENBAUM, AND IGOR MORDATCH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "Improving factuality and reasoning in language models through multiagent debate" published as an arXiv preprint in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="IMPROVING FACTUALITY AND REASONING IN LANGUAGE MODELS THROUGH MULTIAGENT DEBATE">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper titled "Improving factuality and reasoning in language models through multiagent debate" authored by Yilun Du et al., published as an arXiv preprint in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="DHEERU DUA, YIZHONG WANG, PRADEEP DASIGI, GABRIEL STANOVSKY, SAMEER SINGH, AND MATT GARDNER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs" presented at the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="YAN DUAN, JOHN SCHULMAN, XI CHEN, PETER L. BARTLETT, ILYA SUTSKEVER, AND PIETER ABBEEL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "RL^2: Fast reinforcement learning via slow reinforcement learning" presented at the International Conference on Learning Representations in 2017.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="RL^2">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper titled "RL^2: Fast reinforcement learning via slow reinforcement learning" authored by Yan Duan et al., presented at the International Conference on Learning Representations in 2017.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="ADRIEN ECOFFET, JEFF CLUNE, AND JOEL LEHMAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "Open questions in creating safe open-ended AI: Tensions between control and creativity" presented at the Conference on Artificial Life in 2020.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="OPEN QUESTIONS IN CREATING SAFE OPEN-ENDED AI">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper titled "Open questions in creating safe open-ended AI: Tensions between control and creativity" authored by Adrien Ecoffet et al., presented at the Conference on Artificial Life in 2020.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="THOMAS ELSKEN, JAN HENDRIK METZEN, AND FRANK HUTTER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "Neural architecture search: A survey" published in the Journal of Machine Learning Research in 2019.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="MAXENCE FALDOR, JENNY ZHANG, ANTOINE CULLY, AND JEFF CLUNE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "Omni-epic: Open-endedness via models of human notions of interestingness with environments programmed in code" published as an arXiv preprint in 2024.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="CHRISANTHA FERNANDO, DYLAN SUNIL BANARSE, HENRYK MICHALEWSKI, SIMON OSINDERO, AND TIM ROCKT&#196;SCHEL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "Promptbreeder: Self-referential self-improvement via prompt evolution" published in 2024.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="CHELSEA FINN, PIETER ABBEEL, AND SERGEY LEVINE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "Model-agnostic meta-learning for fast adaptation of deep networks" presented at the International Conference on Machine Learning in 2017.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="MODEL-AGNOSTIC META-LEARNING">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper titled "Model-agnostic meta-learning for fast adaptation of deep networks" authored by Chelsea Finn et al., presented at the International Conference on Machine Learning in 2017.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="LUYU GAO, AMAN MADAAN, SHUYAN ZHOU, URI ALON, PENGFEI LIU, YIMING YANG, JAMIE CALLAN, AND GRAHAM NEUBIG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The authors of the paper "Pal: Program-aided language models" presented at the International Conference on Machine Learning in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="PAL">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper titled "Pal: Program-aided language models" authored by Luyu Gao et al., presented at the International Conference on Machine Learning in 2023.
Program-aided language models (PAL) is a method discussed in a paper presented at the International Conference on Machine Learning in 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="RYAN GREENBLATT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The author of the article "Getting 50% sota on arc-agi with gpt-4" published on Redwood Research's Substack in July 2023.
Ryan Greenblatt is the author of a technical report titled "Getting 50% SOTA on ARC-AGI with GPT-4" published in July 2024.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="GETTING 50% SOTA ON ARC-AGI WITH GPT-4">
      <data key="d0">ARTICLE, RESEARCH</data>
      <data key="d1">An article titled "Getting 50% sota on arc-agi with gpt-4" authored by Ryan Greenblatt, published on Redwood Research's Substack in July 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="JILL BURSTEIN, CHRISTY DORAN, AND THAMAR SOLORIO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The editors of the proceedings for the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="PROCEEDINGS OF THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">The proceedings edited by Jill Burstein, Christy Doran, and Thamar Solorio, which include the paper "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs."</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">An academic conference where various research papers, including "RL^2: Fast reinforcement learning via slow reinforcement learning," are presented.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="CONFERENCE ON ARTIFICIAL LIFE">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">An academic conference where the paper "Open questions in creating safe open-ended AI: Tensions between control and creativity" was presented in 2020.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="JOURNAL OF MACHINE LEARNING RESEARCH">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">A journal where the paper "Neural architecture search: A survey" was published in 2019.
The Journal of Machine Learning Research is a publication where the paper "Varibad: Variational bayes-adaptive deep RL via meta-learning" was published in 2021.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">A journal where the paper "Quality and diversity optimization: A unifying modular framework" was published in 2017 and "A fast and elitist multiobjective genetic algorithm: Nsga-ii" was published in 2002.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE AND INTERACTIVE DIGITAL ENTERTAINMENT">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">An academic conference where the paper "Co-generation of game levels and game-playing agents" was presented in 2020.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="PMLR">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">The Proceedings of Machine Learning Research, where the paper "Model-agnostic meta-learning for fast adaptation of deep networks" was published in 2017 and "Pal: Program-aided language models" was published in 2023.
PMLR (Proceedings of Machine Learning Research) is a publication where the paper "Exploration in approximate hyper-state space for meta reinforcement learning" was published in 2021.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="REDWOOD RESEARCH">
      <data key="d0">ORGANIZATION, RESEARCH INSTITUTE</data>
      <data key="d1">The research institute that published the article "Getting 50% sota on arc-agi with gpt-4" on their Substack in July 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="SUBSTACK">
      <data key="d0">PLATFORM, WEBSITE</data>
      <data key="d1">The platform where the article "Getting 50% sota on arc-agi with gpt-4" was published by Ryan Greenblatt in July 2023.</data>
      <data key="d2">022e7927d281e80e188f29ea343cc115</data>
    </node>
    <node id="INTERNATIONAL CONFERENCE ON MACHINE LEARNING">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">An academic conference where the paper "Program-aided language models" was presented in 2023.
The International Conference on Machine Learning is an event where several papers, including "Offline training of language model agents with functions as learnable weights" and "GPTSwarm: Language agents as optimizable graphs," were presented in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="ARC-AGI">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">ARC-AGI is a benchmark used to evaluate the performance of algorithms like GPT-4.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DAN HENDRYCKS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dan Hendrycks is one of the authors of the paper titled "Measuring massive multitask language understanding" presented at the International Conference on Learning Representations in 2021.
Dan Hendrycks is one of the authors of the paper on measuring mathematical problem solving with the math dataset, published in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="COLLIN BURNS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Collin Burns is one of the authors of the paper titled "Measuring massive multitask language understanding" presented at the International Conference on Learning Representations in 2021.
Collin Burns is one of the authors of the paper on measuring mathematical problem solving with the math dataset, published in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="STEVEN BASART">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Steven Basart is one of the authors of the paper titled "Measuring massive multitask language understanding" presented at the International Conference on Learning Representations in 2021.
Steven Basart is one of the authors of the paper on measuring mathematical problem solving with the math dataset, published in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ANDY ZOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Andy Zou is one of the authors of the paper titled "Measuring massive multitask language understanding" presented at the International Conference on Learning Representations in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MANTAS MAZEIKA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mantas Mazeika is one of the authors of the paper titled "Measuring massive multitask language understanding" presented at the International Conference on Learning Representations in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="JACOB STEINHARDT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jacob Steinhardt is one of the authors of the paper titled "Measuring massive multitask language understanding" presented at the International Conference on Learning Representations in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SIRUI HONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sirui Hong is one of the authors of the paper titled "MetaGPT: Meta programming for multi-agent collaborative framework" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="XIAWU ZHENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiawu Zheng is one of the authors of the paper titled "MetaGPT: Meta programming for multi-agent collaborative framework" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="JONATHAN CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jonathan Chen is one of the authors of the paper titled "MetaGPT: Meta programming for multi-agent collaborative framework" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="YUHENG CHENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuheng Cheng is one of the authors of the paper titled "MetaGPT: Meta programming for multi-agent collaborative framework" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="JINLIN WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jinlin Wang is one of the authors of the paper titled "MetaGPT: Meta programming for multi-agent collaborative framework" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CEYAO ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ceyao Zhang is one of the authors of the paper titled "MetaGPT: Meta programming for multi-agent collaborative framework" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZILI WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zili Wang is one of the authors of the paper titled "MetaGPT: Meta programming for multi-agent collaborative framework" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="STEVEN KA SHING YAU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Steven Ka Shing Yau is one of the authors of the paper titled "MetaGPT: Meta programming for multi-agent collaborative framework" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZIJUAN LIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zijuan Lin is one of the authors of the paper titled "MetaGPT: Meta programming for multi-agent collaborative framework" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="LIYANG ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Liyang Zhou is one of the authors of the paper titled "MetaGPT: Meta programming for multi-agent collaborative framework" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="METAGPT">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">MetaGPT is a meta programming framework for multi-agent collaboration discussed in a paper published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="THOUGHT CLONING">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Thought Cloning is a method for learning to think while acting by imitating human thinking, discussed in a paper published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="RAN CHENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ran Cheng is one of the authors of the paper titled "Accelerating multi-objective neural architecture search by random-weight evaluation" published in Complex &amp; Intelligent Systems in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CHENG HE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cheng He is one of the authors of the paper titled "Accelerating multi-objective neural architecture search by random-weight evaluation" published in Complex &amp; Intelligent Systems in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZHICHAO LU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhichao Lu is one of the authors of the paper titled "Accelerating multi-objective neural architecture search by random-weight evaluation" published in Complex &amp; Intelligent Systems in 2021.
One of the authors of the paper "Nsga-net: neural architecture search using multi-objective genetic algorithm," published in the Proceedings of the genetic and evolutionary computation conference in 2019.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="JING WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jing Wang is one of the authors of the paper titled "Accelerating multi-objective neural architecture search by random-weight evaluation" published in Complex &amp; Intelligent Systems in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MIAO ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Miao Zhang is one of the authors of the paper titled "Accelerating multi-objective neural architecture search by random-weight evaluation" published in Complex &amp; Intelligent Systems in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="COMPLEX &amp; INTELLIGENT SYSTEMS">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">A journal where the paper "Accelerating multi-objective neural architecture search by random-weight evaluation" was published in 2021.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SHIHUA HUANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shihua Huang is one of the authors of the paper titled "Revisiting residual networks for adversarial robustness" presented at the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="KALYANMOY DEB">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kalyanmoy Deb is one of the authors of the paper titled "Revisiting residual networks for adversarial robustness" presented at the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.
One of the authors of the paper "Nsga-net: neural architecture search using multi-objective genetic algorithm," published in the Proceedings of the genetic and evolutionary computation conference in 2019.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="VISHNU NARESH BODDETI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Vishnu Naresh Boddeti is one of the authors of the paper titled "Revisiting residual networks for adversarial robustness" presented at the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION">
      <data key="d0">CONFERENCE, EVENT</data>
      <data key="d1">An academic conference where the paper "Revisiting residual networks for adversarial robustness" was presented in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="FRANK HUTTER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Frank Hutter is one of the authors of the book titled "Automated machine learning: methods, systems, challenges" published by Springer Nature in 2019.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="LARS KOTTHOFF">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lars Kotthoff is one of the authors of the book titled "Automated machine learning: methods, systems, challenges" published by Springer Nature in 2019.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="JOAQUIN VANSCHOREN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Joaquin Vanschoren is one of the authors of the book titled "Automated machine learning: methods, systems, challenges" published by Springer Nature in 2019.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="AUTOMATED MACHINE LEARNING">
      <data key="d0">BOOK, PUBLICATION</data>
      <data key="d1">A book titled "Automated machine learning: methods, systems, challenges" published by Springer Nature in 2019.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="OMAR KHATTAB">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Omar Khattab is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" presented at The Twelfth International Conference on Learning Representations in 2024.
Omar Khattab is an author who contributed to the paper "The shift from models to compound ai systems."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ARNAV SINGHVI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Arnav Singhvi is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="PARIDHI MAHESHWARI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Paridhi Maheshwari is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZHIYUAN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhiyuan Zhang is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="KESHAV SANTHANAM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Keshav Santhanam is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SAIFUL HAQ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Saiful Haq is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ASHUTOSH SHARMA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ashutosh Sharma is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="THOMAS T JOSHI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Thomas T Joshi is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="HANNA MOAZAM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hanna Moazam is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="HEATHER MILLER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Heather Miller is one of the authors of the paper titled "Dspy: Compiling declarative language model calls into state-of-the-art pipelines" presented at The Twelfth International Conference on Learning Representations in 2024.
Heather Miller is an author who contributed to the paper "The shift from models to compound ai systems."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ALEX KRIZHEVSKY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alex Krizhevsky is one of the authors of the paper titled "Imagenet classification with deep convolutional neural networks" published in Advances in Neural Information Processing Systems in 2012.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="GEOFFREY E HINTON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Geoffrey E Hinton is one of the authors of the paper titled "Imagenet classification with deep convolutional neural networks" published in Advances in Neural Information Processing Systems in 2012.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="IMAGENET CLASSIFICATION">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Imagenet classification with deep convolutional neural networks is a method discussed in a paper published in Advances in Neural Information Processing Systems in 2012.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ABRAHIM LADHA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Abrahim Ladha is the author of the lecture titled "Lecture 11: Turing-completeness" for the CS 4510 Automata and Complexity course at Georgia Tech, scribed by Rishabh Singhal in February 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="TURING-COMPLETENESS">
      <data key="d0">CONCEPT, THEORY</data>
      <data key="d1">Turing-completeness is a concept discussed in a lecture titled "Lecture 11: Turing-completeness" for the CS 4510 Automata and Complexity course at Georgia Tech in February 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="LANGCHAINAI">
      <data key="d0">ORGANIZATION, COMPANY</data>
      <data key="d1">LangChainAI is the organization behind Langchain, a tool for building context-aware reasoning applications, available on GitHub since 2022.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="JOEL LEHMAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Joel Lehman is one of the authors of the paper titled "Abandoning objectives: Evolution through the search for novelty alone" published in Evolutionary Computation in 2011.
One of the authors of the paper "Language model crossover: Variation through few-shot prompting," published as an arXiv preprint in 2023.
Joel Lehman is one of the authors of the paper "Designing neural networks through neuroevolution" published in Nature Machine Intelligence in 2019.Joel Lehman is one of the authors of the book "Why greatness cannot be planned: The myth of the objective" published by Springer in 2015.
Joel Lehman is an author who contributed to the papers "Poet: open-ended coevolution of environments and their optimized solutions" and "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."Joel Lehman is an author who contributed to the paper "OMNI: Open-endedness via models of human notions of interestingness."
Joel Lehman is one of the authors of the paper titled "OMNI: Open-endedness via models of human notions of interestingness" presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,6109537356a2ce2339f77c827aa3668e,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="KENNETH O STANLEY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kenneth O Stanley is one of the authors of the paper titled "Abandoning objectives: Evolution through the search for novelty alone" published in Evolutionary Computation in 2011.
Kenneth O Stanley is one of the authors of the paper "Designing neural networks through neuroevolution" published in Nature Machine Intelligence in 2019.Kenneth O Stanley is one of the authors of the book "Why greatness cannot be planned: The myth of the objective" published by Springer in 2015.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="EVOLUTIONARY COMPUTATION">
      <data key="d0">JOURNAL, PUBLICATION</data>
      <data key="d1">A journal where the paper "Abandoning objectives: Evolution through the search for novelty alone" was published in 2011.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="PATRICK LEWIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Patrick Lewis is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ETHAN PEREZ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ethan Perez is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ALEKSANDRA PIKTUS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Aleksandra Piktus is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="FABIO PETRONI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fabio Petroni is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="VLADIMIR KARPUKHIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Vladimir Karpukhin is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="HEINRICH K&#220;TTLER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Heinrich K&#252;ttler is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MIKE LEWIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mike Lewis is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="WEN-TAU YIH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wen-tau Yih is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="TIM ROCKT&#196;SCHEL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tim Rockt&#228;schel is one of the authors of the paper titled "Retrieval-augmented generation for knowledge-intensive NLP tasks" published in Advances in Neural Information Processing Systems in 2020.
Tim Rockt&#228;schel is the author of the book "Artificial Intelligence: 10 Things You Should Know" published by Seven Dials in September 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="FEI LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fei Liu is one of the authors of the paper titled "Evolution of heuristics: Towards efficient automatic algorithm design using large language model" presented at the Forty-first International Conference on Machine Learning in 2024.
Fei Liu is one of the authors of the InfoBench project, which evaluates the instruction-following ability in large language models, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="TONG XIALIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tong Xialiang is one of the authors of the paper titled "Evolution of heuristics: Towards efficient automatic algorithm design using large language model" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MINGXUAN YUAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mingxuan Yuan is one of the authors of the paper titled "Evolution of heuristics: Towards efficient automatic algorithm design using large language model" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="XI LIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xi Lin is one of the authors of the paper titled "Evolution of heuristics: Towards efficient automatic algorithm design using large language model" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="FU LUO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fu Luo is one of the authors of the paper titled "Evolution of heuristics: Towards efficient automatic algorithm design using large language model" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZHENKUN WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhenkun Wang is one of the authors of the paper titled "Evolution of heuristics: Towards efficient automatic algorithm design using large language model" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="QINGFU ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qingfu Zhang is one of the authors of the paper titled "Evolution of heuristics: Towards efficient automatic algorithm design using large language model" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="EVOLUTION OF HEURISTICS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Evolution of heuristics is a method for efficient automatic algorithm design using large language models, discussed in a paper presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ZIJUN LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zijun Liu is one of the authors of the paper titled "Dynamic LLM-agent network: An LLM-agent collaboration framework with agent team optimization" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="YANZHE ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yanzhe Zhang is one of the authors of the paper titled "Dynamic LLM-agent network: An LLM-agent collaboration framework with agent team optimization" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="PENG LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Peng Li is one of the authors of the paper titled "Dynamic LLM-agent network: An LLM-agent collaboration framework with agent team optimization" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="YANG LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yang Liu is one of the authors of the paper titled "Dynamic LLM-agent network: An LLM-agent collaboration framework with agent team optimization" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DIYI YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Diyi Yang is one of the authors of the paper titled "Dynamic LLM-agent network: An LLM-agent collaboration framework with agent team optimization" published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DYNAMIC LLM-AGENT NETWORK">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Dynamic LLM-agent network is a collaboration framework with agent team optimization, discussed in a paper published as an arXiv preprint in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CHRIS LU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chris Lu is one of the authors of the paper titled "Arbitrary order meta-learning with simple population-based evolution" presented at the 2023 Artificial Life Conference and published by MIT Press in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SEBASTIAN TOWERS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sebastian Towers is one of the authors of the paper titled "Arbitrary order meta-learning with simple population-based evolution" presented at the 2023 Artificial Life Conference and published by MIT Press in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="JAKOB FOERSTER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jakob Foerster is one of the authors of the paper titled "Arbitrary order meta-learning with simple population-based evolution" presented at the 2023 Artificial Life Conference and published by MIT Press in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ARBITRARY ORDER META-LEARNING">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Arbitrary order meta-learning with simple population-based evolution is a method discussed in a paper presented at the 2023 Artificial Life Conference and published by MIT Press in 2023.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MIT PRESS">
      <data key="d0">PUBLISHER, ORGANIZATION</data>
      <data key="d1">MIT Press is the publisher of the proceedings of the 2023 Artificial Life Conference where the paper "Arbitrary order meta-learning with simple population-based evolution" was presented.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="SAMUEL HOLT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Samuel Holt is one of the authors of the paper titled "Discovering preference optimization algorithms with and for large language models" published as an arXiv preprint in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="CLAUDIO FANCONI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Claudio Fanconi is one of the authors of the paper titled "Discovering preference optimization algorithms with and for large language models" published as an arXiv preprint in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ALEX J CHAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alex J Chan is one of the authors of the paper titled "Discovering preference optimization algorithms with and for large language models" published as an arXiv preprint in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MIHAELA VAN DER SCHAAR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mihaela van der Schaar is one of the authors of the paper titled "Discovering preference optimization algorithms with and for large language models" published as an arXiv preprint in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ROBERT TJARKO LANGE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Robert Tjarko Lange is one of the authors of the paper titled "Discovering preference optimization algorithms with and for large language models" published as an arXiv preprint in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="DISCOVERING PREFERENCE OPTIMIZATION ALGORITHMS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Discovering preference optimization algorithms with and for large language models is a method discussed in a paper published as an arXiv preprint in 2024.</data>
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="THE AI SCIENTIST">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">The AI Scientist is a method for fully automated open-ended scientific discovery, discussed in a paper published as an arXiv preprint in 2024.
A research paper titled "The AI Scientist: Towards fully automated open-ended scientific discovery," published as an arXiv preprint in 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="INTELLIGENT GO-EXPLORE">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Intelligent Go-Explore is a method for standing on the shoulders of giant foundation models, discussed in a paper published as an arXiv preprint in 2024.
A research paper titled "Intelligent go-explore: Standing on the shoulders of giant foundation models," published as an arXiv preprint in 2024.
Intelligent Go-Explore is an algorithm that has a simplified version called Quality-Diversity, used as a baseline for experiments on ARC.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="IAN WHALEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ian Whalen is one of the authors of the paper titled "Intelligent Go-Explore: Standing on the shoulders of giant foundation models" published as an arXiv preprint in 2024.
One of the authors of the paper "Nsga-net: neural architecture search using multi-objective genetic algorithm," published in the Proceedings of the genetic and evolutionary computation conference in 2019.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="YASHESH DHEBAR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yashesh Dhebar is one of the authors of the paper titled "Intelligent Go-Explore: Standing on the shoulders of giant foundation models" published as an arXiv preprint in 2024.
One of the authors of the paper "Nsga-net: neural architecture search using multi-objective genetic algorithm," published in the Proceedings of the genetic and evolutionary computation conference in 2019.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="ACCELERATING MULTI-OBJECTIVE NEURAL ARCHITECTURE SEARCH">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="REVISITING RESIDUAL NETWORKS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">6109537356a2ce2339f77c827aa3668e</data>
    </node>
    <node id="VISHNU BODDETI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Nsga-net: neural architecture search using multi-objective genetic algorithm," published in the Proceedings of the genetic and evolutionary computation conference in 2019.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ERIK GOODMAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Nsga-net: neural architecture search using multi-objective genetic algorithm," published in the Proceedings of the genetic and evolutionary computation conference in 2019.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="WOLFGANG BANZHAF">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Nsga-net: neural architecture search using multi-objective genetic algorithm," published in the Proceedings of the genetic and evolutionary computation conference in 2019.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="NSGA-NET">
      <data key="d0">RESEARCH PAPER, PUBLICATION</data>
      <data key="d1">A research paper titled "Nsga-net: neural architecture search using multi-objective genetic algorithm," published in the Proceedings of the genetic and evolutionary computation conference in 2019.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">RESEARCH PAPER, PUBLICATION</data>
    </node>
    <node id="YECHENG JASON MA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Eureka: Human-level reward design via coding large language models," published in the Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="WILLIAM LIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Eureka: Human-level reward design via coding large language models," published in the Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="OSBERT BASTANI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Eureka: Human-level reward design via coding large language models," published in the Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="DINESH JAYARAMAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Eureka: Human-level reward design via coding large language models," published in the Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="META">
      <data key="d0">ORGANIZATION, COMPANY</data>
      <data key="d1">The company that published the news article "Open source AI is the path forward" in July 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">ORGANIZATION, COMPANY</data>
    </node>
    <node id="OPEN SOURCE AI IS THE PATH FORWARD">
      <data key="d0">NEWS ARTICLE</data>
      <data key="d1">A news article published by Meta in July 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">NEWS ARTICLE</data>
    </node>
    <node id="ELLIOT MEYERSON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Language model crossover: Variation through few-shot prompting," published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="MARK J NELSON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Language model crossover: Variation through few-shot prompting," published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="HERBIE BRADLEY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Language model crossover: Variation through few-shot prompting," published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ADAM GAIER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Language model crossover: Variation through few-shot prompting," published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ARASH MORADI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Language model crossover: Variation through few-shot prompting," published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="AMY K HOOVER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Language model crossover: Variation through few-shot prompting," published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="LANGUAGE MODEL CROSSOVER">
      <data key="d0">RESEARCH PAPER, PUBLICATION</data>
      <data key="d1">A research paper titled "Language model crossover: Variation through few-shot prompting," published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">RESEARCH PAPER, PUBLICATION</data>
    </node>
    <node id="SHEN-YUN MIAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "A diverse corpus for evaluating and developing English math word problem solvers," published in the Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics in 2020.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CHAO-CHUN LIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "A diverse corpus for evaluating and developing English math word problem solvers," published in the Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics in 2020.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="KEH-YIH SU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "A diverse corpus for evaluating and developing English math word problem solvers," published in the Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics in 2020.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="A DIVERSE CORPUS FOR EVALUATING AND DEVELOPING ENGLISH MATH WORD PROBLEM SOLVERS">
      <data key="d0">RESEARCH PAPER, PUBLICATION</data>
      <data key="d1">A research paper titled "A diverse corpus for evaluating and developing English math word problem solvers," published in the Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics in 2020.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">RESEARCH PAPER, PUBLICATION</data>
    </node>
    <node id="JEAN-BAPTISTE MOURET">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Illuminating search spaces by mapping elites," published as an arXiv preprint in 2015.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ILLUMINATING SEARCH SPACES BY MAPPING ELITES">
      <data key="d0">RESEARCH PAPER, PUBLICATION</data>
      <data key="d1">A research paper titled "Illuminating search spaces by mapping elites," published as an arXiv preprint in 2015.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">RESEARCH PAPER, PUBLICATION</data>
    </node>
    <node id="REIICHIRO NAKANO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "WebGPT: Browser-assisted question-answering with human feedback," published as an arXiv preprint in 2021.
Reiichiro Nakano is one of the authors of the paper on training verifiers to solve math word problems, published in 2021.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="JACOB HILTON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "WebGPT: Browser-assisted question-answering with human feedback," published as an arXiv preprint in 2021.
Jacob Hilton is one of the authors of the paper on training verifiers to solve math word problems, published in 2021.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="JEFF WU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "WebGPT: Browser-assisted question-answering with human feedback," published as an arXiv preprint in 2021.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="LONG OUYANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "WebGPT: Browser-assisted question-answering with human feedback," published as an arXiv preprint in 2021.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CHRISTINA KIM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "WebGPT: Browser-assisted question-answering with human feedback," published as an arXiv preprint in 2021.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="CHRISTOPHER HESSE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "WebGPT: Browser-assisted question-answering with human feedback," published as an arXiv preprint in 2021.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="VINEET KOSARAJU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "WebGPT: Browser-assisted question-answering with human feedback," published as an arXiv preprint in 2021.
Vineet Kosaraju is one of the authors of the paper on training verifiers to solve math word problems, published in 2021.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="WILLIAM SAUNDERS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "WebGPT: Browser-assisted question-answering with human feedback," published as an arXiv preprint in 2021.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="WEBGPT">
      <data key="d0">RESEARCH PAPER, PUBLICATION</data>
      <data key="d1">A research paper titled "WebGPT: Browser-assisted question-answering with human feedback," published as an arXiv preprint in 2021.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">RESEARCH PAPER, PUBLICATION</data>
    </node>
    <node id="ANDREW NG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">The author of the newsletter issue "Issue 253," published in June 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ISSUE 253">
      <data key="d0">NEWSLETTER</data>
      <data key="d1">A newsletter issue authored by Andrew Ng, published in June 2024.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">NEWSLETTER</data>
    </node>
    <node id="BEN NORMAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "First-explore, then exploit: Meta-learning intelligent exploration," published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="FIRST-EXPLORE, THEN EXPLOIT">
      <data key="d0">RESEARCH PAPER, PUBLICATION</data>
      <data key="d1">A research paper titled "First-explore, then exploit: Meta-learning intelligent exploration," published as an arXiv preprint in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">RESEARCH PAPER, PUBLICATION</data>
    </node>
    <node id="INTRODUCING CHATGPT">
      <data key="d0">BLOG POST</data>
      <data key="d1">A blog post published by OpenAI in November 2022.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">BLOG POST</data>
    </node>
    <node id="SIMPLE EVALS">
      <data key="d0">RESEARCH PAPER, PUBLICATION</data>
      <data key="d1">A research paper published by OpenAI in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">RESEARCH PAPER, PUBLICATION</data>
    </node>
    <node id="JOON SUNG PARK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Generative agents: Interactive simulacra of human behavior," published in the Proceedings of the 36th annual ACM symposium on user interface software and technology in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="GENERATIVE AGENTS">
      <data key="d0">RESEARCH PAPER, PUBLICATION</data>
      <data key="d1">A research paper titled "Generative agents: Interactive simulacra of human behavior," published in the Proceedings of the 36th annual ACM symposium on user interface software and technology in 2023.</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">RESEARCH PAPER, PUBLICATION</data>
    </node>
    <node id="ARKIL PATEL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">One of the authors of the paper "Are NLP models really able to solve simple math word problems?" published in the Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies in</data>
      <data key="d2">1b1399c76420a477c0c97893d258ae69</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="QIANG WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qiang Wang is one of the authors of the paper "Tool learning with large language models: A survey" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DAWEI YIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dawei Yin is one of the authors of the paper "Tool learning with large language models: A survey" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JUN XU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jun Xu is one of the authors of the paper "Tool learning with large language models: A survey" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JI-RONG WEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ji-Rong Wen is one of the authors of the paper "Tool learning with large language models: A survey" published as an arXiv preprint in 2024.
Ji-Rong Wen is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="TOOL LEARNING WITH LARGE LANGUAGE MODELS: A SURVEY">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Tool learning with large language models: A survey" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="RAFAEL RAFAILOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rafael Rafailov is one of the authors of the paper "Direct preference optimization: Your language model is secretly a reward model" published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ARCHIT SHARMA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Archit Sharma is one of the authors of the paper "Direct preference optimization: Your language model is secretly a reward model" published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ERIC MITCHELL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Eric Mitchell is one of the authors of the paper "Direct preference optimization: Your language model is secretly a reward model" published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="STEFANO ERMON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Stefano Ermon is one of the authors of the paper "Direct preference optimization: Your language model is secretly a reward model" published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DIRECT PREFERENCE OPTIMIZATION: YOUR LANGUAGE MODEL IS SECRETLY A REWARD MODEL">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Direct preference optimization: Your language model is secretly a reward model" published in Advances in Neural Information Processing Systems in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DAVID REIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">David Rein is one of the authors of the paper "Gpqa: A graduate-level google-proof q&amp;a benchmark" published in 2023.
David Rein is one of the authors of the paper titled "GPQA: A graduate-level google-proof Q&amp;A benchmark," published in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="BETTY LI HOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Betty Li Hou is one of the authors of the paper "Gpqa: A graduate-level google-proof q&amp;a benchmark" published in 2023.
Betty Li Hou is one of the authors of the paper titled "GPQA: A graduate-level google-proof Q&amp;A benchmark," published in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ASA COOPER STICKLAND">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Asa Cooper Stickland is one of the authors of the paper "Gpqa: A graduate-level google-proof q&amp;a benchmark" published in 2023.
Asa Cooper Stickland is one of the authors of the paper titled "GPQA: A graduate-level google-proof Q&amp;A benchmark," published in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="JACKSON PETTY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jackson Petty is one of the authors of the paper "Gpqa: A graduate-level google-proof q&amp;a benchmark" published in 2023.
Jackson Petty is one of the authors of the paper titled "GPQA: A graduate-level google-proof Q&amp;A benchmark," published in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="RICHARD YUANZHE PANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Richard Yuanzhe Pang is one of the authors of the paper "Gpqa: A graduate-level google-proof q&amp;a benchmark" published in 2023.
Richard Yuanzhe Pang is one of the authors of the paper titled "GPQA: A graduate-level google-proof Q&amp;A benchmark," published in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="JULIEN DIRANI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Julien Dirani is one of the authors of the paper "Gpqa: A graduate-level google-proof q&amp;a benchmark" published in 2023.
Julien Dirani is one of the authors of the paper titled "GPQA: A graduate-level google-proof Q&amp;A benchmark," published in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="JULIAN MICHAEL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Julian Michael is one of the authors of the paper "Gpqa: A graduate-level google-proof q&amp;a benchmark" published in 2023.
Julian Michael is one of the authors of the paper titled "GPQA: A graduate-level google-proof Q&amp;A benchmark," published in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SAMUEL R. BOWMAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Samuel R. Bowman is one of the authors of the paper "Gpqa: A graduate-level google-proof q&amp;a benchmark" published in 2023.
Samuel R. Bowman is one of the authors of the paper titled "GPQA: A graduate-level google-proof Q&amp;A benchmark," published in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="GPQA: A GRADUATE-LEVEL GOOGLE-PROOF Q&amp;A BENCHMARK">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Gpqa: A graduate-level google-proof q&amp;a benchmark" published in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="TORAN BRUCE RICHARDS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Toran Bruce Richards is the author of the GitHub repository "AutoGPT" created in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="AUTOGPT">
      <data key="d0">SOFTWARE, REPOSITORY</data>
      <data key="d1">AutoGPT is a GitHub repository created by Toran Bruce Richards in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ARTIFICIAL INTELLIGENCE: 10 THINGS YOU SHOULD KNOW">
      <data key="d0">BOOK, PUBLICATION</data>
      <data key="d1">A book titled "Artificial Intelligence: 10 Things You Should Know" authored by Tim Rockt&#228;schel and published by Seven Dials in September 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MD OMAR FARUK ROKON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Md Omar Faruk Rokon is one of the authors of the paper "{SourceFinder}: Finding malware {Source-Code}from publicly available repositories in {GitHub}" published in the 23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020).</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="RISUL ISLAM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Risul Islam is one of the authors of the paper "{SourceFinder}: Finding malware {Source-Code}from publicly available repositories in {GitHub}" published in the 23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020).</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="AHMAD DARKI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ahmad Darki is one of the authors of the paper "{SourceFinder}: Finding malware {Source-Code}from publicly available repositories in {GitHub}" published in the 23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020).</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="EVANGELOS E PAPALEXAKIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Evangelos E Papalexakis is one of the authors of the paper "{SourceFinder}: Finding malware {Source-Code}from publicly available repositories in {GitHub}" published in the 23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020).</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MICHALIS FALOUTSOS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Michalis Faloutsos is one of the authors of the paper "{SourceFinder}: Finding malware {Source-Code}from publicly available repositories in {GitHub}" published in the 23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020).</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="{SOURCEFINDER}: FINDING MALWARE {SOURCE-CODE}FROM PUBLICLY AVAILABLE REPOSITORIES IN {GITHUB}">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "{SourceFinder}: Finding malware {Source-Code}from publicly available repositories in {GitHub}" published in the 23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020).</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="BERNARDINO ROMERA-PAREDES">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bernardino Romera-Paredes is one of the authors of the paper "Mathematical discoveries from program search with large language models" published in Nature in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MOHAMMADAMIN BAREKATAIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mohammadamin Barekatain is one of the authors of the paper "Mathematical discoveries from program search with large language models" published in Nature in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ALEXANDER NOVIKOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alexander Novikov is one of the authors of the paper "Mathematical discoveries from program search with large language models" published in Nature in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MATEJ BALOG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Matej Balog is one of the authors of the paper "Mathematical discoveries from program search with large language models" published in Nature in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="M PAWAN KUMAR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">M Pawan Kumar is one of the authors of the paper "Mathematical discoveries from program search with large language models" published in Nature in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="EMILIEN DUPONT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Emilien Dupont is one of the authors of the paper "Mathematical discoveries from program search with large language models" published in Nature in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="FRANCISCO JR RUIZ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Francisco JR Ruiz is one of the authors of the paper "Mathematical discoveries from program search with large language models" published in Nature in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JORDAN S ELLENBERG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jordan S Ellenberg is one of the authors of the paper "Mathematical discoveries from program search with large language models" published in Nature in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="PENGMING WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Pengming Wang is one of the authors of the paper "Mathematical discoveries from program search with large language models" published in Nature in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="OMAR FAWZI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Omar Fawzi is one of the authors of the paper "Mathematical discoveries from program search with large language models" published in Nature in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MATHEMATICAL DISCOVERIES FROM PROGRAM SEARCH WITH LARGE LANGUAGE MODELS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Mathematical discoveries from program search with large language models" published in Nature in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ERIC HAMBRO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Eric Hambro is one of the authors of the paper "Toolformer: Language models can teach themselves to use tools" published in the Thirty-seventh Conference on Neural Information Processing Systems in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="TOOLFORMER: LANGUAGE MODELS CAN TEACH THEMSELVES TO USE TOOLS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Toolformer: Language models can teach themselves to use tools" published in the Thirty-seventh Conference on Neural Information Processing Systems in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SANDER SCHULHOFF">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sander Schulhoff is one of the authors of the paper "The prompt report: A systematic survey of prompting techniques" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MICHAEL ILIE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Michael Ilie is one of the authors of the paper "The prompt report: A systematic survey of prompting techniques" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="NISHANT BALEPUR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nishant Balepur is one of the authors of the paper "The prompt report: A systematic survey of prompting techniques" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="KONSTANTINE KAHADZE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Konstantine Kahadze is one of the authors of the paper "The prompt report: A systematic survey of prompting techniques" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="AMANDA LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Amanda Liu is one of the authors of the paper "The prompt report: A systematic survey of prompting techniques" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="CHENGLEI SI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chenglei Si is one of the authors of the paper "The prompt report: A systematic survey of prompting techniques" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="YINHENG LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yinheng Li is one of the authors of the paper "The prompt report: A systematic survey of prompting techniques" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="AAYUSH GUPTA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Aayush Gupta is one of the authors of the paper "The prompt report: A systematic survey of prompting techniques" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="HYOJUNG HAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">HyoJung Han is one of the authors of the paper "The prompt report: A systematic survey of prompting techniques" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SEVIEN SCHULHOFF">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sevien Schulhoff is one of the authors of the paper "The prompt report: A systematic survey of prompting techniques" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="THE PROMPT REPORT: A SYSTEMATIC SURVEY OF PROMPTING TECHNIQUES">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "The prompt report: A systematic survey of prompting techniques" published as an arXiv preprint in 2024.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="XUAN SHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xuan Shen is one of the authors of the paper "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="YAOHUA WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yaohua Wang is one of the authors of the paper "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MING LIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ming Lin is one of the authors of the paper "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="YILUN HUANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yilun Huang is one of the authors of the paper "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="HAO TANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hao Tang is one of the authors of the paper "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="XIUYU SUN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiuyu Sun is one of the authors of the paper "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="YANZHI WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yanzhi Wang is one of the authors of the paper "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DEEPMAD: MATHEMATICAL ARCHITECTURE DESIGN FOR DEEP CONVOLUTIONAL NEURAL NETWORK">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Deepmad: Mathematical architecture design for deep convolutional neural network" published in the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="FREDA SHI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Freda Shi is one of the authors of the paper "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MIRAC SUZGUN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mirac Suzgun is one of the authors of the paper "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023.
Mirac Suzgun is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="MARKUS FREITAG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Markus Freitag is one of the authors of the paper "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SURAJ SRIVATS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Suraj Srivats is one of the authors of the paper "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SOROUSH VOSOUGHI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Soroush Vosoughi is one of the authors of the paper "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SEBASTIAN RUDER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sebastian Ruder is one of the authors of the paper "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DIPANJAN DAS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dipanjan Das is one of the authors of the paper "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="LANGUAGE MODELS ARE MULTILINGUAL CHAIN-OF-THOUGHT REASONERS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Language models are multilingual chain-of-thought reasoners" published in The Eleventh International Conference on Learning Representations in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="REFLEXION: LANGUAGE AGENTS WITH VERBAL REINFORCEMENT LEARNING">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Reflexion: Language agents with verbal reinforcement learning" published in Advances in Neural Information Processing Systems in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="WHY GREATNESS CANNOT BE PLANNED: THE MYTH OF THE OBJECTIVE">
      <data key="d0">BOOK, PUBLICATION</data>
      <data key="d1">A book titled "Why greatness cannot be planned: The myth of the objective" authored by Kenneth O Stanley and Joel Lehman, published by Springer in 2015.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="RISTO MIIKKULAINEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Risto Miikkulainen is one of the authors of the paper "Designing neural networks through neuroevolution" published in Nature Machine Intelligence in 2019.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DESIGNING NEURAL NETWORKS THROUGH NEUROEVOLUTION">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Designing neural networks through neuroevolution" published in Nature Machine Intelligence in 2019.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="RICHARD S SUTTON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Richard S Sutton is one of the authors of the book "Reinforcement learning: An introduction" published by MIT Press in 2018.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ANDREW G BARTO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Andrew G Barto is one of the authors of the book "Reinforcement learning: An introduction" published by MIT Press in 2018.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="REINFORCEMENT LEARNING: AN INTRODUCTION">
      <data key="d0">BOOK, PUBLICATION</data>
      <data key="d1">A book titled "Reinforcement learning: An introduction" authored by Richard S Sutton and Andrew G Barto, published by MIT Press in 2018.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="SAI VEMPRALA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sai Vemprala is one of the authors of the technical report "Chatgpt for robotics: Design principles and model abilities" published by Microsoft in February 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ROGERIO BONATTI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rogerio Bonatti is one of the authors of the technical report "Chatgpt for robotics: Design principles and model abilities" published by Microsoft in February 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ARTHUR BUCKER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Arthur Bucker is one of the authors of the technical report "Chatgpt for robotics: Design principles and model abilities" published by Microsoft in February 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ASHISH KAPOOR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ashish Kapoor is one of the authors of the technical report "Chatgpt for robotics: Design principles and model abilities" published by Microsoft in February 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="CHATGPT FOR ROBOTICS: DESIGN PRINCIPLES AND MODEL ABILITIES">
      <data key="d0">TECHNICAL REPORT, RESEARCH</data>
      <data key="d1">A technical report titled "Chatgpt for robotics: Design principles and model abilities" published by Microsoft in February 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="VOYAGER: AN OPEN-ENDED EMBODIED AGENT WITH LARGE LANGUAGE MODELS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Voyager: An open-ended embodied agent with large language models" published as an arXiv preprint in 2023.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JANE X WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jane X Wang is one of the authors of the paper "Learning to reinforcement learn" published as an arXiv preprint in 2016.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ZEB KURTH-NELSON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zeb Kurth-Nelson is one of the authors of the paper "Learning to reinforcement learn" published as an arXiv preprint in 2016.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DHRUVA TIRUMALA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dhruva Tirumala is one of the authors of the paper "Learning to reinforcement learn" published as an arXiv preprint in 2016.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="HUBERT SOYER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hubert Soyer is one of the authors of the paper "Learning to reinforcement learn" published as an arXiv preprint in 2016.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JOEL Z LEIBO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Joel Z Leibo is one of the authors of the paper "Learning to reinforcement learn" published as an arXiv preprint in 2016.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="REMI MUNOS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Remi Munos is one of the authors of the paper "Learning to reinforcement learn" published as an arXiv preprint in 2016.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="CHARLES BLUNDELL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Charles Blundell is one of the authors of the paper "Learning to reinforcement learn" published as an arXiv preprint in 2016.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="DHARSHAN KUMARAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dharshan Kumaran is one of the authors of the paper "Learning to reinforcement learn" published as an arXiv preprint in 2016.</data>
      <data key="d2">34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="MATT BOTVINICK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Matt Botvinick is one of the authors of the paper "Learning to reinforcement learn" published as an arXiv preprint in 2016.
Matt Botvinick is an author who contributed to the paper "Learning to reinforcement learn."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="LEI WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lei Wang is one of the authors of the paper "A survey on large language model based autonomous agents" published in Frontiers of Computer Science.
Lei Wang is an author who contributed to the paper "A survey on large language model based autonomous agents."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="CHEN MA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chen Ma is one of the authors of the paper "A survey on large language model based autonomous agents" published in Frontiers of Computer Science.
Chen Ma is an author who contributed to the paper "A survey on large language model based autonomous agents."
Chen Ma is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="XUEYANG FENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xueyang Feng is one of the authors of the paper "A survey on large language model based autonomous agents" published in Frontiers of Computer Science.
Xueyang Feng is an author who contributed to the paper "A survey on large language model based autonomous agents."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ZEYU ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zeyu Zhang is one of the authors of the paper "A survey on large language model based autonomous agents" published in Frontiers of Computer Science.
Zeyu Zhang is an author who contributed to the paper "A survey on large language model based autonomous agents."
Zeyu Zhang is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="HAO YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hao Yang is one of the authors of the paper "A survey on large language model based autonomous agents" published in Frontiers of Computer Science.
Hao Yang is an author who contributed to the paper "A survey on large language model based autonomous agents."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JINGSEN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jingsen Zhang is one of the authors of the paper "A survey on large language model based autonomous agents" published in Frontiers of Computer Science.
Jingsen Zhang is an author who contributed to the paper "A survey on large language model based autonomous agents."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="ZHIYUAN CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhiyuan Chen is one of the authors of the paper "A survey on large language model based autonomous agents" published in Frontiers of Computer Science.
Zhiyuan Chen is an author who contributed to the paper "A survey on large language model based autonomous agents."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="JIAKAI TANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jiakai Tang is one of the authors of the paper "A survey on large language model based autonomous agents" published in Frontiers of Computer Science.
Jiakai Tang is an author who contributed to the paper "A survey on large language model based autonomous agents."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3</data>
    </node>
    <node id="XU CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xu Chen is one of the authors
Xu Chen is an author who contributed to the paper "A survey on large language model based autonomous agents."
Xu Chen is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,34d0bb2211fc795fe1096442e086a2b3,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SHAN KUMARAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shan Kumaran is an author who contributed to the paper "Learning to reinforcement learn."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="LEARNING TO REINFORCEMENT LEARN">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Shan Kumaran and Matt Botvinick, published as an arXiv preprint in 2016.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="A SURVEY ON LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Lei Wang and others, published in Frontiers of Computer Science in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="RUI WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rui Wang is an author who contributed to the papers "Poet: open-ended coevolution of environments and their optimized solutions" and "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="KENNETH O. STANLEY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kenneth O. Stanley is an author who contributed to the papers "Poet: open-ended coevolution of environments and their optimized solutions" and "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="POET: OPEN-ENDED COEVOLUTION OF ENVIRONMENTS AND THEIR OPTIMIZED SOLUTIONS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Rui Wang, Joel Lehman, Jeff Clune, and Kenneth O. Stanley, presented at the Genetic and Evolutionary Computation Conference in 2019.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="ENHANCED POET: OPEN-ENDED REINFORCEMENT LEARNING THROUGH UNBOUNDED INVENTION OF LEARNING CHALLENGES AND THEIR SOLUTIONS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Rui Wang, Joel Lehman, Aditya Rawal, Jiale Zhi, Yulun Li, Jeffrey Clune, and Kenneth Stanley, presented at the International Conference on Machine Learning in 2020.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="QUOC V LE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Quoc V Le is an author who contributed to the papers "Self-consistency improves chain of thought reasoning in language models" and "Chain-of-thought prompting elicits reasoning in large language models."
Quoc V Le is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures" published as an arXiv preprint in 2024.Quoc V Le is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models" published as an arXiv preprint in 2023.
Quoc V Le is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ED H. CHI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ed H. Chi is an author who contributed to the papers "Self-consistency improves chain of thought reasoning in language models" and "Chain-of-thought prompting elicits reasoning in large language models."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou, presented at The Eleventh International Conference on Learning Representations in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="CHAIN-OF-THOUGHT PROMPTING ELICITS REASONING IN LARGE LANGUAGE MODELS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, and Denny Zhou, published in Advances in Neural Information Processing Systems in 2022.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="QINGYUN WU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qingyun Wu is an author who contributed to the paper "Autogen: Enabling next-gen llm applications via multi-agent conversation framework."
Qingyun Wu is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights" presented at the Forty-first International Conference on Machine Learning in 2024.
Qingyun Wu is one of the authors of the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation," published in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="AUTOGEN: ENABLING NEXT-GEN LLM APPLICATIONS VIA MULTI-AGENT CONVERSATION FRAMEWORK">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Qingyun Wu and others, published as an arXiv preprint in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="BENFENG XU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Benfeng Xu is an author who contributed to the paper "Expertprompting: Instructing large language models to be distinguished experts."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="EXPERTPROMPTING: INSTRUCTING LARGE LANGUAGE MODELS TO BE DISTINGUISHED EXPERTS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Benfeng Xu and others, published as an arXiv preprint in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="CHENGRUN YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chengrun Yang is an author who contributed to the paper "Large language models as optimizers."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="LARGE LANGUAGE MODELS AS OPTIMIZERS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Chengrun Yang and others, presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Shunyu Yao and others, presented at The Eleventh International Conference on Learning Representations in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="BENNET YEE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bennet Yee is an author who contributed to the paper "Native client: A sandbox for portable, untrusted x86 native code."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="NATIVE CLIENT: A SANDBOX FOR PORTABLE, UNTRUSTED X86 NATIVE CODE">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Bennet Yee and others, published in Communications of the ACM in 2010.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="WENHAO YU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wenhao Yu is an author who contributed to the paper "Language to rewards for robotic skill synthesis."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="LANGUAGE TO REWARDS FOR ROBOTIC SKILL SYNTHESIS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Wenhao Yu and others, presented at the Conference on Robot Learning in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="SIYU YUAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Siyu Yuan is an author who contributed to the paper "Evoagent: Towards automatic multi-agent generation via evolutionary algorithms."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="EVOAGENT: TOWARDS AUTOMATIC MULTI-AGENT GENERATION VIA EVOLUTIONARY ALGORITHMS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Siyu Yuan and others, published as an arXiv preprint in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="ELIEZER YUDKOWSKY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Eliezer Yudkowsky is an author who contributed to the paper "Artificial Intelligence as a positive and negative factor in global risk."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="ARTIFICIAL INTELLIGENCE AS A POSITIVE AND NEGATIVE FACTOR IN GLOBAL RISK">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Eliezer Yudkowsky and others, published in Global Catastrophic Risks in 2008.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="MATEI ZAHARIA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Matei Zaharia is an author who contributed to the paper "The shift from models to compound ai systems."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="THE SHIFT FROM MODELS TO COMPOUND AI SYSTEMS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Matei Zaharia and others, published on the BAIR blog in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="OMNI: OPEN-ENDEDNESS VIA MODELS OF HUMAN NOTIONS OF INTERESTINGNESS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A research paper authored by Jenny Zhang and others, presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="SHAOKUN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shaokun Zhang is an author who contributed to the paper "Autogen: Enabling next-gen llm applications via multi-agent conversation framework."
Shaokun Zhang is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights" presented at the Forty-first International Conference on Machine Learning in 2024.
Shaokun Zhang is one of the authors of the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation," published in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ADITYA RAWAL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Aditya Rawal is an author who contributed to the paper "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JIALE ZHI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jiale Zhi is an author who contributed to the paper "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="YULUN LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yulun Li is an author who contributed to the paper "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="GAGAN BANSAL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gagan Bansal is an author who contributed to the paper "Autogen: Enabling next-gen llm applications via multi-agent conversation framework."
Gagan Bansal is one of the authors of the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation," published in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JIEYU ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jieyu Zhang is an author who contributed to the paper "Autogen: Enabling next-gen llm applications via multi-agent conversation framework."
Jieyu Zhang is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights" presented at the Forty-first International Conference on Machine Learning in 2024.
Jieyu Zhang is one of the authors of the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation," published in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIRAN WU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yiran Wu is an author who contributed to the paper "Autogen: Enabling next-gen llm applications via multi-agent conversation framework."
Yiran Wu is one of the authors of the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation," published in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ERKANG ZHU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Erkang Zhu is an author who contributed to the paper "Autogen: Enabling next-gen llm applications via multi-agent conversation framework."
Erkang Zhu is one of the authors of the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation," published in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="BEIBIN LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Beibin Li is an author who contributed to the paper "Autogen: Enabling next-gen llm applications via multi-agent conversation framework."
Beibin Li is one of the authors of the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation," published in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LI JIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Li Jiang is an author who contributed to the paper "Autogen: Enabling next-gen llm applications via multi-agent conversation framework."
Li Jiang is one of the authors of the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation," published in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="XIAOYUN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiaoyun Zhang is an author who contributed to the paper "Autogen: Enabling next-gen llm applications via multi-agent conversation framework."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="CHI WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chi Wang is an author who contributed to the paper "Autogen: Enabling next-gen llm applications via multi-agent conversation framework."
Chi Wang is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights" presented at the Forty-first International Conference on Machine Learning in 2024.
Chi Wang is one of the authors of the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation," published in 2023.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="AN YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">An Yang is an author who contributed to the paper "Expertprompting: Instructing large language models to be distinguished experts."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JUNYANG LIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Junyang Lin is an author who contributed to the paper "Expertprompting: Instructing large language models to be distinguished experts."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="QUAN WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Quan Wang is an author who contributed to the paper "Expertprompting: Instructing large language models to be distinguished experts."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="CHANG ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chang Zhou is an author who contributed to the paper "Expertprompting: Instructing large language models to be distinguished experts."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="YONGDONG ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yongdong Zhang is an author who contributed to the paper "Expertprompting: Instructing large language models to be distinguished experts."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="ZHENDONG MAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhendong Mao is an author who contributed to the paper "Expertprompting: Instructing large language models to be distinguished experts."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="YIFENG LU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yifeng Lu is an author who contributed to the paper "Large language models as optimizers."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="HANXIAO LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hanxiao Liu is an author who contributed to the paper "Large language models as optimizers."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JEFFREY ZHAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jeffrey Zhao is an author who contributed to the paper "React: Synergizing reasoning and acting in language models."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="DIAN YU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dian Yu is an author who contributed to the paper "React: Synergizing reasoning and acting in language models."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="IZHAK SHAFRAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Izhak Shafran is an author who contributed to the paper "React: Synergizing reasoning and acting in language models."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="KARTHIK R NARASIMHAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Karthik R Narasimhan is an author who contributed to the paper "React: Synergizing reasoning and acting in language models."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="YUAN CAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuan Cao is an author who contributed to the paper "React: Synergizing reasoning and acting in language models."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="DAVID SEHR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">David Sehr is an author who contributed to the paper "Native client: A sandbox for portable, untrusted x86 native code."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="GREGORY DARDYK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gregory Dardyk is an author who contributed to the paper "Native client: A sandbox for portable, untrusted x86 native code."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="J BRADLEY CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">J Bradley Chen is an author who contributed to the paper "Native client: A sandbox for portable, untrusted x86 native code."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="ROBERT MUTH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Robert Muth is an author who contributed to the paper "Native client: A sandbox for portable, untrusted x86 native code."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="TAVIS ORMANDY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tavis Ormandy is an author who contributed to the paper "Native client: A sandbox for portable, untrusted x86 native code."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="SHIKI OKASAKA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shiki Okasaka is an author who contributed to the paper "Native client: A sandbox for portable, untrusted x86 native code."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="NEHA NARULA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Neha Narula is an author who contributed to the paper "Native client: A sandbox for portable, untrusted x86 native code."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="NICHOLAS FULLAGAR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nicholas Fullagar is an author who contributed to the paper "Native client: A sandbox for portable, untrusted x86 native code."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="NIMROD GILEADI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nimrod Gileadi is an author who contributed to the paper "Language to rewards for robotic skill synthesis."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="SEAN KIRMANI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sean Kirmani is an author who contributed to the paper "Language to rewards for robotic skill synthesis."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="MONTSERRAT GONZALEZ ARENAS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Montserrat Gonzalez Arenas is an author who contributed to the paper "Language to rewards for robotic skill synthesis."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="HAO-TIEN LEWIS CHIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hao-Tien Lewis Chiang is an author who contributed to the paper "Language to rewards for robotic skill synthesis."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="TOM EREZ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tom Erez is an author who contributed to the paper "Language to rewards for robotic skill synthesis."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="LEONARD HASENCLEVER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Leonard Hasenclever is an author who contributed to the paper "Language to rewards for robotic skill synthesis."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JAN HUMPLIK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jan Humplik is an author who contributed to the paper "Language to rewards for robotic skill synthesis."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JIANGJIE CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jiangjie Chen is an author who contributed to the paper "Evoagent: Towards automatic multi-agent generation via evolutionary algorithms."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="DEQING YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Deqing Yang is an author who contributed to the paper "Evoagent: Towards automatic multi-agent generation via evolutionary algorithms."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="LINGJIAO CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lingjiao Chen is an author who contributed to the paper "The shift from models to compound ai systems."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JARED QUINCY DAVIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jared Quincy Davis is an author who contributed to the paper "The shift from models to compound ai systems."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="CHRIS POTTS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chris Potts is an author who contributed to the paper "The shift from models to compound ai systems."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JAMES ZOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">James Zou is an author who contributed to the paper "The shift from models to compound ai systems."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="MICHAEL CARBIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Michael Carbin is an author who contributed to the paper "The shift from models to compound ai systems."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="JONATHAN FRANKLE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jonathan Frankle is an author who contributed to the paper "The shift from models to compound ai systems."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="NAVEEN RAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Naveen Rao is an author who contributed to the paper "The shift from models to compound ai systems."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="ALI GHODSI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ali Ghodsi is an author who contributed to the paper "The shift from models to compound ai systems."</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </node>
    <node id="KENNETH STANLEY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kenneth Stanley is an author who contributed to the paper "OMNI: Open-endedness via models of human notions of interestingness."
Kenneth Stanley is one of the authors of the paper titled "OMNI: Open-endedness via models of human notions of interestingness" presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">2600a1ed94ad2d3675ea80575c39cbd1,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="OMNI">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">OMNI is a model that explores open-endedness via human notions of interestingness, presented at The Twelfth International Conference on Learning Representations in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JIALE LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jiale Liu is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights" presented at the Forty-first International Conference on Machine Learning in 2024.
Jiale Liu is one of the authors of the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation," published in 2023.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LINXIN SONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Linxin Song is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="RANJAY KRISHNA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ranjay Krishna is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="OFFLINE TRAINING OF LANGUAGE MODEL AGENTS WITH FUNCTIONS AS LEARNABLE WEIGHTS">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">This is a method for training language model agents using functions as learnable weights, presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="XIAOHE BO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiaohe Bo is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="RUI LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rui Li is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="QUANYU DAI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Quanyu Dai is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JIEMING ZHU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jieming Zhu is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="ZHENHUA DONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhenhua Dong is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="A SURVEY ON THE MEMORY MECHANISM OF LARGE LANGUAGE MODEL BASED AGENTS">
      <data key="d0">SURVEY, PAPER</data>
      <data key="d1">This is a survey paper on the memory mechanisms of large language model-based agents, published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="HENG-TZE CHENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Heng-Tze Cheng is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures" published as an arXiv preprint in 2024.Heng-Tze Cheng is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models" published as an arXiv preprint in 2023.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="ED H CHI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ed H Chi is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models" published as an arXiv preprint in 2023.Ed H Chi is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures" published as an arXiv preprint in 2024.
Ed H Chi is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="TAKE A STEP BACK: EVOKING REASONING VIA ABSTRACTION IN LARGE LANGUAGE MODELS">
      <data key="d0">PAPER, METHOD</data>
      <data key="d1">This paper discusses a method for evoking reasoning via abstraction in large language models, published as an arXiv preprint in 2023.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="PEI ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Pei Zhou is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JAY PUJARA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jay Pujara is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="XIANG REN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiang Ren is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SELF-DISCOVER: LARGE LANGUAGE MODELS SELF-COMPOSE REASONING STRUCTURES">
      <data key="d0">PAPER, METHOD</data>
      <data key="d1">This paper discusses a method where large language models self-compose reasoning structures, published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="WANGCHUNSHU ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wangchunshu Zhou is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="YIXIN OU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yixin Ou is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SHENGWEI DING">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shengwei Ding is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="LONG LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Long Li is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JIALONG WU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jialong Wu is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="TIANNAN WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tiannan Wang is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="JIAMIN CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jiamin Chen is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SHUAI WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shuai Wang is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="XIAOHUA XU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiaohua Xu is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="NINGYU ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ningyu Zhang is one of the authors of the paper titled "Symbolic learning enables self-evolving agents" published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SYMBOLIC LEARNING ENABLES SELF-EVOLVING AGENTS">
      <data key="d0">PAPER, METHOD</data>
      <data key="d1">This paper discusses how symbolic learning can enable self-evolving agents, published as an arXiv preprint in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="MINGCHEN ZHUGE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mingchen Zhuge is one of the authors of the paper titled "GPTSwarm: Language agents as optimizable graphs" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="WENYI WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wenyi Wang is one of the authors of the paper titled "GPTSwarm: Language agents as optimizable graphs" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="LOUIS KIRSCH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Louis Kirsch is one of the authors of the paper titled "GPTSwarm: Language agents as optimizable graphs" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="FRANCESCO FACCIO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Francesco Faccio is one of the authors of the paper titled "GPTSwarm: Language agents as optimizable graphs" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="DMITRII KHIZBULLIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dmitrii Khizbullin is one of the authors of the paper titled "GPTSwarm: Language agents as optimizable graphs" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="J&#220;RGEN SCHMIDHUBER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">J&#252;rgen Schmidhuber is one of the authors of the paper titled "GPTSwarm: Language agents as optimizable graphs" presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="GPTSWARM">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">GPTSwarm is a method that treats language agents as optimizable graphs, presented at the Forty-first International Conference on Machine Learning in 2024.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="LUISA ZINTGRAF">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Luisa Zintgraf is one of the authors of the paper titled "Varibad: Variational bayes-adaptive deep RL via meta-learning" published in the Journal of Machine Learning Research in 2021.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SEBASTIAN SCHULZE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sebastian Schulze is one of the authors of the paper titled "Varibad: Variational bayes-adaptive deep RL via meta-learning" published in the Journal of Machine Learning Research in 2021.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="LEO FENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Leo Feng is one of the authors of the paper titled "Varibad: Variational bayes-adaptive deep RL via meta-learning" published in the Journal of Machine Learning Research in 2021.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="MAXIMILIAN IGL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Maximilian Igl is one of the authors of the paper titled "Varibad: Variational bayes-adaptive deep RL via meta-learning" published in the Journal of Machine Learning Research in 2021.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="KYRIACOS SHIARLIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kyriacos Shiarlis is one of the authors of the paper</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="SHIMON WHITEON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shimon Whiteson is one of the authors of the paper titled "Varibad: Variational bayes-adaptive deep RL via meta-learning" published in the Journal of Machine Learning Research in 2021.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="VARIBAD">
      <data key="d0">ALGORITHM, METHOD</data>
      <data key="d1">Varibad is a method for variational bayes-adaptive deep reinforcement learning via meta-learning, published in the Journal of Machine Learning Research in 2021.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="GITHUB">
      <data key="d0">PLATFORM, TOOL</data>
      <data key="d1">GitHub is a platform where the detailed prompts and framework code for the Meta Agent in ADAS are available.
The platform where the full framework code is available, specifically at the URL https://github.com/ShengranHu/ADAS.
GitHub is an online platform where the code and agents from the Meta Agent Search experiment can be found.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2,cc802d9b841fde55e9c0c2ba0ef7869d,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="FRAMEWORK CODE">
      <data key="d0">COMPONENT, TOOL</data>
      <data key="d1">Framework Code is the code used in the ADAS framework to implement the Meta Agent and other components, as described in the supplementary material of the paper "Automated Design of Agentic Systems."</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="EXPERIMENT DETAILS">
      <data key="d0">COMPONENT, TOOL</data>
      <data key="d1">Experiment Details are provided in the supplementary material of the paper "Automated Design of Agentic Systems" for the ARC Challenge and other reasoning and problem-solving domains.
Details about the experiments conducted for the ARC challenge, including the representation of grids and the use of meta agents.
Details about the experimental setup, including the number of questions, evaluation methods, and datasets used.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447,cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="EXAMPLE AGENTS">
      <data key="d0">COMPONENT, TOOL</data>
      <data key="d1">Example Agents are provided in the supplementary material of the paper "Automated Design of Agentic Systems" to illustrate the design of new agentic systems.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="COST OF EXPERIMENTS">
      <data key="d0">COMPONENT, TOOL</data>
      <data key="d1">Cost of Experiments is a section in the supplementary material of the paper "Automated Design of Agentic Systems" that details the costs associated with the experiments conducted.
The financial cost associated with running search and evaluation experiments, particularly in the context of using language models like GPT-3.5-Turbo-0125 and GPT-4o-mini.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SUPPLEMENTARY MATERIAL">
      <data key="d0">COMPONENT, TOOL</data>
      <data key="d1">Supplementary Material is additional content provided in the paper "Automated Design of Agentic Systems" that includes prompts, framework code, experiment details, baselines, example agents, and cost of experiments.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="URL">
      <data key="d0">COMPONENT, TOOL</data>
      <data key="d1">URL is a web address provided in the paper "OMNI: Open-endedness via models of human notions of interestingness" for accessing the paper on openreview.net.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="OPENREVIEW">
      <data key="d0">PLATFORM, TOOL</data>
      <data key="d1">OpenReview is a platform where the paper "OMNI: Open-endedness via models of human notions of interestingness" is available.</data>
      <data key="d2">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </node>
    <node id="NAME">
      <data key="d0">SECTION, COMPONENT</data>
      <data key="d1">A section in the output where the meta agent provides the name of the next agent architecture it proposes.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="IMPLEMENTATION MISTAKES">
      <data key="d0">ERROR, ISSUE</data>
      <data key="d1">Mistakes that the meta agent may make in the implementation of the proposed architecture, which need to be identified and corrected during self-reflection.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="FRAMEWORK">
      <data key="d0">SYSTEM, CODE</data>
      <data key="d1">A simple framework provided to the meta agent to implement basic functions such as querying Foundation Models and formatting prompts. It consists of fewer than 100 lines of code and uses namedtuple Info objects for encapsulating information.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="NAMEDTUPLE INFO OBJECT">
      <data key="d0">DATA STRUCTURE, OBJECT</data>
      <data key="d1">A data structure used in the framework to encapsulate different types of information, facilitating communication between different modules.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="APPENDIX B">
      <data key="d0">SECTION, COMPONENT</data>
      <data key="d1">A section in the document where the framework code is available.
Appendix B specifies the types of tasks/benchmarks and the corresponding methods used to extract answers and generate metrics.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="APPENDICES C AND D">
      <data key="d0">SECTION, COMPONENT</data>
      <data key="d1">Sections in the document where additional information is available.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="OUTPUT INSTRUCTION AND EXAMPLE">
      <data key="d0">INSTRUCTION, GUIDELINE</data>
      <data key="d1">A set of instructions and an example provided to guide the meta agent in generating the output.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="OVERALL IDEA">
      <data key="d0">SECTION, COMPONENT</data>
      <data key="d1">A part of the "thought" section where the meta agent describes its reasoning and the overall concept behind the agent design.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="IMPLEMENTATION">
      <data key="d0">SECTION, COMPONENT</data>
      <data key="d1">A part of the "thought" section where the meta agent details the implementation steps of the proposed agent.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="WRONG IMPLEMENTATION EXAMPLES">
      <data key="d0">ERROR, ISSUE</data>
      <data key="d1">Examples of potential mistakes that the meta agent may make in the implementation, provided to help identify and correct errors.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="SELF-REFLECTION ROUND 1">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">The first round of self-reflection where the meta agent reviews the proposed architecture and implementation to identify mistakes and suggest improvements.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="SELF-REFLECTION ROUND 2">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">The second round of self-reflection where the meta agent further revises the code using tips from the "</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="RUNTIME ERROR">
      <data key="d0">ERROR, ISSUE</data>
      <data key="d1">An error encountered during the execution of the generated code, prompting the meta agent to perform self-reflection and debugging.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="DEBUG_THOUGHT">
      <data key="d0">SECTION, COMPONENT</data>
      <data key="d1">A section in the output where the meta agent captures its thought process for debugging the current code after encountering a runtime error.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="INFO OBJECT">
      <data key="d0">DATA STRUCTURE, OBJECT</data>
      <data key="d1">A namedtuple used in the framework to encapsulate different types of information, facilitating communication between different modules.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0</data>
    </node>
    <node id="FM MODULE">
      <data key="d0">SYSTEM, MODULE</data>
      <data key="d1">A module in the framework that automatically constructs the prompt by concatenating all input Info objects into a structured format.
A module that automatically constructs prompts by concatenating all input Info objects into a structured format, with each Info titled by its metadata. It includes functionalities like generating prompts and querying the FM with provided input information and instructions.
FM Module is a component used in the initial candidate solution generation process, focusing on 'thinking' and 'code'.
A functional module used in various methods and agents, such as Multi-Step Peer Review Agent and Divide and Conquer Agent, for tasks like thinking, answering, and providing feedback.</data>
      <data key="d2">282313a8340c6792e8c35f53ed157cd0,449db721e37968e073e3579b59e023b2,97457e990eb6e3c88c11c862f9e3265b,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="INFO">
      <data key="d0">DATA STRUCTURE, NAMED TUPLE</data>
      <data key="d1">A named tuple used for holding task information, including attributes like name, author, content, and iteration index.
Information provided as input to various modules, often used to guide the feedback and refinement processes.
An object used to encapsulate information about sub-problems, visual representations, and other data elements processed by various modules.</data>
      <data key="d2">84317ae35cc75d612287186d93461447,d66dc9ce4a9545b44f7486ea057b5937,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="FORMAT_INST">
      <data key="d0">FUNCTION, LAMBDA</data>
      <data key="d1">A lambda function that formats instructions for FM responses, ensuring the JSON format is correct and all fields are included.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="ROLE_DESC">
      <data key="d0">FUNCTION, LAMBDA</data>
      <data key="d1">A lambda function that describes the role of the FM Module, generating a role description string.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="GET_JSON_RESPONSE_FROM_GPT">
      <data key="d0">FUNCTION, METHOD</data>
      <data key="d1">A function that gets a JSON response from a GPT model, taking arguments like user message, model, system message, and temperature, and returning a JSON dictionary.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="AGENT SYSTEM">
      <data key="d0">SOFTWARE COMPONENT, SYSTEM</data>
      <data key="d1">A system that processes task information using a forward function, which can return either a namedtuple Info or a string as the answer.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="TASK DESCRIPTIONS">
      <data key="d0">DATA STRUCTURE, INFORMATION</data>
      <data key="d1">Descriptions of tasks that are used to facilitate communication between different modules in the FM Module.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="TOOL FUNCTION CALLS">
      <data key="d0">DATA STRUCTURE, INFORMATION</data>
      <data key="d1">Results from tool function calls that are used as input Info objects in the FM Module.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="META-AGENT SEARCH">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">A simple framework used in the context of the FM Module for agentic systems.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="BACKOFF">
      <data key="d0">FUNCTION, METHOD</data>
      <data key="d1">A method used to handle exceptions, specifically RateLimitError, in the get_json_response_from_gpt function.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="RATE LIMIT ERROR">
      <data key="d0">ERROR, EXCEPTION</data>
      <data key="d1">An error handled by the backoff method in the get_json_response_from_gpt function.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="SYSTEM MESSAGE">
      <data key="d0">DATA STRUCTURE, INFORMATION</data>
      <data key="d1">A message used as an argument in the get_json_response_from_gpt function to guide the GPT model's response.
A type of message in the multi-turn interaction sequence within the Orca-Bench dataset.
A predefined message used to guide the evaluation process for different types of problems.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,bd4eb9459bc29b4c2da4658914fd4635,d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="SAMPLING TEMPERATURE">
      <data key="d0">PARAMETER, CONFIGURATION</data>
      <data key="d1">A parameter used in the get_json_response_from_gpt function to control the randomness of the GPT model's output.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="OUTPUT FIELDS">
      <data key="d0">DATA STRUCTURE, INFORMATION</data>
      <data key="d1">Fields expected in the output of the FM Module.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="UNIQUE IDENTIFIER">
      <data key="d0">DATA STRUCTURE, IDENTIFIER</data>
      <data key="d1">A unique ID for instances of the FM Module.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="INSTRUCTION">
      <data key="d0">DATA STRUCTURE, INFORMATION</data>
      <data key="d1">Instructions provided to the FM Module for generating prompts and querying information.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="ITERATION INDEX">
      <data key="d0">PARAMETER, CONFIGURATION</data>
      <data key="d1">An index used to track iterations in tasks processed by the FM Module.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="COT_INITIAL_INSTRUCTION">
      <data key="d0">DATA STRUCTURE, INFORMATION</data>
      <data key="d1">An instruction for initial reasoning in the self-reflection method.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="COT_REFLECT_INSTRUCTION">
      <data key="d0">DATA STRUCTURE, INFORMATION</data>
      <data key="d1">An instruction for reflecting on previous attempts and feedback in the self-reflection method.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="CRITIC INSTRUCTION">
      <data key="d0">DATA STRUCTURE, INFORMATION</data>
      <data key="d1">An instruction for providing feedback and correcting the answer in the self-reflection method.</data>
      <data key="d2">d66dc9ce4a9545b44f7486ea057b5937</data>
    </node>
    <node id="COT_MODULE">
      <data key="d0">MODULE, COMPONENT</data>
      <data key="d1">A module named FM_Module that handles 'thinking' and 'answer' processes, used in the Chain-of-Thought method.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
      <data key="d3">MODULE, COMPONENT</data>
    </node>
    <node id="CRITIC_INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">An instruction that asks the user to review and criticize the answer, or confirm its correctness by outputting 'True'.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
      <data key="d3">INSTRUCTION</data>
    </node>
    <node id="CRITIC_MODULE">
      <data key="d0">MODULE, COMPONENT</data>
      <data key="d1">A module named FM_Module that handles 'feedback' and 'correct' processes, used in the Critic method.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
      <data key="d3">MODULE, COMPONENT</data>
    </node>
    <node id="N_MAX">
      <data key="d0">PARAMETER</data>
      <data key="d1">A parameter that sets the maximum number of attempts to 5.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="TASKINFO">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Information about the task that is used as input for the modules.
TaskInfo is the input data provided to the agent for solving a task.
Task information provided as input to various modules and processes.
Information related to the task that is processed by various modules such as the decomposition module and integration module.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447,ef75d2c866bee783577ed9f65707cf13</data>
      <data key="d3">DATA, INPUT</data>
    </node>
    <node id="EXAMPLE INPUT-OUTPUT GRID">
      <data key="d0">DATA, EXAMPLE</data>
      <data key="d1">Paired example inputs and outputs grids used to demonstrate the transformation rules in the ARC challenge.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
      <data key="d3">DATA, EXAMPLE</data>
    </node>
    <node id="GPT-4O-2024-05-13">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">A version of the GPT-4 language model used by the meta agent in the ARC challenge.
A version of the GPT-4 model used by the meta agent for evaluation.
GPT-4o-2024-05-13 is a version of the GPT-4 language model used by the meta agent in the described experiments.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447</data>
      <data key="d3">TECHNOLOGY, LANGUAGE MODEL</data>
    </node>
    <node id="GPT-3.5-TURBO-0125">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">A version of the GPT-3.5 language model used to evaluate discovered agents and baselines in the ARC challenge.
A version of the GPT-3.5 model used by discovered agents and baselines to reduce compute costs.A version of the GPT-3.5 model used by discovered agents and baselines to reduce compute cost.
GPT-3.5-turbo-0125 is a version of the GPT-3.5 language model used to evaluate discovered agents and baselines to reduce compute cost.
A language model used during the evaluation of discovered agents, contributing significantly to the cost of experiments.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447,ef75d2c866bee783577ed9f65707cf13</data>
      <data key="d3">TECHNOLOGY, LANGUAGE MODEL</data>
    </node>
    <node id="EXACT MATCH">
      <data key="d0">METRIC</data>
      <data key="d1">A metric used to calculate the accuracy rate by comparing the reference solution and the predicted answer in the ARC challenge.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
      <data key="d3">METRIC</data>
    </node>
    <node id="FM_MODULE">
      <data key="d0">MODULE, COMPONENT</data>
      <data key="d1">A module used in both the Chain-of-Thought and Critic methods to handle various processes like 'thinking', 'answer', 'feedback', and 'correct'.
A module used for various tasks such as providing human-like feedback, expert feedback, and refining solutions.
A flexible module used in various contexts such as decomposition, integration, visual representation, verification, and chain-of-thought processes.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447,ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="INPUT GRID">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">A grid that serves as the input in the ARC challenge, represented as a rectangular matrix of integers between 0 and 9.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="OUTPUT GRID">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">A grid that serves as the output in the ARC challenge, produced by applying a transformation rule to the input grid.</data>
      <data key="d2">4b43decac6833d1515992f8869ecada7</data>
    </node>
    <node id="BEST AGENT">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">The best agent discovered by Meta Agent Search for solving tasks in the ARC benchmark.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="INITIAL INSTRUCTION">
      <data key="d0">INSTRUCTION, COMMAND</data>
      <data key="d1">The initial instruction given to the FM Module to generate candidate solutions, which is 'Please think step by step and then solve the task by writing the code.'</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="INITIAL SOLUTION">
      <data key="d0">SOLUTION, OUTPUT</data>
      <data key="d1">Initial Solution is the output generated by the FM Module based on the initial instruction and TaskInfo.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="CORRECT EXAMPLES">
      <data key="d0">DATA, EXAMPLES</data>
      <data key="d1">Correct Examples are the examples that the initial solution passed successfully.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="WRONG EXAMPLES">
      <data key="d0">DATA, EXAMPLES</data>
      <data key="d1">Wrong Examples are the examples that the initial solution failed to pass.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="ENSEMBLE AGENT">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">An agent that uses multiple FM Modules to generate initial candidate solutions for solving tasks.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="NUM_CANDIDATES">
      <data key="d0">PARAMETER, VARIABLE</data>
      <data key="d1">The number of initial candidate solutions generated by the FM Module, set to 5 in the experiment.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="THOUGHTS">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">The intermediate output generated by the FM Module, consisting of 'thinking' and 'code'.
The output generated by various modules, including the thought process and feedback.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2,84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="CORRECT_COUNT">
      <data key="d0">METRIC, DATA</data>
      <data key="d1">The number of correct examples that an initial solution passed, used to evaluate the solution's effectiveness.</data>
      <data key="d2">449db721e37968e073e3579b59e023b2</data>
    </node>
    <node id="THINKING">
      <data key="d0">PROCESS, ATTRIBUTE</data>
      <data key="d1">The thought process or reasoning associated with a solution or feedback.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="CORRECT_EXAMPLES">
      <data key="d0">DATA, METRIC</data>
      <data key="d1">Examples where the code produced correct results, used to evaluate the effectiveness of solutions.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="WRONG_EXAMPLES">
      <data key="d0">DATA, METRIC</data>
      <data key="d1">Examples where the code produced incorrect results, used to evaluate the effectiveness of solutions.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="INITIAL_SOLUTIONS">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">Initial set of solutions generated based on the initial code and feedback.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="HUMAN_LIKE_FEEDBACK_MODULE">
      <data key="d0">MODULE, SYSTEM</data>
      <data key="d1">A module designed to simulate human-like feedback for code, focusing on common mistakes, heuristic corrections, and best practices.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="HUMAN_FEEDBACK_INSTRUCTION">
      <data key="d0">INSTRUCTION, DATA</data>
      <data key="d1">Instruction provided to the human-like feedback module to guide the feedback process.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="EXPERT_ROLES">
      <data key="d0">ROLE, ATTRIBUTE</data>
      <data key="d1">Different roles assigned to expert advisors, such as Efficiency Expert, Readability Expert, and Simplicity Expert.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="EXPERT_ADVISORS">
      <data key="d0">MODULE, SYSTEM</data>
      <data key="d1">Modules assigned to different expert roles to provide targeted feedback for code improvement.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="EXPERT_INSTRUCTION">
      <data key="d0">INSTRUCTION, DATA</data>
      <data key="d1">Instruction provided to expert advisors to guide the evaluation and feedback process.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="REFINEMENT_MODULE">
      <data key="d0">MODULE, SYSTEM</data>
      <data key="d1">A module designed to parse and structure feedback to refine solutions iteratively.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="MAX_REFINEMENT_ITERATIONS">
      <data key="d0">PARAMETER, ATTRIBUTE</data>
      <data key="d1">The maximum number of iterations allowed for refining solutions.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="REFINEMENT_INSTRUCTION">
      <data key="d0">INSTRUCTION, DATA</data>
      <data key="d1">Instruction provided to the refinement module to guide the refinement process.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="REFINED_SOLUTIONS">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">Solutions that have been refined based on structured feedback.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="SORTED_SOLUTIONS">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">Refined solutions sorted by their performance, specifically by the number of correct examples.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="TOP_SOLUTIONS">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">The top-performing solutions selected from the sorted solutions.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="FINAL_DECISION_INSTRUCTION">
      <data key="d0">INSTRUCTION, DATA</data>
      <data key="d1">Instruction provided to the final decision module to guide the final decision-making process.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="FINAL_DECISION_MODULE">
      <data key="d0">MODULE, SYSTEM</data>
      <data key="d1">A module designed to make the final decision by reasoning over the top solutions and writing the final code.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="FINAL_THOUGHTS">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">The final thought process and code generated by the final decision module.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="META_AGENT">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">An agent using the "gpt-4o-2024-05-13" model for evaluation.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="DISCOVERED_AGENTS">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">Agents evaluated using the "gpt-3.5-turbo-0125" model to reduce compute cost.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="CONTENT">
      <data key="d0">DATA, ATTRIBUTE</data>
      <data key="d1">The actual text or information contained within feedback or other data elements.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="ROLE">
      <data key="d0">ATTRIBUTE, CATEGORY</data>
      <data key="d1">The specific function or position assigned to expert advisors, such as Efficiency Expert, Readability Expert, and Simplicity Expert.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="TEMPERATURE">
      <data key="d0">PARAMETER, ATTRIBUTE</data>
      <data key="d1">A parameter used in various modules to control the randomness or creativity of the output.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="ZERO-SHOT STYLE QUESTIONS">
      <data key="d0">DATA, QUESTION TYPE</data>
      <data key="d1">Questions that are answered without any prior examples or training on similar questions.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="ONE-SHOT STYLE QUESTIONS">
      <data key="d0">DATA, QUESTION TYPE</data>
      <data key="d1">Questions that are answered with the help of one example or prior training on a similar question.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="AUTOMATED DESIGN OF AGENTIC SYSTEMS">
      <data key="d0">DOCUMENT, RESEARCH</data>
      <data key="d1">A document or research paper discussing the automated design of agentic systems, including experimental details and methodologies.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="DISCOVERED AGENTS">
      <data key="d0">AGENT, SYSTEM</data>
      <data key="d1">Agents that are evaluated using models like GPT-3.5-turbo-0125 to reduce compute costs.</data>
      <data key="d2">84317ae35cc75d612287186d93461447</data>
    </node>
    <node id="REASONING AND PROBLEM-SOLVING DOMAINS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="NON-NATIONALS">
      <data key="d0">DEMOGRAPHIC, GROUP</data>
      <data key="d1">Non-nationals are individuals who are not citizens of the country they reside in. In the context of Bahrain, they make up more than half of the population.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="IMMIGRANTS">
      <data key="d0">DEMOGRAPHIC, GROUP</data>
      <data key="d1">Immigrants are individuals who move to a country other than their native one. In Bahrain, they make up about 55% of the overall population.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="INDIANS">
      <data key="d0">DEMOGRAPHIC, GROUP</data>
      <data key="d1">Indians are a demographic group in Bahrain, with roughly 290,000 individuals reported between 2005-2009.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="BANGLADESHIS">
      <data key="d0">DEMOGRAPHIC, GROUP</data>
      <data key="d1">Bangladeshis are a demographic group in Bahrain, with roughly 125,000 individuals reported between 2005-2009.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="PAKISTANIS">
      <data key="d0">DEMOGRAPHIC, GROUP</data>
      <data key="d1">Pakistanis are a demographic group in Bahrain, with roughly 45,000 individuals reported between 2005-2009.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="FILIPINOS">
      <data key="d0">DEMOGRAPHIC, GROUP</data>
      <data key="d1">Filipinos are a demographic group in Bahrain, with roughly 45,000 individuals reported between 2005-2009.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="INDONESIANS">
      <data key="d0">DEMOGRAPHIC, GROUP</data>
      <data key="d1">Indonesians are a demographic group in Bahrain, with roughly 8,000 individuals reported between 2005-2009.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="BIOLOGY">
      <data key="d0">SUBJECT, DOMAIN</data>
      <data key="d1">Biology is one of the domains covered by the GPQA benchmark, consisting of challenging multiple-choice questions.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="PHYSICS">
      <data key="d0">SUBJECT, DOMAIN</data>
      <data key="d1">Physics is one of the domains covered by the GPQA benchmark, consisting of challenging multiple-choice questions.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="CHEMISTRY">
      <data key="d0">SUBJECT, DOMAIN</data>
      <data key="d1">Chemistry is one of the domains covered by the GPQA benchmark, consisting of challenging multiple-choice questions.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="STEM">
      <data key="d0">SUBJECT, DOMAIN</data>
      <data key="d1">STEM (Science, Technology, Engineering, and Mathematics) is one of the subject areas included in the MMLU benchmark.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="SOCIAL SCIENCES">
      <data key="d0">SUBJECT, DOMAIN</data>
      <data key="d1">Social Sciences is one of the subject areas included in the MMLU benchmark.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="HUMANITIES">
      <data key="d0">SUBJECT, DOMAIN</data>
      <data key="d1">Humanities is one of the subject areas included in the MMLU benchmark.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="OPENAI, 2024">
      <data key="d0">AUTHOR, ORGANIZATION</data>
      <data key="d1">OpenAI is the organization mentioned in the context of the meta agent using GPT-4o-2024-05-13.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="DISCRETE REASONING">
      <data key="d0">SKILL, ABILITY</data>
      <data key="d1">Discrete Reasoning is the ability to perform logical reasoning tasks that involve distinct and separate elements, as assessed by the DROP benchmark.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="MULTIPLE PARAGRAPHS">
      <data key="d0">TEXT STRUCTURE, FORMAT</data>
      <data key="d1">Multiple Paragraphs refer to the format of text that the DROP benchmark assesses for comprehension and reasoning.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="GRADUATE-LEVEL GOOGLE-PROOF Q&amp;A BENCHMARK">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">Graduate-Level Google-Proof Q&amp;A Benchmark (GPQA) is a benchmark consisting of challenging multiple-choice questions across the domains of biology, physics, and chemistry.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="MULTILINGUAL GRADE SCHOOL MATH BENCHMARK">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">Multilingual Grade School Math Benchmark (MGSM) evaluates mathematical problem-solving abilities across various languages.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="MASSIVE MULTITASK LANGUAGE UNDERSTANDING">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">Massive Multitask Language Understanding (MMLU) is a benchmark that assesses a model&#8217;s ability to answer questions across a wide range of subjects and difficulty levels.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="AI2 REASONING CHALLENGE">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">AI2 Reasoning Challenge (ARC) is a benchmark used for evaluating reasoning and problem-solving abilities in AI models.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="QUANTUM STATES">
      <data key="d0">PHYSICAL CONCEPT, ENTITY</data>
      <data key="d1">Quantum States refer to the specific states of a quantum system, characterized by distinct energy levels, as discussed in the GPQA example question.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="ENERGY LEVELS">
      <data key="d0">PHYSICAL CONCEPT, ENTITY</data>
      <data key="d1">Energy Levels refer to the specific energies that quantum states can have, as discussed in the GPQA example question.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="UNCERTAINTY PRINCIPLE">
      <data key="d0">PHYSICAL LAW, CONCEPT</data>
      <data key="d1">Uncertainty Principle is a fundamental principle in quantum mechanics that relates the uncertainty in energy and time, as discussed in the GPQA example question.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="DELTA E">
      <data key="d0">PHYSICAL QUANTITY, VARIABLE</data>
      <data key="d1">Delta E refers to the uncertainty in energy, as discussed in the GPQA example question.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="DELTA T">
      <data key="d0">PHYSICAL QUANTITY, VARIABLE</data>
      <data key="d1">Delta T refers to the uncertainty in time, as discussed in the GPQA example question.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="HBAR">
      <data key="d0">PHYSICAL CONSTANT, SYMBOL</data>
      <data key="d1">Hbar is the reduced Planck constant, a fundamental constant in quantum mechanics, as discussed in the GPQA example question.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="PET RABBITS">
      <data key="d0">ANIMAL, PET</data>
      <data key="d1">Pet Rabbits are mentioned in the MGSM example question as being fewer in number compared to pet dogs and cats.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="PET DOGS">
      <data key="d0">ANIMAL, PET</data>
      <data key="d1">Pet Dogs are mentioned in the MGSM example question as being part of the total number of pets in the neighborhood.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="PET CATS">
      <data key="d0">ANIMAL, PET</data>
      <data key="d1">Pet Cats are mentioned in the MGSM example question as being part of the total number of pets in the neighborhood.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="CASSIOPEIA">
      <data key="d0">ASTRONOMICAL OBJECT, CONSTELLATION</data>
      <data key="d1">Cassiopeia is a bright W-shaped constellation in the northern sky, as mentioned in the MMLU example question.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="CENTURUS">
      <data key="d0">ASTRONOMICAL OBJECT, CONSTELLATION</data>
      <data key="d1">Centurus is one of the constellations mentioned in the MMLU example question.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="CYGNUS">
      <data key="d0">ASTRONOMICAL OBJECT, CONSTELLATION</data>
      <data key="d1">Cygnus is one of the constellations mentioned in the MMLU example question.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="CEPHEUS">
      <data key="d0">ASTRONOMICAL OBJECT, CONSTELLATION</data>
      <data key="d1">Cepheus is one of the constellations mentioned in the MMLU example question.</data>
      <data key="d2">10fda605f670bcfccfc13c2ca0dde959</data>
    </node>
    <node id="PHYSICS EXPERT">
      <data key="d0">ROLE</data>
      <data key="d1">A role assigned to a debate module or specialized expert in methods like LLM-Debate and Divide and Conquer Agent.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
      <data key="d3">ROLE</data>
    </node>
    <node id="CHEMISTRY EXPERT">
      <data key="d0">ROLE</data>
      <data key="d1">A role assigned to a debate module or specialized expert in methods like LLM-Debate and Divide and Conquer Agent.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
      <data key="d3">ROLE</data>
    </node>
    <node id="BIOLOGY EXPERT">
      <data key="d0">ROLE</data>
      <data key="d1">A role assigned to a debate module or specialized expert in methods like LLM-Debate and Divide and Conquer Agent.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
      <data key="d3">ROLE</data>
    </node>
    <node id="SCIENCE GENERALIST">
      <data key="d0">ROLE</data>
      <data key="d1">A role assigned to a debate module in methods like LLM-Debate.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
      <data key="d3">ROLE</data>
    </node>
    <node id="PHYSICS CRITIC">
      <data key="d0">ROLE</data>
      <data key="d1">A role assigned to a critic module in methods like Multi-Step Peer Review Agent.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
      <data key="d3">ROLE</data>
    </node>
    <node id="CHEMISTRY CRITIC">
      <data key="d0">ROLE</data>
      <data key="d1">A role assigned to a critic module in methods like Multi-Step Peer Review Agent.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
      <data key="d3">ROLE</data>
    </node>
    <node id="BIOLOGY CRITIC">
      <data key="d0">ROLE</data>
      <data key="d1">A role assigned to a critic module in methods like Multi-Step Peer Review Agent.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
      <data key="d3">ROLE</data>
    </node>
    <node id="GENERAL CRITIC">
      <data key="d0">ROLE</data>
      <data key="d1">A role assigned to a critic module in methods like Multi-Step Peer Review Agent.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
      <data key="d3">ROLE</data>
    </node>
    <node id="FM QUERY">
      <data key="d0">COMPONENT</data>
      <data key="d1">FM Query is a functional module used in various methods like COT-SC and Role Assignment for querying the FM to get answers or choose roles.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="DEBATE MODULE">
      <data key="d0">COMPONENT</data>
      <data key="d1">Debate Module is a functional module used in LLM-Debate, where each module is assigned a unique role and participates in the debate.</data>
      <data key="d2">97457e990eb6e3c88c11c862f9e3265b</data>
    </node>
    <node id="DECOMPOSITION MODULE">
      <data key="d0">MODULE, COMPONENT</data>
      <data key="d1">A module named 'Decomposition Module' that handles the decomposition of tasks into sub-problems. It is instantiated with parameters related to 'thinking' and 'sub_problems'.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SPECIALIZED EXPERT">
      <data key="d0">MODULE, COMPONENT</data>
      <data key="d1">A module named 'Specialized Expert' that is assigned to solve specific sub-problems. It includes roles such as 'Physics Expert', 'Chemistry Expert', 'Biology Expert', and 'General Expert'.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="INTEGRATION MODULE">
      <data key="d0">MODULE, COMPONENT</data>
      <data key="d1">A module named 'Integration Module' that integrates solutions to sub-problems into a final answer. It is instantiated with parameters related to 'thinking' and 'answer'.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SUB_PROBLEMS">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">The sub-problems generated by the decomposition module from the main task.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SUB_SOLUTIONS">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">The solutions to the sub-problems provided by the specialized experts.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="VISUAL REPRESENTATION MODULE">
      <data key="d0">MODULE, COMPONENT</data>
      <data key="d1">A module named 'Visual Representation Module' that generates visual representations of problems, such as diagrams or graphs.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="VERIFICATION MODULE">
      <data key="d0">MODULE, COMPONENT</data>
      <data key="d1">A module named 'Verification Module' that verifies the accuracy and relevance of visual representations and provides feedback and suggestions for improvement.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="CHAIN-OF-THOUGHT MODULE">
      <data key="d0">MODULE, COMPONENT</data>
      <data key="d1">A module named 'Chain-of-Thought Module' that uses verified visual representations to solve problems step by step.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="GPT-4O-MINI">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">A newer language model that is less expensive and offers better performance compared to GPT-3.5-Turbo-0125.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="ADAS ALGORITHMS">
      <data key="d0">METHOD, ALGORITHM</data>
      <data key="d1">Algorithms used for the automated design of agentic systems, which could benefit from more sophisticated evaluation functions to reduce costs.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="VISUAL REPRESENTATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="VERIFIED VISUAL">
      <data key="d0" />
      <data key="d1">The verified visual representation of a problem, produced by the verification module after checking the initial visual output.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
      <data key="d3">DATA, OUTPUT</data>
    </node>
    <node id="DECOMPOSITION INSTRUCTION">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Instructions provided to the decomposition module to guide the decomposition of the main task into sub-problems.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SUB_PROBLEM INSTRUCTION">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Instructions provided to specialized experts to guide the step-by-step solution of sub-problems.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="INTEGRATION INSTRUCTION">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Instructions provided to the integration module to guide the integration of sub-problem solutions into a final answer.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="VISUAL INSTRUCTION">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Instructions provided to the visual representation module to create visual representations of problems.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="VERIFICATION INSTRUCTION">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Instructions provided to the verification module to verify the accuracy and relevance of visual representations.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="COT INSTRUCTION">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Instructions provided to the Chain-of-Thought module to solve problems using verified visual representations.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="SUB_PROBLEM INFO">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Information about individual sub-problems, including their content and index, used by specialized experts to solve sub-problems.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="VISUAL OUTPUT">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">The output generated by the visual representation module, which includes visual representations of problems.</data>
      <data key="d2">ef75d2c866bee783577ed9f65707cf13</data>
    </node>
    <node id="AGENTINSTRUCT">
      <data key="d0">FRAMEWORK, TOOL</data>
      <data key="d1">AgentInstruct is an extensible agentic framework designed to automatically create large amounts of diverse and high-quality synthetic data. It can generate both prompts and responses using raw data sources like text documents and code files as seeds.
AgentInstruct is an agentic solution for Generative Teaching. It focuses on creating demonstration and feedback data using raw documents as input. It can generate high-quality, diverse, and large quantities of data autonomously, using powerful models like GPT-4 and tools like search and code interpreters.
A dataset used to generate approximately 22 million instructions for training machine learning models, focusing on various skills.
A strategy aimed at synthesizing a large and diverse corpus of data with varying degrees of difficulty. It is used to enhance the performance of models like Orca-3.
AgentInstruct is a targeted training method that has shown substantial improvement in Mistral&#8217;s reading comprehension capabilities.
AgentInstruct is a data-driven approach used to enhance the performance of AI models like Mistral across various tasks, including math and format following.
AgentInstruct is an approach that achieved a reduction in hallucinations by 31.34% while maintaining a quality level comparable to GPT-4.
AgentInstruct is a method used to fine-tune language models, reducing the human expertise required for data generation and enabling the creation of high-quality synthetic data at scale.
AgentInstruct is an approach to Generative Teaching that uses agentic flows for synthetic data generation, addressing concerns like lack of diversity and the need for human curation in model training.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="GENERATIVE TEACHING">
      <data key="d0">METHOD, APPROACH</data>
      <data key="d1">Generative Teaching refers to the process of using synthetic data created by powerful models to teach a new skill or behavior to another model. It focuses on post-training to enhance the capabilities of language models.
Generative Teaching is a methodology aimed at generating abundant amounts of diverse, challenging, and high-quality data to teach a particular skill to an AI model. It generalizes the problem settings to a broader objective of data generation for post-training of AI models.
Generative Teaching is a method aimed at teaching skills rather than generating data to meet specific benchmarks, showing effectiveness in enhancing AI model performance.
Generative Teaching is an approach that uses methods like AgentInstruct to generate large amounts of diverse and high-quality data for model post-training.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SYNTHETIC DATA">
      <data key="d0">DATA TYPE</data>
      <data key="d1">Synthetic data is artificially generated data used to accelerate the development of language models. It varies in quality and diversity and often requires significant human effort for curation and filtering to ensure high quality.
Synthetic data refers to artificially generated data used for model training, which can be created using methods like AgentInstruct to improve model performance and customization.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MISTRAL-7B">
      <data key="d0">LANGUAGE MODEL</data>
      <data key="d1">Mistral-7b is a base language model that was post-trained using synthetic data generated by AgentInstruct, resulting in significant performance improvements across various benchmarks.
Mistral-7B is an AI model that was fine-tuned using the synthetic dataset created by AgentInstruct. The fine-tuned version, Orca-3, showed significant improvements over other instruction-tuned models.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="ORCA-3">
      <data key="d0">LANGUAGE MODEL</data>
      <data key="d1">Orca-3 is the resulting model from post-training Mistral-7b with synthetic data generated by AgentInstruct. It shows significant improvements over Mistral-7b-Instruct and other models like LLAMA-8B-instruct and GPT-3.5-turbo.
Orca-3 is the fine-tuned version of the Mistral-7B model, which showed significant improvements in various benchmarks after being trained with the synthetic dataset generated by AgentInstruct.
A machine learning model trained using 25.8 million paired instructions, finetuned on the Mistral-7b-v0.1 model with the AgentInstruct dataset.
An advanced model evaluated using the Orca-Bench dataset, with scores improving from 9.35 to 9.55 across different checkpoints.
Orca-3 is a model evaluated on various benchmarks, showing performance improvements over other baseline models.
Orca-3 is a 7B model that has shown significant improvements in various benchmarks, including reading comprehension and math, compared to its predecessors Orca 2.5 and Mistral-7B-Instruct.
Orca-3 is a model that showed substantial performance improvement across multiple benchmarks after being post-trained with a 25M pair dataset generated by AgentInstruct.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AGIEVAL">
      <data key="d0">BENCHMARK</data>
      <data key="d1">AGIEval is a benchmark used to evaluate the performance of language models. Orca-3 shows a 40% improvement on this benchmark compared to Mistral-7b-Instruct.
AGIEval is a benchmark used to evaluate the performance of AI models. Orca-3 showed a 40% improvement on AGIEval compared to Mistral-Instruct-7B.
A benchmark used to evaluate models, with Orca-3 scoring 56.80, which is a 40% improvement over Orca-2.5.
AGIEval is a human-centric benchmark that evaluates a model&#8217;s abilities in tasks pertinent to human cognition and problem-solving, including standardized exams like SAT and LSAT.
AGIEval is a benchmark used to evaluate the performance of AI models on various tasks, including reading comprehension and math.
A paper titled "Agieval: A human-centric benchmark for evaluating foundation models," published in 2023, discussing a benchmark for evaluating foundation models from a human-centric perspective.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="BBH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">BBH is a benchmark used to evaluate the performance of language models. Orca-3 shows a 38% improvement on this benchmark compared to Mistral-7b-Instruct.
BBH is a benchmark used to evaluate the performance of AI models. Orca-3 showed a 38% improvement on BBH compared to Mistral-Instruct-7B.
A benchmark used to evaluate models, with Orca-3 scoring 61.83, which is a 38% improvement over Orca-2.5.
Big Bench Hard (BBH) is a set of 23 tasks selected from the broader Big-Bench benchmark, requiring complex, multi-step reasoning.
BBH is a benchmark used to evaluate AI models on multi-step arithmetic problems.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="ALPACAEVAL">
      <data key="d0">BENCHMARK</data>
      <data key="d1">AlpacaEval is a benchmark used to evaluate the performance of language models. Orca-3 shows a 45% improvement on this benchmark compared to Mistral-7b-Instruct.
AlpacaEval is a benchmark used to evaluate the performance of AI models. Orca-3 showed a 45% improvement on AlpacaEval compared to Mistral-Instruct-7B.
A benchmark used to evaluate models, with Orca-3 scoring 24.80, which is a 45% improvement over Orca-2.5.
AlpacaEval is a benchmark specifically designed for chat-based language models to assess their abilities in instruction-following tasks, consisting of 805 instructions.
AlpacaEval is an automatic evaluator of instruction-following models, developed by a team of researchers and published in 2023.
AlpacaEval is a benchmark that measures win-rates, i.e., the number of times GPT-4-turbo (version 0613) prefers the outputs of the evaluated model over a reference answer.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="LLAMA-8B-INSTRUCT">
      <data key="d0">LANGUAGE MODEL</data>
      <data key="d1">LLAMA-8B-instruct is a language model that Orca-3 consistently outperforms in various benchmarks.
LLAMA-8B-instruct is an AI model that was outperformed by Orca-3 on multiple benchmarks.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="GPT-3.5-TURBO">
      <data key="d0">LANGUAGE MODEL</data>
      <data key="d1">GPT-3.5-turbo is a language model that Orca-3 consistently outperforms in various benchmarks.
A baseline model evaluated using the Orca-Bench dataset and other benchmarks.
GPT-3.5-turbo is a model whose scores for GSM8K are referenced in the text.
GPT-3.5-turbo is an advanced language model used as a baseline for evaluating the performance of other models like Orca-3.
GPT-3.5-Turbo is a language model used as a baseline for comparison with Orca-3-7B.
GPT-3.5-turbo is a language model evaluated on the MIRAGE datasets, showing performance in RAG tasks.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="ARINDAM MITRA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Arindam Mitra is one of the authors of the paper on AgentInstruct and Generative Teaching.
Arindam Mitra is one of the authors of the Phi-3 technical report.
Arindam Mitra is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="LUCIANO DEL CORRO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Luciano Del Corro is one of the authors of the paper on AgentInstruct and Generative Teaching.
Luciano Del Corro is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="GUOQING ZHENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Guoqing Zheng is one of the authors of the paper on AgentInstruct and Generative Teaching.
Guoqing Zheng is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="SHWETI MAHAJAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shweti Mahajan is one of the authors of the paper on AgentInstruct and Generative Teaching.
Shweti Mahajan is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="DANY ROUHANA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dany Rouhana is one of the authors of the paper on AgentInstruct and Generative Teaching.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="ANDRES CODAS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Andres Codas is one of the authors of the paper on AgentInstruct and Generative Teaching.
Andres Codas is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="YADONG LU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yadong Lu is one of the authors of the paper on AgentInstruct and Generative Teaching.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="WEI-GE CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wei-ge Chen is one of the authors of the paper on AgentInstruct and Generative Teaching.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="OLGA VROUSGOS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Olga Vrousgos is one of the authors of the paper on AgentInstruct and Generative Teaching.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="CORBY ROSSET">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Corby Rosset is one of the authors of the paper on AgentInstruct and Generative Teaching.
Corby Rosset is one of the authors of the Phi-3 technical report.
Corby Rosset is one of the authors of the paper titled "Direct Nash Optimization: Teaching language models to self-improve with general preferences," published in 2024.Corby Rosset is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="FILLIPE SILVA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fillipe Silva is one of the authors of the paper on AgentInstruct and Generative Teaching.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="HAMED KHANPOUR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hamed Khanpour is one of the authors of the paper on AgentInstruct and Generative Teaching.
Hamed Khanpour is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="YASH LARA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yash Lara is one of the authors of the paper on AgentInstruct and Generative Teaching.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="AHMED AWADALLAH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ahmed Awadallah is one of the authors of the paper on AgentInstruct and Generative Teaching.
Ahmed Awadallah is one of the authors of the Phi-3 technical report.
Ahmed Awadallah is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="POST-TRAINING">
      <data key="d0">METHOD, PROCESS</data>
      <data key="d1">Post-training refers to the process of further training a pre-trained language model using additional data to enhance its performance and capabilities.
The phase after the initial training of models, during which their capabilities are enhanced, as shown in the performance comparison.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="INSTRUCTION TUNING">
      <data key="d0">METHOD, PROCESS</data>
      <data key="d1">Instruction tuning is a process where a language model is fine-tuned using a set of instructions to improve its ability to follow and generate instructions accurately.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="RLHF">
      <data key="d0">METHOD, PROCESS</data>
      <data key="d1">Reinforcement Learning from Human Feedback (RLHF) is a method used to train language models by incorporating feedback from human evaluators to improve the model's performance.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="RESPONSES">
      <data key="d0">DATA TYPE</data>
      <data key="d1">Responses are the outputs generated by a language model in reaction to given prompts. They are used to create synthetic data for training and evaluation.
Responses are the outputs generated in reaction to prompts. They are part of the data generated in workflows like those used in Generative Teaching and AgentInstruct.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="TEXT EDITING">
      <data key="d0">SKILL, TASK</data>
      <data key="d1">Text editing is a skill that involves modifying and improving text. It is one of the skills taught to language models using synthetic data generated by AgentInstruct.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="CREATIVE WRITING">
      <data key="d0">SKILL, TASK</data>
      <data key="d1">Creative writing is a skill that involves composing original and imaginative text. It is one of the skills taught to language models using synthetic data generated by AgentInstruct.
Creative writing is a skill that can be taught to AI models using the data generated by AgentInstruct.
Creative writing involves producing original written content, often with a focus on narrative and artistic expression.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TOOL USAGE">
      <data key="d0">SKILL, TASK</data>
      <data key="d1">Tool usage is a skill that involves using various tools like search APIs, calculators, and code interpreters. It is one of the skills taught to language models using synthetic data generated by AgentInstruct.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="CODING">
      <data key="d0">SKILL, TASK</data>
      <data key="d1">Coding is a skill that involves writing and understanding computer code. It is one of the skills taught to language models using synthetic data generated by AgentInstruct.
Coding involves writing, understanding, debugging code, and writing test cases.
Coding involves writing code following instructions, understanding code, debugging code, and tracing or writing test cases.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,6fe27f9eb76cf2ddf712a2cee5783d1c,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SLMS">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Small Language Models (SLMs) are language models that are smaller in size compared to LLMs but are also trained to perform natural language processing tasks.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="MODEL COLLAPSE">
      <data key="d0">ISSUE, PROBLEM</data>
      <data key="d1">Model collapse refers to the degradation of a language model's performance due to training on low-quality or repetitive synthetic data generated by other models.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="IMITATION PROCESS">
      <data key="d0">ISSUE, PROBLEM</data>
      <data key="d1">Imitation process refers to the risk of a language model learning only stylistic characteristics rather than real capabilities when trained on synthetic data generated by other models.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="MULTI-AGENT WORKFLOWS">
      <data key="d0">METHOD, APPROACH</data>
      <data key="d1">Multi-agent workflows involve multiple agents working together to generate high-quality data by using reflection, iteration, and tool usage to improve solutions.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="SEARCH APIS">
      <data key="d0">TOOL, TECHNOLOGY</data>
      <data key="d1">Search APIs are tools that allow agents to perform searches and retrieve information from various sources to improve the quality of generated data.
Search APIs are tools that agents can use to perform specific tasks, such as searching for information.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CALCULATOR">
      <data key="d0">TOOL, TECHNOLOGY</data>
      <data key="d1">A calculator is a tool used by agents to perform mathematical calculations to improve the quality of generated data.
A calculator is a tool that agents can use to perform mathematical calculations.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CODE INTERPRETERS">
      <data key="d0">TOOL, TECHNOLOGY</data>
      <data key="d1">Code interpreters are tools used by agents to execute and understand code to improve the quality of generated data.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="SYNTHETIC-DATA-GENERATION-AS-A-SERVICE">
      <data key="d0">SERVICE, CONCEPT</data>
      <data key="d1">Synthetic-Data-Generation-As-A-Service is a concept where agents start with raw materials and generate data for post-training and fine-tuning, enabling continual learning and improvement of any base LLM.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="CONTENT TRANSFORMATION AGENTS">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">Content Transformation Agents are used in the AgentInstruct methodology to transform raw seeds into diverse sets of instructions.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="REFINEMENT AGENTS">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">Refinement Agents are used in the AgentInstruct methodology to iteratively refine the complexity and quality of the seed instructions.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="RAW SEEDS">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Raw seeds refer to unstructured text documents or source code used as the initial input for the AgentInstruct methodology to generate diverse and high-quality data.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="INSTRUCTION CREATION AGENTS">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">Instruction Creation Agents are used in the AgentInstruct methodology to create a diverse set of instructions from the transformed seeds.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="DATA GENERATION WORKFLOWS">
      <data key="d0">PROCESS, WORKFLOW</data>
      <data key="d1">Data generation workflows refer to the processes involved in creating new data, which can be automated to reduce or eliminate the need for human intervention in some tasks.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="SKILLS">
      <data key="d0">ATTRIBUTE, CAPABILITY</data>
      <data key="d1">Skills refer to the abilities or competencies that an AI model can learn or improve upon, such as creative writing, reasoning, math, and tool use.
Skills are the abilities or tasks that the workflows aim to develop or assess, such as reading comprehension, coding, and creative writing.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TAXONOMY">
      <data key="d0">STRUCTURE, CLASSIFICATION</data>
      <data key="d1">A taxonomy is a structured classification system used by AgentInstruct to organize over 100 subcategories for creating diverse and high-quality prompts and responses.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="VERIFICATION AND DATA FILTERING">
      <data key="d0">PROCESS, WORKFLOW</data>
      <data key="d1">Verification and data filtering are processes applied by AgentInstruct to ensure the quality and relevance of the generated data.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="UNSTRUCTURED TEXT DOCUMENTS">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Unstructured text documents are raw data inputs used as seeds in the AgentInstruct methodology to generate diverse and high-quality data.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="SOURCE CODE">
      <data key="d0">DATA, INPUT</data>
      <data key="d1">Source code is another form of raw data input used as seeds in the AgentInstruct methodology to generate diverse and high-quality data.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="CONTINUAL LEARNING">
      <data key="d0">PROCESS, WORKFLOW</data>
      <data key="d1">Continual learning is the process of continuously improving an AI model by generating new data for post-training and fine-tuning.</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="MISTRAL-INSTRUCT-7B">
      <data key="d0">MODEL, AI</data>
      <data key="d1">Mistral-Instruct-7B is an AI model that was used as a baseline for comparison with the fine-tuned Orca-3 model.
A baseline model evaluated using the Orca-Bench dataset, with an average score of 8.31 out of 10.
Mistral-Instruct-7b is a model used as a baseline for comparison, with performance improvements shown in the text.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="AGENTIC FLOWS">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">Agentic flows are used to automate the generation process and leverage raw articles as seeds to foster diversity and ensure that problems generated in different iterations are distinct and of broad coverage.
Agentic flows are processes used by AgentInstruct for synthetic data generation, which help in creating diverse and high-quality datasets for model training.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CONTENT TRANSFORMATION FLOW">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">Content Transformation Flow converts raw seed into an intermediate representation that simplifies the creation of instructions tailored to specific objectives.
Content Transformation Flow is a method to transform arbitrary articles into well-crafted pieces conducive to the formulation of a wide array of reading comprehension question types. It includes a suite of nine content transformation agents for generating various types of passages.
A process that synthesizes a list of APIs from a random seed, either by using an API retrieval agent or hypothesizing other APIs present in the library.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,427e98b00e49b6a8f8649054122dd45b,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SEED INSTRUCTION GENERATION FLOW">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">Seed Instruction Generation Flow takes transformed content and generates a set of diverse instructions following a comprehensive taxonomy.
The Seed Instruction Generation Flow is a process that involves compiling a collection of reading comprehension question types and defining multiple agents to generate questions based on predefined types from a given text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="INSTRUCTION REFINEMENT FLOW">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">Instruction Refinement Flow iteratively enhances the complexity and quality of instructions generated by the Seed Instruction Generation Flow.
The Instruction Refinement Flow involves suggester-editor agents that modify passage, question pairs to create more complex or unanswerable questions, or alter answers to increase difficulty.
A process that involves refining instructions by using a suggester-editor pair to increase complexity and creativity.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,427e98b00e49b6a8f8649054122dd45b,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SUGGESTER-EDITOR AGENTS">
      <data key="d0">COMPONENT, ENTITY</data>
      <data key="d1">Suggester-Editor Agents are used in the Instruction Refinement Flow to propose and modify instructions to increase their intricacy and quality.
Suggester-editor agents are used in the Instruction Refinement Flow to modify passage, question pairs by adding complexity, introducing distractors, or altering answers.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="QUESTION ANSWERING">
      <data key="d0">SKILL, TASK</data>
      <data key="d1">Question answering involves generating responses to questions over a wide range of topics, without being restricted to a specific domain.
Question answering is an application of reading comprehension that involves providing answers to questions based on a given text.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="RETRIEVAL AUGMENTED GENERATION">
      <data key="d0">SKILL, TASK</data>
      <data key="d1">Retrieval augmented generation involves using retrieved information to generate responses or content.
Retrieval Augmented Generation (RAG) is a method used in natural language processing that combines retrieval-based and generative models to generate responses. It first retrieves relevant documents and then uses these documents to generate a response.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TOOL/API USE">
      <data key="d0">SKILL, TASK</data>
      <data key="d1">Tool/API use involves employing functions or APIs to perform tasks or solve problems.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="WEB CONTROL">
      <data key="d0">SKILL, TASK</data>
      <data key="d1">Web control involves autonomously performing tasks on the web, such as clicking and scrolling.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TEXT MODIFICATION">
      <data key="d0">SKILL, TASK</data>
      <data key="d1">Text modification involves changing existing text to improve its quality, modify its tone, or fit a specific context or audience.
Text modification is the process of editing and refining written content to enhance its quality and effectiveness, involving tasks such as correcting spelling and grammar, clarifying ideas, and adjusting tone.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="WEB AGENT">
      <data key="d0">COMPONENT, ENTITY</data>
      <data key="d1">A web agent is a software program that autonomously performs tasks on the web, such as where to click and how much to scroll.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="BRAIN TEASER">
      <data key="d0">TASK, ACTIVITY</data>
      <data key="d1">A brain teaser is a problem or puzzle requiring thought to solve, often used for amusement or training logical thinking and problem-solving skills.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="ANALYTICAL REASONING">
      <data key="d0">SKILL, TASK</data>
      <data key="d1">Analytical reasoning involves the ability to look at information, discern patterns, and draw logical conclusions about relationships within the information.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="MULTIPLE CHOICE QUESTIONS">
      <data key="d0">TASK, ASSESSMENT</data>
      <data key="d1">Multiple choice questions are a form of assessment where respondents select the best possible answer from a list of choices.
Tasks where models are evaluated in an open-ended generation setting, and GPT-4 is used for extracting the option selected by the model from its response.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="DATA TO TEXT">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">Data-to-text refers to generating human-readable textual summaries from source data, used for reports, explanations, or narratives.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="FERMI PROBLEMS">
      <data key="d0">TASK, ACTIVITY</data>
      <data key="d1">Fermi problems are estimation problems that seek quick, rough estimates of quantities, often requiring justified guesses or assumptions.
Fermi problems are quick, rough estimates of quantities that can be difficult to measure. Named after physicist Enrico Fermi, these problems often require making justified guesses or assumptions to reach a solution.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TEXT EXTRACTION">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">Text extraction is the process of retrieving relevant information from a larger text document, including tasks like named entity recognition and keyword extraction.
Text extraction is the process of retrieving relevant information from a larger text document. This can include tasks like named entity recognition, keyword extraction, or extracting specific data fields from unstructured text.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="RAW ARTICLES">
      <data key="d0">DATA SOURCE, CONTENT</data>
      <data key="d1">Raw articles are used as seeds in the agentic flows to foster diversity and ensure broad coverage in generated problems.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SOURCE CODE FILES">
      <data key="d0">DATA SOURCE, CONTENT</data>
      <data key="d1">Source code files are used as seeds in the agentic flows to foster diversity and ensure broad coverage in generated problems.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="INTERMEDIATE REPRESENTATION">
      <data key="d0">DATA FORMAT, CONTENT</data>
      <data key="d1">Intermediate representation is the transformed content produced by the Content Transformation Flow to simplify the creation of instructions.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="ARGUMENT PASSAGE">
      <data key="d0">DATA FORMAT, CONTENT</data>
      <data key="d1">An argument passage is a type of transformed content used in the Content Transformation Flow.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="MEETING TRANSCRIPT">
      <data key="d0">DATA FORMAT, CONTENT</data>
      <data key="d1">A meeting transcript is a type of transformed content used in the Content Transformation Flow.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="LIST OF APIS">
      <data key="d0">DATA FORMAT, CONTENT</data>
      <data key="d1">A list of APIs is a type of transformed content used in the Content Transformation Flow.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SEED INSTRUCTIONS">
      <data key="d0">DATA FORMAT, CONTENT</data>
      <data key="d1">Seed instructions are generated from transformed content in the Seed Instruction Generation Flow to introduce diversity.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SUGGESTER AGENTS">
      <data key="d0">COMPONENT, ENTITY</data>
      <data key="d1">Suggester agents propose various approaches to increase the intricacy of initial instructions in the Instruction Refinement Flow.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="EDITOR AGENTS">
      <data key="d0">COMPONENT, ENTITY</data>
      <data key="d1">Editor agents modify instructions based on suggestions from suggester agents in the Instruction Refinement Flow.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="CODE INTERPRETER">
      <data key="d0">TOOL, TECHNOLOGY</data>
      <data key="d1">A code interpreter is a tool that agents can use to execute and debug code.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="READING COMPREHENSION TESTS">
      <data key="d0">ASSESSMENT, TASK</data>
      <data key="d1">Reading comprehension tests present text passages followed by questions to assess the reader&#8217;s understanding.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="OPEN DOMAIN QUESTION ANSWERING">
      <data key="d0">SKILL, TASK</data>
      <data key="d1">Open domain question answering involves generating responses to questions over a wide range of topics without being restricted to a specific domain.
Open Domain Question Answering is a method used to generate math problems for evaluating AI models.</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TEXT PASSAGES">
      <data key="d0">DATA FORMAT, CONTENT</data>
      <data key="d1">Text passages are used in reading comprehension tests to assess understanding.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TEXT">
      <data key="d0">DATA FORMAT, CONTENT</data>
      <data key="d1">Text is the primary content used in reading comprehension, text modification, and text extraction tasks.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TASKS">
      <data key="d0">CATEGORY, ATTRIBUTE</data>
      <data key="d1">Tasks are specific activities or assessments within the workflows, such as question answering, text modification, and multiple choice questions.</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TEXT CLASSIFICATION">
      <data key="d0">PROCESS, TASK</data>
      <data key="d1">Text classification is a type of machine learning task where text documents are automatically classified into predefined categories. This can be used for spam detection, sentiment analysis, and topic labeling among others.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="CREATIVE CONTENT GENERATION">
      <data key="d0">ACTIVITY, SKILL</data>
      <data key="d1">Creative content generation involves the creation of original content, often involving elements of novelty, value, and surprise. In AI, this could refer to generating text, music, or images that are not only new but also meaningful and interesting.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="FEW SHOT REASONING">
      <data key="d0">CONCEPT, SKILL</data>
      <data key="d1">Few-shot reasoning refers to the ability of a machine learning model to understand new concepts, patterns, or tasks with minimal examples or guidance. It&#8217;s a desired trait in AI, mimicking the human ability to learn quickly from few examples.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="CONVERSATION">
      <data key="d0">ACTIVITY, SKILL</data>
      <data key="d1">Conversation refers to conversational agents or chatbots that interact with humans in a natural, human-like manner.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="AGENTINSTRUCT FLOW">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">AgentInstruct Flow is a method implemented for various capabilities, including reading comprehension, to guide AI systems in performing specific tasks.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="ARGUMENT PASSAGE GENERATOR">
      <data key="d0">TOOL, AGENT</data>
      <data key="d1">Argument Passage Generator is a content transformation agent that generates argument passages from seed articles, facilitating the creation of reading comprehension materials.
An agent adept at creating passages that articulate arguments, which may occasionally contain logical inconsistencies.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="URIC ACID">
      <data key="d0">SUBSTANCE, BIOLOGICAL CONCEPT</data>
      <data key="d1">Uric acid is a substance produced naturally by the breakdown of purine. Excessive levels can lead to health complications such as hyperuricemia, which may increase the risk of cardiovascular disease.
Uric acid is a chemical found in red meat and seafood, and its levels in the body can be influenced by lifestyle choices such as alcohol consumption and physical inactivity. High levels are associated with an increased risk of cardiovascular disease, while low levels can indicate underlying kidney or liver issues.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="HYPERURICEMIA">
      <data key="d0">CONDITION, MEDICAL TERM</data>
      <data key="d1">Hyperuricemia is a condition characterized by high levels of uric acid in the blood, typically defined as levels above 6 mg/dL in women and 7 mg/dL in men. It can result from increased production of uric acid or insufficient elimination through urine.
Hyperuricemia is a condition characterized by high levels of uric acid in the blood, which is associated with an increased risk of cardiovascular disease.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="HYPOURICEMIA">
      <data key="d0">CONDITION, MEDICAL TERM</data>
      <data key="d1">Hypouricemia is a condition characterized by low levels of uric acid, which is less common and usually does not present symptoms but can indicate underlying kidney or liver issues.
Hypouricemia is a condition characterized by low levels of uric acid in the blood, which can indicate underlying kidney or liver issues but usually does not present symptoms.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="PURINE">
      <data key="d0">SUBSTANCE, BIOLOGICAL CONCEPT</data>
      <data key="d1">Purine is a type of dietary protein that, when broken down by digestion, produces uric acid. It is naturally produced in the body.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="ENRICO FERMI">
      <data key="d0" />
      <data key="d1">Enrico Fermi was a physicist after whom Fermi problems are named.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
      <data key="d3">PERSON, PHYSICIST</data>
    </node>
    <node id="NAMED ENTITY RECOGNITION">
      <data key="d0">TASK, PROCESS</data>
      <data key="d1">Named entity recognition is a task in text extraction that involves identifying and classifying entities in text into predefined categories such as names of persons, organizations, locations, etc.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="KEYWORD EXTRACTION">
      <data key="d0">TASK, PROCESS</data>
      <data key="d1">Keyword extraction is a task in text extraction that involves identifying and extracting important words or phrases from a text document.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="SPAM DETECTION">
      <data key="d0">APPLICATION, TASK</data>
      <data key="d1">Spam detection is an application of text classification where text documents, such as emails, are automatically classified as spam or not spam.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="SENTIMENT ANALYSIS">
      <data key="d0">APPLICATION, TASK</data>
      <data key="d1">Sentiment analysis is an application of text classification that involves determining the sentiment expressed in a text document, such as positive, negative, or neutral.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="TOPIC LABELING">
      <data key="d0">APPLICATION, TASK</data>
      <data key="d1">Topic labeling is an application of text classification where text documents are automatically classified into predefined topics or categories.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="GROUNDED REASONING">
      <data key="d0">APPLICATION, TASK</data>
      <data key="d1">Grounded reasoning is an application of reading comprehension that involves making inferences and drawing conclusions based on a given text.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="LSAT LOGICAL REASONING TEST">
      <data key="d0">TEST, EXAM</data>
      <data key="d1">The LSAT Logical Reasoning test features specialized question categories, including assumption, strengthening/weakening, flaw, and inference questions.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="ASSUMPTION QUESTIONS">
      <data key="d0">QUESTION TYPE, CATEGORY</data>
      <data key="d1">Assumption questions are a type of question in the LSAT Logical Reasoning test that require identifying assumptions made in an argument.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="STRENGTHENING/WEAKENING QUESTIONS">
      <data key="d0">QUESTION TYPE, CATEGORY</data>
      <data key="d1">Strengthening/weakening questions are a type of question in the LSAT Logical Reasoning test that require identifying how an argument can be strengthened or weakened.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="FLAW QUESTIONS">
      <data key="d0">QUESTION TYPE, CATEGORY</data>
      <data key="d1">Flaw questions are a type of question in the LSAT Logical Reasoning test that require identifying flaws in an argument.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="INFERENCE QUESTIONS">
      <data key="d0">QUESTION TYPE, CATEGORY</data>
      <data key="d1">Inference questions are a type of question in the LSAT Logical Reasoning test that require making inferences based on the given information.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="LABORATORY BLOOD TESTS">
      <data key="d0">TEST, MEDICAL PROCEDURE</data>
      <data key="d1">Laboratory blood tests are used to diagnose conditions like hyperuricemia and hypouricemia by measuring levels of substances such as uric acid in the blood.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="LABORATORY URINE TESTS">
      <data key="d0">TEST, MEDICAL PROCEDURE</data>
      <data key="d1">Laboratory urine tests are used to diagnose conditions like hyperuricemia and hypouricemia by measuring levels of substances such as uric acid in the urine.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="CARDIOVASCULAR DISEASE">
      <data key="d0">MEDICAL CONDITION</data>
      <data key="d1">Cardiovascular disease refers to a class of diseases that involve the heart or blood vessels, and high levels of uric acid are associated with an increased risk of developing these diseases.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="LABORATORY BLOOD AND URINE TESTS">
      <data key="d0">DIAGNOSTIC METHOD</data>
      <data key="d1">Laboratory blood and urine tests are used to diagnose conditions related to abnormal uric acid levels, such as hyperuricemia and hypouricemia.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="READING COMPREHENSION QUESTIONS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Reading comprehension questions are designed to assess understanding of a text and can include types such as literal comprehension, critical comprehension, evaluative comprehension, reasoning, and identifying assumptions.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="AGENTS">
      <data key="d0">SYSTEM COMPONENT</data>
      <data key="d1">Agents are defined to target specific categories of reading comprehension questions, generating questions based on a piece of text and a predefined question type.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="CONTENT TRANSFORMATION AGENT">
      <data key="d0">SYSTEM COMPONENT</data>
      <data key="d1">The content transformation agent determines which subset of agents to engage in the Seed Instruction Generation Flow process.
An agent used to synthesize an API description from a source code snippet as part of the content transformation flow.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="PASSAGE, QUESTION PAIRS">
      <data key="d0">DATA OUTPUT</data>
      <data key="d1">Passage, question pairs are the output of the Seed Instruction Generation Flow, consisting of a text passage and associated questions generated by the agents.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="TEXT MODIFICATION TASKS">
      <data key="d0">TASK TYPE</data>
      <data key="d1">Text modification tasks include paraphrasing, expansion, simplification, redacting or removing content, styling, and code switching, among others.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="PARAPHRASING AGENT">
      <data key="d0">SYSTEM COMPONENT</data>
      <data key="d1">The Paraphrasing Agent is defined to create text modification tasks that involve rephrasing a given piece of text while retaining its original meaning.
</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="ALCOHOL CONSUMPTION">
      <data key="d0">LIFESTYLE CHOICE</data>
      <data key="d1">Alcohol consumption is a lifestyle choice that can influence uric acid levels in the body.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="PHYSICAL INACTIVITY">
      <data key="d0">LIFESTYLE CHOICE</data>
      <data key="d1">Physical inactivity is a lifestyle choice that can influence uric acid levels in the body.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="KIDNEY ISSUES">
      <data key="d0">MEDICAL CONDITION</data>
      <data key="d1">Kidney issues can be indicated by low levels of uric acid in the blood, known as hypouricemia.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="LIVER ISSUES">
      <data key="d0">MEDICAL CONDITION</data>
      <data key="d1">Liver issues can be indicated by low levels of uric acid in the blood, known as hypouricemia.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="LITERAL COMPREHENSION QUESTIONS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Literal comprehension questions assess the ability to understand and recall factual information from a text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="CRITICAL COMPREHENSION QUESTIONS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Critical comprehension questions assess the ability to analyze and evaluate the information presented in a text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="EVALUATIVE COMPREHENSION QUESTIONS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Evaluative comprehension questions assess the ability to make judgments about the information presented in a text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="REASONING QUESTIONS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Reasoning questions assess the ability to draw inferences and conclusions based on the information presented in a text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="IDENTIFYING ASSUMPTIONS QUESTIONS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Identifying assumptions questions assess the ability to recognize underlying assumptions in the information presented in a text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="IDENTIFYING INFORMATION THAT STRENGTHENS/WEAKENS AN ARGUMENT QUESTIONS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">These questions assess the ability to identify information that either strengthens or weakens an argument presented in a text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="ORDERING EVENTS QUESTIONS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Ordering events questions assess the ability to sequence events in the order they occurred based on the information presented in a text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="APPENDIX A">
      <data key="d0">DOCUMENT SECTION</data>
      <data key="d1">Appendix A contains a list of reading comprehension question types and text modification tasks.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="STRENGTHEN TYPE QUESTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Strengthen type questions assess the ability to identify information that supports an argument presented in a text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="SUGGESTION 1">
      <data key="d0">SUGGESTION</data>
      <data key="d1">Suggestion 1 involves introducing a hypothetical study or finding that could potentially strengthen an argument, requiring the test-taker to infer its impact on the relationship between uric acid levels and cardiovascular disease.
A suggestion to incorporate a fictional narrative, use a conversational style with colloquial language, and include a humorous element.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SUGGESTION 2">
      <data key="d0">SUGGESTION</data>
      <data key="d1">Suggestion 2 involves adding a layer of complexity by suggesting a genetic predisposition to hyperuricemia and its correlation with increased cardiovascular events, requiring the test-taker to consider both genetic and physiological factors.
A suggestion to translate event details into a poetic format, maintaining accurate information while using rhyming couplets and ensuring a light and engaging tone.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SUGGESTION 3">
      <data key="d0">SUGGESTION</data>
      <data key="d1">Suggestion 3 involves including a distractor option that seems to strengthen the argument but does not directly relate to the causal relationship between uric acid levels and cardiovascular disease, testing the test-taker&#8217;s ability to discern relevant from irrelevant information.
A suggestion to frame event details as a social media post, using internet slang and emojis, and keeping the message within 280 characters.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="MODIFICATION 1">
      <data key="d0">MODIFICATION</data>
      <data key="d1">Modification 1 involves altering the passage to make the question unanswerable.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="MODIFICATION 2">
      <data key="d0">MODIFICATION</data>
      <data key="d1">Modification 2 involves altering the passage to change the answer in the opposite direction.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="MODIFICATION 3">
      <data key="d0">MODIFICATION</data>
      <data key="d1">Modification 3 involves altering the questions or answer choices to make them more complex.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="TEXT MODIFICATION AGENTS">
      <data key="d0">SYSTEM COMPONENT</data>
      <data key="d1">Text modification agents are defined to create text modification tasks such as paraphrasing, expansion, simplification, redacting or removing content, styling, and code switching.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="PARAPHRASING">
      <data key="d0">TEXT MODIFICATION TASK</data>
      <data key="d1">Paraphrasing is a text modification task that involves rephrasing a given piece of text while retaining its original meaning.
Rewriting text using different words and sentence structures while maintaining the original meaning.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="SIMPLIFICATION">
      <data key="d0">TEXT MODIFICATION TASK</data>
      <data key="d1">Simplification is a text modification task that involves making a given piece of text easier to understand.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="REDACTING OR REMOVING CONTENT">
      <data key="d0">TEXT MODIFICATION TASK</data>
      <data key="d1">Redacting or removing content is a text modification task that involves deleting or obscuring parts of a given piece of text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="STYLING">
      <data key="d0">TEXT MODIFICATION TASK</data>
      <data key="d1">Styling is a text modification task that involves changing the appearance or format of a given piece of text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="CODE SWITCHING">
      <data key="d0">TEXT MODIFICATION TASK</data>
      <data key="d1">Code switching is a text modification task that involves alternating between different languages or dialects within a given piece of text.
Alternating between languages or dialects within a text, often to reflect bilingual speakers&#8217; patterns or for creative writing.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="FINANCIALIZATION">
      <data key="d0">CONCEPT, ECONOMIC THEORY</data>
      <data key="d1">A broad concept that describes the increasing social impact and interconnection of financial discourses, markets, actors, and institutions.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="NATASCHA VAN DER ZWAN">
      <data key="d0">RESEARCHER, AUTHOR</data>
      <data key="d1">A researcher who identifies three distinct research streams that approach financialization from different perspectives.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="AMERICAN ANTHROPOLOGICAL ASSOCIATION">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">An organization that hosts events and conferences, such as the SEA 2017 Annual Meeting.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SEA 2017 ANNUAL MEETING">
      <data key="d0">EVENT, CONFERENCE</data>
      <data key="d1">An annual meeting held by the American Anthropological Association from April 6-8, 2017, at the University of Iowa, Iowa City, USA.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SUGGESTER-EDITOR PAIR">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">A duo that increases the complexity of generated instructions by providing suggestions and edits based on input text and task modification instructions.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="API RETRIEVAL AGENT">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">An agent that iteratively searches for similar code to expand an API list during the content transformation flow.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="LIBRARY RECONSTRUCTION">
      <data key="d0">PROCESS, METHOD</data>
      <data key="d1">A scenario within the content transformation flow where a list of APIs is synthesized from a random seed.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="VIEW ALL FOOD ITEMS">
      <data key="d0">API, FUNCTION</data>
      <data key="d1">An API that enables clients to obtain a detailed list of food items, complete with nutritional profiles.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SEARCH FOOD ITEMS">
      <data key="d0">API, FUNCTION</data>
      <data key="d1">An API that allows clients to search for food items by name and retrieve a list of matching items.
Allows clients to search for food items by name and retrieve a list of matching items. It requires a query parameter and optionally a limit parameter to restrict the number of results.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="APRIL 6-8, 2017">
      <data key="d0">DATE, EVENT DATE</data>
      <data key="d1">The dates on which the SEA 2017 Annual Meeting took place at the University of Iowa.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="DECEMBER 1, 2016">
      <data key="d0">DATE, DEADLINE</data>
      <data key="d1">The deadline for submitting abstracts for the SEA 2017 Annual Meeting.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="FINANCE">
      <data key="d0">CONCEPT, ECONOMIC THEORY</data>
      <data key="d1">A broad concept that is hard to escape and has increasing social impact and interconnection with financial discourses, markets, actors, and institutions.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="RANDOM SEED">
      <data key="d0">CONCEPT, INPUT</data>
      <data key="d1">A randomly chosen input used to create a seed (text, text modification instruction) pair for various tasks.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="TASK MODIFICATION INSTRUCTION">
      <data key="d0">INSTRUCTION, METHOD</data>
      <data key="d1">Instructions provided to modify a given task, used in conjunction with input text in the Instruction Refinement Flow.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="INSTRUCTION 1">
      <data key="d0">INSTRUCTION, METHOD</data>
      <data key="d1">An instruction to rewrite event details as if telling a funny story to a friend, using casual and colloquial language, while incorporating a fictional narrative that conveys necessary information.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="INSTRUCTION 2">
      <data key="d0">INSTRUCTION, METHOD</data>
      <data key="d1">An instruction to transform event details into a light-hearted poem with rhyming couplets, ensuring essential information is accurately conveyed in a poetic format.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="INSTRUCTION 3">
      <data key="d0">INSTRUCTION, METHOD</data>
      <data key="d1">An instruction to craft a social media post that includes event details using internet slang, emojis, and a casual tone, while keeping the message concise and within 280 characters.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="API DESCRIPTION">
      <data key="d0">DOCUMENT, DESCRIPTION</data>
      <data key="d1">A description synthesized from a source code snippet by a content transformation agent, detailing the functionality and parameters of an API.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="CALORIE COUNT">
      <data key="d0">ATTRIBUTE, NUTRITION</data>
      <data key="d1">A nutritional profile attribute that indicates the number of calories in a food item.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="PROTEIN">
      <data key="d0">ATTRIBUTE, NUTRITION</data>
      <data key="d1">A nutritional profile attribute that indicates the amount of protein in a food item.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="FAT">
      <data key="d0">ATTRIBUTE, NUTRITION</data>
      <data key="d1">A nutritional profile attribute that indicates the amount of fat in a food item.</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="GET FOOD ITEM DETAILS">
      <data key="d0">API, FUNCTION</data>
      <data key="d1">Provides detailed information about a specific food item. The parameters required for this API are not specified in the provided text.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="CREATE MEAL PLAN">
      <data key="d0">API, FUNCTION</data>
      <data key="d1">Enables the creation of a meal plan based on user preferences and goals. The parameters required for this API are not specified in the provided text.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="UPDATE FOOD ITEM">
      <data key="d0">API, FUNCTION</data>
      <data key="d1">Allows updating the details of an existing food item. The parameters required for this API are not specified in the provided text.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="TRACK USER MEAL">
      <data key="d0">API, FUNCTION</data>
      <data key="d1">Enables tracking of user meals. The parameters required for this API are not specified in the provided text.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="GET DIETARY RECOMMENDATIONS">
      <data key="d0">API, FUNCTION</data>
      <data key="d1">Provides dietary recommendations based on user preferences and goals. The parameters required for this API are not specified in the provided text.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="ADD NEW FOOD ITEM">
      <data key="d0">API, FUNCTION</data>
      <data key="d1">Allows adding a new food item to the database. The parameters required for this API are not specified in the provided text.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="DELETE FOOD ITEM">
      <data key="d0">API, FUNCTION</data>
      <data key="d1">Enables the deletion of a food item from the database. The parameters required for this API are not specified in the provided text.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="GET USER NUTRITIONAL STATS">
      <data key="d0">API, FUNCTION</data>
      <data key="d1">Provides nutritional statistics for the user. The parameters required for this API are not specified in the provided text.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="SEED INSTRUCTION CREATION FLOW">
      <data key="d0">PROCESS, WORKFLOW</data>
      <data key="d1">A process that consumes a list of APIs and employs various agents to create several types of tasks, including those requiring single or multiple APIs, with or without all necessary parameters.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="REFINEMENT FLOW">
      <data key="d0">PROCESS, WORKFLOW</data>
      <data key="d1">A process aimed at increasing the complexity of tasks by suggesting refinements to increase the number of steps required to solve the task.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="AGENT-INSTRUCT FLOW">
      <data key="d0">PROCESS, WORKFLOW</data>
      <data key="d1">A process that creates multi-turn conversations and instructions for an AI assistant to help users achieve their desired outcomes using various APIs.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="ASSISTANT">
      <data key="d0">ACTOR, PARTICIPANT</data>
      <data key="d1">The AI assistant that helps the user achieve their desired outcomes by utilizing various APIs and following structured processes.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
    </node>
    <node id="QUINOA SALAD">
      <data key="d0">FOOD ITEM</data>
      <data key="d1">A recipe for a vegetarian dish that the user wants to add to the database.
A salad made from quinoa, which the user wants to add to the database.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="CHANA MASALA">
      <data key="d0">FOOD ITEM</data>
      <data key="d1">A food item whose calorie count the user believes is incorrect and wants to update.
A spicy chickpea dish that the user wants to update in the database.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="BUTTER CHICKEN">
      <data key="d0">FOOD ITEM</data>
      <data key="d1">A food item that the user wants to remove from the database.
A popular Indian dish made with chicken in a spiced tomato, butter, and cream sauce, which the user wants to remove from the database.</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="VEGETARIAN MEAL PLAN">
      <data key="d0">MEAL PLAN, DIETARY PLAN</data>
      <data key="d1">A meal plan designed for vegetarians with a caloric goal of 1500 calories per day, consisting of three meals a day.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="CALORIC GOAL">
      <data key="d0">NUTRITIONAL TARGET, DIETARY GOAL</data>
      <data key="d1">A target of 1500 calories per day set for the meal plan.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="OATMEAL WITH FRUITS">
      <data key="d0">FOOD ITEM, BREAKFAST</data>
      <data key="d1">A breakfast food item consisting of oatmeal mixed with fruits, included in the vegetarian meal plan.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ALMOND MILK">
      <data key="d0">FOOD ITEM, BEVERAGE</data>
      <data key="d1">A dairy-free milk alternative made from almonds, included in the vegetarian meal plan for breakfast.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="CHICKPEA SALAD">
      <data key="d0">FOOD ITEM, LUNCH</data>
      <data key="d1">A lunch food item consisting of a salad made from chickpeas, included in the vegetarian meal plan.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="WHOLE WHEAT BREAD">
      <data key="d0">FOOD ITEM, LUNCH</data>
      <data key="d1">A type of bread made from whole wheat, included in the vegetarian meal plan for lunch.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="MIXED VEGETABLE STIR FRY">
      <data key="d0">FOOD ITEM, DINNER</data>
      <data key="d1">A dinner food item consisting of various vegetables stir-fried together, included in the vegetarian meal plan.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="BROWN RICE">
      <data key="d0">FOOD ITEM, DINNER</data>
      <data key="d1">A type of rice that is less processed than white rice, included in the vegetarian meal plan for dinner.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="FOOD_ID">
      <data key="d0">IDENTIFIER, DATABASE ATTRIBUTE</data>
      <data key="d1">A unique identifier used to update or remove food items in the database.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ORCA-2.5">
      <data key="d0">MODEL, MACHINE LEARNING</data>
      <data key="d1">A machine learning model trained using 3.8 million paired instructions, used to compare and evaluate the impact of the larger AgentInstruct dataset.
A baseline model evaluated using the Orca-Bench dataset, with an average score of 7.13 out of 10.
Orca-2.5 is a model used as a baseline for comparison, with performance improvements shown in the text.
Orca-2.5 is a previous version of the Orca language model, used as a baseline for comparison with Orca-3-7B.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="MISTRAL-7B-V0.1">
      <data key="d0">MODEL, MACHINE LEARNING</data>
      <data key="d1">A base model with publicly available weights, used as the foundation for finetuning with the AgentInstruct dataset to create Orca-3.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="NVIDIA A100">
      <data key="d0">HARDWARE, GPU</data>
      <data key="d1">A type of GPU used in the training process of the Orca-3 model, with 152 GPUs used in total.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ADAMW OPTIMIZER">
      <data key="d0">OPTIMIZER, MACHINE LEARNING</data>
      <data key="d1">An optimization algorithm used in the training of the Orca-3 model, with an initial learning rate of 8e-6.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ORCA-BENCH">
      <data key="d0">DATASET, EVALUATION</data>
      <data key="d1">A held-out test set consisting of 100 samples from each of the 17 skills curated using AgentInstruct, used to evaluate the performance of machine learning models.
A dataset used to evaluate the performance of various models, scored relative to GPT-4 on a scale from 0 to 10. It includes multi-turn interactions and is used to generate student responses conditioned on preceding conversation history.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="ODQA">
      <data key="d0">TASK, QUESTION ANSWERING</data>
      <data key="d1">Open Domain Question Answering, a category in the Orca-Bench dataset with two subsets: ODQA and Complex ODQA.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="COMPLEX ODQA">
      <data key="d0">TASK, QUESTION ANSWERING</data>
      <data key="d1">A subset of the ODQA category in the Orca-Bench dataset, consisting of more intricate questions developed during the refinement phase.
A subset of questions within the Orca-Bench dataset that includes more intricate questions developed during the refinement phase.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="DAY 1">
      <data key="d0">MEAL PLAN, DIETARY PLAN</data>
      <data key="d1">The first day of the vegetarian meal plan, including specific meals and their caloric content.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="DAY 2">
      <data key="d0">MEAL PLAN, DIETARY PLAN</data>
      <data key="d1">The second day of the vegetarian meal plan, including specific meals and their caloric content.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="MEAL PLAN DATABASE">
      <data key="d0">DATABASE, REPOSITORY</data>
      <data key="d1">A database where meal plans and recipes are stored and managed.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="NUTRITIONAL INFORMATION">
      <data key="d0">DATA, NUTRITION</data>
      <data key="d1">Information about the nutritional content of food items, required to add new recipes to the database.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ORCA-1">
      <data key="d0">MODEL, MACHINE LEARNING</data>
      <data key="d1">A previous version of the Orca model, which contributed to the 3.8 million paired instructions used in Orca-2.5.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ORCA-2">
      <data key="d0">MODEL, MACHINE LEARNING</data>
      <data key="d1">A previous version of the Orca model, which contributed to the 3.8 million paired instructions used in Orca-2.5.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ORCA-MATH">
      <data key="d0">MODEL, MACHINE LEARNING</data>
      <data key="d1">A version of the Orca model focused on mathematical instructions, contributing to the 3.8 million paired instructions used in Orca-2.5.
Orca-Math is a project focused on unlocking the potential of small language models in grade school math, published in 2024.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="KNOWLEDGEPILE">
      <data key="d0">DATASET, TRAINING DATA</data>
      <data key="d1">A dataset used as a source for unstructured text and code files in the AgentInstruct dataset.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="AUTOMATHTEXT">
      <data key="d0">DATASET, TRAINING DATA</data>
      <data key="d1">A dataset used as a source for unstructured text and code files in the AgentInstruct dataset.
A paper titled "Automathtext: Autonomous data selection with language models for mathematical texts," published in 2024, discussing the use of language models for autonomous data selection in mathematical texts.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="OPENSTAX">
      <data key="d0">DATASET, TRAINING DATA</data>
      <data key="d1">A subset of educational content used as a source for unstructured text in the AgentInstruct dataset.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="APACHE-2.0 LICENSED SOURCE CODE">
      <data key="d0">DATASET, TRAINING DATA</data>
      <data key="d1">A subset of source code files licensed under Apache-2.0, used in the AgentInstruct dataset.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="MISTRAL TOKENIZER">
      <data key="d0">TOOL, TOKENIZER</data>
      <data key="d1">A tokenizer used to process the dataset for training the Orca-3 model, ensuring a maximum sequence length of 8192 with packing.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="WEIGHT DECAY">
      <data key="d0">HYPERPARAMETER, MACHINE LEARNING</data>
      <data key="d1">A regularization technique used in the training of the Orca-3 model, set at 0.1.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="COSINE LEARNING RATE SCHEDULE">
      <data key="d0">HYPERPARAMETER, MACHINE LEARNING</data>
      <data key="d1">A learning rate schedule used in the training of the Orca-3 model, featuring a cosine decay pattern.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="LINEAR LEARNING RATE WARM-UP">
      <data key="d0">HYPERPARAMETER, MACHINE LEARNING</data>
      <data key="d1">A technique used during the initial 500 steps of training the Orca-3 model to gradually increase the learning rate.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="EPOCH">
      <data key="d0">TRAINING ITERATION, MACHINE LEARNING</data>
      <data key="d1">A complete pass through the training dataset, with the Orca-3 model trained for three epochs.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="TRAINING LOSS">
      <data key="d0">METRIC, MACHINE LEARNING</data>
      <data key="d1">A measure of the error during the training process, calculated based on the response conditioned on the prompt.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="RESPONSE">
      <data key="d0">OUTPUT, MACHINE LEARNING</data>
      <data key="d1">The output generated by the model in response to the prompt during training.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="MULTI-TURN INTERACTION">
      <data key="d0">INTERACTION, MACHINE LEARNING</data>
      <data key="d1">A type of interaction in the Orca-Bench dataset involving multiple exchanges between the user and the model.
A sequence of exchanges in the Orca-Bench dataset, involving system messages, user inputs, and assistant responses.</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="CHATGPT">
      <data key="d0">MODEL, BASELINE</data>
      <data key="d1">A baseline model evaluated using the Orca-Bench dataset, with an average score of 8.13 out of 10.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="LLAMA3-8B-INSTRUCT">
      <data key="d0">MODEL, BASELINE</data>
      <data key="d1">A baseline model evaluated using the Orca-Bench dataset and other benchmarks.
LLAMA3-8B-Instruct is a language model used as a baseline for comparison with Orca-3-7B.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="FOFO">
      <data key="d0">BENCHMARK</data>
      <data key="d1">A benchmark used to evaluate models, with Orca-3 scoring 84.01, which is a 12% improvement over Orca-2.5.
Format Following (FoFo) is a benchmark that evaluates a model&#8217;s ability to follow complex, domain-specific formats across various real-world domains like Healthcare, Finance, and Marketing.
FoFo is a benchmark used to evaluate the format-following capabilities of AI models in real-world scenarios.
A paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability," published in 2024, discussing a benchmark to evaluate the format-following capability of large language models.
FOFO is a benchmark for evaluating open-ended generation tasks using a judge, GPT-4 (version 0613), to give a format correctness score between 0 and 1.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="IFEVAL">
      <data key="d0">BENCHMARK</data>
      <data key="d1">A benchmark used to evaluate models, with Orca-3 scoring 49.54, which is a 2% improvement over Orca-2.5.
Instruction-Following Evaluation (IFEval) is a benchmark measuring a model&#8217;s ability to follow natural language instructions using a set of 500 prompts covering 25 types of verifiable instructions.
IFEval is a benchmark that checks if the model response follows the verifiable instructions given in the prompt, using code provided by the authors.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="INFOBENCH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">A benchmark used to evaluate models, with Orca-3 scoring 84.30, which is a 4% improvement over Orca-2.5.
InFoBench is a benchmark that evaluates models' instruction-following capability using a metric called Decomposed Requirements Following Ratio (DRFR), which breaks complex instructions into simpler criteria.
InfoBench is a benchmarking tool that evaluates the instruction-following ability in large language models, published in 2024.
InfoBench is a benchmark evaluated using GPT-4 (version 1106-preview) to determine if the model response follows the decomposed instruction, using the implementation provided by the creators.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,3d1f6634f93f8a4c296dc8df7e59859e,86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="EQBENCH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">A benchmark used to evaluate models, with Orca-3 scoring 91.36, which is a 4% improvement over Orca-2.5.
EQBench is an Emotional Intelligence benchmark that evaluates aspects of emotional intelligence in language models. It tests models' capabilities to comprehend intricate emotions and social interactions by providing a conversation between characters and then asking the model to predict the intensity of emotional states of those characters.
A benchmark used for evaluating emotion scores in conversations, with scores generated using specific implementations described in the EQBench paper and repository.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="STUDENT RESPONSE">
      <data key="d0">OUTPUT, RESPONSE</data>
      <data key="d1">The generated response by a student model, conditioned on the preceding conversation history established by the teacher model (GPT-4).
The answer provided by a student in response to a question, which is parsed by the Evaluator Assistant to extract the selected option.
The answer or response provided by the student to the given question.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,5819b66e04fd77fa705574edc49395bb,bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="TEACHER RESPONSE">
      <data key="d0">OUTPUT, RESPONSE</data>
      <data key="d1">The original response generated by the teacher model (GPT-4) used as a benchmark to evaluate student responses.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="PERFORMANCE COMPARISON">
      <data key="d0">EVALUATION, ANALYSIS</data>
      <data key="d1">A comparative analysis of the performance of different models, depicted in Figure 4, showing the enhancement in capabilities during post-training enabled by AgentInstruct data.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="ORCA-3 CHECKPOINTS">
      <data key="d0">MODEL, CHECKPOINT</data>
      <data key="d1">Different stages of the Orca-3 model evaluated at various checkpoints, showing improvement in scores from 9.35 to 9.55.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="TRAINING EPOCH">
      <data key="d0">PROCESS, STAGE</data>
      <data key="d1">A phase in the training process of models, with performance evaluated after each epoch.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="MACRO SCORES">
      <data key="d0">METRIC, SCORE</data>
      <data key="d1">The average scores across all assessed dimensions, used to evaluate the performance of models like Orca-3.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="BENCHMARK RESULTS">
      <data key="d0">EVALUATION, RESULTS</data>
      <data key="d1">The results of evaluating Orca-3 against 5 baseline models on various benchmarks, showing performance scores.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="MODEL PERFORMANCE">
      <data key="d0">EVALUATION, METRIC</data>
      <data key="d1">The performance scores of different models on the Orca-Bench dataset, ranging from 0 to 10, with GPT-4 scoring a perfect 10.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="DIMENSIONS">
      <data key="d0">METRIC, ASSESSMENT</data>
      <data key="d1">Various aspects or dimensions assessed to evaluate the performance of models like Orca-3.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
    </node>
    <node id="CAPABILITIES">
      <data key="d0">ATTRIBUTE, ABILITY</data>
      <data key="d1">The broad spectrum of abilities enhanced during post-training, as shown in the performance comparison of models.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">ATTRIBUTE, ABILITY</data>
    </node>
    <node id="USER INPUT">
      <data key="d0">INPUT, QUERY</data>
      <data key="d1">The input provided by the user in the multi-turn interaction sequence within the Orca-Bench dataset.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">INPUT, QUERY</data>
    </node>
    <node id="ASSISTANT RESPONSE">
      <data key="d0">OUTPUT, RESPONSE</data>
      <data key="d1">The response generated by the assistant in the multi-turn interaction sequence within the Orca-Bench dataset.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">OUTPUT, RESPONSE</data>
    </node>
    <node id="CONVERSATION HISTORY">
      <data key="d0">DATA, CONTEXT</data>
      <data key="d1">The preceding exchanges in a multi-turn interaction, used to condition the student response in the Orca-Bench dataset.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">DATA, CONTEXT</data>
    </node>
    <node id="NORMALIZATION">
      <data key="d0">PROCESS, ADJUSTMENT</data>
      <data key="d1">The process of adjusting scores to a common scale, used to normalize the student's final score to a 0 to 10 scale.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">PROCESS, ADJUSTMENT</data>
    </node>
    <node id="CORPUS">
      <data key="d0">DATA, COLLECTION</data>
      <data key="d1">A large and diverse collection of data synthesized by AgentInstruct, used for training and evaluating models.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">DATA, COLLECTION</data>
    </node>
    <node id="DIFFICULTY">
      <data key="d0">ATTRIBUTE, LEVEL</data>
      <data key="d1">The varying degrees of challenge in the data synthesized by AgentInstruct, used to evaluate model performance.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">ATTRIBUTE, LEVEL</data>
    </node>
    <node id="INFERIORITY">
      <data key="d0">ATTRIBUTE, COMPARISON</data>
      <data key="d1">The relative lower performance of baseline models like Orca-2.5, Mistral-Instruct-7B, and ChatGPT compared to GPT-4.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">ATTRIBUTE, COMPARISON</data>
    </node>
    <node id="ENHANCEMENT">
      <data key="d0">PROCESS, IMPROVEMENT</data>
      <data key="d1">The improvement in model capabilities during post-training, enabled by AgentInstruct data.</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">PROCESS, IMPROVEMENT</data>
    </node>
    <node id="METRIC-V2">
      <data key="d0">METRIC</data>
      <data key="d1">Metric-v2 is a performance metric used to evaluate models, showing a score of 91.36 with a 4% improvement.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="METRIC-V1">
      <data key="d0">METRIC</data>
      <data key="d1">Metric-v1 is a performance metric used to evaluate models, showing a score of 50.28 with a 28% improvement.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="MISTRAL-7B-INSTRUCT">
      <data key="d0">MODEL</data>
      <data key="d1">Mistral-7b-Instruct is a model used as a baseline for comparison, with relative improvements shown in the text.
Mistral-7B-Instruct is a 7B model used as a baseline for performance comparisons with Orca-3 and other models.
Mistral-7B-Instruct is a language model used as a baseline for comparison with Orca-3-7B.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="LSAT">
      <data key="d0">EXAM</data>
      <data key="d1">The Law School Admission Test (LSAT) is a standardized test considered difficult for human test-takers, used to evaluate reading comprehension in models.
The Law School Admission Test (LSAT) is a standardized test used for law school admissions, known for its challenging reading comprehension sections.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="ORCA 2.5">
      <data key="d0">MODEL, AI SYSTEM</data>
      <data key="d1">Orca 2.5 is a 7B model that serves as a predecessor to Orca-3, used for comparison in performance evaluations.</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="GEMINI PRO">
      <data key="d0">MODEL, AI SYSTEM</data>
      <data key="d1">Gemini Pro is an AI model used as a baseline for evaluating the format-following capabilities of other models like Orca-3.
Gemini Pro is a model whose scores are referenced from its original paper.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="MULTIPLE-CHOICE QUESTIONS FLOWS">
      <data key="d0">METHOD, APPROACH</data>
      <data key="d1">Multiple-Choice Questions Flows is a method used to generate math problems for evaluating AI models.</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="PHI3">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">Phi3 is a research paper that reports accuracy scores for GPT-3.5-turbo on the GSM8K benchmark.</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="ORCA-3-7B">
      <data key="d0">MODEL, TECHNOLOGY</data>
      <data key="d1">Orca-3-7B is a language model evaluated on various benchmarks, showing improvements over previous versions like Orca 2.5 and Mistral-7B-Instruct.
Orca-3-7B is a language model fine-tuned with AgentInstruct data, showing substantial improvement in RAG tasks on the MIRAGE datasets.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="FOFO BENCHMARK">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">FoFo is a benchmark used to evaluate the performance of language models, including Orca-3-7B.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="ACI-BENCH">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">The Ambient Clinical Intelligence Benchmark (ACI-Bench) is a dataset designed for benchmarking automatic report generation from doctor-patient conversations.
A novel ambient clinical intelligence dataset for benchmarking automatic visit note generation, discussed in a paper published in 2023.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="INSTRUSUM">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">InstruSum is a dataset for evaluating the generation capabilities of language models for instruction-controllable summarization.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="ORCA-SUM">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">Orca-Sum is a newly created benchmark to evaluate language models' ability to follow summarization and grounded data transformation instructions.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="MIRAGE">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">MIRAGE is a benchmark focusing on answering medical questions by referring to information retrieved from a medical corpus.
MIRAGE is a collection of datasets used to evaluate the performance of different models, particularly in the context of retrieval-augmented generation (RAG).</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="MMLU-MED">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">MMLU-Med is a dataset used to evaluate the medical question-answering capabilities of language models.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="MEDQA-US">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">MedQA-US is a dataset used to evaluate the medical question-answering capabilities of language models.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="MEDMCQA">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">MedMCQA is a dataset used to evaluate the medical question-answering capabilities of language models.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="PUBMEDQA">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">PubMedQA is a dataset used to evaluate the medical question-answering capabilities of language models.
PubMedQA is one of the datasets included in the MIRAGE benchmark, used to evaluate model performance, particularly effective for assessing models' ability to do RAG.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="BIOASQ">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">BioASQ is a dataset used to evaluate the medical question-answering capabilities of language models.
BioASQ is one of the datasets included in the MIRAGE benchmark, used to evaluate model performance.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="HALLUCINATION RATE">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">Hallucination rate is a metric used to measure the frequency of incorrect or fabricated information generated by a language model. Lower rates are better.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="QUALITY SCORE">
      <data key="d0">METRIC, EVALUATION</data>
      <data key="d1">Quality score is a metric used to measure the overall quality of responses generated by a language model. Higher scores are better.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="DATA TRANSFORMATION">
      <data key="d0">METHOD, APPROACH</data>
      <data key="d1">Data transformation involves converting data from one format or structure to another, often used in the context of evaluating language models.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="SUMMARIZATION">
      <data key="d0">METHOD, APPROACH</data>
      <data key="d1">Summarization is the process of condensing information into a shorter form while retaining key points, used to evaluate language models.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="HUGGING FACE">
      <data key="d0">PLATFORM, DATASET</data>
      <data key="d1">Hugging Face is a platform that hosts various datasets, including those used to create the Orca-Sum benchmark.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="GPT-4 (0613) COT">
      <data key="d0">MODEL, TECHNOLOGY</data>
      <data key="d1">GPT-4 (0613) CoT is a variant of GPT-4 evaluated on medical question-answering datasets like MMLU-Med and MedQA-US.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="GPT-3.5-TURBO RAG">
      <data key="d0">MODEL, TECHNOLOGY</data>
      <data key="d1">GPT-3.5-Turbo RAG is a variant of GPT-3.5-Turbo evaluated for its retrieval-augmented generation capabilities.</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="MEDMEDQA">
      <data key="d0">DATASET</data>
      <data key="d1">MedMedQA is one of the datasets included in the MIRAGE benchmark, used to evaluate model performance.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="USMEDMCQA">
      <data key="d0">DATASET</data>
      <data key="d1">USMedMCQA is one of the datasets included in the MIRAGE benchmark, used to evaluate model performance.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="ORCA-2.5-7B">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Orca-2.5-7B is a language model evaluated on the MIRAGE datasets, showing performance in RAG tasks.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="MISTRAL-7B-INSTRUCT-V0.1">
      <data key="d0">TECHNOLOGY, LANGUAGE MODEL</data>
      <data key="d1">Mistral-7B-Instruct-v0.1 is a language model evaluated on the MIRAGE datasets, showing performance in RAG tasks.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="MEDRAG">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">MedRAG is the retrieval mechanism used across all models on the MIRAGE benchmark, involving the same retrieval function and number of retrieved documents.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="AZURE">
      <data key="d0">ORGANIZATION, PLATFORM</data>
      <data key="d1">Azure is a platform that provides transparency notes and various content moderation services for large language models.
Azure is a cloud computing service created by Microsoft, which provides various services including transparency notes for understanding the rationale behind specific outputs or decisions of large language models.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="LIMITATIONS">
      <data key="d0">CONSTRAINT, CHALLENGE</data>
      <data key="d1">Limitations refer to the constraints or challenges associated with a particular method, technology, or dataset, such as those mentioned for AgentInstruct and large language models.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="EXTENSIBILITY">
      <data key="d0">CONSTRAINT, CHALLENGE</data>
      <data key="d1">Extensibility is a limitation related to the human effort required to create agentic flows for different skills in synthetic data generation.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="BIAS">
      <data key="d0">CONSTRAINT, CHALLENGE</data>
      <data key="d1">Bias is a limitation where synthetic data may reflect and amplify biases present in the original seed data used for its generation.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="DEPENDENCY ON SEED DATA">
      <data key="d0">CONSTRAINT, CHALLENGE</data>
      <data key="d1">Dependency on Seed Data is a limitation where the quality of synthetic data is dependent on the quality of the real data used as seeds.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="DATA BIASES">
      <data key="d0">CONSTRAINT, CHALLENGE</data>
      <data key="d1">Data Biases are limitations where large language models may carry biases present in the source data, potentially leading to biased or unfair outputs.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="LACK OF TRANSPARENCY">
      <data key="d0">CONSTRAINT, CHALLENGE</data>
      <data key="d1">Lack of Transparency is a limitation where large language models act as "black boxes," making it difficult to understand the rationale behind specific outputs or decisions.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="CONTENT HARMS">
      <data key="d0">CONSTRAINT, CHALLENGE</data>
      <data key="d1">Content Harms are limitations where large language models can generate harmful content, necessitating the use of content moderation services.
Content harms refer to the various types of negative impacts that large language models can cause, such as generating harmful or disinformation content. It is important to be aware of these risks and take actions to prevent them.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="TRANSPARENCY NOTES">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">Transparency Notes are documents provided by platforms like Azure to offer more information about the transparency and functioning of large language models.
Transparency notes are documents provided by Azure to offer more information and understanding about the rationale behind specific outputs or decisions of large language models.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CONTENT MODERATION SERVICES">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">Content Moderation Services are tools provided by various companies and institutions to prevent harmful content generated by large language models.
Content moderation services are tools provided by different companies and institutions to help prevent content harms caused by large language models.</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="GOVERNMENT AND TECHNOLOGY LEADERS">
      <data key="d0">AUTHORITY, STAKEHOLDER</data>
      <data key="d1">Government and technology leaders are entities that can create regulations and standards to mitigate content harms associated with AI technologies.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="RESEARCH AND OPEN SOURCE COMMUNITY">
      <data key="d0">COMMUNITY, STAKEHOLDER</data>
      <data key="d1">The research and open source community plays an important role in addressing content harms and improving AI technologies.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HALLUCINATION">
      <data key="d0">CONCEPT, RISK</data>
      <data key="d1">Hallucination refers to the phenomenon where language models fabricate content, making it unreliable for critical decisions or information. Smaller models may be more susceptible to hallucination due to reduced memorization capacities.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="POTENTIAL FOR MISUSE">
      <data key="d0">CONCEPT, RISK</data>
      <data key="d1">Potential for misuse refers to the risk that large language models could be used maliciously to generate disinformation or harmful content without suitable safeguards.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DATA DISTRIBUTION">
      <data key="d0">CONCEPT, FACTOR</data>
      <data key="d1">Data distribution refers to the correlation between a model's performance and the distribution of its tuning data, which can limit accuracy in underrepresented areas of the training dataset.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="25M PAIR DATASET">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">The 25M pair dataset is a large dataset generated by AgentInstruct, used for post-training the Orca-3 model, leading to notable performance gains.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="MARAH ABDIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Marah Abdin is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SAM ADE JACOBS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sam Ade Jacobs is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AMMAR AHMAD AWAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ammar Ahmad Awan is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JYOTI ANEJA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jyoti Aneja is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HANY AWADALLA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hany Awadalla is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="NGUYEN BACH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nguyen Bach is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AMIT BAHREE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Amit Bahree is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ARASH BAKHTIARI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Arash Bakhtiari is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JIANMIN BAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jianmin Bao is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HARKIRAT BEHL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Harkirat Behl is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ALON BENHAIM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alon Benhaim is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MISHA BILENKO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Misha Bilenko is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JOHAN BJORCK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Johan Bjorck is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="S&#201;BASTIEN BUBECK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">S&#233;bastien Bubeck is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="QIN CAI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qin Cai is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MARTIN CAI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Martin Cai is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CAIO C&#201;SAR TEODORO MENDES">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Caio C&#233;sar Teodoro Mendes is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="VISHRAV CHAUDHARY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Vishrav Chaudhary is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DONG CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dong Chen is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DONGDONG CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dongdong Chen is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YEN-CHUN CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yen-Chun Chen is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YI-LING CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yi-Ling Chen is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PARUL CHOPRA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Parul Chopra is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="XIYANG DAI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiyang Dai is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ALLIE DEL GIORNO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Allie Del Giorno is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="GUSTAVO DE ROSA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gustavo de Rosa is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MATTHEW DIXON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Matthew Dixon is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="RONEN ELDAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ronen Eldan is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="VICTOR FRAGOSO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Victor Fragoso is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DAN ITER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dan Iter is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MEI GAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mei Gao is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MIN GAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Min Gao is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JIANFENG GAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jianfeng Gao is one of the authors of the Phi-3 technical report.
Jianfeng Gao is one of the authors of a paper on instruction tuning with GPT-4, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AMIT GARG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Amit Garg is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ABHISHEK GOSWAMI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Abhishek Goswami is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SURIYA GUNASEKAR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Suriya Gunasekar is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="EMMAN HAIDER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Emman Haider is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JUNHENG HAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Junheng Hao is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="RUSSELL J. HEWETT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Russell J. Hewett is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JAMIE HUYNH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jamie Huynh is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MOJAN JAVAHERIPI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mojan Javaheripi is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="XIN JIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xin Jin is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PIERO KAUFFMANN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Piero Kauffmann is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="NIKOS KARAMPATZIAKIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nikos Karampatziakis is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DONGWOO KIM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dongwoo Kim is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MAHOUD KHADEMI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mahoud Khademi is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="LEV KURILENKO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lev Kurilenko is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="JAMES R. LEE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">James R. Lee is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YIN TAT LEE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yin Tat Lee is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YUANZHI LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yuanzhi Li is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="YUNSHENG LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yunsheng Li is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CHEN LIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chen Liang is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="LARS LIDEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lars Liden is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MENGCHEN LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mengchen Liu is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="WEISHUNG LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Weishung Liu is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="ERIC LIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Eric Lin is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CHONG LUO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chong Luo is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PIYUSH MADAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Piyush Madan is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MATT MAZZOLA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Matt Mazzola is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HARDIK MODI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hardik Modi is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="BRANDON NORICK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Brandon Norick is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="BARUN PATRA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Barun Patra is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DANIEL PEREZ-BECKER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Daniel Perez-Becker is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="THOMAS PORTET">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Thomas Portet is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="REID PRYZANT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Reid Pryzant is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HEYANG QIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Heyang Qin is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MARKO RADMILAC">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Marko Radmilac is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SAMBUDHA ROY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sambudha Roy is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="OLATUNJI RUWASE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Olatunji Ruwase is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="OLLI SAARIKIVI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Olli Saarikivi is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AMIN SAIED">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Amin Saied is one of the authors of the Phi-3 technical report.
Amin Saied is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models," published in 2023.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ADIL SALIM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Adil Salim is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MICHAEL SANTACROCE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Michael Santacroce is one of the authors of the Phi-3 technical report.
Michael Santacroce is one of the authors of the paper titled "Direct Nash Optimization: Teaching language models to self-improve with general preferences," published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SHITAL SHAH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shital Shah is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="NING SHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ning Shang is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="HITESHI SHARMA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hiteshi Sharma is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="SWADHEEN SHUKLA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Swadheen Shukla is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="XIA SONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xia Song is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MASAHIRO TANAKA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Masahiro Tanaka is one of the authors of the Phi-3 technical report.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="REGULATIONS AND STANDARDS">
      <data key="d0">CONCEPT, POLICY</data>
      <data key="d1">Regulations and standards are guidelines and rules that government and technology leaders can establish to mitigate content harms associated with AI technologies.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MEMORIZATION CAPACITIES">
      <data key="d0">CONCEPT, ATTRIBUTE</data>
      <data key="d1">Memorization capacities refer to the ability of language models to remember and reproduce information, which can affect their susceptibility to hallucination.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="TUNING DATA">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Tuning data is the dataset used to fine-tune a model, which can influence the model's performance and accuracy, especially in areas underrepresented in the training dataset.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="UNSTRUCTURED DATA SOURCES">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Unstructured data sources are raw data inputs that lack a predefined format, which can be used by AgentInstruct to generate tailored datasets for model training.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MODEL POST-TRAINING">
      <data key="d0">PROCESS, TECHNOLOGY</data>
      <data key="d1">Model post-training is the process of further training a pre-trained model using additional data to improve its performance and capabilities.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DOMAIN/TASK SPECIALIZATION">
      <data key="d0">PROCESS, TECHNOLOGY</data>
      <data key="d1">Domain/task specialization is the process of customizing a model to perform better in specific areas or tasks by using domain-specific content as seeds for training.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="CONTINUAL IMPROVEMENT">
      <data key="d0">PROCESS, TECHNOLOGY</data>
      <data key="d1">Continual improvement refers to the ongoing process of enhancing a model's performance by generating higher quality data than the base model using methods like agentic flows.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PHI-3 TECHNICAL REPORT">
      <data key="d0">DOCUMENTATION, RESOURCE</data>
      <data key="d1">The Phi-3 technical report is a document authored by multiple researchers, detailing the technical aspects and findings related to the Phi-3 model.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AI TECHNOLOGIES">
      <data key="d0">TECHNOLOGY, CONCEPT</data>
      <data key="d1">AI technologies refer to the various tools, models, and methods used in artificial intelligence to perform tasks that typically require human intelligence.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="DISINFORMATION">
      <data key="d0">CONCEPT, RISK</data>
      <data key="d1">Disinformation is false or misleading information that can be generated by large language models and used maliciously without suitable safeguards.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">CONCEPT, RISK</data>
    </node>
    <node id="BENCHMARKS">
      <data key="d0">DATASET, EVALUATION</data>
      <data key="d1">Benchmarks are standardized tests or datasets used to evaluate the performance of models like Orca-3 after post-training with synthetic data.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="PROMPTS AND RESPONSES">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Prompts and responses are the input-output pairs generated by methods like AgentInstruct from unstructured data sources, used for training models.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MODEL CUSTOMIZATION">
      <data key="d0">PROCESS, TECHNOLOGY</data>
      <data key="d1">Model customization is the process of tailoring a model to meet specific requirements or perform better in particular domains by using synthetic data and agentic flows.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PROCESS, TECHNOLOGY</data>
    </node>
    <node id="HUMAN CURATION">
      <data key="d0">PROCESS, ACTIVITY</data>
      <data key="d1">Human curation refers to the manual intervention and oversight required during the data creation process to ensure quality and relevance, which AgentInstruct aims to minimize.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PROCESS, ACTIVITY</data>
    </node>
    <node id="DIVERSE DATA">
      <data key="d0">DATA, ATTRIBUTE</data>
      <data key="d1">Diverse data refers to a wide variety of data types and sources used to train models, ensuring they perform well across different scenarios and tasks.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">DATA, ATTRIBUTE</data>
    </node>
    <node id="HIGH-QUALITY DATA">
      <data key="d0">DATA, ATTRIBUTE</data>
      <data key="d1">High-quality data is accurate, relevant, and well-structured data used for training models to improve their performance and reliability.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">DATA, ATTRIBUTE</data>
    </node>
    <node id="MODEL TRAINING">
      <data key="d0">PROCESS, TECHNOLOGY</data>
      <data key="d1">Model training is the process of teaching a machine learning model to perform tasks by feeding it data and adjusting its parameters to improve performance.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PROCESS, TECHNOLOGY</data>
    </node>
    <node id="PRE-TRAINING">
      <data key="d0">PROCESS, TECHNOLOGY</data>
      <data key="d1">Pre-training is the initial phase of training a model on a large dataset to learn general features before fine-tuning it for specific tasks or domains.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PROCESS, TECHNOLOGY</data>
    </node>
    <node id="DOMAIN-SPECIFIC CONTENT">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Domain-specific content is specialized data related to a particular field or area, used as seeds for training models to improve their performance in that domain.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">DATA, RESOURCE</data>
    </node>
    <node id="SEMI-AUTOMATED PIPELINES">
      <data key="d0">PROCESS, TECHNOLOGY</data>
      <data key="d1">Semi-automated pipelines are partially automated processes that use synthetic data and agentic flows to streamline model customization and continual improvement.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PROCESS, TECHNOLOGY</data>
    </node>
    <node id="PHI-3">
      <data key="d0">MODEL, TECHNOLOGY</data>
      <data key="d1">Phi-3 is a model discussed in the technical report authored by multiple researchers, detailing its technical aspects and performance.
Phi-3 is a highly capable language model designed to run locally on mobile devices, as described in a technical report published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172,dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">MODEL, TECHNOLOGY</data>
    </node>
    <node id="LEGAL COGNITIVE SERVICES">
      <data key="d0">SERVICE, TECHNOLOGY</data>
      <data key="d1">Legal cognitive services are tools provided by Microsoft, including transparency notes, to help users understand the rationale behind specific outputs or decisions of large language models.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">SERVICE, TECHNOLOGY</data>
    </node>
    <node id="DIFFICULT REASONING TASKS">
      <data key="d0">TASK, CHALLENGE</data>
      <data key="d1">Difficult reasoning tasks are complex problems that require advanced cognitive abilities, which models like LATS aim to solve with the help of external feedback.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">TASK, CHALLENGE</data>
    </node>
    <node id="LARGE LANGUAGE MODELS">
      <data key="d0">TECHNOLOGY, MODEL</data>
      <data key="d1">Large language models are advanced AI models designed to understand and generate human language, capable of performing a wide range of tasks but also susceptible to risks like hallucination and misuse.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">TECHNOLOGY, MODEL</data>
    </node>
    <node id="FABRICATING CONTENT">
      <data key="d0">CONCEPT, RISK</data>
      <data key="d1">Fabricating content refers to the generation of false or misleading information by language models, which can be problematic in critical decision-making scenarios.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">CONCEPT, RISK</data>
    </node>
    <node id="UNGROUNDED GENERATION">
      <data key="d0">CONCEPT, RISK</data>
      <data key="d1">Ungrounded generation refers to the creation of content by language models without a solid basis in factual information, increasing the risk of hallucination.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">CONCEPT, RISK</data>
    </node>
    <node id="MEASUREMENT AND MITIGATIONS">
      <data key="d0">PROCESS, TECHNOLOGY</data>
      <data key="d1">Measurement and mitigations are efforts to rigorously assess and reduce the risks associated with language models, such as hallucination and misuse.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PROCESS, TECHNOLOGY</data>
    </node>
    <node id="DISTRIBUTION OF TUNING DATA">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Distribution of tuning data refers to how the data used to fine-tune a model is spread across different categories, which can affect the model's performance in underrepresented areas.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="MULTIPLE BENCHMARKS">
      <data key="d0">DATASET, EVALUATION</data>
      <data key="d1">Multiple benchmarks are various standardized tests or datasets used to evaluate the performance of models like Orca-3 after post-training with synthetic data.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="AGENTIC FRAMEWORK">
      <data key="d0">METHOD, TECHNOLOGY</data>
      <data key="d1">An agentic framework is a structured approach used by AgentInstruct to generate synthetic data, facilitating the post-training of models and teaching them a variety of skills.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="UNSTRUCTURED CONTENT">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Unstructured content refers to raw data inputs that lack a predefined format, which can be used by AgentInstruct to generate tailored datasets for model training.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="INSTRUCTION DATA">
      <data key="d0">DATA, RESOURCE</data>
      <data key="d1">Instruction data is the input-output pairs generated by methods like AgentInstruct from unstructured data sources, used for training models.</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="AI2 REASONING CHALLENGE (ARC)">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">The AI2 Reasoning Challenge (ARC) is a benchmark for evaluating question-answering systems, introduced in a paper published in 2018.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="KARL COBBE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Karl Cobbe is one of the authors of the paper on training verifiers to solve math word problems, published in 2021.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CODEPARROT">
      <data key="d0">ORGANIZATION, DATASET PROVIDER</data>
      <data key="d1">CodeParrot is the provider of the Github-code clean dataset, which was accessed in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="GITHUB-CODE CLEAN DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">The Github-code clean dataset is a dataset provided by CodeParrot, accessed in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="NING DING">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ning Ding is one of the authors of the paper on enhancing chat language models by scaling high-quality instructional conversations, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DROA">
      <data key="d0">BENCHMARK, DATASET</data>
      <data key="d1">DROP is a reading comprehension benchmark requiring discrete reasoning over paragraphs, introduced in a paper published in 2019.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZHAOYE FEI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhaoye Fei is one of the authors of the paper on Query of CC, which unearths large-scale domain-specific knowledge from public corpora, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ARNAV GUDIBANDE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Arnav Gudibande is one of the authors of the paper on the false promise of imitating proprietary LLMs, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HAMISH IVISON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hamish Ivison is one of the authors of the paper on enhancing LM adaptation with Tulu 2, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ALBERT Q. JIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Albert Q. Jiang is one of the authors of the paper on Mistral 7B, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HARRISON LEE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Harrison Lee is one of the authors of the paper on RLAIF, which scales reinforcement learning from human feedback with AI feedback, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="GUOHAO LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Guohao Li is one of the authors of the paper on CAMEL, which explores communicative agents for "mind" exploration of large language model society, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="READING COMPREHENSION BENCHMARK">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="QUERY OF CC">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="IMITATING PROPRIETARY LLMS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MEASURING MATHEMATICAL PROBLEM SOLVING">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ENHANCING LM ADAPTATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MISTRAL 7B">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="RLAIF">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CAMEL">
      <data key="d0" />
      <data key="d1">
Camel is a framework for communicative agents designed for the exploration of large language model society, as described in a 2023 paper.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="PHILIPP WITTE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Philipp Witte is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HAIPING WU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Haiping Wu is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MICHAEL WYATT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Michael Wyatt is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="BIN XIAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bin Xiao is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CAN XU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Can Xu is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.
Can Xu is one of the authors of the paper titled "Wizardlm: Empowering large language models to follow complex instructions," published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JIAHANG XU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jiahang Xu is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="WEIJIAN XU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Weijian Xu is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SONALI YADAV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sonali Yadav is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="FAN YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Fan Yang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JIANWEI YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jianwei Yang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZIYI YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ziyi Yang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YIFAN YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yifan Yang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DONGHAN YU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Donghan Yu is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="LU YUAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lu Yuan is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CHENGRUIDONG ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chengruidong Zhang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CYRIL ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Cyril Zhang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JIANWEN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jianwen Zhang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="LI LYNA ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Li Lyna Zhang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YI ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yi Zhang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YUE ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yue Zhang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YUNAN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yunan Zhang is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="XIREN ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiren Zhou is one of the authors of the Phi-3 technical report, a highly capable language model for mobile devices, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ISAAC COWHEY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Isaac Cowhey is one of the authors of the paper on the AI2 Reasoning Challenge (ARC), published in 2018.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="OREN ETZIONI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Oren Etzioni is one of the authors of the paper on the AI2 Reasoning Challenge (ARC), published in 2018.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TUSHAR KHOT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tushar Khot is one of the authors of the paper on the AI2 Reasoning Challenge (ARC), published in 2018.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ASHISH SABHARWAL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ashish Sabharwal is one of the authors of the paper on the AI2 Reasoning Challenge (ARC), published in 2018.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CARISSA SCHOENICK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Carissa Schoenick is one of the authors of the paper on the AI2 Reasoning Challenge (ARC), published in 2018.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="OYVIND TAFJORD">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Oyvind Tafjord is one of the authors of the paper on the AI2 Reasoning Challenge (ARC), published in 2018.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YULIN CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yulin Chen is one of the authors of the paper on enhancing chat language models by scaling high-quality instructional conversations, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="BOKAI XU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bokai Xu is one of the authors of the paper on enhancing chat language models by scaling high-quality instructional conversations, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZHI ZHENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhi Zheng is one of the authors of the paper on enhancing chat language models by scaling high-quality instructional conversations, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SHENGDING HU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shengding Hu is one of the authors of the paper on enhancing chat language models by scaling high-quality instructional conversations, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DHEERU DUA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dheeru Dua is one of the authors of the paper on DROP, a reading comprehension benchmark, published in 2019.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YIZHONG WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yizhong Wang is one of the authors of the paper on DROP, a reading comprehension benchmark, published in 2019.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="PRADEEP DASIGI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Pradeep Dasigi is one of the authors of the paper on DROP, a reading comprehension benchmark, published in 2019.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="GABRIEL STANOVSKY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Gabriel Stanovsky is one of the authors of the paper on DROP, a reading comprehension benchmark, published in 2019.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SAMEER SINGH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sameer Singh is one of the authors of the paper on DROP, a reading comprehension benchmark, published in 2019.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MATT GARDNER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Matt Gardner is one of the authors of the paper on DROP, a reading comprehension benchmark, published in 2019.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YUNFAN SHAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yunfan Shao is one of the authors of the paper on Query of CC, which unearths large-scale domain-specific knowledge from public corpora, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="LINYANG LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Linyang Li is one of the authors of the paper on Query of CC, which unearths large-scale domain-specific knowledge from public corpora, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZHIYUAN ZENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhiyuan Zeng is one of the authors of the paper on Query of CC, which unearths large-scale domain-specific knowledge from public corpora, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HANG YAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hang Yan is one of the authors of the paper on Query of CC, which unearths large-scale domain-specific knowledge from public corpora, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="XIPENG QIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xipeng Qiu is one of the authors of the paper on Query of CC, which unearths large-scale domain-specific knowledge from public corpora, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DAHUA LIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dahua Lin is one of the authors of the paper on Query of CC, which unearths large-scale domain-specific knowledge from public corpora, published in 2024.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ERIC WALLACE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Eric Wallace is one of the authors of the paper on the false promise of imitating proprietary LLMs, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CHARLIE SNELL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Charlie Snell is one of the authors of the paper on the false promise of imitating proprietary LLMs, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="XINYANG GENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xinyang Geng is one of the authors of the paper on the false promise of imitating proprietary LLMs, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HAO LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hao Liu is one of the authors of the paper on the false promise of imitating proprietary LLMs, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="AKUL ARORA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Akul Arora is one of the authors of the paper on measuring mathematical problem solving with the math dataset, published in 2021.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ERIC TANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Eric Tang is one of the authors of the paper on measuring mathematical problem solving with the math dataset, published in 2021.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DAVID WADDEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">David Wadden is one of the authors of the paper on enhancing LM adaptation with Tulu 2, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="NOAH A. SMITH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Noah A. Smith is one of the authors of the paper on enhancing LM adaptation with Tulu 2, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="IZ BELTAGY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Iz Beltagy is one of the authors of the paper on enhancing LM adaptation with Tulu 2, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HANNANEH HAJISHIRZI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hannaneh Hajishirzi is one of the authors of the paper on enhancing LM adaptation with Tulu 2, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ALEXANDRE SABLAYROLLES">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alexandre Sablayrolles is one of the authors of the paper on Mistral 7B, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ARTHUR MENSCH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Arthur Mensch is one of the authors of the paper on Mistral 7B, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CHRIS BAMFORD">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chris Bamford is one of the authors of the paper on Mistral 7B, published in 2023.</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DEVENDRA SINGH CHAPLOT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Devendra Singh Chaplot is one of the authors of</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="RII KHIZBULLIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rii Khizbullin is one of the authors of the paper titled "Camel: Communicative agents for 'mind' exploration of large language model society" published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="BERNARD GHANEM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Bernard Ghanem is one of the authors of the paper titled "Camel: Communicative agents for 'mind' exploration of large language model society" published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="XUECHEN LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xuechen Li is one of the authors of the AlpacaEval project, an automatic evaluator of instruction-following models, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="TIANYI ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tianyi Zhang is one of the authors of the AlpacaEval project, an automatic evaluator of instruction-following models, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="YANN DUBOIS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yann Dubois is one of the authors of the AlpacaEval project, an automatic evaluator of instruction-following models, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ROHAN TAORI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Rohan Taori is one of the authors of the AlpacaEval project, an automatic evaluator of instruction-following models, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ISHAAN GULRAJANI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ishaan Gulrajani is one of the authors of the AlpacaEval project, an automatic evaluator of instruction-following models, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="CARLOS GUESTRIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Carlos Guestrin is one of the authors of the AlpacaEval project, an automatic evaluator of instruction-following models, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="TATSUNORI B. HASHIMOTO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tatsunori B. Hashimoto is one of the authors of the AlpacaEval project, an automatic evaluator of instruction-following models, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="YIXIN LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yixin Liu is one of the authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ALEXANDER R. FABBRI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Alexander R. Fabbri is one of the authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="JIAWEN CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jiawen Chen is one of the authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="YILUN ZHAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yilun Zhao is one of the authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SIMENG HAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Simeng Han is one of the authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SHAFIQ JOTY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shafiq Joty is one of the authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="DRAGOMIR RADEV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Dragomir Radev is one of the authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="CHIEN-SHENG WU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chien-Sheng Wu is one of the authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ARMAN COHAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Arman Cohan is one of the authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="BENCHMARKING GENERATION AND EVALUATION CAPABILITIES">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="LM-SYS">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">LM-Sys is the organization behind the MT-Bench project, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="DANIEL VAN STRIEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Daniel van Strien is one of the authors of the Cosmopedia project, a guide on creating large-scale synthetic data for pre-training, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="LOUBNA BEN ALLAL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Loubna Ben Allal is one of the authors of the Cosmopedia project, a guide on creating large-scale synthetic data for pre-training, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ANTON LOZHKOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Anton Lozhkov is one of the authors of the Cosmopedia project, a guide on creating large-scale synthetic data for pre-training, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="COSMOPEDIA">
      <data key="d0">GUIDE, PROJECT</data>
      <data key="d1">Cosmopedia is a guide on how to create large-scale synthetic data for pre-training, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="CLARISSE SIMOES">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Clarisse Simoes is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SAHAJ AGARWAL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sahaj Agarwal is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="XUXI CHEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xuxi Chen is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ANASTASIA RAZDAIBIEDINA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Anastasia Razdaibiedina is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ERIK JONES">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Erik Jones is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="KRITI AGGARWAL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kriti Aggarwal is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="HAMID PALANGI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Hamid Palangi is one of the authors of the Orca 2 project, which focuses on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ORCA 2">
      <data key="d0">PROJECT, METHOD</data>
      <data key="d1">Orca 2 is a project focused on teaching small language models how to reason, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SUBHABRATA MUKHERJEE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Subhabrata Mukherjee is one of the authors of the Xtremedistil project, a multi-stage distillation method for massive multilingual models, published in 2020.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="XTREMEDISTIL">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">Xtremedistil is a multi-stage distillation method for massive multilingual models, published in 2020.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="GANESH JAWAHAR">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ganesh Jawahar is one of the authors of the Orca project, which focuses on progressive learning from complex explanation traces of GPT-4, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="ORCA">
      <data key="d0">PROJECT, METHOD</data>
      <data key="d1">Orca is a project focused on progressive learning from complex explanation traces of GPT-4, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SAMUEL J. PAECH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Samuel J. Paech is the author of the EQ-Bench project, an emotional intelligence benchmark for large language models, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="EQ-BENCH">
      <data key="d0">TOOL, BENCHMARK</data>
      <data key="d1">EQ-Bench is an emotional intelligence benchmark for large language models, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="BAOLIN PENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Baolin Peng is one of the authors of a paper on instruction tuning with GPT-4, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="CHUNYUAN LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chunyuan Li is one of the authors of a paper on instruction tuning with GPT-4, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="PENGCHENG HE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Pengcheng He is one of the authors of a paper on instruction tuning with GPT-4, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="MICHEL GALLEY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Michel Galley is one of the authors of a paper on instruction tuning with GPT-4, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="INSTRUCTION TUNING WITH GPT-4">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper on instruction tuning with GPT-4, published in 2023.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="YIWEI QIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yiwei Qin is one of the authors of the InfoBench project, which evaluates the instruction-following ability in large language models, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="KAIQIANG SONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kaiqiang Song is one of the authors of the InfoBench project, which evaluates the instruction-following ability in large language models, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="YEBO WEN HU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yebo Wen Hu is one of the authors of the InfoBench project, which evaluates the instruction-following ability in large language models, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="WENLIN YAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wenlin Yao is one of the authors of the InfoBench project, which evaluates the instruction-following ability in large language models, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="SANGWOO CHO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sangwoo Cho is one of the authors of the InfoBench project, which evaluates the instruction-following ability in large language models, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="XIAOYANG WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiaoyang Wang is one of the authors of the InfoBench project, which evaluates the instruction-following ability in large language models, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="XUANSHENG WU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xuansheng Wu is one of the authors of the InfoBench project, which evaluates the instruction-following ability in large language models, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="MOHAMMED LATIF SIDDIQ">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Mohammed Latif Siddiq is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.
Mohammed Latif Siddiq is one of the authors of the paper titled "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks," published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JIAHAO ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jiahao Zhang is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.
Jiahao Zhang is one of the authors of the paper titled "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks," published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LINDSAY RONEY">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Lindsay Roney is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.
Lindsay Roney is one of the authors of the paper titled "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks," published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JOANNA C. S.">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Joanna C. S. is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="THE CURSE OF RECURSION">
      <data key="d0">RESEARCH PAPER</data>
      <data key="d1">A research paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.
A paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024, discussing the negative effects of training models on generated data.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ILIA SHUMAILOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ilia Shumailov is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.
Ilia Shumailov is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ZAKHAR SHUMAYLOV">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zakhar Shumaylov is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.
Zakhar Shumaylov is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIREN ZHAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yiren Zhao is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.
Yiren Zhao is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YARIN GAL">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yarin Gal is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.
Yarin Gal is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NICOLAS PAPERNOT">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nicolas Papernot is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.
Nicolas Papernot is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ROSS ANDERSON">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ross Anderson is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.
Ross Anderson is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget," published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CHING-AN CHENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ching-An Cheng is one of the authors of the paper titled "Direct Nash Optimization: Teaching language models to self-improve with general preferences," published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="TENGYANG XIE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tengyang Xie is one of the authors of the paper titled "Direct Nash Optimization: Teaching language models to self-improve with general preferences," published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="DIRECT NASH OPTIMIZATION">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">Direct Nash Optimization is a method for teaching language models to self-improve with general preferences, published in 2024.</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="JOANNA C. S. SANTOS">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Joanna C. S. Santos is one of the authors of the paper titled "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="RE(GEX|DOS)EVAL">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks," published in 2024, discussing the evaluation of generated regular expressions and their vulnerability to denial-of-service attacks.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NATHANAEL SCH&#196;RLI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nathanael Sch&#228;rli is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CHALLENGING BIG-BENCH TASKS">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them," published in 2022, discussing the challenges of big-bench tasks and the effectiveness of chain-of-thought reasoning.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WEN WAI YIM">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wen Wai Yim is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YUJUAN FU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yujuan Fu is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ASMA BEN ABACHA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Asma Ben Abacha is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NEAL SNIDER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Neal Snider is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="THOMAS LIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Thomas Lin is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="MELIHA YETISGEN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Meliha Yetisgen is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="XIAYUN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiaoyun Zhang is one of the authors of the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="AHMED HASSAN AWADALLAH">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ahmed Hassan Awadallah is one of the authors of the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="RYEN W WHITE">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ryen W White is one of the authors of the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="DOUG BURGER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Doug Burger is one of the authors of the paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="AUTOGEN">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Autogen: Enabling next-gen llm applications via multi-agent conversation," published in 2023, discussing the use of multi-agent conversation to enable next-generation large language model applications.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CONGYING XIA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Congying Xia is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CHEN XING">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chen Xing is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JIANGSHU DU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jiangshu Du is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="XINYI YANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xinyi Yang is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIHAO FENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yihao Feng is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="RAN XU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ran Xu is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WENPENG YIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wenpeng Yin is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CAIMING XIONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Caiming Xiong is one of the authors of the paper titled "Fofo: A benchmark to evaluate llms&#8217; format-following capability," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="GUANGZHI XIONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Guangzhi Xiong is one of the authors of the paper titled "Benchmarking retrieval-augmented generation for medicine," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="QIAO JIN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qiao Jin is one of the authors of the paper titled "Benchmarking retrieval-augmented generation for medicine," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ZHIYONG LU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhiyong Lu is one of the authors of the paper titled "Benchmarking retrieval-augmented generation for medicine," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="AIDONG ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Aidong Zhang is one of the authors of the paper titled "Benchmarking retrieval-augmented generation for medicine," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="BENCHMARKING RETRIEVAL-AUGMENTED GENERATION FOR MEDICINE">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Benchmarking retrieval-augmented generation for medicine," published in 2024, discussing the evaluation of retrieval-augmented generation techniques in the medical field.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="QINGFENG SUN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Qingfeng Sun is one of the authors of the paper titled "Wizardlm: Empowering large language models to follow complex instructions," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="KAI ZHENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Kai Zheng is one of the authors of the paper titled "Wizardlm: Empowering large language models to follow complex instructions," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="XIUBO GENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Xiubo Geng is one of the authors of the paper titled "Wizardlm: Empowering large language models to follow complex instructions," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="PU ZHAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Pu Zhao is one of the authors of the paper titled "Wizardlm: Empowering large language models to follow complex instructions," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JIAZHAN FENG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jiazhan Feng is one of the authors of the paper titled "Wizardlm: Empowering large language models to follow complex instructions," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CHONGYANG TAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Chongyang Tao is one of the authors of the paper titled "Wizardlm: Empowering large language models to follow complex instructions," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="DAXIN JIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Daxin Jiang is one of the authors of the paper titled "Wizardlm: Empowering large language models to follow complex instructions," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WIZARDLM">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Wizardlm: Empowering large language models to follow complex instructions," published in 2023, discussing techniques to enable large</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LONGHUI YU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Longhui Yu is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WEISEN JIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Weisen Jiang is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="HAN SHI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Han Shi is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JINCHENG YU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jincheng Yu is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ZHENGYING LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhengying Liu is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YU ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yu Zhang is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JAMES T KWOK">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">James T Kwok is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ZHENGUO LI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Zhenguo Li is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ADRIAN WELLER">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Adrian Weller is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WEIYANG LIU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Weiyang Liu is one of the authors of the paper titled "Metamath: Bootstrap your own mathematical questions for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="METAMATH">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Metamath: Bootstrap your own mathematical questions for large language models," published in 2023, discussing methods to generate mathematical questions for large language models.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIFAN ZHANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yifan Zhang is one of the authors of the paper titled "Automathtext: Autonomous data selection with language models for mathematical texts," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIFAN LUO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yifan Luo is one of the authors of the paper titled "Automathtext: Autonomous data selection with language models for mathematical texts," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YANG YUAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yang Yuan is one of the authors of the paper titled "Automathtext: Autonomous data selection with language models for mathematical texts," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="ANDREW CHI-CHIH YAO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Andrew Chi-Chih Yao is one of the authors of the paper titled "Automathtext: Autonomous data selection with language models for mathematical texts," published in 2024.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="WANJUN ZHONG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Wanjun Zhong is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="RUIXIANG CUI">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Ruixiang Cui is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YIDUO GUO">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yiduo Guo is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YAOBO LIANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yaobo Liang is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SHUAI LU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Shuai Lu is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YANLIN WANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yanlin Wang is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NAN DUAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Nan Duan is one of the authors of the paper titled "Agieval: A human-centric benchmark for evaluating foundation models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JEFFREY ZHOU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Jeffrey Zhou is one of the authors of the paper titled "Instruction-following evaluation for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="TIANJIAN LU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Tianjian Lu is one of the authors of the paper titled "Instruction-following evaluation for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SIDDHARTHA BRAHMA">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Siddhartha Brahma is one of the authors of the paper titled "Instruction-following evaluation for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SUJOY BASU">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Sujoy Basu is one of the authors of the paper titled "Instruction-following evaluation for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="YI LUAN">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">Yi Luan is one of the authors of the paper titled "Instruction-following evaluation for large language models," published in 2023.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="INSTRUCTION-FOLLOWING EVALUATION">
      <data key="d0">PAPER, RESEARCH</data>
      <data key="d1">A paper titled "Instruction-following evaluation for large language models," published in 2023, discussing methods to evaluate how well large language models follow instructions.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="DEBATE PASSAGE GENERATOR">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">An agent that specializes in crafting passages that mimic the structure and content of debate transcripts.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CONVERSATION PASSAGE GENERATOR">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">An agent that generates passages depicting dialogues.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="MEETING TRANSCRIPT GENERATOR">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">An agent designed to produce meeting transcripts.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="POEM GENERATOR">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">An agent that generates poems.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="SATIRICAL PASSAGE GENERATOR">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">An agent that creates texts infused with satirical wit.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="INSTRUCTIONAL PASSAGE GENERATOR">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">An agent that generates passages resembling instructional manuals.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LONG TEXT GENERATOR">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">An agent that extends the original text by incorporating additional information, thereby increasing its length.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="IDENTITY AGENT">
      <data key="d0">AGENT, TOOL</data>
      <data key="d1">A straightforward agent that replicates the input text verbatim.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="LITERAL COMPREHENSION QUESTION">
      <data key="d0">QUESTION TYPE, INSTRUCTION</data>
      <data key="d1">A question that asks for a specific detail(s) or fact(s) clearly stated in the text.</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="NUMERICAL DISCRETE REASONING">
      <data key="d0">QUESTION TYPE, INSTRUCTION</data>
      <data key="d1">Questions that require the reader to use numerical reasoning over many facts from the text.
Questions that require the reader to use numerical reasoning over many facts from the text.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CRITICAL COMPREHENSION QUESTION">
      <data key="d0">QUESTION TYPE, INSTRUCTION</data>
      <data key="d1">Construct two statements about the purpose or point of view that the reader must assess as true or false, with one being true and the other false.
True/False questions that require the reader to assess the purpose or point of view, with one statement being true and the other false.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="EVALUATIVE COMPREHENSION QUESTION">
      <data key="d0">QUESTION TYPE, INSTRUCTION</data>
      <data key="d1">A question type that requires the reader to evaluate and provide an essay response based on the text.
Open-ended questions that prompt an in-depth analysis of the text&#8217;s theme or the effectiveness of an argument.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="VOCABULARY AND LANGUAGE USE">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Fill-in-the-blank questions that test understanding of a particular word or phrase used in the text.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="RELATIONSHIP COMPREHENSION QUESTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Matching questions where respondents pair items based on a specific criterion.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="SEQUENCING EVENTS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Questions that require arranging a series of events from the text in the correct chronological order.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="STRENGTHEN">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Questions that ask to identify information that would make the argument&#8217;s conclusion more likely to be true.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="WEAKEN">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Questions that ask to find evidence or an argument that would make the conclusion less likely to be true.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="ASSUMPTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Questions that determine what must be true for the argument to hold.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="FLAW">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Questions that point out a mistake in the argument&#8217;s reasoning.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="INFERENCE">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Questions that ask to choose an option that logically follows from the information provided.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="PRINCIPLE">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Questions that recognize the general rule or principle that underlies the argument.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="METHOD OF REASONING">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Questions that describe how the argument is constructed logically.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="RESOLVE THE PARADOX">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Questions that offer an explanation that reconciles seemingly contradictory information.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="TEXT SIMPLIFICATION">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Making text easier to read and understand by using simpler words and sentence structures, often for children or language learners.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="TEXT EXPANSION">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Adding more information or detail to make text more comprehensive or to meet a certain word count.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="TEXT TRANSLATION">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Converting text from one language to another while attempting to preserve the original meaning as closely as possible.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="TEXT FORMATTING">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Altering the appearance of text to improve readability or for stylistic purposes.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="SENTIMENT MODIFICATION">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Changing the tone of the text to alter its emotional impact, such as making a sentence sound more positive or negative.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="TEXT ANNOTATION">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Adding notes, comments, or explanations to a text, often for the purpose of analysis or to provide additional context.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="KEYWORD REPLACEMENT">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Substituting specific words or phrases with synonyms or related terms.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="TEXT REMOVING">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Redacting or removing content from text.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="TEXT CAPITALIZATION">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Adjusting the case of letters in text, such as converting to uppercase, lowercase, title case, or sentence case.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="TEXT STYLING">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Applying styles like bold, italics, underline, etc., to emphasize certain parts of the text or for aesthetic purposes.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="CONTENT REWRITING">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Extensively modifying a text to produce a new version, which could involve changing the perspective, style, or target audience.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="DATA NORMALIZATION">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Standardizing text to ensure consistency, such as converting dates and times to a standard format or unifying the spelling of words.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="PLAGIARISM REWORDING">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Altering text to avoid plagiarism, ensuring that the content is original.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="TEXT OBFUSCATION">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Intentionally making text vague or harder to understand, sometimes for security purposes like masking personal data.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="TEXTUAL ENTAILMENT">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Modifying a sentence or phrase to either entail or contradict another sentence, often used in natural language processing tasks.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="REWRITING WITH VOCABULARY LIMITATIONS">
      <data key="d0">TEXT MODIFICATION METHOD</data>
      <data key="d1">Rewriting the entire text or a piece of it while using a limited vocabulary, such as all words starting with a specific letter.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION METHOD</data>
    </node>
    <node id="INSTRUCTION TAXONOMY">
      <data key="d0">EVALUATION METHOD</data>
      <data key="d1">A classification system used for generating seed instructions for various types of questions and tasks.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="EVALUATOR ASSISTANT">
      <data key="d0">ROLE</data>
      <data key="d1">A role assigned to GPT-4 for parsing student responses and extracting the selected options in multiple choice questions.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="ANSWER OPTIONS">
      <data key="d0">DATA</data>
      <data key="d1">The set of possible answers provided for a multiple choice question, from which the student selects one or more options.</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="ALPHABET ID">
      <data key="d0">DATA</data>
      <data key="d1">The letter representing the option selected by the student in a multiple choice question.
The alphabet representing the option chosen by the student in their response.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="PARSED STUDENT ANSWER">
      <data key="d0">ANSWER FORMAT, STUDENT RESPONSE</data>
      <data key="d1">The final answer extracted from the student's response, represented by the alphabets corresponding to the options chosen by the student.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="OPTIONS">
      <data key="d0">ANSWER CHOICES, MULTIPLE CHOICE</data>
      <data key="d1">A list of possible answers provided for the student to choose from, each represented by an alphabet.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="EXACT MATCH/SPAN EXTRACTION PROBLEMS">
      <data key="d0">TASK TYPE, PROBLEM TYPE</data>
      <data key="d1">Tasks that involve math-based questions or problems where a ground-truth answer value is given, requiring the model to generate and match the exact answer with the provided ground-truth.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="MATHS GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d0">SYSTEM MESSAGE, INSTRUCTION</data>
      <data key="d1">A specific system message used for evaluating a student's answer to a math word problem, ensuring the final answer matches the problem setter's answer.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="GENERAL EXTRACTION SYSTEM MESSAGE">
      <data key="d0">SYSTEM MESSAGE, INSTRUCTION</data>
      <data key="d1">A system message used for parsing student responses and matching them with the correct answer provided in the context.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="EQBENCH GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d0">SYSTEM MESSAGE, INSTRUCTION</data>
      <data key="d1">A system message used for extracting emotion scores from a student agent's response, including first pass scores, critique, and revised scores.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="EMOTION SCORES">
      <data key="d0">SCORE, METRIC</data>
      <data key="d1">Scores generated for each emotion in a conversation, ranging from 0-10, indicating the alignment with the reference answer.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="VERSION 1 AND 2 IMPLEMENTATIONS">
      <data key="d0">IMPLEMENTATION, METHOD</data>
      <data key="d1">Different versions of implementations described in the EQBench paper and repository, used for scoring calculations.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="CREATORS' GITHUB REPOSITORY">
      <data key="d0">REPOSITORY, SOURCE</data>
      <data key="d1">The GitHub repository maintained by the creators of EQBench, containing the implementations and resources for the benchmark.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="FINAL ANSWER">
      <data key="d0">ANSWER, RESPONSE</data>
      <data key="d1">The definitive answer provided by the student after considering all options.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="CORRECT ANSWER">
      <data key="d0">ANSWER, GROUND-TRUTH</data>
      <data key="d1">The answer provided by the problem setter, used as a reference to evaluate the student's response.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="ERROR ANALYSIS">
      <data key="d0">EVALUATION, ANALYSIS</data>
      <data key="d1">A process of comparing the student's final answer with the correct answer to determine if they match.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="FINAL VERDICT">
      <data key="d0">EVALUATION, RESULT</data>
      <data key="d1">The result of the error analysis, indicating whether the student's answer is 'Correct' or 'Incorrect'.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="STUDENT AGENT RESPONSE">
      <data key="d0">RESPONSE, ANSWER</data>
      <data key="d1">The response generated by a student agent, including emotion scores and critiques.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="FIRST PASS SCORES">
      <data key="d0">SCORE, INITIAL EVALUATION</data>
      <data key="d1">The initial scores assigned to each emotion in the student agent's response.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="CRITIQUE">
      <data key="d0">EVALUATION, FEEDBACK</data>
      <data key="d1">A detailed analysis of the student agent's response, explaining the reasoning behind the scores.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="REVISED SCORES">
      <data key="d0">SCORE, FINAL EVALUATION</data>
      <data key="d1">The updated scores assigned to each emotion after considering the critique.</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="ALEX">
      <data key="d0">PERSON</data>
      <data key="d1">Alex is a person who is already in a relationship and has been confessed to by Elliot, putting Alex in an awkward position.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="RESIGNED">
      <data key="d0">EMOTION</data>
      <data key="d1">Resigned is an emotion experienced by Elliot, scored at 7, indicating a feeling of acceptance of an unpleasant situation.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="ANGRY">
      <data key="d0">EMOTION</data>
      <data key="d1">Angry is an emotion experienced by Elliot, scored at 3, indicating a feeling of displeasure or annoyance.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="HOPEFUL">
      <data key="d0">EMOTION</data>
      <data key="d1">Hopeful is an emotion experienced by Elliot, scored at 5, indicating a feeling of optimism or expectation that Alex might reciprocate his feelings.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="EMBARRASSED">
      <data key="d0">EMOTION</data>
      <data key="d1">Embarrassed is an emotion experienced by Elliot, scored at 8, indicating a feeling of self-consciousness or shame for putting Alex in an awkward position.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="OPEN-ENDED GENERATION">
      <data key="d0">TASK, CATEGORY</data>
      <data key="d1">Open-Ended Generation tasks involve generating an answer to an open-ended question without a ground-truth to match the answer. Various benchmarks are used to evaluate these tasks.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="HALLUCINATION JUDGE">
      <data key="d0">TASK, TOOL</data>
      <data key="d1">Hallucination Judge is a task where a judge decides if there is any hallucination in a generated summary by comparing it with relevant facts from the article.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="QUALITY JUDGE">
      <data key="d0">TASK, TOOL</data>
      <data key="d1">Quality Judge is a task where a judge evaluates the quality of a response provided by an AI assistant based on criteria like instruction adherence, content grounding, and overall quality.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="ELLIOT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="EMOTIONS">
      <data key="d0">CATEGORY</data>
      <data key="d1">A list of feelings experienced by Elliot, including resigned, angry, hopeful, and embarrassed.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="SCORES">
      <data key="d0">METRIC</data>
      <data key="d1">Numerical values assigned to each of Elliot's emotions: Resigned (7), Angry (3), Hopeful (5), Embarrassed (8).</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="VERSION 0613">
      <data key="d0">VERSION</data>
      <data key="d1">A specific version of GPT-4 used in the FOFO and AlpacaEval benchmarks.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="VERSION 1106-PREVIEW">
      <data key="d0">VERSION</data>
      <data key="d1">A specific version of GPT-4 used in the InfoBench benchmark.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="JUDGE">
      <data key="d0">ROLE</data>
      <data key="d1">The role played by GPT-4 in evaluating benchmarks like FOFO, MT-Bench, AlpacaEval, and InfoBench.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="PROMPT TEMPLATE">
      <data key="d0">TOOL</data>
      <data key="d1">A predefined format used for tasks like hallucination detection and quality evaluation in text summarization.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="HALLUCINATION DETECTION">
      <data key="d0">TASK</data>
      <data key="d1">The process of identifying hallucinated content in a generated summary by comparing it with relevant facts from the article.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="TEXT SUMMARIZATION">
      <data key="d0">TASK</data>
      <data key="d1">The task of generating a concise and accurate summary of a given text, evaluated for quality and hallucination.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="INSTRUCTION ADHERENCE">
      <data key="d0">CRITERION</data>
      <data key="d1">A criterion used in quality evaluation to check if the response correctly follows the user instruction.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="CONTENT GROUNDING">
      <data key="d0">CRITERION</data>
      <data key="d1">A criterion used in quality evaluation to check if the response is grounded in the instruction without introducing new content.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="OVERALL QUALITY">
      <data key="d0">CRITERION</data>
      <data key="d1">A criterion used in quality evaluation to assess the clarity, coherence, and completeness of the response.</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <edge source="GRAPH RAG" target="LLM">
      <data key="d4">18.0</data>
      <data key="d5">Graph RAG uses LLMs to build a graph-based text index and generate community summaries.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="QFS">
      <data key="d4">16.0</data>
      <data key="d5">Graph RAG combines the strengths of RAG and QFS to answer global questions directed at an entire text corpus.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="COMMUNITY DETECTION">
      <data key="d4">16.0</data>
      <data key="d5">Graph RAG uses community detection to partition the graph index into groups of elements.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="QUERY-FOCUSED SUMMARIZATION">
      <data key="d4">16.0</data>
      <data key="d5">Graph RAG uses query-focused summarization to generate a global answer from community summaries.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="MICROSOFT RESEARCH">
      <data key="d4">16.0</data>
      <data key="d5">Microsoft Research is involved in the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES">
      <data key="d4">16.0</data>
      <data key="d5">Microsoft Strategic Missions and Technologies is involved in the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="MICROSOFT OFFICE OF THE CTO">
      <data key="d4">16.0</data>
      <data key="d5">Microsoft Office of the CTO is involved in the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="DAREN EDGE">
      <data key="d4">12.0</data>
      <data key="d5">Daren Edge is one of the authors of the paper on Graph RAG.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="HA TRINH">
      <data key="d4">12.0</data>
      <data key="d5">Ha Trinh is one of the authors of the paper on Graph RAG.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="NEWMAN CHENG">
      <data key="d4">12.0</data>
      <data key="d5">Newman Cheng is one of the authors of the paper on Graph RAG.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="JOSHUA BRADLEY">
      <data key="d4">12.0</data>
      <data key="d5">Joshua Bradley is one of the authors of the paper on Graph RAG.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="ALEX CHAO">
      <data key="d4">12.0</data>
      <data key="d5">Alex Chao is one of the authors of the paper on Graph RAG.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="APURVA MODY">
      <data key="d4">12.0</data>
      <data key="d5">Apurva Mody is one of the authors of the paper on Graph RAG.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="STEVEN TRUITT">
      <data key="d4">12.0</data>
      <data key="d5">Steven Truitt is one of the authors of the paper on Graph RAG.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="JONATHAN LARSON">
      <data key="d4">12.0</data>
      <data key="d5">Jonathan Larson is one of the authors of the paper on Graph RAG.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="HUMAN SENSEMAKING">
      <data key="d4">14.0</data>
      <data key="d5">Graph RAG supports human sensemaking over entire text corpora.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="KNOWLEDGE GRAPH">
      <data key="d4">9.0</data>
      <data key="d5">Graph RAG uses an LLM-derived knowledge graph for global summarization.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG" target="COMMUNITY DETECTION ALGORITHMS">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG leverages community detection algorithms to partition graphs into modular communities.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG" target="MAP-REDUCE">
      <data key="d4">16.0</data>
      <data key="d5">Graph RAG uses a map-reduce approach to summarize query-focused information.
Graph RAG is compared to a graph-free approach using map-reduce for global summarization of source texts.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7,ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="TOKEN COSTS">
      <data key="d4">1.0</data>
      <data key="d5">Graph RAG shows favorable performance over source text summarization at lower token costs.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG" target="INTERMEDIATE-LEVEL COMMUNITY SUMMARIES">
      <data key="d4">8.0</data>
      <data key="d5">Intermediate-level community summaries are used in the Graph RAG approach.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG" target="LOW-LEVEL COMMUNITY SUMMARIES">
      <data key="d4">8.0</data>
      <data key="d5">Low-level community summaries are used in the Graph RAG approach.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG" target="HIERARCHICAL LEVEL">
      <data key="d4">7.0</data>
      <data key="d5">The hierarchical level of community summaries impacts the performance of the Graph RAG approach.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG" target="CONTEXT WINDOW">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG uses a context window to generate answers, with the size being consistent across conditions.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH RAG" target="ENTITY">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG uses entities to create the graph index for answering queries.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH RAG" target="RELATIONSHIP">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG uses relationships to create the graph index for answering queries.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH RAG" target="GRAPH COMMUNITIES">
      <data key="d4">8.0</data>
      <data key="d5">Graph communities at different levels (C0, C1, C2, C3) are used in the Graph RAG method to answer queries.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH RAG" target="CONDITION">
      <data key="d4">7.0</data>
      <data key="d5">Different conditions (C0, C1, C2, C3) are compared in the Graph RAG method to evaluate performance.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH RAG" target="COMPREHENSIVENESS">
      <data key="d4">24.0</data>
      <data key="d5">Graph RAG provides a comprehensive and detailed list of public figures from various entertainment sectors.
Graph RAG achieves high comprehensiveness win rates in both Podcast and News datasets.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b,ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="NAIVE RAG">
      <data key="d4">9.0</data>
      <data key="d5">Graph RAG outperforms naive RAG in terms of comprehensiveness and diversity.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="PODCAST DATASET">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG is used to evaluate the comprehensiveness and diversity of answers in the Podcast dataset.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="NEWS DATASET">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG is used to evaluate the comprehensiveness and diversity of answers in the News dataset.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="DIVERSITY">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG achieves high diversity win rates in both Podcast and News datasets.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="EMPOWERMENT">
      <data key="d4">14.0</data>
      <data key="d5">Graph RAG performs comparably with larger context sizes on empowerment.
Graph RAG's ability to provide specific examples, quotes, and citations helps in user empowerment.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="COMMUNITY SUMMARIES">
      <data key="d4">25.0</data>
      <data key="d5">Community summaries are used in Graph RAG to improve answer comprehensiveness and diversity.
Graph RAG uses community summaries for efficient summarization and question answering.
Graph RAG uses summaries of root-level communities in the entity-based graph index for global queries.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8,edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="TS">
      <data key="d4">7.0</data>
      <data key="d5">TS is compared to Graph RAG in terms of comprehensiveness and diversity, with Graph RAG showing slight improvements.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="C0">
      <data key="d4">8.0</data>
      <data key="d5">C0 represents root-level community summaries in Graph RAG, requiring dramatically fewer tokens per query.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="C1">
      <data key="d4">8.0</data>
      <data key="d5">C1 represents intermediate-level community summaries in Graph RAG, providing consistent improvement in answer comprehensiveness and diversity.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="C2">
      <data key="d4">8.0</data>
      <data key="d5">C2 represents low-level community summaries in Graph RAG, providing consistent improvement in answer comprehensiveness and diversity.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="C3">
      <data key="d4">8.0</data>
      <data key="d5">C3 represents the lowest level of community summaries in Graph RAG, providing consistent improvement in answer comprehensiveness and diversity.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="CONTEXT TOKENS">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG requires fewer context tokens compared to source text summarization, especially at the root level.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="ROOT-LEVEL COMMUNITY SUMMARIES">
      <data key="d4">9.0</data>
      <data key="d5">Graph RAG uses root-level community summaries to reduce the number of context tokens required.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="SENSEMAKING ACTIVITY">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG facilitates sensemaking activity by providing efficient iterative question answering.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="TUNING ELEMENT EXTRACTION PROMPTS">
      <data key="d4">6.0</data>
      <data key="d5">Tuning element extraction prompts can help retain more details in the Graph RAG index.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="NEO4J">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG is compared to systems like NaLLM that use Neo4J for knowledge graph creation and reasoning.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="NEBULAGRAPH">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG is compared to systems like GraphRAG that use NebulaGraph for knowledge graph creation and reasoning.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="SELF CHECK GPT">
      <data key="d4">6.0</data>
      <data key="d5">Graph RAG's evaluation could be improved by comparing fabrication rates using approaches like SelfCheckGPT.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="SENSEMAKING QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG's evaluation has examined a certain class of sensemaking questions to understand its performance.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="EMBEDDING-BASED MATCHING">
      <data key="d4">7.0</data>
      <data key="d5">Future work on Graph RAG includes embedding-based matching of user queries and graph annotations.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="ALONSO GUEVARA FERN&#193;NDEZ">
      <data key="d4">5.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="AMBER HOAK">
      <data key="d4">5.0</data>
      <data key="d5">Amber Hoak contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="ANDR&#201;S MORALES ESQUIVEL">
      <data key="d4">5.0</data>
      <data key="d5">Andr&#233;s Morales Esquivel contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="BEN CUTLER">
      <data key="d4">5.0</data>
      <data key="d5">Ben Cutler contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="BILLIE RINALDI">
      <data key="d4">5.0</data>
      <data key="d5">Billie Rinaldi contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="CHRIS SANCHEZ">
      <data key="d4">5.0</data>
      <data key="d5">Chris Sanchez contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="CHRIS TREVINO">
      <data key="d4">5.0</data>
      <data key="d5">Chris Trevino contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="CHRISTINE CAGGIANO">
      <data key="d4">5.0</data>
      <data key="d5">Christine Caggiano contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="DAVID TITTSWORTH">
      <data key="d4">5.0</data>
      <data key="d5">David Tittsworth contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="DAYENNE DE SOUZA">
      <data key="d4">5.0</data>
      <data key="d5">Dayenne de Souza contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="DOUGLAS ORBAKER">
      <data key="d4">5.0</data>
      <data key="d5">Douglas Orbaker contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="ED CLARK">
      <data key="d4">5.0</data>
      <data key="d5">Ed Clark contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="GABRIEL NIEVES-PONCE">
      <data key="d4">5.0</data>
      <data key="d5">Gabriel Nieves-Ponce contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="GAUDY BLANCO MENESES">
      <data key="d4">5.0</data>
      <data key="d5">Gaudy Blanco Meneses contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="KATE LYTVYNETS">
      <data key="d4">5.0</data>
      <data key="d5">Kate Lytvynets contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="KATY SMITH">
      <data key="d4">5.0</data>
      <data key="d5">Katy Smith contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="M&#211;NICA CARVAJAL">
      <data key="d4">5.0</data>
      <data key="d5">M&#243;nica Carvajal contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="NATHAN EVANS">
      <data key="d4">5.0</data>
      <data key="d5">Nathan Evans contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="RICHARD ORTEGA">
      <data key="d4">5.0</data>
      <data key="d5">Richard Ortega contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="RODRIGO RACANICCI">
      <data key="d4">5.0</data>
      <data key="d5">Rodrigo Racanicci contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="SARAH SMITH">
      <data key="d4">5.0</data>
      <data key="d5">Sarah Smith contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="SHANE SOLOMON">
      <data key="d4">5.0</data>
      <data key="d5">Shane Solomon contributed to the work on Graph RAG.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="GLOBAL SUMMARIZATION">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG uses global summarization techniques to summarize data across entire datasets.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="SENSEMAKING">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG supports sensemaking by helping users understand and make sense of large text corpora.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="DATA PARTITIONING">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG uses data partitioning to divide data into smaller parts for global summarization.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="CORPORA">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG is evaluated using large corpora of text.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="COMPUTE BUDGET">
      <data key="d4">7.0</data>
      <data key="d5">The decision to build a graph index in Graph RAG depends on the compute budget.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="LIFETIME QUERIES">
      <data key="d4">7.0</data>
      <data key="d5">The decision to build a graph index in Graph RAG depends on the expected number of lifetime queries.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="RICH TEXT ANNOTATIONS">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG uses rich text annotations to support its methods.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="HIERARCHICAL COMMUNITY STRUCTURE">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG uses a hierarchical community structure to organize data.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="QUERY-FOCUSED SUMMARIZATION (QFS)">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG uses query-focused summarization (QFS) to generate summaries based on user queries.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="RETRIEVAL-AUGMENTED GENERATION (RAG)">
      <data key="d4">8.0</data>
      <data key="d5">Graph RAG uses retrieval-augmented generation (RAG) to combine retrieval of information with content generation.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="MAP-REDUCE SUMMARIZATION">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG is compared to map-reduce summarization for global summarization of source texts.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="TOKEN COST">
      <data key="d4">7.0</data>
      <data key="d5">Graph RAG is evaluated based on token cost to measure its efficiency.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="OPEN-SOURCE IMPLEMENTATION">
      <data key="d4">6.0</data>
      <data key="d5">An open-source implementation of Graph RAG is forthcoming.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="PYTHON">
      <data key="d4">6.0</data>
      <data key="d5">Graph RAG will have an open-source implementation in Python.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="RAG" target="EXTERNAL KNOWLEDGE SOURCE">
      <data key="d4">14.0</data>
      <data key="d5">RAG retrieves relevant information from an external knowledge source to answer user questions.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="RAG" target="QFS">
      <data key="d4">12.0</data>
      <data key="d5">RAG is contrasted with QFS, which is more appropriate for global questions directed at an entire text corpus.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="RAG" target="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION">
      <data key="d4">7.0</data>
      <data key="d5">RAG is a method that may be inadequate for query-focused abstractive summarization tasks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="RAG" target="NA&#207;VE RAG">
      <data key="d4">8.0</data>
      <data key="d5">Na&#239;ve RAG is a basic form of RAG that converts documents to text and embeds them into a vector space.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="RAG" target="MODULAR RAG">
      <data key="d4">8.0</data>
      <data key="d5">Modular RAG is an advanced form of RAG that includes patterns for iterative and dynamic cycles of retrieval and generation.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="RAG" target="LANGCHAIN">
      <data key="d4">7.0</data>
      <data key="d5">RAG is a tool that can be used within the LangChain framework to enhance agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="RAG" target="LEWIS ET AL., 2020">
      <data key="d4">16.0</data>
      <data key="d5">Lewis et al. are the authors who contributed to the development of RAG techniques, published in 2020.
Lewis et al. are authors who have worked on Retrieval-Augmented Generation (RAG), a method relevant to ADAS.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="RAG" target="ZHANG ET AL., 2024C">
      <data key="d4">6.0</data>
      <data key="d5">Zhang et al. are the authors who contributed to the development of RAG techniques, published in 2024.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="RAG" target="ADAS">
      <data key="d4">12.0</data>
      <data key="d5">RAG (Retrieval-Augmented Generation) is a method that can be used as a building block in ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="RAG" target="AGENTINSTRUCT">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct generates data to teach AI models the skill of RAG (Retrieval-Augmented Generation).</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="RAG" target="MIRAGE">
      <data key="d4">17.0</data>
      <data key="d5">RAG is evaluated using the MIRAGE benchmark to assess its effectiveness in answering medical questions.
RAG is a technique used to enhance the performance of models on the MIRAGE datasets.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="LLM" target="TRANSFORMER ARCHITECTURE">
      <data key="d4">16.0</data>
      <data key="d5">LLMs are based on transformer architecture, which has shown substantial improvements in summarization tasks.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LLM" target="GPT">
      <data key="d4">14.0</data>
      <data key="d5">GPT is a series of LLMs used for various tasks, including summarization and sensemaking.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LLM" target="LLAMA">
      <data key="d4">14.0</data>
      <data key="d5">Llama is an LLM used for various tasks, including summarization and sensemaking.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LLM" target="GEMINI">
      <data key="d4">14.0</data>
      <data key="d5">Gemini is an LLM used for various tasks, including summarization and sensemaking.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LLM" target="NAMED ENTITIES">
      <data key="d4">9.0</data>
      <data key="d5">The LLM is used to extract named entities from text documents.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="COVARIATES">
      <data key="d4">8.0</data>
      <data key="d5">The LLM supports a secondary extraction prompt for covariates associated with extracted node instances.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="GLEANINGS">
      <data key="d4">8.0</data>
      <data key="d5">The LLM uses multiple rounds of gleanings to ensure all entities are extracted.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="BROWN ET AL., 2020">
      <data key="d4">6.0</data>
      <data key="d5">Brown et al. provided examples for in-context learning for LLMs.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="DATASET">
      <data key="d4">8.0</data>
      <data key="d5">The LLM is used to generate questions and evaluate answers based on the dataset.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="LLM" target="COMPREHENSIVENESS">
      <data key="d4">14.0</data>
      <data key="d5">LLMs are used to generate comprehensive assessments and answers based on data inputs.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="LLM" target="DIVERSITY">
      <data key="d4">14.0</data>
      <data key="d5">LLMs are used to generate diverse perspectives and insights in assessments and answers.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="LLM" target="EMPOWERMENT">
      <data key="d4">14.0</data>
      <data key="d5">LLMs are used to generate empowering assessments and answers that help readers make informed judgments.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="LLM" target="DIRECTNESS">
      <data key="d4">14.0</data>
      <data key="d5">LLMs are used to generate direct and specific assessments and answers.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="LLM" target="AGENT">
      <data key="d4">9.0</data>
      <data key="d5">An agent is powered by an LLM and can optionally use tools to perform specific tasks.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="QFS" target="QUERY-FOCUSED SUMMARIZATION">
      <data key="d4">14.0</data>
      <data key="d5">Query-focused summarization is a type of QFS used in the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="ARINDAM MITRA">
      <data key="d4">6.0</data>
      <data key="d5">Arindam Mitra is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="LUCIANO DEL CORRO">
      <data key="d4">6.0</data>
      <data key="d5">Luciano Del Corro is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="GUOQING ZHENG">
      <data key="d4">6.0</data>
      <data key="d5">Guoqing Zheng is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="SHWETI MAHAJAN">
      <data key="d4">6.0</data>
      <data key="d5">Shweti Mahajan is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="DANY ROUHANA">
      <data key="d4">6.0</data>
      <data key="d5">Dany Rouhana is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="ANDRES CODAS">
      <data key="d4">6.0</data>
      <data key="d5">Andres Codas is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="YADONG LU">
      <data key="d4">6.0</data>
      <data key="d5">Yadong Lu is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="WEI-GE CHEN">
      <data key="d4">6.0</data>
      <data key="d5">Wei-ge Chen is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="OLGA VROUSGOS">
      <data key="d4">6.0</data>
      <data key="d5">Olga Vrousgos is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="CORBY ROSSET">
      <data key="d4">6.0</data>
      <data key="d5">Corby Rosset is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="FILLIPE SILVA">
      <data key="d4">6.0</data>
      <data key="d5">Fillipe Silva is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="HAMED KHANPOUR">
      <data key="d4">6.0</data>
      <data key="d5">Hamed Khanpour is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="YASH LARA">
      <data key="d4">6.0</data>
      <data key="d5">Yash Lara is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MICROSOFT RESEARCH" target="AHMED AWADALLAH">
      <data key="d4">1.0</data>
      <data key="d5">Ahmed Awadallah is affiliated with Microsoft Research.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="HUMAN SENSEMAKING" target="SENSEMAKING">
      <data key="d4">14.0</data>
      <data key="d5">Sensemaking is a key concept in human sensemaking and the development of Graph RAG.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="COMMUNITY DETECTION" target="LEIDEN">
      <data key="d4">14.0</data>
      <data key="d5">Leiden is a community detection algorithm used in the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LEIDEN" target="COMMUNITY DETECTION ALGORITHMS">
      <data key="d4">7.0</data>
      <data key="d5">Leiden is a community detection algorithm used to partition graphs into modular communities.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="QUERY-FOCUSED SUMMARIZATION" target="COMMUNITY SUMMARIES">
      <data key="d4">7.0</data>
      <data key="d5">Community summaries are used for query-focused summarization in a graph-based index.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="SOURCE DOCUMENTS" target="TEXT CHUNKS">
      <data key="d4">19.0</data>
      <data key="d5">Text chunks are segments of source documents extracted in the Graph RAG approach.
Text chunks are extracted from source documents for processing.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="TEXT CHUNKS" target="ELEMENT INSTANCES">
      <data key="d4">12.0</data>
      <data key="d5">Element instances are specific pieces of information extracted from text chunks in the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="TEXT CHUNKS" target="ENTITY EXTRACTION">
      <data key="d4">8.0</data>
      <data key="d5">Entity extraction is performed on text chunks to build a knowledge graph.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="ELEMENT INSTANCES" target="ELEMENT SUMMARIES">
      <data key="d4">20.0</data>
      <data key="d5">Element summaries are domain-tailored summaries of element instances in the Graph RAG approach.
Element instances are summarized into element summaries for each graph element.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d,e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="ELEMENT SUMMARIES" target="HOMOGENEOUS NODES">
      <data key="d4">7.0</data>
      <data key="d5">Homogeneous nodes are used to create rich descriptive text for element summaries.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="GRAPH COMMUNITIES" target="COMMUNITY SUMMARIES">
      <data key="d4">20.0</data>
      <data key="d5">Community summaries are domain-tailored summaries of graph communities in the Graph RAG approach.
Community summaries are created for each graph community detected.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d,e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="GRAPH COMMUNITIES" target="LEIDEN ALGORITHM">
      <data key="d4">9.0</data>
      <data key="d5">The Leiden algorithm is used to detect graph communities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="GRAPH COMMUNITIES" target="FORTUNATO, 2010">
      <data key="d4">6.0</data>
      <data key="d5">Fortunato authored a survey on community detection algorithms, which are used to detect graph communities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="GRAPH COMMUNITIES" target="JIN ET AL., 2021">
      <data key="d4">6.0</data>
      <data key="d5">Jin et al. authored a survey on community detection algorithms, which are used to detect graph communities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="COMMUNITY ANSWERS">
      <data key="d4">12.0</data>
      <data key="d5">Community answers are partial responses generated from community summaries in the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="LEAF-LEVEL COMMUNITIES">
      <data key="d4">9.0</data>
      <data key="d5">Community summaries are generated from leaf-level communities by prioritizing and adding element summaries to the LLM context window.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="HIGHER-LEVEL COMMUNITIES">
      <data key="d4">9.0</data>
      <data key="d5">Community summaries are generated from higher-level communities by summarizing element summaries or using sub-community summaries.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="GLOBAL ANSWER">
      <data key="d4">9.0</data>
      <data key="d5">Community summaries are used to generate the global answer for a user query.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="LLM CONTEXT WINDOW">
      <data key="d4">9.0</data>
      <data key="d5">Community summaries are added to the LLM context window until the token limit is reached.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="INTERMEDIATE ANSWERS">
      <data key="d4">9.0</data>
      <data key="d5">Intermediate answers are generated from chunks of community summaries.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="ROOT-LEVEL SUMMARIES">
      <data key="d4">7.0</data>
      <data key="d5">Root-level summaries are a type of community summary requiring fewer tokens per query.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="INTERMEDIATE-LEVEL SUMMARIES">
      <data key="d4">7.0</data>
      <data key="d5">Intermediate-level summaries are a type of community summary providing consistent improvement in answer comprehensiveness and diversity.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="LOW-LEVEL SUMMARIES">
      <data key="d4">7.0</data>
      <data key="d5">Low-level summaries are a type of community summary providing consistent improvement in answer comprehensiveness and diversity.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="MAP-REDUCE SUMMARIZATION">
      <data key="d4">1.0</data>
      <data key="d5">Map-reduce summarization is compared to community summaries in terms of resource intensity and token count.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="COMMUNITY ANSWERS" target="GLOBAL ANSWER">
      <data key="d4">12.0</data>
      <data key="d5">The global answer is the final response generated from summarizing all community answers in the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GLOBAL ANSWER" target="USER QUERY">
      <data key="d4">9.0</data>
      <data key="d5">The global answer is generated in response to a user query.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="INDEXING TIME" target="PIPELINE STAGE">
      <data key="d4">12.0</data>
      <data key="d5">Indexing time is a pipeline stage in the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="QUERY TIME" target="PIPELINE STAGE">
      <data key="d4">12.0</data>
      <data key="d5">Query time is a pipeline stage in the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="SENSEMAKING" target="EVALUATION">
      <data key="d4">7.0</data>
      <data key="d5">Sensemaking activities are evaluated using specific metrics.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GPT" target="LLMS">
      <data key="d4">8.0</data>
      <data key="d5">GPT is a series of LLMs capable of in-context learning for summarization tasks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GPT" target="ACHIAM ET AL., 2023">
      <data key="d4">8.0</data>
      <data key="d5">Achiam et al. have contributed to the development of the GPT series.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GPT" target="BROWN ET AL., 2020">
      <data key="d4">8.0</data>
      <data key="d5">Brown et al. have contributed to the development of the GPT series.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GPT" target="FOUNDATION MODELS (FMS)">
      <data key="d4">7.0</data>
      <data key="d5">GPT is an example of a Foundation Model used for agentic tasks.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="GPT" target="OPENAI">
      <data key="d4">15.0</data>
      <data key="d5">OpenAI is the organization that developed the GPT Foundation Model.GPT is a Foundation Model developed by OpenAI.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="LLAMA" target="LLMS">
      <data key="d4">8.0</data>
      <data key="d5">Llama is a series of LLMs capable of in-context learning for summarization tasks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="LLAMA" target="TOUVRON ET AL., 2023">
      <data key="d4">8.0</data>
      <data key="d5">Touvron et al. have contributed to the development of the Llama series.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GEMINI" target="LLMS">
      <data key="d4">8.0</data>
      <data key="d5">Gemini is a series of LLMs capable of in-context learning for summarization tasks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GEMINI" target="ANIL ET AL., 2023">
      <data key="d4">8.0</data>
      <data key="d5">Anil et al. have contributed to the development of the Gemini series.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GEMINI" target="J. B. ALAYRAC">
      <data key="d4">6.0</data>
      <data key="d5">J. B. Alayrac is one of the authors of the Gemini model report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GEMINI" target="R. ANIL">
      <data key="d4">6.0</data>
      <data key="d5">R. Anil is one of the authors of the Gemini model report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GEMINI" target="S. BORGEAUD">
      <data key="d4">6.0</data>
      <data key="d5">S. Borgeaud is one of the authors of the Gemini model report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GEMINI" target="Y. WU">
      <data key="d4">6.0</data>
      <data key="d5">Y. Wu is one of the authors of the Gemini model report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GEMINI" target="R. SORICUT">
      <data key="d4">6.0</data>
      <data key="d5">R. Soricut is one of the authors of the Gemini model report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GEMINI" target="J. SCHALKWYK">
      <data key="d4">6.0</data>
      <data key="d5">J. Schalkwyk is one of the authors of the Gemini model report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GEMINI" target="A. M. DAI">
      <data key="d4">6.0</data>
      <data key="d5">A. M. Dai is one of the authors of the Gemini model report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GEMINI" target="A. HAUTH">
      <data key="d4">6.0</data>
      <data key="d5">A. Hauth is one of the authors of the Gemini model report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="SUMMARIZATION TASKS" target="LLMS">
      <data key="d4">9.0</data>
      <data key="d5">Modern LLMs trivialize summarization tasks by using in-context learning.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="SUMMARIZATION TASKS" target="GOODWIN ET AL., 2020">
      <data key="d4">7.0</data>
      <data key="d5">Goodwin et al. have contributed to the state-of-the-art in summarization tasks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="SUMMARIZATION TASKS" target="LASKAR ET AL., 2022">
      <data key="d4">7.0</data>
      <data key="d5">Laskar et al. have contributed to the state-of-the-art in summarization tasks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="SUMMARIZATION TASKS" target="LIU AND LAPATA, 2019">
      <data key="d4">7.0</data>
      <data key="d5">Liu and Lapata have contributed to the state-of-the-art in summarization tasks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="LLMS" target="KURATOV ET AL., 2024">
      <data key="d4">7.0</data>
      <data key="d5">Kuratov et al. have studied the limitations of LLM context windows.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="LLMS" target="LIU ET AL., 2023">
      <data key="d4">7.0</data>
      <data key="d5">Liu et al. have studied the limitations of LLM context windows.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="LLMS" target="SYNTHETIC DATA">
      <data key="d4">8.0</data>
      <data key="d5">Synthetic data is used to accelerate the development of Large Language Models (LLMs).</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION" target="NA&#207;VE RAG">
      <data key="d4">7.0</data>
      <data key="d5">Na&#239;ve RAG is likely inadequate for query-focused abstractive summarization tasks.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION" target="GLOBAL SUMMARIZATION">
      <data key="d4">6.0</data>
      <data key="d5">Global summarization is an alternative to query-focused abstractive summarization.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="COMMUNITY DETECTION ALGORITHMS" target="LOUVAIN">
      <data key="d4">7.0</data>
      <data key="d5">Louvain is a community detection algorithm used to partition graphs into modular communities.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="MAP-REDUCE" target="TEXT SUMMARIZATION (TS)">
      <data key="d4">7.0</data>
      <data key="d5">The map-reduce method is used in text summarization (TS) to process source texts.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="HOTPOTQA" target="RAG SYSTEMS">
      <data key="d4">6.0</data>
      <data key="d5">HotPotQA is a benchmark dataset used to evaluate RAG systems for open-domain question answering.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="HOTPOTQA" target="LANGUAGE AGENT TREE SEARCH (LATS)">
      <data key="d4">12.0</data>
      <data key="d5">HotPotQA is a benchmark used to empirically evaluate the performance of LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="HOTPOTQA" target="LATS">
      <data key="d4">46.0</data>
      <data key="d5">LATS doubles the performance of ReAct on HotPotQA when used with GPT-3.5.
LATS performs well on HotPotQA, demonstrating its effectiveness in decision-making and reasoning tasks.
LATS is evaluated using the HotPotQA benchmark for cost and performance.
LATS is evaluated using the HotPotQA benchmark.
LATS is evaluated on the HotPotQA dataset to test its performance in question-answering tasks that require reasoning over multiple documents.
LATS is evaluated using the HotpotQA benchmark.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b,fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="HOTPOTQA" target="YANG ET AL., 2018">
      <data key="d4">6.0</data>
      <data key="d5">Yang et al. are the authors of the HotPotQA benchmark, published in 2018.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="HOTPOTQA" target="REFLEXION">
      <data key="d4">7.0</data>
      <data key="d5">Reflexion is evaluated using the HotPotQA benchmark, with performance scores reported.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="HOTPOTQA" target="TOT">
      <data key="d4">7.0</data>
      <data key="d5">ToT is evaluated using the HotPotQA benchmark for cost and performance.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="HOTPOTQA" target="RAP">
      <data key="d4">7.0</data>
      <data key="d5">RAP is evaluated using the HotPotQA benchmark for cost and performance.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="HOTPOTQA" target="REACT">
      <data key="d4">7.0</data>
      <data key="d5">ReAct is evaluated on the HotPotQA dataset to test its performance in question-answering tasks that require reasoning over multiple documents.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="HOTPOTQA" target="CROWDWORKERS">
      <data key="d4">7.0</data>
      <data key="d5">Crowdworkers are individuals who contributed to the creation of the HotPotQA dataset by crafting diverse, multi-hop, and explainable question-answer pairs.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="HOTPOTQA" target="SUPPORTING FACTS">
      <data key="d4">7.0</data>
      <data key="d5">Supporting facts are pieces of information provided in the HotPotQA dataset that justify the answers to the questions.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="HOTPOTQA" target="WIKIPEDIA PARAGRAPHS">
      <data key="d4">7.0</data>
      <data key="d5">Wikipedia paragraphs are the text segments used in the HotPotQA dataset to provide the necessary information for answering the questions.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="HOTPOTQA" target="EM (EXACT MATCH)">
      <data key="d4">1.0</data>
      <data key="d5">EM (Exact Match) is a performance metric used to evaluate the accuracy of answers in the HotPotQA dataset.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="HOTPOTQA" target="PROMPT">
      <data key="d4">8.0</data>
      <data key="d5">HotPotQA tasks are guided by specific prompts that include Thought, Action, and Observation steps.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ENTITY EXTRACTION" target="FEW-SHOT EXAMPLES">
      <data key="d4">7.0</data>
      <data key="d5">Few-shot examples are used to tailor the entity extraction prompt to the domain of the document corpus.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="ENTITY EXTRACTION" target="GLEANINGS">
      <data key="d4">1.0</data>
      <data key="d5">Gleanings are used to improve the performance of entity extraction.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="ACTIVITY-CENTERED SENSE-MAKING QUESTIONS" target="COMPREHENSIVENESS">
      <data key="d4">6.0</data>
      <data key="d5">Comprehensiveness is a target quality for evaluating activity-centered sense-making questions.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="ACTIVITY-CENTERED SENSE-MAKING QUESTIONS" target="DIVERSITY">
      <data key="d4">6.0</data>
      <data key="d5">Diversity is a target quality for evaluating activity-centered sense-making questions.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="ACTIVITY-CENTERED SENSE-MAKING QUESTIONS" target="EMPOWERMENT">
      <data key="d4">6.0</data>
      <data key="d5">Empowerment is a target quality for evaluating activity-centered sense-making questions.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="ACTIVITY-CENTERED SENSE-MAKING QUESTIONS" target="PODCAST TRANSCRIPTS">
      <data key="d4">7.0</data>
      <data key="d5">Podcast transcripts are used to generate activity-centered sense-making questions.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="ACTIVITY-CENTERED SENSE-MAKING QUESTIONS" target="NEWS ARTICLES">
      <data key="d4">7.0</data>
      <data key="d5">News articles are used to generate activity-centered sense-making questions.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="LLM EVALUATOR">
      <data key="d4">8.0</data>
      <data key="d5">The LLM Evaluator assesses answers based on the comprehensiveness metric.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="WIN RATE">
      <data key="d4">7.0</data>
      <data key="d5">Win rate is used to evaluate the performance of different summarization approaches in terms of comprehensiveness.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="DIVERSITY" target="LLM EVALUATOR">
      <data key="d4">8.0</data>
      <data key="d5">The LLM Evaluator assesses answers based on the diversity metric.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="DIVERSITY" target="WIN RATE">
      <data key="d4">7.0</data>
      <data key="d5">Win rate is used to evaluate the performance of different summarization approaches in terms of diversity.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="EMPOWERMENT" target="LLM EVALUATOR">
      <data key="d4">8.0</data>
      <data key="d5">The LLM Evaluator assesses answers based on the empowerment metric.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="EMPOWERMENT" target="WIN RATE">
      <data key="d4">7.0</data>
      <data key="d5">Win rate is used to evaluate the performance of different summarization approaches in terms of empowerment.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="PODCASTS">
      <data key="d4">7.0</data>
      <data key="d5">Podcasts are a source of podcast transcripts used in the evaluation of the Graph RAG approach.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="TECH JOURNALIST">
      <data key="d4">6.0</data>
      <data key="d5">Podcast transcripts are used by tech journalists to gain insights and trends in the tech industry.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="KEVIN SCOTT">
      <data key="d4">7.0</data>
      <data key="d5">Kevin Scott is a participant in the podcast transcripts dataset.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="TECHNOLOGY LEADERS">
      <data key="d4">7.0</data>
      <data key="d5">Technology leaders are participants in the podcast transcripts dataset.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="MEDIA COVERAGE">
      <data key="d4">14.0</data>
      <data key="d5">Podcast transcripts are a form of media coverage that provide written records of spoken content.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="NEWS ARTICLES" target="NEW YORK TIMES">
      <data key="d4">7.0</data>
      <data key="d5">The New York Times is a source of news articles used in the evaluation of the Graph RAG approach.</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="NEWS ARTICLES" target="EDUCATOR">
      <data key="d4">6.0</data>
      <data key="d5">News articles are used by educators to incorporate current affairs into curricula.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="NEWS ARTICLES" target="MULTIHOP-RAG">
      <data key="d4">7.0</data>
      <data key="d5">MultiHop-RAG is a benchmark dataset used for evaluating news articles.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="NEWS ARTICLES" target="MEDIA COVERAGE">
      <data key="d4">16.0</data>
      <data key="d5">News articles are a form of media coverage that report on public figures and current events.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="BROWN ET AL., 2020" target="LANGUAGE MODELS (LMS)">
      <data key="d4">10.0</data>
      <data key="d5">Brown et al. are the authors of a significant paper on language models, published in 2020.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="TOUVRON ET AL., 2023" target="LANGUAGE MODELS (LMS)">
      <data key="d4">10.0</data>
      <data key="d5">Touvron et al. are the authors of a significant paper on language models, published in 2023.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="KURATOV ET AL., 2024" target="CONTEXT WINDOW SIZE">
      <data key="d4">6.0</data>
      <data key="d5">Kuratov et al. studied the potential for information to be "lost in the middle" of longer contexts.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="LIU ET AL., 2023" target="CONTEXT WINDOW SIZE">
      <data key="d4">6.0</data>
      <data key="d5">Liu et al. studied the potential for information to be "lost in the middle" of longer contexts.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="LIU ET AL., 2023" target="SEARCH APPROACHES">
      <data key="d4">12.0</data>
      <data key="d5">Liu et al. are the authors mentioned in relation to previous search approaches using LMs as world models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LIU ET AL., 2023" target="SEARCH SPACE">
      <data key="d4">6.0</data>
      <data key="d5">Liu et al. explored search spaces using feed-forward networks within ADAS.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="LIU ET AL., 2023" target="DYLAN">
      <data key="d4">12.0</data>
      <data key="d5">Liu et al. are the authors of the DyLAN algorithm.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="NA&#207;VE RAG" target="DIRECTNESS">
      <data key="d4">16.0</data>
      <data key="d5">Na&#239;ve RAG provides a direct and specific list of public figures frequently mentioned in media.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="NA&#207;VE RAG" target="GAO ET AL., 2023">
      <data key="d4">7.0</data>
      <data key="d5">Gao et al. are researchers who have contributed to the development of Na&#239;ve RAG.</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GLEANINGS" target="LOGIT BIAS">
      <data key="d4">7.0</data>
      <data key="d5">Logit bias is used during the gleanings process to ensure all entities are detected.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="GLEANINGS" target="NOISE">
      <data key="d4">6.0</data>
      <data key="d5">The gleanings process aims to minimize noise while ensuring all entities are detected.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="NAMED ENTITIES" target="DEFAULT PROMPT">
      <data key="d4">8.0</data>
      <data key="d5">The default prompt is used to extract named entities from text documents.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="COVARIATES" target="SECONDARY EXTRACTION PROMPT">
      <data key="d4">8.0</data>
      <data key="d5">The secondary extraction prompt is used to extract covariates associated with detected entities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="COVARIATES" target="LEAF-LEVEL COMMUNITIES">
      <data key="d4">8.0</data>
      <data key="d5">Covariates are described and prioritized in leaf-level communities.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="LEIDEN ALGORITHM" target="TRAAG ET AL., 2019">
      <data key="d4">7.0</data>
      <data key="d5">Traag et al. are the authors of the Leiden algorithm.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LEIDEN ALGORITHM" target="HIERARCHICAL COMMUNITY STRUCTURE">
      <data key="d4">8.0</data>
      <data key="d5">The Leiden algorithm is used to detect hierarchical community structures in large-scale graphs.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="OPENORD">
      <data key="d4">7.0</data>
      <data key="d5">OpenORD is used for node layout in visualizing the MultiHop-RAG dataset.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="FORCE ATLAS 2">
      <data key="d4">7.0</data>
      <data key="d5">Force Atlas 2 is used for node layout in visualizing the MultiHop-RAG dataset.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="TANG AND YANG, 2024">
      <data key="d4">12.0</data>
      <data key="d5">Tang and Yang indexed the MultiHop-RAG dataset.
Tang and Yang are the authors of the MultiHop-RAG benchmark dataset.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba,e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="TANG, Y.">
      <data key="d4">8.0</data>
      <data key="d5">Tang, Y. is one of the authors of the paper titled "MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="YANG, Y.">
      <data key="d4">8.0</data>
      <data key="d5">Yang, Y. is one of the authors of the paper titled "MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="OPENORD" target="MARTIN ET AL., 2011">
      <data key="d4">6.0</data>
      <data key="d5">Martin et al. are the authors of the OpenORD tool.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="FORCE ATLAS 2" target="JACOMY ET AL., 2014">
      <data key="d4">1.0</data>
      <data key="d5">Jacomy et al. are the authors of the Force Atlas 2 tool.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="HIERARCHICAL COMMUNITY STRUCTURE" target="ROOT COMMUNITIES">
      <data key="d4">7.0</data>
      <data key="d5">Root communities represent the highest level of modularity in a hierarchical community structure.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="HIERARCHICAL COMMUNITY STRUCTURE" target="SUB-COMMUNITIES">
      <data key="d4">7.0</data>
      <data key="d5">Sub-communities reveal internal structure within root-level communities in a hierarchical community structure.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="HIERARCHICAL COMMUNITY STRUCTURE" target="LEAF-LEVEL COMMUNITIES">
      <data key="d4">7.0</data>
      <data key="d5">Leaf-level communities are the smallest units in a hierarchical community structure.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LEAF-LEVEL COMMUNITIES" target="NODE DEGREE">
      <data key="d4">1.0</data>
      <data key="d5">Node degree is used to prioritize elements in leaf-level communities during the summarization process.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LEAF-LEVEL COMMUNITIES" target="ROOT-LEVEL COMMUNITIES">
      <data key="d4">8.0</data>
      <data key="d5">Leaf-level communities are the lowest hierarchical level within root-level communities.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="LEAF-LEVEL COMMUNITIES" target="NODES">
      <data key="d4">8.0</data>
      <data key="d5">Nodes are described and prioritized in leaf-level communities.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="LEAF-LEVEL COMMUNITIES" target="EDGES">
      <data key="d4">8.0</data>
      <data key="d5">Edges are described and prioritized in leaf-level communities.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="ROOT-LEVEL COMMUNITIES" target="HIGHER-LEVEL COMMUNITIES">
      <data key="d4">8.0</data>
      <data key="d5">Higher-level communities are above leaf-level communities in the hierarchy within root-level communities.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="USER QUERY" target="TECH JOURNALIST">
      <data key="d4">7.0</data>
      <data key="d5">A tech journalist poses user queries related to tech policy and regulation.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="USER QUERY" target="EDUCATOR">
      <data key="d4">7.0</data>
      <data key="d5">An educator poses user queries related to health and wellness.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="MT-BENCH" target="RAG SYSTEMS">
      <data key="d4">6.0</data>
      <data key="d5">MT-Bench is a benchmark dataset used to evaluate RAG systems for open-domain question answering.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="MT-BENCH" target="ZHENG ET AL., 2024">
      <data key="d4">1.0</data>
      <data key="d5">Zheng et al. are the authors of the MT-Bench benchmark dataset.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="MT-BENCH" target="ORCA-3">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3 scored 8.20 on the MT-Bench benchmark, a 9% improvement over Orca-2.5.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="MT-BENCH" target="OPEN-ENDED GENERATION">
      <data key="d4">7.0</data>
      <data key="d5">MT-Bench is a benchmark used to evaluate open-ended generation tasks by scoring each turn's response using GPT-4.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="RAG SYSTEMS" target="KOESTEN ET AL., 2021">
      <data key="d4">5.0</data>
      <data key="d5">Koesten et al. discussed the process of data sensemaking, which is relevant to the evaluation of RAG systems.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="RAG SYSTEMS" target="XU AND LAPATA, 2021">
      <data key="d4">1.0</data>
      <data key="d5">Xu and Lapata developed methods for extracting latent summarization queries, which are relevant to the evaluation of RAG systems.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="NODES" target="LATS">
      <data key="d4">14.0</data>
      <data key="d5">LATS uses nodes to store and retrieve external feedback in the search process.
Nodes are expanded during the exploration process in LATS.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="NODES" target="TRAJECTORIES">
      <data key="d4">7.0</data>
      <data key="d5">Nodes and trajectories are components of the search process in algorithms like LATS.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="NODES" target="LANGUAGE AGENT TREE SEARCH (LATS)">
      <data key="d4">7.0</data>
      <data key="d5">Nodes are components in the LATS algorithm that are stored explicitly in memory and expanded during the search process.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOKEN LIMIT" target="LLM CONTEXT WINDOW">
      <data key="d4">9.0</data>
      <data key="d5">The token limit determines how many tokens can be included in the LLM context window.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="INTERMEDIATE ANSWERS" target="HELPFULNESS SCORE">
      <data key="d4">9.0</data>
      <data key="d5">Intermediate answers are scored for helpfulness using the helpfulness score metric.</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="ZHENG ET AL., 2024" target="LLM EVALUATOR">
      <data key="d4">6.0</data>
      <data key="d5">Zheng et al. have demonstrated the effectiveness of LLMs in head-to-head comparisons.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="DATASET" target="ACTIVITY-CENTERED APPROACH">
      <data key="d4">7.0</data>
      <data key="d5">The activity-centered approach is used to automate the generation of questions based on the dataset.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="DATASET" target="ORCA-BENCH">
      <data key="d4">8.0</data>
      <data key="d5">Orca-Bench is a dataset used for training and evaluating models.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="USER" target="TASK">
      <data key="d4">7.0</data>
      <data key="d5">Users perform specific tasks involving interaction with the dataset or system.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="USER" target="SEARCH FOOD ITEMS">
      <data key="d4">8.0</data>
      <data key="d5">The user can search for food items using the "Search Food Items" API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="GET FOOD ITEM DETAILS">
      <data key="d4">8.0</data>
      <data key="d5">The user can retrieve detailed information about a specific food item using the "Get Food Item Details" API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="CREATE MEAL PLAN">
      <data key="d4">9.0</data>
      <data key="d5">The user can create a meal plan based on their dietary preferences and goals using the "Create Meal Plan" API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="UPDATE FOOD ITEM">
      <data key="d4">8.0</data>
      <data key="d5">The user can update the details of an existing food item using the "Update Food Item" API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="TRACK USER MEAL">
      <data key="d4">8.0</data>
      <data key="d5">The user can track their daily meals using the "Track User Meal" API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="GET DIETARY RECOMMENDATIONS">
      <data key="d4">8.0</data>
      <data key="d5">The user can get dietary recommendations based on their preferences and goals using the "Get Dietary Recommendations" API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="ADD NEW FOOD ITEM">
      <data key="d4">8.0</data>
      <data key="d5">The user can add a new food item to the database using the "Add New Food Item" API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="DELETE FOOD ITEM">
      <data key="d4">8.0</data>
      <data key="d5">The user can delete a food item from the database using the "Delete Food Item" API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="GET USER NUTRITIONAL STATS">
      <data key="d4">8.0</data>
      <data key="d5">The user can get their nutritional statistics using the "Get User Nutritional Stats" API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="ASSISTANT">
      <data key="d4">1.0</data>
      <data key="d5">The user interacts with the assistant to achieve their desired outcomes, such as creating a meal plan and tracking meals.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="QUINOA SALAD">
      <data key="d4">8.0</data>
      <data key="d5">The user wants to add the Quinoa Salad recipe to the database.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="CHANA MASALA">
      <data key="d4">8.0</data>
      <data key="d5">The user wants to update the calorie count for Chana Masala.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="USER" target="BUTTER CHICKEN">
      <data key="d4">8.0</data>
      <data key="d5">The user wants to remove Butter Chicken from the database.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="TASK" target="QUESTION">
      <data key="d4">7.0</data>
      <data key="d5">Tasks often involve generating or answering questions related to the dataset.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="TASK" target="ANSWER">
      <data key="d4">7.0</data>
      <data key="d5">An answer is the result or solution provided by an agent after performing a task.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="TASK" target="META AGENT SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search programs new agents to solve specific tasks.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="QUESTION" target="N">
      <data key="d4">6.0</data>
      <data key="d5">The variable N represents the number of questions generated per (user, task) combination.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="QUESTION" target="EVALUATION">
      <data key="d4">7.0</data>
      <data key="d5">Evaluation involves assessing the questions generated to understand the dataset.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="QUESTION" target="ARTHUR'S MAGAZINE">
      <data key="d4">6.0</data>
      <data key="d5">Arthur's Magazine is part of a question in a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="QUESTION" target="FIRST FOR WOMEN">
      <data key="d4">6.0</data>
      <data key="d5">First for Women is part of a question in a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="QUESTION" target="STUDENT RESPONSE">
      <data key="d4">7.0</data>
      <data key="d5">The student response is provided in answer to a question.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="QUESTION" target="OPTIONS">
      <data key="d4">8.0</data>
      <data key="d5">The question is accompanied by a list of options for the student to choose from.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="TEXT SUMMARIZATION (TS)" target="CONTEXT WINDOW">
      <data key="d4">8.0</data>
      <data key="d5">Text Summarization (TS) uses a context window to generate answers, with the size being consistent across conditions.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="SEMANTIC SEARCH (SS)" target="CONTEXT WINDOW">
      <data key="d4">8.0</data>
      <data key="d5">Semantic Search (SS) uses a context window to generate answers, with the size being consistent across conditions.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="CONTEXT WINDOW" target="PODCAST DATASET">
      <data key="d4">6.0</data>
      <data key="d5">The Podcast dataset uses a context window size of 600 tokens and 1 gleaning.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="CONTEXT WINDOW" target="NEWS DATASET">
      <data key="d4">6.0</data>
      <data key="d5">The News dataset uses a context window size of 600 tokens and 0 gleanings.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="CONTEXT WINDOW" target="ANSWER GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Answer generation is influenced by the size of the context window used.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="RELATIONSHIP" target="ALEX">
      <data key="d4">8.0</data>
      <data key="d5">Alex is already in a relationship, which complicates Elliot's confession.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="PODCAST DATASET" target="GLEANING">
      <data key="d4">6.0</data>
      <data key="d5">The Podcast dataset uses 1 gleaning in its context window size.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="PODCAST DATASET" target="NAIVE RAG">
      <data key="d4">7.0</data>
      <data key="d5">Naive RAG is used as a baseline to evaluate the comprehensiveness and diversity of answers in the Podcast dataset.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="NEWS DATASET" target="GLEANING">
      <data key="d4">6.0</data>
      <data key="d5">The News dataset uses 0 gleanings in its context window size.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="NEWS DATASET" target="NAIVE RAG">
      <data key="d4">7.0</data>
      <data key="d5">Naive RAG is used as a baseline to evaluate the comprehensiveness and diversity of answers in the News dataset.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="DIRECTNESS" target="LLM EVALUATOR">
      <data key="d4">8.0</data>
      <data key="d5">The LLM Evaluator assesses answers based on the directness metric.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="DIRECTNESS" target="NAIVE RAG">
      <data key="d4">7.0</data>
      <data key="d5">Naive RAG produces the most direct responses across all comparisons.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="LLM EVALUATOR" target="WANG ET AL., 2023A">
      <data key="d4">6.0</data>
      <data key="d5">Wang et al. have shown that LLMs can achieve state-of-the-art results in evaluation.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="ENTERTAINMENT INDUSTRY">
      <data key="d4">19.0</data>
      <data key="d5">Public figures are repeatedly mentioned in entertainment articles, reflecting their impact on the industry.
Public figures contribute significantly to the entertainment industry through their work and influence.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582,c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="MEDIA COVERAGE">
      <data key="d4">18.0</data>
      <data key="d5">Public figures are frequently covered in media due to their high-profile status and public interest.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="CULTURAL NARRATIVES">
      <data key="d4">16.0</data>
      <data key="d5">Public figures shape cultural narratives through their influence in various entertainment sectors.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="CONTROVERSIES">
      <data key="d4">16.0</data>
      <data key="d5">Public figures often become central figures in controversies, attracting widespread attention.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="PROMINENT PUBLIC FIGURES">
      <data key="d4">1.0</data>
      <data key="d5">Prominent public figures are repeatedly mentioned in entertainment articles, reflecting their influence in the industry.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="ENTERTAINMENT INDUSTRY" target="MEDIA COVERAGE">
      <data key="d4">2.0</data>
      <data key="d5">The entertainment industry is frequently covered in media due to its cultural and economic impact.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="EVALUATION" target="RAGAS">
      <data key="d4">7.0</data>
      <data key="d5">RAGAS is used to automatically evaluate the performance of RAG systems.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="EVALUATION" target="HEAD-TO-HEAD COMPARISON">
      <data key="d4">7.0</data>
      <data key="d5">Head-to-head comparison is used to evaluate competing outputs.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="EVALUATION" target="LATS">
      <data key="d4">7.0</data>
      <data key="d5">Evaluation is the third operation in the LATS algorithm.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="EVALUATION" target="META AGENT SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search involves the evaluation of discovered agents on validation and test sets.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="ANSWER GENERATION" target="PROMPT">
      <data key="d4">7.0</data>
      <data key="d5">Prompts are used to guide the LLM in generating answers.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="PROMPT" target="THOUGHT">
      <data key="d4">7.0</data>
      <data key="d5">The prompt includes Thought steps for reasoning about the current situation.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="PROMPT" target="ACTION">
      <data key="d4">7.0</data>
      <data key="d5">The prompt includes Action steps for performing operations like searching for an entity or finishing with an answer.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="PROMPT" target="OBSERVATION">
      <data key="d4">7.0</data>
      <data key="d5">The prompt includes Observation steps that provide feedback based on the Action performed.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="PROMPT" target="META AGENT SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses prompts to guide the programming of new agents.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="PROMPT" target="META AGENT">
      <data key="d4">9.0</data>
      <data key="d5">The meta agent uses the prompt to guide its thought process, design, and implementation of the next function or agent architecture.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="PROMPT" target="RESPONSE">
      <data key="d4">8.0</data>
      <data key="d5">The response is generated by the model in reaction to the prompt during training.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="RAGAS" target="ES ET AL., 2023">
      <data key="d4">6.0</data>
      <data key="d5">Es et al. have contributed to the development of RAGAS for evaluating RAG systems.</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="RAGAS" target="ES, S.">
      <data key="d4">9.0</data>
      <data key="d5">Es, S. is one of the authors of the paper on automated evaluation of retrieval augmented generation.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="RAGAS" target="JAMES, J.">
      <data key="d4">9.0</data>
      <data key="d5">James, J. is one of the authors of the paper on automated evaluation of retrieval augmented generation.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="RAGAS" target="ESPINOSA-ANKE, L.">
      <data key="d4">9.0</data>
      <data key="d5">Espinosa-Anke, L. is one of the authors of the paper on automated evaluation of retrieval augmented generation.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="RAGAS" target="SCHOCKAERT, S.">
      <data key="d4">9.0</data>
      <data key="d5">Schockaert, S. is one of the authors of the paper on automated evaluation of retrieval augmented generation.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="WANG ET AL., 2023A" target="EMBODIED AGENTS">
      <data key="d4">6.0</data>
      <data key="d5">Wang et al. are the authors who contributed to the development of new skills for embodied agents, published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="TAYLOR SWIFT" target="MEDIA COVERAGE">
      <data key="d4">18.0</data>
      <data key="d5">Taylor Swift is frequently mentioned in media coverage due to her professional achievements and personal life.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="TRAVIS KELCE" target="MEDIA COVERAGE">
      <data key="d4">18.0</data>
      <data key="d5">Travis Kelce is frequently mentioned in media coverage due to his sports achievements and personal life.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="BRITNEY SPEARS" target="MEDIA COVERAGE">
      <data key="d4">18.0</data>
      <data key="d5">Britney Spears is frequently mentioned in media coverage due to her professional achievements and personal life.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="JUSTIN TIMBERLAKE" target="MEDIA COVERAGE">
      <data key="d4">18.0</data>
      <data key="d5">Justin Timberlake is frequently mentioned in media coverage due to his professional achievements and personal life.</data>
      <data key="d6">c8e8019de153e439d6a79dcf209b943b</data>
    </edge>
    <edge source="CONTEXT WINDOW SIZE" target="GPT-4-TURBO">
      <data key="d4">7.0</data>
      <data key="d5">The context window size is tested on GPT-4-Turbo to explore its effects on comprehensiveness, diversity, and empowerment.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="CONTEXT WINDOW SIZE" target="SS">
      <data key="d4">7.0</data>
      <data key="d5">SS is used as a baseline condition to determine the optimum context window size for query-time LLM use.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="MAP-REDUCE SUMMARIZATION" target="CONTEXT TOKENS">
      <data key="d4">1.0</data>
      <data key="d5">Map-reduce summarization is compared to community summaries in terms of context tokens, with the former requiring more tokens.</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GAO ET AL., 2023" target="LANGUAGE MODELS (LMS)">
      <data key="d4">10.0</data>
      <data key="d5">Gao et al. are the authors of a significant paper on language models, published in 2023.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="GAO ET AL., 2023" target="GSM-HARD">
      <data key="d4">15.0</data>
      <data key="d5">Gao et al. discussed the GSM-Hard math task benchmark in 2023.
Gao et al. are the authors of the GSM-Hard dataset used to evaluate the transferability of discovered agents.
Gao et al. are the authors of the GSM-Hard dataset, published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="GAO ET AL., 2023" target="GSM-HARD (GAO ET AL., 2023)">
      <data key="d4">6.0</data>
      <data key="d5">Gao et al. are the authors of the GSM-Hard benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="WANG ET AL., 2024" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">1.0</data>
      <data key="d5">Wang et al. are cited in the paper for contributions to the research on agentic systems and their applications.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="WANG ET AL., 2024" target="META AGENT SEARCH">
      <data key="d4">6.0</data>
      <data key="d5">Wang et al. are the authors of the study discussing the effectiveness of Meta Agent Search.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="CAIRE-COVID" target="SU, D.">
      <data key="d4">16.0</data>
      <data key="d5">Su, D. is one of the authors who contributed to the development of CAIRE-COVID.
Su, D. is one of the authors of the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="CAIRE-COVID" target="XU, Y.">
      <data key="d4">16.0</data>
      <data key="d5">Xu, Y. is one of the authors who contributed to the development of CAIRE-COVID.
Xu, Y. is one of the authors of the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="CAIRE-COVID" target="YU, T.">
      <data key="d4">16.0</data>
      <data key="d5">Yu, T. is one of the authors who contributed to the development of CAIRE-COVID.
Yu, T. is one of the authors of the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="CAIRE-COVID" target="SIDDIQUE, F. B.">
      <data key="d4">16.0</data>
      <data key="d5">Siddique, F. B. is one of the authors who contributed to the development of CAIRE-COVID.
Siddique, F. B. is one of the authors of the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="CAIRE-COVID" target="BAREZI, E. J.">
      <data key="d4">16.0</data>
      <data key="d5">Barezi, E. J. is one of the authors who contributed to the development of CAIRE-COVID.
Barezi, E. J. is one of the authors of the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="CAIRE-COVID" target="FUNG, P.">
      <data key="d4">9.0</data>
      <data key="d5">Fung, P. is one of the authors who contributed to the development of CAIRE-COVID.
Fung, P. is one of the authors of the paper titled "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </edge>
    <edge source="YAO ET AL., 2023" target="CHAIN-OF-THOUGHT">
      <data key="d4">6.0</data>
      <data key="d5">Yao et al. are cited in the paper for contributions to the research on chain-of-thought planning and reasoning.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="YAO ET AL., 2023" target="CHAIN-OF-THOUGHT-BASED PLANNING AND REASONING METHODS">
      <data key="d4">6.0</data>
      <data key="d5">Yao et al. are the authors who contributed to the development of chain-of-thought-based planning and reasoning methods, published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="WANG ET AL., 2023B" target="SELF-CONSISTENCY WITH CHAIN-OF-THOUGHT (COT-SC)">
      <data key="d4">12.0</data>
      <data key="d5">Wang et al. are the researchers who developed the Self-Consistency with Chain-of-Thought (COT-SC) method in 2023.
Wang et al. are the authors of the Self-Consistency with Chain-of-Thought (COT-SC) algorithm.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="WANG ET AL., 2023B" target="COT-SC">
      <data key="d4">19.0</data>
      <data key="d5">Wang et al. are the authors of the COT-SC algorithm.
Wang et al. are the authors of the COT-SC algorithm, published in 2023.
Wang et al. are the authors of research on COT-SC, published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="WANG ET AL., 2023B" target="COT-SC (WANG ET AL., 2023B)">
      <data key="d4">6.0</data>
      <data key="d5">Wang et al. are the authors of the COT-SC algorithm.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="LANGCHAIN" target="SEARCH SPACE">
      <data key="d4">7.0</data>
      <data key="d5">LangChain is an open-source agent framework that can be used within the code search space of ADAS.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="LANGCHAIN" target="SEARCH ENGINE TOOLS">
      <data key="d4">7.0</data>
      <data key="d5">Search engine tools are components that can be used within the LangChain framework to enhance agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="LANGCHAIN" target="ADAS">
      <data key="d4">12.0</data>
      <data key="d5">LangChain is an existing agent framework that can be used as a building block in ADAS to support multi-modal capabilities and flexible use of different foundational models.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="LANGCHAIN" target="LANGCHAINAI, 2022">
      <data key="d4">10.0</data>
      <data key="d5">LangChainAI is an organization that has worked on the LangChain framework, relevant to ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="NEO4J" target="NALLM">
      <data key="d4">6.0</data>
      <data key="d5">NaLLM uses Neo4J for knowledge graph creation and reasoning.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="NEBULAGRAPH" target="GRAPHRAG">
      <data key="d4">1.0</data>
      <data key="d5">GraphRAG uses NebulaGraph for knowledge graph creation and reasoning.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="QUERY" target="WEB SHOP">
      <data key="d4">8.0</data>
      <data key="d5">The web shop allows users to enter queries to search for specific products.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="TABLE 3" target="ORCA-3">
      <data key="d4">6.0</data>
      <data key="d5">Table 3 presents the performance of Orca-3 on various benchmarks.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="TABLE 3" target="MISTRAL-7B-INSTRUCT">
      <data key="d4">6.0</data>
      <data key="d5">Table 3 shows the relative improvements of other models over Mistral-7b-Instruct.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="TABLE 3" target="APPENDIX B">
      <data key="d4">5.0</data>
      <data key="d5">Appendix B specifies the methods used to extract answers and generate metrics shown in Table 3.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="SELF CHECK GPT" target="FABRICATION RATES">
      <data key="d4">7.0</data>
      <data key="d5">SelfCheckGPT is used to compare fabrication rates in generated content.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH-BASED RAG APPLICATIONS" target="KNOWLEDGE GRAPHS">
      <data key="d4">8.0</data>
      <data key="d5">Graph-based RAG applications create and reason over knowledge graphs.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="PYTHON" target="ADAS">
      <data key="d4">7.0</data>
      <data key="d5">Python is used in the implementation of ADAS algorithms.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="J. ACHIAM" target="GPT-4">
      <data key="d4">6.0</data>
      <data key="d5">J. Achiam is one of the authors of the GPT-4 technical report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="S. ADLER" target="GPT-4">
      <data key="d4">6.0</data>
      <data key="d5">S. Adler is one of the authors of the GPT-4 technical report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="S. AGARWAL" target="GPT-4">
      <data key="d4">6.0</data>
      <data key="d5">S. Agarwal is one of the authors of the GPT-4 technical report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="L. AHMAD" target="GPT-4">
      <data key="d4">6.0</data>
      <data key="d5">L. Ahmad is one of the authors of the GPT-4 technical report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="I. AKKAYA" target="GPT-4">
      <data key="d4">6.0</data>
      <data key="d5">I. Akkaya is one of the authors of the GPT-4 technical report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="F. L. ALEMAN" target="GPT-4">
      <data key="d4">6.0</data>
      <data key="d5">F. L. Aleman is one of the authors of the GPT-4 technical report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="D. ALMEIDA" target="GPT-4">
      <data key="d4">6.0</data>
      <data key="d5">D. Almeida is one of the authors of the GPT-4 technical report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="J. ALTENSCHMIDT" target="GPT-4">
      <data key="d4">6.0</data>
      <data key="d5">J. Altenschmidt is one of the authors of the GPT-4 technical report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="S. ALTMAN" target="GPT-4">
      <data key="d4">6.0</data>
      <data key="d5">S. Altman is one of the authors of the GPT-4 technical report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="S. ANADKAT" target="GPT-4">
      <data key="d4">6.0</data>
      <data key="d5">S. Anadkat is one of the authors of the GPT-4 technical report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="J. BAEK" target="KNOWLEDGE-AUGMENTED LANGUAGE MODEL PROMPTING">
      <data key="d4">6.0</data>
      <data key="d5">J. Baek is one of the authors of the knowledge-augmented language model prompting report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="A. F. AJI" target="KNOWLEDGE-AUGMENTED LANGUAGE MODEL PROMPTING">
      <data key="d4">6.0</data>
      <data key="d5">A. F. Aji is one of the authors of the knowledge-augmented language model prompting report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="A. SAFFARI" target="KNOWLEDGE-AUGMENTED LANGUAGE MODEL PROMPTING">
      <data key="d4">6.0</data>
      <data key="d5">A. Saffari is one of the authors of the knowledge-augmented language model prompting report.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="T. BAN" target="HARNESSING LARGE LANGUAGE MODELS FOR CAUSAL DISCOVERY">
      <data key="d4">6.0</data>
      <data key="d5">T. Ban is one of the authors of the report on harnessing large language models for causal discovery.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="L. CHEN" target="HARNESSING LARGE LANGUAGE MODELS FOR CAUSAL DISCOVERY">
      <data key="d4">6.0</data>
      <data key="d5">L. Chen is one of the authors of the report on harnessing large language models for causal discovery.</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GPT-4" target="LANGUAGE AGENT TREE SEARCH (LATS)">
      <data key="d4">16.0</data>
      <data key="d5">LATS uses GPT-4 to achieve state-of-the-art pass@1 accuracy for programming on HumanEval.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="GPT-4" target="LATS">
      <data key="d4">9.0</data>
      <data key="d5">LATS, when used with GPT-4, achieves a 92.7 Pass@1 rate on HumanEval, setting the state of the art.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="GPT-4" target="HUMANEVAL">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 is used in experiments with the HumanEval dataset.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="GPT-4" target="INTERNAL TESTS">
      <data key="d4">6.0</data>
      <data key="d5">GPT-4 is evaluated using internal tests.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="GPT-4" target="META AGENT SEARCH">
      <data key="d4">25.0</data>
      <data key="d5">Meta Agent Search transfers discovered agents from GPT-3.5 to GPT-4, showing significant improvement in accuracy rate on ARC tasks.
Meta Agent Search uses GPT-4 to discover high-performance agents.
Meta Agent Search uses GPT-4 as the meta agent.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="GPT-4" target="OPENAI">
      <data key="d4">9.0</data>
      <data key="d5">OpenAI is the organization that developed GPT-4.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="GPT-4" target="ARC">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 is used to evaluate the performance of agents on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="GPT-4" target="ARC-AGI">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4 achieved 50% SOTA on ARC-AGI as discussed in a technical report by Ryan Greenblatt.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="GPT-4" target="AGENTINSTRUCT">
      <data key="d4">16.0</data>
      <data key="d5">AgentInstruct uses GPT-4 to generate high-quality data for teaching AI models.
AgentInstruct achieved a reduction in hallucinations while maintaining a quality level comparable to GPT-4.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="GPT-4" target="ORCA-BENCH">
      <data key="d4">18.0</data>
      <data key="d5">The performance of models on the Orca-Bench dataset is scored relative to GPT-4.
GPT-4 is used as the benchmark model in the Orca-Bench dataset, scoring a perfect 10.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="GPT-4" target="LSAT">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4's performance is used as a benchmark for evaluating the reading comprehension capabilities of other models on the LSAT.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="GPT-4" target="ORCA-3">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3's performance on certain tasks, such as reading comprehension, matches that of GPT-4.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="GPT-4" target="ACI-BENCH">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 is used as an evaluator for summarization abilities on the ACI-Bench dataset.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="INSTRUSUM">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 is used as an evaluator for summarization abilities on the InstruSum dataset.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="ORCA-SUM">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 is used as an evaluator for summarization abilities on the Orca-Sum dataset.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="MMLU-MED">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 is evaluated on the MMLU-Med dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="MEDQA-US">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 is evaluated on the MedQA-US dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="MEDMCQA">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 is evaluated on the MedMCQA dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="PUBMEDQA">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 is evaluated on the PubMedQA dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="BIOASQ">
      <data key="d4">1.0</data>
      <data key="d5">GPT-4 is evaluated on the BioASQ dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="PROMPTS">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 is used to generate prompts for evaluating summarization abilities in the Orca-Sum benchmark.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="MIRAGE">
      <data key="d4">9.0</data>
      <data key="d5">GPT-4 is evaluated on the MIRAGE datasets, showing high performance in RAG tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPT-4" target="AZURE">
      <data key="d4">7.0</data>
      <data key="d5">Azure provides transparency notes and content moderation services for GPT-4.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPT-4" target="MULTIPLE CHOICE QUESTIONS">
      <data key="d4">10.0</data>
      <data key="d5">GPT-4 is used for extracting the option selected by the model from its response in multiple choice questions.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="GPT-4" target="VERSION 0613">
      <data key="d4">7.0</data>
      <data key="d5">Version 0613 of GPT-4 is used in the FOFO and AlpacaEval benchmarks.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="GPT-4" target="VERSION 1106-PREVIEW">
      <data key="d4">7.0</data>
      <data key="d5">Version 1106-preview of GPT-4 is used in the InfoBench benchmark.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="GPT-4" target="JUDGE">
      <data key="d4">8.0</data>
      <data key="d5">GPT-4 acts as a judge in various benchmarks like FOFO, MT-Bench, AlpacaEval, and InfoBench.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="BLONDEL, V. D." target="FAST UNFOLDING OF COMMUNITIES">
      <data key="d4">9.0</data>
      <data key="d5">Blondel, V. D. is one of the authors of the paper on fast unfolding of communities in large networks.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="GUILLAUME, J.-L." target="FAST UNFOLDING OF COMMUNITIES">
      <data key="d4">9.0</data>
      <data key="d5">Guillaume, J.-L. is one of the authors of the paper on fast unfolding of communities in large networks.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="LAMBIOTTE, R." target="FAST UNFOLDING OF COMMUNITIES">
      <data key="d4">9.0</data>
      <data key="d5">Lambiotte, R. is one of the authors of the paper on fast unfolding of communities in large networks.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="LEFEBVRE, E." target="FAST UNFOLDING OF COMMUNITIES">
      <data key="d4">9.0</data>
      <data key="d5">Lefebvre, E. is one of the authors of the paper on fast unfolding of communities in large networks.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="FAST UNFOLDING OF COMMUNITIES" target="JOURNAL OF STATISTICAL MECHANICS: THEORY AND EXPERIMENT">
      <data key="d4">8.0</data>
      <data key="d5">The paper on fast unfolding of communities in large networks was published in the Journal of Statistical Mechanics: Theory and Experiment.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="BROWN, T." target="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d4">9.0</data>
      <data key="d5">Brown, T. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="MANN, B." target="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d4">9.0</data>
      <data key="d5">Mann, B. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="RYDER, N." target="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d4">9.0</data>
      <data key="d5">Ryder, N. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="SUBBIAH, M." target="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d4">9.0</data>
      <data key="d5">Subbiah, M. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="KAPLAN, J. D." target="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d4">9.0</data>
      <data key="d5">Kaplan, J. D. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="DHARIWAL, P." target="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d4">9.0</data>
      <data key="d5">Dhariwal, P. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="NEELAKANTAN, A." target="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d4">9.0</data>
      <data key="d5">Neelakantan, A. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="SHYAM, P." target="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d4">9.0</data>
      <data key="d5">Shyam, P. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="SASTRY, G." target="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d4">9.0</data>
      <data key="d5">Sastry, G. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="ASKELL, A." target="LANGUAGE MODELS ARE FEW-SHOT LEARNERS">
      <data key="d4">9.0</data>
      <data key="d5">Askell, A. is one of the authors of the paper on language models being few-shot learners.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="LANGUAGE MODELS ARE FEW-SHOT LEARNERS" target="ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS">
      <data key="d4">8.0</data>
      <data key="d5">The paper on language models being few-shot learners was published in Advances in Neural Information Processing Systems.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS" target="LIFT YOURSELF UP: RETRIEVAL-AUGMENTED TEXT GENERATION WITH SELF-MEMORY">
      <data key="d4">8.0</data>
      <data key="d5">The paper on retrieval-augmented text generation with self-memory was published in Advances in Neural Information Processing Systems.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="CHENG, X." target="LIFT YOURSELF UP: RETRIEVAL-AUGMENTED TEXT GENERATION WITH SELF-MEMORY">
      <data key="d4">9.0</data>
      <data key="d5">Cheng, X. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="LUO, D." target="LIFT YOURSELF UP: RETRIEVAL-AUGMENTED TEXT GENERATION WITH SELF-MEMORY">
      <data key="d4">9.0</data>
      <data key="d5">Luo, D. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="CHEN, X." target="LIFT YOURSELF UP: RETRIEVAL-AUGMENTED TEXT GENERATION WITH SELF-MEMORY">
      <data key="d4">9.0</data>
      <data key="d5">Chen, X. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="LIU, L." target="LIFT YOURSELF UP: RETRIEVAL-AUGMENTED TEXT GENERATION WITH SELF-MEMORY">
      <data key="d4">9.0</data>
      <data key="d5">Liu, L. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="ZHAO, D." target="LIFT YOURSELF UP: RETRIEVAL-AUGMENTED TEXT GENERATION WITH SELF-MEMORY">
      <data key="d4">9.0</data>
      <data key="d5">Zhao, D. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="YAN, R." target="LIFT YOURSELF UP: RETRIEVAL-AUGMENTED TEXT GENERATION WITH SELF-MEMORY">
      <data key="d4">9.0</data>
      <data key="d5">Yan, R. is one of the authors of the paper on retrieval-augmented text generation with self-memory.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="DANG, H. T." target="EVALUATION OF QUESTION-FOCUSED SUMMARIZATION SYSTEMS">
      <data key="d4">9.0</data>
      <data key="d5">Dang, H. T. is the author of the paper on the evaluation of question-focused summarization systems.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="DUC 2005" target="EVALUATION OF QUESTION-FOCUSED SUMMARIZATION SYSTEMS">
      <data key="d4">8.0</data>
      <data key="d5">The paper on the evaluation of question-focused summarization systems was presented at the DUC 2005 conference.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="FENG, Z." target="RETRIEVAL-GENERATION SYNERGY AUGMENTED LARGE LANGUAGE MODELS">
      <data key="d4">9.0</data>
      <data key="d5">Feng, Z. is one of the authors of the paper on retrieval-generation synergy augmented large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="FENG, X." target="RETRIEVAL-GENERATION SYNERGY AUGMENTED LARGE LANGUAGE MODELS">
      <data key="d4">9.0</data>
      <data key="d5">Feng, X. is one of the authors of the paper on retrieval-generation synergy augmented large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="YANG, M." target="RETRIEVAL-GENERATION SYNERGY AUGMENTED LARGE LANGUAGE MODELS">
      <data key="d4">9.0</data>
      <data key="d5">Yang, M. is one of the authors of the paper on retrieval-generation synergy augmented large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="QIN, B." target="RETRIEVAL-GENERATION SYNERGY AUGMENTED LARGE LANGUAGE MODELS">
      <data key="d4">9.0</data>
      <data key="d5">Qin, B. is one of the authors of the paper on retrieval-generation synergy augmented large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="FORTUNATO, S." target="COMMUNITY DETECTION IN GRAPHS">
      <data key="d4">9.0</data>
      <data key="d5">Fortunato, S. is the author of the paper on community detection in graphs.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="COMMUNITY DETECTION IN GRAPHS" target="PHYSICS REPORTS">
      <data key="d4">8.0</data>
      <data key="d5">The paper on community detection in graphs was published in Physics Reports.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="GAO, Y." target="RETRIEVAL-AUGMENTED GENERATION FOR LARGE LANGUAGE MODELS: A SURVEY">
      <data key="d4">9.0</data>
      <data key="d5">Gao, Y. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="XIONG, Y." target="RETRIEVAL-AUGMENTED GENERATION FOR LARGE LANGUAGE MODELS: A SURVEY">
      <data key="d4">9.0</data>
      <data key="d5">Xiong, Y. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="GAO, X." target="RETRIEVAL-AUGMENTED GENERATION FOR LARGE LANGUAGE MODELS: A SURVEY">
      <data key="d4">9.0</data>
      <data key="d5">Gao, X. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="JIA, K." target="RETRIEVAL-AUGMENTED GENERATION FOR LARGE LANGUAGE MODELS: A SURVEY">
      <data key="d4">9.0</data>
      <data key="d5">Jia, K. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="PAN, J." target="RETRIEVAL-AUGMENTED GENERATION FOR LARGE LANGUAGE MODELS: A SURVEY">
      <data key="d4">9.0</data>
      <data key="d5">Pan, J. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="BI, Y." target="RETRIEVAL-AUGMENTED GENERATION FOR LARGE LANGUAGE MODELS: A SURVEY">
      <data key="d4">9.0</data>
      <data key="d5">Bi, Y. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="DAI, Y." target="RETRIEVAL-AUGMENTED GENERATION FOR LARGE LANGUAGE MODELS: A SURVEY">
      <data key="d4">9.0</data>
      <data key="d5">Dai, Y. is one of the authors of the survey on retrieval-augmented generation for large language models.</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="CHEN, W." target="ENHANCING RETRIEVAL-AUGMENTED LARGE LANGUAGE MODELS WITH ITERATIVE RETRIEVAL-GENERATION SYNERGY">
      <data key="d4">8.0</data>
      <data key="d5">Chen, W. is one of the authors of the paper titled "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="DUAN, N." target="ENHANCING RETRIEVAL-AUGMENTED LARGE LANGUAGE MODELS WITH ITERATIVE RETRIEVAL-GENERATION SYNERGY">
      <data key="d4">8.0</data>
      <data key="d5">Duan, N. is one of the authors of the paper titled "Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="TOUVRON, H." target="LLAMA 2">
      <data key="d4">8.0</data>
      <data key="d5">Touvron, H. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="MARTIN, L." target="LLAMA 2">
      <data key="d4">8.0</data>
      <data key="d5">Martin, L. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="STONE, K." target="LLAMA 2">
      <data key="d4">8.0</data>
      <data key="d5">Stone, K. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="ALBERT, P." target="LLAMA 2">
      <data key="d4">8.0</data>
      <data key="d5">Albert, P. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="ALMAHAIRI, A." target="LLAMA 2">
      <data key="d4">8.0</data>
      <data key="d5">Almahairi, A. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="BABAEI, Y." target="LLAMA 2">
      <data key="d4">8.0</data>
      <data key="d5">Babaei, Y. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="BASHLYKOV, N." target="LLAMA 2">
      <data key="d4">8.0</data>
      <data key="d5">Bashlykov, N. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="BATRA, S." target="LLAMA 2">
      <data key="d4">8.0</data>
      <data key="d5">Batra, S. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="BHARGAVA, P." target="LLAMA 2">
      <data key="d4">8.0</data>
      <data key="d5">Bhargava, P. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="BHOSALE, S." target="LLAMA 2">
      <data key="d4">8.0</data>
      <data key="d5">Bhosale, S. is one of the authors of the paper titled "Llama 2: Open foundation and fine-tuned chat models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="TRAAG, V. A." target="FROM LOUVAIN TO LEIDEN: GUARANTEEING WELL-CONNECTED COMMUNITIES">
      <data key="d4">8.0</data>
      <data key="d5">Traag, V. A. is one of the authors of the paper titled "From Louvain to Leiden: guaranteeing well-connected communities."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="WALTMAN, L." target="FROM LOUVAIN TO LEIDEN: GUARANTEEING WELL-CONNECTED COMMUNITIES">
      <data key="d4">8.0</data>
      <data key="d5">Waltman, L. is one of the authors of the paper titled "From Louvain to Leiden: guaranteeing well-connected communities."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="VAN ECK, N. J." target="FROM LOUVAIN TO LEIDEN: GUARANTEEING WELL-CONNECTED COMMUNITIES">
      <data key="d4">8.0</data>
      <data key="d5">Van Eck, N. J. is one of the authors of the paper titled "From Louvain to Leiden: guaranteeing well-connected communities."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="TRAJANOSKA, M." target="ENHANCING KNOWLEDGE GRAPH CONSTRUCTION USING LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Trajanoska, M. is one of the authors of the paper titled "Enhancing knowledge graph construction using large language models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="STOJANOV, R." target="ENHANCING KNOWLEDGE GRAPH CONSTRUCTION USING LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Stojanov, R. is one of the authors of the paper titled "Enhancing knowledge graph construction using large language models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="TRAJANOV, D." target="ENHANCING KNOWLEDGE GRAPH CONSTRUCTION USING LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Trajanov, D. is one of the authors of the paper titled "Enhancing knowledge graph construction using large language models."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="TRIVEDI, H." target="INTERLEAVING RETRIEVAL WITH CHAIN-OF-THOUGHT REASONING FOR KNOWLEDGE-INTENSIVE MULTI-STEP QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Trivedi, H. is one of the authors of the paper titled "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="BALASUBRAMANIAN, N." target="INTERLEAVING RETRIEVAL WITH CHAIN-OF-THOUGHT REASONING FOR KNOWLEDGE-INTENSIVE MULTI-STEP QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Balasubramanian, N. is one of the authors of the paper titled "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="KHOT, T." target="INTERLEAVING RETRIEVAL WITH CHAIN-OF-THOUGHT REASONING FOR KNOWLEDGE-INTENSIVE MULTI-STEP QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Khot, T. is one of the authors of the paper titled "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="SABHARWAL, A." target="INTERLEAVING RETRIEVAL WITH CHAIN-OF-THOUGHT REASONING FOR KNOWLEDGE-INTENSIVE MULTI-STEP QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Sabharwal, A. is one of the authors of the paper titled "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="WANG, J." target="IS CHATGPT A GOOD NLG EVALUATOR? A PRELIMINARY STUDY">
      <data key="d4">8.0</data>
      <data key="d5">Wang, J. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="LIANG, Y." target="IS CHATGPT A GOOD NLG EVALUATOR? A PRELIMINARY STUDY">
      <data key="d4">8.0</data>
      <data key="d5">Liang, Y. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="MENG, F." target="IS CHATGPT A GOOD NLG EVALUATOR? A PRELIMINARY STUDY">
      <data key="d4">8.0</data>
      <data key="d5">Meng, F. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="SUN, Z." target="IS CHATGPT A GOOD NLG EVALUATOR? A PRELIMINARY STUDY">
      <data key="d4">8.0</data>
      <data key="d5">Sun, Z. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="SHI, H." target="IS CHATGPT A GOOD NLG EVALUATOR? A PRELIMINARY STUDY">
      <data key="d4">8.0</data>
      <data key="d5">Shi, H. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="LI, Z." target="IS CHATGPT A GOOD NLG EVALUATOR? A PRELIMINARY STUDY">
      <data key="d4">8.0</data>
      <data key="d5">Li, Z. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="XU, J." target="IS CHATGPT A GOOD NLG EVALUATOR? A PRELIMINARY STUDY">
      <data key="d4">8.0</data>
      <data key="d5">Xu, J. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="QU, J." target="IS CHATGPT A GOOD NLG EVALUATOR? A PRELIMINARY STUDY">
      <data key="d4">8.0</data>
      <data key="d5">Qu, J. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="ZHOU, J." target="IS CHATGPT A GOOD NLG EVALUATOR? A PRELIMINARY STUDY">
      <data key="d4">8.0</data>
      <data key="d5">Zhou, J. is one of the authors of the paper titled "Is chatgpt a good nlg evaluator? a preliminary study."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="WANG, S." target="FEB4RAG">
      <data key="d4">8.0</data>
      <data key="d5">Wang, S. is one of the authors of the paper titled "Feb4rag: Evaluating federated search in the context of retrieval augmented generation."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="KHRAMTSOVA, E." target="FEB4RAG">
      <data key="d4">8.0</data>
      <data key="d5">Khramtsova, E. is one of the authors of the paper titled "Feb4rag: Evaluating federated search in the context of retrieval augmented generation."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="ZHUANG, S." target="FEB4RAG">
      <data key="d4">8.0</data>
      <data key="d5">Zhuang, S. is one of the authors of the paper titled "Feb4rag: Evaluating federated search in the context of retrieval augmented generation."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="ZUCCON, G." target="FEB4RAG">
      <data key="d4">8.0</data>
      <data key="d5">Zuccon, G. is one of the authors of the paper titled "Feb4rag: Evaluating federated search in the context of retrieval augmented generation."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="WANG, Y." target="KNOWLEDGE GRAPH PROMPTING FOR MULTI-DOCUMENT QUESTION ANSWERING">
      <data key="d4">8.0</data>
      <data key="d5">Wang, Y. is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="LIPKA, N." target="KNOWLEDGE GRAPH PROMPTING FOR MULTI-DOCUMENT QUESTION ANSWERING">
      <data key="d4">8.0</data>
      <data key="d5">Lipka, N. is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="ROSSI, R. A." target="KNOWLEDGE GRAPH PROMPTING FOR MULTI-DOCUMENT QUESTION ANSWERING">
      <data key="d4">8.0</data>
      <data key="d5">Rossi, R. A. is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="SIU, A." target="KNOWLEDGE GRAPH PROMPTING FOR MULTI-DOCUMENT QUESTION ANSWERING">
      <data key="d4">8.0</data>
      <data key="d5">Siu, A. is one of the authors of the paper titled "Knowledge graph prompting for multi-document question answering."</data>
      <data key="d6">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="LANGUAGE MODELS (LMS)">
      <data key="d4">18.0</data>
      <data key="d5">LATS leverages the in-context learning ability of language models for reasoning, acting, and planning.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="MONTE CARLO TREE SEARCH (MCTS)">
      <data key="d4">16.0</data>
      <data key="d5">LATS integrates Monte Carlo Tree Search to enable language models as agents.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="EXTERNAL FEEDBACK">
      <data key="d4">16.0</data>
      <data key="d5">LATS incorporates external feedback to offer a more deliberate and adaptive problem-solving mechanism.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="PROGRAMMING">
      <data key="d4">14.0</data>
      <data key="d5">LATS has been experimentally evaluated in the domain of programming, achieving state-of-the-art pass@1 accuracy.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="INTERACTIVE QUESTION-ANSWERING (QA)">
      <data key="d4">14.0</data>
      <data key="d5">LATS has been validated for its effectiveness in the domain of interactive question-answering.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="WEB NAVIGATION">
      <data key="d4">14.0</data>
      <data key="d5">LATS demonstrates gradient-free performance in the domain of web navigation.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="MATH">
      <data key="d4">14.0</data>
      <data key="d5">LATS has been experimentally evaluated in the domain of math, validating its effectiveness.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="GPT-3.5">
      <data key="d4">16.0</data>
      <data key="d5">LATS uses GPT-3.5 to demonstrate gradient-free performance for web navigation on WebShop.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="HUMANEVAL">
      <data key="d4">16.0</data>
      <data key="d5">LATS achieves state-of-the-art pass@1 accuracy for programming on HumanEval.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="WEB SHOP">
      <data key="d4">14.0</data>
      <data key="d5">LATS demonstrates gradient-free performance for web navigation on WebShop.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="ANDY ZHOU">
      <data key="d4">12.0</data>
      <data key="d5">Andy Zhou is one of the authors of the paper introducing LATS.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="REACT">
      <data key="d4">14.0</data>
      <data key="d5">LATS expands ReAct into a search over a combinatorial space of possible reasoning and acting steps.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="PSEUDOCODE">
      <data key="d4">8.0</data>
      <data key="d5">The pseudocode of the LATS algorithm is shown in Sec. A of the appendix.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="EXPLORATION WEIGHT">
      <data key="d4">7.0</data>
      <data key="d5">The LATS algorithm uses an exploration weight parameter that affects the effectiveness of the search.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SELF-CONSISTENCY WEIGHT">
      <data key="d4">7.0</data>
      <data key="d5">The LATS algorithm uses a self-consistency weight parameter that affects the consistency of the search results.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="COMPUTATIONAL COST">
      <data key="d4">8.0</data>
      <data key="d5">The LATS algorithm has a higher computational cost compared to simpler prompting methods like ReAct or Reflexion.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SAMPLE COMPLEXITY">
      <data key="d4">7.0</data>
      <data key="d5">The LATS algorithm has the same sample complexity as ToT and RAP but achieves better performance.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="ENVIRONMENT REVERSION">
      <data key="d4">7.0</data>
      <data key="d5">The LATS algorithm requires environment reversion for decision-making tasks.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="API-BASED TOOLS">
      <data key="d4">6.0</data>
      <data key="d5">API-based tools are used in LM-based environments and are mentioned as being inexpensive and fast to use in the context of LATS.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="TEXT-BASED MANIPULATION TASKS">
      <data key="d4">6.0</data>
      <data key="d5">Text-based manipulation tasks are a type of task evaluated using environments like Alfworld, mentioned in the context of LATS.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="ROLLBACKS">
      <data key="d4">6.0</data>
      <data key="d5">Rollbacks are a feature that allows reverting to previous states in an environment, mentioned as a limitation for some environments in the context of LATS.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="RESOURCE CONSTRAINTS">
      <data key="d4">6.0</data>
      <data key="d5">Resource constraints are limitations that can affect the design and implementation of the LATS algorithm in various environments.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="PLANNING-BASED PROMPTING METHODS">
      <data key="d4">7.0</data>
      <data key="d5">LATS is a planning-based prompting method used for reasoning and decision-making in language models.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="ADDITIONAL ABLATIONS">
      <data key="d4">7.0</data>
      <data key="d5">Additional ablations are experiments conducted to analyze various designs of the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="TRAJECTORIES">
      <data key="d4">6.0</data>
      <data key="d5">Trajectories are paths or sequences of states and actions evaluated in the LATS algorithm during experiments.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SAMPLING SIZE">
      <data key="d4">6.0</data>
      <data key="d5">Sampling size is a parameter in the LATS algorithm that affects the number of samples taken during the search process.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="TAB. 8">
      <data key="d4">6.0</data>
      <data key="d5">Tab. 8 shows the results of experiments conducted on HotPotQA using the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="FIG. 3">
      <data key="d4">6.0</data>
      <data key="d5">Fig. 3 shows the results of experiments conducted on HumanEval using the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="TAB. 9">
      <data key="d4">6.0</data>
      <data key="d5">Tab. 9 provides a full analysis of the computational cost of the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SEC. A">
      <data key="d4">6.0</data>
      <data key="d5">Sec. A shows the pseudocode of the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SEC. B">
      <data key="d4">6.0</data>
      <data key="d5">Sec. B provides further discussion of the limitations of the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SEC. C">
      <data key="d4">6.0</data>
      <data key="d5">Sec. C presents additional experimental results of the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SEC. D">
      <data key="d4">6.0</data>
      <data key="d5">Sec. D specifies the environment details in the experiments conducted using the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SEC. E">
      <data key="d4">6.0</data>
      <data key="d5">Sec. E lists the prompts used for the HotPotQA environment in the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SEC. F">
      <data key="d4">6.0</data>
      <data key="d5">Sec. F lists the prompts used for the Programming environment in the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="SEC. G">
      <data key="d4">6.0</data>
      <data key="d5">Sec. G lists the prompts used for the WebShop environment in the LATS algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="GAME OF 24">
      <data key="d4">6.0</data>
      <data key="d5">The LATS algorithm uses a self-consistency weight of 0.5 for the Game of 24 task.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE AGENT TREE SEARCH (LATS)" target="PROMPTS">
      <data key="d4">6.0</data>
      <data key="d5">Prompts are inputs used in the LATS algorithm for different environments like HotPotQA, Programming, and WebShop.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="CHOWDHERY ET AL., 2023">
      <data key="d4">10.0</data>
      <data key="d5">Chowdhery et al. are the authors of a significant paper on language models, published in 2023.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="OPENAI, 2023">
      <data key="d4">10.0</data>
      <data key="d5">OpenAI is an organization that has published significant research on language models in 2023.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="NALLAPATI ET AL., 2016">
      <data key="d4">10.0</data>
      <data key="d5">Nallapati et al. are the authors of a significant paper on summarization, published in 2016.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="BOWMAN ET AL., 2015">
      <data key="d4">10.0</data>
      <data key="d5">Bowman et al. are the authors of a significant paper on language inference, published in 2015.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="COBBE ET AL., 2021">
      <data key="d4">10.0</data>
      <data key="d5">Cobbe et al. are the authors of a significant paper on language models, published in 2021.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="SAPAROV AND HE, 2023">
      <data key="d4">10.0</data>
      <data key="d5">Saparov and He are the authors of a significant paper on language models, published in 2023.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="YAO ET AL., 2022">
      <data key="d4">10.0</data>
      <data key="d5">Yao et al. are the authors of a significant paper on web navigation, published in 2022.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="DENG ET AL., 2023">
      <data key="d4">10.0</data>
      <data key="d5">Deng et al. are the authors of a significant paper on web navigation, published in 2023.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="SCHICK ET AL., 2023">
      <data key="d4">10.0</data>
      <data key="d5">Schick et al. are the authors of a significant paper on tool-use, published in 2023.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="FAN ET AL., 2022">
      <data key="d4">10.0</data>
      <data key="d5">Fan et al. are the authors of a significant paper on open-ended games, published in 2022.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="SHINN ET AL., 2023">
      <data key="d4">10.0</data>
      <data key="d5">Shinn et al. are the authors of a significant paper on language models, published in 2023.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="SLOMAN, 1996">
      <data key="d4">10.0</data>
      <data key="d5">Sloman is the author of a significant paper on decision-making, published in 1996.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="EVANS, 2010">
      <data key="d4">10.0</data>
      <data key="d5">Evans is the author of a significant paper on decision-making, published in 2010.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="XIE ET AL., 2023">
      <data key="d4">10.0</data>
      <data key="d5">Xie et al. are the authors of a significant paper on search-guided language models, published in 2023.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="YAO ET AL., 2023A">
      <data key="d4">10.0</data>
      <data key="d5">Yao et al. are the authors of a significant paper on search-guided language models, published in 2023.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="HAO ET AL., 2023">
      <data key="d4">10.0</data>
      <data key="d5">Hao et al. are the authors of a significant paper on search-guided language models, published in 2023.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="LANGUAGE MODELS (LMS)" target="WOOLDRIDGE AND JENNINGS, 1995">
      <data key="d4">2.0</data>
      <data key="d5">Wooldridge and Jennings are the authors of a significant paper on autonomous agents, published in 1995.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="LATS">
      <data key="d4">9.0</data>
      <data key="d5">LATS adapts Monte Carlo Tree Search (MCTS) to enhance language model performance.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="REASONING VIA PLANNING (RAP)">
      <data key="d4">7.0</data>
      <data key="d5">RAP uses MCTS with rollouts simulated by language models for reasoning tasks.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="SILVER ET AL., 2017">
      <data key="d4">6.0</data>
      <data key="d5">Silver et al. are researchers known for their work in model-based reinforcement learning, published in 2017.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="UPPER CONFIDENCE BOUNDS APPLIED TO TREES (UCT)">
      <data key="d4">9.0</data>
      <data key="d5">UCT is used in MCTS to select the best child node for expansion based on a combination of exploration and exploitation.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="YE ET AL., 2021">
      <data key="d4">6.0</data>
      <data key="d5">Ye et al. demonstrated the success of MCTS in decision-making environments like Atari.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="SILVER ET AL., 2016">
      <data key="d4">6.0</data>
      <data key="d5">Silver et al. demonstrated the success of MCTS in decision-making environments like Go.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="RETURN R">
      <data key="d4">8.0</data>
      <data key="d5">Return r is used for updating the value function V(s) in MCTS during backpropagation.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="VALUE FUNCTION V(S)">
      <data key="d4">8.0</data>
      <data key="d5">Value function V(s) is used to guide the search process in MCTS.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="BACKPROPAGATION">
      <data key="d4">8.0</data>
      <data key="d5">Backpropagation is used in MCTS to update the value function V(s) along the path.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="MONTE CARLO TREE SEARCH (MCTS)" target="EPISODES">
      <data key="d4">1.0</data>
      <data key="d5">MCTS runs for multiple episodes to expand and update the decision tree.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="EXTERNAL FEEDBACK" target="LATS">
      <data key="d4">49.0</data>
      <data key="d5">LATS incorporates external feedback to improve decision-making and problem-solving.
LATS incorporates external feedback to improve reasoning and decision-making.
LATS incorporates external feedback to improve performance.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="EXTERNAL FEEDBACK" target="HUANG ET AL., 2024">
      <data key="d4">8.0</data>
      <data key="d5">Huang et al. suggested that external feedback is critical for language models to self-correct their internal reasoning.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="PROGRAMMING" target="LATS">
      <data key="d4">7.0</data>
      <data key="d5">LATS is recommended for difficult tasks like programming.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="PROGRAMMING" target="HUMANEVAL">
      <data key="d4">8.0</data>
      <data key="d5">HumanEval is a dataset used to evaluate programming tasks.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="PROGRAMMING" target="MOSTLY BASIC PROGRAMMING PROBLEMS (MBPP)">
      <data key="d4">8.0</data>
      <data key="d5">MBPP is a dataset used to evaluate programming tasks.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="INTERACTIVE QUESTION-ANSWERING (QA)" target="LATS">
      <data key="d4">7.0</data>
      <data key="d5">LATS enhances performance in interactive question-answering tasks.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="WEB NAVIGATION" target="LATS">
      <data key="d4">7.0</data>
      <data key="d5">LATS improves performance in web navigation tasks.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MATH" target="LATS">
      <data key="d4">7.0</data>
      <data key="d5">LATS demonstrates versatility by enhancing performance in mathematical problem-solving.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MATH" target="MGSM">
      <data key="d4">8.0</data>
      <data key="d5">The MGSM benchmark is used to evaluate math capabilities.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="MATH" target="META AGENT SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search is effective in the Math domain where foundational models possess adequate knowledge.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="MATH" target="AGENTINSTRUCT">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct generates data to teach AI models the skill of math.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="MATH" target="ORCA-3">
      <data key="d4">1.0</data>
      <data key="d5">Orca-3's performance is evaluated on mathematical problem-solving capabilities.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MATH" target="OPEN DOMAIN QUESTION ANSWERING">
      <data key="d4">6.0</data>
      <data key="d5">Open Domain Question Answering is used to generate math problems for evaluating AI models.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="MATH" target="MULTIPLE-CHOICE QUESTIONS FLOWS">
      <data key="d4">6.0</data>
      <data key="d5">Multiple-Choice Questions Flows is used to generate math problems for evaluating AI models.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="MATH" target="BBH">
      <data key="d4">7.0</data>
      <data key="d5">BBH is a benchmark used to evaluate AI models on multi-step arithmetic problems.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="GPT-3.5" target="LATS">
      <data key="d4">25.0</data>
      <data key="d5">LATS, when used with GPT-3.5, significantly improves performance on tasks such as WebShop and HotPotQA.
LATS achieves the highest performance on GPT-3.5 for programming tasks.
LATS, when used with GPT-3.5, shows improved performance in tasks like WebShop, Game of 24, and HotPotQA.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="GPT-3.5" target="REACT">
      <data key="d4">6.0</data>
      <data key="d5">ReAct is used with GPT-3.5 to evaluate performance in various tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="GPT-3.5" target="REFLEXION">
      <data key="d4">6.0</data>
      <data key="d5">Reflexion is used with GPT-3.5 to evaluate performance in various tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="GPT-3.5" target="GAME OF 24">
      <data key="d4">14.0</data>
      <data key="d5">Game of 24 is used to evaluate the reasoning ability of GPT-3.5 with various algorithms.
The Game of 24 is conducted using the GPT-3.5 language model.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="GPT-3.5" target="HOT POT QA">
      <data key="d4">6.0</data>
      <data key="d5">HotPotQA is used to evaluate the performance of GPT-3.5 with various algorithms.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="GPT-3.5" target="FINE-TUNING">
      <data key="d4">6.0</data>
      <data key="d5">Fine-tuning is used to improve the performance of GPT-3.5 in various tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="GPT-3.5" target="HUMANEVAL">
      <data key="d4">7.0</data>
      <data key="d5">GPT-3.5 is used in experiments with the HumanEval dataset.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="GPT-3.5" target="INTERNAL TESTS">
      <data key="d4">6.0</data>
      <data key="d5">GPT-3.5 is evaluated using internal tests.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="GPT-3.5" target="META AGENT SEARCH">
      <data key="d4">23.0</data>
      <data key="d5">Meta Agent Search transfers discovered agents from GPT-3.5 to GPT-4, showing significant improvement in accuracy rate on ARC tasks.
Discovered agents and baselines in Meta Agent Search are evaluated using GPT-3.5 to reduce compute cost.
Meta Agent Search uses GPT-3.5 to evaluate the discovered agents and baselines.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="GPT-3.5" target="OPENAI">
      <data key="d4">9.0</data>
      <data key="d5">OpenAI is the organization that developed GPT-3.5.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="GPT-3.5" target="ARC">
      <data key="d4">7.0</data>
      <data key="d5">GPT-3.5 is used to evaluate the performance of agents on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="GPT-3.5" target="OPENAI, 2022">
      <data key="d4">6.0</data>
      <data key="d5">OpenAI is the organization that developed GPT-3.5.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="GPT-3.5" target="ADAS">
      <data key="d4">14.0</data>
      <data key="d5">GPT-3.5 involves a complex feedback mechanism, which is relevant to the study of ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="GPT-3.5" target="ORCA-3">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3 outperformed GPT-3.5 on multiple benchmarks.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="HUMANEVAL" target="LATS">
      <data key="d4">40.0</data>
      <data key="d5">LATS achieves a 92.7 Pass@1 rate on HumanEval when used with GPT-4, setting the state of the art.
LATS sets the state of the art for HumanEval, validating its effectiveness in programming tasks.
LATS is evaluated using the HumanEval benchmark.
LATS is evaluated on the HumanEval benchmark to test its performance in reasoning and programming tasks.
LATS is evaluated using the HumanEval benchmark.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,48e423e2baf2ed485872756f5b4d87d8,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="HUMANEVAL" target="REFLEXION">
      <data key="d4">7.0</data>
      <data key="d5">Reflexion is evaluated using the HumanEval benchmark, with performance scores reported.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="HUMANEVAL" target="CHEN ET AL., 2021">
      <data key="d4">18.0</data>
      <data key="d5">Chen et al. are the authors of the HumanEval benchmark, published in 2021.
Chen et al. are the authors mentioned in relation to HumanEval.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="HUMANEVAL" target="EXPERT">
      <data key="d4">7.0</data>
      <data key="d5">Expert performance is used as a benchmark for comparison in HumanEval.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="HUMANEVAL" target="BASELINE">
      <data key="d4">7.0</data>
      <data key="d5">Baseline performance is used as a reference for evaluating new methods on the HumanEval benchmark.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="HUMANEVAL" target="REACT">
      <data key="d4">7.0</data>
      <data key="d5">ReAct is evaluated on the HumanEval benchmark to test its performance in reasoning and programming tasks.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="HUMANEVAL" target="NATURAL LANGUAGE DESCRIPTIONS">
      <data key="d4">7.0</data>
      <data key="d5">HumanEval uses natural language descriptions to describe programming tasks.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="HUMANEVAL" target="FUNCTION SIGNATURE">
      <data key="d4">7.0</data>
      <data key="d5">HumanEval includes function signatures as part of the programming problems.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="HUMANEVAL" target="DOCSTRING DESCRIPTION">
      <data key="d4">7.0</data>
      <data key="d5">HumanEval includes docstring descriptions as part of the programming problems.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="HUMANEVAL" target="REFERENCE IMPLEMENTATION">
      <data key="d4">7.0</data>
      <data key="d5">HumanEval includes reference implementations as part of the programming problems.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="HUMANEVAL" target="UNIT TESTS">
      <data key="d4">7.0</data>
      <data key="d5">HumanEval includes unit tests to verify the correctness of solutions.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="HUMANEVAL" target="PASS@K METRIC">
      <data key="d4">7.0</data>
      <data key="d5">HumanEval uses the pass@k metric to evaluate the success rate of solutions.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="HUMANEVAL" target="PROGRAMMING PROMPT">
      <data key="d4">7.0</data>
      <data key="d5">HumanEval is a benchmark used to evaluate the performance of programming tasks.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="HUMANEVAL" target="MINSUBARRAYSUM">
      <data key="d4">7.0</data>
      <data key="d5">HumanEval is a benchmark used to evaluate the performance of the minSubArraySum function.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="HUMANEVAL" target="QUESTION-ANSWERING TASK">
      <data key="d4">7.0</data>
      <data key="d5">HumanEval is a benchmark used to evaluate the performance of question-answering tasks.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="WEB SHOP" target="LATS">
      <data key="d4">16.0</data>
      <data key="d5">LATS raises the average score by 22.1 on WebShop when used with GPT-3.5.
LATS improves both score and success rate (SR) in the WebShop environment, indicating its effectiveness in complex decision-making tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="WEB SHOP" target="REACT">
      <data key="d4">6.0</data>
      <data key="d5">ReAct is used to evaluate performance in the WebShop environment.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="WEB SHOP" target="REFLEXION">
      <data key="d4">6.0</data>
      <data key="d5">Reflexion is used to evaluate performance in the WebShop environment.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="WEB SHOP" target="IL+RL">
      <data key="d4">7.0</data>
      <data key="d5">IL+RL is used to train agents in the WebShop environment, evaluated for its performance in comparison to other methods.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="WEB SHOP" target="EXPERT">
      <data key="d4">7.0</data>
      <data key="d5">Expert performance is used as a benchmark to compare the effectiveness of algorithms in the WebShop environment.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="WEB SHOP" target="SUCCESS RATE (SR)">
      <data key="d4">8.0</data>
      <data key="d5">Success rate (SR) is used as a performance metric to evaluate algorithms in the WebShop environment.
Success Rate is one of the evaluation metrics used in WebShop.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="AVERAGE SCORE">
      <data key="d4">7.0</data>
      <data key="d5">Average score is used as a performance metric to evaluate algorithms in the WebShop environment.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="WEB SHOP" target="BROWSER FEEDBACK">
      <data key="d4">6.0</data>
      <data key="d5">Browser feedback is used by agents to make decisions in the WebShop environment.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="WEB SHOP" target="SEARCH AND CLICK COMMANDS">
      <data key="d4">6.0</data>
      <data key="d5">Search and click commands are actions used by agents to navigate the WebShop environment.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="WEB SHOP" target="PRECONSTRUCTED ACTION SPACE">
      <data key="d4">6.0</data>
      <data key="d5">Preconstructed action space refers to the predefined set of actions available to agents in the WebShop environment.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="WEB SHOP" target="YA0 ET AL., 2022">
      <data key="d4">6.0</data>
      <data key="d5">Yao et al. are the authors of the WebShop environment.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="TASK SCORE">
      <data key="d4">7.0</data>
      <data key="d5">Task Score is one of the evaluation metrics used in WebShop.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="HTML MODE">
      <data key="d4">6.0</data>
      <data key="d5">HTML mode is a rendering mode in WebShop.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="SIMPLE MODE">
      <data key="d4">6.0</data>
      <data key="d5">Simple mode is a rendering mode in WebShop.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="QUERY SEARCHES">
      <data key="d4">7.0</data>
      <data key="d5">Query searches are actions in WebShop.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="BUTTON CLICKS">
      <data key="d4">7.0</data>
      <data key="d5">Button clicks are actions in WebShop.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="LEXICAL MATCHING">
      <data key="d4">6.0</data>
      <data key="d5">Lexical matching is a method used in WebShop to compare products.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="SEMANTIC SIMILARITY METRICS">
      <data key="d4">6.0</data>
      <data key="d5">Semantic similarity metrics are methods used in WebShop to compare products.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="EPISODE">
      <data key="d4">6.0</data>
      <data key="d5">An episode is a complete interaction session in WebShop.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="SEARCH PAGE">
      <data key="d4">6.0</data>
      <data key="d5">The search page is a component of WebShop.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="RESULTS PAGE">
      <data key="d4">6.0</data>
      <data key="d5">The results page is a component of WebShop.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="ITEM PAGE">
      <data key="d4">6.0</data>
      <data key="d5">The item page is a component of WebShop.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="ITEM DETAIL PAGE">
      <data key="d4">1.0</data>
      <data key="d5">The item detail page is a component of WebShop.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="WEB SHOP" target="RESULTS">
      <data key="d4">8.0</data>
      <data key="d5">The web shop returns a list of results in response to a user's query.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="WEB SHOP" target="DAIRY FREE">
      <data key="d4">24.0</data>
      <data key="d5">The web shop allows users to search for products with specific attributes like being dairy-free
The web shop allows users to search for products with specific attributes like being dairy-free</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="WEB SHOP" target="APPLE VARIETY PACK OF CHIPS">
      <data key="d4">24.0</data>
      <data key="d5">The web shop allows users to search for specific products like an apple variety pack of chips
The web shop allows users to search for specific products like an apple variety pack of chips</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="WEB SHOP" target="PRICE LOWER THAN 30.00 DOLLARS">
      <data key="d4">24.0</data>
      <data key="d5">The web shop allows users to set price constraints for their searches
The web shop allows users to set price constraints for their searches</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="WEB SHOP" target="GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON">
      <data key="d4">16.0</data>
      <data key="d5">The web shop allows users to search for specific products like gluten-free vegetarian smoked peppered bacon</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="WEB SHOP" target="PRICE LOWER THAN 40.00 DOLLARS">
      <data key="d4">16.0</data>
      <data key="d5">The web shop allows users to set price constraints for their searches</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="WEB SHOP" target="SEARCH">
      <data key="d4">18.0</data>
      <data key="d5">The user performs a search action on the web shop</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="WEB SHOP" target="THINK">
      <data key="d4">16.0</data>
      <data key="d5">The user reflects on the suitability of products found on the web shop</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="WEB SHOP" target="CLICK">
      <data key="d4">18.0</data>
      <data key="d5">The user clicks on products or options on the web shop</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="WEB SHOP" target="REFLECTION">
      <data key="d4">9.0</data>
      <data key="d5">The user reflects on their previous actions and outcomes to improve future searches on the web shop</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ANDY ZHOU" target="UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN">
      <data key="d4">12.0</data>
      <data key="d5">Andy Zhou is affiliated with the University of Illinois Urbana-Champaign.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="ANDY ZHOU" target="LAPIS LABS">
      <data key="d4">12.0</data>
      <data key="d5">Andy Zhou is affiliated with Lapis Labs.</data>
      <data key="d6">93cb0d0456e0822b5fe30a3e627405f8</data>
    </edge>
    <edge source="REACT" target="YA0 ET AL., 2023B">
      <data key="d4">42.0</data>
      <data key="d5">Yao et al. are the authors of the ReAct algorithm, published in 2023.
Yao et al. are the researchers who developed the ReAct algorithm in 2023.
Yao et al. are the authors mentioned in relation to the ReAct algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,93cb0d0456e0822b5fe30a3e627405f8,c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="REACT" target="LATS">
      <data key="d4">38.0</data>
      <data key="d5">LATS outperforms ReAct on benchmarks like HotPotQA and WebShop.
LATS surpasses ReAct by expanding more nodes with principled search and incorporating external feedback.
LATS uses ReAct as a base prompt in various experiments, showing improved performance over ReAct alone.
LATS is compared to ReAct in terms of performance, sample complexity, and token consumption.
LATS is compared to ReAct in terms of computational cost and efficiency.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="REACT" target="YAO ET AL., 2023B">
      <data key="d4">12.0</data>
      <data key="d5">Yao et al. are the authors of the ReAct algorithm, published in 2023.
Yao et al. are the authors of the ReAct method, published in 2023.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="REACT" target="ACTING-BASED PROMPTING">
      <data key="d4">7.0</data>
      <data key="d5">ReAct is an example of acting-based prompting used in language models.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="REACT" target="COT">
      <data key="d4">14.0</data>
      <data key="d5">ReAct and CoT are both prompting techniques used for reasoning tasks in language models.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="REACT" target="REFLEXION">
      <data key="d4">7.0</data>
      <data key="d5">Both ReAct and Reflexion focus on decision-making tasks where reverting between iterations is feasible.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REACT" target="LANGUAGE MODELS (LM)">
      <data key="d4">8.0</data>
      <data key="d5">ReAct is a technique used to extend the capabilities of language models to tasks requiring interactions with an external environment.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REACT" target="ENVIRONMENTAL FEEDBACK">
      <data key="d4">9.0</data>
      <data key="d5">ReAct uses observations from the environment to improve reasoning and acting.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REACT" target="DECISION-MAKING TASKS">
      <data key="d4">8.0</data>
      <data key="d5">ReAct is used for decision-making tasks that require interactions with an external environment.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REACT" target="WEI ET AL., 2022">
      <data key="d4">6.0</data>
      <data key="d5">Wei et al. are the authors of the ReAct method, published in 2022.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="REACT" target="ACTING-BASED METHODS">
      <data key="d4">8.0</data>
      <data key="d5">ReAct is an acting-based method that combines reasoning and acting for better performance.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="REACT" target="HOT POT QA">
      <data key="d4">6.0</data>
      <data key="d5">ReAct is used as a base prompt in HotPotQA experiments.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="REACT" target="YAO ET AL., 2022">
      <data key="d4">6.0</data>
      <data key="d5">Yao et al. are the authors of studies involving the ReAct algorithm.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="REACT" target="TOT">
      <data key="d4">7.0</data>
      <data key="d5">ToT is a variant of ReAct used for reasoning, acting, and planning in language models.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="REACT" target="COT-SC">
      <data key="d4">6.0</data>
      <data key="d5">ReAct and CoT-SC are both methods evaluated for performance, sample complexity, and token consumption.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="REACT" target="PROMPTING TECHNIQUES">
      <data key="d4">7.0</data>
      <data key="d5">ReAct is a type of prompting technique used for language models.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="OPENAI, 2023" target="DROP">
      <data key="d4">7.0</data>
      <data key="d5">OpenAI is mentioned in the context of the practice followed for one-shot style questions in DROP.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="COBBE ET AL., 2021" target="CHAIN-OF-THOUGHT (COT) PROMPTING">
      <data key="d4">6.0</data>
      <data key="d5">Cobbe et al. are researchers who have contributed to the understanding of reasoning in language models, published in 2021.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="COBBE ET AL., 2021" target="GSM8K">
      <data key="d4">20.0</data>
      <data key="d5">Cobbe et al. discussed the GSM8K math task benchmark in 2021.
Cobbe et al. are the authors of the GSM8K dataset used to evaluate the transferability of discovered agents.
Cobbe et al. are the authors of the GSM8K dataset, published in 2021.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="COBBE ET AL., 2021" target="GSM8K (COBBE ET AL., 2021)">
      <data key="d4">6.0</data>
      <data key="d5">Cobbe et al. are the authors of the GSM8K benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="YAO ET AL., 2022" target="IL+RL">
      <data key="d4">6.0</data>
      <data key="d5">Yao et al. are the authors of studies involving the IL+RL method.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="SCHICK ET AL., 2023" target="EXTERNAL TOOLS">
      <data key="d4">7.0</data>
      <data key="d5">Schick et al. contributed to the development of external tools for language models in 2023.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="SCHICK ET AL., 2023" target="TOOL USE">
      <data key="d4">12.0</data>
      <data key="d5">Schick et al. are cited in the paper for contributions to the research on tool use in agentic systems.
Schick et al. are the authors who contributed to the development of tool use techniques, published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="FAN ET AL., 2022" target="MINECRAFT">
      <data key="d4">6.0</data>
      <data key="d5">Fan et al. are researchers who have worked on complex multimodal games like Minecraft, published in 2022.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="SHINN ET AL., 2023" target="REFLEXION">
      <data key="d4">36.0</data>
      <data key="d5">Shinn et al. are researchers who have developed the Reflexion algorithm, published in 2023.
Shinn et al. are the researchers who developed the Reflexion algorithm in 2023.
Shinn et al. are the authors of the Reflexion algorithm, published in 2023.
Shinn et al. are the authors of the Reflexion algorithm, published in 2023.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="SHINN ET AL., 2023" target="SELF-REFLECTION">
      <data key="d4">7.0</data>
      <data key="d5">Shinn et al. are cited in the paper for contributions to the research on self-reflection in agentic systems.
Shinn et al. contributed to the process of self-reflection to make the generated agent novel and error-free.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SHINN ET AL., 2023" target="SELF-REFINE">
      <data key="d4">13.0</data>
      <data key="d5">Shinn et al. are the authors of the Self-Refine strategy used in Meta Agent Search.
Shinn et al. are the researchers who contributed to the development of the Self-Refine method in 2023.
Shinn et al. are the authors of the Self-Refine algorithm.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="SHINN ET AL., 2023" target="REFLECTION">
      <data key="d4">6.0</data>
      <data key="d5">Shinn et al. are the authors who contributed to the development of reflection techniques, published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="YAO ET AL., 2023A" target="TOT">
      <data key="d4">6.0</data>
      <data key="d5">Yao et al. are the authors of the ToT method, published in 2023.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="HAO ET AL., 2023" target="REASONING VIA PLANNING (RAP)">
      <data key="d4">6.0</data>
      <data key="d5">Hao et al. are researchers who have developed reasoning via planning (RAP) using MCTS, published in 2023.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="HAO ET AL., 2023" target="RAP">
      <data key="d4">15.0</data>
      <data key="d5">Hao et al. developed the RAP technique.
Hao et al. are the authors of the RAP algorithm, published in 2023.
Hao et al. are the authors mentioned in relation to the RAP algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,9bb90746134619cad9a3e649b8b35f24,c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="SELF-REFLECTION">
      <data key="d4">47.0</data>
      <data key="d5">LATS incorporates self-reflection to improve decision-making and problem-solving capabilities.
LATS incorporates self-reflection to improve reasoning and decision-making.
LATS uses self-reflection to provide additional semantic signals, improving its performance in reasoning tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="SELF-CONSISTENCY">
      <data key="d4">7.0</data>
      <data key="d5">LATS uses self-consistency to enhance performance by employing majority voting over sampled chains.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="SEARCH ALGORITHMS">
      <data key="d4">9.0</data>
      <data key="d5">LATS adapts search algorithms to enhance language model performance.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="PROMPTS">
      <data key="d4">8.0</data>
      <data key="d5">LATS uses prompts to guide the generation of responses and store external feedback.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="VALUE FUNCTION">
      <data key="d4">23.0</data>
      <data key="d5">LATS uses a novel value function to guide the search process and incorporate successful heuristics.
The value function in LATS incorporates self-consistency, contributing to its superior performance in reasoning tasks.
LATS uses a value function as a main component to leverage external feedback.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,f8e7ed806916bf15245bcb4d52570c26,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="SELF-REFINEMENT">
      <data key="d4">8.0</data>
      <data key="d5">LATS uses self-refinement to improve performance by learning from its own outputs.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="INTERNAL REASONING PERFORMANCE">
      <data key="d4">7.0</data>
      <data key="d5">LATS aims to surpass internal reasoning performance by incorporating external feedback.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="MODEL-BASED REINFORCEMENT LEARNING">
      <data key="d4">7.0</data>
      <data key="d5">LATS is inspired by the success of model-based reinforcement learning techniques.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="IN-CONTEXT LEARNING">
      <data key="d4">36.0</data>
      <data key="d5">LATS leverages the in-context learning capabilities of modern language models.
LATS leverages the in-context learning abilities of language models.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="AUTONOMOUS REASONING">
      <data key="d4">8.0</data>
      <data key="d5">LATS enhances the autonomous reasoning capabilities of language models.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="DECISION-MAKING">
      <data key="d4">9.0</data>
      <data key="d5">LATS improves decision-making in language models by incorporating reasoning, acting, and planning.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="TEXT-BASED ENVIRONMENTS">
      <data key="d4">7.0</data>
      <data key="d5">LATS enhances performance in text-based environments.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LATS" target="TREE-BASED SEARCH">
      <data key="d4">16.0</data>
      <data key="d5">LATS operates on a tree-based framework to unlock the potential of language models.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LATS" target="OURS">
      <data key="d4">12.0</data>
      <data key="d5">Ours refers to the authors of the Language Agent Tree Search (LATS) algorithm.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LATS" target="REASONING">
      <data key="d4">54.0</data>
      <data key="d5">LATS unifies reasoning, acting, and planning in language models.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LATS" target="ACTING">
      <data key="d4">54.0</data>
      <data key="d5">LATS unifies reasoning, acting, and planning in language models.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LATS" target="PLANNING">
      <data key="d4">54.0</data>
      <data key="d5">LATS unifies reasoning, acting, and planning in language models.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LATS" target="EXTERNAL MEMORY">
      <data key="d4">28.0</data>
      <data key="d5">LATS uses external memory to store past text context for future updates of the solution.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LATS" target="SEARCH ALGORITHM">
      <data key="d4">32.0</data>
      <data key="d5">LATS uses a search algorithm to determine a sequence of actions or decisions.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="LATS" target="LANGUAGE MODELS (LM)">
      <data key="d4">8.0</data>
      <data key="d5">LATS is a technique developed to address the shortcomings of existing prompting techniques in language models.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="LATS" target="MCTS">
      <data key="d4">16.0</data>
      <data key="d5">LATS adapts MCTS for language agents, leveraging language models for planning and decision-making.
LATS uses MCTS as a search algorithm, leading to observed performance gains over other search variants.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="LM">
      <data key="d4">17.0</data>
      <data key="d5">LATS uses language models (LMs) as agents, state evaluators, and feedback generators.
LATS leverages LM capabilities for decision-making tasks.</data>
      <data key="d6">c234cb83764b899335af0950677ad024,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="COT">
      <data key="d4">15.0</data>
      <data key="d5">CoT is used as the base prompting framework in LATS for reasoning tasks without feedback.
LATS uses a CoT-based prompt initially before switching to a ReAct-based prompt upon failure, combining internal and external reasoning.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc,c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="P&#920;">
      <data key="d4">8.0</data>
      <data key="d5">P&#952; is the probabilistic model used within LATS to sample actions and generate language representations.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="SELECTION">
      <data key="d4">13.0</data>
      <data key="d5">Selection is the first operation in the LATS algorithm.
Selection is used to choose the most promising nodes to expand in LATS.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="EXPANSION">
      <data key="d4">7.0</data>
      <data key="d5">Expansion is the second operation in the LATS algorithm.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="SIMULATION">
      <data key="d4">7.0</data>
      <data key="d5">Simulation is an operation in the LATS algorithm.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="BACKPROPAGATION">
      <data key="d4">13.0</data>
      <data key="d5">Backpropagation is an operation in the LATS algorithm.
Backpropagation is used to update the search tree in LATS.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="REFLECTION">
      <data key="d4">7.0</data>
      <data key="d5">Reflection is an operation in the LATS algorithm.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="INITIAL STATE">
      <data key="d4">15.0</data>
      <data key="d5">The initial state is the starting point of the search tree in LATS.
Initial state refers to the starting point or configuration from which the LATS algorithm begins its search process.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8,c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="ROOT NODE">
      <data key="d4">7.0</data>
      <data key="d5">The root node represents the initial state in the LATS search tree.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="LEAF NODE">
      <data key="d4">7.0</data>
      <data key="d5">A leaf node represents a terminal state or end of a trajectory in the LATS search tree.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="CHILD NODE">
      <data key="d4">7.0</data>
      <data key="d5">A child node represents a subsequent state in the LATS search tree.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="LONG-TERM MEMORY STRUCTURE">
      <data key="d4">7.0</data>
      <data key="d5">Long-term memory structure is used to store the expanded search tree in LATS.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="SCALAR VALUE">
      <data key="d4">7.0</data>
      <data key="d5">Scalar value is assigned to each node during the evaluation process in LATS.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="HEURISTIC">
      <data key="d4">13.0</data>
      <data key="d5">Heuristic is used to guide the search algorithm in LATS.
Heuristic methods guide the search process in LATS.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="LM SCORE">
      <data key="d4">7.0</data>
      <data key="d5">LM score is part of the value function in LATS.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LATS" target="TOT">
      <data key="d4">22.0</data>
      <data key="d5">LATS outperforms ToT by expanding more nodes and incorporating external feedback.
LATS is compared to ToT in terms of performance, sample complexity, and token consumption.
LATS has the same sample complexity as ToT but achieves better performance and efficiency.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,99d90aededb61e04241516ed9ec656cc,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="RAP">
      <data key="d4">22.0</data>
      <data key="d5">LATS outperforms RAP by expanding more nodes and incorporating external feedback.
LATS is compared to RAP in terms of performance, sample complexity, and token consumption.
LATS has the same sample complexity as RAP but achieves better performance and efficiency.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,99d90aededb61e04241516ed9ec656cc,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="MBPP">
      <data key="d4">9.0</data>
      <data key="d5">LATS achieves the highest performance on MBPP for programming tasks.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="LATS" target="REFLEXION">
      <data key="d4">14.0</data>
      <data key="d5">LATS shows improved performance over Reflexion in complex environments like WebShop, indicating more effective exploration.
LATS is compared to Reflexion in terms of computational cost and efficiency.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7,594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="GAME OF 24">
      <data key="d4">16.0</data>
      <data key="d5">LATS outperforms previous methods in the Game of 24, demonstrating its superior reasoning ability.
LATS is evaluated in the Game of 24, a mathematical reasoning challenge.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="LATS" target="HOT POT QA">
      <data key="d4">8.0</data>
      <data key="d5">LATS shows improved performance in HotPotQA, validating the effectiveness of its components.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="DFS">
      <data key="d4">6.0</data>
      <data key="d5">LATS experiments include DFS as a variant to observe its effects on performance.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="PROMPTING">
      <data key="d4">6.0</data>
      <data key="d5">LATS uses prompting methods to guide language models like GPT-3.5 in various tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="RL-BASED TRAINING">
      <data key="d4">7.0</data>
      <data key="d5">LATS surpasses RL-based training in performance metrics like score and success rate (SR) in environments like WebShop.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="IMPROVEMENT">
      <data key="d4">15.0</data>
      <data key="d5">LATS shows noticeable improvement in performance metrics.LATS shows noticeable improvement in performance metrics across various tasks and environments.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="TOKEN CONSUMPTION">
      <data key="d4">19.0</data>
      <data key="d5">LATS experiments include ablations for token consumption to evaluate efficiency.Token consumption is evaluated for efficiency in LATS experiments.
LATS is evaluated for token consumption compared to other methods.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="SEMANTIC FEEDBACK">
      <data key="d4">12.0</data>
      <data key="d5">Semantic feedback is used to improve performance in LATS.LATS uses semantic feedback to improve performance, although it may not be as effective in complex environments like WebShop.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="LOCAL MINIMA">
      <data key="d4">12.0</data>
      <data key="d5">LATS addresses the challenge of local minima observed in Reflexion, leading to more effective exploration.LATS addresses the challenge of local minima during exploration.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="EXPLORATION">
      <data key="d4">13.0</data>
      <data key="d5">LATS uses effective exploration techniques to improve performance in various tasks.Exploration is a key component in LATS for finding optimal solutions.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="ITERATIONS">
      <data key="d4">13.0</data>
      <data key="d5">LATS shows performance improvement for the same number of iterations compared to other methods.Iterations are used as a metric to evaluate the performance of LATS.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="SUCCESS RATE">
      <data key="d4">15.0</data>
      <data key="d5">LATS improves the success rate (SR) in tasks like WebShop, indicating its effectiveness.LATS improves the success rate in various tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="SCORE">
      <data key="d4">9.0</data>
      <data key="d5">LATS improves the score in tasks like WebShop, indicating its effectiveness.LATS improves the score in various tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="TRAJECTORIES">
      <data key="d4">14.0</data>
      <data key="d5">Trajectories are paths taken by agents during the exploration process in LATS.
LATS constructs trajectories with search algorithms for decision-making tasks.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="CHILDREN">
      <data key="d4">6.0</data>
      <data key="d5">Children are expanded nodes in the search tree during the exploration process in LATS.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="PRUNING">
      <data key="d4">6.0</data>
      <data key="d5">Pruning removes low-value branches from the search tree in LATS.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="LATS" target="SAMPLE COMPLEXITY">
      <data key="d4">7.0</data>
      <data key="d5">LATS is evaluated for sample complexity compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="NODES EXPANDED">
      <data key="d4">7.0</data>
      <data key="d5">LATS is evaluated for the number of nodes expanded compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="REVERSION PROPERTY">
      <data key="d4">7.0</data>
      <data key="d5">LATS assumes the ability to revert to earlier states in decision-making environments.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="SYSTEM-2 LM APPROACHES">
      <data key="d4">1.0</data>
      <data key="d5">LATS is an example of a System-2 LM approach that involves complex reasoning and decision-making.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="PERFORMANCE">
      <data key="d4">8.0</data>
      <data key="d5">LATS is evaluated for its performance compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="COMPUTATIONAL COST">
      <data key="d4">7.0</data>
      <data key="d5">LATS is evaluated for its computational cost compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="GROUND-TRUTH FEEDBACK">
      <data key="d4">8.0</data>
      <data key="d5">LATS benefits from ground-truth feedback to improve performance.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="INFERENCE-TIME COMPUTE COSTS">
      <data key="d4">7.0</data>
      <data key="d5">LATS is evaluated for inference-time compute costs compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="TRADE-OFF BETWEEN PERFORMANCE AND EFFICIENCY">
      <data key="d4">7.0</data>
      <data key="d5">LATS provides a trade-off between performance and efficiency.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="AUTONOMOUS DECISION-MAKING">
      <data key="d4">8.0</data>
      <data key="d5">LATS enables autonomous decision-making for language models.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="PROMPTING TECHNIQUES">
      <data key="d4">7.0</data>
      <data key="d5">LATS addresses limitations of prior prompting techniques.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="REASONING ABILITY">
      <data key="d4">8.0</data>
      <data key="d5">LATS maintains reasoning ability without additional training.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="DECISION-MAKING TASKS">
      <data key="d4">8.0</data>
      <data key="d5">LATS harnesses LM capabilities for various decision-making tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="EXPERIENCE LEARNING">
      <data key="d4">8.0</data>
      <data key="d5">LATS enables agents to learn from experience to improve performance.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="SYSTEM-2 LM">
      <data key="d4">1.0</data>
      <data key="d5">LATS is an example of a System-2 LM approach that involves complex reasoning and decision-making.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LATS" target="WEBSHOP">
      <data key="d4">7.0</data>
      <data key="d5">LATS is evaluated using the WebShop environment.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="MONTE CARLO TREE SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">LATS uses Monte Carlo Tree Search for decision-making tasks.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="COT-SC">
      <data key="d4">7.0</data>
      <data key="d5">LATS is compared to CoT-SC in terms of efficiency when the number of nodes is set to one.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="MINECRAFT">
      <data key="d4">6.0</data>
      <data key="d5">Minecraft is mentioned as a potential environment for future work using LATS.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="ALFWORLD">
      <data key="d4">6.0</data>
      <data key="d5">Alfworld is an environment used to evaluate LATS.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="TOOLBENCH">
      <data key="d4">6.0</data>
      <data key="d5">ToolBench is an environment used to evaluate LATS.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LATS" target="EXPLORATION WEIGHT">
      <data key="d4">9.0</data>
      <data key="d5">Exploration weight is a parameter in the LATS algorithm that affects its search effectiveness and performance.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="DEPTH">
      <data key="d4">9.0</data>
      <data key="d5">Depth is a parameter in the LATS algorithm that determines the maximum number of steps in the search process, affecting its performance.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="LM VALUE FUNCTION">
      <data key="d4">9.0</data>
      <data key="d5">The LM value function is a component of the LATS algorithm that scores states based on expected future rewards, guiding the search process.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="WIKIPEDIA WEB API">
      <data key="d4">8.0</data>
      <data key="d5">The Wikipedia web API is used in the LATS algorithm for interactive information retrieval, supporting actions like searching for entities and looking up strings.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="SAMPLING SIZE">
      <data key="d4">9.0</data>
      <data key="d5">Sampling size is a parameter in the LATS algorithm that determines the number of samples or trajectories to be considered during the search process.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="STATE SPACE">
      <data key="d4">8.0</data>
      <data key="d5">State space refers to the set of all possible states or configurations that the LATS algorithm can explore during the search process.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="VALUE FUNCTION WEIGHT">
      <data key="d4">9.0</data>
      <data key="d5">Value function weight is a parameter in the LATS algorithm that balances the contributions of different components in the value function.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="ACTION GENERATOR">
      <data key="d4">9.0</data>
      <data key="d5">Action generator is a component in the LATS algorithm that generates possible actions based on the current state.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="REFLECTION GENERATOR">
      <data key="d4">9.0</data>
      <data key="d5">Reflection generator is a component in the LATS algorithm that generates reflections or adjustments based on the current context and state.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="VISIT COUNTER">
      <data key="d4">8.0</data>
      <data key="d5">Visit counter is a component in the LATS algorithm that keeps track of the number of times each state has been visited during the search process.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="ROLL-OUTS">
      <data key="d4">8.0</data>
      <data key="d5">Roll-outs refer to the process of simulating future actions and states to evaluate their potential outcomes in the LATS algorithm.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="CONTEXT">
      <data key="d4">8.0</data>
      <data key="d5">Context refers to the additional information or conditions that influence the search process in the LATS algorithm.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="TERMINAL STATE">
      <data key="d4">8.0</data>
      <data key="d5">Terminal state refers to a state in the search process where no further actions can be taken, often indicating the end of a trajectory.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="ENVIRONMENT REWARDS">
      <data key="d4">8.0</data>
      <data key="d5">Environment rewards are the feedback or scores received from the environment based on the actions taken and states reached during the search process.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="LATS" target="MOSTLY BASIC PROGRAMMING PROBLEMS (MBPP)">
      <data key="d4">7.0</data>
      <data key="d5">LATS is evaluated using the MBPP benchmark.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="LATS" target="VALUE FUNCTION HYPERPARAMETERS">
      <data key="d4">15.0</data>
      <data key="d5">LATS uses value function hyperparameters to configure its evaluation function.
LATS uses value function hyperparameters like &#955; for the LM score and self-consistency score.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9,fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="LATS" target="SELF-CONSISTENCY SCORE">
      <data key="d4">8.0</data>
      <data key="d5">The self-consistency score improves the performance of LATS.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="SELF-REFLECTION" target="UNIT TEST RESULTS">
      <data key="d4">8.0</data>
      <data key="d5">Self-reflection involves analyzing unit test results to identify errors in the function implementation.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="SELF-REFLECTION" target="IMPROVED IMPLEMENTATION">
      <data key="d4">8.0</data>
      <data key="d5">Self-reflection guides the creation of an improved implementation by identifying and addressing errors.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="SELF-REFLECTION" target="REFLECTION PROMPT">
      <data key="d4">7.0</data>
      <data key="d5">The reflection prompt instructs the AI assistant to perform self-reflection on the function implementation.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="SELF-REFLECTION" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">7.0</data>
      <data key="d5">Self-Reflection is a technique used as a building block in agentic systems within the ADAS research area.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SELF-REFLECTION" target="MADAAN ET AL., 2024">
      <data key="d4">12.0</data>
      <data key="d5">Madaan et al. are cited in the paper for contributions to the research on self-reflection in agentic systems.
Madaan et al. contributed to the process of self-reflection to make the generated agent novel and error-free.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SELF-REFLECTION" target="META AGENT">
      <data key="d4">9.0</data>
      <data key="d5">The meta agent performs self-reflection to review its proposed architecture and implementation, identify mistakes, and suggest improvements.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="IMPLEMENTATION MISTAKES">
      <data key="d4">8.0</data>
      <data key="d5">During self-reflection, the meta agent identifies and corrects implementation mistakes.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="IMPROVEMENT">
      <data key="d4">8.0</data>
      <data key="d5">During self-reflection, the meta agent suggests and implements improvements to the proposed architecture.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="WRONG IMPLEMENTATION EXAMPLES">
      <data key="d4">8.0</data>
      <data key="d5">During self-reflection, the meta agent uses wrong implementation examples to identify and correct mistakes.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="SELF-REFLECTION ROUND 1">
      <data key="d4">8.0</data>
      <data key="d5">Self-reflection includes a first round where the meta agent reviews the proposed architecture and implementation.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="SELF-REFLECTION ROUND 2">
      <data key="d4">8.0</data>
      <data key="d5">Self-reflection includes a second round where the meta agent further revises the code.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="RUNTIME ERROR">
      <data key="d4">8.0</data>
      <data key="d5">Self-reflection is performed when a runtime error is encountered during the execution of the generated code.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="SELF-REFLECTION" target="FM MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The Self-Reflection method is implemented using the FM Module to improve task performance based on previous attempts and feedback.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="SELF-REFLECTION" target="COT_INITIAL_INSTRUCTION">
      <data key="d4">7.0</data>
      <data key="d5">The self-reflection method uses cot_initial_instruction for initial reasoning.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="SELF-REFLECTION" target="COT_REFLECT_INSTRUCTION">
      <data key="d4">7.0</data>
      <data key="d5">The self-reflection method uses cot_reflect_instruction for reflecting on previous attempts and feedback.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="SELF-REFLECTION" target="CRITIC INSTRUCTION">
      <data key="d4">1.0</data>
      <data key="d5">The self-reflection method uses critic_instruction for providing feedback and correcting the answer.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="SELF-CONSISTENCY" target="CHAIN-OF-THOUGHT (COT) PROMPTING">
      <data key="d4">6.0</data>
      <data key="d5">Self-consistency is a technique used to mitigate error propagation in chain-of-thought prompting.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="SELF-CONSISTENCY" target="WANG ET AL., 2022">
      <data key="d4">6.0</data>
      <data key="d5">Wang et al. are researchers who have contributed to the development of self-consistency, published in 2022.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="SELF-CONSISTENCY" target="MAJORITY VOTING">
      <data key="d4">7.0</data>
      <data key="d5">Self-consistency employs majority voting over sampled chains to reduce errors.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="TREE-OF-THOUGHT (TOT) PROMPTING">
      <data key="d4">14.0</data>
      <data key="d5">Both are techniques used for decomposing complex inputs into sequential steps in reasoning tasks.
ToT prompting extends CoT prompting by exploring multiple reasoning paths over thoughts.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="REASONING VIA PLANNING (RAP)">
      <data key="d4">6.0</data>
      <data key="d5">Both are techniques used for reasoning tasks, with RAP using MCTS for planning.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="WEI ET AL., 2022">
      <data key="d4">6.0</data>
      <data key="d5">Wei et al. are researchers who have contributed to the development of chain-of-thought prompting and its variants, published in 2022.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="KOJIMA ET AL., 2022">
      <data key="d4">6.0</data>
      <data key="d5">Kojima et al. are researchers who have contributed to the development of chain-of-thought prompting variants, published in 2022.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="CHAIN-OF-THOUGHT (COT) PROMPTING VARIANTS">
      <data key="d4">6.0</data>
      <data key="d5">Variants of CoT prompting build on the original technique to improve reasoning in language models.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="ERROR PROPAGATION">
      <data key="d4">14.0</data>
      <data key="d5">CoT prompting often suffers from error propagation as the number of steps increases.
CoT prompting can lead to error propagation due to reliance on internal representations.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="LANGUAGE MODELS (LM)">
      <data key="d4">8.0</data>
      <data key="d5">CoT prompting is a technique used to improve the performance of language models on intricate tasks.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="THOUGHTS Z">
      <data key="d4">9.0</data>
      <data key="d5">CoT prompting generates intermediate thoughts z to bridge the gap between input x and output y.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="PERFORMANCE CEILING">
      <data key="d4">7.0</data>
      <data key="d5">CoT prompting has a performance ceiling due to reliance on internal representations.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT (COT) PROMPTING" target="FACT HALLUCINATION">
      <data key="d4">7.0</data>
      <data key="d5">CoT prompting can lead to fact hallucination due to reliance on internal representations.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="TREE-OF-THOUGHT (TOT) PROMPTING" target="DEPTH-FIRST SEARCH (DFS)">
      <data key="d4">14.0</data>
      <data key="d5">ToT prompting uses depth-first search to sample trajectories in reasoning tasks.
DFS is a search algorithm used to explore the tree in ToT prompting.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="TREE-OF-THOUGHT (TOT) PROMPTING" target="BREADTH-FIRST SEARCH (BFS)">
      <data key="d4">14.0</data>
      <data key="d5">ToT prompting uses breadth-first search to sample trajectories in reasoning tasks.
BFS is a search algorithm used to explore the tree in ToT prompting.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="TREE-OF-THOUGHT (TOT) PROMPTING" target="LANGUAGE MODELS (LM)">
      <data key="d4">8.0</data>
      <data key="d5">ToT prompting is a technique used to improve the performance of language models by exploring multiple reasoning paths.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="TREE-OF-THOUGHT (TOT) PROMPTING" target="HEURISTICS">
      <data key="d4">8.0</data>
      <data key="d5">Heuristics are used to guide search algorithms in exploring the tree of thoughts in ToT prompting.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="TREE-OF-THOUGHT (TOT) PROMPTING" target="THOUGHTS Z">
      <data key="d4">9.0</data>
      <data key="d5">ToT prompting generates multiple reasoning paths over thoughts z.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="TREE-OF-THOUGHT (TOT) PROMPTING" target="PROPOSAL">
      <data key="d4">8.0</data>
      <data key="d5">ToT prompting uses proposal to generate thoughts zi.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="TREE-OF-THOUGHT (TOT) PROMPTING" target="SAMPLING">
      <data key="d4">8.0</data>
      <data key="d5">ToT prompting uses sampling to generate thoughts zi.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="TREE-OF-THOUGHT (TOT) PROMPTING" target="TRIAL AND ERROR">
      <data key="d4">6.0</data>
      <data key="d5">ToT prompting is limited in its ability to learn from trial and error.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REASONING VIA PLANNING (RAP)" target="ROLL-OUTS">
      <data key="d4">7.0</data>
      <data key="d5">RAP uses roll-outs simulated by language models for planning and reasoning.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="YAO ET AL., 2023B" target="WIKIPEDIA WEB API">
      <data key="d4">1.0</data>
      <data key="d5">Yao et al. are the authors who proposed the Wikipedia web API used in the LATS algorithm.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="WEI ET AL., 2022" target="COT">
      <data key="d4">6.0</data>
      <data key="d5">Wei et al. are the authors of the CoT method, published in 2022.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="WEI ET AL., 2022" target="CHAIN-OF-THOUGHT">
      <data key="d4">25.0</data>
      <data key="d5">Wei et al. are cited in the paper for contributions to the research on chain-of-thought planning and reasoning.
Wei et al. are the authors of the Chain-of-Thought algorithm.
Wei et al. are the authors of the Chain-of-Thought algorithm, published in 2022.
Wei et al. are the authors of research on Chain-of-Thought, published in 2022.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="WEI ET AL., 2022" target="CHAIN-OF-THOUGHT (COT)">
      <data key="d4">12.0</data>
      <data key="d5">Wei et al. are the researchers who developed the Chain-of-Thought (COT) method in 2022.
Wei et al. are the authors of the Chain-of-Thought (COT) algorithm.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="WEI ET AL., 2022" target="CHAIN-OF-THOUGHT (WEI ET AL., 2022)">
      <data key="d4">6.0</data>
      <data key="d5">Wei et al. are the authors of the Chain-of-Thought algorithm.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="WANG ET AL., 2022" target="COT-SC">
      <data key="d4">2.0</data>
      <data key="d5">Wang et al. are the authors mentioned in relation to the CoT-SC algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="GUO ET AL., 2018" target="ERROR PROPAGATION">
      <data key="d4">6.0</data>
      <data key="d5">Guo et al. are researchers who have studied error propagation in reasoning tasks, published in 2018.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHEN ET AL., 2023B" target="ERROR PROPAGATION">
      <data key="d4">6.0</data>
      <data key="d5">Chen et al. are researchers who have studied error propagation in reasoning tasks, published in 2023.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="CHEN ET AL., 2023B" target="AGENTVERSE">
      <data key="d4">12.0</data>
      <data key="d5">Chen et al. are the authors of the AgentVerse algorithm.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ZHOU ET AL., 2022" target="LEAST-TO-MOST PROMPTING">
      <data key="d4">6.0</data>
      <data key="d5">Zhou et al. are researchers who have developed least-to-most prompting for multi-step decomposition in reasoning tasks, published in 2022.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="BESTA ET AL., 2023" target="SEARCH ALGORITHMS">
      <data key="d4">6.0</data>
      <data key="d5">Besta et al. are researchers who have contributed to the development of search algorithms for chain-of-thought prompting, published in 2023.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MADAAN ET AL., 2023" target="SELF-REFINE">
      <data key="d4">24.0</data>
      <data key="d5">Madaan et al. are researchers who have developed self-refine techniques for improving language model performance, published in 2023.
Madaan et al. are the researchers who developed the Self-Refine algorithm in 2023.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6,f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="AHN ET AL., 2022" target="HIGH-LEVEL CONTROLLERS">
      <data key="d4">6.0</data>
      <data key="d5">Ahn et al. are researchers who have employed language models as high-level controllers in robotics, published in 2022.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="HUANG ET AL., 2022" target="HIGH-LEVEL CONTROLLERS">
      <data key="d4">6.0</data>
      <data key="d5">Huang et al. are researchers who have employed language models as high-level controllers in robotics, published in 2022.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="DRIESS ET AL., 2023" target="HIGH-LEVEL CONTROLLERS">
      <data key="d4">6.0</data>
      <data key="d5">Driess et al. are researchers who have employed language models as high-level controllers in robotics, published in 2023.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="BAKER ET AL., 2022" target="COMPLEX MULTIMODAL GAMES">
      <data key="d4">6.0</data>
      <data key="d5">Baker et al. are researchers who have adapted language model agents to complex multimodal games, published in 2022.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="WANG ET AL., 2023" target="COMPLEX MULTIMODAL GAMES">
      <data key="d4">6.0</data>
      <data key="d5">Wang et al. are researchers who have adapted language model agents to complex multimodal games, published in 2023.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="GUSS ET AL., 2019" target="MINECRAFT">
      <data key="d4">6.0</data>
      <data key="d5">Guss et al. are researchers who have worked on complex multimodal games like Minecraft, published in 2019.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LIU ET AL., 2018" target="TEXT-BASED ENVIRONMENTS">
      <data key="d4">6.0</data>
      <data key="d5">Liu et al. are researchers who have employed language models in text-based environments, published in 2018.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="SHRIDHAR ET AL., 2020" target="TEXT-BASED ENVIRONMENTS">
      <data key="d4">6.0</data>
      <data key="d5">Shridhar et al. are researchers who have employed language models in text-based environments, published in 2020.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="SHRIDHAR ET AL., 2020" target="ALFWORLD">
      <data key="d4">12.0</data>
      <data key="d5">Shridhar et al. are the authors mentioned in relation to Alfworld.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LIU ET AL., 2024" target="TEXT-BASED ENVIRONMENTS">
      <data key="d4">1.0</data>
      <data key="d5">Liu et al. are researchers who have employed language models in text-based environments, published in 2024.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LIU ET AL., 2024" target="EOH">
      <data key="d4">7.0</data>
      <data key="d5">Liu et al. are the authors of research on EoH, published in 2024.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="LIU ET AL., 2024" target="BALANCING EXPLORATION AND EXPLOITATION">
      <data key="d4">5.0</data>
      <data key="d5">Liu et al. are authors who have worked on balancing exploration and exploitation in search algorithms, relevant to novelty search algorithms.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ERROR PROPAGATION" target="RAP">
      <data key="d4">7.0</data>
      <data key="d5">RAP can lead to error propagation due to reliance on internal representations.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="LEAST-TO-MOST PROMPTING" target="MULTI-STEP DECOMPOSITION">
      <data key="d4">7.0</data>
      <data key="d5">Least-to-most prompting is a method of multi-step decomposition to improve reasoning.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="LEAST-TO-MOST PROMPTING" target="OLIVIER BOUSQUET">
      <data key="d4">8.0</data>
      <data key="d5">Olivier Bousquet is one of the authors who discussed the Least-to-most prompting method.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LEAST-TO-MOST PROMPTING" target="QUOC LE">
      <data key="d4">8.0</data>
      <data key="d5">Quoc Le is one of the authors who discussed the Least-to-most prompting method.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LEAST-TO-MOST PROMPTING" target="ED CHI">
      <data key="d4">8.0</data>
      <data key="d5">Ed Chi is one of the authors who discussed the Least-to-most prompting method.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="LEAST-TO-MOST PROMPTING" target="ICLR 2022">
      <data key="d4">7.0</data>
      <data key="d5">The Least-to-most prompting method was presented at ICLR 2022.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="SEARCH ALGORITHMS" target="DEPTH-FIRST SEARCH (DFS)">
      <data key="d4">7.0</data>
      <data key="d5">DFS is a search algorithm used to explore the tree in ToT prompting.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="SEARCH ALGORITHMS" target="BREADTH-FIRST SEARCH (BFS)">
      <data key="d4">7.0</data>
      <data key="d5">BFS is a search algorithm used to explore the tree in ToT prompting.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="SELF-REFINE" target="SELF-IMPROVEMENT">
      <data key="d4">7.0</data>
      <data key="d5">Self-refine is a technique of self-improvement used to enhance language model performance.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="SELF-REFINE" target="REFLEXION">
      <data key="d4">16.0</data>
      <data key="d5">Self-Refine and Reflexion are both extensions proposed to enhance reasoning and decision-making through self-improvement.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="SELF-REFINE" target="META AGENT SEARCH">
      <data key="d4">20.0</data>
      <data key="d5">Meta Agent Search uses the Self-Refine strategy to perform iterations of refinement on the novelty and correctness of proposals.
Meta Agent Search uses Self-Refine as one of the state-of-the-art hand-designed agents for comparison.
Meta Agent Search outperforms the Self-Refine algorithm in various domains.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="SELF-REFINE" target="MADAAN ET AL., 2024">
      <data key="d4">37.0</data>
      <data key="d5">Madaan et al. are the authors of the Self-Refine strategy used in Meta Agent Search.
Madaan et al. are the researchers who developed the Self-Refine method in 2024.
Madaan et al. are the authors of the Self-Refine algorithm.
Madaan et al. are the authors of the Self-Refine algorithm, published in 2024.
Madaan et al. are the authors of research on Self-Refine, published in 2024.
Madaan et al. are the authors of the Self-Refine algorithm.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="SELF-REFINE" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Self-Refine is a manually designed agent used for various tasks with specific performance metrics.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="SELF-REFINE" target="ARC">
      <data key="d4">7.0</data>
      <data key="d5">Self-Refine is used as a baseline for experiments on ARC.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="SELF-REFINE" target="SHENGRAN HU">
      <data key="d4">14.0</data>
      <data key="d5">Self-Refine is a method implemented by Shengran Hu and can be found in the repository at https://github.com/ShengranHu/ADAS.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="REFLEXION" target="SELF-IMPROVEMENT">
      <data key="d4">1.0</data>
      <data key="d5">Reflexion is a technique of self-improvement used to enhance language model performance.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="REFLEXION" target="LANGUAGE MODELS (LM)">
      <data key="d4">8.0</data>
      <data key="d5">Reflexion is a technique used to extend the capabilities of language models to decision-making tasks.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REFLEXION" target="ENVIRONMENTAL FEEDBACK">
      <data key="d4">9.0</data>
      <data key="d5">Reflexion uses observations from the environment to improve decision-making tasks.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REFLEXION" target="DECISION-MAKING TASKS">
      <data key="d4">8.0</data>
      <data key="d5">Reflexion is used for decision-making tasks where reverting between iterations is feasible.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="REFLEXION" target="MBPP">
      <data key="d4">7.0</data>
      <data key="d5">Reflexion is evaluated using the MBPP dataset, with performance scores reported.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="REFLEXION" target="HOT POT QA">
      <data key="d4">6.0</data>
      <data key="d5">Reflexion is used to evaluate performance in HotPotQA.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="REFLEXION" target="PROMPTING TECHNIQUES">
      <data key="d4">7.0</data>
      <data key="d5">Reflexion is a type of prompting technique used for language models.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="HIGH-LEVEL CONTROLLERS" target="LANGUAGE MODELS">
      <data key="d4">7.0</data>
      <data key="d5">Language models are used as high-level controllers in robotics and other applications.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="HIGH-LEVEL CONTROLLERS" target="CONTROL POLICIES">
      <data key="d4">7.0</data>
      <data key="d5">High-level controllers oversee and guide control policies in decision-making tasks.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="COMPLEX MULTIMODAL GAMES" target="LANGUAGE MODELS">
      <data key="d4">7.0</data>
      <data key="d5">Language models are adapted to complex multimodal games for decision-making tasks.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="MINECRAFT" target="LANGUAGE MODELS">
      <data key="d4">7.0</data>
      <data key="d5">Language models are used to control agents and make decisions in Minecraft.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="PROMPTS" target="AGENTINSTRUCT">
      <data key="d4">17.0</data>
      <data key="d5">AgentInstruct generates both prompts and responses using raw data sources.
AgentInstruct generates both prompts and responses as part of its data generation process.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="PROMPTS" target="DATA GENERATION WORKFLOWS">
      <data key="d4">7.0</data>
      <data key="d5">Data generation workflows involve the use of prompts to generate new data.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="VALUE FUNCTION" target="MCTS">
      <data key="d4">8.0</data>
      <data key="d5">The value function is used to estimate the expected return of a node in the MCTS algorithm.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="VALUE FUNCTION" target="VOLD(S)">
      <data key="d4">7.0</data>
      <data key="d5">Vold(s) is the old value function of a node before it is updated with the new return value.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="VALUE FUNCTION" target="N(S)">
      <data key="d4">7.0</data>
      <data key="d5">N(s) is the number of times a node has been visited, used in the value function update formula.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="DECISION-MAKING" target="REASONING SETTING">
      <data key="d4">6.0</data>
      <data key="d5">Decision-making and reasoning settings are different environments where models are evaluated on their ability to make choices or solve problems.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="POLICY MODEL" target="LANGUAGE MODELS">
      <data key="d4">7.0</data>
      <data key="d5">Language models are used as policy models in decision-making tasks.</data>
      <data key="d6">f8e7ed806916bf15245bcb4d52570c26</data>
    </edge>
    <edge source="SELF-IMPROVEMENT" target="AGENTINSTRUCT">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct can be used for the self-improvement of larger, more capable models.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="COT" target="GAME OF 24">
      <data key="d4">6.0</data>
      <data key="d5">CoT is used as a base prompting design in the Game of 24.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="COT" target="MIRAGE">
      <data key="d4">8.0</data>
      <data key="d5">CoT is a technique used to evaluate the performance of models on the MIRAGE datasets.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ADAPLANNER" target="SUN ET AL., 2023">
      <data key="d4">18.0</data>
      <data key="d5">Sun et al. are the researchers who developed the AdaPlanner algorithm in 2023.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="EXTERNAL TOOLS" target="SHEN ET AL., 2023">
      <data key="d4">7.0</data>
      <data key="d5">Shen et al. contributed to the development of external tools for language models in 2023.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="EXTERNAL TOOLS" target="SURIS ET AL., 2023">
      <data key="d4">7.0</data>
      <data key="d5">Suris et al. contributed to the development of external tools for language models in 2023.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="TREE-BASED SEARCH" target="MCTS">
      <data key="d4">16.0</data>
      <data key="d5">MCTS is a type of tree-based search algorithm used to explore multiple branches of outcomes.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="TREE-BASED SEARCH" target="SWIECHOWSKI ET AL., 2021">
      <data key="d4">7.0</data>
      <data key="d5">Swiechowski et al. contributed to the development of tree-based search algorithms in 2021.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="TREE-BASED SEARCH" target="LAVALLE, 1998">
      <data key="d4">7.0</data>
      <data key="d5">LaValle contributed to the development of tree-based search algorithms in 1998.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="MCTS" target="UCT ALGORITHM">
      <data key="d4">8.0</data>
      <data key="d5">The UCT algorithm is used within MCTS to balance exploration and exploitation.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="MCTS" target="EXPLORATION WEIGHT">
      <data key="d4">8.0</data>
      <data key="d5">Exploration weight is a parameter used in the MCTS algorithm to balance exploration and exploitation.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="MCTS" target="PARENT NODE">
      <data key="d4">7.0</data>
      <data key="d5">The parent node is used in the backpropagation process of the MCTS algorithm.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="MCTS" target="EPISODE">
      <data key="d4">7.0</data>
      <data key="d5">An episode refers to a sequence of actions and observations in the MCTS algorithm.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="MCTS" target="RETURN">
      <data key="d4">8.0</data>
      <data key="d5">Return is used in the backpropagation process of the MCTS algorithm to update the value function.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="MCTS" target="A*">
      <data key="d4">7.0</data>
      <data key="d5">MCTS is compared to A* as a more principled search algorithm.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="MCTS" target="DFS">
      <data key="d4">7.0</data>
      <data key="d5">MCTS is compared to DFS as a more principled search algorithm.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="MCTS" target="TOT">
      <data key="d4">8.0</data>
      <data key="d5">MCTS is improved by incorporating the LM-based heuristic used in ToT.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="MCTS" target="SEARCH ALGORITHM">
      <data key="d4">9.0</data>
      <data key="d5">MCTS is a type of search algorithm used for decision-making tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LM" target="RESET">
      <data key="d4">7.0</data>
      <data key="d5">Reset is used in language model tasks to return to a previous state or step.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="LM" target="TOT">
      <data key="d4">8.0</data>
      <data key="d5">ToT leverages LM capabilities for decision-making tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="LM" target="RAP">
      <data key="d4">8.0</data>
      <data key="d5">RAP leverages LM capabilities for decision-making tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="HAFNER ET AL., 2019" target="REINFORCEMENT LEARNING">
      <data key="d4">7.0</data>
      <data key="d5">Hafner et al. contributed to the development of reinforcement learning algorithms in 2019.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="DU ET AL., 2023" target="REINFORCEMENT LEARNING">
      <data key="d4">7.0</data>
      <data key="d5">Du et al. contributed to the development of reinforcement learning algorithms in 2023.</data>
      <data key="d6">c95e02c0dca4a4a36b701cbc7dd14da6</data>
    </edge>
    <edge source="DU ET AL., 2023" target="LLM-DEBATE">
      <data key="d4">12.0</data>
      <data key="d5">Du et al. are the researchers who developed the LLM-Debate method in 2023.
Du et al. are the authors of the LLM-Debate algorithm.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="DU ET AL., 2023" target="LLM DEBATE">
      <data key="d4">19.0</data>
      <data key="d5">Du et al. are the authors of the LLM Debate algorithm.
Du et al. are the authors of the LLM Debate algorithm, published in 2023.
Du et al. are the authors of research on LLM Debate, published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="DU ET AL., 2023" target="LLM DEBATE (DU ET AL., 2023)">
      <data key="d4">6.0</data>
      <data key="d5">Du et al. are the authors of the LLM Debate algorithm.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="WU ET AL., 2023" target="FM MODULES">
      <data key="d4">6.0</data>
      <data key="d5">Wu et al. are the authors who contributed to the development of techniques for assigning FM modules in agentic systems, published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="SHEN ET AL., 2023" target="NEURAL ARCHITECTURE SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Shen et al. discussed Neural Architecture Search (NAS) in 2023.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="TOT" target="SEARCH METHODS">
      <data key="d4">7.0</data>
      <data key="d5">ToT is a type of search method that samples and explores more outputs to improve performance.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="TOT" target="GAME OF 24">
      <data key="d4">6.0</data>
      <data key="d5">ToT is evaluated for its performance in the Game of 24.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="TOT" target="HOT POT QA">
      <data key="d4">1.0</data>
      <data key="d5">ToT is evaluated for its performance in HotPotQA.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="TOT" target="TOKEN CONSUMPTION">
      <data key="d4">7.0</data>
      <data key="d5">ToT is evaluated for token consumption compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="TOT" target="SAMPLE COMPLEXITY">
      <data key="d4">7.0</data>
      <data key="d5">ToT is evaluated for sample complexity compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="TOT" target="NODES EXPANDED">
      <data key="d4">7.0</data>
      <data key="d5">ToT is evaluated for the number of nodes expanded compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="TOT" target="TRAJECTORIES">
      <data key="d4">8.0</data>
      <data key="d5">ToT constructs trajectories with search algorithms for decision-making tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="TOT" target="PERFORMANCE">
      <data key="d4">8.0</data>
      <data key="d5">ToT is evaluated for its performance compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="TOT" target="COMPUTATIONAL COST">
      <data key="d4">7.0</data>
      <data key="d5">ToT is evaluated for its computational cost compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="TOT" target="SELECTION OPERATION">
      <data key="d4">7.0</data>
      <data key="d5">ToT removes the selection operation to improve performance.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="TOT" target="BACKPROPAGATION OPERATION">
      <data key="d4">7.0</data>
      <data key="d5">ToT removes the backpropagation operation to improve performance.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="TOT" target="DECISION-MAKING TASKS">
      <data key="d4">8.0</data>
      <data key="d5">ToT harnesses LM capabilities for various decision-making tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="TOT" target="YA0 ET AL., 2023A">
      <data key="d4">12.0</data>
      <data key="d5">Yao et al. are the authors mentioned in relation to the ToT algorithm.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="RAP" target="LANGUAGE MODELS (LM)">
      <data key="d4">7.0</data>
      <data key="d5">RAP is a reasoning-based method used to improve the performance of language models.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="RAP" target="PERFORMANCE CEILING">
      <data key="d4">7.0</data>
      <data key="d5">RAP has a performance ceiling due to reliance on internal representations.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="RAP" target="FACT HALLUCINATION">
      <data key="d4">7.0</data>
      <data key="d5">RAP can lead to fact hallucination due to reliance on internal representations.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="RAP" target="TRIAL AND ERROR">
      <data key="d4">6.0</data>
      <data key="d5">RAP is limited in its ability to learn from trial and error.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="RAP" target="WORLD MODEL">
      <data key="d4">6.0</data>
      <data key="d5">RAP is constrained to tasks where the language model can become a world model and accurately predict states.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="RAP" target="SEARCH METHODS">
      <data key="d4">7.0</data>
      <data key="d5">RAP is a type of search method that samples and explores more outputs to improve performance.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="RAP" target="GAME OF 24">
      <data key="d4">6.0</data>
      <data key="d5">RAP is evaluated for its performance in the Game of 24.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="RAP" target="HOT POT QA">
      <data key="d4">6.0</data>
      <data key="d5">RAP is evaluated for its performance in HotPotQA.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="RAP" target="TOKEN CONSUMPTION">
      <data key="d4">7.0</data>
      <data key="d5">RAP is evaluated for token consumption compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="RAP" target="SAMPLE COMPLEXITY">
      <data key="d4">7.0</data>
      <data key="d5">RAP is evaluated for sample complexity compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="RAP" target="NODES EXPANDED">
      <data key="d4">7.0</data>
      <data key="d5">RAP is evaluated for the number of nodes expanded compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="RAP" target="TRAJECTORIES">
      <data key="d4">8.0</data>
      <data key="d5">RAP constructs trajectories with search algorithms for decision-making tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="RAP" target="PERFORMANCE">
      <data key="d4">8.0</data>
      <data key="d5">RAP is evaluated for its performance compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="RAP" target="COMPUTATIONAL COST">
      <data key="d4">7.0</data>
      <data key="d5">RAP is evaluated for its computational cost compared to other methods.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="RAP" target="DECISION-MAKING TASKS">
      <data key="d4">8.0</data>
      <data key="d5">RAP harnesses LM capabilities for various decision-making tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="REASONING" target="AGENTINSTRUCT">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct generates data to teach AI models the skill of reasoning.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="EXTERNAL MEMORY" target="LEWIS ET AL., 2020">
      <data key="d4">6.0</data>
      <data key="d5">Lewis et al. are the authors who contributed to the development of external memory techniques, published in 2020.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="EXTERNAL MEMORY" target="ZHANG ET AL., 2024C">
      <data key="d4">6.0</data>
      <data key="d5">Zhang et al. are the authors who contributed to the development of external memory techniques, published in 2024.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="SEARCH ALGORITHM" target="A*">
      <data key="d4">9.0</data>
      <data key="d5">A* is a type of search algorithm used for decision-making tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="SEARCH ALGORITHM" target="DFS">
      <data key="d4">9.0</data>
      <data key="d5">DFS is a type of search algorithm used for decision-making tasks.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="SEARCH ALGORITHM" target="ADAS">
      <data key="d4">8.0</data>
      <data key="d5">The search algorithm is a key component of ADAS, specifying how the method explores the search space.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="SEARCH ALGORITHM" target="ZHUGE ET AL., 2024">
      <data key="d4">6.0</data>
      <data key="d5">Zhuge et al. used reinforcement learning as a search algorithm within ADAS.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="SEARCH ALGORITHM" target="SUTTON &amp; BARTO, 2018">
      <data key="d4">1.0</data>
      <data key="d5">Sutton &amp; Barto discussed the exploration-exploitation trade-off, which is considered in the search algorithms of ADAS.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="REINFORCEMENT LEARNING" target="FMS">
      <data key="d4">8.0</data>
      <data key="d5">FMs are used to write reward functions for reinforcement learning in robotics.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="INTERNAL REASONING" target="EXTERNAL RETRIEVAL">
      <data key="d4">8.0</data>
      <data key="d5">Both internal reasoning and external retrieval strategies are used in LATS to perform well on tasks like HotPotQA.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="INPUT" target="META AGENT SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Input refers to the data provided to the Meta Agent Search algorithm to perform tasks and discover new agents.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="UPPER CONFIDENCE BOUNDS APPLIED TO TREES (UCT)" target="KOCSIS AND SZEPESV&#193;RI, 2006">
      <data key="d4">6.0</data>
      <data key="d5">Kocsis and Szepesv&#225;ri developed the UCT value used in MCTS.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="UPPER CONFIDENCE BOUNDS APPLIED TO TREES (UCT)" target="VALUE FUNCTION V(S)">
      <data key="d4">8.0</data>
      <data key="d5">UCT uses the value function V(s) to select the best child node for expansion.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="UPPER CONFIDENCE BOUNDS APPLIED TO TREES (UCT)" target="EXPLORATION WEIGHT W">
      <data key="d4">7.0</data>
      <data key="d5">Exploration weight w is a parameter in the UCT formula.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="INPUT X" target="OUTPUT Y">
      <data key="d4">9.0</data>
      <data key="d5">Input x is transformed into output y by the language model.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="PARENT NODE P" target="CHILD NODE S">
      <data key="d4">8.0</data>
      <data key="d5">Child nodes s are expanded from parent nodes p in the decision tree of MCTS.</data>
      <data key="d6">9bb90746134619cad9a3e649b8b35f24</data>
    </edge>
    <edge source="AGENT" target="ENVIRONMENT">
      <data key="d4">8.0</data>
      <data key="d5">An agent operates within an environment, receiving observations and taking actions.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="AGENT" target="BASE PROMPTING FRAMEWORK">
      <data key="d4">7.0</data>
      <data key="d5">The base prompting framework guides the agent's actions and decisions in a task.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="AGENT" target="OBSERVATION">
      <data key="d4">8.0</data>
      <data key="d5">Observation is the information received by the agent from the environment.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="AGENT" target="ACTION">
      <data key="d4">8.0</data>
      <data key="d5">Action is the decision or move made by the agent based on the policy and observations.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="AGENT" target="POLICY">
      <data key="d4">8.0</data>
      <data key="d5">Policy is the strategy that the agent follows to decide on actions.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="AGENT" target="SEARCH APIS">
      <data key="d4">8.0</data>
      <data key="d5">Agents can use search APIs to perform specific tasks, such as searching for information.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENT" target="CODE INTERPRETER">
      <data key="d4">8.0</data>
      <data key="d5">Agents can use a code interpreter to execute and debug code.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENT" target="CALCULATOR">
      <data key="d4">8.0</data>
      <data key="d5">Agents can use a calculator to perform mathematical calculations.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="EXPANSION" target="BACKPROPAGATED REWARD">
      <data key="d4">7.0</data>
      <data key="d5">Backpropagated reward is used to update the model's parameters during the expansion process in search algorithms.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="EXPANSION" target="TEXT MODIFICATION AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Text modification agents can create expansion tasks.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="REFLECTION" target="SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Reflection led to the decision to perform a new search.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="REFLECTION" target="REFINE SEARCH">
      <data key="d4">1.0</data>
      <data key="d5">Reflection led to the decision to refine the search criteria.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="REFLECTION" target="FAIL">
      <data key="d4">1.0</data>
      <data key="d5">Reflection occurs after a failed attempt to evaluate what went wrong and how to improve.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="REFLECTION" target="MADAAN ET AL., 2024">
      <data key="d4">6.0</data>
      <data key="d5">Madaan et al. are the authors who contributed to the development of reflection techniques, published in 2024.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="REFLECTION" target="MULTI-AGENT WORKFLOWS">
      <data key="d4">7.0</data>
      <data key="d5">Reflection is a key component of multi-agent workflows used to generate high-quality data.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="RESET" target="HISTORICAL TEXT INPUT">
      <data key="d4">7.0</data>
      <data key="d5">Historical text input is used to reset to any step in language model tasks.</data>
      <data key="d6">c234cb83764b899335af0950677ad024</data>
    </edge>
    <edge source="OBSERVATION" target="TRAJECTORY">
      <data key="d4">8.0</data>
      <data key="d5">A trajectory includes observations about the situation in a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="ACTION" target="FINISH[ANSWER]">
      <data key="d4">14.0</data>
      <data key="d5">The Finish[answer] action returns the final answer and concludes the task.
Finish[answer] is a type of action performed in a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ACTION" target="SEARCH[ENTITY]">
      <data key="d4">14.0</data>
      <data key="d5">The Search[entity] action searches for a specific entity on Wikipedia.
Search[entity] is a type of action performed in a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ACTION" target="LOOKUP[KEYWORD]">
      <data key="d4">14.0</data>
      <data key="d5">The Lookup[keyword] action returns the next sentence containing the specified keyword.
Lookup[keyword] is a type of action performed in a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ACTION" target="TRAJECTORY">
      <data key="d4">8.0</data>
      <data key="d5">A trajectory includes actions that are performed in a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="CHEN ET AL., 2021" target="SAFETY CONSIDERATIONS">
      <data key="d4">12.0</data>
      <data key="d5">Chen et al. are the authors of a work that discusses safety considerations for executing model-generated code.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="REWARD" target="SUCCESS RATE (SR)">
      <data key="d4">8.0</data>
      <data key="d5">The success rate is defined as the portion of instructions where the reward equals 1.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="TRAJECTORY" target="VALUE FUNCTION PROMPT">
      <data key="d4">9.0</data>
      <data key="d5">The Value Function Prompt instructs the analysis of trajectories in a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="TRAJECTORY" target="THOUGHT">
      <data key="d4">8.0</data>
      <data key="d5">A trajectory includes thoughts that reason about the current situation in a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="TRAJECTORY" target="REFLECTION PROMPT">
      <data key="d4">9.0</data>
      <data key="d5">The Reflection Prompt instructs the analysis of trajectories in a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="TRAJECTORY" target="SOLUTION">
      <data key="d4">8.0</data>
      <data key="d5">A trajectory leads to a solution in a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="COT-SC" target="META AGENT SEARCH">
      <data key="d4">14.0</data>
      <data key="d5">Meta Agent Search uses the COT-SC strategy to enhance the refinement of generated agents.
Meta Agent Search outperforms the COT-SC algorithm in various domains.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="COT-SC" target="CHAIN-OF-THOUGHT">
      <data key="d4">7.0</data>
      <data key="d5">COT-SC is a variant of Chain-of-Thought, used for similar tasks with specific performance metrics.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AUSTIN ET AL., 2022" target="MBPP">
      <data key="d4">6.0</data>
      <data key="d5">Austin et al. are the authors of the MBPP dataset, published in 2022.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="GAME OF 24" target="PROMPT METHOD">
      <data key="d4">6.0</data>
      <data key="d5">Prompt methods are used to guide language models in the Game of 24 task.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b</data>
    </edge>
    <edge source="TRAJECTORIES" target="VALUE FUNCTION PROMPT">
      <data key="d4">1.0</data>
      <data key="d5">The value function prompt instructs the analysis of solution trajectories.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="FEEDBACK" target="META AGENT SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search uses a sophisticated feedback mechanism to refine answers more effectively.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="FEEDBACK" target="INITIAL SOLUTION">
      <data key="d4">8.0</data>
      <data key="d5">Feedback is generated after running examples to evaluate the correctness of the initial solution.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FEEDBACK" target="CORRECT EXAMPLES">
      <data key="d4">7.0</data>
      <data key="d5">Correct Examples are part of the feedback indicating the examples that the initial solution passed.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FEEDBACK" target="WRONG EXAMPLES">
      <data key="d4">1.0</data>
      <data key="d5">Wrong Examples are part of the feedback indicating the examples that the initial solution failed.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FEEDBACK" target="CORRECT_COUNT">
      <data key="d4">1.0</data>
      <data key="d5">Correct Count is part of the feedback indicating the number of correct examples an initial solution passed.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FEEDBACK" target="CODE">
      <data key="d4">9.0</data>
      <data key="d5">The code is evaluated to generate feedback for improvement.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FEEDBACK" target="CORRECT_EXAMPLES">
      <data key="d4">8.0</data>
      <data key="d5">Feedback is used to improve the code, which is then evaluated using correct examples.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FEEDBACK" target="WRONG_EXAMPLES">
      <data key="d4">8.0</data>
      <data key="d5">Feedback is used to improve the code, which is then evaluated using wrong examples.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FEEDBACK" target="CONTENT">
      <data key="d4">9.0</data>
      <data key="d5">Content is the actual text or information contained within feedback.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FEEDBACK" target="VERIFIED VISUAL">
      <data key="d4">7.0</data>
      <data key="d5">Feedback provided by the verification module helps improve the visual representation, leading to a verified visual.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="TOOLS" target="AGENTINSTRUCT">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct uses tools like search engines and code interpreters to generate high-quality data.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="SEARCH" target="INTERACTIVE INFORMATION RETRIEVAL">
      <data key="d4">8.0</data>
      <data key="d5">Search is one of the actions in the interactive information retrieval method.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="SEARCH" target="REFINE SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Refining a search is a follow-up action to an initial search to better match desired results.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SEARCH" target="READING COMPREHENSION">
      <data key="d4">8.0</data>
      <data key="d5">Search is an application of reading comprehension.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="MBPP" target="EXPERT">
      <data key="d4">1.0</data>
      <data key="d5">Expert performance is used as a benchmark for comparison in MBPP.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="MBPP" target="PASS@1 ACCURACY">
      <data key="d4">8.0</data>
      <data key="d5">Pass@1 accuracy is used to evaluate the performance of models on the MBPP dataset.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="FURUTA ET AL., 2024" target="FINE-TUNING">
      <data key="d4">12.0</data>
      <data key="d5">Furuta et al. are the authors of a fine-tuning method, published in 2024.
Furuta et al. are the authors of a study involving fine-tuning methods for performance evaluation.</data>
      <data key="d6">594449768ae2dea9b2efbe677075096b,99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="COMPUTATIONAL COSTS" target="INFERENCE COSTS">
      <data key="d4">6.0</data>
      <data key="d5">Both computational and inference costs are constraints that affect the performance and feasibility of running algorithms.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="SYNTHETIC TEST SUITE" target="ASSERT STATEMENTS">
      <data key="d4">7.0</data>
      <data key="d5">Assert statements are part of the synthetic test suite used to evaluate the correctness of solutions.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="ACTION SPACE" target="COMPILER FEEDBACK">
      <data key="d4">7.0</data>
      <data key="d5">Action space and compiler feedback are components used in the decision-making process of programming tasks.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="SOLUTION SELECTION" target="REAL TEST SUITE">
      <data key="d4">8.0</data>
      <data key="d5">Solution selection involves choosing the best solution based on evaluation with the real test suite.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="RL-BASED TRAINING" target="HUMAN PERFORMANCE">
      <data key="d4">1.0</data>
      <data key="d5">RL-based training aims to improve model performance to match or exceed human performance benchmarks.</data>
      <data key="d6">99d90aededb61e04241516ed9ec656cc</data>
    </edge>
    <edge source="A*" target="ZHUANG ET AL., 2023">
      <data key="d4">6.0</data>
      <data key="d5">Zhuang et al. are the authors mentioned in the context of the A* algorithm.</data>
      <data key="d6">faa2bd677c7f052136479e0175da3e5b</data>
    </edge>
    <edge source="SUCCESS RATE" target="META AGENT SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses success rate as a performance metric.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="SCORE" target="ORCA-BENCH">
      <data key="d4">8.0</data>
      <data key="d5">Scores are used to evaluate model performance on the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="SCORE" target="NORMALIZATION">
      <data key="d4">7.0</data>
      <data key="d5">Normalization is used to adjust scores to a common scale, normalizing the student's final score to a 0 to 10 scale.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="PERFORMANCE" target="META AGENT SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Performance is a measure used by the Meta Agent Search algorithm to evaluate and refine agents.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="PERFORMANCE" target="EVALUATION FUNCTION">
      <data key="d4">8.0</data>
      <data key="d5">Performance is an objective used in the evaluation function of ADAS to assess the effectiveness of agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="PROMPTING TECHNIQUES" target="CHEN ET AL., 2023A">
      <data key="d4">6.0</data>
      <data key="d5">Chen et al. are the authors who contributed to the development of prompting techniques, published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="PROMPTING TECHNIQUES" target="SCHULHOFF ET AL., 2024">
      <data key="d4">6.0</data>
      <data key="d5">Schulhoff et al. are the authors who contributed to the development of prompting techniques, published in 2024.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="JEFF CLUNE" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">8.0</data>
      <data key="d5">Jeff Clune is one of the authors who formulated the research area of ADAS.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="JEFF CLUNE" target="UNIVERSITY OF BRITISH COLUMBIA">
      <data key="d4">6.0</data>
      <data key="d5">Jeff Clune is affiliated with the University of British Columbia.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="JEFF CLUNE" target="VECTOR INSTITUTE">
      <data key="d4">6.0</data>
      <data key="d5">Jeff Clune is affiliated with the Vector Institute.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="JEFF CLUNE" target="CANADA CIFAR AI CHAIR">
      <data key="d4">7.0</data>
      <data key="d5">Jeff Clune holds the Canada CIFAR AI Chair.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="JEFF CLUNE" target="AI-GAS">
      <data key="d4">9.0</data>
      <data key="d5">Jeff Clune authored the paper "Ai-gas: Ai-generating algorithms, an alternate paradigm for producing general artificial intelligence."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="JEFF CLUNE" target="THOUGHT CLONING">
      <data key="d4">8.0</data>
      <data key="d5">Jeff Clune is one of the authors of the paper discussing Thought Cloning.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="JEFF CLUNE" target="RUI WANG">
      <data key="d4">8.0</data>
      <data key="d5">Both are co-authors of the papers "Poet: open-ended coevolution of environments and their optimized solutions" and "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JEFF CLUNE" target="JOEL LEHMAN">
      <data key="d4">8.0</data>
      <data key="d5">Both are co-authors of the papers "Poet: open-ended coevolution of environments and their optimized solutions" and "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JEFF CLUNE" target="KENNETH O. STANLEY">
      <data key="d4">8.0</data>
      <data key="d5">Both are co-authors of the papers "Poet: open-ended coevolution of environments and their optimized solutions" and "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JEFF CLUNE" target="OMNI">
      <data key="d4">8.0</data>
      <data key="d5">Jeff Clune is one of the authors of the paper titled "OMNI: Open-endedness via models of human notions of interestingness."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="EFFICIENCY" target="EXPERTS">
      <data key="d4">7.0</data>
      <data key="d5">Experts evaluate the efficiency trait in the feedback mechanism of ADAS.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="AAKANKSHA CHOWDHERY" target="CHALLENGING BIG-BENCH TASKS">
      <data key="d4">9.0</data>
      <data key="d5">Aakanksha Chowdhery is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="HYUNG WON CHUNG" target="CHALLENGING BIG-BENCH TASKS">
      <data key="d4">9.0</data>
      <data key="d5">Hyung Won Chung is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="SEBASTIAN GEHRMANN" target="CHALLENGING BIG-BENCH TASKS">
      <data key="d4">9.0</data>
      <data key="d5">Sebastian Gehrmann is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="YI TAY" target="CHALLENGING BIG-BENCH TASKS">
      <data key="d4">9.0</data>
      <data key="d5">Yi Tay is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="DENNY ZHOU" target="SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Denny Zhou is one of the authors of the paper "Self-consistency improves chain of thought reasoning in language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="DENNY ZHOU" target="CHAIN-OF-THOUGHT PROMPTING ELICITS REASONING IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Denny Zhou is one of the authors of the paper "Chain-of-thought prompting elicits reasoning in large language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="DENNY ZHOU" target="TAKE A STEP BACK: EVOKING REASONING VIA ABSTRACTION IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Denny Zhou is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="DENNY ZHOU" target="SELF-DISCOVER: LARGE LANGUAGE MODELS SELF-COMPOSE REASONING STRUCTURES">
      <data key="d4">8.0</data>
      <data key="d5">Denny Zhou is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="DENNY ZHOU" target="CHALLENGING BIG-BENCH TASKS">
      <data key="d4">9.0</data>
      <data key="d5">Denny Zhou is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="XUEZHI WANG" target="SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Xuezhi Wang is one of the authors of the paper "Self-consistency improves chain of thought reasoning in language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="XUEZHI WANG" target="CHAIN-OF-THOUGHT PROMPTING ELICITS REASONING IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Xuezhi Wang is one of the authors of the paper "Chain-of-thought prompting elicits reasoning in large language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JASON WEI" target="SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Jason Wei is one of the authors of the paper "Self-consistency improves chain of thought reasoning in language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JASON WEI" target="CHAIN-OF-THOUGHT PROMPTING ELICITS REASONING IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Jason Wei is one of the authors of the paper "Chain-of-thought prompting elicits reasoning in large language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JASON WEI" target="CHALLENGING BIG-BENCH TASKS">
      <data key="d4">9.0</data>
      <data key="d5">Jason Wei is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="DALE SCHUURMANS" target="SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Dale Schuurmans is one of the authors of the paper "Self-consistency improves chain of thought reasoning in language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="DALE SCHUURMANS" target="CHAIN-OF-THOUGHT PROMPTING ELICITS REASONING IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Dale Schuurmans is one of the authors of the paper "Chain-of-thought prompting elicits reasoning in large language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="PENGFEI LIU" target="YIXIN LIU">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="PENGFEI LIU" target="ALEXANDER R. FABBRI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YIMING YANG" target="PAL">
      <data key="d4">8.0</data>
      <data key="d5">Yiming Yang is one of the authors of the paper discussing Program-aided language models (PAL).</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="JAMIE CALLAN" target="PAL">
      <data key="d4">8.0</data>
      <data key="d5">Jamie Callan is one of the authors of the paper discussing Program-aided language models (PAL).</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="GRAHAM NEUBIG" target="PAL">
      <data key="d4">8.0</data>
      <data key="d5">Graham Neubig is one of the authors of the paper discussing Program-aided language models (PAL).</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="XINYUN CHEN" target="TAKE A STEP BACK: EVOKING REASONING VIA ABSTRACTION IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Xinyun Chen is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="XINYUN CHEN" target="SELF-DISCOVER: LARGE LANGUAGE MODELS SELF-COMPOSE REASONING STRUCTURES">
      <data key="d4">8.0</data>
      <data key="d5">Xinyun Chen is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="SWAROOP MISHRA" target="TAKE A STEP BACK: EVOKING REASONING VIA ABSTRACTION IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Swaroop Mishra is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="SWAROOP MISHRA" target="SELF-DISCOVER: LARGE LANGUAGE MODELS SELF-COMPOSE REASONING STRUCTURES">
      <data key="d4">8.0</data>
      <data key="d5">Swaroop Mishra is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="HUAIXIU STEVEN ZHENG" target="TAKE A STEP BACK: EVOKING REASONING VIA ABSTRACTION IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Huaixiu Steven Zheng is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="PERCY LIANG" target="XUECHEN LI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="PERCY LIANG" target="TIANYI ZHANG">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="PERCY LIANG" target="YANN DUBOIS">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="PERCY LIANG" target="ROHAN TAORI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="PERCY LIANG" target="ISHAAN GULRAJANI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="PERCY LIANG" target="CARLOS GUESTRIN">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="PERCY LIANG" target="TATSUNORI B. HASHIMOTO">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="PERCY LIANG" target="ALPACAEVAL">
      <data key="d4">8.0</data>
      <data key="d5">Percy Liang is one of the authors of the AlpacaEval project.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="PETER CLARK" target="AI2 REASONING CHALLENGE (ARC)">
      <data key="d4">8.0</data>
      <data key="d5">Peter Clark is one of the authors of the paper introducing the AI2 Reasoning Challenge (ARC).</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="OPENAI" target="GET_JSON_RESPONSE_FROM_GPT">
      <data key="d4">8.0</data>
      <data key="d5">The get_json_response_from_gpt function uses a GPT model provided by OpenAI.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="OPENAI" target="GPT-4O-2024-05-13">
      <data key="d4">18.0</data>
      <data key="d5">OpenAI is the organization responsible for developing the GPT-4o-2024-05-13 model.
OpenAI developed the GPT-4o-2024-05-13 language model.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959,84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="OPENAI" target="GPT-3.5-TURBO-0125">
      <data key="d4">18.0</data>
      <data key="d5">OpenAI is the organization responsible for developing the GPT-3.5-turbo-0125 model.
OpenAI developed the GPT-3.5-turbo-0125 language model.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959,84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="TOOLFORMER" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)">
      <data key="d4">7.0</data>
      <data key="d5">Toolformer is a technique used as a building block in agentic systems within the ADAS research area.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SHUNYU YAO" target="REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Shunyu Yao is one of the authors of the paper "React: Synergizing reasoning and acting in language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="YUCHEN ZHUANG" target="TOOLCHAIN*">
      <data key="d4">8.0</data>
      <data key="d5">Yuchen Zhuang is one of the authors who discussed the ToolChain* method.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="CHAO ZHANG" target="TOOLCHAIN*">
      <data key="d4">8.0</data>
      <data key="d5">Chao Zhang is one of the authors who discussed the ToolChain* method.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="HUGO TOUVRON" target="LOUIS MARTIN">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="KEVIN R. STONE">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="PETER ALBERT">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="AMJAD ALMAHAIRI">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="YASMINE BABAEI">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="NIKOLAY BASHLYKOV">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="SOUMYA BATRA">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="PRAJJWAL BHARGAVA">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="SHRUTI BHOSALE">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="DANIEL M. BIKEL">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="LUKAS BLECHER">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="CRISTIAN CANTON FERRER">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="MOYA CHEN">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="GUILLEM CUCURULL">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="DAVID ESIOBU">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="JUDE FERNANDES">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="JEREMY FU">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="WENYIN FU">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="BRIAN FULLER">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="CYNTHIA GAO">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="HUGO TOUVRON" target="VEDANUJ GOSWAMI">
      <data key="d4">7.0</data>
      <data key="d5">Both are authors mentioned in the document, contributing to the same research.</data>
      <data key="d6">8180bf20b7577f3eee40df5991e2886d</data>
    </edge>
    <edge source="NATHAN SCALES" target="CHALLENGING BIG-BENCH TASKS">
      <data key="d4">9.0</data>
      <data key="d5">Nathan Scales is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="TOOLCHAIN*" target="XIANG CHEN">
      <data key="d4">8.0</data>
      <data key="d5">Xiang Chen is one of the authors who discussed the ToolChain* method.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOOLCHAIN*" target="TONG YU">
      <data key="d4">8.0</data>
      <data key="d5">Tong Yu is one of the authors who discussed the ToolChain* method.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOOLCHAIN*" target="SAAYAN MITRA">
      <data key="d4">8.0</data>
      <data key="d5">Saayan Mitra is one of the authors who discussed the ToolChain* method.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOOLCHAIN*" target="VICTOR BURSZTYN">
      <data key="d4">8.0</data>
      <data key="d5">Victor Bursztyn is one of the authors who discussed the ToolChain* method.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOOLCHAIN*" target="RYAN A. ROSSI">
      <data key="d4">8.0</data>
      <data key="d5">Ryan A. Rossi is one of the authors who discussed the ToolChain* method.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOOLCHAIN*" target="SOMDEB SARKHEL">
      <data key="d4">8.0</data>
      <data key="d5">Somdeb Sarkhel is one of the authors who discussed the ToolChain* method.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="TOOLCHAIN*" target="ICLR 2023">
      <data key="d4">7.0</data>
      <data key="d5">The ToolChain* method was presented at ICLR 2023.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="WEBSHOP" target="YA0 ET AL., 2022">
      <data key="d4">6.0</data>
      <data key="d5">Yao et al. are the authors mentioned in relation to the WebShop environment.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="WEBSHOP" target="BRIGHT CITRUS DEODORANT">
      <data key="d4">8.0</data>
      <data key="d5">The webshop allows users to search for and purchase the Bright Citrus Deodorant.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="WEBSHOP" target="PRICE LOWER THAN 50.00 DOLLARS">
      <data key="d4">8.0</data>
      <data key="d5">The webshop allows users to set price constraints for their searches, such as less than 50.00 dollars.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="TOOLBENCH" target="QIN ET AL., 2024">
      <data key="d4">12.0</data>
      <data key="d5">Qin et al. are the authors mentioned in relation to ToolBench.</data>
      <data key="d6">42de130f5b6144472a86a4c8260a87c7</data>
    </edge>
    <edge source="WIKIPEDIA WEB API" target="SEARCH [ENTITY]">
      <data key="d4">8.0</data>
      <data key="d5">Search [entity] is an action in the LATS algorithm that retrieves information from the Wikipedia web API.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="WIKIPEDIA WEB API" target="LOOKUP [STRING]">
      <data key="d4">8.0</data>
      <data key="d5">Lookup [string] is an action in the LATS algorithm that retrieves information from the Wikipedia web API.</data>
      <data key="d6">48e423e2baf2ed485872756f5b4d87d8</data>
    </edge>
    <edge source="INTERACTIVE INFORMATION RETRIEVAL" target="LOOKUP">
      <data key="d4">8.0</data>
      <data key="d5">Lookup is one of the actions in the interactive information retrieval method.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="INTERACTIVE INFORMATION RETRIEVAL" target="FINISH">
      <data key="d4">8.0</data>
      <data key="d5">Finish is one of the actions in the interactive information retrieval method.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="MOSTLY BASIC PROGRAMMING PROBLEMS (MBPP)" target="NATURAL LANGUAGE DESCRIPTIONS">
      <data key="d4">7.0</data>
      <data key="d5">MBPP uses natural language descriptions to describe programming tasks.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="MOSTLY BASIC PROGRAMMING PROBLEMS (MBPP)" target="CROWDSOURCING">
      <data key="d4">7.0</data>
      <data key="d5">MBPP dataset was constructed by crowdsourcing from workers with basic Python knowledge.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="MOSTLY BASIC PROGRAMMING PROBLEMS (MBPP)" target="PYTHON STANDARD LIBRARY">
      <data key="d4">6.0</data>
      <data key="d5">MBPP includes tasks that involve the use of the Python standard library.</data>
      <data key="d6">fb2b4544aedd793e4d4ec3147320a51c</data>
    </edge>
    <edge source="RESULTS" target="PRODUCT TITLE">
      <data key="d4">7.0</data>
      <data key="d5">Each result in the list has a product title that identifies the product.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="OPTION" target="ITEM">
      <data key="d4">7.0</data>
      <data key="d5">Each item may have various options, such as size or color, that can be selected.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="DESC/OVERVIEW" target="ITEM">
      <data key="d4">7.0</data>
      <data key="d5">Each item has a description or overview that provides detailed information about its features.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ITEM" target="ITEM-DETAIL">
      <data key="d4">7.0</data>
      <data key="d5">The item-detail provides more detailed information about the item, including its description and options.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ITEM" target="EPISODE END">
      <data key="d4">8.0</data>
      <data key="d5">The interaction session with the web shop concludes when the user chooses to buy an item.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ENVIRONMENTS" target="DEPTH LIMIT">
      <data key="d4">7.0</data>
      <data key="d5">Experiments are conducted in different environments with a maximum depth limit.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="THOUGHT" target="META AGENT">
      <data key="d4">9.0</data>
      <data key="d5">The meta agent captures its thought process in the "thought" section of the output.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="THOUGHT" target="INSIGHTS">
      <data key="d4">8.0</data>
      <data key="d5">The "thought" section includes insights on what should be the next interesting agent.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="THOUGHT" target="OVERALL IDEA">
      <data key="d4">8.0</data>
      <data key="d5">The "thought" section includes the overall idea and reasoning behind the agent design.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="THOUGHT" target="IMPLEMENTATION">
      <data key="d4">8.0</data>
      <data key="d5">The "thought" section includes detailed implementation steps of the proposed agent.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="ARTHUR'S MAGAZINE" target="FIRST FOR WOMEN">
      <data key="d4">6.0</data>
      <data key="d5">Both are magazines, and the task involves determining which was started first.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ARTHUR'S MAGAZINE" target="TIMOTHY SHAY ARTHUR">
      <data key="d4">15.0</data>
      <data key="d5">Timothy Shay Arthur was the editor of Arthur's Magazine.
Timothy Shay Arthur was the editor of Arthur's Magazine.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ARTHUR'S MAGAZINE" target="GODEY'S LADY'S BOOK">
      <data key="d4">13.0</data>
      <data key="d5">Arthur's Magazine was merged into Godey's Lady's Book in May 1846.
Arthur's Magazine was merged into Godey's Lady's Book in May 1846.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ARTHUR'S MAGAZINE" target="EDGAR A. POE">
      <data key="d4">12.0</data>
      <data key="d5">Edgar A. Poe was a contributor to Arthur's Magazine.
Edgar A. Poe was one of the contributors to Arthur's Magazine.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ARTHUR'S MAGAZINE" target="J.H. INGRAHAM">
      <data key="d4">12.0</data>
      <data key="d5">J.H. Ingraham was a contributor to Arthur's Magazine.
J.H. Ingraham was one of the contributors to Arthur's Magazine.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ARTHUR'S MAGAZINE" target="SARAH JOSEPHA HALE">
      <data key="d4">12.0</data>
      <data key="d5">Sarah Josepha Hale was a contributor to Arthur's Magazine.
Sarah Josepha Hale was one of the contributors to Arthur's Magazine.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="ARTHUR'S MAGAZINE" target="THOMAS G. SPEAR">
      <data key="d4">12.0</data>
      <data key="d5">Thomas G. Spear was a contributor to Arthur's Magazine.
Thomas G. Spear was one of the contributors to Arthur's Magazine.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f,b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="FIRST FOR WOMEN" target="BAUER MEDIA GROUP">
      <data key="d4">7.0</data>
      <data key="d5">First for Women is published by Bauer Media Group.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="COLORADO OROGENY" target="HIGH PLAINS">
      <data key="d4">7.0</data>
      <data key="d5">The Colorado orogeny extends into the High Plains.</data>
      <data key="d6">b8dd0300033963bb4a3e1bad37f8e7b9</data>
    </edge>
    <edge source="VALUE FUNCTION PROMPT" target="QUESTION-ANSWERING TASK">
      <data key="d4">9.0</data>
      <data key="d5">The Value Function Prompt provides instructions for analyzing a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="VALUE FUNCTION PROMPT" target="CORRECTNESS SCORE">
      <data key="d4">7.0</data>
      <data key="d5">The value function prompt asks for a correctness score based on the purchase trajectory</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BACK TO SEARCH" target="INVALID ACTION">
      <data key="d4">8.0</data>
      <data key="d5">The action of clicking "Back to Search" was invalid.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SOLUTION" target="CORRECTNESS SCORE">
      <data key="d4">9.0</data>
      <data key="d5">The solution is evaluated and given a correctness score from 1 to 10.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="ANSWER" target="FINAL_THOUGHTS">
      <data key="d4">9.0</data>
      <data key="d5">The final thoughts include the final code, which produces the answer.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="ANSWER" target="INTEGRATION MODULE">
      <data key="d4">9.0</data>
      <data key="d5">The integration module combines sub-problem solutions to produce the final answer.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="ANSWER" target="CHAIN-OF-THOUGHT MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The Chain-of-Thought module uses verified visual representations to solve problems and generate the final answer.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="ANSWER" target="VERIFIED VISUAL">
      <data key="d4">8.0</data>
      <data key="d5">The verified visual representation is used by the Chain-of-Thought module to solve problems and generate the final answer.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="VALIDATION" target="AGENTINSTRUCT">
      <data key="d4">7.0</data>
      <data key="d5">Validation is a limitation of AgentInstruct, as it can be difficult to ensure synthetic data accurately represents desired scenarios.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="BASELINES" target="GPT-3.5-TURBO-0125">
      <data key="d4">2.0</data>
      <data key="d5">Baselines use the GPT-3.5-turbo-0125 model for evaluation.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="BASELINES" target="SHENGRAN HU">
      <data key="d4">6.0</data>
      <data key="d5">Shengran Hu is mentioned in the context of providing detailed implementations of all baselines.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="BASELINES" target="ORCA-BENCH">
      <data key="d4">8.0</data>
      <data key="d5">Baseline models like Orca-2.5, Mistral-Instruct-7B, and ChatGPT are evaluated using the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="BASELINES" target="INFERIORITY">
      <data key="d4">8.0</data>
      <data key="d5">Baseline models like Orca-2.5, Mistral-Instruct-7B, and ChatGPT show relative inferiority to GPT-4.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="QUESTIONS" target="READING COMPREHENSION TESTS">
      <data key="d4">7.0</data>
      <data key="d5">Questions are used in reading comprehension tests to assess the reader&#8217;s understanding.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="QUESTIONS" target="OPEN DOMAIN QUESTION ANSWERING">
      <data key="d4">7.0</data>
      <data key="d5">Questions are used in open domain question answering to generate responses.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="PLAINS" target="ELEVATION">
      <data key="d4">9.0</data>
      <data key="d5">Plains rise in elevation from around 1,800 to 7,000 feet.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="REFLECTION PROMPT" target="QUESTION-ANSWERING TASK">
      <data key="d4">9.0</data>
      <data key="d5">The Reflection Prompt provides instructions for analyzing a question-answering task.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="REFLECTION PROMPT" target="CORRECTNESS SCORE">
      <data key="d4">1.0</data>
      <data key="d5">The reflection prompt is used to diagnose reasons for a low correctness score and improve future performance</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="PROGRAMMING PROMPT" target="MINSUBARRAYSUM">
      <data key="d4">8.0</data>
      <data key="d5">The Programming Prompt provides instructions for implementing the minSubArraySum function.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="PROGRAMMING PROMPT" target="SAMPLE FUNCTION SIGNATURE">
      <data key="d4">8.0</data>
      <data key="d5">The Programming Prompt provides a sample function signature for implementing a function.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="PROGRAMMING PROMPT" target="SAMPLE FUNCTION BODY">
      <data key="d4">8.0</data>
      <data key="d5">The Programming Prompt provides a sample function body for implementing a function.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="MINSUBARRAYSUM" target="UNIT TEST">
      <data key="d4">1.0</data>
      <data key="d5">Unit tests validate the correctness of the minSubArraySum function implementation.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="UNIT TEST" target="SAMPLE FUNCTION BODY">
      <data key="d4">1.0</data>
      <data key="d5">Unit tests validate the correctness of the sample function body implementation.</data>
      <data key="d6">357f3442ba581c9d2bdf84d90509056f</data>
    </edge>
    <edge source="UNIT TEST" target="ADD FUNCTION">
      <data key="d4">9.0</data>
      <data key="d5">The ADD FUNCTION is validated using UNIT TESTS to check if it returns the correct sum of two integers.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="UNIT TEST" target="ERROR">
      <data key="d4">8.0</data>
      <data key="d5">UNIT TESTS help identify ERRORS in the function implementation by comparing expected and actual outputs.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="AI PYTHON ASSISTANT" target="FUNCTION IMPLEMENTATION">
      <data key="d4">9.0</data>
      <data key="d5">The AI Python assistant provides and improves function implementations based on user input and test results.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="FUNCTION IMPLEMENTATION" target="UNIT TEST RESULTS">
      <data key="d4">9.0</data>
      <data key="d5">Unit test results are used to validate the correctness of a function implementation.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="UNIT TEST RESULTS" target="TEST CASE GENERATION PROMPT">
      <data key="d4">7.0</data>
      <data key="d5">The test case generation prompt helps create unit tests that will produce results for validating function implementations.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="EARTH MAMA">
      <data key="d4">9.0</data>
      <data key="d5">Bright Citrus Deodorant is a product offered by the Earth Mama brand.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="BRIGHT CITRUS DEODORANT BY EARTH MAMA">
      <data key="d4">9.0</data>
      <data key="d5">BRIGHT CITRUS DEODORANT BY EARTH MAMA is a specific product that matches the search criteria for BRIGHT CITRUS DEODORANT.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="SENSITIVE SKIN">
      <data key="d4">9.0</data>
      <data key="d5">Bright Citrus Deodorant is suitable for sensitive skin</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="PREGNANCY AND BREASTFEEDING">
      <data key="d4">9.0</data>
      <data key="d5">Bright Citrus Deodorant is safe for use during pregnancy and breastfeeding</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="ORGANIC CALENDULA">
      <data key="d4">8.0</data>
      <data key="d5">Bright Citrus Deodorant contains organic calendula</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="3 OUNCE (PACK OF 1)">
      <data key="d4">8.0</data>
      <data key="d5">Bright Citrus Deodorant is available in a 3-ounce size</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="ASSORTED SCENTS">
      <data key="d4">8.0</data>
      <data key="d5">Bright Citrus Deodorant is available in assorted scents</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="BRIGHT CITRUS">
      <data key="d4">9.0</data>
      <data key="d5">Bright Citrus Deodorant is available in the bright citrus scent</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="CALMING LAVENDER">
      <data key="d4">8.0</data>
      <data key="d5">Bright Citrus Deodorant is available in the calming lavender scent</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="GINGER FRESH">
      <data key="d4">8.0</data>
      <data key="d5">Bright Citrus Deodorant is available in the ginger fresh scent</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="SIMPLY NON-SCENTS">
      <data key="d4">8.0</data>
      <data key="d5">Bright Citrus Deodorant is available in the simply non-scents option</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="TRAVEL SET (4-PACK)">
      <data key="d4">8.0</data>
      <data key="d5">Bright Citrus Deodorant is available in a travel set (4-pack) size</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="BRIGHT CITRUS DEODORANT" target="3 OUNCE (2-PACK)">
      <data key="d4">8.0</data>
      <data key="d5">Bright Citrus Deodorant is available in a 3 ounce (2-pack) size</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="EARTH MAMA" target="GINGER FRESH DEODORANT">
      <data key="d4">9.0</data>
      <data key="d5">Ginger Fresh Deodorant is a product offered by the Earth Mama brand.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="GINGER FRESH DEODORANT" target="GINGER FRESH DEODORANT BY EARTH MAMA">
      <data key="d4">9.0</data>
      <data key="d5">GINGER FRESH DEODORANT BY EARTH MAMA is a specific product that matches the search criteria for GINGER FRESH DEODORANT.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="BARREL AND OAK" target="CEDAR &amp; PATCHOULI DEODORANT">
      <data key="d4">1.0</data>
      <data key="d5">Cedar &amp; Patchouli Deodorant is a product offered by the Barrel and Oak brand.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="CEDAR &amp; PATCHOULI DEODORANT" target="BARREL AND OAK DEODORANT">
      <data key="d4">1.0</data>
      <data key="d5">BARREL AND OAK DEODORANT includes the CEDAR &amp; PATCHOULI DEODORANT as one of its product variants.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="MIN SUM" target="CURRENT SUM">
      <data key="d4">7.0</data>
      <data key="d5">MIN SUM is updated based on the value of CURRENT SUM during the function execution.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="ADD FUNCTION" target="DOCSTRING">
      <data key="d4">7.0</data>
      <data key="d5">The ADD FUNCTION includes a DOCSTRING that describes its purpose and behavior.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="ADD FUNCTION" target="SIGNATURE">
      <data key="d4">8.0</data>
      <data key="d5">The ADD FUNCTION has a SIGNATURE that declares its name, parameters, and return type.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="ERROR" target="OPERATOR">
      <data key="d4">9.0</data>
      <data key="d5">The ERROR in the ADD FUNCTION was due to the incorrect use of the '-' OPERATOR instead of '+'.</data>
      <data key="d6">785ad59c6a37896a4676ec5c1689735f</data>
    </edge>
    <edge source="ERROR" target="META AGENT SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Errors are mistakes or incorrect results produced by agents in the Meta Agent Search algorithm, which need to be refined.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="DAIRY FREE" target="ENJOY LIFE FOODS SOFT BAKED OVALS">
      <data key="d4">27.0</data>
      <data key="d5">Enjoy Life Foods Soft Baked Ovals are dairy-free
Enjoy Life Foods Soft Baked Ovals are dairy-free</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="DAIRY FREE" target="ENJOY LIFE SOFT BAKED CHEWY BARS">
      <data key="d4">27.0</data>
      <data key="d5">Enjoy Life Soft Baked Chewy Bars are dairy-free
Enjoy Life Soft Baked Chewy Bars are dairy-free</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="DAIRY FREE" target="ENJOY LIFE LENTIL CHIPS VARIETY PACK">
      <data key="d4">27.0</data>
      <data key="d5">Enjoy Life Lentil Chips Variety Pack is dairy-free
Enjoy Life Lentil Chips Variety Pack is dairy-free</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="APPLE VARIETY PACK OF CHIPS" target="ENJOY LIFE LENTIL CHIPS VARIETY PACK">
      <data key="d4">23.0</data>
      <data key="d5">Both are products that can be searched for in the web shop
Enjoy Life Lentil Chips Variety Pack is the apple variety pack of chips the user wants</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="APPLE VARIETY PACK OF CHIPS" target="ENJOY LIFE FOODS SOFT BAKED OVALS">
      <data key="d4">5.0</data>
      <data key="d5">Both are products that can be searched for in the web shop</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="APPLE VARIETY PACK OF CHIPS" target="ENJOY LIFE SOFT BAKED CHEWY BARS">
      <data key="d4">5.0</data>
      <data key="d5">Both are products that can be searched for in the web shop</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="VARIETY PACK">
      <data key="d4">24.0</data>
      <data key="d5">Enjoy Life Lentil Chips Variety Pack is available as a variety pack
Enjoy Life Lentil Chips Variety Pack includes multiple varieties or flavors</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="0.8 OUNCE (PACK OF 24)">
      <data key="d4">24.0</data>
      <data key="d5">Enjoy Life Lentil Chips Variety Pack is available in a 0.8 ounce (pack of 24) size
Enjoy Life Lentil Chips Variety Pack is available in the size option of 0.8 ounces per pack and 24 packs in total</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd,6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="DILL AND SOUR CREAM">
      <data key="d4">8.0</data>
      <data key="d5">Enjoy Life Lentil Chips Variety Pack is available in the dill and sour cream flavor</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="GARLIC &amp; PARMESAN">
      <data key="d4">8.0</data>
      <data key="d5">Enjoy Life Lentil Chips Variety Pack is available in the garlic &amp; parmesan flavor</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="LIGHT SEA SALT">
      <data key="d4">8.0</data>
      <data key="d5">Enjoy Life Lentil Chips Variety Pack is available in the light sea salt flavor</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="MARGHERITA PIZZA">
      <data key="d4">8.0</data>
      <data key="d5">Enjoy Life Lentil Chips Variety Pack is available in the margherita pizza flavor</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="THAI CHILI LIME">
      <data key="d4">8.0</data>
      <data key="d5">Enjoy Life Lentil Chips Variety Pack is available in the thai chili lime flavor</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="4 OUNCE (PACK OF 12)">
      <data key="d4">1.0</data>
      <data key="d5">Enjoy Life Lentil Chips Variety Pack is available in a 4 ounce (pack of 12) size</data>
      <data key="d6">6f486e20e3102c7a285e357d356417ad</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="BUY NOW">
      <data key="d4">18.0</data>
      <data key="d5">The user decided to buy the Enjoy Life Lentil Chips Variety Pack</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="FLAVOR NAME">
      <data key="d4">8.0</data>
      <data key="d5">The Enjoy Life Lentil Chips Variety Pack includes different flavor options</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="SIZE">
      <data key="d4">8.0</data>
      <data key="d5">The Enjoy Life Lentil Chips Variety Pack is available in different size options</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="RATING">
      <data key="d4">7.0</data>
      <data key="d5">The Enjoy Life Lentil Chips Variety Pack has a rating attribute</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="DESCRIPTION">
      <data key="d4">7.0</data>
      <data key="d5">The Enjoy Life Lentil Chips Variety Pack has a detailed description</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="FEATURES">
      <data key="d4">7.0</data>
      <data key="d5">The Enjoy Life Lentil Chips Variety Pack has specific features</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="ENJOY LIFE LENTIL CHIPS VARIETY PACK" target="REVIEWS">
      <data key="d4">1.0</data>
      <data key="d5">The Enjoy Life Lentil Chips Variety Pack has customer reviews</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON" target="SMOKED BACON SEA SALT 3-PACK">
      <data key="d4">14.0</data>
      <data key="d5">Smoked Bacon Sea Salt 3-Pack is a similar product to gluten-free vegetarian smoked peppered bacon</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON" target="LOUISVILLE VEGAN JERKY">
      <data key="d4">14.0</data>
      <data key="d5">Louisville Vegan Jerky is a similar product to gluten-free vegetarian smoked peppered bacon</data>
      <data key="d6">4ed5aa10872b585d02aa2daf4ff8f7fd</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="NON-GMO">
      <data key="d4">9.0</data>
      <data key="d5">Louisville Vegan Jerky is labeled as non-GMO.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="GLUTEN-FREE">
      <data key="d4">9.0</data>
      <data key="d5">Louisville Vegan Jerky is labeled as gluten-free.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="BLACK PEPPER">
      <data key="d4">9.0</data>
      <data key="d5">Louisville Vegan Jerky includes Black Pepper as one of its flavors.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="BUFFALO DILL">
      <data key="d4">9.0</data>
      <data key="d5">Louisville Vegan Jerky includes Buffalo Dill as one of its flavors.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="PEPPERONI">
      <data key="d4">9.0</data>
      <data key="d5">Louisville Vegan Jerky includes Pepperoni as one of its flavors.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="MAPLE BACON">
      <data key="d4">9.0</data>
      <data key="d5">Louisville Vegan Jerky includes Maple Bacon as one of its flavors.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="LOUISVILLE VEGAN JERKY" target="CAROLINA BBQ">
      <data key="d4">9.0</data>
      <data key="d5">Louisville Vegan Jerky includes Carolina BBQ as one of its flavors.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="RATING" target="STUDENT RESPONSE">
      <data key="d4">8.0</data>
      <data key="d5">Student responses are rated against teacher responses on a scale from 0 to 10.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="NON-GMO">
      <data key="d4">9.0</data>
      <data key="d5">The Spicy Hot Pepper Sea Salt 3-Pack is labeled as non-GMO.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="GLUTEN-FREE">
      <data key="d4">9.0</data>
      <data key="d5">The Spicy Hot Pepper Sea Salt 3-Pack is labeled as gluten-free.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="KOSHER">
      <data key="d4">9.0</data>
      <data key="d5">The Spicy Hot Pepper Sea Salt 3-Pack is labeled as kosher.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="NO MSG">
      <data key="d4">9.0</data>
      <data key="d5">The Spicy Hot Pepper Sea Salt 3-Pack is labeled as containing no MSG.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="GHOST PEPPER">
      <data key="d4">9.0</data>
      <data key="d5">The Spicy Hot Pepper Sea Salt 3-Pack includes Ghost Pepper as one of its flavors.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="JALAPENO">
      <data key="d4">9.0</data>
      <data key="d5">The Spicy Hot Pepper Sea Salt 3-Pack includes Jalapeno as one of its flavors.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="SPICY HOT PEPPER SEA SALT 3-PACK" target="HABANERO">
      <data key="d4">9.0</data>
      <data key="d5">The Spicy Hot Pepper Sea Salt 3-Pack includes Habanero as one of its flavors.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="VEGETARIAN BACON" target="4 OUNCE PACK OF 2">
      <data key="d4">7.0</data>
      <data key="d5">The user is looking for vegetarian bacon that comes in a 4-ounce pack of 2.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="FAIL" target="INVALID ACTION">
      <data key="d4">8.0</data>
      <data key="d5">The status of "Fail" was reached due to invalid actions.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="INVALID ACTION" target="NEXT">
      <data key="d4">8.0</data>
      <data key="d5">The action of clicking "Next" was invalid.</data>
      <data key="d6">5d356b8ff719763a38cecff22c4e17b7</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="META AGENT SEARCH">
      <data key="d4">9.0</data>
      <data key="d5">Meta Agent Search is an algorithm used within the ADAS research area to automatically create and discover new agents.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="SHENGRAN HU">
      <data key="d4">8.0</data>
      <data key="d5">Shengran Hu is one of the authors who formulated the research area of ADAS.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="CONG LU">
      <data key="d4">8.0</data>
      <data key="d5">Cong Lu is one of the authors who formulated the research area of ADAS.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="CHAIN-OF-THOUGHT">
      <data key="d4">7.0</data>
      <data key="d5">Chain-of-Thought is a technique used as a building block in agentic systems within the ADAS research area.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="ROCKT&#196;SCHEL, 2024">
      <data key="d4">6.0</data>
      <data key="d5">Rockt&#228;schel is cited in the paper for contributions to the research on agentic systems.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)" target="ZAHARIA ET AL., 2024">
      <data key="d4">6.0</data>
      <data key="d5">Zaharia et al. are cited in the paper for contributions to the research on agentic systems.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SHENGRAN HU" target="UNIVERSITY OF BRITISH COLUMBIA">
      <data key="d4">6.0</data>
      <data key="d5">Shengran Hu is affiliated with the University of British Columbia.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SHENGRAN HU" target="VECTOR INSTITUTE">
      <data key="d4">6.0</data>
      <data key="d5">Shengran Hu is affiliated with the Vector Institute.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="SHENGRAN HU" target="THOUGHT CLONING">
      <data key="d4">8.0</data>
      <data key="d5">Shengran Hu is one of the authors of the paper discussing Thought Cloning.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="SHENGRAN HU" target="GITHUB">
      <data key="d4">1.0</data>
      <data key="d5">Shengran Hu is the author of the framework code available on GitHub.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="SHENGRAN HU" target="ADAS">
      <data key="d4">14.0</data>
      <data key="d5">Shengran Hu is associated with the repository at https://github.com/ShengranHu/ADAS.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="CONG LU" target="UNIVERSITY OF BRITISH COLUMBIA">
      <data key="d4">6.0</data>
      <data key="d5">Cong Lu is affiliated with the University of British Columbia.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="CONG LU" target="VECTOR INSTITUTE">
      <data key="d4">6.0</data>
      <data key="d5">Cong Lu is affiliated with the Vector Institute.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MULTI-STEP PEER REVIEW AGENT">
      <data key="d4">22.0</data>
      <data key="d5">The Multi-Step Peer Review Agent is an example of an agent discovered by the Meta Agent Search algorithm.
The Multi-Step Peer Review Agent was discovered by Meta Agent Search in the Reading Comprehension domain.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="VERIFIED MULTIMODAL AGENT">
      <data key="d4">22.0</data>
      <data key="d5">The Verified Multimodal Agent is an example of an agent discovered by the Meta Agent Search algorithm.
The Verified Multimodal Agent was discovered by Meta Agent Search in the Math domain.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="DIVIDE AND CONQUER AGENT">
      <data key="d4">22.0</data>
      <data key="d5">The Divide and Conquer Agent is an example of an agent discovered by the Meta Agent Search algorithm.
The Divide and Conquer Agent was discovered by Meta Agent Search.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="META AGENT">
      <data key="d4">18.0</data>
      <data key="d5">Meta Agent Search is an algorithm where a meta agent programs other agents, tests their performance, and refines them iteratively.
Meta Agent Search uses meta agents to iteratively program new agents based on an archive of previous discoveries.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="AGENT ARCHIVE">
      <data key="d4">8.0</data>
      <data key="d5">The agent archive is used by the Meta Agent Search algorithm to store discovered agents and inform subsequent iterations.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="CODE">
      <data key="d4">7.0</data>
      <data key="d5">Code refers to the programming instructions used by the Meta Agent Search algorithm to define the behavior of agents.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="TURING COMPLETE">
      <data key="d4">8.0</data>
      <data key="d5">The Meta Agent Search algorithm leverages the Turing Complete nature of programming languages to enable the learning of any possible agentic system.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ADAS">
      <data key="d4">70.0</data>
      <data key="d5">Meta Agent Search is an algorithm in the research area of ADAS.
Meta Agent Search is an algorithm developed within the ADAS framework to demonstrate the approach of defining and searching for agents.
Meta Agent Search is an algorithm studied within the research area of Automated Design of Agentic Systems (ADAS).
ADAS showcases the potential and effectiveness of Meta Agent Search in discovering superior agents.
Meta Agent Search is part of the proposed research area ADAS.
Meta Agent Search is an algorithm used in ADAS to program new agents in code.
Meta Agent Search is a proposed method for ADAS.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b,4884e8429ca1e567dadf5e22b4b68274,6bdf681c0bd9e401ac72344a6a0ae479,7de66b94cf868b37b1df51dc545c415f,81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FMS">
      <data key="d4">9.0</data>
      <data key="d5">Meta Agent Search uses foundational models (FMs) as meta agents to program new agents.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FUNSEARCH">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses a similar practice to FunSearch in defining a "forward" function to create new agentic systems.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ARC">
      <data key="d4">25.0</data>
      <data key="d5">Meta Agent Search is evaluated using the ARC logic puzzle task as a benchmark.
Meta Agent Search discovers agents that are evaluated on the ARC benchmark.
Meta Agent Search is used to discover the best performing agents on the ARC benchmark.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="META AGENT SEARCH" target="DROP">
      <data key="d4">15.0</data>
      <data key="d5">Meta Agent Search is evaluated using the DROP benchmark to assess reading comprehension abilities.
Meta Agent Search is tested on the DROP benchmark for evaluating reading comprehension.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MGSM">
      <data key="d4">23.0</data>
      <data key="d5">Meta Agent Search is evaluated using the MGSM benchmark to assess math abilities.
Meta Agent Search is tested on the MGSM benchmark for evaluating math capabilities.
Meta Agent Search discovers agents that are evaluated on the MGSM domain.
MGSM is a benchmark used to evaluate the performance of agents discovered by Meta Agent Search in the math domain.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,2901d5e2711fa4f32d39cd8eea36cd71,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GSM8K">
      <data key="d4">15.0</data>
      <data key="d5">Meta Agent Search is evaluated using the GSM8K dataset to assess the transferability of discovered agents from MGSM math tasks.
Meta Agent Search improves accuracy in the GSM8K dataset compared to baselines.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GSM-HARD">
      <data key="d4">15.0</data>
      <data key="d5">Meta Agent Search is evaluated using the GSM-Hard dataset to assess the transferability of discovered agents from MGSM math tasks.
Meta Agent Search improves accuracy in the GSM-Hard dataset compared to baselines.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="CHAIN-OF-THOUGHT (COT)">
      <data key="d4">13.0</data>
      <data key="d5">Meta Agent Search uses the Chain-of-Thought (COT) strategy to generate, refine, and ensemble answers.
Meta Agent Search uses Chain-of-Thought (COT) as one of the state-of-the-art hand-designed agents for comparison.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="LLM DEBATE">
      <data key="d4">13.0</data>
      <data key="d5">Meta Agent Search uses the LLM Debate strategy involving multiple critics for enhanced refinement.
Meta Agent Search outperforms the LLM Debate algorithm in various domains.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="QUALITY-DIVERSITY">
      <data key="d4">19.0</data>
      <data key="d5">Meta Agent Search uses the Quality-Diversity strategy to explore novel or worthwhile agents.
Meta Agent Search uses Quality-Diversity as one of the state-of-the-art hand-designed agents for comparison.
Meta Agent Search outperforms the Quality-Diversity algorithm in various domains.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FORWARD FUNCTION">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search uses a forward function to define new agentic systems.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="VALIDATION DATA">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search uses validation data to evaluate the performance of generated agents.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="BOOTSTRAP CONFIDENCE INTERVAL">
      <data key="d4">21.0</data>
      <data key="d5">Meta Agent Search uses the bootstrap confidence interval as a metric to evaluate the performance of generated agents.
Meta Agent Search uses the bootstrap confidence interval to report the median accuracy and variability of agent performance.
Meta Agent Search reports test accuracy using bootstrap confidence intervals.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ITERATION">
      <data key="d4">16.0</data>
      <data key="d5">Meta Agent Search involves an iterative process of programming, evaluating, and updating agents.
Meta Agent Search involves repeated iterations to discover and refine agents.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ARCHIVE">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search maintains an archive of previous discoveries and evaluation metrics, updated at every iteration.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="EXPERIMENT">
      <data key="d4">16.0</data>
      <data key="d5">Meta Agent Search is evaluated through various experiments on different benchmarks and tasks.
The experiment was conducted using the Meta Agent Search method to discover the best agent.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="META AGENT SEARCH" target="BENCHMARK">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search is evaluated using benchmarks like ARC, DROP, and MGSM.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="F1 SCORE">
      <data key="d4">15.0</data>
      <data key="d5">Meta Agent Search uses F1 score as a performance metric, particularly in reading comprehension tasks.
Meta Agent Search uses F1 Score as a metric to evaluate agent performance.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ACCURACY RATE">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses accuracy rate as a performance metric, particularly in math tasks.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="DYNAMIC MEMORY">
      <data key="d4">13.0</data>
      <data key="d5">Meta Agent Search introduces dynamic memory for more refinements during the programming of new agents.
Meta Agent Search introduces dynamic memory for doing more refinements.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ENSEMBLING">
      <data key="d4">6.0</data>
      <data key="d5">Meta Agent Search uses ensembling to combine multiple answers generated by the Chain-of-Thought strategy.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="CRITIC">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses critics to provide feedback and enhance the refinement of generated agents.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="EFFICIENCY EXPERT">
      <data key="d4">13.0</data>
      <data key="d5">Meta Agent Search uses efficiency experts as critics to improve the efficiency of generated agents.
Meta Agent Search uses an efficiency expert to provide feedback on the efficiency of answers.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="READABILITY EXPERT">
      <data key="d4">13.0</data>
      <data key="d5">Meta Agent Search uses readability experts as critics to improve the readability of generated agents.
Meta Agent Search uses a readability expert to provide feedback on the readability of answers.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SIMPLICITY">
      <data key="d4">1.0</data>
      <data key="d5">Meta Agent Search aims to achieve simplicity in the generated agents, often evaluated by critics like the readability expert.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ARC CHALLENGE">
      <data key="d4">9.0</data>
      <data key="d5">Meta Agent Search is used to discover high-performance agents that outperform existing state-of-the-art hand-designed agents in the ARC challenge.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SELF-CONSISTENCY WITH CHAIN-OF-THOUGHT (COT-SC)">
      <data key="d4">6.0</data>
      <data key="d5">Meta Agent Search uses Self-Consistency with Chain-of-Thought (COT-SC) as one of the state-of-the-art hand-designed agents for comparison.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="LLM-DEBATE">
      <data key="d4">6.0</data>
      <data key="d5">Meta Agent Search uses LLM-Debate as one of the state-of-the-art hand-designed agents for comparison.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="EXPERTS">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search incorporates feedback from experts to refine answers more effectively.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ENSEMBLE">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses the ensemble process to combine multiple answers to produce a final, more accurate answer.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FALDOR ET AL., 2024">
      <data key="d4">5.0</data>
      <data key="d5">Faldor et al. have worked on open-endedness and AI-GAs, which are critical in Meta Agent Search.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="LEHMAN &amp; STANLEY, 2011">
      <data key="d4">5.0</data>
      <data key="d5">Lehman &amp; Stanley have contributed to prior works on open-endedness and AI-GAs, which are critical in Meta Agent Search.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="WANG ET AL., 2019, 2020">
      <data key="d4">5.0</data>
      <data key="d5">Wang et al. have contributed to prior works on open-endedness and AI-GAs, which are critical in Meta Agent Search.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ZHANG ET AL., 2024A">
      <data key="d4">1.0</data>
      <data key="d5">Zhang et al. have contributed to prior works on open-endedness and AI-GAs, which are critical in Meta Agent Search.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MULTIPLE CRITICS">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search introduces multiple critics for enhanced refinement.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="META-AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The meta-agent in Meta Agent Search is responsible for discovering high-performance agents.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="HUMAN-LIKE CRITIC">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses a human-like critic to provide feedback and simulate human evaluation.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SIMPLICITY EXPERT">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses a simplicity expert to provide feedback on the simplicity of answers.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FEEDBACK EFFICIENCY">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search aims to improve feedback efficiency to refine answers more effectively.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="REFINEMENT">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search involves the process of refinement to improve answers through iterative feedback and evaluation.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="HELD-OUT TEST SET">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses a held-out test set to evaluate the performance of discovered agents.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="PUBLIC TRAINING SET (EASY)">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses the Public Training Set (Easy) for training agents in the ARC challenge.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="VALIDATION SET">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses a validation set to assess the performance of agents.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="TEST SET">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses a test set to evaluate the final performance of agents.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="STOCHASTIC SAMPLING">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search uses stochastic sampling to reduce variance in the evaluation of agents.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="TOOL FUNCTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search provides tool functions to evaluate the generated transformation code in the ARC challenge.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ARC QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search involves solving ARC questions to evaluate agent performance.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="APPENDIX C">
      <data key="d4">6.0</data>
      <data key="d5">Appendix C contains detailed implementation of the best-discovered agent and more algorithmic details and examples of ARC questions.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="APPENDIX E">
      <data key="d4">6.0</data>
      <data key="d5">Appendix E contains more details about the baselines used in Meta Agent Search.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="META AGENT SEARCH" target="STEPPING STONES">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search uses the concept of stepping stones to progressively discover superior agents.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MMLU">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search is tested on the MMLU benchmark for evaluating multi-task problem solving.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GPQA">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search is tested on the GPQA benchmark for evaluating science capabilities.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="CHAIN-OF-THOUGHT">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search outperforms the Chain-of-Thought algorithm in various domains.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="STEP-BACK ABSTRACTION">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search outperforms the Step-back Abstraction algorithm in various domains.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ROLE ASSIGNMENT">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search outperforms the Role Assignment algorithm in various domains.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ACCURACY">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search uses accuracy as a metric to evaluate agent performance.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="EXPERIMENT SETTINGS">
      <data key="d4">7.0</data>
      <data key="d5">Experiment settings are the specific configurations under which Meta Agent Search is tested.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT SEARCH" target="FOUNDATIONAL MODELS (FMS)">
      <data key="d4">8.0</data>
      <data key="d5">Meta Agent Search optimizes agentic systems based on the knowledge possessed by foundational models.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="READING COMPREHENSION">
      <data key="d4">14.0</data>
      <data key="d5">Meta Agent Search is effective in the Reading Comprehension domain where foundational models possess adequate knowledge.
Meta Agent Search improves performance in the Reading Comprehension domain.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GSM8K (COBBE ET AL., 2021)">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search discovers agents that are evaluated on the GSM8K benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GSM-HARD (GAO ET AL., 2023)">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search discovers agents that are evaluated on the GSM-Hard benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SVAMP (PATEL ET AL., 2021)">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search discovers agents that are evaluated on the SVAMP benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="ASDIV (MIAO ET AL., 2020)">
      <data key="d4">1.0</data>
      <data key="d5">Meta Agent Search discovers agents that are evaluated on the ASDiv benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MULTI-TASK">
      <data key="d4">14.0</data>
      <data key="d5">Meta Agent Search outperforms baselines in the Multi-task domain.
Meta Agent Search improves performance in the Multi-task domain.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SCIENCE">
      <data key="d4">14.0</data>
      <data key="d5">Meta Agent Search outperforms baselines in the Science domain.
Meta Agent Search matches the state-of-the-art performance in the Science domain.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="HALLUCINATIONS">
      <data key="d4">6.0</data>
      <data key="d5">Meta Agent Search helps mitigate hallucinations in foundational models.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="CALCULATION MISTAKES">
      <data key="d4">6.0</data>
      <data key="d5">Meta Agent Search helps mitigate calculation mistakes in foundational models.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="META AGENT SEARCH" target="DYNAMIC ROLE-PLAYING ARCHITECTURE">
      <data key="d4">15.0</data>
      <data key="d5">Dynamic Role-Playing Architecture is a top agent discovered by Meta Agent Search.
Dynamic Role-Playing Architecture is a top agent discovered by Meta Agent Search in the math domain, transferred to non-math domains with specific performance metrics.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="META AGENT SEARCH" target="STRUCTURED MULTIMODAL FEEDBACK LOOP">
      <data key="d4">15.0</data>
      <data key="d5">Structured Multimodal Feedback Loop is a top agent discovered by Meta Agent Search.
Structured Multimodal Feedback Loop is a top agent discovered by Meta Agent Search in the math domain, transferred to non-math domains with specific performance metrics.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="META AGENT SEARCH" target="INTERACTIVE MULTIMODAL FEEDBACK LOOP">
      <data key="d4">15.0</data>
      <data key="d5">Interactive Multimodal Feedback Loop is a top agent discovered by Meta Agent Search.
Interactive Multimodal Feedback Loop is a top agent discovered by Meta Agent Search in the math domain, transferred to non-math domains with specific performance metrics.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SAFETY CONSIDERATIONS">
      <data key="d4">18.0</data>
      <data key="d5">Safety considerations are advised when executing untrusted model-generated code in Meta Agent Search.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SANDBOX ENVIRONMENTS">
      <data key="d4">16.0</data>
      <data key="d5">Sandbox environments are recommended for safely running untrusted model-generated code in Meta Agent Search.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="META AGENT SEARCH" target="HIGHER-ORDER ADAS">
      <data key="d4">14.0</data>
      <data key="d5">Higher-order ADAS involves improving the meta agent used in Meta Agent Search through self-referential meta-learning.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="META AGENT SEARCH" target="NOVELTY SEARCH ALGORITHMS">
      <data key="d4">12.0</data>
      <data key="d5">Novelty search algorithms can be incorporated into Meta Agent Search to explore interesting new designs.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="META AGENT SEARCH" target="SINGLE-STEP QA TASKS">
      <data key="d4">12.0</data>
      <data key="d5">Single-step QA tasks are used to evaluate Meta Agent Search.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="META AGENT SEARCH" target="MULTI-STEP INTERACTION">
      <data key="d4">12.0</data>
      <data key="d5">Multi-step interaction is proposed as a future direction for Meta Agent Search to handle more complex tasks.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="META AGENT SEARCH" target="COMPLEX DOMAINS">
      <data key="d4">6.0</data>
      <data key="d5">Complex domains are proposed as a future direction for Meta Agent Search to handle more complex tasks.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="META AGENT SEARCH" target="BEST AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The best agent was discovered through the Meta Agent Search method.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GITHUB">
      <data key="d4">7.0</data>
      <data key="d5">The code and agents from the Meta Agent Search experiment can be found on GitHub.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="META AGENT SEARCH" target="GPT-4O-MINI">
      <data key="d4">7.0</data>
      <data key="d5">Meta Agent Search could achieve improved results at a lower cost using the GPT-4o-mini model.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="CLAUDE">
      <data key="d4">7.0</data>
      <data key="d5">Claude is an example of a Foundation Model used for agentic tasks.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="ADAS">
      <data key="d4">8.0</data>
      <data key="d5">Foundation Models (FMs) are used as modules in the control flow of agentic systems within the ADAS framework.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="AGENTIC SYSTEMS">
      <data key="d4">8.0</data>
      <data key="d5">Foundation Models (FMs) are used as modules in the control flow of agentic systems to solve tasks.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="AI-GENERATING ALGORITHMS (AI-GAS)">
      <data key="d4">9.0</data>
      <data key="d5">Foundation Models are used in AI-GAs to write code for discovering better optimization algorithms, programming loss functions, and creating learning environments.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="AUTOML">
      <data key="d4">9.0</data>
      <data key="d5">Foundation Models are used in AutoML to write code for discovering better optimization algorithms, programming loss functions, and creating learning environments.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="OMNI-EPIC">
      <data key="d4">8.0</data>
      <data key="d5">OMNI-EPIC uses Foundation Models to create robotics learning environments by programming in code.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="FUNSEARCH">
      <data key="d4">8.0</data>
      <data key="d5">FunSearch uses Foundation Models to write code for discovering better optimization algorithms.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="EOH">
      <data key="d4">8.0</data>
      <data key="d5">EoH uses Foundation Models to write code for discovering better optimization algorithms.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="DISCOPOP">
      <data key="d4">8.0</data>
      <data key="d5">DiscoPOP uses Foundation Models to program the loss function for preference learning in FM alignment training.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="EUREKA">
      <data key="d4">8.0</data>
      <data key="d5">Eureka uses Foundation Models to write reward functions for reinforcement learning in robotics.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="LANGUAGE-TO-REWARD">
      <data key="d4">8.0</data>
      <data key="d5">Language-to-Reward uses Foundation Models to write reward functions for reinforcement learning in robotics.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="FOUNDATION MODELS (FMS)" target="FRAMEWORK">
      <data key="d4">7.0</data>
      <data key="d5">The framework includes querying Foundation Models as part of its basic functions.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT" target="HU &amp; CLUNE, 2024">
      <data key="d4">6.0</data>
      <data key="d5">Hu &amp; Clune are cited in the paper for contributions to the research on chain-of-thought planning and reasoning.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Chain-of-Thought is a manually designed agent used for various tasks with specific performance metrics.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT" target="FM MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The Chain-of-Thought method is used in the FM Module for step-by-step reasoning and solving tasks.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT" target="FM_MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The FM_MODULE is used in the Chain-of-Thought method to handle 'thinking' and 'answer' processes.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="VECTOR INSTITUTE" target="ADAS">
      <data key="d4">12.0</data>
      <data key="d5">The Vector Institute supported the work on ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="EXPERTS">
      <data key="d4">7.0</data>
      <data key="d5">Experts are used by the Multi-Step Peer Review Agent to review tasks and provide answers.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="REVIEWERS">
      <data key="d4">7.0</data>
      <data key="d5">Reviewers evaluate the answers provided by the Multi-Step Peer Review Agent.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="ENSEMBLE ANSWER">
      <data key="d4">7.0</data>
      <data key="d5">The Multi-Step Peer Review Agent uses ensemble answers to provide more accurate solutions to tasks.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="GPQA">
      <data key="d4">14.0</data>
      <data key="d5">The Multi-Step Peer Review Agent was discovered in the GPQA domain.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="PHYSICS CRITIC">
      <data key="d4">12.0</data>
      <data key="d5">In the Multi-Step Peer Review Agent, one of the roles assigned to a critic module is Physics Critic.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="CHEMISTRY CRITIC">
      <data key="d4">12.0</data>
      <data key="d5">In the Multi-Step Peer Review Agent, one of the roles assigned to a critic module is Chemistry Critic.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="BIOLOGY CRITIC">
      <data key="d4">12.0</data>
      <data key="d5">In the Multi-Step Peer Review Agent, one of the roles assigned to a critic module is Biology Critic.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="GENERAL CRITIC">
      <data key="d4">12.0</data>
      <data key="d5">In the Multi-Step Peer Review Agent, one of the roles assigned to a critic module is General Critic.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="MULTI-STEP PEER REVIEW AGENT" target="REIN ET AL., 2023">
      <data key="d4">14.0</data>
      <data key="d5">Rein et al. are the authors associated with the discovery of the Multi-Step Peer Review Agent in the Reading Comprehension domain, published in 2023.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="VERIFIED MULTIMODAL AGENT" target="VISUAL PARADIGM">
      <data key="d4">7.0</data>
      <data key="d5">Visual Paradigm is a method used by the Verified Multimodal Agent to handle tasks involving visual data.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="VERIFIED MULTIMODAL AGENT" target="VISUAL ANALYZER">
      <data key="d4">7.0</data>
      <data key="d5">Visual Analyzer is a component of the Verified Multimodal Agent that analyzes visual data to provide answers.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="VERIFIED MULTIMODAL AGENT" target="MGSM">
      <data key="d4">14.0</data>
      <data key="d5">The Verified Multimodal Agent was discovered in the MGSM domain.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="VERIFIED MULTIMODAL AGENT" target="SHI ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">Shi et al. are the authors associated with the discovery of the Verified Multimodal Agent in the Math domain, published in 2023.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="DIVIDE AND CONQUER AGENT" target="SUB-PROBLEM">
      <data key="d4">7.0</data>
      <data key="d5">The Divide and Conquer Agent divides tasks into sub-problems and solves them iteratively.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="DIVIDE AND CONQUER AGENT" target="PHYSICS EXPERT">
      <data key="d4">12.0</data>
      <data key="d5">In the Divide and Conquer Agent, one of the roles assigned to a specialized expert is Physics Expert.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="DIVIDE AND CONQUER AGENT" target="CHEMISTRY EXPERT">
      <data key="d4">12.0</data>
      <data key="d5">In the Divide and Conquer Agent, one of the roles assigned to a specialized expert is Chemistry Expert.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="DIVIDE AND CONQUER AGENT" target="BIOLOGY EXPERT">
      <data key="d4">12.0</data>
      <data key="d5">In the Divide and Conquer Agent, one of the roles assigned to a specialized expert is Biology Expert.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="CLAUDE" target="ANTHROPIC">
      <data key="d4">15.0</data>
      <data key="d5">Claude is a Foundation Model developed by Anthropic.Anthropic is the organization that developed the Claude Foundation Model.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="HOG" target="CONVOLUTIONAL NEURAL NETWORKS (CNNS)">
      <data key="d4">8.0</data>
      <data key="d5">HOG features were eventually replaced by learned features from Convolutional Neural Networks.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="HOG" target="COMPUTER VISION">
      <data key="d4">7.0</data>
      <data key="d5">HOG features were used in early computer vision tasks before being replaced by learned features.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="HOG" target="DALAL &amp; TRIGGS, 2005">
      <data key="d4">6.0</data>
      <data key="d5">Dalal &amp; Triggs contributed to the research on HOG features in computer vision.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="CONVOLUTIONAL NEURAL NETWORKS (CNNS)" target="NEURAL ARCHITECTURE SEARCH">
      <data key="d4">14.0</data>
      <data key="d5">Neural Architecture Search is used to design high-performing Convolutional Neural Networks.Neural Architecture Search is a method used to design high-performing Convolutional Neural Networks.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="CONVOLUTIONAL NEURAL NETWORKS (CNNS)" target="COMPUTER VISION">
      <data key="d4">7.0</data>
      <data key="d5">Convolutional Neural Networks are used in computer vision to learn features from data.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="CONVOLUTIONAL NEURAL NETWORKS (CNNS)" target="KRIZHEVSKY ET AL., 2012">
      <data key="d4">6.0</data>
      <data key="d5">Krizhevsky et al. contributed to the research on Convolutional Neural Networks.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="ELSKEN">
      <data key="d4">1.0</data>
      <data key="d5">Elsken contributed to the research on Neural Architecture Search.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="ELSKEN ET AL., 2019">
      <data key="d4">16.0</data>
      <data key="d5">Elsken et al. discussed Neural Architecture Search (NAS) in 2019.
Elsken et al. contributed to the method of Neural Architecture Search, published in 2019.
Elsken et al. are the authors of research on Neural Architecture Search, published in 2019.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="ADAS">
      <data key="d4">18.0</data>
      <data key="d5">Neural Architecture Search is a method within AutoML that is conceptually similar to the optimization processes in ADAS.
Neural Architecture Search provides insights into neural networks, similar to how ADAS provides insights into agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274,7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="AI-GENERATING ALGORITHMS (AI-GAS)">
      <data key="d4">8.0</data>
      <data key="d5">Neural Architecture Search is a method that falls under the first pillar of AI-GAs, aiming to automate the design of neural network architectures.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="HU ET AL., 2021">
      <data key="d4">7.0</data>
      <data key="d5">Hu et al. are the authors of research on Neural Architecture Search, published in 2021.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="NEURAL ARCHITECTURE SEARCH" target="LU ET AL., 2019">
      <data key="d4">7.0</data>
      <data key="d5">Lu et al. are the authors of research on Neural Architecture Search, published in 2019.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AUTO ML" target="AI-GENERATING ALGORITHMS (AI-GAS)">
      <data key="d4">14.0</data>
      <data key="d5">Both AutoML and AI-Generating Algorithms automate the creation of AI systems.Both AutoML and AI-Generating Algorithms are methods that automate the creation of AI systems.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AUTO ML" target="HUTTER ET AL., 2019">
      <data key="d4">6.0</data>
      <data key="d5">Hutter et al. contributed to the research on AutoML methods.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS (AI-GAS)" target="CLUNE, 2019">
      <data key="d4">13.0</data>
      <data key="d5">Clune contributed to the research on AI-Generating Algorithms.
Clune is the author of research on AI-GAs, published in 2019.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS (AI-GAS)" target="ADAS">
      <data key="d4">8.0</data>
      <data key="d5">ADAS aims to invent novel building blocks and design powerful agentic systems, which aligns with the goals of AI-GAs to learn more components in AI systems.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS (AI-GAS)" target="AUTOML">
      <data key="d4">9.0</data>
      <data key="d5">Both AI-GAs and AutoML aim to automate the design and learning processes in AI systems.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS (AI-GAS)" target="MAML">
      <data key="d4">8.0</data>
      <data key="d5">MAML is an algorithm that falls under the second pillar of AI-GAs, allowing "learning to learn" for better sample efficiency and generalizability.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS (AI-GAS)" target="META-RL">
      <data key="d4">8.0</data>
      <data key="d5">Meta-RL is an algorithm that falls under the second pillar of AI-GAs, allowing "learning to learn" for better sample efficiency and generalizability.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS (AI-GAS)" target="POET">
      <data key="d4">8.0</data>
      <data key="d5">POET is an algorithm that falls under the third pillar of AI-GAs, aiming to generate learning environments in an open-ended manner.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS (AI-GAS)" target="OMNI-EPIC">
      <data key="d4">8.0</data>
      <data key="d5">OMNI-EPIC is an algorithm that falls under the third pillar of AI-GAs, aiming to generate learning environments in an open-ended manner.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="HU &amp; CLUNE, 2024" target="CHAIN-OF-THOUGHT-BASED PLANNING AND REASONING METHODS">
      <data key="d4">6.0</data>
      <data key="d5">Hu &amp; Clune are the authors who contributed to the development of chain-of-thought-based planning and reasoning methods, published in 2024.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="LEWIS ET AL., 2020" target="MEMORY STRUCTURES">
      <data key="d4">6.0</data>
      <data key="d5">Lewis et al. are cited in the paper for contributions to the research on memory structures in agentic systems.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="ZHANG ET AL., 2024C" target="MEMORY STRUCTURES">
      <data key="d4">6.0</data>
      <data key="d5">Zhang et al. are cited in the paper for contributions to the research on memory structures in agentic systems.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="QU ET AL., 2024" target="TOOL USE">
      <data key="d4">12.0</data>
      <data key="d5">Qu et al. are cited in the paper for contributions to the research on tool use in agentic systems.
Qu et al. are the authors who contributed to the development of tool use techniques, published in 2024.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="MADAAN ET AL., 2024" target="SELF-REFINE (MADAAN ET AL., 2024)">
      <data key="d4">6.0</data>
      <data key="d5">Madaan et al. are the authors of the Self-Refine algorithm.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="TOOL USE" target="NAKANO ET AL., 2021">
      <data key="d4">6.0</data>
      <data key="d5">Nakano et al. are the authors who contributed to the development of tool use techniques, published in 2021.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="TOOL USE" target="AGENTINSTRUCT">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct generates data to teach AI models the skill of tool use.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="TOOL USE" target="CONTENT TRANSFORMATION FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Tool use involves enabling models to interact with external tools or services, which is part of the Content Transformation Flow.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="EXPERTS" target="SIMPLICITY">
      <data key="d4">7.0</data>
      <data key="d5">Experts evaluate the simplicity trait in the feedback mechanism of ADAS.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="META AGENT" target="NAME">
      <data key="d4">9.0</data>
      <data key="d5">The meta agent provides the name of the next agent architecture in the "name" section of the output.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="CODE">
      <data key="d4">9.0</data>
      <data key="d5">The meta agent provides the complete Python code for the "forward()" function in the "code" section of the output.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="FRAMEWORK">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent uses a simple framework to implement basic functions such as querying Foundation Models and formatting prompts.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="APPENDIX B">
      <data key="d4">7.0</data>
      <data key="d5">The meta agent's framework code is available in Appendix B.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="APPENDICES C AND D">
      <data key="d4">7.0</data>
      <data key="d5">Additional information relevant to the meta agent is available in Appendices C and D.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="OUTPUT INSTRUCTION AND EXAMPLE">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent uses the output instruction and example to guide its generation of the output.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="META AGENT" target="ARC CHALLENGE">
      <data key="d4">16.0</data>
      <data key="d5">The META AGENT is designed to generate agents that can solve tasks in the ARC CHALLENGE by generating code solutions.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="META AGENT" target="GPT-4O-2024-05-13">
      <data key="d4">33.0</data>
      <data key="d5">The META AGENT uses the GPT-4O-2024-05-13 language model to perform tasks in the ARC CHALLENGE.
The meta agent uses the GPT-4o-2024-05-13 model for evaluation.
The meta agent uses GPT-4o-2024-05-13 for its operations.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959,4b43decac6833d1515992f8869ecada7,84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="META AGENT" target="DROP">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent aims to find an optimal agent performing well on the DROP benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="META AGENT" target="GPT-3.5-TURBO-0125">
      <data key="d4">7.0</data>
      <data key="d5">Discovered agents and baselines are evaluated using GPT-3.5-turbo-0125 to reduce compute cost.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="META AGENT" target="GPQA">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent aims to find an optimal agent performing well on the GPQA benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="META AGENT" target="MGSM">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent aims to find an optimal agent performing well on the MGSM benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="META AGENT" target="MMLU">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent aims to find an optimal agent performing well on the MMLU benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="META AGENT" target="OPENAI, 2024">
      <data key="d4">7.0</data>
      <data key="d5">OpenAI is mentioned in the context of the meta agent using GPT-4o-2024-05-13.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="META AGENT" target="AGENTIC SYSTEMS">
      <data key="d4">7.0</data>
      <data key="d5">The meta agent is part of the discussion on automated design of agentic systems.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="CODE" target="TASKINFO">
      <data key="d4">8.0</data>
      <data key="d5">Task information is used as input for generating the code.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="CODE" target="THINKING">
      <data key="d4">9.0</data>
      <data key="d5">The thought process influences the generation and refinement of the code.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="COMPUTE" target="LEARNED SOLUTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Learned solutions become more efficient over time as more compute becomes available.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="DATA" target="LEARNED SOLUTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Learned solutions become more efficient over time as more data becomes available.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="HISTORY OF MACHINE LEARNING" target="HAND-DESIGNED SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">The history of machine learning shows that hand-designed solutions are eventually replaced by learned solutions.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="HISTORY OF MACHINE LEARNING" target="LEARNED SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">The history of machine learning shows that learned solutions become more efficient over time.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="HAND-DESIGNED SOLUTIONS" target="LEARNED SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Hand-designed solutions are often replaced by more efficient learned solutions in machine learning.</data>
      <data key="d6">c3d0436082aada237ee4bee645f16059</data>
    </edge>
    <edge source="HUTTER ET AL., 2019" target="AUTOML">
      <data key="d4">21.0</data>
      <data key="d5">Hutter et al. discussed AutoML methods in 2019.
Hutter et al. contributed to the research area of AutoML, published in 2019.
Hutter et al. are the authors of research on AutoML, published in 2019.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="CLUNE, 2019" target="AI-GA">
      <data key="d4">8.0</data>
      <data key="d5">Clune introduced AI-Generating Algorithms (AI-GAs) in 2019.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="CLUNE, 2019" target="AI-GAS">
      <data key="d4">6.0</data>
      <data key="d5">Clune contributed to the research area of AI-GAs, published in 2019.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="CLUNE, 2019" target="AGI">
      <data key="d4">12.0</data>
      <data key="d5">Clune discusses the potential of AI-GA and AGI in a work published in 2019.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="KRIZHEVSKY ET AL., 2012" target="CNN">
      <data key="d4">9.0</data>
      <data key="d5">Krizhevsky et al. introduced Convolutional Neural Networks (CNNs) in 2012.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="AUTOML" target="ADAS">
      <data key="d4">15.0</data>
      <data key="d5">ADAS is similar to the research area of AutoML, focusing on the automation of agentic systems.
ADAS aims to invent novel building blocks and design powerful agentic systems, which aligns with the goals of AutoML to automate the design of neural network architectures and learning algorithms.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274,7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="AI-GA" target="AGI">
      <data key="d4">16.0</data>
      <data key="d5">ADAS is a new area in AI-GA research that could potentially contribute to the creation of AGI.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="LLM ALIGNMENT" target="LEARNED LOSS FUNCTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Learned loss functions are used in LLM alignment to optimize model performance.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="LEARNED LOSS FUNCTIONS" target="LU ET AL., 2024A">
      <data key="d4">8.0</data>
      <data key="d5">Lu et al. discussed learned loss functions in 2024a.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="DPO" target="RAFAILOV ET AL., 2024">
      <data key="d4">7.0</data>
      <data key="d5">Rafailov et al. discussed DPO, a hand-designed loss function, in 2024.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="AI SCIENTIST" target="LU ET AL., 2024B">
      <data key="d4">8.0</data>
      <data key="d5">Lu et al. introduced the AI Scientist in 2024b.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="OMNI-EPIC" target="FALDOR ET AL., 2024">
      <data key="d4">27.0</data>
      <data key="d5">Faldor et al. discussed OMNI-EPIC, a system for generating robotics learning environments, in 2024.
Faldor et al. are the authors of research on OMNI-EPIC, published in 2024.
Faldor et al. are the authors of the OMNI-EPIC algorithm.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb,81c504ffbcc5ed882e234802135295ba,dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="OMNI-EPIC" target="FMS">
      <data key="d4">16.0</data>
      <data key="d5">FMs are used in the OMNI-EPIC algorithm to create robotics learning environments by programming in code.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="FM">
      <data key="d4">7.0</data>
      <data key="d5">Foundation Models (FMs) are used as meta agents in ADAS.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="ADAS" target="SEARCH SPACE">
      <data key="d4">8.0</data>
      <data key="d5">The search space is a key component of ADAS, defining which agentic systems can be represented and discovered.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="ADAS" target="EVALUATION FUNCTION">
      <data key="d4">8.0</data>
      <data key="d5">The evaluation function is a key component of ADAS, defining how to evaluate a candidate agent on target objectives.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="ADAS" target="AGENTIC SYSTEMS">
      <data key="d4">9.0</data>
      <data key="d5">ADAS involves the automated design of agentic systems using a search algorithm to optimize an evaluation function.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="ADAS" target="AI-GAS">
      <data key="d4">7.0</data>
      <data key="d5">ADAS is similar to the research area of AI-GAs, focusing on the automated design and optimization of agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="ADAS" target="HUMAN-LIKE FEEDBACK">
      <data key="d4">8.0</data>
      <data key="d5">Human-like feedback is a component of the feedback mechanism in ADAS.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="ADAS" target="ARC CHALLENGE">
      <data key="d4">7.0</data>
      <data key="d5">ADAS demonstrates its proficiency in in-context learning through the ARC Challenge.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="ADAS" target="OPRO">
      <data key="d4">14.0</data>
      <data key="d5">OPRO is an attempt at ADAS that focuses on learning better prompts for agents.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="PROMPTBREEDER">
      <data key="d4">14.0</data>
      <data key="d5">PromptBreeder is an attempt at ADAS that focuses on learning better prompts for agents.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="SELF-DISCOVER">
      <data key="d4">14.0</data>
      <data key="d5">Self-Discover is an attempt at ADAS that focuses on learning better prompts for agents.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="EVOAGENT">
      <data key="d4">14.0</data>
      <data key="d5">EvoAgent is an attempt at ADAS that optimizes role definition in the prompt for agents.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="AGENTVERSE">
      <data key="d4">14.0</data>
      <data key="d5">AgentVerse is an attempt at ADAS that optimizes role definition in the prompt for agents.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="DYLAN">
      <data key="d4">14.0</data>
      <data key="d5">DyLAN is an attempt at ADAS that uses FMs to score the response quality of nodes in a network and prunes the connections.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="DSPY">
      <data key="d4">14.0</data>
      <data key="d5">DSPy is an attempt at ADAS that generates and optimizes nodes in a network.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="GPT-SWARM">
      <data key="d4">14.0</data>
      <data key="d5">GPT-Swarm is an attempt at ADAS that represents an agentic system in a graph and optimizes the connections between nodes.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="AGENTOPTIMIZER">
      <data key="d4">14.0</data>
      <data key="d5">AgentOptimizer is an attempt at ADAS that learns the tools used in agents.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="AGENT SYMBOLIC LEARNING">
      <data key="d4">14.0</data>
      <data key="d5">Agent Symbolic Learning is an attempt at ADAS that learns prompts, tools, and control flow together.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ADAS" target="API ACCESS">
      <data key="d4">18.0</data>
      <data key="d5">ADAS demonstrates that with available API access to powerful foundational models, it is easy to program powerful agentic systems.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="GPUS">
      <data key="d4">16.0</data>
      <data key="d5">ADAS can be programmed without the need for expensive hardware like GPUs.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="SAFE-ADAS">
      <data key="d4">16.0</data>
      <data key="d5">Safe-ADAS is a proposed direction to ensure that ADAS algorithms conduct their tasks safely and create only honest, helpful, and harmless agents.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="SEARCH ENGINE TOOLS">
      <data key="d4">12.0</data>
      <data key="d5">Search engine tools are existing human efforts that can be used as building blocks in ADAS to improve efficiency and performance.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="MULTI-OBJECTIVE ADAS">
      <data key="d4">14.0</data>
      <data key="d5">Multi-objective ADAS involves integrating multiple objectives, such as cost, latency, and robustness, in the optimization process of ADAS algorithms.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="EVALUATION FUNCTIONS">
      <data key="d4">14.0</data>
      <data key="d5">Evaluation functions are methods used in ADAS to assess the performance of discovered agents.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="CALDWELL, 2011">
      <data key="d4">10.0</data>
      <data key="d5">Caldwell is an author referenced in the text, contributing to discussions on AI and its implications, which are relevant to ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="META, 2024">
      <data key="d4">10.0</data>
      <data key="d5">Meta is an organization referenced in the text, contributing to AI research relevant to ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="ADAS" target="AGENTIC SYSTEM">
      <data key="d4">16.0</data>
      <data key="d5">ADAS aims to design powerful agentic systems.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="CANADA CIFAR AI CHAIRS PROGRAM">
      <data key="d4">12.0</data>
      <data key="d5">The Canada CIFAR AI Chairs program supported the work on ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="SCHMIDT FUTURES">
      <data key="d4">12.0</data>
      <data key="d5">Schmidt Futures provided grants to support the work on ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="OPEN PHILANTHROPY">
      <data key="d4">12.0</data>
      <data key="d5">Open Philanthropy provided grants to support the work on ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="NSERC DISCOVERY GRANT">
      <data key="d4">12.0</data>
      <data key="d5">The NSERC Discovery Grant supported the work on ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="RAFAEL COSMAN">
      <data key="d4">12.0</data>
      <data key="d5">Rafael Cosman made a donation to support the work on ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="JENNY ZHANG">
      <data key="d4">10.0</data>
      <data key="d5">Jenny Zhang provided discussions and feedback on the work on ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="RACH PRADHAN">
      <data key="d4">10.0</data>
      <data key="d5">Rach Pradhan provided discussions and feedback on the work on ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="RUIYU GOU">
      <data key="d4">10.0</data>
      <data key="d5">Ruiyu Gou provided discussions and feedback on the work on ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ADAS" target="NICHOLAS IOANNIDIS">
      <data key="d4">5.0</data>
      <data key="d5">Nicholas Ioannidis provided discussions and feedback on the work on ADAS.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="ARC" target="CHOLLET, 2019">
      <data key="d4">14.0</data>
      <data key="d5">Chollet introduced the ARC logic puzzle task in 2019.
Chollet is the author of the ARC logic puzzle task used as a benchmark in the experiments.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="ARC" target="CLAUDE-HAIKU">
      <data key="d4">7.0</data>
      <data key="d5">Claude-Haiku is used to evaluate the performance of agents on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ARC" target="CLAUDE-SONNET">
      <data key="d4">7.0</data>
      <data key="d5">Claude-Sonnet is used to evaluate the performance of agents on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ARC" target="CHAIN-OF-THOUGHT (WEI ET AL., 2022)">
      <data key="d4">6.0</data>
      <data key="d5">Chain-of-Thought is evaluated on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ARC" target="COT-SC (WANG ET AL., 2023B)">
      <data key="d4">6.0</data>
      <data key="d5">COT-SC is evaluated on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ARC" target="LLM DEBATE (DU ET AL., 2023)">
      <data key="d4">6.0</data>
      <data key="d5">LLM Debate is evaluated on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ARC" target="SELF-REFINE (MADAAN ET AL., 2024)">
      <data key="d4">6.0</data>
      <data key="d5">Self-Refine is evaluated on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ARC" target="QUALITY-DIVERSITY (LU ET AL., 2024C)">
      <data key="d4">6.0</data>
      <data key="d5">Quality-Diversity is evaluated on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ARC" target="STRUCTURED FEEDBACK AND ENSEMBLE AGENT">
      <data key="d4">7.0</data>
      <data key="d5">Structured Feedback and Ensemble Agent is evaluated on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ARC" target="HIERARCHICAL COMMITTEE REINFORCEMENT AGENT">
      <data key="d4">7.0</data>
      <data key="d5">Hierarchical Committee Reinforcement Agent is evaluated on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ARC" target="DYNAMIC MEMORY AND REFINEMENT AGENT">
      <data key="d4">7.0</data>
      <data key="d5">Dynamic Memory and Refinement Agent is evaluated on the ARC benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ARC" target="CHAIN-OF-THOUGHT (COT)">
      <data key="d4">7.0</data>
      <data key="d5">Chain-of-Thought (COT) is used as a baseline for experiments on ARC.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="ARC" target="SELF-CONSISTENCY WITH CHAIN-OF-THOUGHT (COT-SC)">
      <data key="d4">7.0</data>
      <data key="d5">Self-Consistency with Chain-of-Thought (COT-SC) is used as a baseline for experiments on ARC.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="ARC" target="LLM-DEBATE">
      <data key="d4">7.0</data>
      <data key="d5">LLM-Debate is used as a baseline for experiments on ARC.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="ARC" target="QUALITY-DIVERSITY">
      <data key="d4">7.0</data>
      <data key="d5">Quality-Diversity is used as a baseline for experiments on ARC.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="ARC" target="GPT-3.5-TURBO-0125">
      <data key="d4">7.0</data>
      <data key="d5">The ARC dataset is evaluated using the GPT-3.5-Turbo-0125 model, contributing to the cost of experiments.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="ARC" target="ORCA-3">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3 scored 92.47 on the ARC benchmark, a 12% improvement over Orca-2.5.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="DROP" target="DUA ET AL., 2019">
      <data key="d4">20.0</data>
      <data key="d5">Dua et al. discussed the DROP reading comprehension benchmark in 2019.
Dua et al. are the authors of the DROP benchmark used to assess reading comprehension abilities.
Dua et al. are the authors of the DROP benchmark.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="DROP" target="READING COMPREHENSION">
      <data key="d4">8.0</data>
      <data key="d5">The DROP benchmark is used to evaluate reading comprehension capabilities.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="DROP" target="DHEERU DUA, YIZHONG WANG, PRADEEP DASIGI, GABRIEL STANOVSKY, SAMEER SINGH, AND MATT GARDNER">
      <data key="d4">9.0</data>
      <data key="d5">Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt Gardner authored the paper "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="DROP" target="META_AGENT">
      <data key="d4">7.0</data>
      <data key="d5">The DROP dataset is used for evaluating the meta agent.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="DROP" target="DISCRETE REASONING">
      <data key="d4">8.0</data>
      <data key="d5">DROP assesses the ability to perform discrete reasoning.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="DROP" target="MULTIPLE PARAGRAPHS">
      <data key="d4">8.0</data>
      <data key="d5">DROP assesses comprehension and reasoning across multiple paragraphs.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="DROP" target="ORCA-3">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3 scored 71.14 on the DROP benchmark, a 22% improvement over Orca-2.5.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="DROP" target="EXACT MATCH/SPAN EXTRACTION PROBLEMS">
      <data key="d4">7.0</data>
      <data key="d5">DROP is a dataset used for exact match/span extraction problems where a ground-truth answer value is given.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="MGSM" target="SHI ET AL., 2023">
      <data key="d4">20.0</data>
      <data key="d5">Shi et al. discussed the MGSM math task benchmark in 2023.
Shi et al. are the authors of the MGSM benchmark used to evaluate math abilities.
Shi et al. are the authors of the MGSM benchmark.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,81c504ffbcc5ed882e234802135295ba,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="MGSM" target="PET RABBITS">
      <data key="d4">6.0</data>
      <data key="d5">Pet Rabbits are mentioned in the MGSM example question.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MGSM" target="PET DOGS">
      <data key="d4">6.0</data>
      <data key="d5">Pet Dogs are mentioned in the MGSM example question.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MGSM" target="PET CATS">
      <data key="d4">6.0</data>
      <data key="d5">Pet Cats are mentioned in the MGSM example question.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="GSM8K" target="ORCA-3">
      <data key="d4">31.0</data>
      <data key="d5">Orca-3 shows a 54% improvement on the GSM8K benchmark compared to Mistral-7b-Instruct.
Orca-3 showed a 54% improvement on the GSM8K benchmark.
Orca-3 scored 83.09 on the GSM8K benchmark, a 54% improvement over Orca-2.5.
Orca-3 shows significant performance improvements on the GSM8K benchmark.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="GSM8K" target="GPT-3.5-TURBO">
      <data key="d4">7.0</data>
      <data key="d5">GPT-3.5-turbo's accuracy scores on the GSM8K benchmark are reported in the Phi3 paper.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="GSM8K" target="PHI3">
      <data key="d4">1.0</data>
      <data key="d5">The Phi3 paper reports accuracy scores for GPT-3.5-turbo on the GSM8K benchmark.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="GSM8K" target="EXACT MATCH/SPAN EXTRACTION PROBLEMS">
      <data key="d4">7.0</data>
      <data key="d5">GSM8K is a dataset used for exact match/span extraction problems involving math-based questions.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="LU ET AL., 2024A" target="LU ET AL., 2024C">
      <data key="d4">6.0</data>
      <data key="d5">Lu et al. are the authors of studies in 2024a and 2024c discussing learned loss functions and open-endedness algorithms.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="LU ET AL., 2024A" target="DISCOPOP">
      <data key="d4">7.0</data>
      <data key="d5">Lu et al. are the authors of research on DiscoPOP, published in 2024.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="LU ET AL., 2024B" target="SUBJECTIVE ANSWER EVALUATIONS">
      <data key="d4">5.0</data>
      <data key="d5">Lu et al. are authors who have worked on subjective answer evaluations in ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="LU ET AL., 2024C" target="ZHANG ET AL., 2024A">
      <data key="d4">6.0</data>
      <data key="d5">Zhang et al. and Lu et al. discussed open-endedness algorithms in 2024a and 2024c, respectively.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="LU ET AL., 2024C" target="QUALITY-DIVERSITY">
      <data key="d4">36.0</data>
      <data key="d5">Lu et al. are the authors of an open-endedness algorithm that leverages human notions of interestingness, referenced in Meta Agent Search.
Lu et al. are the researchers who developed the Quality-Diversity method in 2024.
Lu et al. are the authors of the Quality-Diversity algorithm.
Lu et al. are the authors of the Quality-Diversity algorithm, published in 2024.
Lu et al. are the authors of research on Quality-Diversity, published in 2024.
Lu et al. are the authors of the Quality-Diversity algorithm.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,1a6353c9d196dc2debad7c27c902bcd7,24d7b89ae9522ae60d2317984951355b,7c08d98f503d722d7de13be55375c8cb,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="LU ET AL., 2024C" target="QUALITY-DIVERSITY (LU ET AL., 2024C)">
      <data key="d4">6.0</data>
      <data key="d5">Lu et al. are the authors of the Quality-Diversity algorithm.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ZHANG ET AL., 2024A" target="QUALITY-DIVERSITY">
      <data key="d4">5.0</data>
      <data key="d5">Zhang et al. are the authors of an open-endedness algorithm that leverages human notions of interestingness, referenced in Meta Agent Search.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b</data>
    </edge>
    <edge source="ZHANG ET AL., 2024A" target="OPEN-ENDED ALGORITHMS">
      <data key="d4">5.0</data>
      <data key="d5">Zhang et al. are authors who have worked on open-ended algorithms, relevant to novelty search algorithms.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="FERNANDO ET AL., 2024" target="YANG ET AL., 2024">
      <data key="d4">6.0</data>
      <data key="d5">Fernando et al. and Yang et al. discussed designing prompts in ADAS methods in 2024.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="FERNANDO ET AL., 2024" target="PROMPTBREEDER">
      <data key="d4">18.0</data>
      <data key="d5">Fernando et al. are the authors of PromptBreeder, an algorithm used within the search space of ADAS.
Fernando et al. are the authors of the PromptBreeder algorithm.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274,dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="YANG ET AL., 2024" target="OPRO">
      <data key="d4">12.0</data>
      <data key="d5">Yang et al. are the authors of the OPRO algorithm.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="BOYER &amp; MOORE, 1983" target="LADHA, 2024">
      <data key="d4">1.0</data>
      <data key="d5">Boyer and Moore (1983) and Ladha (2024) discussed the Turing Completeness of programming languages.</data>
      <data key="d6">81c504ffbcc5ed882e234802135295ba</data>
    </edge>
    <edge source="FALDOR ET AL., 2024" target="OPEN-ENDED ALGORITHMS">
      <data key="d4">5.0</data>
      <data key="d5">Faldor et al. are authors who have worked on open-ended algorithms, relevant to novelty search algorithms.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="AGENTIC SYSTEMS" target="MATHEMATICS">
      <data key="d4">6.0</data>
      <data key="d5">Agentic systems can be applied and evaluated for performance in the domain of mathematics.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="AGENTIC SYSTEMS" target="READING COMPREHENSION">
      <data key="d4">6.0</data>
      <data key="d5">Agentic systems can be applied and evaluated for performance in the domain of reading comprehension.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="AGENTIC SYSTEMS" target="CHASE, 2024">
      <data key="d4">6.0</data>
      <data key="d5">Chase contributed to the definitions and terminologies of agentic systems, published in 2024.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="AGENTIC SYSTEMS" target="NG, 2024">
      <data key="d4">6.0</data>
      <data key="d5">Ng contributed to the definitions and terminologies of agentic systems, published in 2024.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="AGENTIC SYSTEMS" target="HUMAN ORGANIZATIONS">
      <data key="d4">14.0</data>
      <data key="d5">Human organizations are closely connected to agentic systems in terms of complexity and operation.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="READING COMPREHENSION" target="AGENTINSTRUCT">
      <data key="d4">15.0</data>
      <data key="d5">AgentInstruct generates synthetic data to teach language models the skill of reading comprehension.
Reading comprehension capabilities are evaluated through targeted training with AgentInstruct.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="READING COMPREHENSION" target="QUESTION ANSWERING">
      <data key="d4">14.0</data>
      <data key="d5">Both are skills involving the understanding and processing of text.
Question answering is an application of reading comprehension.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="READING COMPREHENSION" target="READING COMPREHENSION TESTS">
      <data key="d4">8.0</data>
      <data key="d5">Reading comprehension tests are used to assess the skill of reading comprehension.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="READING COMPREHENSION" target="SKILLS">
      <data key="d4">8.0</data>
      <data key="d5">Reading comprehension is one of the skills developed or assessed by the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="READING COMPREHENSION" target="AGENTINSTRUCT FLOW">
      <data key="d4">9.0</data>
      <data key="d5">AgentInstruct Flow includes a specific flow for reading comprehension.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION" target="CONTENT TRANSFORMATION FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Content Transformation Flow aims to generate materials conducive to reading comprehension.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION" target="GROUNDED REASONING">
      <data key="d4">8.0</data>
      <data key="d5">Grounded reasoning is an application of reading comprehension.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION" target="LSAT LOGICAL REASONING TEST">
      <data key="d4">7.0</data>
      <data key="d5">The LSAT Logical Reasoning test features specialized question categories that require reading comprehension skills.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION" target="MISTRAL-INSTRUCT-7B">
      <data key="d4">7.0</data>
      <data key="d5">Reading comprehension capabilities of Mistral-Instruct-7b are evaluated and improved through targeted training.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MULTI-TASK PROBLEM SOLVING" target="MMLU">
      <data key="d4">8.0</data>
      <data key="d5">The MMLU benchmark is used to evaluate multi-task problem solving capabilities.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="ITERATION" target="MULTI-AGENT WORKFLOWS">
      <data key="d4">7.0</data>
      <data key="d5">Iteration is a key component of multi-agent workflows used to generate high-quality data.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="SCIENCE" target="GPQA">
      <data key="d4">8.0</data>
      <data key="d5">The GPQA benchmark is used to evaluate science capabilities.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="SEARCH SPACE" target="PROMPTBREEDER">
      <data key="d4">7.0</data>
      <data key="d5">PromptBreeder is an example of a search space design within ADAS, mutating text prompts of an agent.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="SEARCH SPACE" target="ZHUGE ET AL., 2024">
      <data key="d4">6.0</data>
      <data key="d5">Zhuge et al. explored search spaces such as graph structures within ADAS.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="EVALUATION FUNCTION" target="COST">
      <data key="d4">8.0</data>
      <data key="d5">Cost is an objective used in the evaluation function of ADAS to assess the economic efficiency of agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="EVALUATION FUNCTION" target="LATENCY">
      <data key="d4">8.0</data>
      <data key="d5">Latency is an objective used in the evaluation function of ADAS to assess the response time of agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="EVALUATION FUNCTION" target="SAFETY">
      <data key="d4">8.0</data>
      <data key="d5">Safety is an objective used in the evaluation function of ADAS to assess the reliability and security of agentic systems.</data>
      <data key="d6">4884e8429ca1e567dadf5e22b4b68274</data>
    </edge>
    <edge source="EVALUATION FUNCTION" target="ADAS ALGORITHMS">
      <data key="d4">2.0</data>
      <data key="d5">ADAS algorithms could benefit from more sophisticated evaluation functions to reduce costs.ADAS algorithms could benefit from more sophisticated evaluation functions to reduce costs and improve efficiency.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="ZHUGE ET AL., 2024" target="GPT-SWARM">
      <data key="d4">12.0</data>
      <data key="d5">Zhuge et al. are the authors of the GPT-Swarm algorithm.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="SUTTON &amp; BARTO, 2018" target="BALANCING EXPLORATION AND EXPLOITATION">
      <data key="d4">5.0</data>
      <data key="d5">Sutton &amp; Barto are authors who have worked on balancing exploration and exploitation in search algorithms, relevant to novelty search algorithms.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="COST" target="AGENTINSTRUCT">
      <data key="d4">7.0</data>
      <data key="d5">Cost is a limitation of AgentInstruct, as generating synthetic data with multiple agents can be resource-intensive.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="FMS" target="LOSS FUNCTION">
      <data key="d4">8.0</data>
      <data key="d5">FMs are used to program the loss function for preference learning in FM alignment training.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="FMS" target="EUREKA">
      <data key="d4">16.0</data>
      <data key="d5">FMs are used in the Eureka algorithm to write reward functions for reinforcement learning in robotics.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="FMS" target="LANGUAGE-TO-REWARD">
      <data key="d4">16.0</data>
      <data key="d5">FMs are used in the language-to-reward algorithm to write reward functions for reinforcement learning in robotics.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="FMS" target="PREFERENCE LEARNING">
      <data key="d4">8.0</data>
      <data key="d5">FMs are used to program the loss function for preference learning in FM alignment training.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="FMS" target="ROBOTICS LEARNING ENVIRONMENTS">
      <data key="d4">8.0</data>
      <data key="d5">FMs are used to create robotics learning environments by programming in code.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="FUNSEARCH" target="ROMERA-PAREDES ET AL., 2024">
      <data key="d4">12.0</data>
      <data key="d5">Romera-Paredes et al. are the authors of the FunSearch algorithm, referenced in Meta Agent Search.
Romera-Paredes et al. are the authors of research on FunSearch, published in 2024.</data>
      <data key="d6">24d7b89ae9522ae60d2317984951355b,7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="LLM DEBATE" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">LLM Debate is a manually designed agent used for various tasks with specific performance metrics.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Quality-Diversity is a manually designed agent used for various tasks with specific performance metrics.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="NOVELTY SEARCH ALGORITHMS">
      <data key="d4">12.0</data>
      <data key="d5">Quality-Diversity is a concept that can be incorporated into novelty search algorithms to balance exploration and quality of solutions.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="QUALITY-DIVERSITY" target="CULLY &amp; DEMIRIS, 2017">
      <data key="d4">10.0</data>
      <data key="d5">Cully &amp; Demiris are authors who have worked on Quality-Diversity in search algorithms, relevant to novelty search algorithms.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="FORWARD FUNCTION" target="AGENT SYSTEM">
      <data key="d4">8.0</data>
      <data key="d5">The Agent System uses the forward function to process task information.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="EXPERIMENT" target="ENSEMBLE AGENT">
      <data key="d4">7.0</data>
      <data key="d5">The Ensemble Agent was used in the experiment to generate initial candidate solutions.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="CRITIC" target="FM_MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The FM_MODULE is used in the Critic method to handle 'feedback' and 'correct' processes.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="TRANSFORMATION RULE">
      <data key="d4">17.0</data>
      <data key="d5">The ARC challenge involves learning transformation rules of grid patterns from examples.
The ARC CHALLENGE involves learning a TRANSFORMATION RULE from example input-output grids.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7,4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="GREENBLATT, 2024">
      <data key="d4">6.0</data>
      <data key="d5">Greenblatt followed common practice in requiring the agent to write code for the transformation rule in the ARC challenge.</data>
      <data key="d6">1a6353c9d196dc2debad7c27c902bcd7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="EXAMPLE INPUT-OUTPUT GRID">
      <data key="d4">18.0</data>
      <data key="d5">The ARC CHALLENGE involves using EXAMPLE INPUT-OUTPUT GRID to learn transformation rules.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="GPT-3.5-TURBO-0125">
      <data key="d4">14.0</data>
      <data key="d5">The GPT-3.5-TURBO-0125 language model is used to evaluate discovered agents and baselines in the ARC CHALLENGE.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="EXACT MATCH">
      <data key="d4">8.0</data>
      <data key="d5">The EXACT MATCH metric is used to calculate the accuracy rate in the ARC CHALLENGE.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="INPUT GRID">
      <data key="d4">8.0</data>
      <data key="d5">The INPUT GRID is part of the ARC CHALLENGE, serving as the input for learning transformation rules.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="OUTPUT GRID">
      <data key="d4">8.0</data>
      <data key="d5">The OUTPUT GRID is part of the ARC CHALLENGE, produced by applying a transformation rule to the input grid.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="ARC CHALLENGE" target="EXPERIMENT DETAILS">
      <data key="d4">1.0</data>
      <data key="d5">The EXPERIMENT DETAILS provide information about the experiments conducted for the ARC CHALLENGE.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="LLM-DEBATE" target="PHYSICS EXPERT">
      <data key="d4">12.0</data>
      <data key="d5">In LLM-Debate, one of the roles assigned to a debate module is Physics Expert.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="LLM-DEBATE" target="CHEMISTRY EXPERT">
      <data key="d4">12.0</data>
      <data key="d5">In LLM-Debate, one of the roles assigned to a debate module is Chemistry Expert.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="LLM-DEBATE" target="BIOLOGY EXPERT">
      <data key="d4">12.0</data>
      <data key="d5">In LLM-Debate, one of the roles assigned to a debate module is Biology Expert.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="LLM-DEBATE" target="SCIENCE GENERALIST">
      <data key="d4">12.0</data>
      <data key="d5">In LLM-Debate, one of the roles assigned to a debate module is Science Generalist.</data>
      <data key="d6">97457e990eb6e3c88c11c862f9e3265b</data>
    </edge>
    <edge source="VALIDATION SET" target="EXPERIMENT DETAILS">
      <data key="d4">8.0</data>
      <data key="d5">Experiment details include information about the validation set used for performance evaluation.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="TEST SET" target="EXPERIMENT DETAILS">
      <data key="d4">8.0</data>
      <data key="d5">Experiment details include information about the test set used for performance evaluation.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="APPENDIX E" target="EXPERIMENT SETTINGS">
      <data key="d4">1.0</data>
      <data key="d5">Appendix E contains more details about the baselines used in the experiment settings.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="STEPPING STONES" target="MEYERSON ET AL., 2023">
      <data key="d4">7.0</data>
      <data key="d5">Meyerson et al. contributed to the concept of combining different stepping stones, resembling crossover in evolution via LLMs.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="MMLU" target="HENDRYCKS ET AL., 2021">
      <data key="d4">6.0</data>
      <data key="d5">Hendrycks et al. are the authors of the MMLU benchmark.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="MMLU" target="STEM">
      <data key="d4">8.0</data>
      <data key="d5">STEM is one of the subject areas included in the MMLU benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MMLU" target="SOCIAL SCIENCES">
      <data key="d4">8.0</data>
      <data key="d5">Social Sciences is one of the subject areas included in the MMLU benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MMLU" target="HUMANITIES">
      <data key="d4">8.0</data>
      <data key="d5">Humanities is one of the subject areas included in the MMLU benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MMLU" target="CASSIOPEIA">
      <data key="d4">6.0</data>
      <data key="d5">Cassiopeia is mentioned in the MMLU example question.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MMLU" target="CENTURUS">
      <data key="d4">6.0</data>
      <data key="d5">Centurus is mentioned in the MMLU example question.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MMLU" target="CYGNUS">
      <data key="d4">6.0</data>
      <data key="d5">Cygnus is mentioned in the MMLU example question.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MMLU" target="CEPHEUS">
      <data key="d4">1.0</data>
      <data key="d5">Cepheus is mentioned in the MMLU example question.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="MMLU" target="ORCA-3">
      <data key="d4">31.0</data>
      <data key="d5">Orca-3 shows a 19% improvement on the MMLU benchmark compared to Mistral-7b-Instruct.
Orca-3 showed a 19% improvement on the MMLU benchmark.
Orca-3 scored 69.95 on the MMLU benchmark, a 19% improvement over Orca-2.5.
Orca-3 shows significant performance improvements on the MMLU benchmark across various levels of mathematics.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="MMLU" target="EQBENCH">
      <data key="d4">8.0</data>
      <data key="d5">EQBench has a strong correlation (r=0.97) with comprehensive multi-domain benchmarks like MMLU.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="MIRAGE">
      <data key="d4">8.0</data>
      <data key="d5">MMLU is one of the datasets included in the MIRAGE benchmark.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPQA" target="REIN ET AL., 2023">
      <data key="d4">6.0</data>
      <data key="d5">Rein et al. are the authors of the GPQA benchmark.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="GPQA" target="META_AGENT">
      <data key="d4">7.0</data>
      <data key="d5">The GPQA dataset is used for evaluating the meta agent.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="GPQA" target="BIOLOGY">
      <data key="d4">8.0</data>
      <data key="d5">Biology is one of the domains covered by the GPQA benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="GPQA" target="PHYSICS">
      <data key="d4">8.0</data>
      <data key="d5">Physics is one of the domains covered by the GPQA benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="GPQA" target="CHEMISTRY">
      <data key="d4">8.0</data>
      <data key="d5">Chemistry is one of the domains covered by the GPQA benchmark.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="GPQA" target="UNCERTAINTY PRINCIPLE">
      <data key="d4">7.0</data>
      <data key="d5">The uncertainty principle is discussed in the context of a GPQA example question.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="GPQA" target="ORCA-3">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3 scored 28.12 on the GPQA benchmark, a 4% decrease compared to Orca-2.5.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="STEP-BACK ABSTRACTION" target="ZHENG ET AL., 2023">
      <data key="d4">41.0</data>
      <data key="d5">Zheng et al. are the authors of the Step-back Abstraction algorithm.
Zheng et al. are the authors of the Step-back Abstraction algorithm, published in 2023.
Zheng et al. are the authors of research on Step-back Abstraction, published in 2023.
Zheng et al. are the authors of the Step-back Abstraction algorithm.
Step-back Abstraction is a method described by Zheng et al. in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="STEP-BACK ABSTRACTION" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Step-back Abstraction is a manually designed agent used for various tasks with specific performance metrics.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="STEP-BACK ABSTRACTION" target="REASONING AND PROBLEM-SOLVING DOMAINS">
      <data key="d4">7.0</data>
      <data key="d5">Step-back Abstraction is used as a baseline for experiments on Reasoning and Problem-Solving domains.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="ROLE ASSIGNMENT" target="XU ET AL., 2023">
      <data key="d4">25.0</data>
      <data key="d5">Xu et al. are the authors of the Role Assignment algorithm.
Xu et al. are the authors of the Role Assignment algorithm, published in 2023.
Xu et al. are the authors of research on Role Assignment, published in 2023.
Xu et al. are the authors of the Role Assignment algorithm.
Role Assignment is a method described by Xu et al. in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64,10fda605f670bcfccfc13c2ca0dde959,7c08d98f503d722d7de13be55375c8cb,97457e990eb6e3c88c11c862f9e3265b,bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="ROLE ASSIGNMENT" target="MANUALLY DESIGNED AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Role Assignment is a manually designed agent used for various tasks with specific performance metrics.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="ROLE ASSIGNMENT" target="REASONING AND PROBLEM-SOLVING DOMAINS">
      <data key="d4">7.0</data>
      <data key="d5">Role Assignment is used as a baseline for experiments on Reasoning and Problem-Solving domains.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="ACCURACY" target="AGENTINSTRUCT">
      <data key="d4">7.0</data>
      <data key="d5">Accuracy is a limitation of AgentInstruct, as synthetic data may not perfectly replicate real-world data.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="EXPERIMENT SETTINGS" target="APPENDIX D">
      <data key="d4">6.0</data>
      <data key="d5">Appendix D contains more details about the experiment settings.</data>
      <data key="d6">bc26e68b0b2783ba912b9e5606d9eb0b</data>
    </edge>
    <edge source="CLAUDE-HAIKU" target="ANTHROPIC, 2024A">
      <data key="d4">6.0</data>
      <data key="d5">Anthropic is the organization that developed Claude-Haiku.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="CLAUDE-SONNET" target="ANTHROPIC, 2024B">
      <data key="d4">6.0</data>
      <data key="d5">Anthropic is the organization that developed Claude-Sonnet.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="SVAMP (PATEL ET AL., 2021)" target="PATEL ET AL., 2021">
      <data key="d4">6.0</data>
      <data key="d5">Patel et al. are the authors of the SVAMP benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="ASDIV (MIAO ET AL., 2020)" target="MIAO ET AL., 2020">
      <data key="d4">1.0</data>
      <data key="d5">Miao et al. are the authors of the ASDiv benchmark.</data>
      <data key="d6">2901d5e2711fa4f32d39cd8eea36cd71</data>
    </edge>
    <edge source="OPENAI, 2022" target="GPT-3.5-TURBO-0125">
      <data key="d4">7.0</data>
      <data key="d5">OpenAI is mentioned in the context of using GPT-3.5-turbo-0125 to evaluate discovered agents and baselines.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="PATEL ET AL., 2021" target="SVAMP">
      <data key="d4">6.0</data>
      <data key="d5">Patel et al. are the authors of the SVAMP dataset, published in 2021.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="MIAO ET AL., 2020" target="ASDIV">
      <data key="d4">6.0</data>
      <data key="d5">Miao et al. are the authors of the ASDiv dataset, published in 2020.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="EMBODIED AGENTS" target="VEMPRALA ET AL., 2023">
      <data key="d4">6.0</data>
      <data key="d5">Vemprala et al. are the authors who contributed to the development of new skills for embodied agents, published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="FM MODULES" target="HONG ET AL., 2023">
      <data key="d4">6.0</data>
      <data key="d5">Hong et al. are the authors who contributed to the development of techniques for assigning FM modules in agentic systems, published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="FM MODULES" target="QIAN ET AL., 2023">
      <data key="d4">6.0</data>
      <data key="d5">Qian et al. are the authors who contributed to the development of techniques for assigning FM modules in agentic systems, published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="FM MODULES" target="QIAN ET AL., 2024">
      <data key="d4">6.0</data>
      <data key="d5">Qian et al. are the authors who contributed to the development of techniques for assigning FM modules in agentic systems, published in 2024.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="HONG ET AL., 2023" target="ORGANIZATIONAL STRUCTURE">
      <data key="d4">12.0</data>
      <data key="d5">Hong et al. are authors who have worked on incorporating organizational structures for human companies in agents.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="HONG ET AL., 2023" target="AGENTIC SYSTEM">
      <data key="d4">14.0</data>
      <data key="d5">Hong et al. incorporated organizational structures of human companies into agents.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="SELF-INSTRUCTION" target="RICHARDS, 2023">
      <data key="d4">1.0</data>
      <data key="d5">Richards is the author who contributed to the development of self-instruction techniques, published in 2023.</data>
      <data key="d6">0b6b4880e77d40e284702da16be4ef64</data>
    </edge>
    <edge source="MAML" target="FINN ET AL., 2017">
      <data key="d4">7.0</data>
      <data key="d5">Finn et al. are the authors of research on MAML, published in 2017.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="META-RL" target="DUAN ET AL., 2017">
      <data key="d4">7.0</data>
      <data key="d5">Duan et al. are the authors of research on Meta-RL, published in 2017.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="META-RL" target="NORMAN &amp; CLUNE, 2023">
      <data key="d4">7.0</data>
      <data key="d5">Norman and Clune are the authors of research on Meta-RL, published in 2023.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="META-RL" target="WANG ET AL., 2016">
      <data key="d4">7.0</data>
      <data key="d5">Wang et al. are the authors of research on Meta-RL, published in 2016.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="META-RL" target="ZINTGRAF ET AL., 2021A">
      <data key="d4">7.0</data>
      <data key="d5">Zintgraf et al. are the authors of research on Meta-RL, published in 2021.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="META-RL" target="ZINTGRAF ET AL., 2021B">
      <data key="d4">7.0</data>
      <data key="d5">Zintgraf et al. are the authors of research on Meta-RL, published in 2021.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="POET" target="DHARNA ET AL., 2020">
      <data key="d4">7.0</data>
      <data key="d5">Dharna et al. are the authors of research on POET, published in 2020.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="POET" target="WANG ET AL., 2019">
      <data key="d4">7.0</data>
      <data key="d5">Wang et al. are the authors of research on POET, published in 2019.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="POET" target="WANG ET AL., 2020">
      <data key="d4">7.0</data>
      <data key="d5">Wang et al. are the authors of research on POET, published in 2020.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="EUREKA" target="MA ET AL., 2023">
      <data key="d4">19.0</data>
      <data key="d5">Ma et al. are the authors of research on Eureka, published in 2023.
Ma et al. are the authors of the Eureka algorithm.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb,dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="LANGUAGE-TO-REWARD" target="YU ET AL., 2023">
      <data key="d4">19.0</data>
      <data key="d5">Yu et al. are the authors of research on language-to-reward, published in 2023.
Yu et al. are the authors of the language-to-reward algorithm.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb,dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="HU ET AL., 2021" target="MULTI-OBJECTIVE ADAS">
      <data key="d4">10.0</data>
      <data key="d5">Hu et al. are authors who have worked on multi-objective optimization in agentic systems, relevant to ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="RAFALIOV ET AL., 2024" target="FM ALIGNMENT TRAINING">
      <data key="d4">7.0</data>
      <data key="d5">Rafailov et al. are the authors of research on FM alignment training, published in 2024.</data>
      <data key="d6">7c08d98f503d722d7de13be55375c8cb</data>
    </edge>
    <edge source="LOSS FUNCTION" target="RAFALOV ET AL., 2024">
      <data key="d4">12.0</data>
      <data key="d5">Rafailov et al. are the authors of a work that involves programming the loss function for preference learning in FM alignment training.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="SELF-DISCOVER" target="ZHOU ET AL., 2024A">
      <data key="d4">12.0</data>
      <data key="d5">Zhou et al. are the authors of the Self-Discover algorithm.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="EVOAGENT" target="YUAN ET AL., 2024">
      <data key="d4">12.0</data>
      <data key="d5">Yuan et al. are the authors of the EvoAgent algorithm.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="AGENTVERSE" target="CHEN, YUSHENG SU, JINGWEI ZUO, CHENG YANG, CHENFEI YUAN, CHI-MIN CHAN, HEYANG YU, YAXI LU, YI-HSIN HUNG, CHEN QIAN, ET AL.">
      <data key="d4">9.0</data>
      <data key="d5">The group of researchers authored the paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="AGENTVERSE" target="THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS">
      <data key="d4">8.0</data>
      <data key="d5">The paper "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors" was presented at The Twelfth International Conference on Learning Representations in 2023.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="DSPY" target="KHATTAB ET AL., 2024">
      <data key="d4">12.0</data>
      <data key="d5">Khattab et al. are the authors of the DSPy algorithm.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="AGENTOPTIMIZER" target="ZHANG ET AL., 2024B">
      <data key="d4">12.0</data>
      <data key="d5">Zhang et al. are the authors of the AgentOptimizer algorithm.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="AGENT SYMBOLIC LEARNING" target="ZHOU ET AL., 2024B">
      <data key="d4">12.0</data>
      <data key="d5">Zhou et al. are the authors of the Agent Symbolic Learning algorithm.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="AGI" target="BENGIO ET AL., 2024">
      <data key="d4">12.0</data>
      <data key="d5">Bengio et al. discuss the ethical considerations of advancing AI capabilities in a work published in 2024.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="AGI" target="BOSTROM, 2002">
      <data key="d4">12.0</data>
      <data key="d5">Bostrom discusses the ethical considerations of advancing AI capabilities in a work published in 2002.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="AGI" target="ECOFFET ET AL., 2020">
      <data key="d4">12.0</data>
      <data key="d5">Ecoffet et al. discuss the ethical considerations of advancing AI capabilities in a work published in 2020.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="AGI" target="YUDKOWSKY ET AL., 2008">
      <data key="d4">2.0</data>
      <data key="d5">Yudkowsky et al. discuss the ethical considerations of advancing AI capabilities in a work published in 2008.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="SAFETY CONSIDERATIONS" target="ROKON ET AL., 2020">
      <data key="d4">12.0</data>
      <data key="d5">Rokon et al. are the authors of a work that discusses safety considerations for executing model-generated code.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="SAFETY CONSIDERATIONS" target="YEE ET AL., 2010">
      <data key="d4">12.0</data>
      <data key="d5">Yee et al. are the authors of a work that discusses safety considerations for executing model-generated code.</data>
      <data key="d6">dc55f071b95dec721a9820d39cdb3ccd</data>
    </edge>
    <edge source="ZHOU ET AL., 2024B" target="EVALUATION FUNCTIONS">
      <data key="d4">5.0</data>
      <data key="d5">Zhou et al. are authors who have worked on intelligent evaluation functions in ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="SAFE-ADAS" target="CONSTITUTIONAL AI">
      <data key="d4">14.0</data>
      <data key="d5">Constitutional AI is a concept that can be incorporated into Safe-ADAS to ensure the creation of ethical and harmless agents.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="CONSTITUTIONAL AI" target="BAI ET AL., 2022">
      <data key="d4">10.0</data>
      <data key="d5">Bai et al. are authors who have worked on Constitutional AI, a concept relevant to Safe-ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="HIGHER-ORDER ADAS" target="LU ET AL., 2023">
      <data key="d4">10.0</data>
      <data key="d5">Lu et al. are authors who have worked on higher-order meta-learning in ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="MULTI-OBJECTIVE ADAS" target="HUANG ET AL., 2023">
      <data key="d4">10.0</data>
      <data key="d5">Huang et al. are authors who have worked on multi-objective optimization in agentic systems, relevant to ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="MULTI-OBJECTIVE ADAS" target="DEB ET AL., 2002">
      <data key="d4">10.0</data>
      <data key="d5">Deb et al. are authors who have worked on multi-objective search algorithms, relevant to ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="NOVELTY SEARCH ALGORITHMS" target="AI-GENERATING ALGORITHMS">
      <data key="d4">12.0</data>
      <data key="d5">AI-generating algorithms are methods that can be incorporated into novelty search algorithms to create new AI systems.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="NOVELTY SEARCH ALGORITHMS" target="OPEN-ENDED ALGORITHMS">
      <data key="d4">12.0</data>
      <data key="d5">Open-ended algorithms are methods that can be incorporated into novelty search algorithms to continuously explore and generate new solutions.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="AI-GENERATING ALGORITHMS" target="MOURET &amp; CLUNE, 2015">
      <data key="d4">10.0</data>
      <data key="d5">Mouret &amp; Clune are authors who have worked on AI-generating algorithms, relevant to novelty search algorithms.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="OPEN-ENDED ALGORITHMS" target="STANLEY &amp; LEHMAN, 2015">
      <data key="d4">5.0</data>
      <data key="d5">Stanley &amp; Lehman are authors who have worked on open-ended algorithms, relevant to novelty search algorithms.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="OPEN-ENDED ALGORITHMS" target="STANLEY ET AL., 2019">
      <data key="d4">5.0</data>
      <data key="d5">Stanley et al. are authors who have worked on open-ended algorithms, relevant to novelty search algorithms.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="CHIANG ET AL., 2024" target="SUBJECTIVE ANSWER EVALUATIONS">
      <data key="d4">5.0</data>
      <data key="d5">Chiang et al. are authors who have worked on subjective answer evaluations in ADAS.</data>
      <data key="d6">6bdf681c0bd9e401ac72344a6a0ae479</data>
    </edge>
    <edge source="AS" target="HUMAN ORGANIZATION">
      <data key="d4">18.0</data>
      <data key="d5">AS sheds light on the origins of complexity emerging from human organization and society.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="HUMAN ORGANIZATION" target="AGENTIC SYSTEM">
      <data key="d4">16.0</data>
      <data key="d5">Agentic systems simulate human organizations and societies.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="AGENTIC SYSTEM" target="PARK ET AL., 2023">
      <data key="d4">14.0</data>
      <data key="d5">Park et al. simulated a human town with agents.</data>
      <data key="d6">7de66b94cf868b37b1df51dc545c415f</data>
    </edge>
    <edge source="JENNY ZHANG" target="OMNI">
      <data key="d4">8.0</data>
      <data key="d5">Jenny Zhang is one of the authors of the paper titled "OMNI: Open-endedness via models of human notions of interestingness."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="DAWN SONG" target="MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING">
      <data key="d4">8.0</data>
      <data key="d5">Dawn Song is one of the authors of the paper discussing measuring massive multitask language understanding.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="WEI-LIN CHIANG, LIANMIN ZHENG, YING SHENG, ANASTASIOS NIKOLAS ANGELOPOULOS, TIANLE LI, DACHENG LI, HAO ZHANG, BANGHUA ZHU, MICHAEL JORDAN, JOSEPH E. GONZALEZ, AND ION STOICA" target="CHATBOT ARENA">
      <data key="d4">9.0</data>
      <data key="d5">The group of researchers authored the paper "Chatbot arena: An open platform for evaluating llms by human preference."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="FRAN&#199;OIS CHOLLET" target="ON THE MEASURE OF INTELLIGENCE">
      <data key="d4">9.0</data>
      <data key="d5">Fran&#231;ois Chollet authored the paper "On the measure of intelligence."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="KARL COBBE, VINEET KOSARAJU, MOHAMMAD BAVARIAN, MARK CHEN, HEEWOO JUN, LUKASZ KAISER, MATTHIAS PLAPPERT, JERRY TWOREK, JACOB HILTON, REIICHIRO NAKANO, ET AL." target="TRAINING VERIFIERS TO SOLVE MATH WORD PROBLEMS">
      <data key="d4">9.0</data>
      <data key="d5">The group of researchers authored the paper "Training verifiers to solve math word problems."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="TRAINING VERIFIERS TO SOLVE MATH WORD PROBLEMS" target="KARL COBBE">
      <data key="d4">8.0</data>
      <data key="d5">Karl Cobbe is one of the authors of the paper on training verifiers to solve math word problems.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="ANTOINE CULLY AND YIANNIS DEMIRIS" target="QUALITY AND DIVERSITY OPTIMIZATION">
      <data key="d4">9.0</data>
      <data key="d5">Antoine Cully and Yiannis Demiris authored the paper "Quality and diversity optimization: A unifying modular framework."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="ANTOINE CULLY AND YIANNIS DEMIRIS" target="IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION">
      <data key="d4">8.0</data>
      <data key="d5">The paper "Quality and diversity optimization: A unifying modular framework" was published in IEEE Transactions on Evolutionary Computation in 2017.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="N. DALAL AND B. TRIGGS" target="HISTOGRAMS OF ORIENTED GRADIENTS FOR HUMAN DETECTION">
      <data key="d4">9.0</data>
      <data key="d5">N. Dalal and B. Triggs authored the paper "Histograms of oriented gradients for human detection."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="KALYANMOY DEB, AMRIT PRATAP, SAMEER AGARWAL, AND TAMT MEYARIVAN" target="NSGA-II">
      <data key="d4">9.0</data>
      <data key="d5">Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, and TAMT Meyarivan authored the paper "A fast and elitist multiobjective genetic algorithm: Nsga-ii."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="KALYANMOY DEB, AMRIT PRATAP, SAMEER AGARWAL, AND TAMT MEYARIVAN" target="IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION">
      <data key="d4">8.0</data>
      <data key="d5">The paper "A fast and elitist multiobjective genetic algorithm: Nsga-ii" was published in IEEE Transactions on Evolutionary Computation in 2002.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="AARON DHARNA, JULIAN TOGELIUS, AND LISA B SOROS" target="CO-GENERATION OF GAME LEVELS AND GAME-PLAYING AGENTS">
      <data key="d4">9.0</data>
      <data key="d5">Aaron Dharna, Julian Togelius, and Lisa B Soros authored the paper "Co-generation of game levels and game-playing agents."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="AARON DHARNA, JULIAN TOGELIUS, AND LISA B SOROS" target="AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE AND INTERACTIVE DIGITAL ENTERTAINMENT">
      <data key="d4">8.0</data>
      <data key="d5">The paper "Co-generation of game levels and game-playing agents" was presented at the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment in 2020.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="YILUN DU, SHUANG LI, ANTONIO TORRALBA, JOSHUA B TENENBAUM, AND IGOR MORDATCH" target="IMPROVING FACTUALITY AND REASONING IN LANGUAGE MODELS THROUGH MULTIAGENT DEBATE">
      <data key="d4">9.0</data>
      <data key="d5">Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch authored the paper "Improving factuality and reasoning in language models through multiagent debate."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="DHEERU DUA, YIZHONG WANG, PRADEEP DASIGI, GABRIEL STANOVSKY, SAMEER SINGH, AND MATT GARDNER" target="PROCEEDINGS OF THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES">
      <data key="d4">8.0</data>
      <data key="d5">The paper "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs" was included in the proceedings edited by Jill Burstein, Christy Doran, and Thamar Solorio.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="YAN DUAN, JOHN SCHULMAN, XI CHEN, PETER L. BARTLETT, ILYA SUTSKEVER, AND PIETER ABBEEL" target="RL^2">
      <data key="d4">9.0</data>
      <data key="d5">Yan Duan, John Schulman, Xi Chen, Peter L. Bartlett, Ilya Sutskever, and Pieter Abbeel authored the paper "RL^2: Fast reinforcement learning via slow reinforcement learning."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="YAN DUAN, JOHN SCHULMAN, XI CHEN, PETER L. BARTLETT, ILYA SUTSKEVER, AND PIETER ABBEEL" target="INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS">
      <data key="d4">8.0</data>
      <data key="d5">The paper "RL^2: Fast reinforcement learning via slow reinforcement learning" was presented at the International Conference on Learning Representations in 2017.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="ADRIEN ECOFFET, JEFF CLUNE, AND JOEL LEHMAN" target="OPEN QUESTIONS IN CREATING SAFE OPEN-ENDED AI">
      <data key="d4">9.0</data>
      <data key="d5">Adrien Ecoffet, Jeff Clune, and Joel Lehman authored the paper "Open questions in creating safe open-ended AI: Tensions between control and creativity."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="ADRIEN ECOFFET, JEFF CLUNE, AND JOEL LEHMAN" target="CONFERENCE ON ARTIFICIAL LIFE">
      <data key="d4">8.0</data>
      <data key="d5">The paper "Open questions in creating safe open-ended AI: Tensions between control and creativity" was presented at the Conference on Artificial Life in 2020.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="THOMAS ELSKEN, JAN HENDRIK METZEN, AND FRANK HUTTER" target="JOURNAL OF MACHINE LEARNING RESEARCH">
      <data key="d4">8.0</data>
      <data key="d5">The paper "Neural architecture search: A survey" was published in the Journal of Machine Learning Research in 2019.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="CHELSEA FINN, PIETER ABBEEL, AND SERGEY LEVINE" target="PMLR">
      <data key="d4">8.0</data>
      <data key="d5">The paper "Model-agnostic meta-learning for fast adaptation of deep networks" was published in the Proceedings of Machine Learning Research (PMLR) in 2017.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="LUYU GAO, AMAN MADAAN, SHUYAN ZHOU, URI ALON, PENGFEI LIU, YIMING YANG, JAMIE CALLAN, AND GRAHAM NEUBIG" target="PMLR">
      <data key="d4">8.0</data>
      <data key="d5">The paper "Pal: Program-aided language models" was published in the Proceedings of Machine Learning Research (PMLR) in 2023.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="RYAN GREENBLATT" target="REDWOOD RESEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Ryan Greenblatt is associated with Redwood Research, which published his article "Getting 50% sota on arc-agi with gpt-4."</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="RYAN GREENBLATT" target="ARC-AGI">
      <data key="d4">7.0</data>
      <data key="d5">Ryan Greenblatt authored a technical report discussing achieving 50% SOTA on ARC-AGI with GPT-4.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="JILL BURSTEIN, CHRISTY DORAN, AND THAMAR SOLORIO" target="PROCEEDINGS OF THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES">
      <data key="d4">8.0</data>
      <data key="d5">Jill Burstein, Christy Doran, and Thamar Solorio edited the proceedings for the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="REDWOOD RESEARCH" target="SUBSTACK">
      <data key="d4">1.0</data>
      <data key="d5">Redwood Research published the article "Getting 50% sota on arc-agi with gpt-4" on Substack.</data>
      <data key="d6">022e7927d281e80e188f29ea343cc115</data>
    </edge>
    <edge source="DAN HENDRYCKS" target="MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING">
      <data key="d4">8.0</data>
      <data key="d5">Dan Hendrycks is one of the authors of the paper discussing measuring massive multitask language understanding.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="DAN HENDRYCKS" target="MEASURING MATHEMATICAL PROBLEM SOLVING">
      <data key="d4">8.0</data>
      <data key="d5">Dan Hendrycks is one of the authors of the paper on measuring mathematical problem solving.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="COLLIN BURNS" target="MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING">
      <data key="d4">8.0</data>
      <data key="d5">Collin Burns is one of the authors of the paper discussing measuring massive multitask language understanding.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="STEVEN BASART" target="MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING">
      <data key="d4">8.0</data>
      <data key="d5">Steven Basart is one of the authors of the paper discussing measuring massive multitask language understanding.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="ANDY ZOU" target="MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING">
      <data key="d4">8.0</data>
      <data key="d5">Andy Zou is one of the authors of the paper discussing measuring massive multitask language understanding.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="MANTAS MAZEIKA" target="MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING">
      <data key="d4">8.0</data>
      <data key="d5">Mantas Mazeika is one of the authors of the paper discussing measuring massive multitask language understanding.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="JACOB STEINHARDT" target="MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING">
      <data key="d4">8.0</data>
      <data key="d5">Jacob Steinhardt is one of the authors of the paper discussing measuring massive multitask language understanding.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="SIRUI HONG" target="METAGPT">
      <data key="d4">8.0</data>
      <data key="d5">Sirui Hong is one of the authors of the paper discussing MetaGPT.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="XIAWU ZHENG" target="METAGPT">
      <data key="d4">8.0</data>
      <data key="d5">Xiawu Zheng is one of the authors of the paper discussing MetaGPT.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="JONATHAN CHEN" target="METAGPT">
      <data key="d4">8.0</data>
      <data key="d5">Jonathan Chen is one of the authors of the paper discussing MetaGPT.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="YUHENG CHENG" target="METAGPT">
      <data key="d4">8.0</data>
      <data key="d5">Yuheng Cheng is one of the authors of the paper discussing MetaGPT.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="JINLIN WANG" target="METAGPT">
      <data key="d4">8.0</data>
      <data key="d5">Jinlin Wang is one of the authors of the paper discussing MetaGPT.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="CEYAO ZHANG" target="METAGPT">
      <data key="d4">8.0</data>
      <data key="d5">Ceyao Zhang is one of the authors of the paper discussing MetaGPT.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="ZILI WANG" target="METAGPT">
      <data key="d4">8.0</data>
      <data key="d5">Zili Wang is one of the authors of the paper discussing MetaGPT.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="STEVEN KA SHING YAU" target="METAGPT">
      <data key="d4">8.0</data>
      <data key="d5">Steven Ka Shing Yau is one of the authors of the paper discussing MetaGPT.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="ZIJUAN LIN" target="METAGPT">
      <data key="d4">8.0</data>
      <data key="d5">Zijuan Lin is one of the authors of the paper discussing MetaGPT.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="LIYANG ZHOU" target="METAGPT">
      <data key="d4">8.0</data>
      <data key="d5">Liyang Zhou is one of the authors of the paper discussing MetaGPT.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="RAN CHENG" target="ACCELERATING MULTI-OBJECTIVE NEURAL ARCHITECTURE SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Ran Cheng is one of the authors of the paper discussing accelerating multi-objective neural architecture search.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="CHENG HE" target="ACCELERATING MULTI-OBJECTIVE NEURAL ARCHITECTURE SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Cheng He is one of the authors of the paper discussing accelerating multi-objective neural architecture search.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="ZHICHAO LU" target="ACCELERATING MULTI-OBJECTIVE NEURAL ARCHITECTURE SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Zhichao Lu is one of the authors of the paper discussing accelerating multi-objective neural architecture search.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="JING WANG" target="ACCELERATING MULTI-OBJECTIVE NEURAL ARCHITECTURE SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Jing Wang is one of the authors of the paper discussing accelerating multi-objective neural architecture search.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="MIAO ZHANG" target="ACCELERATING MULTI-OBJECTIVE NEURAL ARCHITECTURE SEARCH">
      <data key="d4">8.0</data>
      <data key="d5">Miao Zhang is one of the authors of the paper discussing accelerating multi-objective neural architecture search.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="SHIHUA HUANG" target="REVISITING RESIDUAL NETWORKS">
      <data key="d4">8.0</data>
      <data key="d5">Shihua Huang is one of the authors of the paper discussing revisiting residual networks for adversarial robustness.</data>
      <data key="d6">6109537356a2ce2339f77c827aa3668e</data>
    </edge>
    <edge source="JOEL LEHMAN" target="RUI WANG">
      <data key="d4">8.0</data>
      <data key="d5">Both are co-authors of the papers "Poet: open-ended coevolution of environments and their optimized solutions" and "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JOEL LEHMAN" target="KENNETH O. STANLEY">
      <data key="d4">8.0</data>
      <data key="d5">Both are co-authors of the papers "Poet: open-ended coevolution of environments and their optimized solutions" and "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JOEL LEHMAN" target="OMNI">
      <data key="d4">8.0</data>
      <data key="d5">Joel Lehman is one of the authors of the paper titled "OMNI: Open-endedness via models of human notions of interestingness."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JI-RONG WEN" target="A SURVEY ON THE MEMORY MECHANISM OF LARGE LANGUAGE MODEL BASED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Ji-Rong Wen is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="MIRAC SUZGUN" target="CHALLENGING BIG-BENCH TASKS">
      <data key="d4">9.0</data>
      <data key="d5">Mirac Suzgun is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="MATT BOTVINICK" target="SHAN KUMARAN">
      <data key="d4">8.0</data>
      <data key="d5">Both are co-authors of the paper "Learning to reinforcement learn."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="LEI WANG" target="A SURVEY ON LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Lei Wang is one of the authors of the paper "A survey on large language model based autonomous agents."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="CHEN MA" target="A SURVEY ON LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Chen Ma is one of the authors of the paper "A survey on large language model based autonomous agents."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="CHEN MA" target="A SURVEY ON THE MEMORY MECHANISM OF LARGE LANGUAGE MODEL BASED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Chen Ma is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="XUEYANG FENG" target="A SURVEY ON LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Xueyang Feng is one of the authors of the paper "A survey on large language model based autonomous agents."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="ZEYU ZHANG" target="A SURVEY ON LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Zeyu Zhang is one of the authors of the paper "A survey on large language model based autonomous agents."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="ZEYU ZHANG" target="A SURVEY ON THE MEMORY MECHANISM OF LARGE LANGUAGE MODEL BASED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Zeyu Zhang is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="HAO YANG" target="A SURVEY ON LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Hao Yang is one of the authors of the paper "A survey on large language model based autonomous agents."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JINGSEN ZHANG" target="A SURVEY ON LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Jingsen Zhang is one of the authors of the paper "A survey on large language model based autonomous agents."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="ZHIYUAN CHEN" target="A SURVEY ON LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Zhiyuan Chen is one of the authors of the paper "A survey on large language model based autonomous agents."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="JIAKAI TANG" target="A SURVEY ON LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Jiakai Tang is one of the authors of the paper "A survey on large language model based autonomous agents."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="XU CHEN" target="A SURVEY ON LARGE LANGUAGE MODEL BASED AUTONOMOUS AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Xu Chen is one of the authors of the paper "A survey on large language model based autonomous agents."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="XU CHEN" target="A SURVEY ON THE MEMORY MECHANISM OF LARGE LANGUAGE MODEL BASED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Xu Chen is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="RUI WANG" target="KENNETH O. STANLEY">
      <data key="d4">8.0</data>
      <data key="d5">Both are co-authors of the papers "Poet: open-ended coevolution of environments and their optimized solutions" and "Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="QUOC V LE" target="SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Quoc V Le is one of the authors of the paper "Self-consistency improves chain of thought reasoning in language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="QUOC V LE" target="CHAIN-OF-THOUGHT PROMPTING ELICITS REASONING IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Quoc V Le is one of the authors of the paper "Chain-of-thought prompting elicits reasoning in large language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="QUOC V LE" target="TAKE A STEP BACK: EVOKING REASONING VIA ABSTRACTION IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Quoc V Le is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="QUOC V LE" target="SELF-DISCOVER: LARGE LANGUAGE MODELS SELF-COMPOSE REASONING STRUCTURES">
      <data key="d4">8.0</data>
      <data key="d5">Quoc V Le is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="QUOC V LE" target="CHALLENGING BIG-BENCH TASKS">
      <data key="d4">9.0</data>
      <data key="d5">Quoc V Le is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="ED H. CHI" target="SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Ed H. Chi is one of the authors of the paper "Self-consistency improves chain of thought reasoning in language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="ED H. CHI" target="CHAIN-OF-THOUGHT PROMPTING ELICITS REASONING IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Ed H. Chi is one of the authors of the paper "Chain-of-thought prompting elicits reasoning in large language models."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="QINGYUN WU" target="AUTOGEN: ENABLING NEXT-GEN LLM APPLICATIONS VIA MULTI-AGENT CONVERSATION FRAMEWORK">
      <data key="d4">8.0</data>
      <data key="d5">Qingyun Wu is one of the authors of the paper "Autogen: Enabling next-gen llm applications via multi-agent conversation framework."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="QINGYUN WU" target="OFFLINE TRAINING OF LANGUAGE MODEL AGENTS WITH FUNCTIONS AS LEARNABLE WEIGHTS">
      <data key="d4">8.0</data>
      <data key="d5">Qingyun Wu is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="BENFENG XU" target="EXPERTPROMPTING: INSTRUCTING LARGE LANGUAGE MODELS TO BE DISTINGUISHED EXPERTS">
      <data key="d4">8.0</data>
      <data key="d5">Benfeng Xu is one of the authors of the paper "Expertprompting: Instructing large language models to be distinguished experts."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="CHENGRUN YANG" target="LARGE LANGUAGE MODELS AS OPTIMIZERS">
      <data key="d4">8.0</data>
      <data key="d5">Chengrun Yang is one of the authors of the paper "Large language models as optimizers."</data>
      <data key="d6">2600a1ed94ad2d3675ea80575c39cbd1</data>
    </edge>
    <edge source="SHAOKUN ZHANG" target="OFFLINE TRAINING OF LANGUAGE MODEL AGENTS WITH FUNCTIONS AS LEARNABLE WEIGHTS">
      <data key="d4">8.0</data>
      <data key="d5">Shaokun Zhang is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JIEYU ZHANG" target="OFFLINE TRAINING OF LANGUAGE MODEL AGENTS WITH FUNCTIONS AS LEARNABLE WEIGHTS">
      <data key="d4">8.0</data>
      <data key="d5">Jieyu Zhang is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="CHI WANG" target="OFFLINE TRAINING OF LANGUAGE MODEL AGENTS WITH FUNCTIONS AS LEARNABLE WEIGHTS">
      <data key="d4">8.0</data>
      <data key="d5">Chi Wang is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="KENNETH STANLEY" target="OMNI">
      <data key="d4">8.0</data>
      <data key="d5">Kenneth Stanley is one of the authors of the paper titled "OMNI: Open-endedness via models of human notions of interestingness."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JIALE LIU" target="OFFLINE TRAINING OF LANGUAGE MODEL AGENTS WITH FUNCTIONS AS LEARNABLE WEIGHTS">
      <data key="d4">8.0</data>
      <data key="d5">Jiale Liu is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="LINXIN SONG" target="OFFLINE TRAINING OF LANGUAGE MODEL AGENTS WITH FUNCTIONS AS LEARNABLE WEIGHTS">
      <data key="d4">8.0</data>
      <data key="d5">Linxin Song is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="RANJAY KRISHNA" target="OFFLINE TRAINING OF LANGUAGE MODEL AGENTS WITH FUNCTIONS AS LEARNABLE WEIGHTS">
      <data key="d4">8.0</data>
      <data key="d5">Ranjay Krishna is one of the authors of the paper titled "Offline training of language model agents with functions as learnable weights."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="XIAOHE BO" target="A SURVEY ON THE MEMORY MECHANISM OF LARGE LANGUAGE MODEL BASED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Xiaohe Bo is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="RUI LI" target="A SURVEY ON THE MEMORY MECHANISM OF LARGE LANGUAGE MODEL BASED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Rui Li is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="QUANYU DAI" target="A SURVEY ON THE MEMORY MECHANISM OF LARGE LANGUAGE MODEL BASED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Quanyu Dai is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JIEMING ZHU" target="A SURVEY ON THE MEMORY MECHANISM OF LARGE LANGUAGE MODEL BASED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Jieming Zhu is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="ZHENHUA DONG" target="A SURVEY ON THE MEMORY MECHANISM OF LARGE LANGUAGE MODEL BASED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Zhenhua Dong is one of the authors of the paper titled "A survey on the memory mechanism of large language model based agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="HENG-TZE CHENG" target="TAKE A STEP BACK: EVOKING REASONING VIA ABSTRACTION IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Heng-Tze Cheng is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="HENG-TZE CHENG" target="SELF-DISCOVER: LARGE LANGUAGE MODELS SELF-COMPOSE REASONING STRUCTURES">
      <data key="d4">8.0</data>
      <data key="d5">Heng-Tze Cheng is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="ED H CHI" target="TAKE A STEP BACK: EVOKING REASONING VIA ABSTRACTION IN LARGE LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Ed H Chi is one of the authors of the paper titled "Take a step back: Evoking reasoning via abstraction in large language models."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="ED H CHI" target="SELF-DISCOVER: LARGE LANGUAGE MODELS SELF-COMPOSE REASONING STRUCTURES">
      <data key="d4">8.0</data>
      <data key="d5">Ed H Chi is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="ED H CHI" target="CHALLENGING BIG-BENCH TASKS">
      <data key="d4">9.0</data>
      <data key="d5">Ed H Chi is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="PEI ZHOU" target="SELF-DISCOVER: LARGE LANGUAGE MODELS SELF-COMPOSE REASONING STRUCTURES">
      <data key="d4">8.0</data>
      <data key="d5">Pei Zhou is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JAY PUJARA" target="SELF-DISCOVER: LARGE LANGUAGE MODELS SELF-COMPOSE REASONING STRUCTURES">
      <data key="d4">8.0</data>
      <data key="d5">Jay Pujara is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="XIANG REN" target="SELF-DISCOVER: LARGE LANGUAGE MODELS SELF-COMPOSE REASONING STRUCTURES">
      <data key="d4">8.0</data>
      <data key="d5">Xiang Ren is one of the authors of the paper titled "Self-discover: Large language models self-compose reasoning structures."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="WANGCHUNSHU ZHOU" target="SYMBOLIC LEARNING ENABLES SELF-EVOLVING AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Wangchunshu Zhou is one of the authors of the paper titled "Symbolic learning enables self-evolving agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="YIXIN OU" target="SYMBOLIC LEARNING ENABLES SELF-EVOLVING AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Yixin Ou is one of the authors of the paper titled "Symbolic learning enables self-evolving agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="SHENGWEI DING" target="SYMBOLIC LEARNING ENABLES SELF-EVOLVING AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Shengwei Ding is one of the authors of the paper titled "Symbolic learning enables self-evolving agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="LONG LI" target="SYMBOLIC LEARNING ENABLES SELF-EVOLVING AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Long Li is one of the authors of the paper titled "Symbolic learning enables self-evolving agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JIALONG WU" target="SYMBOLIC LEARNING ENABLES SELF-EVOLVING AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Jialong Wu is one of the authors of the paper titled "Symbolic learning enables self-evolving agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="TIANNAN WANG" target="SYMBOLIC LEARNING ENABLES SELF-EVOLVING AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Tiannan Wang is one of the authors of the paper titled "Symbolic learning enables self-evolving agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="JIAMIN CHEN" target="SYMBOLIC LEARNING ENABLES SELF-EVOLVING AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Jiamin Chen is one of the authors of the paper titled "Symbolic learning enables self-evolving agents."</data>
      <data key="d6">cc802d9b841fde55e9c0c2ba0ef7869d</data>
    </edge>
    <edge source="EXPERIMENT DETAILS" target="ZERO-SHOT STYLE QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Experiment details include the use of zero-shot style questions for evaluation.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="EXPERIMENT DETAILS" target="ONE-SHOT STYLE QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">Experiment details include the use of one-shot style questions for evaluation.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="EXPERIMENT DETAILS" target="AUTOMATED DESIGN OF AGENTIC SYSTEMS">
      <data key="d4">8.0</data>
      <data key="d5">The document "Automated Design of Agentic Systems" includes experimental details.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="COST OF EXPERIMENTS" target="GPT-3.5-TURBO-0125">
      <data key="d4">7.0</data>
      <data key="d5">The cost of experiments is significantly influenced by the use of the GPT-3.5-Turbo-0125 model.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="COST OF EXPERIMENTS" target="GPT-4O-MINI">
      <data key="d4">7.0</data>
      <data key="d5">The cost of experiments could be reduced by using the GPT-4o-mini model, which is less expensive and offers better performance.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="FRAMEWORK" target="NAMEDTUPLE INFO OBJECT">
      <data key="d4">7.0</data>
      <data key="d5">The framework uses namedtuple Info objects to encapsulate different types of information.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="FRAMEWORK" target="INFO OBJECT">
      <data key="d4">7.0</data>
      <data key="d5">The framework uses Info objects to encapsulate different types of information.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="FRAMEWORK" target="FM MODULE">
      <data key="d4">1.0</data>
      <data key="d5">The framework includes an FM module that constructs the prompt by concatenating all input Info objects.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="RUNTIME ERROR" target="DEBUG_THOUGHT">
      <data key="d4">8.0</data>
      <data key="d5">After encountering a runtime error, the meta agent captures its debugging thought process in the "debug_thought" section.</data>
      <data key="d6">282313a8340c6792e8c35f53ed157cd0</data>
    </edge>
    <edge source="FM MODULE" target="INFO">
      <data key="d4">9.0</data>
      <data key="d5">The FM Module uses Info objects to construct prompts and facilitate communication between different modules.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="FORMAT_INST">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module uses the FORMAT_INST lambda function to format instructions for FM responses.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="ROLE_DESC">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module uses the ROLE_DESC lambda function to generate role descriptions.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="GET_JSON_RESPONSE_FROM_GPT">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module can use the get_json_response_from_gpt function to get JSON responses from a GPT model.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="AGENT SYSTEM">
      <data key="d4">8.0</data>
      <data key="d5">The Agent System can use the FM Module to process task information and generate responses.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="TASK DESCRIPTIONS">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module uses task descriptions to facilitate communication between different modules.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="TOOL FUNCTION CALLS">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module uses results from tool function calls as input Info objects.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="META-AGENT SEARCH">
      <data key="d4">7.0</data>
      <data key="d5">The FM Module is part of the simple framework used in Meta-Agent Search.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="OUTPUT FIELDS">
      <data key="d4">7.0</data>
      <data key="d5">The FM Module has output fields that are expected in its output.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="UNIQUE IDENTIFIER">
      <data key="d4">7.0</data>
      <data key="d5">The FM Module has a unique identifier for its instances.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module uses instructions for generating prompts and querying information.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="ITERATION INDEX">
      <data key="d4">7.0</data>
      <data key="d5">The FM Module uses an iteration index to track iterations in tasks.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="FM MODULE" target="INITIAL INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module uses the initial instruction to generate candidate solutions.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FM MODULE" target="TASKINFO">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module processes TaskInfo to generate initial solutions.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FM MODULE" target="INITIAL SOLUTION">
      <data key="d4">8.0</data>
      <data key="d5">Initial solutions are generated by the FM Module based on the initial instruction and TaskInfo.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="FM MODULE" target="THOUGHTS">
      <data key="d4">8.0</data>
      <data key="d5">The FM Module generates thoughts consisting of 'thinking' and 'code' as part of the initial solution.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="INFO" target="FM_MODULE">
      <data key="d4">8.0</data>
      <data key="d5">Info is provided as input to the FM_Module to guide its operations.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="INFO" target="SUB_PROBLEM INFO">
      <data key="d4">7.0</data>
      <data key="d5">Sub-problem info is a specific type of Info object used to encapsulate information about individual sub-problems.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="GET_JSON_RESPONSE_FROM_GPT" target="BACKOFF">
      <data key="d4">8.0</data>
      <data key="d5">The backoff method is used in the get_json_response_from_gpt function to handle RateLimitError exceptions.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="GET_JSON_RESPONSE_FROM_GPT" target="RATE LIMIT ERROR">
      <data key="d4">7.0</data>
      <data key="d5">The get_json_response_from_gpt function handles RateLimitError exceptions using the backoff method.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="GET_JSON_RESPONSE_FROM_GPT" target="SYSTEM MESSAGE">
      <data key="d4">8.0</data>
      <data key="d5">The get_json_response_from_gpt function uses a system message as an argument to guide the GPT model's response.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="GET_JSON_RESPONSE_FROM_GPT" target="SAMPLING TEMPERATURE">
      <data key="d4">8.0</data>
      <data key="d5">The get_json_response_from_gpt function uses sampling temperature as a parameter to control the randomness of the GPT model's output.</data>
      <data key="d6">d66dc9ce4a9545b44f7486ea057b5937</data>
    </edge>
    <edge source="SYSTEM MESSAGE" target="MULTI-TURN INTERACTION">
      <data key="d4">7.0</data>
      <data key="d5">System messages are part of the multi-turn interaction sequence within the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="SYSTEM MESSAGE" target="MATHS GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d4">8.0</data>
      <data key="d5">The Maths GPT-4 Extraction System Message is a type of system message used for evaluating math-based questions.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="SYSTEM MESSAGE" target="GENERAL EXTRACTION SYSTEM MESSAGE">
      <data key="d4">8.0</data>
      <data key="d5">The General Extraction System Message is a type of system message used for evaluating exact match/span extraction problems.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="COT_MODULE" target="N_MAX">
      <data key="d4">14.0</data>
      <data key="d5">The N_MAX parameter sets the maximum number of attempts for the COT_MODULE to refine the answer.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="COT_MODULE" target="TASKINFO">
      <data key="d4">14.0</data>
      <data key="d5">TASKINFO is used as input for the COT_MODULE to generate 'thinking' and 'answer' processes.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="CRITIC_INSTRUCTION" target="CRITIC_MODULE">
      <data key="d4">16.0</data>
      <data key="d5">The CRITIC_INSTRUCTION is used by the CRITIC_MODULE to review and criticize the answer or confirm its correctness.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="CRITIC_MODULE" target="TASKINFO">
      <data key="d4">14.0</data>
      <data key="d5">TASKINFO is used as input for the CRITIC_MODULE to generate 'feedback' and 'correct' processes.</data>
      <data key="d6">4b43decac6833d1515992f8869ecada7</data>
    </edge>
    <edge source="TASKINFO" target="THINKING">
      <data key="d4">8.0</data>
      <data key="d5">Task information is used as input for generating the thought process.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="TASKINFO" target="DECOMPOSITION MODULE">
      <data key="d4">8.0</data>
      <data key="d5">TaskInfo is processed by the decomposition module to generate sub-problems.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="TASKINFO" target="INTEGRATION MODULE">
      <data key="d4">8.0</data>
      <data key="d5">TaskInfo is used as part of the input for the integration module to generate the final answer.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="GPT-4O-2024-05-13" target="META_AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The meta agent uses the GPT-4o-2024-05-13 model for evaluation.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="GPT-3.5-TURBO-0125" target="DISCOVERED_AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Discovered agents use the GPT-3.5-turbo-0125 model for evaluation.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="GPT-3.5-TURBO-0125" target="DISCOVERED AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Discovered agents use the GPT-3.5-turbo-0125 model for evaluation.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FM_MODULE" target="THOUGHTS">
      <data key="d4">9.0</data>
      <data key="d5">The FM_Module generates thoughts, which include the thought process and feedback.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FM_MODULE" target="TEMPERATURE">
      <data key="d4">7.0</data>
      <data key="d5">Temperature is a parameter used in the FM_Module to control the randomness or creativity of the output.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FM_MODULE" target="DECOMPOSITION MODULE">
      <data key="d4">9.0</data>
      <data key="d5">The decomposition module is an instance of the FM_Module used to decompose tasks into sub-problems.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="FM_MODULE" target="SPECIALIZED EXPERT">
      <data key="d4">9.0</data>
      <data key="d5">Specialized experts are instances of the FM_Module used to solve specific sub-problems.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="FM_MODULE" target="INTEGRATION MODULE">
      <data key="d4">9.0</data>
      <data key="d5">The integration module is an instance of the FM_Module used to integrate sub-problem solutions into a final answer.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="FM_MODULE" target="VISUAL REPRESENTATION MODULE">
      <data key="d4">9.0</data>
      <data key="d5">The visual representation module is an instance of the FM_Module used to generate visual representations of problems.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="FM_MODULE" target="VERIFICATION MODULE">
      <data key="d4">9.0</data>
      <data key="d5">The verification module is an instance of the FM_Module used to verify visual representations and provide feedback.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="FM_MODULE" target="CHAIN-OF-THOUGHT MODULE">
      <data key="d4">9.0</data>
      <data key="d5">The Chain-of-Thought module is an instance of the FM_Module used to solve problems using verified visual representations.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="ENSEMBLE AGENT" target="NUM_CANDIDATES">
      <data key="d4">7.0</data>
      <data key="d5">The Ensemble Agent generates a specified number of initial candidate solutions, set by the num_candidates parameter.</data>
      <data key="d6">449db721e37968e073e3579b59e023b2</data>
    </edge>
    <edge source="INITIAL_SOLUTIONS" target="HUMAN_LIKE_FEEDBACK_MODULE">
      <data key="d4">7.0</data>
      <data key="d5">Initial solutions are evaluated using the human-like feedback module.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="INITIAL_SOLUTIONS" target="EXPERT_ADVISORS">
      <data key="d4">7.0</data>
      <data key="d5">Initial solutions are evaluated by expert advisors.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="INITIAL_SOLUTIONS" target="REFINEMENT_MODULE">
      <data key="d4">7.0</data>
      <data key="d5">Initial solutions are refined using the refinement module.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="HUMAN_LIKE_FEEDBACK_MODULE" target="HUMAN_FEEDBACK_INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">The human-like feedback module operates based on the human feedback instruction.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="EXPERT_ADVISORS" target="EXPERT_INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">Expert advisors operate based on the expert instruction.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="EXPERT_ADVISORS" target="ROLE">
      <data key="d4">8.0</data>
      <data key="d5">Roles such as Efficiency Expert, Readability Expert, and Simplicity Expert are assigned to expert advisors.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="REFINEMENT_MODULE" target="REFINEMENT_INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">The refinement module operates based on the refinement instruction.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="REFINEMENT_MODULE" target="MAX_REFINEMENT_ITERATIONS">
      <data key="d4">7.0</data>
      <data key="d5">The refinement module iterates based on the maximum refinement iterations parameter.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="REFINED_SOLUTIONS" target="SORTED_SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Refined solutions are sorted based on their performance.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="SORTED_SOLUTIONS" target="TOP_SOLUTIONS">
      <data key="d4">8.0</data>
      <data key="d5">The top-performing solutions are selected from the sorted solutions.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="TOP_SOLUTIONS" target="FINAL_DECISION_MODULE">
      <data key="d4">7.0</data>
      <data key="d5">Top solutions are evaluated by the final decision module.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FINAL_DECISION_INSTRUCTION" target="FINAL_DECISION_MODULE">
      <data key="d4">8.0</data>
      <data key="d5">The final decision module operates based on the final decision instruction.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="FINAL_DECISION_MODULE" target="FINAL_THOUGHTS">
      <data key="d4">8.0</data>
      <data key="d5">The final decision module generates the final thoughts.</data>
      <data key="d6">84317ae35cc75d612287186d93461447</data>
    </edge>
    <edge source="NON-NATIONALS" target="IMMIGRANTS">
      <data key="d4">8.0</data>
      <data key="d5">Non-nationals in Bahrain are primarily composed of immigrants.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="IMMIGRANTS" target="INDIANS">
      <data key="d4">7.0</data>
      <data key="d5">Indians are a significant demographic group among the immigrants in Bahrain.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="IMMIGRANTS" target="BANGLADESHIS">
      <data key="d4">7.0</data>
      <data key="d5">Bangladeshis are a significant demographic group among the immigrants in Bahrain.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="IMMIGRANTS" target="PAKISTANIS">
      <data key="d4">7.0</data>
      <data key="d5">Pakistanis are a significant demographic group among the immigrants in Bahrain.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="IMMIGRANTS" target="FILIPINOS">
      <data key="d4">7.0</data>
      <data key="d5">Filipinos are a significant demographic group among the immigrants in Bahrain.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="IMMIGRANTS" target="INDONESIANS">
      <data key="d4">6.0</data>
      <data key="d5">Indonesians are a demographic group among the immigrants in Bahrain.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="QUANTUM STATES" target="ENERGY LEVELS">
      <data key="d4">8.0</data>
      <data key="d5">Quantum states are characterized by distinct energy levels.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="UNCERTAINTY PRINCIPLE" target="DELTA E">
      <data key="d4">7.0</data>
      <data key="d5">Delta E is the uncertainty in energy, as discussed in the context of the uncertainty principle.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="UNCERTAINTY PRINCIPLE" target="DELTA T">
      <data key="d4">7.0</data>
      <data key="d5">Delta T is the uncertainty in time, as discussed in the context of the uncertainty principle.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="UNCERTAINTY PRINCIPLE" target="HBAR">
      <data key="d4">7.0</data>
      <data key="d5">Hbar is the reduced Planck constant, a fundamental constant in the uncertainty principle.</data>
      <data key="d6">10fda605f670bcfccfc13c2ca0dde959</data>
    </edge>
    <edge source="DECOMPOSITION MODULE" target="SUB_PROBLEMS">
      <data key="d4">9.0</data>
      <data key="d5">The decomposition module generates sub-problems from the main task.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="DECOMPOSITION MODULE" target="DECOMPOSITION INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">The decomposition module uses decomposition instructions to guide the decomposition of tasks into sub-problems.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="SPECIALIZED EXPERT" target="SUB_SOLUTIONS">
      <data key="d4">9.0</data>
      <data key="d5">Specialized experts provide solutions to the sub-problems.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="SPECIALIZED EXPERT" target="SUB_PROBLEM INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">Specialized experts use sub-problem instructions to solve sub-problems step by step.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="INTEGRATION MODULE" target="INTEGRATION INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">The integration module uses integration instructions to guide the integration of sub-problem solutions into a final answer.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="VISUAL REPRESENTATION MODULE" target="VISUAL REPRESENTATION">
      <data key="d4">8.0</data>
      <data key="d5">The visual representation module generates visual representations of problems.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="VISUAL REPRESENTATION MODULE" target="VISUAL INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">The visual representation module uses visual instructions to create visual representations of problems.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="VERIFICATION MODULE" target="VERIFIED VISUAL">
      <data key="d4">8.0</data>
      <data key="d5">The verification module verifies the visual representations and provides feedback.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="VERIFICATION MODULE" target="VERIFICATION INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">The verification module uses verification instructions to verify the accuracy and relevance of visual representations.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="CHAIN-OF-THOUGHT MODULE" target="COT INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">The Chain-of-Thought module uses CoT instructions to solve problems using verified visual representations.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="VERIFIED VISUAL" target="VISUAL OUTPUT">
      <data key="d4">8.0</data>
      <data key="d5">The verified visual is produced by the verification module after checking the initial visual output.</data>
      <data key="d6">ef75d2c866bee783577ed9f65707cf13</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="GENERATIVE TEACHING">
      <data key="d4">25.0</data>
      <data key="d5">AgentInstruct is used to implement Generative Teaching by creating synthetic data for post-training language models.
AgentInstruct is an agentic solution designed to implement the Generative Teaching methodology.
AgentInstruct is used as a method for Generative Teaching, enhancing AI model performance across various tasks.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="SYNTHETIC DATA">
      <data key="d4">17.0</data>
      <data key="d5">AgentInstruct generates synthetic data for post-training language models.
AgentInstruct uses agentic flows to generate synthetic data for model training.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="MISTRAL-7B">
      <data key="d4">16.0</data>
      <data key="d5">AgentInstruct was used to generate synthetic data for post-training Mistral-7b.
AgentInstruct generated the synthetic dataset used to fine-tune the Mistral-7B model.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="POST-TRAINING">
      <data key="d4">9.0</data>
      <data key="d5">AgentInstruct generates synthetic data specifically for post-training language models.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="INSTRUCTION TUNING">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct generates synthetic data that can be used for instruction tuning of language models.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="RESPONSES">
      <data key="d4">17.0</data>
      <data key="d5">AgentInstruct generates both prompts and responses using raw data sources.
AgentInstruct generates both prompts and responses as part of its data generation process.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="TEXT EDITING">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct generates synthetic data to teach language models the skill of text editing.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="CREATIVE WRITING">
      <data key="d4">15.0</data>
      <data key="d5">AgentInstruct generates synthetic data to teach language models the skill of creative writing.
AgentInstruct generates data to teach AI models the skill of creative writing.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="TOOL USAGE">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct generates synthetic data to teach language models the skill of tool usage.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="CODING">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct generates synthetic data to teach language models the skill of coding.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="MULTI-AGENT WORKFLOWS">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct utilizes multi-agent workflows to generate high-quality synthetic data.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="SYNTHETIC-DATA-GENERATION-AS-A-SERVICE">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct can be used to implement Synthetic-Data-Generation-As-A-Service.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="CONTENT TRANSFORMATION AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Content Transformation Agents are part of the AgentInstruct methodology to transform raw seeds.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="REFINEMENT AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Refinement Agents are part of the AgentInstruct methodology to refine seed instructions.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="RAW SEEDS">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct uses raw seeds as the initial input for data generation.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="INSTRUCTION CREATION AGENTS">
      <data key="d4">1.0</data>
      <data key="d5">Instruction Creation Agents are part of the AgentInstruct methodology to create diverse instructions.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="SKILLS">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct can be used to teach various skills to AI models, such as creative writing, reasoning, math, and tool use.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="TAXONOMY">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct uses a taxonomy of over 100 subcategories to create diverse and high-quality prompts and responses.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="VERIFICATION AND DATA FILTERING">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct applies verification and data filtering processes to ensure the quality of the generated data.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="UNSTRUCTURED TEXT DOCUMENTS">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct uses unstructured text documents as raw seeds for data generation.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="SOURCE CODE">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct uses source code as raw seeds for data generation.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="CONTINUAL LEARNING">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct enables continual learning by generating new data for post-training and fine-tuning.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="ORCA-3">
      <data key="d4">26.0</data>
      <data key="d5">Orca-3 is trained using the AgentInstruct dataset, which includes approximately 22 million instructions.
AgentInstruct data has led to a performance augmentation of 33.94% over the Orca-2.5 baseline and an enhancement of 14.92% over Mistral-Instruct-7B.
Orca-3 showed substantial performance improvement after being post-trained with a dataset generated by AgentInstruct.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="ORCA-2.5">
      <data key="d4">8.0</data>
      <data key="d5">Orca-2.5 is used to compare and evaluate the impact of the larger AgentInstruct dataset.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="KNOWLEDGEPILE">
      <data key="d4">7.0</data>
      <data key="d5">KnowledgePile was used as a source for unstructured text and code files in the AgentInstruct dataset.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="AUTOMATHTEXT">
      <data key="d4">7.0</data>
      <data key="d5">AutoMathText was used as a source for unstructured text and code files in the AgentInstruct dataset.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="OPENSTAX">
      <data key="d4">7.0</data>
      <data key="d5">Openstax was used as a source for unstructured text in the AgentInstruct dataset.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="APACHE-2.0 LICENSED SOURCE CODE">
      <data key="d4">7.0</data>
      <data key="d5">Apache-2.0 licensed source code files were used in the AgentInstruct dataset.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="CORPUS">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct synthesizes a large and diverse corpus of data for training and evaluating models.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="DIFFICULTY">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct data includes varying degrees of difficulty to evaluate model performance.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="MISTRAL-7B-INSTRUCT">
      <data key="d4">14.0</data>
      <data key="d5">AgentInstruct has shown substantial improvement in Mistral&#8217;s reading comprehension capabilities.
AgentInstruct is used to enhance Mistral-7B-Instruct's performance across various tasks.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="LSAT">
      <data key="d4">1.0</data>
      <data key="d5">AgentInstruct has elevated the performance of a 7B model to match that of GPT-4 on the reading comprehension sections of the LSAT.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="ORCA-3-7B">
      <data key="d4">9.0</data>
      <data key="d5">Orca-3-7B is fine-tuned with AgentInstruct data, showing substantial improvement in RAG tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="LIMITATIONS">
      <data key="d4">9.0</data>
      <data key="d5">AgentInstruct has several limitations, including extensibility, accuracy, cost, bias, validation, and dependency on seed data.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="EXTENSIBILITY">
      <data key="d4">7.0</data>
      <data key="d5">Extensibility is a limitation of AgentInstruct, requiring human effort to create agentic flows for different skills.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="BIAS">
      <data key="d4">7.0</data>
      <data key="d5">Bias is a limitation of AgentInstruct, where synthetic data may reflect and amplify biases from the original seed data.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="DEPENDENCY ON SEED DATA">
      <data key="d4">7.0</data>
      <data key="d5">Dependency on Seed Data is a limitation of AgentInstruct, where the quality of synthetic data depends on the quality of the real data used as seeds.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="UNSTRUCTURED DATA SOURCES">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct generates tailored datasets from unstructured data sources for model training.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="MODEL POST-TRAINING">
      <data key="d4">8.0</data>
      <data key="d5">AgentInstruct facilitates model post-training by generating high-quality synthetic data.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="DOMAIN/TASK SPECIALIZATION">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct can be used for domain/task specialization by generating tailored datasets.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="CONTINUAL IMPROVEMENT">
      <data key="d4">7.0</data>
      <data key="d5">AgentInstruct supports continual improvement of models by generating higher quality data.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="SYNTHETIC DATA" target="SLMS">
      <data key="d4">8.0</data>
      <data key="d5">Synthetic data is used to accelerate the development of Small Language Models (SLMs).</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="SYNTHETIC DATA" target="MODEL COLLAPSE">
      <data key="d4">7.0</data>
      <data key="d5">Model collapse can occur when language models are pre-trained on low-quality or repetitive synthetic data.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="SYNTHETIC DATA" target="IMITATION PROCESS">
      <data key="d4">7.0</data>
      <data key="d5">The imitation process is a risk when using synthetic data generated by other models for training.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MISTRAL-7B" target="ORCA-3">
      <data key="d4">18.0</data>
      <data key="d5">Orca-3 is the result of post-training Mistral-7b with synthetic data generated by AgentInstruct.
Orca-3 is the fine-tuned version of the Mistral-7B model.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="ORCA-3" target="AGIEVAL">
      <data key="d4">31.0</data>
      <data key="d5">Orca-3 shows a 40% improvement on the AGIEval benchmark compared to Mistral-7b-Instruct.
Orca-3 showed a 40% improvement on the AGIEval benchmark.
Orca-3 scored 56.80 on the AGIEval benchmark, a 40% improvement over Orca-2.5.
Orca-3 is evaluated using the AGIEval benchmark, showing significant improvements in various tasks.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="BBH">
      <data key="d4">23.0</data>
      <data key="d5">Orca-3 shows a 38% improvement on the BBH benchmark compared to Mistral-7b-Instruct.
Orca-3 showed a 38% improvement on the BBH benchmark.
Orca-3 scored 61.83 on the BBH benchmark, a 38% improvement over Orca-2.5.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="ALPACAEVAL">
      <data key="d4">23.0</data>
      <data key="d5">Orca-3 shows a 45% improvement on the AlpacaEval benchmark compared to Mistral-7b-Instruct.
Orca-3 showed a 45% improvement on the AlpacaEval benchmark.
Orca-3 scored 24.80 on the AlpacaEval benchmark, a 45% improvement over Orca-2.5.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="LLAMA-8B-INSTRUCT">
      <data key="d4">14.0</data>
      <data key="d5">Orca-3 consistently outperforms LLAMA-8B-instruct in various benchmarks.
Orca-3 outperformed LLAMA-8B-instruct on multiple benchmarks.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="ORCA-3" target="GPT-3.5-TURBO">
      <data key="d4">21.0</data>
      <data key="d5">Orca-3 consistently outperforms GPT-3.5-turbo in various benchmarks.
Orca-3's performance is compared to GPT-3.5-turbo for the GSM8K benchmark.
Orca-3 shows significant performance improvements over GPT-3.5-turbo in various benchmarks.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ORCA-3" target="MISTRAL-INSTRUCT-7B">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3 showed significant improvements over Mistral-Instruct-7B on various benchmarks.
Orca-3 shows a 21% gain relative to Mistral-Instruct-7b in reading comprehension capabilities.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="ORCA-3" target="MISTRAL-7B-V0.1">
      <data key="d4">9.0</data>
      <data key="d5">Orca-3 is a finetuned version of the Mistral-7b-v0.1 model using the AgentInstruct dataset.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="NVIDIA A100">
      <data key="d4">8.0</data>
      <data key="d5">The training of Orca-3 used 152 NVIDIA A100 GPUs.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="ADAMW OPTIMIZER">
      <data key="d4">8.0</data>
      <data key="d5">The training of Orca-3 used the AdamW optimizer with an initial learning rate of 8e-6.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="MISTRAL TOKENIZER">
      <data key="d4">8.0</data>
      <data key="d5">The Mistral tokenizer was used to process the dataset for training the Orca-3 model.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="WEIGHT DECAY">
      <data key="d4">7.0</data>
      <data key="d5">Weight decay was used as a regularization technique in the training of the Orca-3 model.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="COSINE LEARNING RATE SCHEDULE">
      <data key="d4">7.0</data>
      <data key="d5">A cosine learning rate schedule was used in the training of the Orca-3 model.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="LINEAR LEARNING RATE WARM-UP">
      <data key="d4">7.0</data>
      <data key="d5">A linear learning rate warm-up was used during the initial 500 steps of training the Orca-3 model.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="EPOCH">
      <data key="d4">8.0</data>
      <data key="d5">The Orca-3 model was trained for three epochs.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="TRAINING LOSS">
      <data key="d4">8.0</data>
      <data key="d5">Training loss was calculated based on the response conditioned on the prompt during the training of the Orca-3 model.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="ORCA-BENCH">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3 is an advanced model evaluated using the Orca-Bench dataset, with scores improving across different checkpoints.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="FOFO">
      <data key="d4">16.0</data>
      <data key="d5">Orca-3 scored 84.01 on the FOFO benchmark, a 12% improvement over Orca-2.5.
Orca-3 shows significant improvements in format-following capabilities as evaluated by the FoFo benchmark.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="IFEVAL">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3 scored 49.54 on the IFEval benchmark, a 2% improvement over Orca-2.5.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="INFOBENCH">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3 scored 84.30 on the InfoBench benchmark, a 4% improvement over Orca-2.5.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="EQBENCH">
      <data key="d4">1.0</data>
      <data key="d5">Orca-3 scored 91.36 on the EQBench benchmark, a 4% improvement over Orca-2.5.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="PERFORMANCE COMPARISON">
      <data key="d4">8.0</data>
      <data key="d5">The performance comparison shows the enhancement in capabilities of Orca-3 during post-training.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="ORCA-3 CHECKPOINTS">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3 is evaluated at different checkpoints, showing improvement in scores from 9.35 to 9.55.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="TRAINING EPOCH">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3's performance is evaluated after each training epoch.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="MACRO SCORES">
      <data key="d4">7.0</data>
      <data key="d5">Macro scores are used to evaluate the performance of Orca-3 across all assessed dimensions.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="BENCHMARK RESULTS">
      <data key="d4">8.0</data>
      <data key="d5">Benchmark results show the performance of Orca-3 against 5 baseline models.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="DIMENSIONS">
      <data key="d4">7.0</data>
      <data key="d5">Various dimensions are assessed to evaluate the performance of Orca-3.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="CAPABILITIES">
      <data key="d4">8.0</data>
      <data key="d5">The capabilities of Orca-3 are enhanced during post-training.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="POST-TRAINING">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3's capabilities are enhanced during the post-training phase.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="ENHANCEMENT">
      <data key="d4">1.0</data>
      <data key="d5">The enhancement in Orca-3's capabilities is enabled by AgentInstruct data.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="MISTRAL-7B-INSTRUCT">
      <data key="d4">16.0</data>
      <data key="d5">Orca-3 shows relative improvements over Mistral-7b-Instruct in various benchmarks.
Orca-3 shows significant performance improvements over Mistral-7B-Instruct in various benchmarks.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ORCA-3" target="ORCA-2.5">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3 shows an 18% improvement over Orca-2.5 in reading comprehension capabilities.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="ORCA-3" target="ORCA 2.5">
      <data key="d4">9.0</data>
      <data key="d5">Orca-3 shows significant performance improvements over its predecessor, Orca 2.5, in various benchmarks.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ORCA-3" target="LSAT">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3's performance on the reading comprehension sections of the LSAT matches that of GPT-4.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ORCA-3" target="GEMINI PRO">
      <data key="d4">1.0</data>
      <data key="d5">Orca-3 surpasses Gemini Pro in format-following capabilities.</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="ALPACAEVAL" target="XUECHEN LI">
      <data key="d4">8.0</data>
      <data key="d5">Xuechen Li is one of the authors of the AlpacaEval project.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACAEVAL" target="TIANYI ZHANG">
      <data key="d4">8.0</data>
      <data key="d5">Tianyi Zhang is one of the authors of the AlpacaEval project.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACAEVAL" target="YANN DUBOIS">
      <data key="d4">8.0</data>
      <data key="d5">Yann Dubois is one of the authors of the AlpacaEval project.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACAEVAL" target="ROHAN TAORI">
      <data key="d4">8.0</data>
      <data key="d5">Rohan Taori is one of the authors of the AlpacaEval project.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACAEVAL" target="ISHAAN GULRAJANI">
      <data key="d4">8.0</data>
      <data key="d5">Ishaan Gulrajani is one of the authors of the AlpacaEval project.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACAEVAL" target="CARLOS GUESTRIN">
      <data key="d4">8.0</data>
      <data key="d5">Carlos Guestrin is one of the authors of the AlpacaEval project.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACAEVAL" target="TATSUNORI B. HASHIMOTO">
      <data key="d4">8.0</data>
      <data key="d5">Tatsunori B. Hashimoto is one of the authors of the AlpacaEval project.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALPACAEVAL" target="OPEN-ENDED GENERATION">
      <data key="d4">7.0</data>
      <data key="d5">AlpacaEval is a benchmark used to evaluate open-ended generation tasks by measuring win-rates using GPT-4-turbo.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="GPT-3.5-TURBO" target="ORCA-BENCH">
      <data key="d4">7.0</data>
      <data key="d5">GPT-3.5-turbo is a baseline model evaluated using the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="GPT-3.5-TURBO" target="ORCA-3-7B">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3-7B is compared with GPT-3.5-Turbo in various evaluations.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-3.5-TURBO" target="MIRAGE">
      <data key="d4">8.0</data>
      <data key="d5">GPT-3.5-turbo is evaluated on the MIRAGE datasets, showing performance in RAG tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPT-3.5-TURBO" target="AZURE">
      <data key="d4">1.0</data>
      <data key="d5">Azure provides transparency notes and content moderation services for GPT-3.5-turbo.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="AHMED AWADALLAH" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Ahmed Awadallah is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="RESPONSES" target="DATA GENERATION WORKFLOWS">
      <data key="d4">7.0</data>
      <data key="d5">Data generation workflows involve the creation of responses to prompts.</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="CREATIVE WRITING" target="SKILLS">
      <data key="d4">8.0</data>
      <data key="d5">Creative writing is one of the skills developed or assessed by the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CODING" target="TOOL/API USE">
      <data key="d4">6.0</data>
      <data key="d5">Both involve the use of tools or APIs to perform tasks or solve problems.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CODING" target="SKILLS">
      <data key="d4">8.0</data>
      <data key="d5">Coding is one of the skills developed or assessed by the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="MULTI-AGENT WORKFLOWS" target="SEARCH APIS">
      <data key="d4">7.0</data>
      <data key="d5">Search APIs are tools used in multi-agent workflows to improve the quality of generated data.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MULTI-AGENT WORKFLOWS" target="CALCULATOR">
      <data key="d4">7.0</data>
      <data key="d5">Calculators are tools used in multi-agent workflows to improve the quality of generated data.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MULTI-AGENT WORKFLOWS" target="CODE INTERPRETERS">
      <data key="d4">1.0</data>
      <data key="d5">Code interpreters are tools used in multi-agent workflows to improve the quality of generated data.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="SKILLS" target="QUESTION ANSWERING">
      <data key="d4">8.0</data>
      <data key="d5">Question answering is one of the skills developed or assessed by the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="SKILLS" target="RETRIEVAL AUGMENTED GENERATION">
      <data key="d4">8.0</data>
      <data key="d5">Retrieval augmented generation is one of the skills developed or assessed by the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="SKILLS" target="TOOL/API USE">
      <data key="d4">8.0</data>
      <data key="d5">Tool/API use is one of the skills developed or assessed by the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="SKILLS" target="WEB CONTROL">
      <data key="d4">8.0</data>
      <data key="d5">Web control is one of the skills developed or assessed by the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="MISTRAL-INSTRUCT-7B" target="ORCA-BENCH">
      <data key="d4">7.0</data>
      <data key="d5">Mistral-Instruct-7B is a baseline model evaluated using the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="CONTENT TRANSFORMATION FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Content Transformation Flow is one of the flows defined by Agentic Flows to convert raw seeds into intermediate representations.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="SEED INSTRUCTION GENERATION FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Seed Instruction Generation Flow is one of the flows defined by Agentic Flows to generate diverse instructions from transformed content.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="INSTRUCTION REFINEMENT FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Instruction Refinement Flow is one of the flows defined by Agentic Flows to iteratively enhance the complexity and quality of instructions.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="RAW ARTICLES">
      <data key="d4">7.0</data>
      <data key="d5">Raw articles are used as seeds in the agentic flows to foster diversity and ensure broad coverage in generated problems.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="SOURCE CODE FILES">
      <data key="d4">7.0</data>
      <data key="d5">Source code files are used as seeds in the agentic flows to foster diversity and ensure broad coverage in generated problems.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="SEED INSTRUCTION GENERATION FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Seed Instruction Generation Flow takes transformed content from the Content Transformation Flow to generate diverse instructions.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="INTERMEDIATE REPRESENTATION">
      <data key="d4">8.0</data>
      <data key="d5">Content Transformation Flow converts raw seeds into intermediate representations to simplify the creation of instructions.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="ARGUMENT PASSAGE GENERATOR">
      <data key="d4">8.0</data>
      <data key="d5">Argument Passage Generator is one of the content transformation agents used in the Content Transformation Flow.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="CONTENT TRANSFORMATION AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The Content Transformation Agent is used in the Content Transformation Flow to synthesize an API description from a source code snippet.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="API RETRIEVAL AGENT">
      <data key="d4">8.0</data>
      <data key="d5">The API Retrieval Agent is used in the Content Transformation Flow to iteratively search for similar code to expand an API list.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="LIBRARY RECONSTRUCTION">
      <data key="d4">7.0</data>
      <data key="d5">Library Reconstruction is a scenario within the Content Transformation Flow where a list of APIs is synthesized from a random seed.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="INSTRUCTION REFINEMENT FLOW">
      <data key="d4">8.0</data>
      <data key="d5">Instruction Refinement Flow takes instructions from the Seed Instruction Generation Flow and enhances their complexity and quality.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="SEED INSTRUCTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Seed Instruction Generation Flow generates seed instructions from transformed content to introduce diversity.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="READING COMPREHENSION QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">The Seed Instruction Generation Flow involves compiling a collection of reading comprehension question types.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">The Seed Instruction Generation Flow defines multiple agents to generate questions based on predefined types.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="CONTENT TRANSFORMATION AGENT">
      <data key="d4">7.0</data>
      <data key="d5">The content transformation agent determines which subset of agents to engage in the Seed Instruction Generation Flow process.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="PASSAGE, QUESTION PAIRS">
      <data key="d4">8.0</data>
      <data key="d5">The Seed Instruction Generation Flow results in the creation of passage, question pairs.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="LITERAL COMPREHENSION QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Generation Flow includes literal comprehension questions as one of the types.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="CRITICAL COMPREHENSION QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Generation Flow includes critical comprehension questions as one of the types.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="EVALUATIVE COMPREHENSION QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Generation Flow includes evaluative comprehension questions as one of the types.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="REASONING QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Generation Flow includes reasoning questions as one of the types.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="IDENTIFYING ASSUMPTIONS QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Generation Flow includes identifying assumptions questions as one of the types.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="IDENTIFYING INFORMATION THAT STRENGTHENS/WEAKENS AN ARGUMENT QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Generation Flow includes questions that identify information that strengthens or weakens an argument.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="ORDERING EVENTS QUESTIONS">
      <data key="d4">7.0</data>
      <data key="d5">The Seed Instruction Generation Flow includes ordering events questions as one of the types.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="APPENDIX A">
      <data key="d4">6.0</data>
      <data key="d5">Appendix A contains a list of reading comprehension question types included in the Seed Instruction Generation Flow.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="SUGGESTER-EDITOR AGENTS">
      <data key="d4">15.0</data>
      <data key="d5">Suggester-Editor Agents are used in the Instruction Refinement Flow to propose and modify instructions.
The Instruction Refinement Flow involves suggester-editor agents that modify passage, question pairs.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d,f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="SUGGESTER AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Suggester agents propose various approaches to increase the intricacy of initial instructions in the Instruction Refinement Flow.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="EDITOR AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Editor agents modify instructions based on suggestions from suggester agents in the Instruction Refinement Flow.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="PASSAGE, QUESTION PAIRS">
      <data key="d4">8.0</data>
      <data key="d5">The Instruction Refinement Flow modifies passage, question pairs to create more complex or unanswerable questions.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="STRENGTHEN TYPE QUESTION">
      <data key="d4">7.0</data>
      <data key="d5">The Instruction Refinement Flow includes strengthen type questions as an example.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="SUGGESTER-EDITOR PAIR">
      <data key="d4">8.0</data>
      <data key="d5">The Suggester-Editor Pair is used in the Instruction Refinement Flow to increase the complexity of generated instructions.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="TASK MODIFICATION INSTRUCTION">
      <data key="d4">8.0</data>
      <data key="d5">Task modification instructions are used in the Instruction Refinement Flow to refine and increase the complexity of generated instructions.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SUGGESTER-EDITOR AGENTS" target="SUGGESTION 1">
      <data key="d4">6.0</data>
      <data key="d5">Suggester-editor agents can introduce a hypothetical study or finding as Suggestion 1.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SUGGESTER-EDITOR AGENTS" target="SUGGESTION 2">
      <data key="d4">6.0</data>
      <data key="d5">Suggester-editor agents can add a layer of complexity by suggesting a genetic predisposition as Suggestion 2.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SUGGESTER-EDITOR AGENTS" target="SUGGESTION 3">
      <data key="d4">6.0</data>
      <data key="d5">Suggester-editor agents can include a distractor option as Suggestion 3.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SUGGESTER-EDITOR AGENTS" target="MODIFICATION 1">
      <data key="d4">6.0</data>
      <data key="d5">Suggester-editor agents can alter the passage to make the question unanswerable as Modification 1.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SUGGESTER-EDITOR AGENTS" target="MODIFICATION 2">
      <data key="d4">6.0</data>
      <data key="d5">Suggester-editor agents can alter the passage to change the answer in the opposite direction as Modification 2.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SUGGESTER-EDITOR AGENTS" target="MODIFICATION 3">
      <data key="d4">6.0</data>
      <data key="d5">Suggester-editor agents can alter the questions or answer choices to make them more complex as Modification 3.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="RETRIEVAL AUGMENTED GENERATION" target="TEXT EXTRACTION">
      <data key="d4">8.0</data>
      <data key="d5">Retrieval Augmented Generation involves retrieving relevant documents, which is a form of text extraction.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="WEB CONTROL" target="WEB AGENT">
      <data key="d4">1.0</data>
      <data key="d5">A web agent performs tasks on the web, which is a form of web control.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="TEXT EXTRACTION">
      <data key="d4">6.0</data>
      <data key="d5">Both involve processing and altering text to suit different purposes.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="TEXT">
      <data key="d4">8.0</data>
      <data key="d5">Text modification involves changing existing text to improve its quality or fit a specific context.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="TASKS">
      <data key="d4">8.0</data>
      <data key="d5">Text modification is one of the tasks within the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="TEXT MODIFICATION TASKS">
      <data key="d4">8.0</data>
      <data key="d5">Text modification involves various tasks such as paraphrasing, expansion, and simplification.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="PARAPHRASING AGENT">
      <data key="d4">1.0</data>
      <data key="d5">The Paraphrasing Agent is used to create text modification tasks involving rephrasing.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="TEXT MODIFICATION AGENTS">
      <data key="d4">7.0</data>
      <data key="d5">Text modification involves agents that create tasks such as paraphrasing, expansion, and simplification.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="MULTIPLE CHOICE QUESTIONS" target="TASKS">
      <data key="d4">8.0</data>
      <data key="d5">Multiple choice questions are one of the tasks within the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="MULTIPLE CHOICE QUESTIONS" target="EVALUATOR ASSISTANT">
      <data key="d4">8.0</data>
      <data key="d5">The Evaluator Assistant role is used in the context of multiple choice questions to parse student responses.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="DATA TO TEXT" target="TASKS">
      <data key="d4">8.0</data>
      <data key="d5">Data-to-text is one of the tasks within the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="FERMI PROBLEMS" target="TASKS">
      <data key="d4">8.0</data>
      <data key="d5">Fermi problems are one of the tasks within the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="FERMI PROBLEMS" target="ENRICO FERMI">
      <data key="d4">18.0</data>
      <data key="d5">Fermi problems are named after physicist Enrico Fermi.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TEXT EXTRACTION" target="TEXT">
      <data key="d4">8.0</data>
      <data key="d5">Text extraction involves retrieving relevant information from a larger text document.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT EXTRACTION" target="TASKS">
      <data key="d4">1.0</data>
      <data key="d5">Text extraction is one of the tasks within the workflows.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT EXTRACTION" target="TEXT CLASSIFICATION">
      <data key="d4">7.0</data>
      <data key="d5">Both text extraction and text classification are tasks in natural language processing that deal with processing and understanding text.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TEXT EXTRACTION" target="NAMED ENTITY RECOGNITION">
      <data key="d4">8.0</data>
      <data key="d5">Named entity recognition is a task involved in text extraction.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TEXT EXTRACTION" target="KEYWORD EXTRACTION">
      <data key="d4">8.0</data>
      <data key="d5">Keyword extraction is a task involved in text extraction.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="INTERMEDIATE REPRESENTATION" target="ARGUMENT PASSAGE">
      <data key="d4">6.0</data>
      <data key="d5">An argument passage is a type of intermediate representation used in the Content Transformation Flow.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="INTERMEDIATE REPRESENTATION" target="MEETING TRANSCRIPT">
      <data key="d4">6.0</data>
      <data key="d5">A meeting transcript is a type of intermediate representation used in the Content Transformation Flow.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="INTERMEDIATE REPRESENTATION" target="LIST OF APIS">
      <data key="d4">6.0</data>
      <data key="d5">A list of APIs is a type of intermediate representation used in the Content Transformation Flow.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="READING COMPREHENSION TESTS" target="TEXT PASSAGES">
      <data key="d4">7.0</data>
      <data key="d5">Text passages are used in reading comprehension tests to assess understanding.</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT CLASSIFICATION" target="SPAM DETECTION">
      <data key="d4">8.0</data>
      <data key="d5">Spam detection is an application of text classification.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TEXT CLASSIFICATION" target="SENTIMENT ANALYSIS">
      <data key="d4">8.0</data>
      <data key="d5">Sentiment analysis is an application of text classification.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TEXT CLASSIFICATION" target="TOPIC LABELING">
      <data key="d4">8.0</data>
      <data key="d5">Topic labeling is an application of text classification.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="URIC ACID" target="HYPERURICEMIA">
      <data key="d4">18.0</data>
      <data key="d5">Hyperuricemia is a condition characterized by high levels of uric acid.
Hyperuricemia is a condition characterized by high levels of uric acid in the blood.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="URIC ACID" target="HYPOURICEMIA">
      <data key="d4">18.0</data>
      <data key="d5">Hypouricemia is a condition characterized by low levels of uric acid.
Hypouricemia is a condition characterized by low levels of uric acid in the blood.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="URIC ACID" target="PURINE">
      <data key="d4">1.0</data>
      <data key="d5">Uric acid is a byproduct of purine metabolism.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="URIC ACID" target="CARDIOVASCULAR DISEASE">
      <data key="d4">8.0</data>
      <data key="d5">High levels of uric acid are associated with an increased risk of cardiovascular disease.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="URIC ACID" target="ALCOHOL CONSUMPTION">
      <data key="d4">7.0</data>
      <data key="d5">Alcohol consumption can influence uric acid levels in the body.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="URIC ACID" target="PHYSICAL INACTIVITY">
      <data key="d4">7.0</data>
      <data key="d5">Physical inactivity can influence uric acid levels in the body.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPERURICEMIA" target="LABORATORY BLOOD TESTS">
      <data key="d4">9.0</data>
      <data key="d5">Laboratory blood tests are used to diagnose hyperuricemia by measuring uric acid levels in the blood.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="HYPERURICEMIA" target="LABORATORY URINE TESTS">
      <data key="d4">9.0</data>
      <data key="d5">Laboratory urine tests are used to diagnose hyperuricemia by measuring uric acid levels in the urine.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="HYPERURICEMIA" target="CARDIOVASCULAR DISEASE">
      <data key="d4">8.0</data>
      <data key="d5">Hyperuricemia is associated with an increased risk of cardiovascular disease.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPERURICEMIA" target="LABORATORY BLOOD AND URINE TESTS">
      <data key="d4">7.0</data>
      <data key="d5">Hyperuricemia can be diagnosed using laboratory blood and urine tests.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPOURICEMIA" target="LABORATORY BLOOD TESTS">
      <data key="d4">9.0</data>
      <data key="d5">Laboratory blood tests are used to diagnose hypouricemia by measuring uric acid levels in the blood.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="HYPOURICEMIA" target="LABORATORY URINE TESTS">
      <data key="d4">1.0</data>
      <data key="d5">Laboratory urine tests are used to diagnose hypouricemia by measuring uric acid levels in the urine.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="HYPOURICEMIA" target="LABORATORY BLOOD AND URINE TESTS">
      <data key="d4">7.0</data>
      <data key="d5">Hypouricemia can be diagnosed using laboratory blood and urine tests.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPOURICEMIA" target="KIDNEY ISSUES">
      <data key="d4">7.0</data>
      <data key="d5">Hypouricemia can indicate underlying kidney issues.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPOURICEMIA" target="LIVER ISSUES">
      <data key="d4">7.0</data>
      <data key="d5">Hypouricemia can indicate underlying liver issues.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="LSAT LOGICAL REASONING TEST" target="ASSUMPTION QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Assumption questions are a type of question in the LSAT Logical Reasoning test.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="LSAT LOGICAL REASONING TEST" target="STRENGTHENING/WEAKENING QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Strengthening/weakening questions are a type of question in the LSAT Logical Reasoning test.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="LSAT LOGICAL REASONING TEST" target="FLAW QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Flaw questions are a type of question in the LSAT Logical Reasoning test.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="LSAT LOGICAL REASONING TEST" target="INFERENCE QUESTIONS">
      <data key="d4">8.0</data>
      <data key="d5">Inference questions are a type of question in the LSAT Logical Reasoning test.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION QUESTIONS" target="AGENTS">
      <data key="d4">8.0</data>
      <data key="d5">Agents are defined to target specific categories of reading comprehension questions.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION AGENT" target="API DESCRIPTION">
      <data key="d4">8.0</data>
      <data key="d5">An API description is synthesized by the Content Transformation Agent from a source code snippet.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="PARAPHRASING AGENT" target="RANDOM SEED">
      <data key="d4">7.0</data>
      <data key="d5">A random seed is used by the Paraphrasing Agent to create text modification tasks.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SUGGESTION 1" target="SUGGESTER-EDITOR PAIR">
      <data key="d4">7.0</data>
      <data key="d5">Suggestion 1 is provided by the Suggester-Editor Pair to incorporate a fictional narrative and use a conversational style with colloquial language.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SUGGESTION 1" target="INSTRUCTION 1">
      <data key="d4">7.0</data>
      <data key="d5">Instruction 1 is a modified version of Suggestion 1, rewriting event details as if telling a funny story to a friend.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SUGGESTION 2" target="SUGGESTER-EDITOR PAIR">
      <data key="d4">7.0</data>
      <data key="d5">Suggestion 2 is provided by the Suggester-Editor Pair to translate event details into a poetic format with rhyming couplets.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SUGGESTION 2" target="INSTRUCTION 2">
      <data key="d4">7.0</data>
      <data key="d5">Instruction 2 is a modified version of Suggestion 2, transforming event details into a light-hearted poem with rhyming couplets.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SUGGESTION 3" target="SUGGESTER-EDITOR PAIR">
      <data key="d4">7.0</data>
      <data key="d5">Suggestion 3 is provided by the Suggester-Editor Pair to frame event details as a social media post using internet slang and emojis.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SUGGESTION 3" target="INSTRUCTION 3">
      <data key="d4">7.0</data>
      <data key="d5">Instruction 3 is a modified version of Suggestion 3, crafting a social media post with event details using internet slang and emojis.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="TEXT MODIFICATION AGENTS" target="PARAPHRASING">
      <data key="d4">7.0</data>
      <data key="d5">Text modification agents can create paraphrasing tasks.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="TEXT MODIFICATION AGENTS" target="SIMPLIFICATION">
      <data key="d4">7.0</data>
      <data key="d5">Text modification agents can create simplification tasks.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="TEXT MODIFICATION AGENTS" target="REDACTING OR REMOVING CONTENT">
      <data key="d4">7.0</data>
      <data key="d5">Text modification agents can create tasks involving redacting or removing content.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="TEXT MODIFICATION AGENTS" target="STYLING">
      <data key="d4">7.0</data>
      <data key="d5">Text modification agents can create styling tasks.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="TEXT MODIFICATION AGENTS" target="CODE SWITCHING">
      <data key="d4">1.0</data>
      <data key="d5">Text modification agents can create code switching tasks.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="FINANCIALIZATION" target="NATASCHA VAN DER ZWAN">
      <data key="d4">9.0</data>
      <data key="d5">Natascha van der Zwan identifies three distinct research streams that approach financialization from different perspectives.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="FINANCIALIZATION" target="FINANCE">
      <data key="d4">7.0</data>
      <data key="d5">Finance is a broad concept that is increasingly interconnected with financialization.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="AMERICAN ANTHROPOLOGICAL ASSOCIATION" target="SEA 2017 ANNUAL MEETING">
      <data key="d4">8.0</data>
      <data key="d5">The American Anthropological Association hosts the SEA 2017 Annual Meeting.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SEA 2017 ANNUAL MEETING" target="APRIL 6-8, 2017">
      <data key="d4">8.0</data>
      <data key="d5">The SEA 2017 Annual Meeting took place on April 6-8, 2017.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SEA 2017 ANNUAL MEETING" target="DECEMBER 1, 2016">
      <data key="d4">8.0</data>
      <data key="d5">December 1, 2016, is the deadline for submitting abstracts for the SEA 2017 Annual Meeting.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="LIBRARY RECONSTRUCTION" target="VIEW ALL FOOD ITEMS">
      <data key="d4">7.0</data>
      <data key="d5">View All Food Items is an API that is part of the Library Reconstruction scenario.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="LIBRARY RECONSTRUCTION" target="SEARCH FOOD ITEMS">
      <data key="d4">1.0</data>
      <data key="d5">Search Food Items is an API that is part of the Library Reconstruction scenario.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="VIEW ALL FOOD ITEMS" target="CALORIE COUNT">
      <data key="d4">7.0</data>
      <data key="d5">Calorie count is a nutritional profile attribute included in the View All Food Items API.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="VIEW ALL FOOD ITEMS" target="PROTEIN">
      <data key="d4">7.0</data>
      <data key="d5">Protein is a nutritional profile attribute included in the View All Food Items API.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="VIEW ALL FOOD ITEMS" target="FAT">
      <data key="d4">1.0</data>
      <data key="d5">Fat is a nutritional profile attribute included in the View All Food Items API.</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="CREATE MEAL PLAN" target="QUINOA SALAD">
      <data key="d4">7.0</data>
      <data key="d5">The user wants to add the Quinoa Salad recipe while creating a meal plan.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="UPDATE FOOD ITEM" target="CHANA MASALA">
      <data key="d4">8.0</data>
      <data key="d5">The user wants to update the nutritional information for Chana Masala using the "Update Food Item" API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="DELETE FOOD ITEM" target="BUTTER CHICKEN">
      <data key="d4">1.0</data>
      <data key="d5">The user wants to remove Butter Chicken from the database using the "Delete Food Item" API.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="SEED INSTRUCTION CREATION FLOW" target="ASSISTANT">
      <data key="d4">7.0</data>
      <data key="d5">The assistant uses the Seed Instruction Creation Flow to create tasks based on the list of available APIs.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="REFINEMENT FLOW" target="ASSISTANT">
      <data key="d4">7.0</data>
      <data key="d5">The assistant uses the Refinement Flow to increase the complexity of tasks by suggesting additional steps.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="AGENT-INSTRUCT FLOW" target="ASSISTANT">
      <data key="d4">7.0</data>
      <data key="d5">The assistant uses the Agent-Instruct Flow to create multi-turn conversations and instructions to help the user achieve their desired outcomes.</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="QUINOA SALAD" target="FOOD_ID">
      <data key="d4">7.0</data>
      <data key="d5">The user needs to provide the nutritional information for the Quinoa Salad to add it to the database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="QUINOA SALAD" target="MEAL PLAN DATABASE">
      <data key="d4">7.0</data>
      <data key="d5">The Quinoa Salad recipe needs to be added to the meal plan database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="QUINOA SALAD" target="NUTRITIONAL INFORMATION">
      <data key="d4">7.0</data>
      <data key="d5">Nutritional information is required to add the Quinoa Salad recipe to the database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="CHANA MASALA" target="FOOD_ID">
      <data key="d4">7.0</data>
      <data key="d5">The user needs the unique identifier (food_id) to update the Chana Masala recipe in the database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="CHANA MASALA" target="MEAL PLAN DATABASE">
      <data key="d4">7.0</data>
      <data key="d5">The Chana Masala recipe needs to be updated in the meal plan database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="BUTTER CHICKEN" target="FOOD_ID">
      <data key="d4">7.0</data>
      <data key="d5">The user needs the unique identifier (food_id) to remove the Butter Chicken recipe from the database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="BUTTER CHICKEN" target="MEAL PLAN DATABASE">
      <data key="d4">7.0</data>
      <data key="d5">The Butter Chicken recipe needs to be removed from the meal plan database.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="CALORIC GOAL">
      <data key="d4">9.0</data>
      <data key="d5">The vegetarian meal plan is designed to meet a caloric goal of 1500 calories per day.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="OATMEAL WITH FRUITS">
      <data key="d4">8.0</data>
      <data key="d5">Oatmeal with fruits is included in the vegetarian meal plan for breakfast.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="ALMOND MILK">
      <data key="d4">8.0</data>
      <data key="d5">Almond milk is included in the vegetarian meal plan for breakfast.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="CHICKPEA SALAD">
      <data key="d4">8.0</data>
      <data key="d5">Chickpea salad is included in the vegetarian meal plan for lunch.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="WHOLE WHEAT BREAD">
      <data key="d4">8.0</data>
      <data key="d5">Whole wheat bread is included in the vegetarian meal plan for lunch.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="MIXED VEGETABLE STIR FRY">
      <data key="d4">8.0</data>
      <data key="d5">Mixed vegetable stir fry is included in the vegetarian meal plan for dinner.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="VEGETARIAN MEAL PLAN" target="BROWN RICE">
      <data key="d4">8.0</data>
      <data key="d5">Brown rice is included in the vegetarian meal plan for dinner.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="OATMEAL WITH FRUITS" target="DAY 1">
      <data key="d4">8.0</data>
      <data key="d5">Oatmeal with fruits is included in the meal plan for Day 1.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ALMOND MILK" target="DAY 1">
      <data key="d4">8.0</data>
      <data key="d5">Almond milk is included in the meal plan for Day 1.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="CHICKPEA SALAD" target="DAY 1">
      <data key="d4">8.0</data>
      <data key="d5">Chickpea salad is included in the meal plan for Day 1.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="WHOLE WHEAT BREAD" target="DAY 1">
      <data key="d4">8.0</data>
      <data key="d5">Whole wheat bread is included in the meal plan for Day 1.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="MIXED VEGETABLE STIR FRY" target="DAY 1">
      <data key="d4">8.0</data>
      <data key="d5">Mixed vegetable stir fry is included in the meal plan for Day 1.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="BROWN RICE" target="DAY 1">
      <data key="d4">8.0</data>
      <data key="d5">Brown rice is included in the meal plan for Day 1.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-2.5" target="ORCA-1">
      <data key="d4">8.0</data>
      <data key="d5">Orca-1 contributed to the 3.8 million paired instructions used in Orca-2.5.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-2.5" target="ORCA-2">
      <data key="d4">8.0</data>
      <data key="d5">Orca-2 contributed to the 3.8 million paired instructions used in Orca-2.5.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-2.5" target="ORCA-MATH">
      <data key="d4">8.0</data>
      <data key="d5">Orca-Math contributed to the 3.8 million paired instructions used in Orca-2.5.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-2.5" target="ORCA-BENCH">
      <data key="d4">7.0</data>
      <data key="d5">Orca-2.5 is a baseline model evaluated using the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-2.5" target="ORCA-3-7B">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B shows improvements over Orca-2.5 in various evaluations.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-BENCH" target="MULTI-TURN INTERACTION">
      <data key="d4">9.0</data>
      <data key="d5">Some entries in the Orca-Bench dataset involve multi-turn interactions.
Multi-turn interactions are part of the Orca-Bench dataset.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-BENCH" target="COMPLEX ODQA">
      <data key="d4">8.0</data>
      <data key="d5">Complex ODQA is a subset of questions within the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-BENCH" target="CHATGPT">
      <data key="d4">7.0</data>
      <data key="d5">ChatGPT is a baseline model evaluated using the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-BENCH" target="LLAMA3-8B-INSTRUCT">
      <data key="d4">7.0</data>
      <data key="d5">LLAMA3-8B-Instruct is a baseline model evaluated using the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-BENCH" target="MODEL PERFORMANCE">
      <data key="d4">8.0</data>
      <data key="d5">Model performance on the Orca-Bench dataset is scored on a scale from 0 to 10.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ODQA" target="COMPLEX ODQA">
      <data key="d4">1.0</data>
      <data key="d5">Complex ODQA is a subset of the ODQA category in the Orca-Bench dataset.</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="MULTI-TURN INTERACTION" target="USER INPUT">
      <data key="d4">7.0</data>
      <data key="d5">User inputs are part of the multi-turn interaction sequence within the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="MULTI-TURN INTERACTION" target="ASSISTANT RESPONSE">
      <data key="d4">7.0</data>
      <data key="d5">Assistant responses are part of the multi-turn interaction sequence within the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="MULTI-TURN INTERACTION" target="CONVERSATION HISTORY">
      <data key="d4">8.0</data>
      <data key="d5">Conversation history is used to condition the student response in the multi-turn interaction sequence within the Orca-Bench dataset.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="LLAMA3-8B-INSTRUCT" target="ORCA-3-7B">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3-7B is compared with LLAMA3-8B-Instruct in various evaluations.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="FOFO" target="OPEN-ENDED GENERATION">
      <data key="d4">7.0</data>
      <data key="d5">FOFO is a benchmark used to evaluate open-ended generation tasks by checking format correctness using GPT-4.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="IFEVAL" target="OPEN-ENDED GENERATION">
      <data key="d4">7.0</data>
      <data key="d5">IFEval is a benchmark used to evaluate open-ended generation tasks by checking if the model response follows verifiable instructions.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="INFOBENCH" target="OPEN-ENDED GENERATION">
      <data key="d4">7.0</data>
      <data key="d5">InfoBench is a benchmark used to evaluate open-ended generation tasks by checking if the model response follows decomposed instructions using GPT-4.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="EQBENCH" target="EQBENCH GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d4">8.0</data>
      <data key="d5">The EQBench GPT-4 Extraction System Message is used for extracting emotion scores from responses evaluated using EQBench.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="EQBENCH" target="VERSION 1 AND 2 IMPLEMENTATIONS">
      <data key="d4">7.0</data>
      <data key="d5">The scoring calculations for EQBench are based on version 1 and 2 implementations described in the EQBench paper and repository.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="EQBENCH" target="CREATORS' GITHUB REPOSITORY">
      <data key="d4">6.0</data>
      <data key="d5">The creators' GitHub repository contains the implementations and resources for EQBench.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="EQBENCH" target="EMOTION SCORES">
      <data key="d4">8.0</data>
      <data key="d5">Emotion scores are generated as part of the EQBench evaluation process.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="EQBENCH" target="STUDENT AGENT RESPONSE">
      <data key="d4">8.0</data>
      <data key="d5">The student agent response is evaluated using the EQBench benchmark.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="STUDENT RESPONSE" target="TEACHER RESPONSE">
      <data key="d4">9.0</data>
      <data key="d5">Student responses are evaluated against the original teacher responses generated by GPT-4.</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="STUDENT RESPONSE" target="EVALUATOR ASSISTANT">
      <data key="d4">8.0</data>
      <data key="d5">The Evaluator Assistant parses the student response to extract the selected option.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="STUDENT RESPONSE" target="ANSWER OPTIONS">
      <data key="d4">7.0</data>
      <data key="d5">The student response includes the selection of one or more answer options.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="STUDENT RESPONSE" target="PARSED STUDENT ANSWER">
      <data key="d4">9.0</data>
      <data key="d5">The parsed student answer is extracted from the student's response.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="STUDENT RESPONSE" target="FINAL ANSWER">
      <data key="d4">9.0</data>
      <data key="d5">The final answer is derived from the student's response after considering all options.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="MISTRAL-7B-INSTRUCT" target="ORCA-3-7B">
      <data key="d4">7.0</data>
      <data key="d5">Orca-3-7B shows improvements over Mistral-7B-Instruct in various evaluations.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GEMINI PRO" target="ORCA-3-7B">
      <data key="d4">6.0</data>
      <data key="d5">The scores for Gemini Pro are referenced for comparison with Orca-3-7B.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="FOFO BENCHMARK">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B is evaluated on the FoFo benchmark, showing improvements over previous models.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="HALLUCINATION RATE">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B has a lower hallucination rate compared to previous models like Orca-2.5 and Mistral-7B-Instruct.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="QUALITY SCORE">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B has a higher quality score compared to previous models like Orca-2.5 and Mistral-7B-Instruct.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-3-7B" target="MIRAGE">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B is evaluated on the MIRAGE datasets, showing substantial improvement in RAG tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ORCA-3-7B" target="LIMITATIONS">
      <data key="d4">8.0</data>
      <data key="d5">Orca-3-7B retains many limitations of the Mistral model family and other large language models, including data biases, lack of transparency, and content harms.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ORCA-3-7B" target="DATA BIASES">
      <data key="d4">7.0</data>
      <data key="d5">Data Biases are a limitation of Orca-3-7B, where the model may carry biases present in the source data.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ORCA-3-7B" target="LACK OF TRANSPARENCY">
      <data key="d4">7.0</data>
      <data key="d5">Lack of Transparency is a limitation of Orca-3-7B, making it difficult to understand the rationale behind specific outputs.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ORCA-3-7B" target="CONTENT HARMS">
      <data key="d4">7.0</data>
      <data key="d5">Content Harms are a limitation of Orca-3-7B, where the model can generate harmful content.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ACI-BENCH" target="WEN WAI YIM">
      <data key="d4">9.0</data>
      <data key="d5">Wen Wai Yim is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="ACI-BENCH" target="YUJUAN FU">
      <data key="d4">9.0</data>
      <data key="d5">Yujuan Fu is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="ACI-BENCH" target="ASMA BEN ABACHA">
      <data key="d4">9.0</data>
      <data key="d5">Asma Ben Abacha is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="ACI-BENCH" target="NEAL SNIDER">
      <data key="d4">9.0</data>
      <data key="d5">Neal Snider is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="ACI-BENCH" target="THOMAS LIN">
      <data key="d4">9.0</data>
      <data key="d5">Thomas Lin is one of the authors of the paper titled "Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="ORCA-SUM" target="DATA TRANSFORMATION">
      <data key="d4">7.0</data>
      <data key="d5">Orca-Sum evaluates the data transformation abilities of language models.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-SUM" target="SUMMARIZATION">
      <data key="d4">7.0</data>
      <data key="d5">Orca-Sum evaluates the summarization abilities of language models.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ORCA-SUM" target="HUGGING FACE">
      <data key="d4">6.0</data>
      <data key="d5">Hugging Face hosts the datasets used to create the Orca-Sum benchmark.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MIRAGE" target="MEDMEDQA">
      <data key="d4">8.0</data>
      <data key="d5">MedMedQA is one of the datasets included in the MIRAGE benchmark.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MIRAGE" target="USMEDMCQA">
      <data key="d4">8.0</data>
      <data key="d5">USMedMCQA is one of the datasets included in the MIRAGE benchmark.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MIRAGE" target="PUBMEDQA">
      <data key="d4">8.0</data>
      <data key="d5">PubMedQA is one of the datasets included in the MIRAGE benchmark.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MIRAGE" target="BIOASQ">
      <data key="d4">8.0</data>
      <data key="d5">BioASQ is one of the datasets included in the MIRAGE benchmark.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MIRAGE" target="ORCA-2.5-7B">
      <data key="d4">7.0</data>
      <data key="d5">Orca-2.5-7B is evaluated on the MIRAGE datasets, showing performance in RAG tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MIRAGE" target="MISTRAL-7B-INSTRUCT-V0.1">
      <data key="d4">7.0</data>
      <data key="d5">Mistral-7B-Instruct-v0.1 is evaluated on the MIRAGE datasets, showing performance in RAG tasks.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MIRAGE" target="MEDRAG">
      <data key="d4">8.0</data>
      <data key="d5">MedRAG is the retrieval mechanism used across all models on the MIRAGE benchmark.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MMLU-MED" target="GPT-4 (0613) COT">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 (0613) CoT is evaluated on the MMLU-Med dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MMLU-MED" target="GPT-3.5-TURBO RAG">
      <data key="d4">7.0</data>
      <data key="d5">GPT-3.5-Turbo RAG is evaluated on the MMLU-Med dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MEDQA-US" target="GPT-4 (0613) COT">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 (0613) CoT is evaluated on the MedQA-US dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MEDQA-US" target="GPT-3.5-TURBO RAG">
      <data key="d4">7.0</data>
      <data key="d5">GPT-3.5-Turbo RAG is evaluated on the MedQA-US dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MEDMCQA" target="GPT-4 (0613) COT">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 (0613) CoT is evaluated on the MedMCQA dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MEDMCQA" target="GPT-3.5-TURBO RAG">
      <data key="d4">7.0</data>
      <data key="d5">GPT-3.5-Turbo RAG is evaluated on the MedMCQA dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="PUBMEDQA" target="GPT-4 (0613) COT">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 (0613) CoT is evaluated on the PubMedQA dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="PUBMEDQA" target="GPT-3.5-TURBO RAG">
      <data key="d4">7.0</data>
      <data key="d5">GPT-3.5-Turbo RAG is evaluated on the PubMedQA dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="BIOASQ" target="GPT-4 (0613) COT">
      <data key="d4">7.0</data>
      <data key="d5">GPT-4 (0613) CoT is evaluated on the BioASQ dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="BIOASQ" target="GPT-3.5-TURBO RAG">
      <data key="d4">1.0</data>
      <data key="d5">GPT-3.5-Turbo RAG is evaluated on the BioASQ dataset for medical question-answering capabilities.</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="AZURE" target="TRANSPARENCY NOTES">
      <data key="d4">16.0</data>
      <data key="d5">Azure provides transparency notes to offer more information about the functioning of large language models.
Azure provides transparency notes to help users understand the rationale behind specific outputs or decisions of large language models.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="AZURE" target="CONTENT MODERATION SERVICES">
      <data key="d4">1.0</data>
      <data key="d5">Azure provides content moderation services to prevent harmful content generated by large language models.</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="CONTENT HARMS" target="CONTENT MODERATION SERVICES">
      <data key="d4">9.0</data>
      <data key="d5">Content moderation services are recommended to prevent content harms caused by large language models.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="CONTENT HARMS" target="RESEARCH AND OPEN SOURCE COMMUNITY">
      <data key="d4">7.0</data>
      <data key="d5">The research and open source community plays an important role in addressing content harms and improving AI technologies.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="GOVERNMENT AND TECHNOLOGY LEADERS" target="REGULATIONS AND STANDARDS">
      <data key="d4">8.0</data>
      <data key="d5">Government and technology leaders are expected to create regulations and standards to mitigate content harms associated with AI technologies.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="HALLUCINATION" target="MEMORIZATION CAPACITIES">
      <data key="d4">7.0</data>
      <data key="d5">Hallucination in language models may be influenced by their memorization capacities, with smaller models potentially being more susceptible.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="POTENTIAL FOR MISUSE" target="DISINFORMATION">
      <data key="d4">9.0</data>
      <data key="d5">Without suitable safeguards, there is a risk that large language models could be used to generate disinformation.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="DATA DISTRIBUTION" target="TUNING DATA">
      <data key="d4">8.0</data>
      <data key="d5">The performance of models like Orca-3 is likely to correlate strongly with the distribution of the tuning data.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="MARAH ABDIN" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Marah Abdin is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="SAM ADE JACOBS" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Sam Ade Jacobs is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="AMMAR AHMAD AWAN" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Ammar Ahmad Awan is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="JYOTI ANEJA" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Jyoti Aneja is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="HANY AWADALLA" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Hany Awadalla is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="NGUYEN BACH" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Nguyen Bach is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="AMIT BAHREE" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Amit Bahree is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="ARASH BAKHTIARI" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Arash Bakhtiari is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="JIANMIN BAO" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Jianmin Bao is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="HARKIRAT BEHL" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Harkirat Behl is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="ALON BENHAIM" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Alon Benhaim is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="MISHA BILENKO" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Misha Bilenko is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="JOHAN BJORCK" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Johan Bjorck is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="S&#201;BASTIEN BUBECK" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">S&#233;bastien Bubeck is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="QIN CAI" target="PHI-3 TECHNICAL REPORT">
      <data key="d4">6.0</data>
      <data key="d5">Qin Cai is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">dd9a46950237e49ef9b1c7ef08e08d42</data>
    </edge>
    <edge source="PHI-3" target="WANG">
      <data key="d4">8.0</data>
      <data key="d5">Wang is one of the authors of the Phi-3 technical report.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="CODEPARROT" target="GITHUB-CODE CLEAN DATASET">
      <data key="d4">8.0</data>
      <data key="d5">CodeParrot is the provider of the Github-code clean dataset.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="NING DING" target="ENHANCING CHAT LANGUAGE MODELS">
      <data key="d4">8.0</data>
      <data key="d5">Ning Ding is one of the authors of the paper on enhancing chat language models.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="DROA" target="READING COMPREHENSION BENCHMARK">
      <data key="d4">8.0</data>
      <data key="d5">DROP is a reading comprehension benchmark requiring discrete reasoning over paragraphs.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="ZHAOYE FEI" target="QUERY OF CC">
      <data key="d4">8.0</data>
      <data key="d5">Zhaoye Fei is one of the authors of the paper on Query of CC.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="ARNAV GUDIBANDE" target="IMITATING PROPRIETARY LLMS">
      <data key="d4">8.0</data>
      <data key="d5">Arnav Gudibande is one of the authors of the paper on the false promise of imitating proprietary LLMs.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="HAMISH IVISON" target="ENHANCING LM ADAPTATION">
      <data key="d4">8.0</data>
      <data key="d5">Hamish Ivison is one of the authors of the paper on enhancing LM adaptation.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="ALBERT Q. JIANG" target="MISTRAL 7B">
      <data key="d4">8.0</data>
      <data key="d5">Albert Q. Jiang is one of the authors of the paper on Mistral 7B.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="HARRISON LEE" target="RLAIF">
      <data key="d4">8.0</data>
      <data key="d5">Harrison Lee is one of the authors of the paper on RLAIF.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="GUOHAO LI" target="CAMEL">
      <data key="d4">1.0</data>
      <data key="d5">Guohao Li is one of the authors of the paper on CAMEL.</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="CAMEL" target="RII KHIZBULLIN">
      <data key="d4">8.0</data>
      <data key="d5">Rii Khizbullin is one of the authors of the paper describing the Camel framework.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="CAMEL" target="BERNARD GHANEM">
      <data key="d4">8.0</data>
      <data key="d5">Bernard Ghanem is one of the authors of the paper describing the Camel framework.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="RII KHIZBULLIN" target="BERNARD GHANEM">
      <data key="d4">8.0</data>
      <data key="d5">Both are co-authors of the paper titled "Camel: Communicative agents for 'mind' exploration of large language model society," published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="XUECHEN LI" target="TIANYI ZHANG">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="XUECHEN LI" target="YANN DUBOIS">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="XUECHEN LI" target="ROHAN TAORI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="XUECHEN LI" target="ISHAAN GULRAJANI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="XUECHEN LI" target="CARLOS GUESTRIN">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="XUECHEN LI" target="TATSUNORI B. HASHIMOTO">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="TIANYI ZHANG" target="YANN DUBOIS">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="TIANYI ZHANG" target="ROHAN TAORI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="TIANYI ZHANG" target="ISHAAN GULRAJANI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="TIANYI ZHANG" target="CARLOS GUESTRIN">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="TIANYI ZHANG" target="TATSUNORI B. HASHIMOTO">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YANN DUBOIS" target="ROHAN TAORI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YANN DUBOIS" target="ISHAAN GULRAJANI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YANN DUBOIS" target="CARLOS GUESTRIN">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YANN DUBOIS" target="TATSUNORI B. HASHIMOTO">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ROHAN TAORI" target="ISHAAN GULRAJANI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ROHAN TAORI" target="CARLOS GUESTRIN">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ROHAN TAORI" target="TATSUNORI B. HASHIMOTO">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ISHAAN GULRAJANI" target="CARLOS GUESTRIN">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ISHAAN GULRAJANI" target="TATSUNORI B. HASHIMOTO">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="CARLOS GUESTRIN" target="TATSUNORI B. HASHIMOTO">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of the AlpacaEval project, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YIXIN LIU" target="ALEXANDER R. FABBRI">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YIXIN LIU" target="JIAWEN CHEN">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YIXIN LIU" target="YILUN ZHAO">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YIXIN LIU" target="SIMENG HAN">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YIXIN LIU" target="SHAFIQ JOTY">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YIXIN LIU" target="DRAGOMIR RADEV">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YIXIN LIU" target="CHIEN-SHENG WU">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="YIXIN LIU" target="ARMAN COHAN">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALEXANDER R. FABBRI" target="JIAWEN CHEN">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALEXANDER R. FABBRI" target="YILUN ZHAO">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALEXANDER R. FABBRI" target="SIMENG HAN">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="ALEXANDER R. FABBRI" target="SHAFIQ JOTY">
      <data key="d4">7.0</data>
      <data key="d5">Both are co-authors of a paper on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization, published in 2023.</data>
      <data key="d6">3d1f6634f93f8a4c296dc8df7e59859e</data>
    </edge>
    <edge source="MOHAMMED LATIF SIDDIQ" target="RE(GEX|DOS)EVAL">
      <data key="d4">9.0</data>
      <data key="d5">Mohammed Latif Siddiq is one of the authors of the paper titled "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="JIAHAO ZHANG" target="RE(GEX|DOS)EVAL">
      <data key="d4">9.0</data>
      <data key="d5">Jiahao Zhang is one of the authors of the paper titled "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="LINDSAY RONEY" target="RE(GEX|DOS)EVAL">
      <data key="d4">9.0</data>
      <data key="d5">Lindsay Roney is one of the authors of the paper titled "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="THE CURSE OF RECURSION" target="ILIA SHUMAILOV">
      <data key="d4">9.0</data>
      <data key="d5">Ilia Shumailov is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="THE CURSE OF RECURSION" target="ZAKHAR SHUMAYLOV">
      <data key="d4">9.0</data>
      <data key="d5">Zakhar Shumaylov is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="THE CURSE OF RECURSION" target="YIREN ZHAO">
      <data key="d4">9.0</data>
      <data key="d5">Yiren Zhao is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="THE CURSE OF RECURSION" target="YARIN GAL">
      <data key="d4">9.0</data>
      <data key="d5">Yarin Gal is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="THE CURSE OF RECURSION" target="NICOLAS PAPERNOT">
      <data key="d4">9.0</data>
      <data key="d5">Nicolas Papernot is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="THE CURSE OF RECURSION" target="ROSS ANDERSON">
      <data key="d4">9.0</data>
      <data key="d5">Ross Anderson is one of the authors of the paper titled "The curse of recursion: Training on generated data makes models forget."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="JOANNA C. S. SANTOS" target="RE(GEX|DOS)EVAL">
      <data key="d4">9.0</data>
      <data key="d5">Joanna C. S. Santos is one of the authors of the paper titled "Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="NATHANAEL SCH&#196;RLI" target="CHALLENGING BIG-BENCH TASKS">
      <data key="d4">9.0</data>
      <data key="d5">Nathanael Sch&#228;rli is one of the authors of the paper titled "Challenging big-bench tasks and whether chain-of-thought can solve them."</data>
      <data key="d6">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </edge>
    <edge source="ANSWER OPTIONS" target="ALPHABET ID">
      <data key="d4">1.0</data>
      <data key="d5">The alphabet ID represents the option selected by the student from the answer options.</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="ALPHABET ID" target="PARSED STUDENT ANSWER">
      <data key="d4">9.0</data>
      <data key="d5">The parsed student answer consists of the alphabet IDs representing the options chosen by the student.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="EXACT MATCH/SPAN EXTRACTION PROBLEMS" target="MATHS GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d4">8.0</data>
      <data key="d5">The Maths GPT-4 Extraction System Message is used for evaluating exact match/span extraction problems involving math-based questions.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="EXACT MATCH/SPAN EXTRACTION PROBLEMS" target="GENERAL EXTRACTION SYSTEM MESSAGE">
      <data key="d4">8.0</data>
      <data key="d5">The General Extraction System Message is used for evaluating exact match/span extraction problems where a ground-truth answer value is given.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="EQBENCH GPT-4 EXTRACTION SYSTEM MESSAGE" target="EMOTION SCORES">
      <data key="d4">1.0</data>
      <data key="d5">The EQBench GPT-4 Extraction System Message is used to parse and extract emotion scores from responses.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="CORRECT ANSWER" target="ERROR ANALYSIS">
      <data key="d4">9.0</data>
      <data key="d5">The correct answer is used in the error analysis to compare with the student's final answer.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="ERROR ANALYSIS" target="FINAL VERDICT">
      <data key="d4">9.0</data>
      <data key="d5">The error analysis leads to the final verdict, indicating whether the student's answer is 'Correct' or 'Incorrect'.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="STUDENT AGENT RESPONSE" target="FIRST PASS SCORES">
      <data key="d4">8.0</data>
      <data key="d5">The first pass scores are part of the student agent's response, representing initial emotion evaluations.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="STUDENT AGENT RESPONSE" target="CRITIQUE">
      <data key="d4">8.0</data>
      <data key="d5">The critique is part of the student agent's response, providing feedback on the initial scores.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="STUDENT AGENT RESPONSE" target="REVISED SCORES">
      <data key="d4">8.0</data>
      <data key="d5">The revised scores are part of the student agent's response, representing the final emotion evaluations after critique.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="FIRST PASS SCORES" target="REVISED SCORES">
      <data key="d4">8.0</data>
      <data key="d5">The revised scores are updated from the first pass scores after considering the critique.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="CRITIQUE" target="REVISED SCORES">
      <data key="d4">1.0</data>
      <data key="d5">The critique influences the revised scores in the student agent's response.</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="RESIGNED" target="ELLIOT">
      <data key="d4">8.0</data>
      <data key="d5">Elliot feels resigned after confessing his feelings to Alex, knowing that Alex is already in a relationship.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="ANGRY" target="ELLIOT">
      <data key="d4">7.0</data>
      <data key="d5">Elliot feels angry at himself for putting himself in the situation of confessing to Alex.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="HOPEFUL" target="ELLIOT">
      <data key="d4">6.0</data>
      <data key="d5">Elliot feels hopeful that Alex might reciprocate his feelings.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="EMBARRASSED" target="ELLIOT">
      <data key="d4">8.0</data>
      <data key="d5">Elliot feels embarrassed for putting Alex in an awkward position.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="HALLUCINATION JUDGE" target="QUALITY JUDGE">
      <data key="d4">1.0</data>
      <data key="d5">Both Hallucination Judge and Quality Judge are tasks that involve evaluating the output of AI models, focusing on hallucination detection and overall quality, respectively.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="QUALITY JUDGE" target="PROMPT TEMPLATE">
      <data key="d4">7.0</data>
      <data key="d5">A prompt template is used for the task of quality evaluation in text summarization.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="QUALITY JUDGE" target="TEXT SUMMARIZATION">
      <data key="d4">8.0</data>
      <data key="d5">Quality Judge is a task within text summarization to evaluate the overall quality of the generated summary.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="QUALITY JUDGE" target="INSTRUCTION ADHERENCE">
      <data key="d4">7.0</data>
      <data key="d5">Instruction adherence is a criterion used in the Quality Judge task to evaluate the response.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="QUALITY JUDGE" target="CONTENT GROUNDING">
      <data key="d4">7.0</data>
      <data key="d5">Content grounding is a criterion used in the Quality Judge task to evaluate the response.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="QUALITY JUDGE" target="OVERALL QUALITY">
      <data key="d4">1.0</data>
      <data key="d5">Overall quality is a criterion used in the Quality Judge task to evaluate the response.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="EMOTIONS" target="SCORES">
      <data key="d4">8.0</data>
      <data key="d5">The emotions experienced by Elliot are quantified with specific scores: Resigned (7), Angry (3), Hopeful (5), Embarrassed (8).</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="PROMPT TEMPLATE" target="HALLUCINATION DETECTION">
      <data key="d4">7.0</data>
      <data key="d5">A prompt template is used for the task of hallucination detection in text summarization.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="HALLUCINATION DETECTION" target="TEXT SUMMARIZATION">
      <data key="d4">8.0</data>
      <data key="d5">Hallucination detection is a task within text summarization to ensure the generated summary is accurate.</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
  </graph>
</graphml>