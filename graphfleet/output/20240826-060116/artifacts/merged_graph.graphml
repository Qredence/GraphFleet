<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d6" for="edge" attr.name="source_id" attr.type="string" />
  <key id="d5" for="edge" attr.name="description" attr.type="string" />
  <key id="d4" for="edge" attr.name="weight" attr.type="double" />
  <key id="d3" for="node" attr.name="entity_type" attr.type="string" />
  <key id="d2" for="node" attr.name="source_id" attr.type="string" />
  <key id="d1" for="node" attr.name="description" attr.type="string" />
  <key id="d0" for="node" attr.name="type" attr.type="string" />
  <graph edgedefault="undirected">
    <node id="GRAPH RAG">
      <data key="d0">APPROACH, METHOD</data>
      <data key="d1">A method for question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed. It uses an LLM to build a graph-based text index in two stages: deriving an entity knowledge graph from source documents and pre-generating community summaries for groups of closely-related entities.
A novel approach that uses a graph-based method for retrieval-augmented generation, focusing on global summarization of an LLM-derived knowledge graph
A retrieval-augmented generation system that uses graph-based community summaries to answer user queries
A system that provides comprehensive and detailed lists of public figures from various entertainment sectors, including their contributions and impacts


A specific approach to retrieval-augmented generation that uses the natural modularity of graphs to partition data for global summarization</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7,ac21ebe9a9d70d691c717f961d3f10c8,c8e8019de153e439d6a79dcf209b943b,edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
      <data key="d3">APPROACH, METHOD</data>
    </node>
    <node id="QUERY-FOCUSED SUMMARIZATION (QFS)">
      <data key="d0">TASK, METHOD</data>
      <data key="d1">A task that involves generating summaries of text that are focused on answering specific user queries, rather than just retrieving relevant text excerpts.
A summarization method that focuses on generating summaries based on specific user queries</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">TASK, METHOD</data>
    </node>
    <node id="RETRIEVAL-AUGMENTED GENERATION (RAG)">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A technique that retrieves relevant information from an external knowledge source to enable large language models to answer questions over private and/or previously unseen document collections.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="LARGE LANGUAGE MODELS (LLMS)">
      <data key="d0">TECHNOLOGY, MODEL</data>
      <data key="d1">Advanced machine learning models trained on vast amounts of text data to understand and generate human language, used in various applications including sensemaking and summarization.
Large Language Models (LLMs) are advanced machine learning models trained on vast amounts of text data to understand and generate human language.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
      <data key="d3">TECHNOLOGY, MODEL</data>
    </node>
    <node id="COMMUNITY DETECTION">
      <data key="d0">TECHNIQUE, METHOD</data>
      <data key="d1">A process used to partition a graph into groups of elements (nodes, edges, covariates) that can be summarized in parallel at both indexing time and query time.
Community detection is a method used to partition a graph into communities of nodes with stronger connections to one another than to other nodes in the graph.

The process of identifying groups of related nodes within a graph, as discussed by Fortunato in 2010</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,aa79049289e6532592eec17b9e76adfb,ac21ebe9a9d70d691c717f961d3f10c8,e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">TECHNIQUE, METHOD</data>
    </node>
    <node id="SENSEMAKING">
      <data key="d0">PROCESS, ACTIVITY</data>
      <data key="d1">A motivated, continuous effort to understand connections among people, places, and events in order to anticipate their trajectories and act effectively.
The process of understanding and making sense of large text corpora, supported by Graph RAG and other summarization techniques
The process of understanding and making sense of complex information, as discussed by Klein, Moon, and Hoffman in 2006</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,aa79049289e6532592eec17b9e76adfb,ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PROCESS, ACTIVITY</data>
    </node>
    <node id="MICROSOFT RESEARCH">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">A division of Microsoft responsible for conducting research in various domains, including the development of the Graph RAG approach.
Microsoft Research is the research division of Microsoft, where the authors of the paper are affiliated.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,6fe27f9eb76cf2ddf712a2cee5783d1c</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">A division of Microsoft involved in strategic missions and technologies, contributing to the research on Graph RAG.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="MICROSOFT OFFICE OF THE CTO">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">A division of Microsoft led by the Chief Technology Officer, involved in the research on Graph RAG.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="DAREN EDGE">
      <data key="d0">PERSON</data>
      <data key="d1">A researcher at Microsoft Research who contributed to the development of the Graph RAG approach.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="HA TRINH">
      <data key="d0">PERSON</data>
      <data key="d1">A researcher at Microsoft Research who contributed to the development of the Graph RAG approach.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NEWMAN CHENG">
      <data key="d0">PERSON</data>
      <data key="d1">A researcher at Microsoft Strategic Missions and Technologies who contributed to the development of the Graph RAG approach.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JOSHUA BRADLEY">
      <data key="d0">PERSON</data>
      <data key="d1">A researcher at Microsoft Strategic Missions and Technologies who contributed to the development of the Graph RAG approach.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ALEX CHAO">
      <data key="d0">PERSON</data>
      <data key="d1">A researcher at Microsoft Office of the CTO who contributed to the development of the Graph RAG approach.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="APURVA MODY">
      <data key="d0">PERSON</data>
      <data key="d1">A researcher at Microsoft Office of the CTO who contributed to the development of the Graph RAG approach.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="STEVEN TRUITT">
      <data key="d0">PERSON</data>
      <data key="d1">A researcher at Microsoft Strategic Missions and Technologies who contributed to the development of the Graph RAG approach.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JONATHAN LARSON">
      <data key="d0">PERSON</data>
      <data key="d1">A researcher at Microsoft Research who contributed to the development of the Graph RAG approach.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LEIDEN">
      <data key="d0">METHOD, TECHNIQUE</data>
      <data key="d1">A community detection method used to partition a graph index into groups of elements that can be summarized in parallel.
A community detection algorithm that improves upon Louvain, used to partition graphs into modular communities</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7</data>
      <data key="d3">METHOD, TECHNIQUE</data>
    </node>
    <node id="SENSEMAKING IN COMPLEX DOMAINS">
      <data key="d0">ACTIVITY, PROCESS</data>
      <data key="d1">The process of automating human-like sensemaking in complex domains like scientific discovery and intelligence analysis using large language models.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">ACTIVITY, PROCESS</data>
    </node>
    <node id="GLOBAL SENSEMAKING QUESTIONS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Questions that require understanding connections and drawing conclusions from large text corpora, often beyond what is explicitly stated in the source texts.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="INDEXING TIME">
      <data key="d0">TIME PERIOD, STAGE</data>
      <data key="d1">The stage in the Graph RAG pipeline where the graph index of source document text is created and partitioned into communities.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">TIME PERIOD, STAGE</data>
    </node>
    <node id="QUERY TIME">
      <data key="d0">TIME PERIOD, STAGE</data>
      <data key="d1">The stage in the Graph RAG pipeline where community summaries are used to generate partial responses to a query, which are then summarized into a final response.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">TIME PERIOD, STAGE</data>
    </node>
    <node id="GRAPH INDEX">
      <data key="d0">DATA STRUCTURE, INDEX</data>
      <data key="d1">An index created by an LLM that spans nodes (e.g., entities), edges (e.g., relationships), and covariates (e.g., claims) detected, extracted, and summarized from source documents.
An index created using generic prompts for entity and relationship extraction, tailored to the domain of the data
An index built using graph structures to support various retrieval-augmented generation approaches and global summarization</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,26b2dad01a219bc034ac7d6a32d07582,ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">DATA STRUCTURE, INDEX</data>
    </node>
    <node id="COMMUNITY SUMMARIES">
      <data key="d0">DATA, OUTPUT</data>
      <data key="d1">Summaries generated for groups of closely-related entities in the graph index, used to generate partial responses to queries.
Community summaries are report-like summaries of each community in a hierarchical graph, used to understand the global structure and semantics of the dataset.
Summaries generated for communities, which are used to generate final answers in a multi-stage process
Summaries of different levels of graph communities (C0, C1, C2, C3) used to answer user queries in the Graph RAG system
Summaries generated at different levels of a graph community hierarchy</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,26b2dad01a219bc034ac7d6a32d07582,4930fce6da868f894757a9da465807ba,e66ed885a08f92cc69f4895302c33047,ede7063998065122cf7a7152979c1909</data>
      <data key="d3">DATA, OUTPUT</data>
    </node>
    <node id="GLOBAL ANSWER">
      <data key="d0">OUTPUT, RESPONSE</data>
      <data key="d1">The final response to a query, produced by summarizing all community summaries that report relevance to the query.
The final answer generated from community summaries in response to a user query</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,4930fce6da868f894757a9da465807ba</data>
      <data key="d3">OUTPUT, RESPONSE</data>
    </node>
    <node id="LOCAL GRAPH RAG">
      <data key="d0">APPROACH, METHOD</data>
      <data key="d1">A variant of the Graph RAG approach that focuses on local regions of text for question answering.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">APPROACH, METHOD</data>
    </node>
    <node id="GLOBAL GRAPH RAG">
      <data key="d0">APPROACH, METHOD</data>
      <data key="d1">A variant of the Graph RAG approach that scales to global questions over large text corpora.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">APPROACH, METHOD</data>
    </node>
    <node id="OPEN-SOURCE IMPLEMENTATION">
      <data key="d0">SOFTWARE, TOOL</data>
      <data key="d1">An open-source, Python-based implementation of both global and local Graph RAG approaches, available at https://aka.ms/graphrag.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">SOFTWARE, TOOL</data>
    </node>
    <node id="TRANSFORMER ARCHITECTURE">
      <data key="d0">TECHNOLOGY, MODEL</data>
      <data key="d1">A type of neural network architecture that has shown substantial improvements in various summarization tasks.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">TECHNOLOGY, MODEL</data>
    </node>
    <node id="GPT">
      <data key="d0">MODEL, TECHNOLOGY</data>
      <data key="d1">A large language model developed by OpenAI, used for various natural language processing tasks including summarization.
A series of large language models developed by OpenAI, known for their ability to generate human-like text</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7</data>
      <data key="d3">MODEL, TECHNOLOGY</data>
    </node>
    <node id="LLAMA">
      <data key="d0">MODEL, TECHNOLOGY</data>
      <data key="d1">A large language model used for natural language processing tasks, including summarization.
A series of large language models developed by Meta, known for their in-context learning capabilities</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7</data>
      <data key="d3">MODEL, TECHNOLOGY</data>
    </node>
    <node id="GEMINI">
      <data key="d0">MODEL, TECHNOLOGY</data>
      <data key="d1">A large language model used for natural language processing tasks, including summarization.
A series of large language models developed by Google, capable of in-context learning and summarization
A family of highly capable multimodal models, as mentioned in the references</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,64476a39d7d8b87b399e3bd3cead79c7,ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">MODEL, TECHNOLOGY</data>
    </node>
    <node id="MICROSOFT">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">A technology company involved in the development of the Graph RAG approach and various other research initiatives.
Microsoft is a technology company that conducted a preliminary study on the impact of large language models on scientific discovery using GPT-4</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d,df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="RANADE AND JOSHI">
      <data key="d0">AUTHORS, RESEARCHERS</data>
      <data key="d1">Researchers who contributed to the study of sensemaking in intelligence analysis.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">AUTHORS, RESEARCHERS</data>
    </node>
    <node id="KLEIN ET AL.">
      <data key="d0">AUTHORS, RESEARCHERS</data>
      <data key="d1">Researchers who defined sensemaking as a motivated, continuous effort to understand connections among people, places, and events.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">AUTHORS, RESEARCHERS</data>
    </node>
    <node id="LEWIS ET AL.">
      <data key="d0">AUTHORS, RESEARCHERS</data>
      <data key="d1">Researchers who contributed to the development of the retrieval-augmented generation (RAG) technique.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">AUTHORS, RESEARCHERS</data>
    </node>
    <node id="DANG">
      <data key="d0">AUTHOR, RESEARCHER</data>
      <data key="d1">A researcher who contributed to the study of query-focused summarization (QFS).</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">AUTHOR, RESEARCHER</data>
    </node>
    <node id="BAUMEL ET AL.">
      <data key="d0">AUTHORS, RESEARCHERS</data>
      <data key="d1">Researchers who contributed to the study of query-focused abstractive summarization.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">AUTHORS, RESEARCHERS</data>
    </node>
    <node id="LASKAR ET AL.">
      <data key="d0">AUTHORS, RESEARCHERS</data>
      <data key="d1">Researchers who contributed to the study of query-focused abstractive summarization.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">AUTHORS, RESEARCHERS</data>
    </node>
    <node id="YAO ET AL.">
      <data key="d0">AUTHORS, RESEARCHERS</data>
      <data key="d1">Researchers who contributed to the study of query-focused abstractive summarization.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">AUTHORS, RESEARCHERS</data>
    </node>
    <node id="GOODWIN ET AL.">
      <data key="d0">AUTHORS, RESEARCHERS</data>
      <data key="d1">Researchers who contributed to the study of summarization tasks using transformer architecture.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">AUTHORS, RESEARCHERS</data>
    </node>
    <node id="LIU AND LAPATA">
      <data key="d0">AUTHORS, RESEARCHERS</data>
      <data key="d1">Researchers who contributed to the study of summarization tasks using transformer architecture.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">AUTHORS, RESEARCHERS</data>
    </node>
    <node id="ACHIAM ET AL.">
      <data key="d0">AUTHORS, RESEARCHERS</data>
      <data key="d1">Researchers who contributed to the development of the GPT model.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">AUTHORS, RESEARCHERS</data>
    </node>
    <node id="BROWN ET AL.">
      <data key="d0">AUTHORS, RESEARCHERS</data>
      <data key="d1">Researchers who contributed to the development of the GPT model.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">AUTHORS, RESEARCHERS</data>
    </node>
    <node id="TOUVRON ET AL.">
      <data key="d0">AUTHORS, RESEARCHERS</data>
      <data key="d1">Researchers who contributed to the development of the Llama model.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">AUTHORS, RESEARCHERS</data>
    </node>
    <node id="ANIL ET AL.">
      <data key="d0">AUTHORS, RESEARCHERS</data>
      <data key="d1">Researchers who contributed to the development of the Gemini model.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
      <data key="d3">AUTHORS, RESEARCHERS</data>
    </node>
    <node id="DARREN EDGE">
      <data key="d0">PERSON</data>
      <data key="d1">A researcher at Microsoft Research who contributed to the development of the Graph RAG approach.</data>
      <data key="d2">0c932f7def033fa2b1bf210fbb771e7d</data>
    </node>
    <node id="LLMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Large Language Models, advanced machine learning models capable of understanding and generating human language</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="IN-CONTEXT LEARNING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A method where models learn to perform tasks by being given examples within the context of the input</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION">
      <data key="d0">TASK</data>
      <data key="d1">A summarization task that focuses on generating summaries based on specific queries over an entire corpus
A method for summarizing text by focusing on the relevance of the query, as discussed by Laskar et al. (2020)</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">TASK</data>
    </node>
    <node id="RAG">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Retrieval-Augmented Generation, a method that combines information retrieval with text generation
Retrieval-Augmented Generation (RAG) is a method that involves retrieving relevant information from external data sources and adding it to the context window of an LLM along with the original query
A skill covered in the synthetic post-training dataset created by AgentInstruct
Retrieval Augmented Generation (RAG) is a technique that enhances the ability of language models to generate informed and contextually precise responses</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,8ee9617c145e19fa95f1f9349bfbe69b,b88745a13b69cecbc0ee9c3af41389bf,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="KNOWLEDGE GRAPH">
      <data key="d0">STRUCTURE</data>
      <data key="d1">A structured representation of knowledge in the form of entities and their relationships, derived from LLMs
A Knowledge Graph is a structured representation of knowledge in the form of entities and their relationships</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">STRUCTURE</data>
    </node>
    <node id="MODULARITY">
      <data key="d0">PROPERTY</data>
      <data key="d1">An inherent quality of graphs that allows them to be partitioned into modular communities of closely-related nodes
The study of the degree to which a network can be divided into smaller, tightly-knit communities, as discussed by Newman (2006)</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PROPERTY</data>
    </node>
    <node id="COMMUNITY DETECTION ALGORITHMS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Algorithms used to partition graphs into modular communities, such as Louvain and Leiden</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="LOUVAIN">
      <data key="d0">ALGORITHM</data>
      <data key="d1">A community detection algorithm used to partition graphs into modular communities</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
      <data key="d3">ALGORITHM</data>
    </node>
    <node id="HOTPOTQA">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset used for evaluating question answering systems, containing diverse and complex questions
A benchmark dataset for open-domain question answering
A dataset for diverse, explainable multi-hop question answering</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,64476a39d7d8b87b399e3bd3cead79c7,d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="GPT-4-TURBO">
      <data key="d0">MODEL</data>
      <data key="d1">An advanced version of the GPT-4 model, used for entity extraction in the described approach
A large language model with a context size of 128k tokens
GPT-4-turbo is a variant of GPT-4 used in the AlpacaEval benchmark to prefer the outputs of the evaluated model over a reference answer</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,64476a39d7d8b87b399e3bd3cead79c7,ede7063998065122cf7a7152979c1909</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="MAP-REDUCE">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A programming model used for processing large data sets with a distributed algorithm</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="PODCAST TRANSCRIPTS">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset containing transcripts of podcast episodes
Compiled transcripts of podcast conversations between Kevin Scott, Microsoft CTO, and other technology leaders
Written records of spoken content from podcasts, often used for analysis and reference</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,64476a39d7d8b87b399e3bd3cead79c7,c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="NEWS ARTICLES">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset containing articles from news sources
A benchmark dataset comprising news articles published from September 2013 to December 2023 in various categories
Articles that cover current events, trends, and public figures, often influencing public opinion and discourse</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,64476a39d7d8b87b399e3bd3cead79c7,c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="COMPREHENSIVENESS">
      <data key="d0">METRIC</data>
      <data key="d1">A quality metric that measures the extent to which a summary covers all relevant information
A metric that measures how much detail an answer provides to cover all aspects and details of the question
A measure of how complete and detailed a response or list is, covering a wide range of aspects and examples
A measure of how complete and thorough the answers are</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7,c8e8019de153e439d6a79dcf209b943b,ede7063998065122cf7a7152979c1909</data>
      <data key="d3">METRIC</data>
    </node>
    <node id="DIVERSITY">
      <data key="d0">METRIC</data>
      <data key="d1">A quality metric that measures the variety of information included in a summary
A metric that measures how varied and rich an answer is in providing different perspectives and insights on the question
A measure of how varied and rich a response or list is, covering different sectors, perspectives, and sources
A measure of how varied and different the answers are</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7,c8e8019de153e439d6a79dcf209b943b,ede7063998065122cf7a7152979c1909</data>
      <data key="d3">METRIC</data>
    </node>
    <node id="EMPOWERMENT">
      <data key="d0">METRIC</data>
      <data key="d1">A quality metric that measures the extent to which a summary enables understanding of broad issues and themes
A metric that measures how well an answer helps the reader understand and make informed judgments about the topic
A measure of how well a response or list helps the reader understand the breadth of a topic and make informed judgments
A measure of how much the answers enable or empower the user
Empowerment in this context refers to the ability of a system to help users reach an informed understanding by providing specific examples, quotes, and citations</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7,c8e8019de153e439d6a79dcf209b943b,edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
      <data key="d3">METRIC</data>
    </node>
    <node id="SOURCE TEXT SUMMARIZATION">
      <data key="d0">TASK</data>
      <data key="d1">The process of creating summaries directly from source texts</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
      <data key="d3">TASK</data>
    </node>
    <node id="TOKEN COSTS">
      <data key="d0">METRIC</data>
      <data key="d1">A measure of the computational cost associated with processing text, often related to the number of tokens used</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
      <data key="d3">METRIC</data>
    </node>
    <node id="TEXT CHUNKS">
      <data key="d0">DATA UNIT</data>
      <data key="d1">Segments of text extracted from source documents for processing
</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7</data>
      <data key="d3">DATA UNIT</data>
    </node>
    <node id="ENTITY EXTRACTION">
      <data key="d0">TASK</data>
      <data key="d1">The process of identifying and extracting entities from text</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
      <data key="d3">TASK</data>
    </node>
    <node id="ELEMENT INSTANCES">
      <data key="d0">DATA UNIT</data>
      <data key="d1">Instances of graph nodes and edges identified and extracted from text chunks
Element instances refer to individual occurrences of entities, relationships, and claims represented in source texts.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">DATA UNIT</data>
    </node>
    <node id="FEW-SHOT EXAMPLES">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Examples provided to a model to help it learn a task with minimal training data</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="NAMED ENTITIES">
      <data key="d0">CATEGORY</data>
      <data key="d1">Entities such as people, places, and organizations that are identified in text
Named entities refer to specific categories of information such as people, places, and organizations that are extracted from text.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">CATEGORY</data>
    </node>
    <node id="COVARIATES">
      <data key="d0">ATTRIBUTE</data>
      <data key="d1">Additional variables associated with extracted node instances
Covariates are additional variables that are associated with the extracted node instances, such as claims linked to detected entities.</data>
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7,e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">ATTRIBUTE</data>
    </node>
    <node id="SUMMARIZATION TASKS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="DATASET">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="MODEL">
      <data key="d0" />
      <data key="d1">
A system or algorithm designed to perform specific tasks, such as evaluating answers or generating text
A machine learning system trained to perform specific tasks, such as generating text or evaluating responses</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,103d98395c393552cc954c89d4e59f50,64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="METRIC">
      <data key="d0" />
      <data key="d1">
A standard of measurement used to evaluate the quality of generated answers, including comprehensiveness, diversity, empowerment, and directness</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="DATA UNIT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="TASK">
      <data key="d0" />
      <data key="d1">
A specific activity or job that a user performs with the dataset, such as generating questions</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="TECHNIQUE">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="CATEGORY">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="ATTRIBUTE">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">64476a39d7d8b87b399e3bd3cead79c7</data>
    </node>
    <node id="LOGIT BIAS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Logit bias is a method used to influence the output of a language model by adjusting the probabilities of certain tokens.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="ELEMENT SUMMARIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Element summaries are descriptive texts created by summarizing multiple instances of entities, relationships, and claims.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="ENTITY GRAPH">
      <data key="d0">CONCEPT</data>
      <data key="d1">An entity graph is a structured representation of entities and their relationships, often used for knowledge representation and reasoning.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="LEIDEN ALGORITHM">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The Leiden algorithm is a method for detecting hierarchical community structures in large-scale graphs efficiently.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="GRAPH COMMUNITIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Graph communities are groups of nodes in a graph that have stronger connections to each other than to nodes in other communities.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="OPENORD">
      <data key="d0">TOOL</data>
      <data key="d1">OpenORD is a tool used for node layout in graph visualization, helping to arrange nodes in a visually meaningful way.
An open-source toolbox for large graph layout, as discussed by Martin et al. (2011)</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88,e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">TOOL</data>
    </node>
    <node id="FORCE ATLAS 2">
      <data key="d0">TOOL</data>
      <data key="d1">Force Atlas 2 is a tool used for node layout in graph visualization, helping to arrange nodes based on their connections and relationships.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
      <data key="d3">TOOL</data>
    </node>
    <node id="LLM">
      <data key="d0" />
      <data key="d1">
Large Language Model used for generating community summaries and answers
Large Language Model, a type of advanced machine learning model trained on vast amounts of text data to understand and generate human language
Large Language Models used for generating assessments and evaluations of different systems
Large Language Models (LLMs) are advanced machine learning models trained on vast amounts of text data to understand and generate human language
Large Language Models (LLMs) are advanced machine learning models trained on vast amounts of text data to understand and generate human language
Large Language Models used to hypothesize other APIs present in a library</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,427e98b00e49b6a8f8649054122dd45b,4930fce6da868f894757a9da465807ba,c8e8019de153e439d6a79dcf209b943b,e66ed885a08f92cc69f4895302c33047,edab4014b8f55e5b25bd7f396314be1f,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="MULTIHOP-RAG">
      <data key="d0">DATASET</data>
      <data key="d1">MultiHop-RAG is a dataset used for benchmarking retrieval-augmented generation for multi-hop queries.
A system for retrieval-augmented generation used in the context of news articles
A system for benchmarking retrieval-augmented generation for multi-hop queries, as described in the arXiv preprint arXiv:2401.15391</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,d4c8ce26fd0f9a7bc6dad0efa1ce98e3,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="CLAIMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Claims are statements or assertions linked to detected entities, often including details such as subject, object, type, description, source text span, and dates.
Statements or assertions that are made about a topic, often supported by evidence and analysis</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="HIERARCHICAL COMMUNITY STRUCTURE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Hierarchical community structure refers to the organization of graph communities in a multi-level hierarchy, where each level represents a different granularity of community partitioning.</data>
      <data key="d2">e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="GLOBAL SUMMARIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Global summarization is the process of creating comprehensive summaries that capture the overall structure and key information of a dataset or graph.
A method for summarizing source texts without using graph structures, mentioned as performing competitively against graph-based methods</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8,e66ed885a08f92cc69f4895302c33047</data>
    </node>
    <node id="LEAF-LEVEL COMMUNITIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Communities at the leaf level where element summaries (nodes, edges, covariates) are prioritized and added to the LLM context window until the token limit is reached</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="HIGHER-LEVEL COMMUNITIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Communities at a higher level where element summaries are summarized within the community, and sub-communities are ranked and substituted to fit within the context window</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="USER QUERY">
      <data key="d0">CONCEPT</data>
      <data key="d1">A question posed by the user that the system aims to answer using community summaries</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="COMMUNITY ANSWERS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Intermediate answers generated from community summaries, which are then used to form the global answer</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="TOKEN LIMIT">
      <data key="d0">CONSTRAINT</data>
      <data key="d1">The maximum number of tokens that can be included in the LLM context window</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">CONSTRAINT</data>
    </node>
    <node id="TECH JOURNALIST">
      <data key="d0">USER</data>
      <data key="d1">A user looking for insights and trends in the tech industry</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">USER</data>
    </node>
    <node id="EDUCATOR">
      <data key="d0">USER</data>
      <data key="d1">A user incorporating current affairs into curricula</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">USER</data>
    </node>
    <node id="TECH POLICY">
      <data key="d0">TOPIC</data>
      <data key="d1">The role of policy and regulation in the tech industry</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">TOPIC</data>
    </node>
    <node id="GOVERNMENT REGULATION">
      <data key="d0">TOPIC</data>
      <data key="d1">Government rules and laws affecting the tech industry</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">TOPIC</data>
    </node>
    <node id="PRIVACY LAWS">
      <data key="d0">TOPIC</data>
      <data key="d1">Laws related to the protection of personal information and privacy</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">TOPIC</data>
    </node>
    <node id="INNOVATION">
      <data key="d0">TOPIC</data>
      <data key="d1">The process of creating new technologies and ideas</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">TOPIC</data>
    </node>
    <node id="ETHICAL CONSIDERATIONS">
      <data key="d0">TOPIC</data>
      <data key="d1">Moral principles that affect decision-making in technology development</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">TOPIC</data>
    </node>
    <node id="COLLABORATIONS">
      <data key="d0">TOPIC</data>
      <data key="d1">Partnerships between tech companies and governments</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">TOPIC</data>
    </node>
    <node id="HEALTH EDUCATION">
      <data key="d0">TOPIC</data>
      <data key="d1">Teaching about health and wellness</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">TOPIC</data>
    </node>
    <node id="PREVENTIVE MEDICINE">
      <data key="d0">TOPIC</data>
      <data key="d1">Medical practices aimed at preventing diseases</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">TOPIC</data>
    </node>
    <node id="WELLNESS">
      <data key="d0">TOPIC</data>
      <data key="d1">The state of being in good health</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">TOPIC</data>
    </node>
    <node id="PUBLIC HEALTH">
      <data key="d0">TOPIC</data>
      <data key="d1">The health of the population as a whole</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">TOPIC</data>
    </node>
    <node id="HEALTH LITERACY">
      <data key="d0">TOPIC</data>
      <data key="d1">The ability to understand and use health information</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">TOPIC</data>
    </node>
    <node id="MT-BENCH">
      <data key="d0">DATASET</data>
      <data key="d1">A benchmark dataset for open-domain question answering
A benchmark used to evaluate the performance of various models, with Orca-3 scoring 8.20
MT-Bench is a benchmark designed to assess the competence of chat assistants in multi-turn conversations using GPT-4 as the evaluator.
A system for benchmarking, as described by Lm-sys in 2023
A benchmark consisting of a first-turn query and a second-turn query independent of the evaluated model&#8217;s response, judged by GPT-4 to provide a score from 1 to 10</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,3d1f6634f93f8a4c296dc8df7e59859e,4930fce6da868f894757a9da465807ba,86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="RAG SYSTEMS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Retrieval-augmented generation systems used for answering questions and summarizing data</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="DATA SENSEMAKING">
      <data key="d0">PROCESS</data>
      <data key="d1">The process through which people inspect, engage with, and contextualize data within the broader scope of real-world activities
The behaviors and processes involved in understanding and interpreting data, as discussed by Koesten et al. in 2021The behaviors and processes involved in understanding and interpreting data, as discussed by Koesten et al. in 2021)("relationship"</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">PROCESS</data>
    </node>
    <node id="LATENT SUMMARIZATION QUERIES">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Methods for extracting summarization queries from source texts</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="KEVIN SCOTT">
      <data key="d0">PERSON</data>
      <data key="d1">Microsoft CTO who participates in podcast conversations</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KOESTEN ET AL.">
      <data key="d0">AUTHORS</data>
      <data key="d1">Researchers who discussed the process of data sensemaking in 2021</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">AUTHORS</data>
    </node>
    <node id="XU AND LAPATA">
      <data key="d0">AUTHORS</data>
      <data key="d1">Researchers who discussed methods for extracting latent summarization queries in 2021</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">AUTHORS</data>
    </node>
    <node id="TANG AND YANG">
      <data key="d0">AUTHORS</data>
      <data key="d1">Researchers who discussed the MultiHop-RAG system in 2024</data>
      <data key="d2">4930fce6da868f894757a9da465807ba</data>
      <data key="d3">AUTHORS</data>
    </node>
    <node id="ZHENG ET AL.">
      <data key="d0">AUTHORS</data>
      <data key="d1">Researchers who discussed the MT-Bench dataset in 2024
Authors who contributed to the research on head-to-head comparison of competing outputs using LLMs</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,4930fce6da868f894757a9da465807ba</data>
      <data key="d3">AUTHORS</data>
    </node>
    <node id="BEHIND THE TECH">
      <data key="d0">PODCAST</data>
      <data key="d1">A podcast featuring conversations between Kevin Scott and other technology leaders
A series by Microsoft that explores the impact of technology and the people behind it</data>
      <data key="d2">4930fce6da868f894757a9da465807ba,df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PODCAST</data>
    </node>
    <node id="USER">
      <data key="d0">ACTOR</data>
      <data key="d1">An individual who interacts with the dataset, performing various tasks and generating questions
The individual who interacts with the AI assistant to achieve specific goals, such as creating a meal plan, tracking meals, and updating food items</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,26b2dad01a219bc034ac7d6a32d07582</data>
      <data key="d3">ACTOR</data>
    </node>
    <node id="QUESTION">
      <data key="d0">OUTPUT</data>
      <data key="d1">A query generated by the LLM based on the dataset and user-task combinations
A problem or query presented to the student for which they need to provide an answer</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,26b2dad01a219bc034ac7d6a32d07582</data>
      <data key="d3">OUTPUT</data>
    </node>
    <node id="TEXT SUMMARIZATION (TS)">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A method that applies a map-reduce approach directly to source texts for summarization</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="SEMANTIC SEARCH (SS)">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A naive retrieval-augmented generation approach where text chunks are retrieved and added to the context window until the token limit is reached</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="CONTEXT WINDOW">
      <data key="d0">PARAMETER</data>
      <data key="d1">The size of the text context used for generating answers in the retrieval-augmented generation systems</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="PODCAST DATASET">
      <data key="d0">DATA</data>
      <data key="d1">A specific dataset used in the evaluation, consisting of podcast-related data
A dataset consisting of podcast transcripts used for testing the models</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
      <data key="d3">DATA</data>
    </node>
    <node id="NEWS DATASET">
      <data key="d0">DATA</data>
      <data key="d1">A specific dataset used in the evaluation, consisting of news-related data
A dataset consisting of news articles used for testing the models</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
      <data key="d3">DATA</data>
    </node>
    <node id="DIRECTNESS">
      <data key="d0">METRIC</data>
      <data key="d1">A control metric that measures how specifically and clearly an answer addresses the question
A measure of how concise and specific a response or list is, directly addressing the question with clear examples
A measure of how straightforward and direct the answers are</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,c8e8019de153e439d6a79dcf209b943b,ede7063998065122cf7a7152979c1909</data>
      <data key="d3">METRIC</data>
    </node>
    <node id="LLM EVALUATOR">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A large language model used to evaluate the quality of generated answers based on specific metrics</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="PUBLIC FIGURES">
      <data key="d0">ENTITY</data>
      <data key="d1">Individuals who are repeatedly mentioned across various entertainment articles, reflecting their impact and presence within the industry</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
      <data key="d3">ENTITY</data>
    </node>
    <node id="ENTERTAINMENT ARTICLES">
      <data key="d0">DATA</data>
      <data key="d1">Articles related to the entertainment industry, encompassing film, television, music, sports, and digital media
Articles that cover various aspects of the entertainment industry, including news about public figures, trends, and controversies</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">DATA</data>
    </node>
    <node id="SOURCE TEXTS">
      <data key="d0" />
      <data key="d1">
The original texts from which summaries are generated</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="ANSWER GENERATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="EVALUATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="GLEANING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A method used in the graph indexing process to extract relevant information from the dataset</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="RAGAS">
      <data key="d0">SYSTEM</data>
      <data key="d1">A system for automatically evaluating the performance of retrieval-augmented generation systems
Automated evaluation system for retrieval-augmented generation, as described by Es, James, Espinosa-Anke, and Schockaert in 2023</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="WANG ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Authors who contributed to the research on evaluating natural language generation using LLMs</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="ES ET AL.">
      <data key="d0">PERSON</data>
      <data key="d1">Authors who contributed to the research on automatically evaluating qualities like context relevance, faithfulness, and answer relevance in RAG systems</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582</data>
    </node>
    <node id="RETRIEVAL-AUGMENTED GENERATION">
      <data key="d0" />
      <data key="d1">
A method that combines information retrieval with text generation to improve the quality and relevance of generated content, as surveyed by Gao et al. in 2023
A method that combines information retrieval with text generation to improve the quality and relevance of generated content, as discussed by Lewis et al. (2020)
A method that combines information retrieval with text generation to improve the quality and relevance of generated content</data>
      <data key="d2">26b2dad01a219bc034ac7d6a32d07582,aa79049289e6532592eec17b9e76adfb,d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="PUBLIC FIGURES IN CONTROVERSY">
      <data key="d0">CATEGORY</data>
      <data key="d1">Individuals who are frequently involved in public controversies, often covered in entertainment articles</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CATEGORY</data>
    </node>
    <node id="MUSICIANS">
      <data key="d0">PROFESSION</data>
      <data key="d1">Individuals who create, perform, and produce music</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">PROFESSION</data>
    </node>
    <node id="EXECUTIVES">
      <data key="d0">PROFESSION</data>
      <data key="d1">Individuals who hold high-level management positions in companies, particularly in the entertainment industry</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">PROFESSION</data>
    </node>
    <node id="ATHLETES">
      <data key="d0">PROFESSION</data>
      <data key="d1">Individuals who compete in sports at a professional level</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">PROFESSION</data>
    </node>
    <node id="COACHES">
      <data key="d0">PROFESSION</data>
      <data key="d1">Individuals who train and guide athletes or sports teams</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">PROFESSION</data>
    </node>
    <node id="INFLUENCERS">
      <data key="d0">PROFESSION</data>
      <data key="d1">Individuals who have the power to affect the purchasing decisions of others because of their authority, knowledge, position, or relationship with their audience</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">PROFESSION</data>
    </node>
    <node id="ENTREPRENEURS">
      <data key="d0">PROFESSION</data>
      <data key="d1">Individuals who start and run businesses, often in innovative or high-risk sectors</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">PROFESSION</data>
    </node>
    <node id="TAYLOR SWIFT">
      <data key="d0">PERSON</data>
      <data key="d1">A highly influential musician known for her contributions to the music industry and her high-profile personal life</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="TRAVIS KELCE">
      <data key="d0">PERSON</data>
      <data key="d1">A professional athlete known for his achievements in sports and his high-profile personal life</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BRITNEY SPEARS">
      <data key="d0">PERSON</data>
      <data key="d1">A highly influential musician known for her contributions to the music industry and her high-profile personal life</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JUSTIN TIMBERLAKE">
      <data key="d0">PERSON</data>
      <data key="d1">A highly influential musician and actor known for his contributions to the entertainment industry and his high-profile personal life</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CULTURAL NARRATIVES">
      <data key="d0">CONCEPT</data>
      <data key="d1">The stories and ideas that shape the cultural understanding and values of a society, often influenced by media and public figures</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="FILM">
      <data key="d0">MEDIA</data>
      <data key="d1">A form of visual storytelling that involves the production and distribution of movies</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">MEDIA</data>
    </node>
    <node id="TELEVISION">
      <data key="d0">MEDIA</data>
      <data key="d1">A form of visual storytelling that involves the production and distribution of TV shows</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">MEDIA</data>
    </node>
    <node id="MUSIC">
      <data key="d0">MEDIA</data>
      <data key="d1">A form of auditory art that involves the creation, performance, and distribution of songs and compositions</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">MEDIA</data>
    </node>
    <node id="DIGITAL MEDIA">
      <data key="d0">MEDIA</data>
      <data key="d1">Content that is created, distributed, and consumed through digital platforms, including social media, websites, and streaming services</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">MEDIA</data>
    </node>
    <node id="SOCIAL DISCUSSIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Public conversations and debates that occur in society, often influenced by media coverage and public figures</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="PUBLIC DISCOURSE">
      <data key="d0">CONCEPT</data>
      <data key="d1">The exchange of ideas and opinions in the public sphere, often influenced by media and public figures</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="MEDIA COVERAGE">
      <data key="d0">CONCEPT</data>
      <data key="d1">The reporting and analysis of events, trends, and public figures by various media outlets</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="PROFESSIONAL ACHIEVEMENTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">The accomplishments and successes that individuals achieve in their professional careers</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="PERSONAL LIVES">
      <data key="d0">CONCEPT</data>
      <data key="d1">The private aspects of individuals' lives, often covered by media when it involves public figures</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="CULTURAL IMPACT">
      <data key="d0">CONCEPT</data>
      <data key="d1">The influence that individuals, media, and events have on the cultural values, norms, and practices of a society</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="ECONOMIC IMPACT">
      <data key="d0">CONCEPT</data>
      <data key="d1">The effect that individuals, media, and events have on the economy, including financial markets, consumer behavior, and industry trends</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="NAIVE RAG">
      <data key="d0">SYSTEM</data>
      <data key="d1">A system that provides concise and specific lists of public figures, focusing on their frequent mentions in entertainment articles</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">SYSTEM</data>
    </node>
    <node id="DECISION">
      <data key="d0">CONCEPT</data>
      <data key="d1">The process of making a choice between different options, often based on evaluations and assessments</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="DATA REPORTS">
      <data key="d0">MEDIA</data>
      <data key="d1">Documents that provide detailed information and analysis on various topics, often used as evidence to support claims</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">MEDIA</data>
    </node>
    <node id="ENTERTAINMENT INDUSTRY">
      <data key="d0">SECTOR</data>
      <data key="d1">The sector that includes film, television, music, sports, gaming, and digital media, involving the production and distribution of entertainment content</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">SECTOR</data>
    </node>
    <node id="GAMING">
      <data key="d0">MEDIA</data>
      <data key="d1">A form of interactive entertainment that involves playing video games</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">MEDIA</data>
    </node>
    <node id="TRENDS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Patterns or movements in society, culture, or industry that indicate a general direction of change or development</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="CONTROVERSIES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Public disputes or debates that arise from differing opinions, often involving public figures and media coverage</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="IMPLICATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">The possible effects or consequences of an event, action, or decision, often discussed in media and public discourse</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="PERSPECTIVES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Different viewpoints or angles from which a topic can be understood or analyzed</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="INSIGHTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Deep understanding or knowledge about a topic, often gained through analysis and evaluation</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="EVIDENCE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Information or data that supports a claim or argument, often used in media and academic writing</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="JUDGMENTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Decisions or conclusions that are made based on evaluations and assessments</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="INFORMED JUDGMENTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Decisions or conclusions that are made based on comprehensive and well-supported information</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="MISLED">
      <data key="d0">CONCEPT</data>
      <data key="d1">Being given incorrect or misleading information, often resulting in incorrect judgments or decisions</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="BREADTH">
      <data key="d0">CONCEPT</data>
      <data key="d1">The wide scope or range of a topic, covering various aspects and examples</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="DEPTH">
      <data key="d0">CONCEPT</data>
      <data key="d1">The detailed and thorough coverage of a topic, providing in-depth analysis and understanding</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="VARIETY">
      <data key="d0">CONCEPT</data>
      <data key="d1">The inclusion of different elements, perspectives, or examples in a response or list</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="SPECIFICITY">
      <data key="d0">CONCEPT</data>
      <data key="d1">The quality of being clear and precise, providing specific examples and details</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="CONCISENESS">
      <data key="d0">CONCEPT</data>
      <data key="d1">The quality of being brief and to the point, providing information in a clear and succinct manner</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="SECTORS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Different areas or divisions within an industry or field, such as film, television, music, sports, and digital media</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="CONTRIBUTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">The actions or efforts made by individuals that add value or impact to their field or society</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="IMPACT">
      <data key="d0">CONCEPT</data>
      <data key="d1">The effect or influence that an event, action, or individual has on a field, society, or culture</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="CONTEXT">
      <data key="d0">CONCEPT</data>
      <data key="d1">The circumstances or background information that help to understand a topic or event</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="DATA SOURCES">
      <data key="d0">CONCEPT</data>
      <data key="d1">The origins of information or data used to support claims and analysis</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="EVIDENCE TO SUPPORT CLAIMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Information or data that is used to back up statements or assertions</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="PERSPECTIVES AND INSIGHTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Different viewpoints and deep understanding about a topic, often gained through analysis and evaluation</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="SINGLE SOURCE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Relying on one origin of information or data, which may limit the diversity of perspectives and insights</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="BROAD UNDERSTANDING">
      <data key="d0">CONCEPT</data>
      <data key="d1">A wide and comprehensive grasp of a topic, covering various aspects and examples</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="SPECIFIC EXAMPLES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Clear and precise instances or cases that illustrate a point or concept</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="CONTRIBUTIONS AND IMPACTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">The actions or efforts made by individuals and their effects on their field or society</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="FREQUENT MENTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">The repeated appearance or reference to individuals or topics in media or discussions</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="CONCISE EXPLANATIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Brief and clear descriptions that provide essential information</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="DETAILED INFORMATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">Comprehensive and thorough data or descriptions that provide in-depth understanding</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="ENTERTAINMENT SECTORS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Different areas within the entertainment industry, such as film, television, music, sports, gaming, and digital media</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="SPECIFIC DATA SOURCES">
      <data key="d0">CONCEPT</data>
      <data key="d1">Particular origins of information or data used to support claims and analysis</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="VARIED AND RICH RESPONSE">
      <data key="d0">CONCEPT</data>
      <data key="d1">A reply that includes a wide range of elements, perspectives, and examples</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="WIDE RANGE OF PUBLIC FIGURES">
      <data key="d0">CONCEPT</data>
      <data key="d1">A diverse group of individuals from different sectors of the entertainment industry</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="CONTRIBUTIONS AND INFLUENCE">
      <data key="d0">CONCEPT</data>
      <data key="d1">The actions or efforts made by individuals and their effects on their field or society</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="CONTROVERSIES AND IMPACT">
      <data key="d0">CONCEPT</data>
      <data key="d1">Public disputes or debates and their effects on society and public discourse</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="PUBLIC DISCOURSE AND IMPACT">
      <data key="d0">CONCEPT</data>
      <data key="d1">The exchange of ideas and opinions in the public sphere and its effects on society</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="BROAD SPECTRUM OF PROFESSIONAL INFLUENCE">
      <data key="d0">CONCEPT</data>
      <data key="d1">The wide range of effects that individuals have in their professional fields</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="PERSONAL LIVES AND RELATIONSHIPS">
      <data key="d0">CONCEPT</data>
      <data key="d1">The private aspects of individuals' lives and their interactions with others, often covered by media</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="BREADTH OF THE TOPIC">
      <data key="d0">CONCEPT</data>
      <data key="d1">The wide scope or range of a subject, covering various aspects and examples</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="INFORMED JUDGMENTS AND UNDERSTANDING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Decisions or conclusions that are made based on comprehensive and well-supported informationDecisions or conclusions that are made based on comprehensive and well-supported information, providing a sound basis for the choice and a deeper grasp of the subject</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="MISLED AND INCORRECT JUDGMENTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Being given incorrect or misleading information, resulting in incorrect decisions or conclusions</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="BREADTH AND VARIETY">
      <data key="d0">CONCEPT</data>
      <data key="d1">The wide scope and range of elements, perspectives, or examples in a response or list, providing a comprehensive understandingThe wide scope and range of elements, perspectives, or examples in a response or list</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="DEPTH AND VARIETY">
      <data key="d0">CONCEPT</data>
      <data key="d1">The detailed and thorough coverage of a topic, providing in-depth analysis and understanding, along with a range of elements and perspectives</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="VARIETY AND PERSPECTIVES">
      <data key="d0">CONCEPT</data>
      <data key="d1">The inclusion of different elements, viewpoints, or angles in a response or list</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="SPECIFICITY AND CONCISENESS">
      <data key="d0">CONCEPT</data>
      <data key="d1">The quality of being clear and precise, providing specific examples and details in a brief and to-the-point manner</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="CONCISENESS AND SPECIFICITY">
      <data key="d0">CONCEPT</data>
      <data key="d1">The quality of being brief and to the point, providing clear and precise examples and details</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="SECTORS AND CONTRIBUTIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Different areas within an industry or field and the actions or efforts made by individuals that add value or impact</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="CONTRIBUTIONS AND IMPACT">
      <data key="d0">CONCEPT</data>
      <data key="d1">The actions or efforts made by individuals and their effects on their field or society</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="CONTEXT AND UNDERSTANDING">
      <data key="d0">CONCEPT</data>
      <data key="d1">The circumstances or background information that help to understand a topic or event, providing a deeper grasp of the subject</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="DATA SOURCES AND EVIDENCE">
      <data key="d0">CONCEPT</data>
      <data key="d1">The origins of information or data used to support claims and analysis, providing proof or backing for statements</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="EVIDENCE AND CLAIMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Information or data that supports a statement or assertion, providing proof or backing for the argument</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="JUDGMENTS AND DECISIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Decisions or conclusions that are made based on evaluations and assessments, often influenced by evidence and analysis</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="INFORMED JUDGMENTS AND DECISIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Decisions or conclusions that are made based on comprehensive and well-supported information, providing a sound basis for the choice</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="MISLED AND INCORRECT DECISIONS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Being given incorrect or misleading information, resulting in incorrect judgments or conclusions</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="BREADTH AND DEPTH">
      <data key="d0">CONCEPT</data>
      <data key="d1">The wide scope and detailed coverage of a topic, providing a comprehensive and thorough understanding</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="VARIETY AND DEPTH">
      <data key="d0">CONCEPT</data>
      <data key="d1">The inclusion of different elements and detailed coverage of a topic, providing a comprehensive and thorough understanding</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="SPECIFICITY AND EXAMPLES">
      <data key="d0">CONCEPT</data>
      <data key="d1">The quality of being clear and precise, providing specific instances or cases that illustrate a point or concept</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="CONCISENESS AND EXAMPLES">
      <data key="d0">CONCEPT</data>
      <data key="d1">The quality of being brief and to the point, providing clear and precise instances or cases that illustrate a point or concept</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="SECTORS AND IMPACT">
      <data key="d0">CONCEPT</data>
      <data key="d1">Different areas within an industry or field and the effects or influence that individuals, media, and events have on the field or society</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="CONTRIBUTIONS AND CONTEXT">
      <data key="d0">CONCEPT</data>
      <data key="d1">The actions or efforts made by individuals and the circumstances or background information that help to understand their impact</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="IMPACT AND CONTEXT">
      <data key="d0">CONCEPT</data>
      <data key="d1">The effects or influence that individuals, media, and events have on a field or society, and the circumstances or background information that help to understand these effects</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="DATA SOURCES AND CLAIMS">
      <data key="d0">CONCEPT</data>
      <data key="d1">The origins of information or data used to support statements or assertions, providing proof or backing for the argument</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="EVIDENCE AND JUDGMENTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">Information or data that supports a statement or assertion, providing proof or backing for decisions or conclusions</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="JUDGMENTS AND UNDERSTANDING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Decisions or conclusions that are made based on evaluations and assessments, providing a deeper grasp of the subject</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="MISLED AND INCORRECT UNDERSTANDING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Being given incorrect or misleading information, resulting in incorrect judgments or conclusions and a flawed grasp of the subject</data>
      <data key="d2">c8e8019de153e439d6a79dcf209b943b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="NA&#207;VE RAG">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A basic retrieval-augmented generation approach that does not use graph-based methods
Na&#239;ve RAG is a basic retrieval-augmented generation approach that converts documents to text, splits text into chunks, and embeds these chunks into a vector space for retrieval</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="CONTEXT WINDOW SIZE">
      <data key="d0">PARAMETER</data>
      <data key="d1">The size of the context window used in the model, tested at 8k, 16k, 32k, and 64k tokens</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
      <data key="d3">PARAMETER</data>
    </node>
    <node id="KURATOV ET AL., 2024">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a study by Kuratov and colleagues in 2024</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="LIU ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a study by Liu and colleagues in 2023</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="MAP-REDUCE SUMMARIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A summarization approach that is resource-intensive and requires a high number of context tokens
A summarization method that uses map-reduce operations to summarize source texts, mentioned as a global but graph-free approach</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="GLOBAL TEXT SUMMARIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A summarization approach that does not use a graph index</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="BASELINE CONDITION (SS)">
      <data key="d0">PARAMETER</data>
      <data key="d1">The baseline condition used for testing, referred to as SS</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C0">
      <data key="d0">PARAMETER</data>
      <data key="d1">Root-level community summaries in the graph community hierarchy
A reference to root-level community summaries in the context of Graph RAG</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C1">
      <data key="d0">PARAMETER</data>
      <data key="d1">Intermediate-level community summaries in the graph community hierarchy</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C2">
      <data key="d0">PARAMETER</data>
      <data key="d1">Intermediate-level community summaries in the graph community hierarchy</data>
      <data key="d2">ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="C3">
      <data key="d0">PARAMETER</data>
      <data key="d1">Low-level community summaries in the graph community hierarchy
A reference to low-level community summaries in the context of Graph RAG</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </node>
    <node id="MODULAR RAG">
      <data key="d0">SYSTEM</data>
      <data key="d1">Modular RAG systems include patterns for iterative and dynamic cycles of interleaved retrieval and generation to overcome the drawbacks of Na&#239;ve RAG</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="SELF-MEMORY">
      <data key="d0">CONCEPT</data>
      <data key="d1">Self-memory is a concept related to generation-augmented retrieval, facilitating future generation cycles by retaining information from previous interactions
</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="GENERATION-AUGMENTED RETRIEVAL">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Generation-Augmented Retrieval (GAR) is a method that combines retrieval and generation processes to improve the quality of responses
A method that combines text generation with information retrieval to improve the quality of answers in open-domain question answering, as discussed by Mao et al. (2020)</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="ITERATIVE RETRIEVAL-GENERATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Iterative Retrieval-Generation (Iter-RetGen) is a strategy that involves multiple cycles of retrieval and generation to refine responses</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="FEDERATED RETRIEVAL-GENERATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Federated Retrieval-Generation (FeB4RAG) is a strategy that involves parallel generation of community answers from summaries</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="MULTI-DOCUMENT SUMMARIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Multi-Document Summarization is a method that combines information from multiple documents to create a comprehensive summary</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="MULTI-HOP QUESTION ANSWERING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Multi-Hop Question Answering is a method that involves answering questions by retrieving and integrating information from multiple sources</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="HIERARCHICAL INDEX">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Hierarchical Indexing involves generating a hierarchical structure of text chunks by clustering the vectors of text embeddings</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="TREE OF CLARIFICATIONS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Tree of Clarifications is a method for generating multiple interpretations of ambiguous questions and answering them
A system for answering ambiguous questions using retrieval-augmented large language models, as described by Kim et al. in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="CAUSAL GRAPHS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Causal Graphs are graphical representations that show causal relationships between variables</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="KAPING">
      <data key="d0">SYSTEM</data>
      <data key="d1">An advanced RAG system where the index is a knowledge graphKAPING is an advanced RAG system where the index is a knowledge graph</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SYSTEM</data>
    </node>
    <node id="G-RETRIEVER">
      <data key="d0">SYSTEM</data>
      <data key="d1">G-Retriever is a system where subsets of the graph structure are the objects of enquiryA system where subsets of the graph structure are the objects of enquiry
A system for retrieval-augmented generation for textual graph understanding and question answering, as described by He et al. in 2024</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SYSTEM</data>
    </node>
    <node id="GRAPH-TOOLFORMER">
      <data key="d0">SYSTEM</data>
      <data key="d1">A system where derived graph metrics are the objects of enquiryGraph-ToolFormer is a system where derived graph metrics are the objects of enquiry
A system designed to empower large language models with graph reasoning ability via prompt augmented by ChatGPT</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SYSTEM</data>
    </node>
    <node id="SURGE">
      <data key="d0">SYSTEM</data>
      <data key="d1">A system where narrative outputs are strongly grounded in the facts of retrieved subgraphsSURGE is a system where narrative outputs are strongly grounded in the facts of retrieved subgraphs</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SYSTEM</data>
    </node>
    <node id="FABULA">
      <data key="d0">SYSTEM</data>
      <data key="d1">A system where retrieved event-plot subgraphs are serialized using narrative templatesFABULA is a system where retrieved event-plot subgraphs are serialized using narrative templates
A system for intelligence report generation using retrieval-augmented narrative construction, as discussed by Ranade and Joshi (2023)</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SYSTEM</data>
    </node>
    <node id="ITRG">
      <data key="d0">SYSTEM</data>
      <data key="d1">ITRG is a system that supports both creation and traversal of text-relationship graphs for multi-hop question answeringA system that supports both creation and traversal of text-relationship graphs for multi-hop question answering</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SYSTEM</data>
    </node>
    <node id="LANGCHAIN">
      <data key="d0">SOFTWARE</data>
      <data key="d1">A library that supports various graph databases for graph-based RAG applicationsLangChain is a library that supports various graph databases for graph-based RAG applications
LangChain is a framework for building applications with large language models, including graph-based use cases</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SOFTWARE</data>
    </node>
    <node id="LLAMAINDEX">
      <data key="d0">SOFTWARE</data>
      <data key="d1">A library that supports various graph databases for graph-based RAG applicationsLlamaIndex is a library that supports various graph databases for graph-based RAG applications
LlamaIndex is a framework for building knowledge graphs and other structured data representations</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SOFTWARE</data>
    </node>
    <node id="NEO4J">
      <data key="d0">SOFTWARE</data>
      <data key="d1">Neo4J is a graph database supported by LangChain and LlamaIndex for creating and reasoning over knowledge graphsA graph database supported by LangChain and LlamaIndex for creating and reasoning over knowledge graphs
A graph database management system that is used for creating and managing knowledge graphs
Neo4j is a graph database technology that developed Project NaLLM</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8,df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SOFTWARE</data>
    </node>
    <node id="NEBULAGRAPH">
      <data key="d0">SOFTWARE</data>
      <data key="d1">A graph database supported by LangChain and LlamaIndex for creating and reasoning over knowledge graphsNebulaGraph is a graph database supported by LangChain and LlamaIndex for creating and reasoning over knowledge graphs
A graph database management system that supports the creation and management of knowledge graphs
NebulaGraph is a graph database technology that launched an industry-first graph RAG (retrieval-augmented generation) with LLM based on knowledge graphs</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8,df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">SOFTWARE</data>
    </node>
    <node id="GRAPH RAG INDEX">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A self-generated graph index used in Graph RAG for partitioning data for global summarizationGraph RAG Index is a self-generated graph index used in Graph RAG for partitioning data for global summarization</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="RAM ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a work by Ram et al. in 2023 related to RAG approaches</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="GAO ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a work by Gao et al. in 2023 related to Na&#239;ve RAG and advanced RAG systems</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="CHENG ET AL., 2024">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a work by Cheng et al. in 2024 related to self-memory in generation-augmented retrieval</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="MAO ET AL., 2020">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a work by Mao et al. in 2020 related to generation-augmented retrieval</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="SHAO ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a work by Shao et al. in 2023 related to iterative retrieval-generation strategies</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="WANG ET AL., 2024">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a work by Wang et al. in 2024 related to federated retrieval-generation strategies</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="SU ET AL., 2020">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a work by Su et al. in 2020 related to multi-document summarization</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="FENG ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a work by Feng et al. in 2023 related to multi-hop question answering</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="TRIVEDI ET AL., 2022">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a work by Trivedi et al. in 2022 related to multi-hop question answering</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="KHATTAB ET AL., 2022">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a work by Khattab et al. in 2022 related to multi-hop question answering</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="SARTHI ET AL., 2024">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a work by Sarthi et al. in 2024 related to hierarchical indexing</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="KIM ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a work by Kim et al. in 2023 related to generating a tree of clarifications</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="TRAJANOSKA ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a work by Trajanoska et al. in 2023 related to knowledge graph creation</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="YAO ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a work by Yao et al. in 2023 related to knowledge graph completion</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="BAN ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a work by Ban et al. in 2023 related to the extraction of causal graphs</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="ZHANG ET AL., 2024">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a work by Zhang et al. in 2024 related to the extraction of causal graphs</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="BAEK ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a work by Baek et al. in 2023 related to KAPING</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="HE ET AL., 2024">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a work by He et al. in 2024 related to G-Retriever</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="ZHANG, 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a work by Zhang in 2023 related to Graph-ToolFormer</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="KANG ET AL., 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a work by Kang et al. in 2023 related to SURGE</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="RANADE AND JOSHI, 2023">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a work by Ranade and Joshi in 2023 related to FABULA</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="WANG ET AL., 2023B">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a work by Wang et al. in 2023 related to ITRG</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="LANGCHAIN, 2024">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to the LangChain library in 2024</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="LLAMAINDEX, 2024">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to the LlamaIndex library in 2024</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="NEO4J, 2024">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to the Neo4J graph database in 2024</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="NEBULAGRAPH, 2024">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to the NebulaGraph database in 2024</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
      <data key="d3">REFERENCE</data>
    </node>
    <node id="NEWS LOW-LEVEL COMMUNITY SUMMARIES">
      <data key="d0">SUMMARY</data>
      <data key="d1">Summaries of news content at a low level of detail, focused on community aspects</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="TABLE 3">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to a table that illustrates the scalability advantages of Graph RAG compared to source text summarization</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="SS">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to global approaches versus na&#239;ve RAG in the context of empowerment comparisons</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="TS">
      <data key="d0">REFERENCE</data>
      <data key="d1">A reference to Graph RAG approaches versus source text summarization in the context of empowerment comparisons</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="AD-HOC LLM">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The use of large language models in an ad-hoc manner to analyze reasoning for empowerment measures</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="ELEMENT EXTRACTION PROMPTS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Prompts used to extract specific elements from text, which can be tuned to retain more details in the Graph RAG index</data>
      <data key="d2">edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="RAPTOR">
      <data key="d0">SYSTEM</data>
      <data key="d1">A system that generates a hierarchical index of text chunks by clustering the vectors of text embeddings
A system for recursive abstractive processing for tree-organized retrieval, as discussed by Sarthi et al. (2024)</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88,edab4014b8f55e5b25bd7f396314be1f</data>
    </node>
    <node id="SELFCHECKGPT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A method or tool used to compare fabrication rates in generated content, as mentioned in the context of improving analysis
A tool for zero-resource black-box hallucination detection in generative large language models, as discussed by Manakul et al. (2023)</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8,df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="ALONSO GUEVARA FERN&#193;NDEZ">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AMBER HOAK">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANDR&#201;S MORALES ESQUIVEL">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BEN CUTLER">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BILLIE RINALDI">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHRIS SANCHEZ">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHRIS TREVINO">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHRISTINE CAGGIANO">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DAVID TITTSWORTH">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DAYENNE DE SOUZA">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DOUGLAS ORBAKER">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ED CLARK">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GABRIEL NIEVES-PONCE">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GAUDY BLANCO MENESES">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KATE LYTVYNETS">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="KATY SMITH">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="M&#211;NICA CARVAJAL">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NATHAN EVANS">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RICHARD ORTEGA">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RODRIGO RACANICCI">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SARAH SMITH">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHANE SOLOMON">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GPT-4 TECHNICAL REPORT">
      <data key="d0">DOCUMENT</data>
      <data key="d1">A technical report on GPT-4, as mentioned in the references</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">DOCUMENT</data>
    </node>
    <node id="KNOWLEDGE-AUGMENTED LANGUAGE MODEL PROMPTING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A method for zero-shot knowledge graph question answering, as mentioned in the references</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="LARGE LANGUAGE MODELS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Advanced machine learning models that are trained on vast amounts of text data to understand and generate human language

Advanced machine learning models that are trained on vast amounts of text data to understand and generate human language
Advanced machine learning models trained on extensive data to understand and generate human language</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,ab04427ae0415a1c812a35cf8d3ee1a2,ac21ebe9a9d70d691c717f961d3f10c8,d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="CAUSAL DISCOVERY">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The process of identifying causal relationships from data, as mentioned in the references</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="QUERY FOCUSED ABSTRACTIVE SUMMARIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A summarization method that incorporates query relevance, multi-document coverage, and summary length constraints into seq2seq models</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="FAST UNFOLDING OF COMMUNITIES">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A method for detecting communities in large networks, as mentioned in the references
A method for detecting communities in large networks, described by Blondel, Guillaume, Lambiotte, and Lefebvre in 2008</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="J. ACHIAM">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the GPT-4 technical report</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="S. ADLER">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the GPT-4 technical report</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="S. AGARWAL">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the GPT-4 technical report</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="L. AHMAD">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the GPT-4 technical report</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="I. AKKAYA">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the GPT-4 technical report</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="F. L. ALEMAN">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the GPT-4 technical report</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="D. ALMEIDA">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the GPT-4 technical report</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="J. ALTENSCHMIDT">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the GPT-4 technical report</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="S. ALTMAN">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the GPT-4 technical report</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="S. ANADKAT">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the GPT-4 technical report</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="R. ANIL">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the Gemini technical report</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="S. BORGEAUD">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the Gemini technical report</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="Y. WU">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the Gemini technical report</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="J.-B. ALAYRAC">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the Gemini technical report</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="J. YU">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the Gemini technical report</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="R. SORICUT">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the Gemini technical report</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="J. SCHALKWYK">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the Gemini technical report</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="A. M. DAI">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the Gemini technical report</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="A. HAUTH">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the Gemini technical report</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="J. BAEK">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the knowledge-augmented language model prompting paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="A. F. AJI">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the knowledge-augmented language model prompting paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="A. SAFFARI">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the knowledge-augmented language model prompting paper</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="T. BAN">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the paper on harnessing large language models for advanced causal discovery</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="L. CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the paper on harnessing large language models for advanced causal discovery</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="X. WANG">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the paper on harnessing large language models for advanced causal discovery</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="H. CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the paper on harnessing large language models for advanced causal discovery</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="T. BAUMEL">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the paper on query focused abstractive summarization</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="M. EYAL">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the paper on query focused abstractive summarization</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="M. ELHADAD">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the paper on query focused abstractive summarization</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="V. D. BLONDEL">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the paper on fast unfolding of communities in large networks</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="J.-L. GUILLAUME">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the paper on fast unfolding of communities in large networks</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="R. LAMBIOTTE">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the paper on fast unfolding of communities in large networks</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="E. LEFEBVRE">
      <data key="d0">PERSON</data>
      <data key="d1">An author of the paper on fast unfolding of communities in large networks</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GRAPH-BASED RAG APPLICATIONS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="FABRICATION RATES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="GPT-4 TECHNICAL REPORT&lt;**ANALYSIS:**(&quot;ENTITY&quot;">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="KATE LYTIVYNETS">
      <data key="d0">PERSON</data>
      <data key="d1">A contributor to the work on Graph RAG</data>
      <data key="d2">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </node>
    <node id="LANGUAGE MODELS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Advanced machine learning models designed to understand and generate human language, as discussed in the paper "Language models are few-shot learners" by Brown et al. in 2020
</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="RETRIEVAL-AUGMENTED TEXT GENERATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A method that combines information retrieval with text generation to improve the quality and relevance of generated content, as described by Cheng et al. in 2024</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="DUC 2005">
      <data key="d0">EVALUATION</data>
      <data key="d1">An evaluation of question-focused summarization systems conducted by H. T. Dang in 2006</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">EVALUATION</data>
    </node>
    <node id="RETRIEVAL-GENERATION SYNERGY">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A method that enhances large language models by combining retrieval and generation processes, as described by Feng et al. in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="PEGASUS">
      <data key="d0">MODEL</data>
      <data key="d1">A transformer model used for few-shot and zero-shot multi-document abstractive summarization, as compared by Goodwin, Savery, and Demner-Fushman in 2020</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="FORCEATLAS2">
      <data key="d0">ALGORITHM</data>
      <data key="d1">A continuous graph layout algorithm designed for network visualization, as described by Jacomy, Venturini, Heymann, and Bastian in 2014</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">ALGORITHM</data>
    </node>
    <node id="COMMUNITY DETECTION APPROACHES">
      <data key="d0">RESEARCH TOPIC</data>
      <data key="d1">Various methods for identifying communities within graphs, ranging from statistical modeling to deep learning, as surveyed by Jin et al. in 2021</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">RESEARCH TOPIC</data>
    </node>
    <node id="KNOWLEDGE GRAPH-AUGMENTED LANGUAGE MODELS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Language models enhanced with knowledge graphs for knowledge-grounded dialogue generation, as described by Kang et al. in 2023</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="DEMONSTRATE-SEARCH-PREDICT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A method that combines retrieval and language models for knowledge-intensive NLP tasks, as described by Khattab et al. in 2022</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="FEW-SHOT LEARNING">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GRAPH VISUALIZATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KNOWLEDGE-GROUNDED DIALOGUE GENERATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KNOWLEDGE-INTENSIVE NLP">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RETRIEVAL-AUGMENTED LARGE LANGUAGE MODELS">
      <data key="d0" />
      <data key="d1">
Large language models that are enhanced with retrieval-augmented techniques to improve their performance in generating relevant information</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
    </node>
    <node id="ALTERNATIVE PERSPECTIVES">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SENSEMAKING BEHAVIORS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="BLONDEL, V. D.">
      <data key="d0">PERSON</data>
      <data key="d1">V. D. Blondel is an author who contributed to the research on fast unfolding of communities in large networks</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GUILLAUME, J.-L.">
      <data key="d0">PERSON</data>
      <data key="d1">J.-L. Guillaume is an author who contributed to the research on fast unfolding of communities in large networks</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LAMBIOTTE, R.">
      <data key="d0">PERSON</data>
      <data key="d1">R. Lambiotte is an author who contributed to the research on fast unfolding of communities in large networks</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LEFEBVRE, E.">
      <data key="d0">PERSON</data>
      <data key="d1">E. Lefebvre is an author who contributed to the research on fast unfolding of communities in large networks</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="BROWN, T.">
      <data key="d0">PERSON</data>
      <data key="d1">T. Brown is an author who contributed to the research on language models as few-shot learners</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="MANN, B.">
      <data key="d0">PERSON</data>
      <data key="d1">B. Mann is an author who contributed to the research on language models as few-shot learners</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="RYDER, N.">
      <data key="d0">PERSON</data>
      <data key="d1">N. Ryder is an author who contributed to the research on language models as few-shot learners</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SUBBIAH, M.">
      <data key="d0">PERSON</data>
      <data key="d1">M. Subbiah is an author who contributed to the research on language models as few-shot learners</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KAPLAN, J. D.">
      <data key="d0">PERSON</data>
      <data key="d1">J. D. Kaplan is an author who contributed to the research on language models as few-shot learners</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DHARIWAL, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Dhariwal is an author who contributed to the research on language models as few-shot learners</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="NEELAKANTAN, A.">
      <data key="d0">PERSON</data>
      <data key="d1">A. Neelakantan is an author who contributed to the research on language models as few-shot learners</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SHYAM, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Shyam is an author who contributed to the research on language models as few-shot learners</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SASTRY, G.">
      <data key="d0">PERSON</data>
      <data key="d1">G. Sastry is an author who contributed to the research on language models as few-shot learners</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ASKELL, A.">
      <data key="d0">PERSON</data>
      <data key="d1">A. Askell is an author who contributed to the research on language models as few-shot learners</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="CHENG, X.">
      <data key="d0">PERSON</data>
      <data key="d1">X. Cheng is an author who contributed to the research on retrieval-augmented text generation with self-memory</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LUO, D.">
      <data key="d0">PERSON</data>
      <data key="d1">D. Luo is an author who contributed to the research on retrieval-augmented text generation with self-memory</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="CHEN, X.">
      <data key="d0">PERSON</data>
      <data key="d1">X. Chen is an author who contributed to the research on retrieval-augmented text generation with self-memory</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LIU, L.">
      <data key="d0">PERSON</data>
      <data key="d1">L. Liu is an author who contributed to the research on retrieval-augmented text generation with self-memory</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ZHAO, D.">
      <data key="d0">PERSON</data>
      <data key="d1">D. Zhao is an author who contributed to the research on retrieval-augmented text generation with self-memory</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="YAN, R.">
      <data key="d0">PERSON</data>
      <data key="d1">R. Yan is an author who contributed to the research on retrieval-augmented text generation with self-memory</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ES, S.">
      <data key="d0">PERSON</data>
      <data key="d1">S. Es is an author who contributed to the research on automated evaluation of retrieval-augmented generation</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JAMES, J.">
      <data key="d0">PERSON</data>
      <data key="d1">J. James is an author who contributed to the research on automated evaluation of retrieval-augmented generation</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ESPINOSA-ANKE, L.">
      <data key="d0">PERSON</data>
      <data key="d1">L. Espinosa-Anke is an author who contributed to the research on automated evaluation of retrieval-augmented generation</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SCHOCKAERT, S.">
      <data key="d0">PERSON</data>
      <data key="d1">S. Schockaert is an author who contributed to the research on automated evaluation of retrieval-augmented generation</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FENG, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Z. Feng is an author who contributed to the research on retrieval-generation synergy augmented large language models</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="FENG, X.">
      <data key="d0">PERSON</data>
      <data key="d1">X. Feng is an author who contributed to the research on retrieval-generation synergy augmented large language models</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="YANG, M.">
      <data key="d0">PERSON</data>
      <data key="d1">M. Yang is an author who contributed to the research on retrieval-generation synergy augmented large language models</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="QIN, B.">
      <data key="d0">PERSON</data>
      <data key="d1">B. Qin is an author who contributed to the research on retrieval-generation synergy augmented large language models</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GAO, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Gao is an author who contributed to the survey on retrieval-augmented generation for large language models</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="XIONG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Xiong is an author who contributed to the survey on retrieval-augmented generation for large language models</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GAO, X.">
      <data key="d0">PERSON</data>
      <data key="d1">X. Gao is an author who contributed to the survey on retrieval-augmented generation for large language models</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JIA, K.">
      <data key="d0">PERSON</data>
      <data key="d1">K. Jia is an author who contributed to the survey on retrieval-augmented generation for large language models</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PAN, J.">
      <data key="d0">PERSON</data>
      <data key="d1">J. Pan is an author who contributed to the survey on retrieval-augmented generation for large language models</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="BI, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Bi is an author who contributed to the survey on retrieval-augmented generation for large language models</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DAI, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Dai is an author who contributed to the survey on retrieval-augmented generation for large language models</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SUN, J.">
      <data key="d0">PERSON</data>
      <data key="d1">J. Sun is an author who contributed to the survey on retrieval-augmented generation for large language models</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="WANG, H.">
      <data key="d0">PERSON</data>
      <data key="d1">H. Wang is an author who contributed to the survey on retrieval-augmented generation for large language models</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GOODWIN, T. R.">
      <data key="d0">PERSON</data>
      <data key="d1">T. R. Goodwin is an author who contributed to the research on comparing transformers on few-shot and zero-shot multi-document abstractive summarization</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SAVERY, M. E.">
      <data key="d0">PERSON</data>
      <data key="d1">M. E. Savery is an author who contributed to the research on comparing transformers on few-shot and zero-shot multi-document abstractive summarization</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="DEMNER-FUSHMAN, D.">
      <data key="d0">PERSON</data>
      <data key="d1">D. Demner-Fushman is an author who contributed to the research on comparing transformers on few-shot and zero-shot multi-document abstractive summarization</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HE, X.">
      <data key="d0">PERSON</data>
      <data key="d1">X. He is an author who contributed to the research on G-Retriever for retrieval-augmented generation for textual graph understanding and question answering</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="TIAN, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Tian is an author who contributed to the research on G-Retriever for retrieval-augmented generation for textual graph understanding and question answering</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SUN, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Sun is an author who contributed to the research on G-Retriever for retrieval-augmented generation for textual graph understanding and question answering</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="CHAWLA, N. V.">
      <data key="d0">PERSON</data>
      <data key="d1">N. V. Chawla is an author who contributed to the research on G-Retriever for retrieval-augmented generation for textual graph understanding and question answering</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LAURENT, T.">
      <data key="d0">PERSON</data>
      <data key="d1">T. Laurent is an author who contributed to the research on G-Retriever for retrieval-augmented generation for textual graph understanding and question answering</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LECUN, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. LeCun is an author who contributed to the research on G-Retriever for retrieval-augmented generation for textual graph understanding and question answering</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="BRESSON, X.">
      <data key="d0">PERSON</data>
      <data key="d1">X. Bresson is an author who contributed to the research on G-Retriever for retrieval-augmented generation for textual graph understanding and question answering</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HOOI, B.">
      <data key="d0">PERSON</data>
      <data key="d1">B. Hooi is an author who contributed to the research on G-Retriever for retrieval-augmented generation for textual graph understanding and question answering</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JACOMY, M.">
      <data key="d0">PERSON</data>
      <data key="d1">M. Jacomy is an author who contributed to the research on ForceAtlas2, a continuous graph layout algorithm for network visualization</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="VENTURINI, T.">
      <data key="d0">PERSON</data>
      <data key="d1">T. Venturini is an author who contributed to the research on ForceAtlas2, a continuous graph layout algorithm for network visualization</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HEYMANN, S.">
      <data key="d0">PERSON</data>
      <data key="d1">S. Heymann is an author who contributed to the research on ForceAtlas2, a continuous graph layout algorithm for network visualization</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="BASTIAN, M.">
      <data key="d0">PERSON</data>
      <data key="d1">M. Bastian is an author who contributed to the research on ForceAtlas2, a continuous graph layout algorithm for network visualization</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JIN, D.">
      <data key="d0">PERSON</data>
      <data key="d1">D. Jin is an author who contributed to the survey of community detection approaches</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="YU, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Z. Yu is an author who contributed to the survey of community detection approaches</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JIAO, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Jiao is an author who contributed to the survey of community detection approaches</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PAN, S.">
      <data key="d0">PERSON</data>
      <data key="d1">S. Pan is an author who contributed to the survey of community detection approaches</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HE, D.">
      <data key="d0">PERSON</data>
      <data key="d1">D. He is an author who contributed to the survey of community detection approaches</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="WU, J.">
      <data key="d0">PERSON</data>
      <data key="d1">J. Wu is an author who contributed to the survey of community detection approaches</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PHILIP, S. Y.">
      <data key="d0">PERSON</data>
      <data key="d1">S. Y. Philip is an author who contributed to the survey of community detection approaches</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ZHANG, W.">
      <data key="d0">PERSON</data>
      <data key="d1">W. Zhang is an author who contributed to the survey of community detection approaches</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KANG, M.">
      <data key="d0">PERSON</data>
      <data key="d1">M. Kang is an author who contributed to the research on knowledge graph-augmented language models for knowledge-grounded dialogue generation</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KWAK, J. M.">
      <data key="d0">PERSON</data>
      <data key="d1">J. M. Kwak is an author who contributed to the research on knowledge graph-augmented language models for knowledge-grounded dialogue generation</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="BAEK, J.">
      <data key="d0">PERSON</data>
      <data key="d1">J. Baek is an author who contributed to the research on knowledge graph-augmented language models for knowledge-grounded dialogue generation</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HWANG, S. J.">
      <data key="d0">PERSON</data>
      <data key="d1">S. J. Hwang is an author who contributed to the research on knowledge graph-augmented language models for knowledge-grounded dialogue generation</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KHATTAB, O.">
      <data key="d0">PERSON</data>
      <data key="d1">O. Khattab is an author who contributed to the research on demonstrate-search-predict for knowledge-intensive NLP</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="SANTHANAM, K.">
      <data key="d0">PERSON</data>
      <data key="d1">K. Santhanam is an author who contributed to the research on demonstrate-search-predict for knowledge-intensive NLP</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LI, X. L.">
      <data key="d0">PERSON</data>
      <data key="d1">X. L. Li is an author who contributed to the research on demonstrate-search-predict for knowledge-intensive NLP</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="HALL, D.">
      <data key="d0">PERSON</data>
      <data key="d1">D. Hall is an author who contributed to the research on demonstrate-search-predict for knowledge-intensive NLP</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="LIANG, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Liang is an author who contributed to the research on demonstrate-search-predict for knowledge-intensive NLP
P. Liang is an author who contributed to the research on how language models use long contexts</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb,df50c95dff7da074cbb2f68e88686f88</data>
    </node>
    <node id="POTTS, C.">
      <data key="d0">PERSON</data>
      <data key="d1">C. Potts is an author who contributed to the research on demonstrate-search-predict for knowledge-intensive NLP</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="ZAHARIA, M.">
      <data key="d0">PERSON</data>
      <data key="d1">M. Zaharia is an author who contributed to the research on demonstrate-search-predict for knowledge-intensive NLP</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KIM, G.">
      <data key="d0">PERSON</data>
      <data key="d1">G. Kim is an author who contributed to the research on tree of clarifications for answering ambiguous questions</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KIM, S.">
      <data key="d0">PERSON</data>
      <data key="d1">S. Kim is an author who contributed to the research on tree of clarifications for answering ambiguous questions</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="JEON, B.">
      <data key="d0">PERSON</data>
      <data key="d1">B. Jeon is an author who contributed to the research on tree of clarifications for answering ambiguous questions</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="PARK, J.">
      <data key="d0">PERSON</data>
      <data key="d1">J. Park is an author who contributed to the research on tree of clarifications for answering ambiguous questions</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="KANG, J.">
      <data key="d0">PERSON</data>
      <data key="d1">J. Kang is an author who contributed to the research on tree of clarifications for answering ambiguous questions</data>
      <data key="d2">aa79049289e6532592eec17b9e76adfb</data>
    </node>
    <node id="GREGORY, K.">
      <data key="d0">PERSON</data>
      <data key="d1">K. Gregory is an author who contributed to the research on understanding data sensemaking behaviors</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GROTH, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Groth is an author who contributed to the research on understanding data sensemaking behaviors</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SIMPERL, E.">
      <data key="d0">PERSON</data>
      <data key="d1">E. Simperl is an author who contributed to the research on understanding data sensemaking behaviors</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DATA SENSEMAKING BEHAVIORS">
      <data key="d0">RESEARCH TOPIC</data>
      <data key="d1">The study of how individuals interpret and make sense of data, as discussed in the paper by Koesten et al. (2021)</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">RESEARCH TOPIC</data>
    </node>
    <node id="KURATOV, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Kuratov is an author who contributed to the research on recurrent memory in large language models</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BULATOV, A.">
      <data key="d0">PERSON</data>
      <data key="d1">A. Bulatov is an author who contributed to the research on recurrent memory in large language models</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANOKHIN, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Anokhin is an author who contributed to the research on recurrent memory in large language models</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SOROKIN, D.">
      <data key="d0">PERSON</data>
      <data key="d1">D. Sorokin is an author who contributed to the research on recurrent memory in large language models</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SOROKIN, A.">
      <data key="d0">PERSON</data>
      <data key="d1">A. Sorokin is an author who contributed to the research on recurrent memory in large language models</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BURTSEV, M.">
      <data key="d0">PERSON</data>
      <data key="d1">M. Burtsev is an author who contributed to the research on recurrent memory in large language models</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RECURRENT MEMORY">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A method used in large language models to improve their ability to find relevant information in large datasets, as discussed by Kuratov et al. (2024)</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="LANGCHAIN GRAPHS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A specific feature of LangChain that involves the use of graphs for various applications</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="LASKAR, M. T. R.">
      <data key="d0">PERSON</data>
      <data key="d1">M. T. R. Laskar is an author who contributed to the research on query-focused abstractive summarization and domain adaptation with pre-trained transformers</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HOQUE, E.">
      <data key="d0">PERSON</data>
      <data key="d1">E. Hoque is an author who contributed to the research on query-focused abstractive summarization and domain adaptation with pre-trained transformers</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HUANG, J.">
      <data key="d0">PERSON</data>
      <data key="d1">J. Huang is an author who contributed to the research on query-focused abstractive summarization and domain adaptation with pre-trained transformers</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DOMAIN ADAPTATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The process of adapting pre-trained models to new domains, as discussed by Laskar et al. (2022)</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="TRANSFORMER MODELS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Advanced machine learning models used for various natural language processing tasks, including summarization and domain adaptation</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="LEWIS, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Lewis is an author who contributed to the research on retrieval-augmented generation for knowledge-intensive NLP tasks</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PEREZ, E.">
      <data key="d0">PERSON</data>
      <data key="d1">E. Perez is an author who contributed to the research on retrieval-augmented generation for knowledge-intensive NLP tasks</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PIKTUS, A.">
      <data key="d0">PERSON</data>
      <data key="d1">A. Piktus is an author who contributed to the research on retrieval-augmented generation for knowledge-intensive NLP tasks</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PETRONI, F.">
      <data key="d0">PERSON</data>
      <data key="d1">F. Petroni is an author who contributed to the research on retrieval-augmented generation for knowledge-intensive NLP tasks</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KARPUKHIN, V.">
      <data key="d0">PERSON</data>
      <data key="d1">V. Karpukhin is an author who contributed to the research on retrieval-augmented generation for knowledge-intensive NLP tasks</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GOYAL, N.">
      <data key="d0">PERSON</data>
      <data key="d1">N. Goyal is an author who contributed to the research on retrieval-augmented generation for knowledge-intensive NLP tasks</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="K&#220;TTLER, H.">
      <data key="d0">PERSON</data>
      <data key="d1">H. K&#252;ttler is an author who contributed to the research on retrieval-augmented generation for knowledge-intensive NLP tasks</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LEWIS, M.">
      <data key="d0">PERSON</data>
      <data key="d1">M. Lewis is an author who contributed to the research on retrieval-augmented generation for knowledge-intensive NLP tasks</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YIH, W.-T.">
      <data key="d0">PERSON</data>
      <data key="d1">W.-T. Yih is an author who contributed to the research on retrieval-augmented generation for knowledge-intensive NLP tasks</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ROCKT&#196;SCHEL, T.">
      <data key="d0">PERSON</data>
      <data key="d1">T. Rockt&#228;schel is an author who contributed to the research on retrieval-augmented generation for knowledge-intensive NLP tasks</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LIU, N. F.">
      <data key="d0">PERSON</data>
      <data key="d1">N. F. Liu is an author who contributed to the research on how language models use long contexts</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LIN, K.">
      <data key="d0">PERSON</data>
      <data key="d1">K. Lin is an author who contributed to the research on how language models use long contexts</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HEWITT, J.">
      <data key="d0">PERSON</data>
      <data key="d1">J. Hewitt is an author who contributed to the research on how language models use long contexts</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PARANJAPE, A.">
      <data key="d0">PERSON</data>
      <data key="d1">A. Paranjape is an author who contributed to the research on how language models use long contexts</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BEVILACQUA, M.">
      <data key="d0">PERSON</data>
      <data key="d1">M. Bevilacqua is an author who contributed to the research on how language models use long contexts</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LONG CONTEXTS">
      <data key="d0">RESEARCH TOPIC</data>
      <data key="d1">The study of how language models handle and utilize long sequences of text, as discussed by Liu et al. (2023)</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">RESEARCH TOPIC</data>
    </node>
    <node id="LLAMAINDEX KNOWLEDGE GRAPH INDEX">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A specific feature of LlamaIndex that involves creating and using knowledge graphs</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="MANAKUL, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Manakul is an author who contributed to the research on hallucination detection in generative large language models</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LIUSIE, A.">
      <data key="d0">PERSON</data>
      <data key="d1">A. Liusie is an author who contributed to the research on hallucination detection in generative large language models</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GALES, M. J.">
      <data key="d0">PERSON</data>
      <data key="d1">M. J. Gales is an author who contributed to the research on hallucination detection in generative large language models</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MAO, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Mao is an author who contributed to the research on generation-augmented retrieval for open-domain question answering</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HE, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. He is an author who contributed to the research on generation-augmented retrieval for open-domain question answering</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LIU, X.">
      <data key="d0">PERSON</data>
      <data key="d1">X. Liu is an author who contributed to the research on generation-augmented retrieval for open-domain question answering</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHEN, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Shen is an author who contributed to the research on generation-augmented retrieval for open-domain question answeringY. Shen is an author who contributed to the research on enhancing retrieval-augmented large language models with iterative retrieval-generation synergy</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GAO, J.">
      <data key="d0">PERSON</data>
      <data key="d1">J. Gao is an author who contributed to the research on generation-augmented retrieval for open-domain question answering</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HAN, J.">
      <data key="d0">PERSON</data>
      <data key="d1">J. Han is an author who contributed to the research on generation-augmented retrieval for open-domain question answering</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHEN, W.">
      <data key="d0">PERSON</data>
      <data key="d1">W. Chen is an author who contributed to the research on enhancing retrieval-augmented large language models with iterative retrieval-generation synergyW. Chen is an author who contributed to the research on generation-augmented retrieval for open-domain question answering
W. Chen is an author who contributed to the research on enhancing retrieval-augmented large language models with iterative retrieval-generation synergy</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MARTIN, S.">
      <data key="d0">PERSON</data>
      <data key="d1">S. Martin is an author who contributed to the development of OpenOrd, an open-source toolbox for large graph layout</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BROWN, W. M.">
      <data key="d0">PERSON</data>
      <data key="d1">W. M. Brown is an author who contributed to the development of OpenOrd, an open-source toolbox for large graph layout</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KLAVANS, R.">
      <data key="d0">PERSON</data>
      <data key="d1">R. Klavans is an author who contributed to the development of OpenOrd, an open-source toolbox for large graph layout</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BOYACK, K.">
      <data key="d0">PERSON</data>
      <data key="d1">K. Boyack is an author who contributed to the development of OpenOrd, an open-source toolbox for large graph layout</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GPT-4">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A large language model developed by OpenAI, used in a preliminary study by Microsoft to assess its impact on scientific discovery
GPT-4 is a powerful model often used to generate responses to prompts in the process of creating synthetic data for training language models.
A powerful language model used by AgentInstruct to generate high-quality data
A model used as a baseline for scoring the performance of other models on the Orca-Bench dataset
A state-of-the-art language model used as a benchmark with a score of 10 in the Orca-Bench dataset
GPT-4 is a model used as a benchmark for comparison in reading comprehension evaluations.
GPT-4 is a state-of-the-art language model developed by OpenAI, used as a benchmark for evaluating the performance of other models
GPT-4 is a language model used as an evaluator for summarization abilities and other performance metrics
A large language model developed by OpenAI, evaluated on the MIRAGE datasets using CoT and RAG techniques
A large language model developed by OpenAI, as described in the 2023 technical report
An advanced language model used for extracting the option selected by the model from the model&#8217;s response in multiple choice questions
An advanced language model developed by OpenAI, used for extracting and evaluating answers
</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,0cf2e43f324fa4175b9b00b90e5e90ba,103d98395c393552cc954c89d4e59f50,3d1f6634f93f8a4c296dc8df7e59859e,5819b66e04fd77fa705574edc49395bb,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635,df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="PROJECT NALLM">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A project by Neo4j involving large language models and graph databases</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="NEWMAN, M. E.">
      <data key="d0">PERSON</data>
      <data key="d1">M. E. Newman is an author who contributed to the research on modularity and community structure in networks</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="COMMUNITY STRUCTURE">
      <data key="d0">RESEARCH TOPIC</data>
      <data key="d1">The study of how networks are organized into communities or clusters, as discussed by Newman (2006)</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">RESEARCH TOPIC</data>
    </node>
    <node id="RAM, O.">
      <data key="d0">PERSON</data>
      <data key="d1">O. Ram is an author who contributed to the research on in-context retrieval-augmented language models</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LEVINE, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Levine is an author who contributed to the research on in-context retrieval-augmented language models</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DALMEDIGOS, I.">
      <data key="d0">PERSON</data>
      <data key="d1">I. Dalmedigos is an author who contributed to the research on in-context retrieval-augmented language models</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MUHLGAY, D.">
      <data key="d0">PERSON</data>
      <data key="d1">D. Muhlgay is an author who contributed to the research on in-context retrieval-augmented language models</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHASHUA, A.">
      <data key="d0">PERSON</data>
      <data key="d1">A. Shashua is an author who contributed to the research on in-context retrieval-augmented language models</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LEYTON-BROWN, K.">
      <data key="d0">PERSON</data>
      <data key="d1">K. Leyton-Brown is an author who contributed to the research on in-context retrieval-augmented language models</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHOHAM, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Shoham is an author who contributed to the research on in-context retrieval-augmented language models</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="IN-CONTEXT RETRIEVAL-AUGMENTED LANGUAGE MODELS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A method that enhances language models by incorporating retrieval mechanisms within the context of the input, as discussed by Ram et al. (2023)</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="RANADE, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Ranade is an author who contributed to the research on intelligence report generation using retrieval-augmented narrative construction</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JOSHI, A.">
      <data key="d0">PERSON</data>
      <data key="d1">A. Joshi is an author who contributed to the research on intelligence report generation using retrieval-augmented narrative construction</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SARTHI, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Sarthi is an author who contributed to the research on recursive abstractive processing for tree-organized retrieval</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ABDULLAH, S.">
      <data key="d0">PERSON</data>
      <data key="d1">S. Abdullah is an author who contributed to the research on recursive abstractive processing for tree-organized retrieval</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="TULI, A.">
      <data key="d0">PERSON</data>
      <data key="d1">A. Tuli is an author who contributed to the research on recursive abstractive processing for tree-organized retrieval</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KHANNA, S.">
      <data key="d0">PERSON</data>
      <data key="d1">S. Khanna is an author who contributed to the research on recursive abstractive processing for tree-organized retrieval</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GOLDIE, A.">
      <data key="d0">PERSON</data>
      <data key="d1">A. Goldie is an author who contributed to the research on recursive abstractive processing for tree-organized retrieval</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MANNING, C. D.">
      <data key="d0">PERSON</data>
      <data key="d1">C. D. Manning is an author who contributed to the research on recursive abstractive processing for tree-organized retrieval
C. D. Manning is an author who contributed to the development of HotpotQA</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SCOTT, K.">
      <data key="d0">PERSON</data>
      <data key="d1">K. Scott is an author who contributed to the "Behind the Tech" series by Microsoft</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHAO, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Z. Shao is an author who contributed to the research on enhancing retrieval-augmented large language models with iterative retrieval-generation synergy</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GONG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Gong is an author who contributed to the research on enhancing retrieval-augmented large language models with iterative retrieval-generation synergy</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HUANG, M.">
      <data key="d0">PERSON</data>
      <data key="d1">M. Huang is an author who contributed to the research on enhancing retrieval-augmented large language models with iterative retrieval-generation synergy</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DUAN, N.">
      <data key="d0">PERSON</data>
      <data key="d1">N. Duan is an author who contributed to the research on enhancing retrieval-augmented large language models with iterative retrieval-generation synergy</data>
      <data key="d2">df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ITERATIVE RETRIEVAL-GENERATION SYNERGY">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A method that enhances retrieval-augmented large language models by iteratively refining the retrieval and generation processes, as discussed by Shao et al. (2023)
A method that involves iterative processes of retrieval and generation to enhance the performance of large language models</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="SU, D.">
      <data key="d0">PERSON</data>
      <data key="d1">D. Su is an author who contributed to the research on CAIRE-COVID, a question answering and query-focused multi-document summarization system
D. Su is an author who contributed to the development of Caire-covid, a question answering and query-focused multi-document summarization system for COVID-19 scholarly information management</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XU, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Xu is an author who contributed to the research on CAIRE-COVID, a question answering and query-focused multi-document summarization system
Y. Xu is an author who contributed to the research on text summarization with latent queriesY. Xu is an author who contributed to the development of Caire-covid, a question answering and query-focused multi-document summarization system for COVID-19 scholarly information management</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YU, T.">
      <data key="d0">PERSON</data>
      <data key="d1">T. Yu is an author who contributed to the research on CAIRE-COVID,T. Yu is an author who contributed to the research on CAIRE-COVID
T. Yu is an author who contributed to the development of Caire-covid, a question answering and query-focused multi-document summarization system for COVID-19 scholarly information management</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3,df50c95dff7da074cbb2f68e88686f88</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SIDDIQUE, F. B.">
      <data key="d0">PERSON</data>
      <data key="d1">F. B. Siddique is an author who contributed to the development of Caire-covid, a question answering and query-focused multi-document summarization system for COVID-19 scholarly information management</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BAREZI, E. J.">
      <data key="d0">PERSON</data>
      <data key="d1">E. J. Barezi is an author who contributed to the development of Caire-covid, a question answering and query-focused multi-document summarization system for COVID-19 scholarly information management</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="FUNG, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Fung is an author who contributed to the development of Caire-covid, a question answering and query-focused multi-document summarization system for COVID-19 scholarly information management</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CAIRE-COVID">
      <data key="d0">SYSTEM</data>
      <data key="d1">A question answering and query-focused multi-document summarization system for managing COVID-19 scholarly information</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">SYSTEM</data>
    </node>
    <node id="TANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Tang is an author who contributed to the development of MultiHop-RAG</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Yang is an author who contributed to the development of MultiHop-RAG</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LLAMA 2">
      <data key="d0">MODEL</data>
      <data key="d1">Open foundation and fine-tuned chat models, as described in the arXiv preprint arXiv:2307.09288</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="TOUVRON, H.">
      <data key="d0">PERSON</data>
      <data key="d1">H. Touvron is an author who contributed to the development of Llama 2</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MARTIN, L.">
      <data key="d0">PERSON</data>
      <data key="d1">L. Martin is an author who contributed to the development of Llama 2</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="STONE, K.">
      <data key="d0">PERSON</data>
      <data key="d1">K. Stone is an author who contributed to the development of Llama 2</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ALBERT, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Albert is an author who contributed to the development of Llama 2</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ALMAHAIRI, A.">
      <data key="d0">PERSON</data>
      <data key="d1">A. Almahairi is an author who contributed to the development of Llama 2</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BABAEI, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Babaei is an author who contributed to the development of Llama 2</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BASHLYKOV, N.">
      <data key="d0">PERSON</data>
      <data key="d1">N. Bashlykov is an author who contributed to the development of Llama 2</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BATRA, S.">
      <data key="d0">PERSON</data>
      <data key="d1">S. Batra is an author who contributed to the development of Llama 2</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BHARGAVA, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Bhargava is an author who contributed to the development of Llama 2</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BHOSALE, S.">
      <data key="d0">PERSON</data>
      <data key="d1">S. Bhosale is an author who contributed to the development of Llama 2</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LOUVAIN TO LEIDEN">
      <data key="d0">METHOD</data>
      <data key="d1">A method for guaranteeing well-formedness in community detection, as described by Traag, Waltman, and Van Eck in 2019</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">METHOD</data>
    </node>
    <node id="TRAAG, V. A.">
      <data key="d0">PERSON</data>
      <data key="d1">V. A. Traag is an author who contributed to the development of the Louvain to Leiden method</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WALTMAN, L.">
      <data key="d0">PERSON</data>
      <data key="d1">L. Waltman is an author who contributed to the development of the Louvain to Leiden method</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="VAN ECK, N. J.">
      <data key="d0">PERSON</data>
      <data key="d1">N. J. Van Eck is an author who contributed to the development of the Louvain to Leiden method</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SCIENTIFIC REPORTS">
      <data key="d0">PUBLICATION</data>
      <data key="d1">Scientific Reports is a peer-reviewed open access scientific journal covering all areas of the natural sciences</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PUBLICATION</data>
    </node>
    <node id="TRAJANOSKA, M.">
      <data key="d0">PERSON</data>
      <data key="d1">M. Trajanoska is an author who contributed to the research on enhancing knowledge graph construction using large language models</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="STOJANOV, R.">
      <data key="d0">PERSON</data>
      <data key="d1">R. Stojanov is an author who contributed to the research on enhancing knowledge graph construction using large language models</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="TRAJANOV, D.">
      <data key="d0">PERSON</data>
      <data key="d1">D. Trajanov is an author who contributed to the research on enhancing knowledge graph construction using large language models</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KNOWLEDGE GRAPH CONSTRUCTION">
      <data key="d0">RESEARCH TOPIC</data>
      <data key="d1">The process of creating a knowledge graph, which is a structured representation of knowledge in the form of entities and their relationships</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">RESEARCH TOPIC</data>
    </node>
    <node id="ARXIV">
      <data key="d0">PUBLICATION PLATFORM</data>
      <data key="d1">arXiv is an open-access repository of electronic preprints approved for publication after moderation, but not full peer review</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PUBLICATION PLATFORM</data>
    </node>
    <node id="TRIVEDI, H.">
      <data key="d0">PERSON</data>
      <data key="d1">H. Trivedi is an author who contributed to the research on interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BALASUBRAMANIAN, N.">
      <data key="d0">PERSON</data>
      <data key="d1">N. Balasubramanian is an author who contributed to the research on interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KHOT, T.">
      <data key="d0">PERSON</data>
      <data key="d1">T. Khot is an author who contributed to the research on interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SABHARWAL, A.">
      <data key="d0">PERSON</data>
      <data key="d1">A. Sabharwal is an author who contributed to the research on interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHAIN-OF-THOUGHT REASONING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A reasoning process that involves breaking down complex problems into a series of simpler, interconnected steps</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="WANG, J.">
      <data key="d0">PERSON</data>
      <data key="d1">J. Wang is an author who contributed to the research on evaluating ChatGPT as a natural language generation evaluator</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LIANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Liang is an author who contributed to the research on evaluating ChatGPT as a natural language generation evaluator</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MENG, F.">
      <data key="d0">PERSON</data>
      <data key="d1">F. Meng is an author who contributed to the research on evaluating ChatGPT as a natural language generation evaluator</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SUN, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Z. Sun is an author who contributed to the research on evaluating ChatGPT as a natural language generation evaluator</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHI, H.">
      <data key="d0">PERSON</data>
      <data key="d1">H. Shi is an author who contributed to the research on evaluating ChatGPT as a natural language generation evaluator</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LI, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Z. Li is an author who contributed to the research on evaluating ChatGPT as a natural language generation evaluator</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XU, J.">
      <data key="d0">PERSON</data>
      <data key="d1">J. Xu is an author who contributed to the research on evaluating ChatGPT as a natural language generation evaluator</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="QU, J.">
      <data key="d0">PERSON</data>
      <data key="d1">J. Qu is an author who contributed to the research on evaluating ChatGPT as a natural language generation evaluator</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHOU, J.">
      <data key="d0">PERSON</data>
      <data key="d1">J. Zhou is an author who contributed to the research on evaluating ChatGPT as a natural language generation evaluator</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHATGPT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">ChatGPT is a large language model developed by OpenAI, designed to generate human-like text based on the input it receives
A baseline model evaluated using the Orca-Bench dataset, scoring 8.13 on average</data>
      <data key="d2">bd4eb9459bc29b4c2da4658914fd4635,d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="NATURAL LANGUAGE GENERATION">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">The process of generating coherent and contextually relevant text from structured data or other forms of input</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="WANG, S.">
      <data key="d0">PERSON</data>
      <data key="d1">S. Wang is an author who contributed to the research on evaluating federated search in the context of retrieval augmented generation</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KHRAMTSOVA, E.">
      <data key="d0">PERSON</data>
      <data key="d1">E. Khramtsova is an author who contributed to the research on evaluating federated search in the context of retrieval augmented generation</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHUANG, S.">
      <data key="d0">PERSON</data>
      <data key="d1">S. Zhuang is an author who contributed to the research on evaluating federated search in the context of retrieval augmented generation</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZUCCON, G.">
      <data key="d0">PERSON</data>
      <data key="d1">G. Zuccon is an author who contributed to the research on evaluating federated search in the context of retrieval augmented generation</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="FEB4RAG">
      <data key="d0">SYSTEM</data>
      <data key="d1">A system for evaluating federated search in the context of retrieval augmented generation</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">SYSTEM</data>
    </node>
    <node id="WANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Wang is an author who contributed to the research on knowledge graph prompting for multi-document question answering</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LIPKA, N.">
      <data key="d0">PERSON</data>
      <data key="d1">N. Lipka is an author who contributed to the research on knowledge graph prompting for multi-document question answering</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ROSSI, R. A.">
      <data key="d0">PERSON</data>
      <data key="d1">R. A. Rossi is an author who contributed to the research on knowledge graph prompting for multi-document question answering</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SIU, A.">
      <data key="d0">PERSON</data>
      <data key="d1">A. Siu is an author who contributed to the research on knowledge graph prompting for multi-document question answering</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHANG, R.">
      <data key="d0">PERSON</data>
      <data key="d1">R. Zhang is an author who contributed to the research on knowledge graph prompting for multi-document question answering</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DERR, T.">
      <data key="d0">PERSON</data>
      <data key="d1">T. Derr is an author who contributed to the research on knowledge graph prompting for multi-document question answering</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KNOWLEDGE GRAPH PROMPTING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A method that uses knowledge graphs to enhance the process of multi-document question answering</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="LAPATA, M.">
      <data key="d0">PERSON</data>
      <data key="d1">M. Lapata is an author who contributed to the research on text summarization with latent queries</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="TEXT SUMMARIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The process of creating a concise and coherent summary of a longer text document</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="LATENT QUERIES">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A method that involves using hidden or implicit queries to improve the process of text summarization</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="YANG, Z.">
      <data key="d0">PERSON</data>
      <data key="d1">Z. Yang is an author who contributed to the development of HotpotQA</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="QI, P.">
      <data key="d0">PERSON</data>
      <data key="d1">P. Qi is an author who contributed to the development of HotpotQA</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHANG, S.">
      <data key="d0">PERSON</data>
      <data key="d1">S. Zhang is an author who contributed to the development of HotpotQA</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BENGIO, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Bengio is an author who contributed to the development of HotpotQA</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="COHEN, W. W.">
      <data key="d0">PERSON</data>
      <data key="d1">W. W. Cohen is an author who contributed to the development of HotpotQA</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SALAKHUTDINOV, R.">
      <data key="d0">PERSON</data>
      <data key="d1">R. Salakhutdinov is an author who contributed to the development of HotpotQA</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="EMNLP">
      <data key="d0">CONFERENCE</data>
      <data key="d1">The Conference on Empirical Methods in Natural Language Processing, where research related to natural language processing is presented</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">CONFERENCE</data>
    </node>
    <node id="YAO, J.-G.">
      <data key="d0">PERSON</data>
      <data key="d1">J.-G. Yao is an author who contributed to the research on recent advances in document summarization</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WAN, X.">
      <data key="d0">PERSON</data>
      <data key="d1">X. Wan is an author who contributed to the research on recent advances in document summarization</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XIAO, J.">
      <data key="d0">PERSON</data>
      <data key="d1">J. Xiao is an author who contributed to the research on recent advances in document summarization</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DOCUMENT SUMMARIZATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The process of creating a concise and coherent summary of a longer text document</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="KNOWLEDGE AND INFORMATION SYSTEMS">
      <data key="d0">PUBLICATION</data>
      <data key="d1">A journal that publishes research on knowledge and information systems</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PUBLICATION</data>
    </node>
    <node id="YAO, L.">
      <data key="d0">PERSON</data>
      <data key="d1">L. Yao is an author who contributed to the research on causal graph discovery with retrieval-augmented generation based large language modelsL. Yao is an author who contributed to the research on exploring large language models for knowledge graph completion</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PENG, J.">
      <data key="d0">PERSON</data>
      <data key="d1">J. Peng is an author who contributed to the research on exploring large language models for knowledge graph completion</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MAO, C.">
      <data key="d0">PERSON</data>
      <data key="d1">C. Mao is an author who contributed to the research on exploring large language models for knowledge graph completion</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LUO, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Luo is an author who contributed to the research on exploring large language models for knowledge graph completion</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KNOWLEDGE GRAPH COMPLETION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The process of filling in missing information in a knowledge graph</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="ZHANG, J.">
      <data key="d0">PERSON</data>
      <data key="d1">J. Zhang is an author who contributed to the development of Graph-toolformer</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHANG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Zhang is an author who contributed to the research on causal graph discovery with retrieval-augmented generation based large language models</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GAN, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Gan is an author who contributed to the research on causal graph discovery with retrieval-augmented generation based large language models</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WANG, C.">
      <data key="d0">PERSON</data>
      <data key="d1">C. Wang is an author who contributed to the research on causal graph discovery with retrieval-augmented generation based large language models</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CAUSAL GRAPH DISCOVERY">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The process of identifying causal relationships between variables using graph-based methods</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="ZHENG, L.">
      <data key="d0">PERSON</data>
      <data key="d1">L. Zheng is an author who contributed to the research on judging large language models as a judge with MT-Bench and Chatbot Arena</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHIANG, W.-L.">
      <data key="d0">PERSON</data>
      <data key="d1">W.-L. Chiang is an author who contributed to the research on judging large language models as a judge with MT-Bench and Chatbot Arena</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHENG, Y.">
      <data key="d0">PERSON</data>
      <data key="d1">Y. Sheng is an author who contributed to the research on judging large language models as a judge with MT-Bench and Chatbot Arena</data>
      <data key="d2">d4c8ce26fd0f9a7bc6dad0efa1ce98e3</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GENERATIVE TEACHING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Generative Teaching refers to the process of using synthetic data created by powerful models to teach a new skill or behavior to another model.
A methodology for generating abundant amounts of diverse, challenging, and high-quality data to teach a particular skill to an AI model
Generative Teaching is a technique aimed at teaching skills rather than generating data to meet specific benchmarks, evidenced by enhancements across various mathematical datasets</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="SYNTHETIC DATA">
      <data key="d0">DATA TYPE</data>
      <data key="d1">Synthetic data is artificially generated data used to accelerate the development of language models. It varies in quality and diversity and often requires significant human effort in curation.
Data generated artificially using techniques like AgentInstruct, which may have limitations such as extensibility, accuracy, cost, bias, validation, and dependency on seed data</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,ab04427ae0415a1c812a35cf8d3ee1a2</data>
      <data key="d3">DATA TYPE</data>
    </node>
    <node id="MISTRAL-7B">
      <data key="d0">MODEL</data>
      <data key="d1">Mistral-7b is a base language model that was post-trained using synthetic data generated by AgentInstruct.
A base model that was fine-tuned using the synthetic dataset created by AgentInstruct</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="ORCA-3">
      <data key="d0">MODEL</data>
      <data key="d1">Orca-3 is the resulting model from post-training Mistral-7b with synthetic data generated by AgentInstruct, showing significant improvements across various benchmarks.
The fine-tuned version of the Mistral-7B model, which shows significant improvement over other instruction-tuned models
A model trained using approximately 25.8 million paired instructions, including data from Orca-1, Orca-2, Orca-Math, and other sources
An advanced model evaluated using the Orca-Bench dataset, showing notable enhancement in capabilities and scoring 9.55 on average
Orca-3 is a model evaluated on various benchmarks, showing performance improvements over other baseline models.
Orca-3 is a model that has shown significant improvements over Orca 2.5 and Mistral-Instruct-7B in various benchmarks, including reading comprehension and math problem-solving tasks
A model whose performance is influenced by the distribution of its tuning data, potentially limiting its accuracy in underrepresented areas</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635,dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="AGIEVAL">
      <data key="d0">BENCHMARK</data>
      <data key="d1">AGIEval is a benchmark used to evaluate the performance of language models, where Orca-3 showed a 40% improvement over Mistral-7b-Instruct.
A benchmark used to evaluate the performance of the fine-tuned Mistral model (Orca-3)
A benchmark used to evaluate the performance of various models, with Orca-3 scoring 56.80
AGIEval is a human-centric benchmark that evaluates a model&#8217;s abilities in tasks pertinent to human cognition and problem-solving, including standardized exams like SAT and LSAT.
AGIEval is a benchmark used to evaluate the performance of models on various tasks, including reading comprehension and math problem-solving</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="MMLU">
      <data key="d0">BENCHMARK</data>
      <data key="d1">MMLU is a benchmark used to evaluate the performance of language models, where Orca-3 showed a 19% improvement over Mistral-7b-Instruct.
A benchmark used to evaluate the performance of the fine-tuned Mistral model (Orca-3)
A benchmark used to evaluate the performance of various models, with Orca-3 scoring 69.95
Massive Multitask Language Understanding (MMLU) is a benchmark that measures a model&#8217;s multitask understanding across 57 academic subjects, including general and specialized knowledge.
MMLU is a benchmark used to evaluate the performance of models on various mathematical tasks, including abstract algebra and college-level mathematics</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="GSM8K">
      <data key="d0">BENCHMARK</data>
      <data key="d1">GSM8K is a benchmark used to evaluate the performance of language models, where Orca-3 showed a 54% improvement over Mistral-7b-Instruct.
A benchmark used to evaluate the performance of the fine-tuned Mistral model (Orca-3)
A benchmark used to evaluate the performance of various models, with Orca-3 scoring 83.09
Grade School Math 8K (GSM8K) is a dataset of high-quality, diverse grade school math word problems requiring between 2 and 8 steps to solve.
GSM8K is a benchmark used to evaluate the performance of models on math problem-solving tasks
A dataset consisting of math-based questions used for evaluating model performance</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="BBH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">BBH is a benchmark used to evaluate the performance of language models, where Orca-3 showed a 38% improvement over Mistral-7b-Instruct.
A benchmark used to evaluate the performance of the fine-tuned Mistral model (Orca-3)
A benchmark used to evaluate the performance of various models, with Orca-3 scoring 61.83
Big Bench Hard (BBH) is a set of 23 tasks selected from the broader Big-Bench benchmark, requiring complex, multi-step reasoning.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="ALPACAEVAL">
      <data key="d0">BENCHMARK</data>
      <data key="d1">AlpacaEval is a benchmark used to evaluate the performance of language models, where Orca-3 showed a 45% improvement over Mistral-7b-Instruct.
A benchmark used to evaluate the performance of the fine-tuned Mistral model (Orca-3)
A benchmark used to evaluate the performance of various models, with Orca-3 scoring 24.80
AlpacaEval is a benchmark specifically designed for chat-based language models to assess their abilities in instruction-following tasks.
An automatic evaluator of instruction-following models, as described in the 2023 paper
A benchmark measuring win-rates, i.e., the number of times GPT-4-turbo prefers the outputs of the evaluated model over a reference answer</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,3d1f6634f93f8a4c296dc8df7e59859e,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="LLAMA-8B-INSTRUCT">
      <data key="d0">MODEL</data>
      <data key="d1">LLAMA-8B-Instruct is another language model that Orca-3 consistently outperforms.
Another model that was outperformed by the fine-tuned Mistral model (Orca-3)</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="GPT-3.5-TURBO">
      <data key="d0">MODEL</data>
      <data key="d1">GPT-3.5-turbo is another language model that Orca-3 consistently outperforms.
A baseline model evaluated using the Orca-Bench dataset
GPT-3.5-turbo is a model whose scores for GSM8K are referenced in the text.
GPT-3.5-turbo is a version of the GPT-3 model, used as a baseline for comparison in various performance evaluations
GPT-3.5-turbo is a language model used for comparison in performance evaluations
A variant of the GPT-3 model developed by OpenAI, evaluated on the MIRAGE datasets using CoT and RAG techniques</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="INSTRUCTION-TUNING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Instruction-tuning is a technique used in the training of language models, involving the use of synthetic data to improve model performance.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="RLHF">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Reinforcement Learning from Human Feedback (RLHF) is a technique used in the training of language models, involving the use of human feedback to improve model performance.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="MODEL COLLAPSE">
      <data key="d0">CONCEPT</data>
      <data key="d1">Model collapse refers to the phenomenon where models gradually degenerate as a result of being trained on synthetic data generated by other models.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="MULTIAGENT WORKFLOWS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Multiagent workflows involve the use of multiple agents to generate high-quality data through reflection, iteration, and the use of tools, surpassing the capabilities of the underlying LLMs.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="PROMPTS">
      <data key="d0">DATA TYPE</data>
      <data key="d1">Prompts are initial inputs used to generate responses in the process of creating synthetic data for training language models.
Initial inputs used to generate responses in the data generation process</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
      <data key="d3">DATA TYPE</data>
    </node>
    <node id="RESPONSES">
      <data key="d0">DATA TYPE</data>
      <data key="d1">Responses are the outputs generated in response to prompts in the process of creating synthetic data for training language models.
Outputs generated in response to prompts during the data generation process</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
      <data key="d3">DATA TYPE</data>
    </node>
    <node id="TOOLS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Tools such as search APIs, calculators, and code interpreters are used in multiagent workflows to address limitations of LLMs and improve data generation.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="POST-TRAINING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Post-training is a stage in the training of language models where additional data is used to teach new skills or behaviors to an already trained model.)("relationship"Post-training is a stage in the training of language models where additional data is used to teach new skills or behaviors to an already trained model.
The phase of training a model after its initial training, often involving fine-tuning with additional data</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="AGENTINSTRUCT">
      <data key="d0" />
      <data key="d1">
An agentic solution for Generative Teaching that focuses on creating demonstration and feedback data using raw documents as input
A method used to generate instruction data from unstructured content, aimed at teaching various skills
A system designed to synthesize a large and diverse corpus of data with varying degrees of difficulty, aiming to create a challenging dataset for baseline models
AgentInstruct is a targeted training technique used to improve reading comprehension capabilities in models like Mistral.
AgentInstruct is a technique used to enhance the proficiency of models like Mistral across various difficulties, including elementary to college-level math
AgentInstruct is an approach that successfully reduced hallucinations by 31.34% while maintaining a quality level comparable to GPT4
A method that reduces human expertise required for data generation and enables creating high-quality synthetic data at scale
A generative teaching approach that uses agentic flows for synthetic data generation to improve model post-training</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635,dd9a46950237e49ef9b1c7ef08e08d42</data>
    </node>
    <node id="TEXT EDITING">
      <data key="d0">SKILL</data>
      <data key="d1">Text editing is one of the skills that the dataset created by AgentInstruct aims to teach language models.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="CREATIVE WRITING">
      <data key="d0">SKILL</data>
      <data key="d1">Creative writing is one of the skills that the dataset created by AgentInstruct aims to teach language models.
A skill covered in the synthetic post-training dataset created by AgentInstruct
Creative writing involves crafting original content, often with a focus on narrative, character development, and imaginative expression</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TOOL USAGE">
      <data key="d0">SKILL</data>
      <data key="d1">Tool usage is one of the skills that the dataset created by AgentInstruct aims to teach language models.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="CODING">
      <data key="d0">SKILL</data>
      <data key="d1">Coding is one of the skills that the dataset created by AgentInstruct aims to teach language models.
Coding involves writing, understanding, debugging code, and writing test cases
Involves writing code following instructions, understanding code, debugging code, tracing or writing test cases</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,6fe27f9eb76cf2ddf712a2cee5783d1c,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="READING COMPREHENSION">
      <data key="d0">SKILL</data>
      <data key="d1">Reading comprehension is one of the skills that the dataset created by AgentInstruct aims to teach language models.
Reading comprehension is the ability to understand, process, and interpret written text, necessary for learning and encompassing decoding, fluency, and vocabulary knowledge
A critical skill involving processing and understanding text, necessary for learning and encompassing decoding, fluency, and vocabulary knowledge
Reading comprehension is a crucial capability for language models, especially for Small Language Models (SLMs), and is evaluated using various benchmarks like DROP and LSAT.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,6fe27f9eb76cf2ddf712a2cee5783d1c,86f77e15d41cbd0cb33f635ccb2cb66b,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="SEARCH APIS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Search APIs are tools used in multiagent workflows to enhance the data generation process by providing access to external information.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="CALCULATORS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Calculators are tools used in multiagent workflows to enhance the data generation process by performing mathematical computations.</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </node>
    <node id="CODE INTERPRETERS">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">Code interpreters are tools used in multiagent workflows to enhance the data generation process by executing and interpreting code.)("relationship"
Tools used by AgentInstruct to generate high-quality data</data>
      <data key="d2">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="RAW DOCUMENTS">
      <data key="d0">DATA SOURCE</data>
      <data key="d1">Unstructured text documents or source code used as seeds for generating synthetic data</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
      <data key="d3">DATA SOURCE</data>
    </node>
    <node id="GPT-3.5">
      <data key="d0">MODEL</data>
      <data key="d1">Another model that was outperformed by the fine-tuned Mistral model (Orca-3)</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="SYNTHETIC-DATA-GENERATION-AS-A-SERVICE">
      <data key="d0">SERVICE</data>
      <data key="d1">A proposed service for generating data for post-training and fine-tuning using raw materials</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
      <data key="d3">SERVICE</data>
    </node>
    <node id="CONTENT TRANSFORMATION AGENTS">
      <data key="d0">AGENTS</data>
      <data key="d1">Agents used to transform raw seeds into content during the data generation process</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
      <data key="d3">AGENTS</data>
    </node>
    <node id="INSTRUCTION CREATION AGENTS">
      <data key="d0">AGENTS</data>
      <data key="d1">Agents used to create a diverse set of instructions from transformed seeds</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
      <data key="d3">AGENTS</data>
    </node>
    <node id="REFINEMENT AGENTS">
      <data key="d0">AGENTS</data>
      <data key="d1">Agents used to iteratively refine the complexity and quality of seed instructions</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
      <data key="d3">AGENTS</data>
    </node>
    <node id="AGENTIC FLOWS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Automated processes used to generate data at scale, ensuring diversity and complexity

Flows created to enable different skills in models, requiring human effort for construction</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf,f7eb89a70f544664546a510e46d5febd</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="REASONING">
      <data key="d0">SKILL</data>
      <data key="d1">A skill covered in the synthetic post-training dataset created by AgentInstruct</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="MATH">
      <data key="d0">SKILL</data>
      <data key="d1">A skill covered in the synthetic post-training dataset created by AgentInstruct</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="TOOL USE">
      <data key="d0">SKILL</data>
      <data key="d1">A skill covered in the synthetic post-training dataset created by AgentInstruct
Tool use involves the employment of functions or APIs to perform tasks or solve problems
Involves the manipulation of tools to achieve goals, referring to the ability of an AI system to use available resources or auxiliary systems to solve complex tasks
The task of enabling models to interact with external tools or services via APIs</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,427e98b00e49b6a8f8649054122dd45b,b88745a13b69cecbc0ee9c3af41389bf,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="DATA GENERATION WORKFLOWS">
      <data key="d0">PROCESS</data>
      <data key="d1">Workflows that enable automation of data generation, reducing or eliminating the need for human intervention</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="DATA FILTERING">
      <data key="d0">PROCESS</data>
      <data key="d1">A process applied by AgentInstruct to ensure the quality of generated data</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="VERIFICATION">
      <data key="d0">PROCESS</data>
      <data key="d1">A process applied by AgentInstruct to ensure the accuracy of generated data</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="REFLECTION FLOWS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Flows used by agents in AgentInstruct to improve the quality of generated responses</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="SEARCH">
      <data key="d0">TOOL</data>
      <data key="d1">A tool used by AgentInstruct to generate high-quality data
A scenario enabled by reading comprehension where information is sought and found in text</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="TAXONOMY">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A classification system used by AgentInstruct to create diverse and high-quality prompts and responses</data>
      <data key="d2">b88745a13b69cecbc0ee9c3af41389bf</data>
    </node>
    <node id="CONTENT TRANSFORMATION FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">Content Transformation Flow converts the raw seed into an intermediate representation that simplifies the creation of instructions tailored to specific objectives
A system designed to transform arbitrary articles into well-crafted pieces conducive to the formulation of a wide array of reading comprehension question types
A process that involves synthesizing API descriptions from source code snippets or other seeds</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,427e98b00e49b6a8f8649054122dd45b,f7eb89a70f544664546a510e46d5febd</data>
      <data key="d3">PROCESS</data>
    </node>
    <node id="SEED INSTRUCTION GENERATION FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">Seed Instruction Generation Flow creates instances of the target tasks following a taxonomy and introduces diversity by generating a set of diverse instructions
A process involving the compilation of 43 types of reading comprehension questions, targeting various comprehension skills.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,f7eb89a70f544664546a510e46d5febd</data>
      <data key="d3">PROCESS</data>
    </node>
    <node id="INSTRUCTION REFINEMENT FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">Instruction Refinement Flow iteratively enhances the complexity and quality of instructions by using Suggester-Editor Agents
A process involving suggester-editor agents to refine (passage, question) pairs by modifying passages, questions, or answer choices.
A process that involves refining instructions by incorporating suggestions and edits from a suggester-editor pair</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,427e98b00e49b6a8f8649054122dd45b,f7eb89a70f544664546a510e46d5febd</data>
      <data key="d3">PROCESS</data>
    </node>
    <node id="SUGGESTER-EDITOR AGENTS">
      <data key="d0">AGENTS</data>
      <data key="d1">Suggester-Editor Agents are used in the Instruction Refinement Flow to propose and modify instructions to increase their intricacy, making them more complex, unsolvable, or tricky
Agents that refine (passage, question) pairs by making them unanswerable, altering answers, or adding complexity.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,f7eb89a70f544664546a510e46d5febd</data>
      <data key="d3">AGENTS</data>
    </node>
    <node id="AGENT">
      <data key="d0">AGENT</data>
      <data key="d1">An agent is powered by an LLM and can optionally use tools such as search APIs, code interpreter, or a calculator, with a specific role and set of instructions</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
      <data key="d3">AGENT</data>
    </node>
    <node id="QUESTION ANSWERING">
      <data key="d0">SKILL</data>
      <data key="d1">Open domain question answering involves generating responses to questions over a wide range of topics, without being restricted to a specific domain
A scenario enabled by reading comprehension where questions are answered based on text</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
      <data key="d3">SKILL</data>
    </node>
    <node id="TEXT MODIFICATION">
      <data key="d0">SKILL</data>
      <data key="d1">Text modification involves changing existing text to improve its quality, modify its tone, or fit a specific context or audience
The process of editing and refining written content to enhance quality, effectiveness, or alter attributes.
</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d,5819b66e04fd77fa705574edc49395bb,f7eb89a70f544664546a510e46d5febd</data>
      <data key="d3">SKILL</data>
    </node>
    <node id="WEB AGENT">
      <data key="d0">AGENT</data>
      <data key="d1">A web agent is a software program that autonomously performs tasks on the web, such as where to click and how much to scroll</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
      <data key="d3">AGENT</data>
    </node>
    <node id="BRAIN TEASER">
      <data key="d0">TASK</data>
      <data key="d1">A brain teaser is a problem or puzzle requiring thought to solve, often used for amusement or training logical thinking and problem-solving skills</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
      <data key="d3">TASK</data>
    </node>
    <node id="ANALYTICAL REASONING">
      <data key="d0">SKILL</data>
      <data key="d1">Analytical reasoning involves the ability to look at information, discern patterns, and draw logical conclusions about relationships within the information</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
      <data key="d3">SKILL</data>
    </node>
    <node id="MULTIPLE CHOICE QUESTIONS">
      <data key="d0">TASK</data>
      <data key="d1">Multiple choice questions are a form of assessment where respondents select the best possible answer from a list of choices
A method where models are evaluated in an open-ended generation setting with an empty system message, and GPT-4 is used for extraction of the option selected by the model from the model&#8217;s response</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb,f7eb89a70f544664546a510e46d5febd</data>
      <data key="d3">TASK</data>
    </node>
    <node id="DATA TO TEXT">
      <data key="d0">TASK</data>
      <data key="d1">Data-to-text refers to generating human-readable textual summaries from source data, used for reports, explanations, or narratives</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
      <data key="d3">TASK</data>
    </node>
    <node id="FERMI PROBLEMS">
      <data key="d0">TASK</data>
      <data key="d1">Fermi problems are estimation problems that seek quick, rough estimates of quantities, often requiring justified guesses or assumptions</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
      <data key="d3">TASK</data>
    </node>
    <node id="TEXT EXTRACTION">
      <data key="d0">TASK</data>
      <data key="d1">Text extraction is the process of retrieving relevant information from a larger text document, including tasks like named entity recognition and keyword extraction
The process of retrieving relevant information from a larger text document, including tasks like named entity recognition, keyword extraction, or extracting specific data fields from unstructured text</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
      <data key="d3">TASK</data>
    </node>
    <node id="RETRIEVAL AUGMENTED GENERATION">
      <data key="d0">SKILL</data>
      <data key="d1">Retrieval augmented generation combines information retrieval with text generation to improve the quality and relevance of generated content
A method used in natural language processing that combines retrieval-based and generative models to generate responses by first retrieving relevant documents and then using these documents to generate a response</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="WEB CONTROL">
      <data key="d0">SKILL</data>
      <data key="d1">Web control involves managing and automating interactions with web interfaces, such as navigating websites and performing online tasks</data>
      <data key="d2">f7eb89a70f544664546a510e46d5febd</data>
    </node>
    <node id="TEXT CLASSIFICATION">
      <data key="d0">PROCESS</data>
      <data key="d1">A type of machine learning task where text documents are automatically classified into predefined categories, used for spam detection, sentiment analysis, and topic labeling among others</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="CREATIVE CONTENT GENERATION">
      <data key="d0">ACTIVITY</data>
      <data key="d1">Involves the creation of original content, often involving elements of novelty, value, and surprise, such as generating text, music, or images that are new, meaningful, and interesting</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="FEW SHOT REASONING">
      <data key="d0">CONCEPT</data>
      <data key="d1">Refers to the ability of a machine learning model to understand new concepts, patterns, or tasks with minimal examples or guidance, mimicking the human ability to learn quickly from few examples</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="CONVERSATION">
      <data key="d0">ACTIVITY</data>
      <data key="d1">Refers to conversational agents or chatbots that interact with humans in a natural, human-like manner</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="AGENTINSTRUCT FLOW">
      <data key="d0">SYSTEM</data>
      <data key="d1">A system implemented for various capabilities, including reading comprehension</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="ARGUMENT PASSAGE GENERATOR">
      <data key="d0">TOOL</data>
      <data key="d1">A tool within the Content Transformation Flow that generates argument passages from seed articles</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="URIC ACID">
      <data key="d0">SUBSTANCE</data>
      <data key="d1">A substance produced naturally by the breakdown of purine, which can form crystals in the body causing pain and other issues when in excess
</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="HYPERURICEMIA">
      <data key="d0">CONDITION</data>
      <data key="d1">A condition characterized by high levels of uric acid in the blood, which may increase the risk of cardiovascular disease
A condition characterized by high levels of uric acid in the blood, which can increase the risk of cardiovascular disease.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="HYPOURICEMIA">
      <data key="d0">CONDITION</data>
      <data key="d1">A condition characterized by low levels of uric acid, which is less common and usually does not present symptoms but can indicate underlying kidney or liver issues
A condition characterized by low levels of uric acid in the blood, usually asymptomatic but can indicate underlying kidney or liver issues.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="PURINE">
      <data key="d0">SUBSTANCE</data>
      <data key="d1">A type of dietary protein that, when broken down, produces uric acid</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="CARDIOVASCULAR DISEASE">
      <data key="d0">CONDITION</data>
      <data key="d1">A class of diseases that involve the heart or blood vessels, which may be associated with high levels of uric acid
A class of diseases that involve the heart or blood vessels, potentially linked to high levels of uric acid.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="LSAT LOGICAL REASONING TEST">
      <data key="d0">TEST</data>
      <data key="d1">A test featuring specialized question categories, including assumption, strengthening/weakening, flaw, and inference questions</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="LABORATORY BLOOD AND URINE TESTS">
      <data key="d0">TEST</data>
      <data key="d1">Tests required to diagnose conditions like hyperuricemia and hypouricemia
Tests required to diagnose conditions related to uric acid levels, such as hyperuricemia and hypouricemia.</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="NAMED ENTITY RECOGNITION">
      <data key="d0" />
      <data key="d1">A task within text extraction that involves identifying and classifying named entities in text</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
      <data key="d3">PROCESS</data>
    </node>
    <node id="KEYWORD EXTRACTION">
      <data key="d0" />
      <data key="d1">A task within text extraction that involves identifying and extracting important keywords from text</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
      <data key="d3">PROCESS</data>
    </node>
    <node id="DATA FIELDS">
      <data key="d0" />
      <data key="d1">Specific pieces of information extracted from unstructured text during text extraction</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
      <data key="d3">PROCESS</data>
    </node>
    <node id="SPAM DETECTION">
      <data key="d0" />
      <data key="d1">An application of text classification used to identify and filter out spam messages</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
      <data key="d3">PROCESS</data>
    </node>
    <node id="SENTIMENT ANALYSIS">
      <data key="d0" />
      <data key="d1">An application of text classification used to determine the sentiment expressed in a text</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
      <data key="d3">PROCESS</data>
    </node>
    <node id="TOPIC LABELING">
      <data key="d0" />
      <data key="d1">An application of text classification used to assign topics to text documents</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
      <data key="d3">PROCESS</data>
    </node>
    <node id="NATURAL LANGUAGE PROCESSING">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
    </node>
    <node id="RETRIEVAL-BASED MODELS">
      <data key="d0" />
      <data key="d1">Models used in retrieval augmented generation to retrieve relevant documents</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="GENERATIVE MODELS">
      <data key="d0" />
      <data key="d1">Models used in retrieval augmented generation to generate responses based on retrieved documents</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
      <data key="d3">TECHNOLOGY</data>
    </node>
    <node id="DECODING">
      <data key="d0" />
      <data key="d1">A component of reading comprehension involving the ability to interpret and make sense of text</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
      <data key="d3">SKILL</data>
    </node>
    <node id="FLUENCY">
      <data key="d0" />
      <data key="d1">A component of reading comprehension involving the ability to read text smoothly and accurately</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
      <data key="d3">SKILL</data>
    </node>
    <node id="VOCABULARY KNOWLEDGE">
      <data key="d0" />
      <data key="d1">A component of reading comprehension involving the understanding of word meanings</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
      <data key="d3">SKILL</data>
    </node>
    <node id="GROUNDED REASONING">
      <data key="d0" />
      <data key="d1">A scenario enabled by reading comprehension involving reasoning based on text</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
      <data key="d3">ACTIVITY</data>
    </node>
    <node id="ASSUMPTION QUESTIONS">
      <data key="d0" />
      <data key="d1">A type of question featured in the LSAT Logical Reasoning test that involves identifying assumptions</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
      <data key="d3">PROCESS</data>
    </node>
    <node id="STRENGTHENING/WEAKENING QUESTIONS">
      <data key="d0" />
      <data key="d1">A type of question featured in the LSAT Logical Reasoning test that involves strengthening or weakening arguments</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
      <data key="d3">PROCESS</data>
    </node>
    <node id="FLAW QUESTIONS">
      <data key="d0" />
      <data key="d1">A type of question featured in the LSAT Logical Reasoning test that involves identifying flaws in arguments</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
      <data key="d3">PROCESS</data>
    </node>
    <node id="INFERENCE QUESTIONS">
      <data key="d0" />
      <data key="d1">A type of question featured in the LSAT Logical Reasoning test that involves making inferences from text</data>
      <data key="d2">0c212c1467564ad33330b1f655a8e27e</data>
      <data key="d3">PROCESS</data>
    </node>
    <node id="READING COMPREHENSION QUESTIONS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Questions designed to assess different levels of comprehension, including literal, critical, and evaluative comprehension.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="AGENTS">
      <data key="d0">SYSTEM COMPONENT</data>
      <data key="d1">Defined entities targeting specific categories of comprehension questions, generating questions based on predefined types.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
      <data key="d3">SYSTEM COMPONENT</data>
    </node>
    <node id="CONTENT TRANSFORMATION AGENT">
      <data key="d0">SYSTEM COMPONENT</data>
      <data key="d1">An agent that determines which subset of question-generating agents to engage based on the content.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
      <data key="d3">SYSTEM COMPONENT</data>
    </node>
    <node id="PASSAGE-QUESTION PAIRS">
      <data key="d0">DATA</data>
      <data key="d1">Pairs of text passages and corresponding questions generated for use in subsequent stages of the process.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
      <data key="d3">DATA</data>
    </node>
    <node id="TEXT MODIFICATION TASKS">
      <data key="d0">TASK</data>
      <data key="d1">Tasks such as paraphrasing, expansion, simplification, redacting, styling, and code switching, aimed at modifying text.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
      <data key="d3">TASK</data>
    </node>
    <node id="PARAPHRASING AGENT">
      <data key="d0">SYSTEM COMPONENT</data>
      <data key="d1">An agent that takes a piece of text and creates paraphrased versions as part of text modification tasks.An agent that takes a piece of text and creates paraphrased versions as part of text modification tasks.)("relationship"</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
      <data key="d3">SYSTEM COMPONENT</data>
    </node>
    <node id="KIDNEY OR LIVER ISSUES">
      <data key="d0" />
      <data key="d1">Underlying health problems that can be indicated by low levels of uric acid.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
      <data key="d3">CONDITION</data>
    </node>
    <node id="LIFESTYLE CHOICES">
      <data key="d0">FACTOR</data>
      <data key="d1">Choices such as alcohol consumption and physical inactivity that can affect uric acid levels.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="APPENDIX A">
      <data key="d0">DOCUMENT SECTION</data>
      <data key="d1">A section in the document that lists types of reading comprehension questions and text modification tasks.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="STRENGTHEN TYPE QUESTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">A type of question designed to assess the ability to identify information that strengthens an argument.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="HYPOTHETICAL STUDY">
      <data key="d0">DATA</data>
      <data key="d1">A suggested study or finding used to add complexity to a question by requiring inference.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="GENETIC PREDISPOSITION">
      <data key="d0">FACTOR</data>
      <data key="d1">A suggested genetic factor that could be correlated with increased cardiovascular events and hyperuricemia.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="DISTRACTOR OPTION">
      <data key="d0">QUESTION COMPONENT</data>
      <data key="d1">An answer choice designed to confuse the test-taker by appearing relevant but not directly related to the question.</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="EDITOR AGENT">
      <data key="d0">SYSTEM COMPONENT</data>
      <data key="d1">An agent that modifies passages, questions, or answer choices to refine the (passage, question) pairs.)("relationship"</data>
      <data key="d2">1d8835c0ce90e56be22873bcf2740a5d</data>
    </node>
    <node id="SEED INSTRUCTION">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">An initial instruction used to generate tasks, such as rewriting event details in a more casual tone</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
      <data key="d3">INSTRUCTION</data>
    </node>
    <node id="RANDOM SEED">
      <data key="d0">CONCEPT</data>
      <data key="d1">A randomly selected element used to initiate a process, such as generating a seed instruction</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="UNIVERSITY OF IOWA">
      <data key="d0">LOCATION</data>
      <data key="d1">The location of the event mentioned in the text, specifically in Iowa City, USA</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
      <data key="d3">LOCATION</data>
    </node>
    <node id="FINANCIALIZATION">
      <data key="d0">CONCEPT</data>
      <data key="d1">A broad concept describing the increasing social impact and interconnection of financial discourses, markets, actors, and institutions</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="NATASCHA VAN DER ZWAN">
      <data key="d0">PERSON</data>
      <data key="d1">A researcher who identifies three distinct research streams that approach financialization</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANTHROPOLOGICAL SKEPTICS">
      <data key="d0">GROUP</data>
      <data key="d1">A group of anthropologists who argue that finance has a longer genealogy than recognized by financialization literature</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
      <data key="d3">GROUP</data>
    </node>
    <node id="SUPPLY CHAINS OF FINANCIAL PRODUCTS">
      <data key="d0">CONCEPT</data>
      <data key="d1">The networks that connect different places and political projects across the globe through financial instruments</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="AMERICAN ANTHROPOLOGICAL ASSOCIATION">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">An organization that hosts the SEA 2017 Annual Meeting and provides a platform for submitting abstracts</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="SEA 2017 ANNUAL MEETING">
      <data key="d0">EVENT</data>
      <data key="d1">An annual meeting organized by the American Anthropological Association, held in April 2017 at the University of Iowa</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
      <data key="d3">EVENT</data>
    </node>
    <node id="SUGGESTER-EDITOR PAIR">
      <data key="d0">AGENT</data>
      <data key="d1">A duo responsible for increasing the complexity of generated instructions by providing suggestions and edits</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
      <data key="d3">AGENT</data>
    </node>
    <node id="API RETRIEVAL AGENT">
      <data key="d0">AGENT</data>
      <data key="d1">An agent that searches for similar code to expand the list of APIs</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
      <data key="d3">AGENT</data>
    </node>
    <node id="VIEW ALL FOOD ITEMS">
      <data key="d0">API</data>
      <data key="d1">An API that enables clients to obtain a detailed list of food items, complete with nutritional profiles</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
      <data key="d3">API</data>
    </node>
    <node id="SEARCH FOOD ITEMS">
      <data key="d0">API</data>
      <data key="d1">An API that allows clients to search for food items by name and retrieve a list of matching items
</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,427e98b00e49b6a8f8649054122dd45b</data>
      <data key="d3">API</data>
    </node>
    <node id="LIBRARY RECONSTRUCTION">
      <data key="d0">SCENARIO</data>
      <data key="d1">A scenario in which a content transformation flow is used to reconstruct a list of APIs from a given seedA scenario in which a content transformation flow is used to reconstruct a list of APIs from a given seed)("relationship"</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
      <data key="d3">SCENARIO</data>
    </node>
    <node id="APRIL 6-8, 2017">
      <data key="d0">DATE</data>
      <data key="d1">The dates on which the SEA 2017 Annual Meeting was held</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="DECEMBER 1, 2016">
      <data key="d0">DATE</data>
      <data key="d1">The deadline for submitting abstracts for the SEA 2017 Annual Meeting</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="MEETING REGISTRATION">
      <data key="d0">TASK</data>
      <data key="d1">The process of registering for the SEA 2017 Annual Meeting through the American Anthropological Association's website</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="INSTRUCTION 1">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">An instruction to rewrite event details in a casual and colloquial language, incorporating a fictional narrative</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="INSTRUCTION 2">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">An instruction to transform event details into a light-hearted poem with rhyming couplets</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="INSTRUCTION 3">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">An instruction to craft a social media post with event details using internet slang, emojis, and a casual tone</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SUGGESTION 1">
      <data key="d0">SUGGESTION</data>
      <data key="d1">A suggestion to incorporate a fictional narrative and use a conversational style with colloquial language and humor</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SUGGESTION 2">
      <data key="d0">SUGGESTION</data>
      <data key="d1">A suggestion to translate event details into a poetic format with rhyming couplets</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="SUGGESTION 3">
      <data key="d0">SUGGESTION</data>
      <data key="d1">A suggestion to frame event details as a social media post using internet slang and emojis</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="API DESCRIPTION">
      <data key="d0">DESCRIPTION</data>
      <data key="d1">A detailed description of an API, including its name, purpose, and parameters</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="NUTRITIONAL PROFILES">
      <data key="d0">DATA</data>
      <data key="d1">Information about the nutritional content of food items, such as calorie count, protein, and fat)("relationship"</data>
      <data key="d2">427e98b00e49b6a8f8649054122dd45b</data>
    </node>
    <node id="GET FOOD ITEM DETAILS">
      <data key="d0">API</data>
      <data key="d1">Provides detailed information about a specific food item</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
      <data key="d3">API</data>
    </node>
    <node id="CREATE MEAL PLAN">
      <data key="d0">API</data>
      <data key="d1">Enables the creation of a meal plan based on specified dietary preferences and caloric goals</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
      <data key="d3">API</data>
    </node>
    <node id="UPDATE FOOD ITEM">
      <data key="d0">API</data>
      <data key="d1">Allows updating the details of an existing food item</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
      <data key="d3">API</data>
    </node>
    <node id="TRACK USER MEAL">
      <data key="d0">API</data>
      <data key="d1">Enables tracking of user meals</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
      <data key="d3">API</data>
    </node>
    <node id="GET DIETARY RECOMMENDATIONS">
      <data key="d0">API</data>
      <data key="d1">Provides dietary recommendations based on user preferences and goals</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
      <data key="d3">API</data>
    </node>
    <node id="ADD NEW FOOD ITEM">
      <data key="d0">API</data>
      <data key="d1">Allows adding a new food item to the database</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
      <data key="d3">API</data>
    </node>
    <node id="DELETE FOOD ITEM">
      <data key="d0">API</data>
      <data key="d1">Enables the deletion of a food item from the database</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
      <data key="d3">API</data>
    </node>
    <node id="GET USER NUTRITIONAL STATS">
      <data key="d0">API</data>
      <data key="d1">Provides nutritional statistics for a user</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
      <data key="d3">API</data>
    </node>
    <node id="SEED INSTRUCTION CREATION FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">A process that consumes a list of APIs and employs various agents to create several types of tasks</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
      <data key="d3">PROCESS</data>
    </node>
    <node id="REFINEMENT FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">A process aimed at increasing the complexity of tasks by suggesting refinements to increase the number of steps required to solve the task</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
      <data key="d3">PROCESS</data>
    </node>
    <node id="AGENT-INSTRUCT FLOW">
      <data key="d0">PROCESS</data>
      <data key="d1">A process that creates multi-turn conversations for task completion</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
      <data key="d3">PROCESS</data>
    </node>
    <node id="SYSTEM MESSAGE">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">A message that provides guidelines for an AI assistant to assist users in achieving their desired outcomes using various APIs
A predefined message used to guide the behavior of a model or system</data>
      <data key="d2">0922646b93a124514ce2a267d961d229,103d98395c393552cc954c89d4e59f50</data>
      <data key="d3">INSTRUCTION</data>
    </node>
    <node id="ASSISTANT">
      <data key="d0">ACTOR</data>
      <data key="d1">The AI assistant responsible for helping the user achieve their goals by utilizing various APIs</data>
      <data key="d2">0922646b93a124514ce2a267d961d229</data>
      <data key="d3">ACTOR</data>
    </node>
    <node id="CALORIC GOAL">
      <data key="d0">GOAL</data>
      <data key="d1">A target of 1500 calories per day for the meal plan</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
      <data key="d3">GOAL</data>
    </node>
    <node id="MEAL PLAN">
      <data key="d0">PLAN</data>
      <data key="d1">A structured plan that includes specific meals for each day, designed to meet dietary preferences and caloric goals</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
      <data key="d3">PLAN</data>
    </node>
    <node id="DAY 1">
      <data key="d0">DAY</data>
      <data key="d1">The first day of the meal plan, which includes specific meals for breakfast, lunch, and dinner</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
      <data key="d3">DAY</data>
    </node>
    <node id="BREAKFAST">
      <data key="d0">MEAL</data>
      <data key="d1">The first meal of the day, which includes oatmeal with fruits and almond milk, totaling 350 calories</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
      <data key="d3">MEAL</data>
    </node>
    <node id="LUNCH">
      <data key="d0">MEAL</data>
      <data key="d1">The second meal of the day, which includes chickpea salad and whole wheat bread, totaling 500 calories</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
      <data key="d3">MEAL</data>
    </node>
    <node id="DINNER">
      <data key="d0">MEAL</data>
      <data key="d1">The third meal of the day, which includes mixed vegetable stir fry and brown rice, totaling 650 calories</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
      <data key="d3">MEAL</data>
    </node>
    <node id="QUINOA SALAD">
      <data key="d0">FOOD ITEM</data>
      <data key="d1">A salad made with quinoa, for which nutritional information is requested to be added to the database</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
      <data key="d3">FOOD ITEM</data>
    </node>
    <node id="CHANA MASALA">
      <data key="d0">FOOD ITEM</data>
      <data key="d1">A dish made with chickpeas, for which the unique identifier (food_id) is requested for updating in the database</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
      <data key="d3">FOOD ITEM</data>
    </node>
    <node id="BUTTER CHICKEN">
      <data key="d0">FOOD ITEM</data>
      <data key="d1">A dish made with chicken, for which the unique identifier (food_id) is requested for removal from the database</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
      <data key="d3">FOOD ITEM</data>
    </node>
    <node id="KNOWLEDGEPILE">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset used as a source for unstructured text and code files in the creation of instruction data</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="AUTOMATHTEXT">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset used as a source for unstructured text and code files in the creation of instruction data
A system for autonomous data selection with language models for mathematical texts</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="OPENSTAX">
      <data key="d0">DATASET</data>
      <data key="d1">A subset of openstax content used as a source for unstructured text and code files in the creation of instruction data</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="APACHE-2.0 LICENSED SOURCE CODE">
      <data key="d0">DATASET</data>
      <data key="d1">A subset of source code files licensed under Apache-2.0, used as a source for unstructured text and code files in the creation of instruction data</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="ORCA-2.5-DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset consisting of approximately 3.8 million paired instructions sourced from Orca-1, Orca-2, Orca-Math, and other publicly available sources</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="MISTRAL-7B-V0.1">
      <data key="d0">MODEL</data>
      <data key="d1">A base model with publicly available weights, finetuned using the AgentInstruct dataset to create Orca-3</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="NVIDIA A100">
      <data key="d0">HARDWARE</data>
      <data key="d1">A type of GPU used in the training process of the model, with 19 nodes or 152 GPUs in total</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
      <data key="d3">HARDWARE</data>
    </node>
    <node id="ADAMW OPTIMIZER">
      <data key="d0">OPTIMIZER</data>
      <data key="d1">An optimization algorithm used in the training process, with an initial learning rate of 8e-6 and a cosine learning rate schedule</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
      <data key="d3">OPTIMIZER</data>
    </node>
    <node id="ORCA-BENCH">
      <data key="d0">DATASET</data>
      <data key="d1">A held-out test set consisting of 100 samples from each of the 17 skills curated using AgentInstruct, used for evaluation
A dataset used to evaluate the performance of various models, scored relative to GPT-4 on a scale from 0 to 10</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="ODQA">
      <data key="d0">CATEGORY</data>
      <data key="d1">Open Domain Question Answering, a category within the Orca-Bench dataset with two test sets: ODQA and Complex ODQA</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
      <data key="d3">CATEGORY</data>
    </node>
    <node id="COMPLEX ODQA">
      <data key="d0">CATEGORY</data>
      <data key="d1">A subset of the ODQA category within the Orca-Bench dataset, consisting of more intricate questions developed during the refinement phaseA subset of the ODQA category within the Orca-Bench dataset, consisting of more intricate questions developed during the refinement phase)("relationship"
</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">CATEGORY</data>
    </node>
    <node id="VEGETARIAN MEAL PLAN">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="DATABASE">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="INSTRUCTION DATA">
      <data key="d0">DATA</data>
      <data key="d1">Data generated from unstructured content to teach various skills, used in the training of models like Orca-3</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="INSTRUCTION TUNING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A method of finetuning models using instruction data to improve their performance on specific tasks
A method for improving the performance of language models by fine-tuning them on specific instructions, as described in the 2023 paper</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a,3d1f6634f93f8a4c296dc8df7e59859e</data>
    </node>
    <node id="TOKENIZATION">
      <data key="d0">PROCESS</data>
      <data key="d1">The process of converting text into tokens, used in the preparation of data for model training</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="LABEL MASKING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A method used during training to ensure that the loss is calculated based only on the response conditioned on the prompt</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="WEIGHT DECAY">
      <data key="d0">HYPERPARAMETER</data>
      <data key="d1">A regularization technique used during training to prevent overfitting, set at 0.1 in the training of Orca-3</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="COSINE LEARNING RATE SCHEDULE">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A method of adjusting the learning rate during training, used in the training of Orca-3</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="LINEAR LEARNING RATE WARM-UP">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A method of gradually increasing the learning rate during the initial steps of training, used in the training of Orca-3</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="EPOCH">
      <data key="d0">TERM</data>
      <data key="d1">A complete pass through the training dataset, with Orca-3 being trained for three epochs</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="TRAINING LOSS">
      <data key="d0">METRIC</data>
      <data key="d1">A measure of the error during training, calculated based on the response conditioned on the prompt</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="MULTI-TURN INTERACTION">
      <data key="d0">TERM</data>
      <data key="d1">A type of interaction involving multiple exchanges, used in some entries within the Orca-Bench dataset)("relationship"</data>
      <data key="d2">09cb89de3b77d765983cff25b7d74a1a</data>
    </node>
    <node id="ORCA-2.5">
      <data key="d0">MODEL</data>
      <data key="d1">A baseline model evaluated using the Orca-Bench dataset, scoring 7.13 on average
Orca-2.5 is a previous version of the Orca language model, used as a baseline for comparison in performance evaluations</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="MISTRAL-INSTRUCT-7B">
      <data key="d0">MODEL</data>
      <data key="d1">A baseline model evaluated using the Orca-Bench dataset, scoring 8.31 on average
Mistral-Instruct-7b is a model referenced in the text, showing a performance improvement in reading comprehension when compared to Mistral.
Mistral-Instruct-7B is a model used as a baseline for comparison in various performance evaluations, including reading comprehension and math problem-solving tasks</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="LLAMA3-8B-INSTRUCT">
      <data key="d0">MODEL</data>
      <data key="d1">A baseline model evaluated using the Orca-Bench dataset
LLAMA3-8B-Instruct is a language model used for comparison in performance evaluations</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="ARC">
      <data key="d0">BENCHMARK</data>
      <data key="d1">A benchmark used to evaluate the performance of various models, with Orca-3 scoring 92.47
The AI2 Reasoning Challenge (ARC) is a benchmark developed by AllenAI to measure reasoning, commonsense knowledge, and deep comprehension abilities of language models.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="GPQA">
      <data key="d0">BENCHMARK</data>
      <data key="d1">A benchmark used to evaluate the performance of various models, with Orca-3 scoring 28.12
Graduate-level Google-Proof Q&amp;A (GPQA) is a challenging benchmark of 448 high-quality, difficult multiple-choice questions created by domain experts in biology, chemistry, and physics.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="DROP">
      <data key="d0">BENCHMARK</data>
      <data key="d1">A benchmark used to evaluate the performance of various models, with Orca-3 scoring 71.14
Discrete Reasoning over Paragraphs (DROP) is a reading comprehension benchmark requiring models to resolve references in questions and perform discrete operations like sorting, counting, and addition.
A reading comprehension benchmark requiring discrete reasoning over paragraphs, as described by Dua et al., 2019
A dataset containing problems with ground-truth answer values used for evaluating model performance</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="FOFO">
      <data key="d0">BENCHMARK</data>
      <data key="d1">A benchmark used to evaluate the performance of various models, with Orca-3 scoring 84.01
Format Following (FoFo) is a benchmark that evaluates a model&#8217;s ability to follow complex, domain-specific formats across various real-world domains.
FoFo is a benchmark used to evaluate the performance of models on format-following tasks
A benchmark to evaluate large language models' format-following capability
A benchmark where evaluation is done using GPT-4 to give a format correctness score between 0 and 1, based on how strictly the model's response follows the format specified in the prompt</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="IFEVAL">
      <data key="d0">BENCHMARK</data>
      <data key="d1">A benchmark used to evaluate the performance of various models, with Orca-3 scoring 49.54
Instruction-Following Evaluation (IFEval) is a benchmark measuring a model&#8217;s ability to follow natural language instructions using a set of 500 prompts covering 25 types of verifiable instructions.
A benchmark that requires checking if the model response follows the verifiable instructions given in the prompt, using code provided by the authors</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="INFOBENCH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">A benchmark used to evaluate the performance of various models, with Orca-3 scoring 84.30
InFoBench is a benchmark that evaluates models' instruction-following capability using a metric called Decomposed Requirements Following Ratio (DRFR).
A system for evaluating instruction-following ability in large language models, as described in the 2024 paper
A benchmark evaluated using GPT-4 to determine if the model response follows the decomposed instruction, using the implementation provided by the creators</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,3d1f6634f93f8a4c296dc8df7e59859e,86f77e15d41cbd0cb33f635ccb2cb66b,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="EQBENCH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">A benchmark used to evaluate the performance of various models, with Orca-3 scoring 91.36
A benchmark used to evaluate emotion scores in conversations</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,bd4eb9459bc29b4c2da4658914fd4635</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="METRIC-V2">
      <data key="d0">METRIC</data>
      <data key="d1">Metric-v2 is a performance metric used to evaluate models, showing a score of 91.36 with a 4% improvement over a previous version.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
      <data key="d3">METRIC</data>
    </node>
    <node id="METRIC-V1">
      <data key="d0">METRIC</data>
      <data key="d1">Metric-v1 is a performance metric used to evaluate models, showing a score of 50.28 with a 28% improvement over a previous version.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
      <data key="d3">METRIC</data>
    </node>
    <node id="MISTRAL-7B-INSTRUCT">
      <data key="d0">MODEL</data>
      <data key="d1">Mistral-7b-Instruct is a model used as a baseline for comparison in performance metrics.
Mistral-7B-Instruct is a language model used as a baseline for comparison in performance evaluations</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,8ee9617c145e19fa95f1f9349bfbe69b</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="LSAT">
      <data key="d0">EXAM</data>
      <data key="d1">The Law School Admission Test (LSAT) is a standardized test considered difficult for human test-takers, used to evaluate reading comprehension in models.
The Law School Admission Test (LSAT) is a standardized test used for law school admissions, known for its challenging reading comprehension sections</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
      <data key="d3">EXAM</data>
    </node>
    <node id="SAT">
      <data key="d0" />
      <data key="d1">The SAT is a standardized test widely used for college admissions in the United States, referenced in the AGIEval benchmark.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
      <data key="d3">EXAM</data>
    </node>
    <node id="MATH COMPETITIONS">
      <data key="d0" />
      <data key="d1">Math competitions are referenced in the AGIEval benchmark as part of the tasks used to evaluate models.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
      <data key="d3">EXAM</data>
    </node>
    <node id="ACADEMIC SUBJECTS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="ALLENAI">
      <data key="d0" />
      <data key="d1">AllenAI is the organization that developed the AI2 Reasoning Challenge (ARC) benchmark.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="BIG-BENCH">
      <data key="d0" />
      <data key="d1">Big-Bench is a broader benchmark from which the Big Bench Hard (BBH) tasks are selected.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="DOMAIN EXPERTS">
      <data key="d0" />
      <data key="d1">Domain experts, who are pursuing PhDs in their fields, created the questions for the GPQA benchmark.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GRADE SCHOOL MATH">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="DOMAIN-SPECIFIC FORMATS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="NATURAL LANGUAGE INSTRUCTIONS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="INSTRUCTION-FOLLOWING TASKS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="DRFR">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="MISTRAL">
      <data key="d0" />
      <data key="d1">Mistral is a model whose reading comprehension capabilities are improved using the AgentInstruct technique.
A family of models used as a base for fine-tuning with AgentInstruct data</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,ab04427ae0415a1c812a35cf8d3ee1a2</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="SMALL LANGUAGE MODELS (SLMS)">
      <data key="d0">MODEL</data>
      <data key="d1">Small Language Models (SLMs) are better suited as reasoning engines than mere retrieval systems, and their reading comprehension capabilities are evaluated in the text.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="ORCA 2.5">
      <data key="d0">MODEL</data>
      <data key="d1">Orca 2.5 is a model referenced in the text, showing a performance improvement in reading comprehension when compared to Mistral.
</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </node>
    <node id="LAW SCHOOL ADMISSION TESTS (LSATS)">
      <data key="d0">EXAM</data>
      <data key="d1">The Law School Admission Tests (LSATs) are used to evaluate reading comprehension in models, and are considered difficult for human test-takers.</data>
      <data key="d2">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </node>
    <node id="DROPM">
      <data key="d0">BENCHMARK</data>
      <data key="d1">DROP is a benchmark used to evaluate the performance of models on reading comprehension tasks</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="BBH MULTISTEP-ARITHMETIC-TWO">
      <data key="d0">BENCHMARK</data>
      <data key="d1">BBH multistep-arithmetic-two is a benchmark used to evaluate the performance of models on multi-step arithmetic problems</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="FORMAT FOLLOWING">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Format Following is a technique used to ensure that language models adhere to specific formatting guidelines, improving their applicability in real-world situations</data>
      <data key="d2">bb87f82e6a9f1d4da6480ec78a0e3701</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="GEMINI PRO">
      <data key="d0">MODEL</data>
      <data key="d1">Gemini Pro is a model used as a baseline for comparison in format-following tasks
Gemini Pro is a model whose scores are referenced from its original paper for comparison purposes</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="FOFO BENCHMARK">
      <data key="d0">BENCHMARK</data>
      <data key="d1">FoFo benchmark is used to evaluate the performance of language models, including Orca-3-7B, in various tasks</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="ABSTRACTIVE SUMMARIZATION">
      <data key="d0">TASK</data>
      <data key="d1">Abstractive summarization is the process of generating a concise and coherent summary of a longer text, focusing on the main points and ideas</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
      <data key="d3">TASK</data>
    </node>
    <node id="HALLUCINATIONS">
      <data key="d0">METRIC</data>
      <data key="d1">Hallucinations refer to the generation of incorrect or nonsensical information by language models during summarization tasks</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
      <data key="d3">METRIC</data>
    </node>
    <node id="QUALITY">
      <data key="d0">METRIC</data>
      <data key="d1">Quality is a metric used to evaluate the coherence and relevance of the generated summaries by language models</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
      <data key="d3">METRIC</data>
    </node>
    <node id="GPT4">
      <data key="d0">EVALUATOR</data>
      <data key="d1">GPT4 is used as an evaluator for assessing the summarization abilities of other language models</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
      <data key="d3">EVALUATOR</data>
    </node>
    <node id="ACI-BENCH">
      <data key="d0">BENCHMARK</data>
      <data key="d1">The Ambient Clinical Intelligence Benchmark (ACI-Bench) is a dataset designed for benchmarking automatic report generation from doctor-patient conversations
A novel ambient clinical intelligence dataset for benchmarking automatic visit note generation</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="INSTRUSUM">
      <data key="d0">BENCHMARK</data>
      <data key="d1">InstruSum is a dataset for evaluating the generation capabilities of language models for instruction-controllable summarization</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="ORCA-SUM">
      <data key="d0">BENCHMARK</data>
      <data key="d1">Orca-Sum is a newly created benchmark to evaluate language models' ability to follow summarization and grounded data transformation instructions</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="MIRAGE">
      <data key="d0">BENCHMARK</data>
      <data key="d1">MIRAGE is a benchmark focusing on answering medical questions by referring to information retrieved from a medical corpus</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
      <data key="d3">BENCHMARK</data>
    </node>
    <node id="MEDICAL CORPUS">
      <data key="d0">DATASET</data>
      <data key="d1">A collection of medical information used to evaluate the RAG capabilities of language models</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="MMLU-MED">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset used in the MIRAGE benchmark for evaluating language models on medical questions</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="MEDQA-US">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset used in the MIRAGE benchmark for evaluating language models on medical questions</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="MEDMCQA">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset used in the MIRAGE benchmark for evaluating language models on medical questions</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="PUBMEDQA">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset used in the MIRAGE benchmark for evaluating language models on medical questions
A dataset within the MIRAGE collection, considered an effective testbed for assessing models' ability to do RAG</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="BIOASQ">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset used in the MIRAGE benchmark for evaluating language models on medical questions
A dataset within the MIRAGE collection used for evaluating the performance of various models</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="COT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">Chain-of-Thought (CoT) is a reasoning process used by language models to break down complex problems into simpler, interconnected steps</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="ORCA-3-7B">
      <data key="d0" />
      <data key="d1">
A model fine-tuned with AgentInstruct data, evaluated on the MIRAGE datasets using CoT and RAG techniques</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b,ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="MODELORCA-3">
      <data key="d0">MODEL</data>
      <data key="d1">ModelOrca-3 is a language model evaluated on various benchmarks, including FoFo, for its performance in summarization and hallucination rates</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="MODELORCA-2.5">
      <data key="d0">MODEL</data>
      <data key="d1">ModelOrca-2.5 is a previous version of the Orca language model, used as a baseline for comparison in performance evaluations</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="MODELORCA-7B-INSTRUCT">
      <data key="d0">MODEL</data>
      <data key="d1">ModelOrca-7B-Instruct is a language model used as a baseline for comparison in performance evaluations</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="MODELORCA-8B-INSTRUCT">
      <data key="d0">MODEL</data>
      <data key="d1">ModelOrca-8B-Instruct is a language model used as a baseline for comparison in performance evaluations</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </node>
    <node id="MODELORCA-3.5-TURBO">
      <data key="d0">MODEL</data>
      <data key="d1">ModelOrca-3.5-turbo is a language model used for comparison in performance evaluationsModelOrca-3.5-turbo is a language model used</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="MODELORCA-4">
      <data key="d0">MODEL</data>
      <data key="d1">ModelOrca-4 is a language model used as an evaluator for summarization abilities and other performance metrics</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="MODELORCA-3.5">
      <data key="d0">MODEL</data>
      <data key="d1">ModelOrca-3.5 is a language model used for comparison in performance evaluations</data>
      <data key="d2">8ee9617c145e19fa95f1f9349bfbe69b</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="ORCA-2.5-7B">
      <data key="d0">MODEL</data>
      <data key="d1">A model evaluated on the MIRAGE datasets using CoT and RAG techniques</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="MISTRAL-7B-INSTRUCT-V0.1">
      <data key="d0">MODEL</data>
      <data key="d1">A model evaluated on the MIRAGE datasets using CoT and RAG techniques</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="COT (CHAIN-OF-THOUGHT)">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A technique that shows the performance of models when answering directly without using RAG</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="RAG (RETRIEVAL-AUGMENTED GENERATION)">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A technique that involves using a retrieval mechanism to incorporate retrieved results into model responses</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="MEDRAG">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A retrieval mechanism used across all models on the MIRAGE datasets</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="AZURE">
      <data key="d0">PLATFORM</data>
      <data key="d1">A cloud computing service that provides transparency notes for large language models
Azure is a cloud computing service created by Microsoft for building, testing, deploying, and managing applications and services</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2,dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PLATFORM</data>
    </node>
    <node id="DATA BIASES">
      <data key="d0">ISSUE</data>
      <data key="d1">Biases present in the source data that can be inadvertently carried by large language models, leading to potentially biased or unfair outputs</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
      <data key="d3">ISSUE</data>
    </node>
    <node id="LACK OF TRANSPARENCY">
      <data key="d0">ISSUE</data>
      <data key="d1">The difficulty in comprehending the rationale behind specific outputs or decisions made by large language models due to their complexity and size</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
      <data key="d3">ISSUE</data>
    </node>
    <node id="CONTENT HARMS">
      <data key="d0">ISSUE</data>
      <data key="d1">Various types of harmful content that large language models can generate, necessitating the use of content moderation services
Various types of negative impacts that large language models can cause, such as generating harmful or inappropriate content</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2,dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">ISSUE</data>
    </node>
    <node id="TRANSPARENCY NOTES">
      <data key="d0">DOCUMENT</data>
      <data key="d1">Documents provided by platforms like Azure to offer more information on the transparency of large language models)("relationship"Documents provided by platforms like Azure to offer more information on the transparency of large language models</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
      <data key="d3">DOCUMENT</data>
    </node>
    <node id="MIRAGE DATASETS">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="VALIDATION">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="DEPENDENCY ON SEED DATA">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="MEDMEDQA">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset within the MIRAGE collection used for evaluating the performance of various models</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="USMEDMCQA">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset within the MIRAGE collection used for evaluating the performance of various models</data>
      <data key="d2">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </node>
    <node id="CONTENT MODERATION SERVICES">
      <data key="d0">SERVICE</data>
      <data key="d1">Services provided by companies and institutions to monitor and manage the content generated by large language models to prevent harm</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">SERVICE</data>
    </node>
    <node id="GOVERNMENT AND TECHNOLOGY LEADERS">
      <data key="d0">STAKEHOLDERS</data>
      <data key="d1">Authorities and industry leaders responsible for creating regulations and standards around content harms for AI technologies</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">STAKEHOLDERS</data>
    </node>
    <node id="RESEARCH AND OPEN SOURCE COMMUNITY">
      <data key="d0">STAKEHOLDERS</data>
      <data key="d1">Groups and individuals involved in research and open-source projects that can contribute to addressing content harms in AI technologies</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">STAKEHOLDERS</data>
    </node>
    <node id="HALLUCINATION">
      <data key="d0">ISSUE</data>
      <data key="d1">The phenomenon where language models generate content that is not based on real data, leading to fabricated information
The generation of incorrect or fabricated information by an AI model</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">ISSUE</data>
    </node>
    <node id="UNGROUNDED GENERATION">
      <data key="d0">ISSUE</data>
      <data key="d1">The generation of content by language models without a solid basis in factual data, which can lead to hallucinations</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">ISSUE</data>
    </node>
    <node id="POTENTIAL FOR MISUSE">
      <data key="d0">ISSUE</data>
      <data key="d1">The risk that large language models could be used maliciously to generate disinformation or harmful content</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">ISSUE</data>
    </node>
    <node id="DATA DISTRIBUTION">
      <data key="d0">CONCEPT</data>
      <data key="d1">The distribution of data used to train a model, which can affect the model's performance and accuracy</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">CONCEPT</data>
    </node>
    <node id="SYNTHETIC DATA GENERATION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">The process of creating artificial data to be used in training machine learning models</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="UNSTRUCTURED DATA SOURCES">
      <data key="d0">DATA TYPE</data>
      <data key="d1">Data that is not organized in a pre-defined manner, which can be used by AgentInstruct to generate synthetic datasets</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">DATA TYPE</data>
    </node>
    <node id="25M PAIR DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset consisting of 25 million pairs of prompts and responses generated by AgentInstruct for post-training the Orca-3 model</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="PRE-TRAINING">
      <data key="d0">PROCESS</data>
      <data key="d1">The initial phase of training a machine learning model using a large dataset</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PROCESS</data>
    </node>
    <node id="DOMAIN/TASK SPECIALIZATION">
      <data key="d0">PROCESS</data>
      <data key="d1">The process of customizing a model to perform well in specific domains or tasks</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PROCESS</data>
    </node>
    <node id="PHI-3 TECHNICAL REPORT">
      <data key="d0">DOCUMENT</data>
      <data key="d1">A technical report authored by multiple researchers, detailing the Phi-3 model and its attributes</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">DOCUMENT</data>
    </node>
    <node id="MARAH ABDIN">
      <data key="d0">PERSON</data>
      <data key="d1">Marah Abdin is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SAM ADE JACOBS">
      <data key="d0">PERSON</data>
      <data key="d1">Sam Ade Jacobs is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AMMAR AHMAD AWAN">
      <data key="d0">PERSON</data>
      <data key="d1">Ammar Ahmad Awan is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JYOTI ANEJA">
      <data key="d0">PERSON</data>
      <data key="d1">Jyoti Aneja is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AHMED AWADALLAH">
      <data key="d0">PERSON</data>
      <data key="d1">Ahmed Awadallah is one of the authors of the Phi-3 technical report
Ahmed Awadallah is an author who contributed to the research on Orca 2, Orca-Math, Xtremedistil, Orca, and Direct Nash Optimization, systems for teaching small language models how to reason, unlocking the potential of SLMs in grade school math, multi-stage distillation for massive multilingual models, progressive learning from complex explanation traces of GPT-4, and teaching language models to self-improve with general preferences</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HANY AWADALLA">
      <data key="d0">PERSON</data>
      <data key="d1">Hany Awadalla is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NGUYEN BACH">
      <data key="d0">PERSON</data>
      <data key="d1">Nguyen Bach is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AMIT BAHREE">
      <data key="d0">PERSON</data>
      <data key="d1">Amit Bahree is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ARASH BAKHTIARI">
      <data key="d0">PERSON</data>
      <data key="d1">Arash Bakhtiari is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JIANMIN BAO">
      <data key="d0">PERSON</data>
      <data key="d1">Jianmin Bao is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HARKIRAT BEHL">
      <data key="d0">PERSON</data>
      <data key="d1">Harkirat Behl is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ALON BENHAIM">
      <data key="d0">PERSON</data>
      <data key="d1">Alon Benhaim is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MISHA BILENKO">
      <data key="d0">PERSON</data>
      <data key="d1">Misha Bilenko is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JOHAN BJORCK">
      <data key="d0">PERSON</data>
      <data key="d1">Johan Bjorck is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="S&#201;BASTIEN BUBECK">
      <data key="d0">PERSON</data>
      <data key="d1">S&#233;bastien Bubeck is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="QIN CAI">
      <data key="d0">PERSON</data>
      <data key="d1">Qin Cai is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MARTIN CAI">
      <data key="d0">PERSON</data>
      <data key="d1">Martin Cai is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CAIO C&#201;SAR TEODORO MENDES">
      <data key="d0">PERSON</data>
      <data key="d1">Caio C&#233;sar Teodoro Mendes is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WEIZHU CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Weizhu Chen is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="VISHRAV CHAUDHARY">
      <data key="d0">PERSON</data>
      <data key="d1">Vishrav Chaudhary is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DONG CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Dong Chen is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DONGDONG CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Dongdong Chen is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YEN-CHUN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Yen-Chun Chen is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YI-LING CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Yi-Ling Chen is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PARUL CHOPRA">
      <data key="d0">PERSON</data>
      <data key="d1">Parul Chopra is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XIYANG DAI">
      <data key="d0">PERSON</data>
      <data key="d1">Xiyang Dai is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ALLIE DEL GIORNO">
      <data key="d0">PERSON</data>
      <data key="d1">Allie Del Giorno is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GUSTAVO DE ROSA">
      <data key="d0">PERSON</data>
      <data key="d1">Gustavo de Rosa is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MATTHEW DIXON">
      <data key="d0">PERSON</data>
      <data key="d1">Matthew Dixon is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RONEN ELDAN">
      <data key="d0">PERSON</data>
      <data key="d1">Ronen Eldan is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="VICTOR FRAGOSO">
      <data key="d0">PERSON</data>
      <data key="d1">Victor Fragoso is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DAN ITER">
      <data key="d0">PERSON</data>
      <data key="d1">Dan Iter is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MEI GAO">
      <data key="d0">PERSON</data>
      <data key="d1">Mei Gao is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MIN GAO">
      <data key="d0">PERSON</data>
      <data key="d1">Min Gao is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JIANFENG GAO">
      <data key="d0">PERSON</data>
      <data key="d1">Jianfeng Gao is one of the authors of the Phi-3 technical report
Jianfeng Gao is an author who contributed to the research on instruction tuning with GPT-4</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AMIT GARG">
      <data key="d0">PERSON</data>
      <data key="d1">Amit Garg is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ABHISHEK GOSWAMI">
      <data key="d0">PERSON</data>
      <data key="d1">Abhishek Goswami is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SURIYA GUNASEKAR">
      <data key="d0">PERSON</data>
      <data key="d1">Suriya Gunasekar is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="EMMAN HAIDER">
      <data key="d0">PERSON</data>
      <data key="d1">Emman Haider is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JUNHENG HAO">
      <data key="d0">PERSON</data>
      <data key="d1">Junheng Hao is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RUSSELL J. HEWETT">
      <data key="d0">PERSON</data>
      <data key="d1">Russell J. Hewett is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JAMIE HUYNH">
      <data key="d0">PERSON</data>
      <data key="d1">Jamie Huynh is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MOJAN JAVAHERIPI">
      <data key="d0">PERSON</data>
      <data key="d1">Mojan Javaheripi is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XIN JIN">
      <data key="d0">PERSON</data>
      <data key="d1">Xin Jin is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PIERO KAUFFMANN">
      <data key="d0">PERSON</data>
      <data key="d1">Piero Kauffmann is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NIKOS KARAMPATZIAKIS">
      <data key="d0">PERSON</data>
      <data key="d1">Nikos Karampatziakis is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DONGWOO KIM">
      <data key="d0">PERSON</data>
      <data key="d1">Dongwoo Kim is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MAHOUD KHADEMI">
      <data key="d0">PERSON</data>
      <data key="d1">Mahoud Khademi is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LEV KURILENKO">
      <data key="d0">PERSON</data>
      <data key="d1">Lev Kurilenko is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JAMES R. LEE">
      <data key="d0">PERSON</data>
      <data key="d1">James R. Lee is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YIN TAT LEE">
      <data key="d0">PERSON</data>
      <data key="d1">Yin Tat Lee is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YUANZHI LI">
      <data key="d0">PERSON</data>
      <data key="d1">Yuanzhi Li is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YUNSHENG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Yunsheng Li is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHEN LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Chen Liang is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LARS LIDEN">
      <data key="d0">PERSON</data>
      <data key="d1">Lars Liden is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CE LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Ce Liu is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MENGCHEN LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Mengchen Liu is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WEISHUNG LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Weishung Liu is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ERIC LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Lin is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZEQI LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Zeqi Lin is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHONG LUO">
      <data key="d0">PERSON</data>
      <data key="d1">Chong Luo is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PIYUSH MADAN">
      <data key="d0">PERSON</data>
      <data key="d1">Piyush Madan is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MATT MAZZOLA">
      <data key="d0">PERSON</data>
      <data key="d1">Matt Mazzola is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ARINDAM MITRA">
      <data key="d0">PERSON</data>
      <data key="d1">Arindam Mitra is one of the authors of the Phi-3 technical report
Arindam Mitra is an author who contributed to the research on Orca 2 and Orca-Math, systems for teaching small language models how to reason and unlocking the potential of SLMs in grade school math</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HARDIK MODI">
      <data key="d0">PERSON</data>
      <data key="d1">Hardik Modi is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANH NGUYEN">
      <data key="d0">PERSON</data>
      <data key="d1">Anh Nguyen is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BRANDON NORICK">
      <data key="d0">PERSON</data>
      <data key="d1">Brandon Norick is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BARUN PATRA">
      <data key="d0">PERSON</data>
      <data key="d1">Barun Patra is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DANIEL PEREZ-BECKER">
      <data key="d0">PERSON</data>
      <data key="d1">Daniel Perez-Becker is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="THOMAS PORTET">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas Portet is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="REID PRYZANT">
      <data key="d0">PERSON</data>
      <data key="d1">Reid Pryzant is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HEYANG QIN">
      <data key="d0">PERSON</data>
      <data key="d1">Heyang Qin is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MARKO RADMILAC">
      <data key="d0">PERSON</data>
      <data key="d1">Marko Radmilac is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CORBY ROSSET">
      <data key="d0">PERSON</data>
      <data key="d1">Corby Rosset is one of the authors of the Phi-3 technical report
Corby Rosset is an author who contributed to the research on Orca 2, Orca-Math, and Direct Nash Optimization, systems for teaching small language models how to reason, unlocking the potential of SLMs in grade school math, and teaching language models to self-improve with general preferences</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SAMBUDHA ROY">
      <data key="d0">PERSON</data>
      <data key="d1">Sambudha Roy is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="OLATUNJI RUWASE">
      <data key="d0">PERSON</data>
      <data key="d1">Olatunji Ruwase is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="OLLI SAARIKIVI">
      <data key="d0">PERSON</data>
      <data key="d1">Olli Saarikivi is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AMIN SAIED">
      <data key="d0">PERSON</data>
      <data key="d1">Amin Saied is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ADIL SALIM">
      <data key="d0">PERSON</data>
      <data key="d1">Adil Salim is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MICHAEL SANTACROCE">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Santacroce is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHITAL SHAH">
      <data key="d0">PERSON</data>
      <data key="d1">Shital Shah is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NING SHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Ning Shang is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HITESHI SHARMA">
      <data key="d0">PERSON</data>
      <data key="d1">Hiteshi Sharma is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SWADHEEN SHUKLA">
      <data key="d0">PERSON</data>
      <data key="d1">Swadheen Shukla is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XIA SONG">
      <data key="d0">PERSON</data>
      <data key="d1">Xia Song is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MASAHIRO TANAKA">
      <data key="d0">PERSON</data>
      <data key="d1">Masahiro Tanaka is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANDREA TUPINI">
      <data key="d0">PERSON</data>
      <data key="d1">Andrea Tupini is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XIN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xin Wang is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LIJUAN WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Lijuan Wang is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHUNYU WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Chunyu Wang is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YU WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yu Wang is one of the authors of the Phi-3 technical report</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RACHEL WARD">
      <data key="d0">PERSON</data>
      <data key="d1">Rachel Ward is one of the authors of the Phi-3 technical</data>
      <data key="d2">dd9a46950237e49ef9b1c7ef08e08d42</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AI2 REASONING CHALLENGE">
      <data key="d0">CHALLENGE</data>
      <data key="d1">A challenge designed to test the capabilities of AI systems in question answering, as described by Clark et al., 2018</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">CHALLENGE</data>
    </node>
    <node id="VERIFIERS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A method used to solve math word problems, as described by Cobbe et al., 2021</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="GITHUB-CODE CLEAN DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset of cleaned code from GitHub, as described by CodeParrot, 2022</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="CHAT LANGUAGE MODELS">
      <data key="d0">MODEL</data>
      <data key="d1">Language models enhanced by scaling high-quality instructional conversations, as described by Ding et al., 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="QUERY OF CC">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A method for unearthing large-scale domain-specific knowledge from public corpora, as described by Fei et al., 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="IMITATING PROPRIETARY LLMS">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A method critiqued for its false promise in imitating proprietary large language models, as described by Gudibande et al., 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="MATH DATASET">
      <data key="d0">DATASET</data>
      <data key="d1">A dataset used for measuring mathematical problem solving, as described by Hendrycks et al., 2021</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">DATASET</data>
    </node>
    <node id="TULU 2">
      <data key="d0">MODEL</data>
      <data key="d1">A model used for enhancing language model adaptation, as described by Ivison et al., 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="MISTRAL 7B">
      <data key="d0">MODEL</data>
      <data key="d1">A language model, as described by Jiang et al., 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="RLAIF">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A method for scaling reinforcement learning from human feedback with AI feedback, as described by Lee et al., 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="CAMEL">
      <data key="d0">MODEL</data>
      <data key="d1">Communicative agents for "mind" exploration of large language model society, as described by Li et al., 2023
Communicative agents for "mind" exploration of large language model society, as described in the 2023 paper</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">MODEL</data>
    </node>
    <node id="WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Wang is an author who contributed to the technical report on Phi-3, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PETER CLARK">
      <data key="d0">PERSON</data>
      <data key="d1">Peter Clark is an author who contributed to the AI2 reasoning challenge, 2018</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KARL COBBE">
      <data key="d0">PERSON</data>
      <data key="d1">Karl Cobbe is an author who contributed to the research on training verifiers to solve math word problems, 2021</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CODEPARROT">
      <data key="d0">ORGANIZATION</data>
      <data key="d1">CodeParrot is an organization that created the GitHub-code clean dataset, 2022</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">ORGANIZATION</data>
    </node>
    <node id="NING DING">
      <data key="d0">PERSON</data>
      <data key="d1">Ning Ding is an author who contributed to the research on enhancing chat language models, 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DHEERU DUA">
      <data key="d0">PERSON</data>
      <data key="d1">Dheeru Dua is an author who contributed to the DROP benchmark, 2019</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHAOYE FEI">
      <data key="d0">PERSON</data>
      <data key="d1">Zhaoye Fei is an author who contributed to the research on Query of CC, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ARNAV GUDIBANDE">
      <data key="d0">PERSON</data>
      <data key="d1">Arnav Gudibande is an author who contributed to the research on the false promise of imitating proprietary LLMs, 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DAN HENDRYCKS">
      <data key="d0">PERSON</data>
      <data key="d1">Dan Hendrycks is an author who contributed to the research on the math dataset, 2021</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HAMISH IVISON">
      <data key="d0">PERSON</data>
      <data key="d1">Hamish Ivison is an author who contributed to the research on Tulu 2, 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ALBERT Q. JIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Albert Q. Jiang is an author who contributed to the research on Mistral 7B, 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HARRISON LEE">
      <data key="d0">PERSON</data>
      <data key="d1">Harrison Lee is an author who contributed to the research on RLAIF, 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GUOHAO LI">
      <data key="d0">PERSON</data>
      <data key="d1">Guohao Li is an author who contributed to the research on CAMEL, 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PHI-3">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="PHILIPP WITTE">
      <data key="d0">PERSON</data>
      <data key="d1">Philipp Witte is an author who contributed to the technical report on Phi-3, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HAIPING WU">
      <data key="d0">PERSON</data>
      <data key="d1">Haiping Wu is an author who contributed to the technical report on Phi-3, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MICHAEL WYATT">
      <data key="d0">PERSON</data>
      <data key="d1">Michael Wyatt is an author who contributed to the technical report on Phi-3, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="BIN XIAO">
      <data key="d0">PERSON</data>
      <data key="d1">Bin Xiao is an author who contributed to the technical report on Phi-3, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CAN XU">
      <data key="d0">PERSON</data>
      <data key="d1">Can Xu is an author who contributed to the technical report on Phi-3, 2024
Can Xu is an author who contributed to the research on WizardLM, empowering large language models to follow complex instructions</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172,f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="JIAHANG XU">
      <data key="d0">PERSON</data>
      <data key="d1">Jiahang Xu is an author who contributed to the technical report on Phi-3, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="WEIJIAN XU">
      <data key="d0">PERSON</data>
      <data key="d1">Weijian Xu is an author who contributed to the technical report on Phi-3, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SONALI YADAV">
      <data key="d0">PERSON</data>
      <data key="d1">Sonali Yadav is an author who contributed to the technical report on Phi-3, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="FAN YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Fan Yang is an author who contributed to the technical report on Phi-3, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JIANWEI YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jianwei Yang is an author who contributed to the technical report on Phi-3, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZIYI YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Ziyi Yang is an author who contributed to the technical report on Phi-3, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YIFAN YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yifan Yang is an author who contributed to the technical report on Phi-3, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DONGHAN YU">
      <data key="d0">PERSON</data>
      <data key="d1">Donghan Yu is an author who contributed to the technical report on Phi-3, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="LU YUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Lu Yuan is an author who contributed to the technical report on Phi-3, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CHENGRUIDONG ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Chengruidong Zhang is an author who contributed to the technical report on Phi-3, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CYRIL ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Cyril Zhang is an author who contributed to the technical report on Phi-3, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JIANWEN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jianwen Zhang is an author who contributed to the technical report on Phi-3, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="LI LYNA ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Li Lyna Zhang is an author who contributed to the technical report on Phi-3, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YI ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yi Zhang is an author who contributed to the technical report on Phi-3, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YUE ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yue Zhang is an author who contributed to the technical report on Phi-3, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YUNAN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yunan Zhang is an author who contributed to the technical report on Phi-3, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="XIREN ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Xiren Zhou is an author who contributed to the technical report on Phi-3, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ISAAC COWHEY">
      <data key="d0">PERSON</data>
      <data key="d1">Isaac Cowhey is an author who contributed to the AI2 reasoning challenge, 2018</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="OREN ETZIONI">
      <data key="d0">PERSON</data>
      <data key="d1">Oren Etzioni is an author who contributed to the AI2 reasoning challenge, 2018</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="TUSHAR KHOT">
      <data key="d0">PERSON</data>
      <data key="d1">Tushar Khot is an author who contributed to the AI2 reasoning challenge, 2018</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ASHISH SABHARWAL">
      <data key="d0">PERSON</data>
      <data key="d1">Ashish Sabharwal is an author who contributed to the AI2 reasoning challenge, 2018</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CARISSA SCHOENICK">
      <data key="d0">PERSON</data>
      <data key="d1">Carissa Schoenick is an author who contributed to the AI2 reasoning challenge, 2018</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="OYVIND TAFJORD">
      <data key="d0">PERSON</data>
      <data key="d1">Oyvind Tafjord is an author who contributed to the AI2 reasoning challenge, 2018</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="VINEET KOSARAJU">
      <data key="d0">PERSON</data>
      <data key="d1">Vineet Kosaraju is an author who contributed to the research on training verifiers to solve math word problems, 2021</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MOHAMMAD BAVARIAN">
      <data key="d0">PERSON</data>
      <data key="d1">Mohammad Bavarian is an author who contributed to the research on training verifiers to solve math word problems, 2021</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MARK CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Mark Chen is an author who contributed to the research on training verifiers to solve math word problems, 2021</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HEEWOO JUN">
      <data key="d0">PERSON</data>
      <data key="d1">Heewoo Jun is an author who contributed to the research on training verifiers to solve math word problems, 2021</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="LUKASZ KAISER">
      <data key="d0">PERSON</data>
      <data key="d1">Lukasz Kaiser is an author who contributed to the research on training verifiers to solve math word problems, 2021</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MATTHIAS PLAPPERT">
      <data key="d0">PERSON</data>
      <data key="d1">Matthias Plappert is an author who contributed to the research on training verifiers to solve math word problems, 2021</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JERRY TWOREK">
      <data key="d0">PERSON</data>
      <data key="d1">Jerry Tworek is an author who contributed to the research on training verifiers to solve math word problems, 2021</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JACOB HILTON">
      <data key="d0">PERSON</data>
      <data key="d1">Jacob Hilton is an author who contributed to the research on training verifiers to solve math word problems, 2021</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="REIICHIRO NAKANO">
      <data key="d0">PERSON</data>
      <data key="d1">Reiichiro Nakano is an author who contributed to the research on training verifiers to solve math word problems, 2021</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YULIN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Yulin Chen is an author who contributed to the research on enhancing chat language models, 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="BOKAI XU">
      <data key="d0">PERSON</data>
      <data key="d1">Bokai Xu is an author who contributed to the research on enhancing chat language models, 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YUJIA QIN">
      <data key="d0">PERSON</data>
      <data key="d1">Yujia Qin is an author who contributed to the research on enhancing chat language models, 2023
Yujia Qin is an author who contributed to the research on ToolLLM, a system for facilitating large language models to master 16000+ real-world APIs</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZHI ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhi Zheng is an author who contributed to the research on enhancing chat language models, 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SHENGDING HU">
      <data key="d0">PERSON</data>
      <data key="d1">Shengding Hu is an author who contributed to the research on enhancing chat language models, 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZHIYUAN LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Zhiyuan Liu is an author who contributed to the research on enhancing chat language models, 2023
Zhiy</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e,cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MAOSONG SUN">
      <data key="d0">PERSON</data>
      <data key="d1">Maosong Sun is an author who contributed to the research on enhancing chat language models, 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="BOWEN ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Bowen Zhou is an author who contributed to the research on enhancing chat language models, 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YIZHONG WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yizhong Wang is an author who contributed to the DROP benchmark, 2019</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="PRADEEP DASIGI">
      <data key="d0">PERSON</data>
      <data key="d1">Pradeep Dasigi is an author who contributed to the DROP benchmark, 2019</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="GABRIEL STANOVSKY">
      <data key="d0">PERSON</data>
      <data key="d1">Gabriel Stanovsky is an author who contributed to the DROP benchmark, 2019</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SAMEER SINGH">
      <data key="d0">PERSON</data>
      <data key="d1">Sameer Singh is an author who contributed to the DROP benchmark, 2019</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MATT GARDNER">
      <data key="d0">PERSON</data>
      <data key="d1">Matt Gardner is an author who contributed to the DROP benchmark, 2019</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="YUNFAN SHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Yunfan Shao is an author who contributed to the research on Query of CC, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="LINYANG LI">
      <data key="d0">PERSON</data>
      <data key="d1">Linyang Li is an author who contributed to the research on Query of CC, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ZHIYUAN ZENG">
      <data key="d0">PERSON</data>
      <data key="d1">Zhiyuan Zeng is an author who contributed to the research on Query of CC, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HANG YAN">
      <data key="d0">PERSON</data>
      <data key="d1">Hang Yan is an author who contributed to the research on Query of CC, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="XI PENG QIU">
      <data key="d0">PERSON</data>
      <data key="d1">Xi Peng Qiu is an author who contributed to the research on Query of CC, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DAHUA LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Dahua Lin is an author who contributed to the research on Query of CC, 2024</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ERIC WALLACE">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Wallace is an author who contributed to the research on the false promise of imitating proprietary LLMs, 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="CHARLIE SNELL">
      <data key="d0">PERSON</data>
      <data key="d1">Charlie Snell is an author who contributed to the research on the false promise of imitating proprietary LLMs, 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="XINYANG GENG">
      <data key="d0">PERSON</data>
      <data key="d1">Xinyang Geng is an author who contributed to the research on the false promise of imitating proprietary LLMs, 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="HAO LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Hao Liu is an author who contributed to the research on the false promise of imitating proprietary LLMs, 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="PIETER ABBEEL">
      <data key="d0">PERSON</data>
      <data key="d1">Pieter Abbeel is an author who contributed to the research on the false promise of imitating proprietary LLMs, 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SERGEY LEVINE">
      <data key="d0">PERSON</data>
      <data key="d1">Sergey Levine is an author who contributed to the research on the false promise of imitating proprietary LLMs, 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="DAWN SONG">
      <data key="d0">PERSON</data>
      <data key="d1">Dawn Song is an author who contributed to the research on the false promise of imitating proprietary LLMs, 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="COLLIN BURNS">
      <data key="d0">PERSON</data>
      <data key="d1">Collin Burns is an author who contributed to the research on the math dataset, 2021</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="SAURAV KADAVATH">
      <data key="d0">PERSON</data>
      <data key="d1">Saurav Kadavath is an author who contributed to the research on the math dataset, 2021</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="AKUL ARORA">
      <data key="d0">PERSON</data>
      <data key="d1">Akul Arora is an author who contributed to the research on the math dataset, 2021</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="STEVEN BASART">
      <data key="d0">PERSON</data>
      <data key="d1">Steven Basart is an author who contributed to the research on the math dataset, 2021</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="ERIC TANG">
      <data key="d0">PERSON</data>
      <data key="d1">Eric Tang is an author who contributed to the research on the math dataset, 2021</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JACOB STEINHARDT">
      <data key="d0">PERSON</data>
      <data key="d1">Jacob Steinhardt is an author who contributed to the research on the math dataset, 2021</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="VALENTINA PYATKIN">
      <data key="d0">PERSON</data>
      <data key="d1">Valentina Pyatkin is an author who contributed to the research on Tulu 2, 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="NATHAN LAMBERT">
      <data key="d0">PERSON</data>
      <data key="d1">Nathan Lambert is an author who contributed to the research on Tulu 2, 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="MATTHEW PETERS">
      <data key="d0">PERSON</data>
      <data key="d1">Matthew Peters is an author who contributed to the research on Tulu 2, 2023</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="JOEL JANG">
      <data key="d0">PERSON</data>
      <data key="d1">Joel Jang is an author who contributed</data>
      <data key="d2">cc20c99cad8edecc66b82ac751ff7172</data>
    </node>
    <node id="BERNARD GHANEM">
      <data key="d0">PERSON</data>
      <data key="d1">Bernard Ghanem is an author who contributed to the research on communicative agents for "mind" exploration of large language model society</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XUECHEN LI">
      <data key="d0">PERSON</data>
      <data key="d1">Xuechen Li is an author who contributed to the research on AlpacaEval, an automatic evaluator of instruction-following models</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="TIANYI ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Tianyi Zhang is an author who contributed to the research on AlpacaEval, an automatic evaluator of instruction-following models</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YANN DUBOIS">
      <data key="d0">PERSON</data>
      <data key="d1">Yann Dubois is an author who contributed to the research on AlpacaEval, an automatic evaluator of instruction-following models</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ROHAN TAORI">
      <data key="d0">PERSON</data>
      <data key="d1">Rohan Taori is an author who contributed to the research on AlpacaEval, an automatic evaluator of instruction-following models</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ISHAAN GULRAJANI">
      <data key="d0">PERSON</data>
      <data key="d1">Ishaan Gulrajani is an author who contributed to the research on AlpacaEval, an automatic evaluator of instruction-following models</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CARLOS GUESTRIN">
      <data key="d0">PERSON</data>
      <data key="d1">Carlos Guestrin is an author who contributed to the research on AlpacaEval, an automatic evaluator of instruction-following models</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PERCY LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Percy Liang is an author who contributed to the research on AlpacaEval, an automatic evaluator of instruction-following models</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="TATSUNORI B. HASHIMOTO">
      <data key="d0">PERSON</data>
      <data key="d1">Tatsunori B. Hashimoto is an author who contributed to the research on AlpacaEval, an automatic evaluator of instruction-following models</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YIXIN LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Yixin Liu is an author who contributed to the research on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ALEXANDER R. FABBRI">
      <data key="d0">PERSON</data>
      <data key="d1">Alexander R. Fabbri is an author who contributed to the research on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JIAWEN CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Jiawen Chen is an author who contributed to the research on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YILUN ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Yilun Zhao is an author who contributed to the research on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SIMENG HAN">
      <data key="d0">PERSON</data>
      <data key="d1">Simeng Han is an author who contributed to the research on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHAFIQ JOTY">
      <data key="d0">PERSON</data>
      <data key="d1">Shafiq Joty is an author who contributed to the research on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PENGFEI LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Pengfei Liu is an author who contributed to the research on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarizationPengfei Liu is an author who contributed to the research on InfoBench, a system for evaluating instruction-following ability in large language models</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DRAGOMIR RADEV">
      <data key="d0">PERSON</data>
      <data key="d1">Dragomir Radev is an author who contributed to the research on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHIEN-SHENG WU">
      <data key="d0">PERSON</data>
      <data key="d1">Chien-Sheng Wu is an author who contributed to the research on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ARMAN COHAN">
      <data key="d0">PERSON</data>
      <data key="d1">Arman Cohan is an author who contributed to the research on benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DANIEL VAN STRIEN">
      <data key="d0">PERSON</data>
      <data key="d1">Daniel van Strien is an author who contributed to the research on Cosmopedia, a method for creating large-scale synthetic data for pre-training</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LOUBNA BEN ALLAL">
      <data key="d0">PERSON</data>
      <data key="d1">Loubna Ben Allal is an author who contributed to the research on Cosmopedia, a method for creating large-scale synthetic data for pre-training</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANTON LOZHKOV">
      <data key="d0">PERSON</data>
      <data key="d1">Anton Lozhkov is an author who contributed to the research on Cosmopedia, a method for creating large-scale synthetic data for pre-training</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="COSMOPEDIA">
      <data key="d0">SYSTEM</data>
      <data key="d1">A method for creating large-scale synthetic data for pre-training, as described in the 2024 paper</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">SYSTEM</data>
    </node>
    <node id="LUCIANO DEL CORRO">
      <data key="d0">PERSON</data>
      <data key="d1">Luciano Del Corro is an author who contributed to the research on Orca 2, a system for teaching small language models how to reason</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHWETI MAHAJAN">
      <data key="d0">PERSON</data>
      <data key="d1">Shweti Mahajan is an author who contributed to the research on Orca 2, a system for teaching small language models how to reason</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANDRES CODAS">
      <data key="d0">PERSON</data>
      <data key="d1">Andres Codas is an author who contributed to the research on Orca 2, a system for teaching small language models how to reason</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CLARISSE SIMOES">
      <data key="d0">PERSON</data>
      <data key="d1">Clarisse Simoes is an author who contributed to the research on Orca 2, a system for teaching small language models how to reason</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SAHAJ AGARWAL">
      <data key="d0">PERSON</data>
      <data key="d1">Sahaj Agarwal is an author who contributed to the research on Orca 2 and Orca, systems for teaching small language models how to reason and progressive learning from complex explanation traces of GPT-4</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XUXI CHEN">
      <data key="d0">PERSON</data>
      <data key="d1">Xuxi Chen is an author who contributed to the research on Orca 2, a system for teaching small language models how to reason</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANASTASIA RAZDAIBIEDINA">
      <data key="d0">PERSON</data>
      <data key="d1">Anastasia Razdaibiedina is an author who contributed to the research on Orca 2, a system for teaching small language models how to reason</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ERIK JONES">
      <data key="d0">PERSON</data>
      <data key="d1">Erik Jones is an author who contributed to the research on Orca 2, a system for teaching small language models how to reason</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KRITI AGGARWAL">
      <data key="d0">PERSON</data>
      <data key="d1">Kriti Aggarwal is an author who contributed to the research on Orca 2, a system for teaching small language models how to reason</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HAMID PALANGI">
      <data key="d0">PERSON</data>
      <data key="d1">Hamid Palangi is an author who contributed to the research on Orca 2, Orca, and Xtremedistil, systems for teaching small language models how to reason, progressive learning from complex explanation traces of GPT-4, and multi-stage distillation for massive multilingual models</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GUOQING ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Guoqing Zheng is an author who contributed to the research on Orca 2, a system for teaching small language models how to reason</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HAMED KHANPOUR">
      <data key="d0">PERSON</data>
      <data key="d1">Hamed Khanpour is an author who contributed to the research on Orca 2, Orca-Math, and Direct Nash Optimization, systems for teaching small language models how to reason, unlocking the potential of SLMs in grade school math, and teaching language models to self-improve with general preferences</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ORCA 2">
      <data key="d0">SYSTEM</data>
      <data key="d1">A system for teaching small language models how to reason, as described in the 2023 paper</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">SYSTEM</data>
    </node>
    <node id="ORCA-MATH">
      <data key="d0">SYSTEM</data>
      <data key="d1">A system for unlocking the potential of SLMs in grade school math, as described in the 2024 paper</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">SYSTEM</data>
    </node>
    <node id="XTREMEDISTIL">
      <data key="d0">SYSTEM</data>
      <data key="d1">A system for multi-stage distillation for massive multilingual models, as described in the 2020 paper</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">SYSTEM</data>
    </node>
    <node id="ORCA">
      <data key="d0">SYSTEM</data>
      <data key="d1">A system for progressive learning from complex explanation traces of GPT-4, as described in the 2023 paper</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">SYSTEM</data>
    </node>
    <node id="EQ-BENCH">
      <data key="d0">SYSTEM</data>
      <data key="d1">An emotional intelligence benchmark for large language models, as described by Samuel J. Paech in 2024</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">SYSTEM</data>
    </node>
    <node id="SAMUEL J. PAECH">
      <data key="d0">PERSON</data>
      <data key="d1">Samuel J. Paech is an author who contributed to the research on EQ-Bench, an emotional intelligence benchmark for large language models</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BAOLIN PENG">
      <data key="d0">PERSON</data>
      <data key="d1">Baolin Peng is an author who contributed to the research on instruction tuning with GPT-4</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHUNYUAN LI">
      <data key="d0">PERSON</data>
      <data key="d1">Chunyuan Li is an author who contributed to the research on instruction tuning with GPT-4</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PENGCHENG HE">
      <data key="d0">PERSON</data>
      <data key="d1">Pengcheng He is an author who contributed to the research on instruction tuning with GPT-4</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MICHEL GALLEY">
      <data key="d0">PERSON</data>
      <data key="d1">Michel Galley is an author who contributed to the research on instruction tuning with GPT-4</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YIWEI QIN">
      <data key="d0">PERSON</data>
      <data key="d1">Yiwei Qin is an author who contributed to the research on InfoBench, a system for evaluating instruction-following ability in large language models</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KAIQIANG SONG">
      <data key="d0">PERSON</data>
      <data key="d1">Kaiqiang Song is an author who contributed to the research on InfoBench, a system for evaluating instruction-following ability in large language models</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YEBO WEN HU">
      <data key="d0">PERSON</data>
      <data key="d1">Yebo Wen Hu is an author who contributed to the research on InfoBench, a system for evaluating instruction-following ability in large language models</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WENLIN YAO">
      <data key="d0">PERSON</data>
      <data key="d1">Wenlin Yao is an author who contributed to the research on InfoBench, a system for evaluating instruction-following ability in large language models</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SANGWOO CHO">
      <data key="d0">PERSON</data>
      <data key="d1">Sangwoo Cho is an author who contributed to the research on InfoBench, a system for evaluating instruction-following ability in large language models</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XIAOYANG WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xiaoyang Wang is an author who contributed to the research on InfoBench, a system for evaluating instruction-following ability in large language models</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XUANSHENG WU">
      <data key="d0">PERSON</data>
      <data key="d1">Xuansheng Wu is an author who contributed to the research on InfoBench, a system for evaluating instruction-following ability in large language models</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="FEI LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Fei Liu is an author who contributed to the research on InfoBench, a system for evaluating instruction-following ability in large language models</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DONG YU">
      <data key="d0">PERSON</data>
      <data key="d1">Dong Yu is an author who contributed to the research on InfoBench, a system for evaluating instruction-following ability in large language models</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHIHAO LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Shihao Liang is an author who contributed to the research on ToolLLM, a system for facilitating large language models to master 16000+ real-world APIs</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YINING YE">
      <data key="d0">PERSON</data>
      <data key="d1">Yining Ye is an author who contributed to the research on ToolLLM, a system for facilitating large language models to master 16000+ real-world APIs</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KUNLUN ZHU">
      <data key="d0">PERSON</data>
      <data key="d1">Kunlun Zhu is an author who contributed to the research on ToolLLM, a system for facilitating large language models to master 16000+ real-world APIs</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LAN YAN">
      <data key="d0">PERSON</data>
      <data key="d1">Lan Yan is an author who contributed to the research on ToolLLM, a system for facilitating large language models to master 16000+ real-world APIs</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YAXI LU">
      <data key="d0">PERSON</data>
      <data key="d1">Yaxi Lu is an author who contributed to the research on ToolLLM, a system for facilitating large language models to master 16000+ real-world APIs</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YANKAI LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Yankai Lin is an author who contributed to the research on ToolLLM, a system for facilitating large language models to master 16000+ real-world APIs</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XIN CONG">
      <data key="d0">PERSON</data>
      <data key="d1">Xin Cong is an author who contributed to the research on ToolLLM, a system for facilitating large language models to master 16000+ real-world APIs</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XIANGRU TANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xiangru Tang is an author who contributed to the research on ToolLLM, a system for facilitating large language models to master 16000+ real-world APIs</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BILL QIAN">
      <data key="d0">PERSON</data>
      <data key="d1">Bill Qian is an author who contributed to the research on ToolLLM, a system for facilitating large language models to master 16000+ real-world APIs</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SIHAN ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Sihan Zhao is an author who contributed to the research on ToolLLM, a system for facilitating large language models to master 16000+ real-world APIs</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RUNCHU TIAN">
      <data key="d0">PERSON</data>
      <data key="d1">Runchu Tian is an author who contributed to the research on ToolLLM, a system for facilitating large language models to master 16000+ real-world APIs</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RUOBING XIE">
      <data key="d0">PERSON</data>
      <data key="d1">Ruobing Xie is an author who contributed to the research on ToolLLM, a system for facilitating large language models to master 16000+ real-world APIs</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JIE ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Jie Zhou is an author who contributed to the research on ToolLLM, a system for facilitating large language models to master 16000+ real-world APIs</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MARK GERSTEIN">
      <data key="d0">PERSON</data>
      <data key="d1">Mark Gerstein is an author who contributed to the research on ToolLLM, a system for facilitating large language models to master 16000+ real-world APIs</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DAHAI LI">
      <data key="d0">PERSON</data>
      <data key="d1">Dahai Li is an author who contributed to the research on ToolLLM, a system for facilitating large language models to master 16000+ real-world APIs</data>
      <data key="d2">3d1f6634f93f8a4c296dc8df7e59859e</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZAKHAR SHUMAYLOV">
      <data key="d0">PERSON</data>
      <data key="d1">Zakhar Shumaylov is an author who contributed to the research on the curse of recursion and its effects on training models with generated data</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YIREN ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Yiren Zhao is an author who contributed to the research on the curse of recursion and its effects on training models with generated data</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YARIN GAL">
      <data key="d0">PERSON</data>
      <data key="d1">Yarin Gal is an author who contributed to the research on the curse of recursion and its effects on training models with generated data</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NICOLAS PAPERNOT">
      <data key="d0">PERSON</data>
      <data key="d1">Nicolas Papernot is an author who contributed to the research on the curse of recursion and its effects on training models with generated data</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ROSS ANDERSON">
      <data key="d0">PERSON</data>
      <data key="d1">Ross Anderson is an author who contributed to the research on the curse of recursion and its effects on training models with generated data</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="THE CURSE OF RECURSION">
      <data key="d0">RESEARCH TOPIC</data>
      <data key="d1">A study on how training models on generated data can lead to forgetting previously learned information</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">RESEARCH TOPIC</data>
    </node>
    <node id="MOHAMMED LATIF SIDDIQ">
      <data key="d0">PERSON</data>
      <data key="d1">Mohammed Latif Siddiq is an author who contributed to the research on evaluating generated regular expressions and their proneness to DoS attacks</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JIAHAO ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jiahao Zhang is an author who contributed to the research on evaluating generated regular expressions and their proneness to DoS attacks</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LINDSAY RONEY">
      <data key="d0">PERSON</data>
      <data key="d1">Lindsay Roney is an author who contributed to the research on evaluating generated regular expressions and their proneness to DoS attacks</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JOANNA C. S. SANTOS">
      <data key="d0">PERSON</data>
      <data key="d1">Joanna C. S. Santos is an author who contributed to the research on evaluating generated regular expressions and their proneness to DoS attacks</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RE(GEX|DOS)EVAL">
      <data key="d0">RESEARCH TOPIC</data>
      <data key="d1">A study on evaluating generated regular expressions and their susceptibility to denial-of-service attacks</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">RESEARCH TOPIC</data>
    </node>
    <node id="MIRAC SUZGUN">
      <data key="d0">PERSON</data>
      <data key="d1">Mirac Suzgun is an author who contributed to the research on challenging big-bench tasks and the effectiveness of chain-of-thought reasoning</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NATHAN SCALES">
      <data key="d0">PERSON</data>
      <data key="d1">Nathan Scales is an author who contributed to the research on challenging big-bench tasks and the effectiveness of chain-of-thought reasoning</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NATHANAEL SCH&#196;RLI">
      <data key="d0">PERSON</data>
      <data key="d1">Nathanael Sch&#228;rli is an author who contributed to the research on challenging big-bench tasks and the effectiveness of chain-of-thought reasoning</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SEBASTIAN GEHRMANN">
      <data key="d0">PERSON</data>
      <data key="d1">Sebastian Gehrmann is an author who contributed to the research on challenging big-bench tasks and the effectiveness of chain-of-thought reasoning</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YI TAY">
      <data key="d0">PERSON</data>
      <data key="d1">Yi Tay is an author who contributed to the research on challenging big-bench tasks and the effectiveness of chain-of-thought reasoning</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HYUNG WON CHUNG">
      <data key="d0">PERSON</data>
      <data key="d1">Hyung Won Chung is an author who contributed to the research on challenging big-bench tasks and the effectiveness of chain-of-thought reasoning</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AAKANKSHA CHOWDHERY">
      <data key="d0">PERSON</data>
      <data key="d1">Aakanksha Chowdhery is an author who contributed to the research on challenging big-bench tasks and the effectiveness of chain-of-thought reasoning</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="QUOC V LE">
      <data key="d0">PERSON</data>
      <data key="d1">Quoc V Le is an author who contributed to the research on challenging big-bench tasks and the effectiveness of chain-of-thought reasoning</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ED H CHI">
      <data key="d0">PERSON</data>
      <data key="d1">Ed H Chi is an author who contributed to the research on challenging big-bench tasks and the effectiveness of chain-of-thought reasoning</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DENNY ZHOU">
      <data key="d0">PERSON</data>
      <data key="d1">Denny Zhou is an author who contributed to the research on challenging big-bench tasks and the effectiveness of chain-of-thought reasoning</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JASON WEI">
      <data key="d0">PERSON</data>
      <data key="d1">Jason Wei is an author who contributed to the research on challenging big-bench tasks and the effectiveness of chain-of-thought reasoning</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHAIN-OF-THOUGHT">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A reasoning process that involves breaking down complex problems into a series of simpler, interconnected steps</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="WEN WAI YIM">
      <data key="d0">PERSON</data>
      <data key="d1">Wen Wai Yim is an author who contributed to the research on ACI-Bench, a dataset for benchmarking automatic visit note generation</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YUJUAN FU">
      <data key="d0">PERSON</data>
      <data key="d1">Yujuan Fu is an author who contributed to the research on ACI-Bench, a dataset for benchmarking automatic visit note generation</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ASMA BEN ABACHA">
      <data key="d0">PERSON</data>
      <data key="d1">Asma Ben Abacha is an author who contributed to the research on ACI-Bench, a dataset for benchmarking automatic visit note generation</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="NEAL SNIDER">
      <data key="d0">PERSON</data>
      <data key="d1">Neal Snider is an author who contributed to the research on ACI-Bench, a dataset for benchmarking automatic visit note generation</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="THOMAS LIN">
      <data key="d0">PERSON</data>
      <data key="d1">Thomas Lin is an author who contributed to the research on ACI-Bench, a dataset for benchmarking automatic visit note generation</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="MELIHA YETISGEN">
      <data key="d0">PERSON</data>
      <data key="d1">Meliha Yetisgen is an author who contributed to the research on ACI-Bench, a dataset for benchmarking automatic visit note generation</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="QINGYUN WU">
      <data key="d0">PERSON</data>
      <data key="d1">Qingyun Wu is an author who contributed to the research on AutoGen, enabling next-gen LLM applications via multi-agent conversation</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GAGAN BANSAL">
      <data key="d0">PERSON</data>
      <data key="d1">Gagan Bansal is an author who contributed to the research on AutoGen, enabling next-gen LLM applications via multi-agent conversation</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JIEYU ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Jieyu Zhang is an author who contributed to the research on AutoGen, enabling next-gen LLM applications via multi-agent conversation</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YIRAN WU">
      <data key="d0">PERSON</data>
      <data key="d1">Yiran Wu is an author who contributed to the research on AutoGen, enabling next-gen LLM applications via multi-agent conversation</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="BEIBIN LI">
      <data key="d0">PERSON</data>
      <data key="d1">Beibin Li is an author who contributed to the research on AutoGen, enabling next-gen LLM applications via multi-agent conversation</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ERKANG ZHU">
      <data key="d0">PERSON</data>
      <data key="d1">Erkang Zhu is an author who contributed to the research on AutoGen, enabling next-gen LLM applications via multi-agent conversation</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="LI JIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Li Jiang is an author who contributed to the research on AutoGen, enabling next-gen LLM applications via multi-agent conversation</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XIAOYUN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xiaoyun Zhang is an author who contributed to the research on AutoGen, enabling next-gen LLM applications via multi-agent conversation</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHAOKUN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Shaokun Zhang is an author who contributed to the research on AutoGen, enabling next-gen LLM applications via multi-agent conversation</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JIALE LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Jiale Liu is an author who contributed to the research on AutoGen, enabling next-gen LLM applications via multi-agent conversation</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AHMED HASSAN AWADALLAH">
      <data key="d0">PERSON</data>
      <data key="d1">Ahmed Hassan Awadallah is an author who contributed to the research on AutoGen, enabling next-gen LLM applications via multi-agent conversation</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RYEN W WHITE">
      <data key="d0">PERSON</data>
      <data key="d1">Ryen W White is an author who contributed to the research on AutoGen, enabling next-gen LLM applications via multi-agent conversation</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DOUG BURGER">
      <data key="d0">PERSON</data>
      <data key="d1">Doug Burger is an author who contributed to the research on AutoGen, enabling next-gen LLM applications via multi-agent conversation</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHI WANG">
      <data key="d0">PERSON</data>
      <data key="d1">Chi Wang is an author who contributed to the research on AutoGen, enabling next-gen LLM applications via multi-agent conversation</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AUTOGEN">
      <data key="d0">SYSTEM</data>
      <data key="d1">A system enabling next-gen large language model applications via multi-agent conversation</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">SYSTEM</data>
    </node>
    <node id="CONGYING XIA">
      <data key="d0">PERSON</data>
      <data key="d1">Congying Xia is an author who contributed to the research on FoFo, a benchmark to evaluate LLMs' format-following capability</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHEN XING">
      <data key="d0">PERSON</data>
      <data key="d1">Chen Xing is an author who contributed to the research on FoFo, a benchmark to evaluate LLMs' format-following capability</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JIANGSHU DU">
      <data key="d0">PERSON</data>
      <data key="d1">Jiangshu Du is an author who contributed to the research on FoFo, a benchmark to evaluate LLMs' format-following capability</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XINYI YANG">
      <data key="d0">PERSON</data>
      <data key="d1">Xinyi Yang is an author who contributed to the research on FoFo, a benchmark to evaluate LLMs' format-following capability</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YIHAO FENG">
      <data key="d0">PERSON</data>
      <data key="d1">Yihao Feng is an author who contributed to the research on FoFo, a benchmark to evaluate LLMs' format-following capability</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RAN XU">
      <data key="d0">PERSON</data>
      <data key="d1">Ran Xu is an author who contributed to the research on FoFo, a benchmark to evaluate LLMs' format-following capability</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WENPENG YIN">
      <data key="d0">PERSON</data>
      <data key="d1">Wenpeng Yin is an author who contributed to the research on FoFo, a benchmark to evaluate LLMs' format-following capability</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CAIMING XIONG">
      <data key="d0">PERSON</data>
      <data key="d1">Caiming Xiong is an author who contributed to the research on FoFo, a benchmark to evaluate LLMs' format-following capability</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="GUANGZHI XIONG">
      <data key="d0">PERSON</data>
      <data key="d1">Guangzhi Xiong is an author who contributed to the research on benchmarking retrieval-augmented generation for medicine</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="QIAO JIN">
      <data key="d0">PERSON</data>
      <data key="d1">Qiao Jin is an author who contributed to the research on benchmarking retrieval-augmented generation for medicine</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHIYONG LU">
      <data key="d0">PERSON</data>
      <data key="d1">Zhiyong Lu is an author who contributed to the research on benchmarking retrieval-augmented generation for medicine</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="AIDONG ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Aidong Zhang is an author who contributed to the research on benchmarking retrieval-augmented generation for medicine</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RETRIEVAL-AUGMENTED GENERATION FOR MEDICINE">
      <data key="d0">RESEARCH TOPIC</data>
      <data key="d1">A study on the application of retrieval-augmented generation techniques in the field of medicine</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">RESEARCH TOPIC</data>
    </node>
    <node id="QINGFENG SUN">
      <data key="d0">PERSON</data>
      <data key="d1">Qingfeng Sun is an author who contributed to the research on WizardLM, empowering large language models to follow complex instructions</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="KAI ZHENG">
      <data key="d0">PERSON</data>
      <data key="d1">Kai Zheng is an author who contributed to the research on WizardLM, empowering large language models to follow complex instructions</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="XIUBO GENG">
      <data key="d0">PERSON</data>
      <data key="d1">Xiubo Geng is an author who contributed to the research on WizardLM, empowering large language models to follow complex instructions</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="PU ZHAO">
      <data key="d0">PERSON</data>
      <data key="d1">Pu Zhao is an author who contributed to the research on WizardLM, empowering large language models to follow complex instructions</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JIAZHAN FENG">
      <data key="d0">PERSON</data>
      <data key="d1">Jiazhan Feng is an author who contributed to the research on WizardLM, empowering large language models to follow complex instructions</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="CHONGYANG TAO">
      <data key="d0">PERSON</data>
      <data key="d1">Chongyang Tao is an author who contributed to the research on WizardLM, empowering large language models to follow complex instructions</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="DAXIN JIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Daxin Jiang is an author who contributed to the research on WizardLM, empowering large language models to follow complex instructions</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WIZARDLM">
      <data key="d0">SYSTEM</data>
      <data key="d1">A system designed to empower large language models to follow complex instructions</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">SYSTEM</data>
    </node>
    <node id="LONGHUI YU">
      <data key="d0">PERSON</data>
      <data key="d1">Longhui Yu is an author who contributed to the research on MetaMath, a system for bootstrapping mathematical questions for large language models</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WEISEN JIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Weisen Jiang is an author who contributed to the research on MetaMath, a system for bootstrapping mathematical questions for large language models</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="HAN SHI">
      <data key="d0">PERSON</data>
      <data key="d1">Han Shi is an author who contributed to the research on MetaMath, a system for bootstrapping mathematical questions for large language models</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JINCHENG YU">
      <data key="d0">PERSON</data>
      <data key="d1">Jincheng Yu is an author who contributed to the research on MetaMath, a system for bootstrapping mathematical questions for large language models</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHENGYING LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Zhengying Liu is an author who contributed to the research on MetaMath, a system for bootstrapping mathematical questions for large language models</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YU ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yu Zhang is an author who contributed to the research on MetaMath, a system for bootstrapping mathematical questions for large language models</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="JAMES T KWOK">
      <data key="d0">PERSON</data>
      <data key="d1">James T Kwok is an author who contributed to the research on MetaMath, a system for bootstrapping mathematical questions for large language models</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ZHENGUO LI">
      <data key="d0">PERSON</data>
      <data key="d1">Zhenguo Li is an author who contributed to the research on MetaMath, a system for bootstrapping mathematical questions for large language models</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ADRIAN WELLER">
      <data key="d0">PERSON</data>
      <data key="d1">Adrian Weller is an author who contributed to the research on MetaMath, a system for bootstrapping mathematical questions for large language models</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WEIYANG LIU">
      <data key="d0">PERSON</data>
      <data key="d1">Weiyang Liu is an author who contributed to the research on MetaMath, a system for bootstrapping mathematical questions for large language models</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="METAMATH">
      <data key="d0">SYSTEM</data>
      <data key="d1">A system designed to bootstrap mathematical questions for large language models</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">SYSTEM</data>
    </node>
    <node id="YIFAN ZHANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yifan Zhang is an author who contributed to the research on AutoMathText, a system for autonomous data selection with language models for mathematical texts</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YIFAN LUO">
      <data key="d0">PERSON</data>
      <data key="d1">Yifan Luo is an author who contributed to the research on AutoMathText, a system for autonomous data selection with language models for mathematical texts</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YANG YUAN">
      <data key="d0">PERSON</data>
      <data key="d1">Yang Yuan is an author who contributed to the research on AutoMathText, a system for autonomous data selection with language models for mathematical texts</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANDREW CHI-CHIH YAO">
      <data key="d0">PERSON</data>
      <data key="d1">Andrew Chi-Chih Yao is an author who contributed to the research on AutoMathText, a system for autonomous data selection with language models for mathematical texts</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="WANJUN ZHONG">
      <data key="d0">PERSON</data>
      <data key="d1">Wanjun Zhong is an author who contributed to the research on AGIEval, a human-centric benchmark for evaluating foundation models</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="RUIXIANG CUI">
      <data key="d0">PERSON</data>
      <data key="d1">Ruixiang Cui is an author who contributed to the research on AGIEval, a human-centric benchmark for evaluating foundation models</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YIDUO GUO">
      <data key="d0">PERSON</data>
      <data key="d1">Yiduo Guo is an author who contributed to the research on AGIEval, a human-centric benchmark for evaluating foundation models</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YAOBO LIANG">
      <data key="d0">PERSON</data>
      <data key="d1">Yaobo Liang is an author who contributed to the research on AGIEval, a human-centric benchmark for evaluating foundation models</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="SHUAI LU">
      <data key="d0">PERSON</data>
      <data key="d1">Shuai Lu is an author who contributed to the research on AGIEval, a human-centric benchmark for evaluating foundation models</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="YANLIN WANG">
      <data key="d0">**ANALYSIS:**("ENTITY"</data>
      <data key="d1">ILIA SHUMAILOV</data>
      <data key="d2">f4e98ee0b7fb42428f3312f29cb444dd</data>
    </node>
    <node id="CRITICAL COMPREHENSION QUESTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Construct two statements about the purpose or point of view that the reader must assess as true or false, with one being true and the other false</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="EVALUATIVE COMPREHENSION QUESTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">An open-ended question that prompts an in-depth analysis of the text&#8217;s theme or the effectiveness of an argument</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="VOCABULARY AND LANGUAGE USE">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">A fill-in-the-blank question that tests understanding of a particular word or phrase used in the text</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="RELATIONSHIP COMPREHENSION QUESTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">A matching question where respondents pair items based on a specific criterion</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="SEQUENCING EVENTS">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">A series of events from the text arranged in the correct chronological order</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="STRENGTHEN">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Identify information that would make the argument&#8217;s conclusion more likely to be true</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="WEAKEN">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Find evidence or an argument that would make the conclusion less likely to be true</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="ASSUMPTION">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Determine what must be true for the argument to hold</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="FLAW">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Point out a mistake in the argument&#8217;s reasoning</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="INFERENCE">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Choose an option that logically follows from the information provided</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="PRINCIPLE">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Recognize the general rule or principle that underlies the argument</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="METHOD OF REASONING">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Describe how the argument is constructed logically</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="RESOLVE THE PARADOX">
      <data key="d0">QUESTION TYPE</data>
      <data key="d1">Offer an explanation that reconciles seemingly contradictory information</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">QUESTION TYPE</data>
    </node>
    <node id="PARAPHRASING">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Rewriting text using different words and sentence structures while maintaining the original meaning</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION</data>
    </node>
    <node id="TEXT SIMPLIFICATION">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Making text easier to read and understand by using simpler words and sentence structures, often for children or language learners</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION</data>
    </node>
    <node id="TEXT EXPANSION">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Adding more information or detail to make text more comprehensive or to meet a certain word count</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION</data>
    </node>
    <node id="TEXT TRANSLATION">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Converting text from one language to another while attempting to preserve the original meaning as closely as possible</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION</data>
    </node>
    <node id="TEXT FORMATTING">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Altering the appearance of text to improve readability or for stylistic purposes</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION</data>
    </node>
    <node id="SENTIMENT MODIFICATION">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Changing the tone of the text to alter its emotional impact, such as making a sentence sound more positive or negative</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION</data>
    </node>
    <node id="TEXT ANNOTATION">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Adding notes, comments, or explanations to a text, often for the purpose of analysis or to provide additional context</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION</data>
    </node>
    <node id="KEYWORD REPLACEMENT">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Substituting specific words or phrases with synonyms or related terms</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION</data>
    </node>
    <node id="TEXT REMOVING">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Redacting or removing content from text</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION</data>
    </node>
    <node id="TEXT CAPITALIZATION">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Adjusting the case of letters in text, such as converting to uppercase, lowercase, title case, or sentence case, starting every sentence with a particular letter, word</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION</data>
    </node>
    <node id="TEXT STYLING">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Applying styles like bold, italics, underline, etc., to emphasize certain parts of the text or for aesthetic purposes</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION</data>
    </node>
    <node id="CONTENT REWRITING">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Extensively modifying a text to produce a new version, which could involve changing the perspective, style, or target audience</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION</data>
    </node>
    <node id="DATA NORMALIZATION">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Standardizing text to ensure consistency, such as converting dates and times to a standard format or unifying the spelling of words</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION</data>
    </node>
    <node id="PLAGIARISM REWORDING">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Altering text to avoid plagiarism, ensuring that the content is original</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION</data>
    </node>
    <node id="CODE SWITCHING">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Alternating between languages or dialects within a text, often to reflect bilingual speakers&#8217; patterns or for creative writing</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION</data>
    </node>
    <node id="TEXT OBFUSCATION">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Intentionally making text vague or harder to understand, sometimes for security purposes like masking personal data</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION</data>
    </node>
    <node id="TEXTUAL ENTAILMENT">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Modifying a sentence or phrase to either entail or contradict another sentence, often used in natural language processing tasks</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION</data>
    </node>
    <node id="REWRITING WITH VOCABULARY LIMITATIONS">
      <data key="d0">TEXT MODIFICATION</data>
      <data key="d1">Rewriting the entire text or a piece of it while using a limited vocabulary, such as all words starting with a specific letter</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
      <data key="d3">TEXT MODIFICATION</data>
    </node>
    <node id="NUMERICAL DISCRETE REASONING">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="QUESTION TYPE">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="EVALUATION METHOD">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="TECHNOLOGY">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="INSTRUCTION TAXONOMY">
      <data key="d0">EVALUATION METHOD</data>
      <data key="d1">A structured classification of different types of instructions used for seed instruction generation</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="SEED INSTRUCTION GENERATION">
      <data key="d0">EVALUATION METHOD</data>
      <data key="d1">The process of creating initial instructions for a task, often used in machine learning and natural language processing</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="EVALUATOR ASSISTANT">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A system or tool designed to assist evaluators by parsing student responses and extracting relevant information
An assistant that helps in evaluating student responses by parsing and comparing answers</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50,5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="EXTRACTION SYSTEM MESSAGE">
      <data key="d0">TECHNOLOGY</data>
      <data key="d1">A predefined message used by the GPT-4 model to extract the option selected by the model from the model&#8217;s response in multiple choice questions</data>
      <data key="d2">5819b66e04fd77fa705574edc49395bb</data>
    </node>
    <node id="STUDENT">
      <data key="d0">PERSON</data>
      <data key="d1">An individual who is responding to the questions and providing answers</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
      <data key="d3">PERSON</data>
    </node>
    <node id="ANSWER">
      <data key="d0">RESPONSE</data>
      <data key="d1">The response given by the student to a question, which can be a single option or multiple options</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
      <data key="d3">RESPONSE</data>
    </node>
    <node id="OPTIONS">
      <data key="d0">CHOICES</data>
      <data key="d1">A list of possible answers provided to the student from which they can choose</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
      <data key="d3">CHOICES</data>
    </node>
    <node id="PARSED STUDENT ANSWER">
      <data key="d0">EXTRACTED RESPONSE</data>
      <data key="d1">The final answer extracted from the student's response, represented by the alphabet(s) corresponding to the chosen option(s)</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
      <data key="d3">EXTRACTED RESPONSE</data>
    </node>
    <node id="EXACT MATCH/SPAN EXTRACTION">
      <data key="d0">TECHNIQUE</data>
      <data key="d1">A method used to evaluate the correctness of a student's answer by comparing it with a ground-truth answer</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
      <data key="d3">TECHNIQUE</data>
    </node>
    <node id="MATHS GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">A specific system message used to guide GPT-4 in evaluating math-based questions</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
      <data key="d3">INSTRUCTION</data>
    </node>
    <node id="GENERAL EXTRACTION SYSTEM MESSAGE">
      <data key="d0">INSTRUCTION</data>
      <data key="d1">A system message used to guide GPT-4 in evaluating exact match/span extraction problems</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
      <data key="d3">INSTRUCTION</data>
    </node>
    <node id="EMOTION SCORES">
      <data key="d0">METRIC</data>
      <data key="d1">Scores assigned to different emotions based on a conversation, ranging from 0 to 10</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
      <data key="d3">METRIC</data>
    </node>
    <node id="CRITIQUE">
      <data key="d0">FEEDBACK</data>
      <data key="d1">A step-by-step analysis provided to justify the emotion scores</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
      <data key="d3">FEEDBACK</data>
    </node>
    <node id="REVISED SCORES">
      <data key="d0">UPDATED METRIC</data>
      <data key="d1">Updated emotion scores after considering the critique</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
      <data key="d3">UPDATED METRIC</data>
    </node>
    <node id="RESIGNED">
      <data key="d0">EMOTION</data>
      <data key="d1">A feeling of acceptance of something undesirable but inevitable
Elliot feels resigned because he has confessed his feelings to Alex, knowing that Alex is already in a relationship. This emotion is scored 7 out of 10</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,103d98395c393552cc954c89d4e59f50</data>
      <data key="d3">EMOTION</data>
    </node>
    <node id="ANGRY">
      <data key="d0">EMOTION</data>
      <data key="d1">A strong feeling of displeasure or hostility
Elliot feels a bit angry at himself for putting himself in this situation. This emotion is scored 3 out of 10</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,103d98395c393552cc954c89d4e59f50</data>
      <data key="d3">EMOTION</data>
    </node>
    <node id="HOPEFUL">
      <data key="d0">EMOTION</data>
      <data key="d1">A feeling of expectation and desire for a certain thing to happen
Elliot feels a slight sense of hopefulness in his confession, hoping that Alex might reciprocate his feelings. This emotion is scored 5 out of 10</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,103d98395c393552cc954c89d4e59f50</data>
      <data key="d3">EMOTION</data>
    </node>
    <node id="EMBARRASSED">
      <data key="d0">EMOTION</data>
      <data key="d1">A feeling of self-consciousness, shame, or awkwardness
Elliot feels embarrassed for putting Alex in an awkward position. This emotion is scored 8 out of 10</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba,103d98395c393552cc954c89d4e59f50</data>
      <data key="d3">EMOTION</data>
    </node>
    <node id="VERDICT">
      <data key="d0">RESULT</data>
      <data key="d1">The final judgment on whether the student's answer is correct or incorrect</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="CORRECT">
      <data key="d0">RESULT</data>
      <data key="d1">Indicates that the student's answer matches the correct answer</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="INCORRECT">
      <data key="d0">RESULT</data>
      <data key="d1">Indicates that the student's answer does not match the correct answer</data>
      <data key="d2">103d98395c393552cc954c89d4e59f50</data>
    </node>
    <node id="ALEX">
      <data key="d0">PERSON</data>
      <data key="d1">Alex is a person who is already in a relationship and is the recipient of Elliot's confession of feelings</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="OPEN-ENDED GENERATION">
      <data key="d0">TASK</data>
      <data key="d1">Tasks where a model is prompted to generate an answer to an open-ended question without a ground-truth to match the answer</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="HALLUCINATION JUDGE">
      <data key="d0">TASK</data>
      <data key="d1">A task where a judge decides if there is any hallucination in a generated summary by extracting relevant facts and verifying the correctness of the summary</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="QUALITY JUDGE">
      <data key="d0">TASK</data>
      <data key="d1">A task where a judge evaluates the quality of a response provided by an AI assistant based on criteria like instruction adherence, content grounding, and overall quality</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="ELLIOT">
      <data key="d0" />
      <data key="d1" />
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="VERSION 0613">
      <data key="d0">VERSION</data>
      <data key="d1">Version 0613 of GPT-4 is used in the FOFO and AlpacaEval benchmarks for evaluation purposes</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="VERSION 1106-PREVIEW">
      <data key="d0">VERSION</data>
      <data key="d1">Version 1106-preview of GPT-4 is used in the InfoBench benchmark for evaluation purposes</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="BENCHMARK">
      <data key="d0">TASK</data>
      <data key="d1">A standard or point of reference against which things may be compared or assessed, used in the context of evaluating AI models</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="PROMPT">
      <data key="d0">TASK</data>
      <data key="d1">A set of instructions or questions given to an AI model to generate a response</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="SCORE">
      <data key="d0">METRIC</data>
      <data key="d1">A numerical value assigned to evaluate the performance or quality of a model's response</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="WIN-RATE">
      <data key="d0">METRIC</data>
      <data key="d1">The number of times a model's output is preferred over a reference answer in a benchmark</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="SUMMARY">
      <data key="d0">TASK</data>
      <data key="d1">A brief statement or account of the main points of something, often generated by an AI model</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="INSTRUCTION ADHERENCE">
      <data key="d0">CRITERIA</data>
      <data key="d1">The degree to which a model's response follows the given instructions</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="CONTENT GROUNDING">
      <data key="d0">CRITERIA</data>
      <data key="d1">The degree to which a model's response is based on the given content without introducing new information</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <node id="OVERALL QUALITY">
      <data key="d0">CRITERIA</data>
      <data key="d1">The overall assessment of the clarity, coherence, and completeness of a model's response</data>
      <data key="d2">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </node>
    <edge source="GRAPH RAG" target="QUERY-FOCUSED SUMMARIZATION (QFS)">
      <data key="d4">4.0</data>
      <data key="d5">Graph RAG is proposed as a method to combine the strengths of retrieval-augmented generation and query-focused summarization.
Graph RAG combines query-focused summarization with knowledge graph generation and retrieval-augmented generation</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d,ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="RETRIEVAL-AUGMENTED GENERATION (RAG)">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG aims to address the limitations of RAG by incorporating query-focused summarization.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="LARGE LANGUAGE MODELS (LLMS)">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG uses large language models to build a graph-based text index and generate community summaries.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="COMMUNITY DETECTION">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG uses community detection to partition the graph index into groups of elements that can be summarized in parallel.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="SENSEMAKING">
      <data key="d4">4.0</data>
      <data key="d5">Graph RAG supports human-led sensemaking over entire text corpora by enabling the generation of comprehensive and diverse answers to global questions.
Graph RAG supports human sensemaking over entire text corpora</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d,ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="MICROSOFT RESEARCH">
      <data key="d4">2.0</data>
      <data key="d5">Microsoft Research is involved in the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES">
      <data key="d4">2.0</data>
      <data key="d5">Microsoft Strategic Missions and Technologies is involved in the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="MICROSOFT OFFICE OF THE CTO">
      <data key="d4">2.0</data>
      <data key="d5">Microsoft Office of the CTO is involved in the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="DAREN EDGE">
      <data key="d4">2.0</data>
      <data key="d5">Daren Edge contributed to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="HA TRINH">
      <data key="d4">2.0</data>
      <data key="d5">Ha Trinh contributed to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="NEWMAN CHENG">
      <data key="d4">2.0</data>
      <data key="d5">Newman Cheng contributed to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="JOSHUA BRADLEY">
      <data key="d4">2.0</data>
      <data key="d5">Joshua Bradley contributed to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="ALEX CHAO">
      <data key="d4">2.0</data>
      <data key="d5">Alex Chao contributed to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="APURVA MODY">
      <data key="d4">2.0</data>
      <data key="d5">Apurva Mody contributed to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="STEVEN TRUITT">
      <data key="d4">2.0</data>
      <data key="d5">Steven Truitt contributed to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="JONATHAN LARSON">
      <data key="d4">2.0</data>
      <data key="d5">Jonathan Larson contributed to the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="INDEXING TIME">
      <data key="d4">2.0</data>
      <data key="d5">Indexing time is a stage in the Graph RAG pipeline where the graph index is created and partitioned.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="QUERY TIME">
      <data key="d4">2.0</data>
      <data key="d5">Query time is a stage in the Graph RAG pipeline where community summaries are used to generate partial and final responses to queries.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="GRAPH INDEX">
      <data key="d4">4.0</data>
      <data key="d5">Graph RAG uses a graph index created by an LLM to organize and summarize source document text.
Graph RAG uses the graph index to partition data for global summarization</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d,ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="COMMUNITY SUMMARIES">
      <data key="d4">4.0</data>
      <data key="d5">Graph RAG generates community summaries for groups of closely-related entities in the graph index.
Graph RAG uses community summaries to answer user queries</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d,26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH RAG" target="GLOBAL ANSWER">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG produces a global answer by summarizing all community summaries relevant to a query.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="LOCAL GRAPH RAG">
      <data key="d4">2.0</data>
      <data key="d5">Local Graph RAG is a variant of the Graph RAG approach that focuses on local regions of text.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="GLOBAL GRAPH RAG">
      <data key="d4">2.0</data>
      <data key="d5">Global Graph RAG is a variant of the Graph RAG approach that scales to global questions over large text corpora.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="OPEN-SOURCE IMPLEMENTATION">
      <data key="d4">2.0</data>
      <data key="d5">An open-source implementation of the Graph RAG approach is available for public use.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="MICROSOFT">
      <data key="d4">2.0</data>
      <data key="d5">Microsoft is involved in the development of the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH RAG" target="RAG">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG is a novel approach based on RAG</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GRAPH RAG" target="KNOWLEDGE GRAPH">
      <data key="d4">4.0</data>
      <data key="d5">Graph RAG uses a knowledge graph for summarization
Graph RAG uses a self-generated graph index, which is a type of knowledge graph</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7,edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="NA&#207;VE RAG">
      <data key="d4">4.0</data>
      <data key="d5">Graph RAG consistently outperformed na&#239;ve RAG in both comprehensiveness and diversity metrics across datasets
Graph RAG is an advanced system that overcomes the drawbacks of Na&#239;ve RAG</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f,ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GRAPH RAG" target="LLM">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG uses LLMs for summarizing and retrieving information</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="GENERATION-AUGMENTED RETRIEVAL">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG incorporates concepts related to generation-augmented retrieval</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="ITERATIVE RETRIEVAL-GENERATION">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG uses iterative retrieval-generation strategies</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="FEDERATED RETRIEVAL-GENERATION">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG uses federated retrieval-generation strategies</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="MULTI-DOCUMENT SUMMARIZATION">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG incorporates concepts related to multi-document summarization</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="MULTI-HOP QUESTION ANSWERING">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG incorporates concepts related to multi-hop question answering</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="HIERARCHICAL INDEX">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG uses hierarchical indexing for summarization</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="TREE OF CLARIFICATIONS">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG's approach bears resemblance to generating a tree of clarifications</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="CAUSAL GRAPHS">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG's approach is related to the extraction of causal graphs</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="GRAPH RAG INDEX">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG uses a self-generated graph index for partitioning data</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH RAG" target="GLOBAL SUMMARIZATION">
      <data key="d4">2.0</data>
      <data key="d5">Graph RAG achieves competitive results in global summarization compared to graph-free approaches</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="ALONSO GUEVARA FERN&#193;NDEZ">
      <data key="d4">2.0</data>
      <data key="d5">Alonso Guevara Fern&#225;ndez contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="AMBER HOAK">
      <data key="d4">2.0</data>
      <data key="d5">Amber Hoak contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="ANDR&#201;S MORALES ESQUIVEL">
      <data key="d4">2.0</data>
      <data key="d5">Andr&#233;s Morales Esquivel contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="BEN CUTLER">
      <data key="d4">2.0</data>
      <data key="d5">Ben Cutler contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="BILLIE RINALDI">
      <data key="d4">2.0</data>
      <data key="d5">Billie Rinaldi contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="CHRIS SANCHEZ">
      <data key="d4">2.0</data>
      <data key="d5">Chris Sanchez contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="CHRIS TREVINO">
      <data key="d4">2.0</data>
      <data key="d5">Chris Trevino contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="CHRISTINE CAGGIANO">
      <data key="d4">2.0</data>
      <data key="d5">Christine Caggiano contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="DAVID TITTSWORTH">
      <data key="d4">2.0</data>
      <data key="d5">David Tittsworth contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="DAYENNE DE SOUZA">
      <data key="d4">2.0</data>
      <data key="d5">Dayenne de Souza contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="DOUGLAS ORBAKER">
      <data key="d4">2.0</data>
      <data key="d5">Douglas Orbaker contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="ED CLARK">
      <data key="d4">2.0</data>
      <data key="d5">Ed Clark contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="GABRIEL NIEVES-PONCE">
      <data key="d4">2.0</data>
      <data key="d5">Gabriel Nieves-Ponce contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="GAUDY BLANCO MENESES">
      <data key="d4">2.0</data>
      <data key="d5">Gaudy Blanco Meneses contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="KATE LYTVYNETS">
      <data key="d4">1.0</data>
      <data key="d5">Kate Lytvynets contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="KATY SMITH">
      <data key="d4">2.0</data>
      <data key="d5">Katy Smith contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="M&#211;NICA CARVAJAL">
      <data key="d4">2.0</data>
      <data key="d5">M&#243;nica Carvajal contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="NATHAN EVANS">
      <data key="d4">2.0</data>
      <data key="d5">Nathan Evans contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="RICHARD ORTEGA">
      <data key="d4">2.0</data>
      <data key="d5">Richard Ortega contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="RODRIGO RACANICCI">
      <data key="d4">2.0</data>
      <data key="d5">Rodrigo Racanicci contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="SARAH SMITH">
      <data key="d4">2.0</data>
      <data key="d5">Sarah Smith contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="SHANE SOLOMON">
      <data key="d4">2.0</data>
      <data key="d5">Shane Solomon contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GRAPH RAG" target="KATE LYTIVYNETS">
      <data key="d4">1.0</data>
      <data key="d5">Kate Lytvynets contributed to the work on Graph RAG</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="QUERY-FOCUSED SUMMARIZATION (QFS)" target="DANG">
      <data key="d4">2.0</data>
      <data key="d5">Dang contributed to the study of query-focused summarization.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="QUERY-FOCUSED SUMMARIZATION (QFS)" target="BAUMEL ET AL.">
      <data key="d4">2.0</data>
      <data key="d5">Baumel et al. contributed to the study of query-focused abstractive summarization.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="QUERY-FOCUSED SUMMARIZATION (QFS)" target="LASKAR ET AL.">
      <data key="d4">2.0</data>
      <data key="d5">Laskar et al. contributed to the study of query-focused abstractive summarization.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="QUERY-FOCUSED SUMMARIZATION (QFS)" target="YAO ET AL.">
      <data key="d4">2.0</data>
      <data key="d5">Yao et al. contributed to the study of query-focused abstractive summarization.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="QUERY-FOCUSED SUMMARIZATION (QFS)" target="QUERY FOCUSED ABSTRACTIVE SUMMARIZATION">
      <data key="d4">2.0</data>
      <data key="d5">Query focused abstractive summarization is a method that incorporates query relevance into summarization</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="RETRIEVAL-AUGMENTED GENERATION (RAG)" target="LEWIS ET AL.">
      <data key="d4">2.0</data>
      <data key="d5">Lewis et al. contributed to the development of the retrieval-augmented generation technique.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="SENSEMAKING IN COMPLEX DOMAINS">
      <data key="d4">2.0</data>
      <data key="d5">Large language models are used to automate human-like sensemaking in complex domains.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="TRANSFORMER ARCHITECTURE">
      <data key="d4">2.0</data>
      <data key="d5">Transformer architecture has shown substantial improvements in various summarization tasks and is used in large language models.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="GPT">
      <data key="d4">2.0</data>
      <data key="d5">GPT is a type of large language model used for natural language processing tasks.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="LLAMA">
      <data key="d4">2.0</data>
      <data key="d5">Llama is a type of large language model used for natural language processing tasks.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="GEMINI">
      <data key="d4">2.0</data>
      <data key="d5">Gemini is a type of large language model used for natural language processing tasks.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS (LLMS)" target="SYNTHETIC DATA">
      <data key="d4">2.0</data>
      <data key="d5">Synthetic data is used to accelerate the development of Large Language Models (LLMs).</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="COMMUNITY DETECTION" target="LEIDEN">
      <data key="d4">2.0</data>
      <data key="d5">Leiden is a method used for community detection in the Graph RAG approach.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="COMMUNITY DETECTION" target="ENTITY GRAPH">
      <data key="d4">2.0</data>
      <data key="d5">Community detection is applied to the entity graph to partition it into communities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="COMMUNITY DETECTION" target="LEIDEN ALGORITHM">
      <data key="d4">2.0</data>
      <data key="d5">The Leiden algorithm is a method used for community detection.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="COMMUNITY DETECTION" target="GRAPH COMMUNITIES">
      <data key="d4">2.0</data>
      <data key="d5">Graph communities are the result of community detection.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="COMMUNITY DETECTION" target="FAST UNFOLDING OF COMMUNITIES">
      <data key="d4">2.0</data>
      <data key="d5">Fast unfolding of communities is a method for detecting communities in large networks</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="COMMUNITY DETECTION" target="COMMUNITY DETECTION APPROACHES">
      <data key="d4">1.0</data>
      <data key="d5">Community detection approaches are various methods for identifying communities within graphs</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="SENSEMAKING" target="GLOBAL SENSEMAKING QUESTIONS">
      <data key="d4">2.0</data>
      <data key="d5">Global sensemaking questions require understanding connections and drawing conclusions from large text corpora.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="SENSEMAKING" target="KLEIN ET AL.">
      <data key="d4">2.0</data>
      <data key="d5">Klein et al. defined sensemaking as a motivated, continuous effort to understand connections among people, places, and events.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="SENSEMAKING" target="ALTERNATIVE PERSPECTIVES">
      <data key="d4">1.0</data>
      <data key="d5">Sensemaking involves understanding complex information from alternative perspectives, as discussed by Klein, Moon, and Hoffman in 2006</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="LEIDEN" target="COMMUNITY DETECTION ALGORITHMS">
      <data key="d4">2.0</data>
      <data key="d5">Leiden is a type of community detection algorithm</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="SENSEMAKING IN COMPLEX DOMAINS" target="RANADE AND JOSHI">
      <data key="d4">2.0</data>
      <data key="d5">Ranade and Joshi contributed to the study of sensemaking in complex domains.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GRAPH INDEX" target="COMMUNITY SUMMARIES">
      <data key="d4">1.0</data>
      <data key="d5">The graph index is created using community summaries</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="GRAPH INDEX" target="GLEANING">
      <data key="d4">1.0</data>
      <data key="d5">Gleaning is used in the graph indexing process</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="GRAPH COMMUNITIES">
      <data key="d4">2.0</data>
      <data key="d5">Community summaries are created for each graph community.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="GLOBAL SUMMARIZATION">
      <data key="d4">1.0</data>
      <data key="d5">Community summaries are used for global summarization of the dataset.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="GLOBAL ANSWER">
      <data key="d4">2.0</data>
      <data key="d5">Community summaries are used to generate the global answer</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="LLM">
      <data key="d4">2.0</data>
      <data key="d5">LLM generates community summaries</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="SOURCE TEXTS">
      <data key="d4">2.0</data>
      <data key="d5">Community summaries are compared to source texts using Graph RAG</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="C0">
      <data key="d4">1.0</data>
      <data key="d5">C0 represents root-level community summaries in the graph community hierarchy</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="C1">
      <data key="d4">1.0</data>
      <data key="d5">C1 represents intermediate-level community summaries in the graph community hierarchy</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="C2">
      <data key="d4">1.0</data>
      <data key="d5">C2 represents intermediate-level community summaries in the graph community hierarchy</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="COMMUNITY SUMMARIES" target="C3">
      <data key="d4">1.0</data>
      <data key="d5">C3 represents low-level community summaries in the graph community hierarchy</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GLOBAL ANSWER" target="USER QUERY">
      <data key="d4">2.0</data>
      <data key="d5">The global answer is generated in response to a user query</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="GLOBAL ANSWER" target="COMMUNITY ANSWERS">
      <data key="d4">2.0</data>
      <data key="d5">Community answers are used to form the global answer</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="TRANSFORMER ARCHITECTURE" target="GOODWIN ET AL.">
      <data key="d4">2.0</data>
      <data key="d5">Goodwin et al. contributed to the study of summarization tasks using transformer architecture.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="TRANSFORMER ARCHITECTURE" target="LIU AND LAPATA">
      <data key="d4">2.0</data>
      <data key="d5">Liu and Lapata contributed to the study of summarization tasks using transformer architecture.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GPT" target="ACHIAM ET AL.">
      <data key="d4">2.0</data>
      <data key="d5">Achiam et al. contributed to the development of the GPT model.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GPT" target="BROWN ET AL.">
      <data key="d4">2.0</data>
      <data key="d5">Brown et al. contributed to the development of the GPT model.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GPT" target="LLMS">
      <data key="d4">2.0</data>
      <data key="d5">GPT is a type of LLM</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="LLAMA" target="TOUVRON ET AL.">
      <data key="d4">2.0</data>
      <data key="d5">Touvron et al. contributed to the development of the Llama model.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="LLAMA" target="LLMS">
      <data key="d4">2.0</data>
      <data key="d5">Llama is a type of LLM</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GEMINI" target="ANIL ET AL.">
      <data key="d4">2.0</data>
      <data key="d5">Anil et al. contributed to the development of the Gemini model.</data>
      <data key="d6">0c932f7def033fa2b1bf210fbb771e7d</data>
    </edge>
    <edge source="GEMINI" target="LLMS">
      <data key="d4">2.0</data>
      <data key="d5">Gemini is a type of LLM</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="LLMS" target="IN-CONTEXT LEARNING">
      <data key="d4">2.0</data>
      <data key="d5">In-context learning is a technique used by LLMs</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION" target="SUMMARIZATION TASKS">
      <data key="d4">2.0</data>
      <data key="d5">Query-focused abstractive summarization is a type of summarization task</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION" target="RAG">
      <data key="d4">2.0</data>
      <data key="d5">RAG is a technique used for query-focused abstractive summarization</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="QUERY-FOCUSED ABSTRACTIVE SUMMARIZATION" target="MAP-REDUCE">
      <data key="d4">2.0</data>
      <data key="d5">Map-Reduce is a technique used for query-focused abstractive summarization</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="RAG" target="LLM">
      <data key="d4">2.0</data>
      <data key="d5">RAG involves using LLMs to retrieve and generate relevant information</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="RAG" target="RAM ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">Ram et al. (2023) contributed to the research on RAG approaches</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="RAG" target="AGENTINSTRUCT">
      <data key="d4">1.0</data>
      <data key="d5">AgentInstruct generates data covering the skill of RAG</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="RAG" target="LANGUAGE MODELS">
      <data key="d4">1.0</data>
      <data key="d5">RAG enhances the ability of language models to generate informed and contextually precise responses</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="RAG" target="MIRAGE">
      <data key="d4">1.0</data>
      <data key="d5">MIRAGE is used to evaluate the RAG capabilities of language models</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="MODULARITY">
      <data key="d4">2.0</data>
      <data key="d5">Modularity is a property of knowledge graphs</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="COMMUNITY DETECTION ALGORITHMS">
      <data key="d4">2.0</data>
      <data key="d5">Community detection algorithms are used to partition knowledge graphs</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="KAPING">
      <data key="d4">2.0</data>
      <data key="d5">KAPING uses a knowledge graph as its index</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="G-RETRIEVER">
      <data key="d4">2.0</data>
      <data key="d5">G-Retriever uses subsets of the graph structure for retrieval</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="GRAPH-TOOLFORMER">
      <data key="d4">2.0</data>
      <data key="d5">Graph-ToolFormer uses derived graph metrics for retrieval</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="SURGE">
      <data key="d4">2.0</data>
      <data key="d5">SURGE grounds narrative outputs in the facts of retrieved subgraphs</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="FABULA">
      <data key="d4">2.0</data>
      <data key="d5">FABULA serializes retrieved event-plot subgraphs using narrative templates</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="ITRG">
      <data key="d4">2.0</data>
      <data key="d5">ITRG supports creation and traversal of text-relationship graphs</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="LANGCHAIN">
      <data key="d4">2.0</data>
      <data key="d5">LangChain supports various graph databases for knowledge graph creation and reasoning</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="LLAMAINDEX">
      <data key="d4">2.0</data>
      <data key="d5">LlamaIndex supports various graph databases for knowledge graph creation and reasoning</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="NEO4J">
      <data key="d4">2.0</data>
      <data key="d5">Neo4J is a graph database used for knowledge graph creation and reasoning</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="NEBULAGRAPH">
      <data key="d4">2.0</data>
      <data key="d5">NebulaGraph is a graph database used for knowledge graph creation and reasoning</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="TRAJANOSKA ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">Trajanoska et al. (2023) contributed to the research on knowledge graph creation</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH" target="YAO ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">Yao et al. (2023) contributed to the research on knowledge graph completion</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="COMMUNITY DETECTION ALGORITHMS" target="LOUVAIN">
      <data key="d4">2.0</data>
      <data key="d5">Louvain is a type of community detection algorithm</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="HOTPOTQA" target="DATASET">
      <data key="d4">2.0</data>
      <data key="d5">HotPotQA is a dataset used for evaluating question answering systems</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="HOTPOTQA" target="RAG SYSTEMS">
      <data key="d4">2.0</data>
      <data key="d5">HotPotQA is a benchmark dataset used to evaluate RAG systems</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="GPT-4-TURBO" target="MODEL">
      <data key="d4">2.0</data>
      <data key="d5">GPT-4-Turbo is a model used for entity extraction</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="GPT-4-TURBO" target="CONTEXT WINDOW SIZE">
      <data key="d4">2.0</data>
      <data key="d5">The context window size is a parameter tested for models like GPT-4-Turbo</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="GPT-4-TURBO" target="ALPACAEVAL">
      <data key="d4">1.0</data>
      <data key="d5">GPT-4-turbo is used in the AlpacaEval benchmark to prefer the outputs of the evaluated model over a reference answer</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="DATASET">
      <data key="d4">2.0</data>
      <data key="d5">Podcast transcripts are a type of dataset</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="PODCAST TRANSCRIPTS" target="TECH JOURNALIST">
      <data key="d4">2.0</data>
      <data key="d5">Tech journalists use podcast transcripts to gain insights and trends in the tech industry</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="NEWS ARTICLES" target="DATASET">
      <data key="d4">2.0</data>
      <data key="d5">News articles are a type of dataset</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="NEWS ARTICLES" target="EDUCATOR">
      <data key="d4">2.0</data>
      <data key="d5">Educators use news articles to incorporate current affairs into curricula</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="NEWS ARTICLES" target="MULTIHOP-RAG">
      <data key="d4">2.0</data>
      <data key="d5">MultiHop-RAG is used in the context of news articles</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="METRIC">
      <data key="d4">2.0</data>
      <data key="d5">Comprehensiveness is a quality metric for summarization</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="COMPREHENSIVENESS" target="DIVERSITY">
      <data key="d4">2.0</data>
      <data key="d5">Both metrics are used to evaluate the quality of answers</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="DIVERSITY" target="METRIC">
      <data key="d4">2.0</data>
      <data key="d5">Diversity is a quality metric for summarization</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="EMPOWERMENT" target="METRIC">
      <data key="d4">2.0</data>
      <data key="d5">Empowerment is a quality metric for summarization</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="SOURCE TEXT SUMMARIZATION" target="SUMMARIZATION TASKS">
      <data key="d4">2.0</data>
      <data key="d5">Source text summarization is a type of summarization task</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="TOKEN COSTS" target="METRIC">
      <data key="d4">2.0</data>
      <data key="d5">Token costs are a metric related to the computational cost of processing text</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="TEXT CHUNKS" target="DATA UNIT">
      <data key="d4">2.0</data>
      <data key="d5">Text chunks are segments of text extracted from source documents</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="TEXT CHUNKS" target="SEMANTIC SEARCH (SS)">
      <data key="d4">2.0</data>
      <data key="d5">Semantic search retrieves text chunks and adds them to the context window</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="ENTITY EXTRACTION" target="TASK">
      <data key="d4">2.0</data>
      <data key="d5">Entity extraction is a task involving the identification and extraction of entities from text</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="ELEMENT INSTANCES" target="DATA UNIT">
      <data key="d4">2.0</data>
      <data key="d5">Element instances are instances of graph nodes and edges extracted from text chunks</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="ELEMENT INSTANCES" target="ELEMENT SUMMARIES">
      <data key="d4">2.0</data>
      <data key="d5">Element instances are summarized into element summaries.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="FEW-SHOT EXAMPLES" target="TECHNIQUE">
      <data key="d4">2.0</data>
      <data key="d5">Few-shot examples are a technique used to help models learn tasks with minimal training data</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="NAMED ENTITIES" target="CATEGORY">
      <data key="d4">2.0</data>
      <data key="d5">Named entities are a category of entities identified in text</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="COVARIATES" target="ATTRIBUTE">
      <data key="d4">2.0</data>
      <data key="d5">Covariates are additional variables associated with extracted node instances</data>
      <data key="d6">64476a39d7d8b87b399e3bd3cead79c7</data>
    </edge>
    <edge source="COVARIATES" target="LLM">
      <data key="d4">2.0</data>
      <data key="d5">LLMs are used to extract covariates associated with detected entities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="COVARIATES" target="CLAIMS">
      <data key="d4">1.0</data>
      <data key="d5">Claims are a type of covariate linked to detected entities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="MODEL" target="SYSTEM MESSAGE">
      <data key="d4">1.0</data>
      <data key="d5">The model follows the instructions provided in the system message</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="METRIC" target="EVALUATION">
      <data key="d4">2.0</data>
      <data key="d5">Metrics are used to evaluate the quality of generated answers</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="METRIC" target="LLM EVALUATOR">
      <data key="d4">2.0</data>
      <data key="d5">The LLM evaluator uses metrics to assess the quality of answers</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="TASK" target="USER">
      <data key="d4">2.0</data>
      <data key="d5">Users perform specific tasks with the dataset</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="TASK" target="QUESTION">
      <data key="d4">2.0</data>
      <data key="d5">Tasks performed by users result in the generation of questions</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="LOGIT BIAS" target="LLM">
      <data key="d4">2.0</data>
      <data key="d5">Logit bias is used to influence the output of LLMs.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="ELEMENT SUMMARIES" target="ENTITY GRAPH">
      <data key="d4">2.0</data>
      <data key="d5">Element summaries are used to create an entity graph.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LEIDEN ALGORITHM" target="MULTIHOP-RAG">
      <data key="d4">1.0</data>
      <data key="d5">The Leiden algorithm is used to detect graph communities in the MultiHop-RAG dataset.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LEIDEN ALGORITHM" target="HIERARCHICAL COMMUNITY STRUCTURE">
      <data key="d4">1.0</data>
      <data key="d5">The Leiden algorithm is used to recover hierarchical community structures in large-scale graphs.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="GRAPH COMMUNITIES" target="OPENORD">
      <data key="d4">2.0</data>
      <data key="d5">OpenORD is used for node layout in visualizing graph communities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="GRAPH COMMUNITIES" target="FORCE ATLAS 2">
      <data key="d4">2.0</data>
      <data key="d5">Force Atlas 2 is used for node layout in visualizing graph communities.</data>
      <data key="d6">e66ed885a08f92cc69f4895302c33047</data>
    </edge>
    <edge source="LLM" target="LEAF-LEVEL COMMUNITIES">
      <data key="d4">2.0</data>
      <data key="d5">Leaf-level communities are summarized and added to the LLM context window</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="LLM" target="HIGHER-LEVEL COMMUNITIES">
      <data key="d4">2.0</data>
      <data key="d5">Higher-level communities are summarized and added to the LLM context window</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="LLM" target="QUESTION">
      <data key="d4">2.0</data>
      <data key="d5">The LLM generates questions based on the dataset and user-task combinations</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="LLM" target="NA&#207;VE RAG">
      <data key="d4">2.0</data>
      <data key="d5">Na&#239;ve RAG uses LLMs for basic retrieval-augmented generation</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="LLM" target="AGENT">
      <data key="d4">2.0</data>
      <data key="d5">An agent is powered by an LLM</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="LLM" target="CONTENT TRANSFORMATION FLOW">
      <data key="d4">2.0</data>
      <data key="d5">LLMs are used in the Content Transformation Flow to hypothesize other APIs</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="MULTIHOP-RAG" target="TANG AND YANG">
      <data key="d4">2.0</data>
      <data key="d5">Tang and Yang discussed the MultiHop-RAG system</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="GLOBAL SUMMARIZATION" target="MAP-REDUCE SUMMARIZATION">
      <data key="d4">2.0</data>
      <data key="d5">Map-reduce summarization is a global but graph-free approach to summarizing source texts</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="TECH JOURNALIST" target="TECH POLICY">
      <data key="d4">2.0</data>
      <data key="d5">Tech journalists are interested in episodes dealing with tech policy</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="TECH JOURNALIST" target="GOVERNMENT REGULATION">
      <data key="d4">2.0</data>
      <data key="d5">Tech journalists are interested in episodes dealing with government regulation</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="TECH JOURNALIST" target="PRIVACY LAWS">
      <data key="d4">2.0</data>
      <data key="d5">Tech journalists are interested in the impact of privacy laws on technology development</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="TECH JOURNALIST" target="INNOVATION">
      <data key="d4">2.0</data>
      <data key="d5">Tech journalists are interested in the balance between innovation and ethical considerations</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="TECH JOURNALIST" target="ETHICAL CONSIDERATIONS">
      <data key="d4">2.0</data>
      <data key="d5">Tech journalists are interested in the balance between innovation and ethical considerations</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="TECH JOURNALIST" target="COLLABORATIONS">
      <data key="d4">2.0</data>
      <data key="d5">Tech journalists are interested in collaborations between tech companies and governments</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="EDUCATOR" target="HEALTH EDUCATION">
      <data key="d4">2.0</data>
      <data key="d5">Educators are interested in integrating current topics in health into health education curricula</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="EDUCATOR" target="PREVENTIVE MEDICINE">
      <data key="d4">2.0</data>
      <data key="d5">Educators are interested in how news articles address preventive medicine</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="EDUCATOR" target="WELLNESS">
      <data key="d4">2.0</data>
      <data key="d5">Educators are interested in how news articles address wellness</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="EDUCATOR" target="PUBLIC HEALTH">
      <data key="d4">2.0</data>
      <data key="d5">Educators are interested in public health priorities based on news coverage</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="EDUCATOR" target="HEALTH LITERACY">
      <data key="d4">2.0</data>
      <data key="d5">Educators are interested in highlighting the importance of health literacy</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="MT-BENCH" target="RAG SYSTEMS">
      <data key="d4">2.0</data>
      <data key="d5">MT-Bench is a benchmark dataset used to evaluate RAG systems</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="MT-BENCH" target="ZHENG ET AL.">
      <data key="d4">2.0</data>
      <data key="d5">Zheng et al. discussed the MT-Bench dataset</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="MT-BENCH" target="ORCA-3">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3 scored 8.20 on the MT-Bench benchmark</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="MT-BENCH" target="GPT-4">
      <data key="d4">3.0</data>
      <data key="d5">MT-Bench uses GPT-4 as the evaluator for assessing chat assistants.
GPT-4 is used as a judge in the MT-Bench benchmark to score each turn's response</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba,86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MT-BENCH" target="OPEN-ENDED GENERATION">
      <data key="d4">1.0</data>
      <data key="d5">MT-Bench is a benchmark used to evaluate open-ended generation tasks</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="RAG SYSTEMS" target="DATA SENSEMAKING">
      <data key="d4">2.0</data>
      <data key="d5">RAG systems are used for data sensemaking tasks</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="DATA SENSEMAKING" target="LATENT SUMMARIZATION QUERIES">
      <data key="d4">2.0</data>
      <data key="d5">Latent summarization queries are used for data sensemaking</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="DATA SENSEMAKING" target="KOESTEN ET AL.">
      <data key="d4">2.0</data>
      <data key="d5">Koesten et al. discussed data sensemaking</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="DATA SENSEMAKING" target="SENSEMAKING BEHAVIORS">
      <data key="d4">1.0</data>
      <data key="d5">Data sensemaking involves understanding and interpreting data through sensemaking behaviors</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="LATENT SUMMARIZATION QUERIES" target="XU AND LAPATA">
      <data key="d4">2.0</data>
      <data key="d5">Xu and Lapata discussed latent summarization queries</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="KEVIN SCOTT" target="BEHIND THE TECH">
      <data key="d4">2.0</data>
      <data key="d5">Kevin Scott is a participant in the Behind the Tech podcast</data>
      <data key="d6">4930fce6da868f894757a9da465807ba</data>
    </edge>
    <edge source="ZHENG ET AL." target="LLM EVALUATOR">
      <data key="d4">1.0</data>
      <data key="d5">Zheng et al. contributed to the research on head-to-head comparison of competing outputs using LLMs</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="USER" target="ASSISTANT">
      <data key="d4">2.0</data>
      <data key="d5">The user interacts with the assistant to achieve specific goals</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="QUESTION" target="OPTIONS">
      <data key="d4">2.0</data>
      <data key="d5">The question is accompanied by a list of options</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="TEXT SUMMARIZATION (TS)" target="SOURCE TEXTS">
      <data key="d4">2.0</data>
      <data key="d5">Text summarization applies a map-reduce approach directly to source texts</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="CONTEXT WINDOW" target="ANSWER GENERATION">
      <data key="d4">2.0</data>
      <data key="d5">The size of the context window affects answer generation</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="PODCAST DATASET" target="EVALUATION">
      <data key="d4">2.0</data>
      <data key="d5">The podcast dataset is used for evaluation</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="PODCAST DATASET" target="NEWS DATASET">
      <data key="d4">2.0</data>
      <data key="d5">Both datasets are used for testing the models</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="NEWS DATASET" target="EVALUATION">
      <data key="d4">2.0</data>
      <data key="d5">The news dataset is used for evaluation</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="LLM EVALUATOR" target="WANG ET AL.">
      <data key="d4">1.0</data>
      <data key="d5">Wang et al. contributed to the research on evaluating natural language generation using LLMs</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="PUBLIC FIGURES" target="ENTERTAINMENT ARTICLES">
      <data key="d4">2.0</data>
      <data key="d5">Public figures are repeatedly mentioned in entertainment articles</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="SOURCE TEXTS" target="MAP-REDUCE SUMMARIZATION">
      <data key="d4">1.0</data>
      <data key="d5">Map-reduce summarization is a resource-intensive approach requiring a high number of context tokens from source texts</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="RAGAS" target="RETRIEVAL-AUGMENTED GENERATION">
      <data key="d4">2.0</data>
      <data key="d5">RAGAS evaluates the performance of retrieval-augmented generation systems
RAGAS is an automated evaluation system for retrieval-augmented generation</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582,aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="RAGAS" target="ES ET AL.">
      <data key="d4">1.0</data>
      <data key="d5">Es et al. contributed to the research on automatically evaluating qualities in RAG systems</data>
      <data key="d6">26b2dad01a219bc034ac7d6a32d07582</data>
    </edge>
    <edge source="RETRIEVAL-AUGMENTED GENERATION" target="G-RETRIEVER">
      <data key="d4">1.0</data>
      <data key="d5">G-Retriever is a system for retrieval-augmented generation</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="NA&#207;VE RAG" target="GLOBAL TEXT SUMMARIZATION">
      <data key="d4">1.0</data>
      <data key="d5">Global text summarization without a graph index is compared to na&#239;ve RAG</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="NA&#207;VE RAG" target="MODULAR RAG">
      <data key="d4">2.0</data>
      <data key="d5">Modular RAG systems are designed to overcome the drawbacks of Na&#239;ve RAG</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="NA&#207;VE RAG" target="GAO ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">Gao et al. (2023) contributed to the research on Na&#239;ve RAG</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="CONTEXT WINDOW SIZE" target="BASELINE CONDITION (SS)">
      <data key="d4">1.0</data>
      <data key="d5">The baseline condition (SS) was used to determine the optimum context window size</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="KURATOV ET AL., 2024" target="LIU ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">Both references discuss the potential for information to be "lost in the middle" of longer contexts</data>
      <data key="d6">ede7063998065122cf7a7152979c1909</data>
    </edge>
    <edge source="MODULAR RAG" target="GAO ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">Gao et al. (2023) contributed to the research on advanced RAG systems</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="SELF-MEMORY" target="GENERATION-AUGMENTED RETRIEVAL">
      <data key="d4">2.0</data>
      <data key="d5">Self-memory is a concept related to generation-augmented retrieval</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="SELF-MEMORY" target="CHENG ET AL., 2024">
      <data key="d4">2.0</data>
      <data key="d5">Cheng et al. (2024) contributed to the research on self-memory</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="SELF-MEMORY" target="RETRIEVAL-AUGMENTED TEXT GENERATION">
      <data key="d4">1.0</data>
      <data key="d5">The retrieval-augmented text generation method incorporates self-memory, as described by Cheng et al. in 2024</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="GENERATION-AUGMENTED RETRIEVAL" target="MAO ET AL., 2020">
      <data key="d4">2.0</data>
      <data key="d5">Mao et al. (2020) contributed to the research on generation-augmented retrieval</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="ITERATIVE RETRIEVAL-GENERATION" target="SHAO ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">Shao et al. (2023) contributed to the research on iterative retrieval-generation</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="FEDERATED RETRIEVAL-GENERATION" target="WANG ET AL., 2024">
      <data key="d4">2.0</data>
      <data key="d5">Wang et al. (2024) contributed to the research on federated retrieval-generation</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="MULTI-DOCUMENT SUMMARIZATION" target="SU ET AL., 2020">
      <data key="d4">2.0</data>
      <data key="d5">Su et al. (2020) contributed to the research on multi-document summarization</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="MULTI-HOP QUESTION ANSWERING" target="FENG ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">Feng et al. (2023) contributed to the research on multi-hop question answering</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="MULTI-HOP QUESTION ANSWERING" target="TRIVEDI ET AL., 2022">
      <data key="d4">2.0</data>
      <data key="d5">Trivedi et al. (2022) contributed to the research on multi-hop question answering</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="MULTI-HOP QUESTION ANSWERING" target="KHATTAB ET AL., 2022">
      <data key="d4">2.0</data>
      <data key="d5">Khattab et al. (2022) contributed to the research on multi-hop question answering</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="HIERARCHICAL INDEX" target="SARTHI ET AL., 2024">
      <data key="d4">2.0</data>
      <data key="d5">Sarthi et al. (2024) contributed to the research on hierarchical indexing</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="TREE OF CLARIFICATIONS" target="KIM ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">Kim et al. (2023) contributed to the research on generating a tree of clarifications</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="TREE OF CLARIFICATIONS" target="RETRIEVAL-AUGMENTED LARGE LANGUAGE MODELS">
      <data key="d4">1.0</data>
      <data key="d5">Tree of Clarifications uses retrieval-augmented large language models to answer ambiguous questions</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="CAUSAL GRAPHS" target="BAN ET AL., 2023">
      <data key="d4">2.0</data>
      <data key="d5">Ban et al. (2023) contributed to the research on the extraction of causal graphs</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="CAUSAL GRAPHS" target="ZHANG ET AL., 2024">
      <data key="d4">1.0</data>
      <data key="d5">Zhang et al. (2024) contributed to the research on the extraction of causal graphs</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="KAPING" target="BAEK ET AL., 2023">
      <data key="d4">1.0</data>
      <data key="d5">Baek et al. (2023) contributed to the research on KAPING</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="G-RETRIEVER" target="HE ET AL., 2024">
      <data key="d4">1.0</data>
      <data key="d5">He et al. (2024) contributed to the research on G-Retriever</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="GRAPH-TOOLFORMER" target="ZHANG, 2023">
      <data key="d4">1.0</data>
      <data key="d5">Zhang (2023) contributed to the research on Graph-ToolFormer</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="SURGE" target="KANG ET AL., 2023">
      <data key="d4">1.0</data>
      <data key="d5">Kang et al. (2023) contributed to the research on SURGE</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="FABULA" target="RANADE AND JOSHI, 2023">
      <data key="d4">1.0</data>
      <data key="d5">Ranade and Joshi (2023) contributed to the research on FABULA</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="ITRG" target="WANG ET AL., 2023B">
      <data key="d4">1.0</data>
      <data key="d5">Wang et al. (2023) contributed to the research on ITRG</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="LANGCHAIN" target="LANGCHAIN, 2024">
      <data key="d4">1.0</data>
      <data key="d5">LangChain (2024) is a reference to the LangChain library</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="LLAMAINDEX" target="LLAMAINDEX, 2024">
      <data key="d4">1.0</data>
      <data key="d5">LlamaIndex (2024) is a reference to the LlamaIndex library</data>
      <data key="d6">edab4014b8f55e5b25bd7f396314be1f</data>
    </edge>
    <edge source="NEO4J" target="GRAPH-BASED RAG APPLICATIONS">
      <data key="d4">2.0</data>
      <data key="d5">Neo4J is a format used by graph-based RAG applications for creating and reasoning over knowledge graphs</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="NEBULAGRAPH" target="GRAPH-BASED RAG APPLICATIONS">
      <data key="d4">2.0</data>
      <data key="d5">NebulaGraph is a format used by graph-based RAG applications for creating and reasoning over knowledge graphs</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="SELFCHECKGPT" target="FABRICATION RATES">
      <data key="d4">2.0</data>
      <data key="d5">SelfCheckGPT is used to compare fabrication rates in generated content</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GPT-4 TECHNICAL REPORT" target="J. ACHIAM">
      <data key="d4">2.0</data>
      <data key="d5">J. Achiam is an author of the GPT-4 technical report</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GPT-4 TECHNICAL REPORT" target="S. ADLER">
      <data key="d4">2.0</data>
      <data key="d5">S. Adler is an author of the GPT-4 technical report</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GPT-4 TECHNICAL REPORT" target="S. AGARWAL">
      <data key="d4">2.0</data>
      <data key="d5">S. Agarwal is an author of the GPT-4 technical report</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GPT-4 TECHNICAL REPORT" target="L. AHMAD">
      <data key="d4">2.0</data>
      <data key="d5">L. Ahmad is an author of the GPT-4 technical report</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GPT-4 TECHNICAL REPORT" target="I. AKKAYA">
      <data key="d4">2.0</data>
      <data key="d5">I. Akkaya is an author of the GPT-4 technical report</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GPT-4 TECHNICAL REPORT" target="F. L. ALEMAN">
      <data key="d4">2.0</data>
      <data key="d5">F. L. Aleman is an author of the GPT-4 technical report</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="GPT-4 TECHNICAL REPORT" target="D. ALMEIDA">
      <data key="d4">2.0</data>
      <data key="d5">D. Almeida is an author of the GPT-4 technical report</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="KNOWLEDGE-AUGMENTED LANGUAGE MODEL PROMPTING" target="LARGE LANGUAGE MODELS">
      <data key="d4">2.0</data>
      <data key="d5">Large language models are used in knowledge-augmented language model prompting for zero-shot knowledge graph question answering</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="CAUSAL DISCOVERY">
      <data key="d4">2.0</data>
      <data key="d5">Large language models are harnessed for advanced causal discovery from data</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="RETRIEVAL-GENERATION SYNERGY">
      <data key="d4">1.0</data>
      <data key="d5">Retrieval-generation synergy is used to enhance large language models</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="DATA BIASES">
      <data key="d4">2.0</data>
      <data key="d5">Large language models can carry biases present in the source data</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="LACK OF TRANSPARENCY">
      <data key="d4">2.0</data>
      <data key="d5">Large language models can act as "black boxes" due to their complexity and size</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="LARGE LANGUAGE MODELS" target="CONTENT HARMS">
      <data key="d4">2.0</data>
      <data key="d5">Large language models can generate various types of harmful content</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="J. ALTENSCHMIDT" target="GPT-4 TECHNICAL REPORT&lt;**ANALYSIS:**(&quot;ENTITY&quot;">
      <data key="d4">1.0</data>
      <data key="d5">GRAPH-BASED RAG APPLICATIONS</data>
      <data key="d6">ac21ebe9a9d70d691c717f961d3f10c8</data>
    </edge>
    <edge source="LANGUAGE MODELS" target="FEW-SHOT LEARNING">
      <data key="d4">1.0</data>
      <data key="d5">Language models are capable of few-shot learning, as discussed by Brown et al. in 2020</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="LANGUAGE MODELS" target="COT">
      <data key="d4">1.0</data>
      <data key="d5">Chain-of-Thought reasoning is used by language models to break down complex problems</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="FORCEATLAS2" target="GRAPH VISUALIZATION">
      <data key="d4">1.0</data>
      <data key="d5">ForceAtlas2 is an algorithm designed for graph visualization</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="KNOWLEDGE GRAPH-AUGMENTED LANGUAGE MODELS" target="KNOWLEDGE-GROUNDED DIALOGUE GENERATION">
      <data key="d4">1.0</data>
      <data key="d5">Knowledge graph-augmented language models are used for knowledge-grounded dialogue generation</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="DEMONSTRATE-SEARCH-PREDICT" target="KNOWLEDGE-INTENSIVE NLP">
      <data key="d4">1.0</data>
      <data key="d5">Demonstrate-search-predict is a method for knowledge-intensive NLP tasks</data>
      <data key="d6">aa79049289e6532592eec17b9e76adfb</data>
    </edge>
    <edge source="GPT-4" target="SYNTHETIC DATA">
      <data key="d4">1.0</data>
      <data key="d5">GPT-4 is often used to generate responses to prompts in the process of creating synthetic data.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="GPT-4" target="AGENTINSTRUCT">
      <data key="d4">2.0</data>
      <data key="d5">AgentInstruct uses GPT-4 to generate high-quality data</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="GPT-4" target="ORCA-BENCH">
      <data key="d4">4.0</data>
      <data key="d5">GPT-4 is used as a baseline for scoring the performance on the Orca-Bench dataset
GPT-4 is used as a benchmark model in the Orca-Bench dataset</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="GPT-4" target="READING COMPREHENSION">
      <data key="d4">2.0</data>
      <data key="d5">GPT-4 is used as a benchmark for reading comprehension evaluations.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="GPT-4" target="ORCA-3">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3's performance is compared to GPT-4 in various benchmarks</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="GPT-4" target="ORCA-3-7B">
      <data key="d4">1.0</data>
      <data key="d5">Orca-3-7B's performance was evaluated by GPT-4</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-4" target="COT (CHAIN-OF-THOUGHT)">
      <data key="d4">1.0</data>
      <data key="d5">GPT-4's performance is measured using CoT</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPT-4" target="RAG (RETRIEVAL-AUGMENTED GENERATION)">
      <data key="d4">1.0</data>
      <data key="d5">GPT-4's performance is measured using RAG</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPT-4" target="TECHNOLOGY">
      <data key="d4">2.0</data>
      <data key="d5">GPT-4 is a technology used for extracting the option selected by the model from the model&#8217;s response in multiple choice questions</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="GPT-4" target="MATHS GPT-4 EXTRACTION SYSTEM MESSAGE">
      <data key="d4">2.0</data>
      <data key="d5">GPT-4 uses the Maths GPT-4 extraction system message to evaluate math-based questions</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="GPT-4" target="GENERAL EXTRACTION SYSTEM MESSAGE">
      <data key="d4">2.0</data>
      <data key="d5">GPT-4 uses the General extraction system message to evaluate exact match/span extraction problems</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="GPT-4" target="FOFO">
      <data key="d4">1.0</data>
      <data key="d5">GPT-4 is used as a judge in the FOFO benchmark to evaluate format correctness</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="GPT-4" target="IFEVAL">
      <data key="d4">1.0</data>
      <data key="d5">GPT-4 is used as a judge in the IFEval benchmark to check if the model response follows verifiable instructions</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="GPT-4" target="INFOBENCH">
      <data key="d4">1.0</data>
      <data key="d5">GPT-4 is used as a judge in the InfoBench benchmark to determine if the model response follows decomposed instructions</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="CHATGPT" target="ORCA-3">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3 shows a performance improvement over ChatGPT</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="GENERATIVE TEACHING" target="AGENTINSTRUCT">
      <data key="d4">4.0</data>
      <data key="d5">AgentInstruct is an agentic solution for Generative Teaching
AgentInstruct is effective for Generative Teaching, evidenced by enhancements across various mathematical datasets</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="SYNTHETIC DATA" target="AGENTINSTRUCT">
      <data key="d4">4.0</data>
      <data key="d5">AgentInstruct generates synthetic data for post-training language models.
AgentInstruct is used to generate synthetic data</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="SYNTHETIC DATA" target="INSTRUCTION-TUNING">
      <data key="d4">2.0</data>
      <data key="d5">Synthetic data is used in instruction-tuning to improve the performance of language models.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="SYNTHETIC DATA" target="RLHF">
      <data key="d4">2.0</data>
      <data key="d5">Synthetic data is used in Reinforcement Learning from Human Feedback (RLHF) to improve the performance of language models.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="SYNTHETIC DATA" target="MODEL COLLAPSE">
      <data key="d4">2.0</data>
      <data key="d5">Model collapse can occur when models are pre-trained on synthetic data generated by other models.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="SYNTHETIC DATA" target="POST-TRAINING">
      <data key="d4">2.0</data>
      <data key="d5">Synthetic data is used in post-training to teach new skills or behaviors to an already trained model.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="SYNTHETIC DATA" target="DATA BIASES">
      <data key="d4">2.0</data>
      <data key="d5">Synthetic data can reflect and amplify biases present in the original seed data</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="SYNTHETIC DATA" target="VALIDATION">
      <data key="d4">2.0</data>
      <data key="d5">It can be difficult to validate synthetic data to ensure it accurately represents the desired scenarios</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="SYNTHETIC DATA" target="DEPENDENCY ON SEED DATA">
      <data key="d4">2.0</data>
      <data key="d5">The quality of synthetic data is dependent on the quality of the real data used as seeds</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MISTRAL-7B" target="AGENTINSTRUCT">
      <data key="d4">2.0</data>
      <data key="d5">AgentInstruct was used to generate synthetic data for post-training Mistral-7b.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MISTRAL-7B" target="ORCA-3">
      <data key="d4">4.0</data>
      <data key="d5">Orca-3 is the result of post-training Mistral-7b with synthetic data generated by AgentInstruct.
Orca-3 is the fine-tuned version of the Mistral-7B model</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="ORCA-3" target="AGIEVAL">
      <data key="d4">6.0</data>
      <data key="d5">Orca-3 showed a 40% improvement over Mistral-7b-Instruct on the AGIEval benchmark.
Orca-3 shows significant improvement on the AGIEval benchmark
Orca-3 scored 56.80 on the AGIEval benchmark</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="MMLU">
      <data key="d4">6.0</data>
      <data key="d5">Orca-3 showed a 19% improvement over Mistral-7b-Instruct on the MMLU benchmark.
Orca-3 shows significant improvement on the MMLU benchmark
Orca-3 scored 69.95 on the MMLU benchmark</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="GSM8K">
      <data key="d4">6.0</data>
      <data key="d5">Orca-3 showed a 54% improvement over Mistral-7b-Instruct on the GSM8K benchmark.
Orca-3 shows significant improvement on the GSM8K benchmark
Orca-3 scored 83.09 on the GSM8K benchmark</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="BBH">
      <data key="d4">6.0</data>
      <data key="d5">Orca-3 showed a 38% improvement over Mistral-7b-Instruct on the BBH benchmark.
Orca-3 shows significant improvement on the BBH benchmark
Orca-3 scored 61.83 on the BBH benchmark</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="ALPACAEVAL">
      <data key="d4">6.0</data>
      <data key="d5">Orca-3 showed a 45% improvement over Mistral-7b-Instruct on the AlpacaEval benchmark.
Orca-3 shows significant improvement on the AlpacaEval benchmark
Orca-3 scored 24.80 on the AlpacaEval benchmark</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="LLAMA-8B-INSTRUCT">
      <data key="d4">4.0</data>
      <data key="d5">Orca-3 consistently outperforms LLAMA-8B-Instruct.
Orca-3 outperforms LLAMA-8B-instruct on multiple benchmarks</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="ORCA-3" target="GPT-3.5-TURBO">
      <data key="d4">4.0</data>
      <data key="d5">Orca-3 consistently outperforms GPT-3.5-turbo.
Orca-3 is evaluated against GPT-3.5-turbo</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="GPT-3.5">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3 outperforms GPT-3.5 on multiple benchmarks</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="ORCA-3" target="AGENTINSTRUCT">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3 is trained using data generated through the AgentInstruct method</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="KNOWLEDGEPILE">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3's training data includes unstructured text and code files from KnowledgePile</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="AUTOMATHTEXT">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3's training data includes unstructured text and code files from AutoMathText</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="OPENSTAX">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3's training data includes a subset of openstax content</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="APACHE-2.0 LICENSED SOURCE CODE">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3's training data includes a subset of Apache-2.0 licensed source code files</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="ORCA-2.5-DATASET">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3's training data includes approximately 3.8 million paired instructions from the Orca-2.5-dataset</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="MISTRAL-7B-V0.1">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3 is a finetuned version of the Mistral-7b-v0.1 model</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="NVIDIA A100">
      <data key="d4">2.0</data>
      <data key="d5">The training of Orca-3 used 152 NVIDIA A100 GPUs</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="ADAMW OPTIMIZER">
      <data key="d4">2.0</data>
      <data key="d5">The training of Orca-3 used the AdamW optimizer</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="ORCA-BENCH">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3's performance is evaluated using the Orca-Bench dataset</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="INSTRUCTION DATA">
      <data key="d4">1.0</data>
      <data key="d5">Orca-3 is trained using instruction data generated from unstructured content</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="INSTRUCTION TUNING">
      <data key="d4">1.0</data>
      <data key="d5">Orca-3 is finetuned using instruction tuning</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="TOKENIZATION">
      <data key="d4">1.0</data>
      <data key="d5">The training data for Orca-3 undergoes tokenization</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="LABEL MASKING">
      <data key="d4">1.0</data>
      <data key="d5">Label masking is applied during the training of Orca-3</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="WEIGHT DECAY">
      <data key="d4">1.0</data>
      <data key="d5">Weight decay is used during the training of Orca-3</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="COSINE LEARNING RATE SCHEDULE">
      <data key="d4">1.0</data>
      <data key="d5">A cosine learning rate schedule is used during the training of Orca-3</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="LINEAR LEARNING RATE WARM-UP">
      <data key="d4">1.0</data>
      <data key="d5">A linear learning rate warm-up is used during the initial steps of training Orca-3</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="EPOCH">
      <data key="d4">1.0</data>
      <data key="d5">Orca-3 is trained for three epochs</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="TRAINING LOSS">
      <data key="d4">1.0</data>
      <data key="d5">Training loss is calculated during the training of Orca-3</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-3" target="ORCA-2.5">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3 shows a performance improvement over Orca-2.5</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="MISTRAL-INSTRUCT-7B">
      <data key="d4">4.0</data>
      <data key="d5">Orca-3 shows a performance improvement over Mistral-Instruct-7B
Orca-3 shows significant improvements over Mistral-Instruct-7B in various benchmarks</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="LLAMA3-8B-INSTRUCT">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3 is evaluated against LLAMA3-8B-Instruct</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="ARC">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3 scored 92.47 on the ARC benchmark</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="GPQA">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3 scored 28.12 on the GPQA benchmark</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="DROP">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3 scored 71.14 on the DROP benchmark</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="FOFO">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3 scored 84.01 on the FOFO benchmark</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="IFEVAL">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3 scored 49.54 on the IFEval benchmark</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="INFOBENCH">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3 scored 84.30 on the InfoBench benchmark</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="EQBENCH">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3 scored 91.36 on the EQBench benchmark</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-3" target="MISTRAL-7B-INSTRUCT">
      <data key="d4">2.0</data>
      <data key="d5">Orca-3 shows performance improvements over Mistral-7b-Instruct in various benchmarks.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="ORCA-3" target="ORCA 2.5">
      <data key="d4">3.0</data>
      <data key="d5">Orca-3 shows an 18% improvement over Orca 2.5 in reading comprehension.
Orca-3 shows significant improvements over Orca 2.5 in various benchmarks</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b,bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="AGIEVAL" target="SAT">
      <data key="d4">2.0</data>
      <data key="d5">AGIEval evaluates models' performance in answering questions from standardized exams like SAT.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="AGIEVAL" target="LSAT">
      <data key="d4">2.0</data>
      <data key="d5">AGIEval evaluates models' performance in answering questions from standardized exams like LSAT.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="AGIEVAL" target="MATH COMPETITIONS">
      <data key="d4">2.0</data>
      <data key="d5">AGIEval evaluates models' performance in answering questions from math competitions.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="MMLU" target="ACADEMIC SUBJECTS">
      <data key="d4">2.0</data>
      <data key="d5">MMLU includes approximately 16000 multiple-choice questions covering 57 academic subjects.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="GSM8K" target="GPT-3.5-TURBO">
      <data key="d4">2.0</data>
      <data key="d5">GPT-3.5-turbo scores for GSM8K are referenced in the text.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="GSM8K" target="GRADE SCHOOL MATH">
      <data key="d4">2.0</data>
      <data key="d5">GSM8K is a dataset of grade school math word problems.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="GSM8K" target="EXACT MATCH/SPAN EXTRACTION">
      <data key="d4">2.0</data>
      <data key="d5">Exact match/span extraction is used to evaluate answers in the GSM8K dataset</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="BBH" target="BIG-BENCH">
      <data key="d4">2.0</data>
      <data key="d5">BBH consists of tasks selected from the broader Big-Bench benchmark.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="ALPACAEVAL" target="INSTRUCTION-FOLLOWING TASKS">
      <data key="d4">2.0</data>
      <data key="d5">AlpacaEval assesses chat-based language models in instruction-following tasks.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="ALPACAEVAL" target="OPEN-ENDED GENERATION">
      <data key="d4">1.0</data>
      <data key="d5">AlpacaEval is a benchmark used to evaluate open-ended generation tasks</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="ALPACAEVAL" target="VERSION 0613">
      <data key="d4">1.0</data>
      <data key="d5">Version 0613 of GPT-4 is used in the AlpacaEval benchmark for evaluation</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="GPT-3.5-TURBO" target="ORCA-3-7B">
      <data key="d4">1.0</data>
      <data key="d5">Orca-3-7B's performance was compared to GPT-3.5-turbo</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="GPT-3.5-TURBO" target="MIRAGE DATASETS">
      <data key="d4">1.0</data>
      <data key="d5">GPT-3.5-Turbo is evaluated on the MIRAGE datasets</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPT-3.5-TURBO" target="COT (CHAIN-OF-THOUGHT)">
      <data key="d4">1.0</data>
      <data key="d5">GPT-3.5-Turbo's performance is measured using CoT</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="GPT-3.5-TURBO" target="RAG (RETRIEVAL-AUGMENTED GENERATION)">
      <data key="d4">1.0</data>
      <data key="d5">GPT-3.5-Turbo's performance is measured using RAG</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MULTIAGENT WORKFLOWS" target="AGENTINSTRUCT">
      <data key="d4">2.0</data>
      <data key="d5">AgentInstruct utilizes multiagent workflows to generate high-quality synthetic data.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MULTIAGENT WORKFLOWS" target="TOOLS">
      <data key="d4">2.0</data>
      <data key="d5">Tools are used in multiagent workflows to address limitations of LLMs and improve data generation.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MULTIAGENT WORKFLOWS" target="SEARCH APIS">
      <data key="d4">1.0</data>
      <data key="d5">Search APIs are used in multiagent workflows to enhance the data generation process.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MULTIAGENT WORKFLOWS" target="CALCULATORS">
      <data key="d4">1.0</data>
      <data key="d5">Calculators are used in multiagent workflows to enhance the data generation process.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="MULTIAGENT WORKFLOWS" target="CODE INTERPRETERS">
      <data key="d4">1.0</data>
      <data key="d5">Code interpreters are used in multiagent workflows to enhance the data generation process.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="PROMPTS" target="RESPONSES">
      <data key="d4">2.0</data>
      <data key="d5">Prompts are used to generate responses in the process of creating synthetic data.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="PROMPTS" target="AGENTINSTRUCT">
      <data key="d4">2.0</data>
      <data key="d5">AgentInstruct generates both prompts and responses</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="RESPONSES" target="AGENTINSTRUCT">
      <data key="d4">2.0</data>
      <data key="d5">AgentInstruct generates both prompts and responses</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="TEXT EDITING">
      <data key="d4">1.0</data>
      <data key="d5">AgentInstruct generates synthetic data to teach language models the skill of text editing.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="CREATIVE WRITING">
      <data key="d4">2.0</data>
      <data key="d5">AgentInstruct generates synthetic data to teach language models the skill of creative writing.
AgentInstruct generates data covering the skill of creative writing</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="TOOL USAGE">
      <data key="d4">1.0</data>
      <data key="d5">AgentInstruct generates synthetic data to teach language models the skill of tool usage.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="CODING">
      <data key="d4">1.0</data>
      <data key="d5">AgentInstruct generates synthetic data to teach language models the skill of coding.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="READING COMPREHENSION">
      <data key="d4">1.0</data>
      <data key="d5">AgentInstruct generates synthetic data to teach language models the skill of reading comprehension.</data>
      <data key="d6">6fe27f9eb76cf2ddf712a2cee5783d1c</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="RAW DOCUMENTS">
      <data key="d4">2.0</data>
      <data key="d5">AgentInstruct uses raw documents as input for generating synthetic data</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="SYNTHETIC-DATA-GENERATION-AS-A-SERVICE">
      <data key="d4">2.0</data>
      <data key="d5">AgentInstruct can enable the creation of Synthetic-Data-Generation-As-A-Service</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="CONTENT TRANSFORMATION AGENTS">
      <data key="d4">2.0</data>
      <data key="d5">AgentInstruct uses Content Transformation Agents to transform raw seeds</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="INSTRUCTION CREATION AGENTS">
      <data key="d4">2.0</data>
      <data key="d5">AgentInstruct uses Instruction Creation Agents to create diverse instructions</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="REFINEMENT AGENTS">
      <data key="d4">2.0</data>
      <data key="d5">AgentInstruct uses Refinement Agents to refine seed instructions</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="AGENTIC FLOWS">
      <data key="d4">3.0</data>
      <data key="d5">AgentInstruct uses agentic flows to automate the data generation process
AgentInstruct involves creating agentic flows for different skills</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2,b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="REASONING">
      <data key="d4">1.0</data>
      <data key="d5">AgentInstruct generates data covering the skill of reasoning</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="MATH">
      <data key="d4">1.0</data>
      <data key="d5">AgentInstruct generates data covering the skill of math</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="TOOL USE">
      <data key="d4">1.0</data>
      <data key="d5">AgentInstruct generates data covering the skill of tool use</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="DATA GENERATION WORKFLOWS">
      <data key="d4">1.0</data>
      <data key="d5">AgentInstruct enables automation of data generation workflows</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="DATA FILTERING">
      <data key="d4">1.0</data>
      <data key="d5">AgentInstruct applies data filtering to ensure the quality of generated data</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="VERIFICATION">
      <data key="d4">1.0</data>
      <data key="d5">AgentInstruct applies verification to ensure the accuracy of generated data</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="REFLECTION FLOWS">
      <data key="d4">1.0</data>
      <data key="d5">AgentInstruct uses reflection flows to improve the quality of generated responses</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="SEARCH">
      <data key="d4">1.0</data>
      <data key="d5">AgentInstruct uses search as a tool to generate high-quality data</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="CODE INTERPRETERS">
      <data key="d4">1.0</data>
      <data key="d5">AgentInstruct uses code interpreters as tools to generate high-quality data</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="TAXONOMY">
      <data key="d4">1.0</data>
      <data key="d5">AgentInstruct uses a taxonomy to create diverse and high-quality prompts and responses</data>
      <data key="d6">b88745a13b69cecbc0ee9c3af41389bf</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="MISTRAL-7B-V0.1">
      <data key="d4">2.0</data>
      <data key="d5">Mistral-7b-v0.1 is finetuned using the AgentInstruct dataset</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="ORCA-2.5">
      <data key="d4">2.0</data>
      <data key="d5">AgentInstruct data led to a performance augmentation of 33.94% over the Orca-2.5 baseline</data>
      <data key="d6">bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="MISTRAL-INSTRUCT-7B">
      <data key="d4">4.0</data>
      <data key="d5">AgentInstruct data led to a performance enhancement of 14.92% over Mistral-Instruct-7B
AgentInstruct is used to enhance Mistral's proficiency across various difficulties</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="MISTRAL">
      <data key="d4">2.0</data>
      <data key="d5">AgentInstruct is used to improve Mistral&#8217;s reading comprehension capabilities.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="FORMAT FOLLOWING">
      <data key="d4">2.0</data>
      <data key="d5">Format Following is taught in all AgentInstruct flows to improve model performance</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="HALLUCINATIONS">
      <data key="d4">1.0</data>
      <data key="d5">AgentInstruct approach reduced hallucinations by 31.34%</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="AGENTINSTRUCT" target="ORCA-3-7B">
      <data key="d4">1.0</data>
      <data key="d5">Orca-3-7B is fine-tuned with AgentInstruct data</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="CREATIVE WRITING" target="RETRIEVAL AUGMENTED GENERATION">
      <data key="d4">1.0</data>
      <data key="d5">Both skills involve generating content, with retrieval augmented generation focusing on improving relevance</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="CODING" target="TOOL USE">
      <data key="d4">2.0</data>
      <data key="d5">Coding often involves the use of various tools and APIs</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="READING COMPREHENSION" target="QUESTION ANSWERING">
      <data key="d4">4.0</data>
      <data key="d5">Both are skills related to understanding and processing text
Reading comprehension enables scenarios like question answering</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e,f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="READING COMPREHENSION" target="MULTIPLE CHOICE QUESTIONS">
      <data key="d4">2.0</data>
      <data key="d5">Multiple choice questions are often used to assess reading comprehension</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="READING COMPREHENSION" target="AGENTINSTRUCT FLOW">
      <data key="d4">2.0</data>
      <data key="d5">AgentInstruct Flow includes a flow for reading comprehension</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION" target="DECODING">
      <data key="d4">2.0</data>
      <data key="d5">Decoding is a component of reading comprehension</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION" target="FLUENCY">
      <data key="d4">2.0</data>
      <data key="d5">Fluency is a component of reading comprehension</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION" target="VOCABULARY KNOWLEDGE">
      <data key="d4">2.0</data>
      <data key="d5">Vocabulary knowledge is a component of reading comprehension</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION" target="SEARCH">
      <data key="d4">2.0</data>
      <data key="d5">Reading comprehension enables scenarios like search</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION" target="GROUNDED REASONING">
      <data key="d4">2.0</data>
      <data key="d5">Reading comprehension enables scenarios like grounded reasoning</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION" target="CONTENT TRANSFORMATION FLOW">
      <data key="d4">2.0</data>
      <data key="d5">Content Transformation Flow is designed to generate materials for reading comprehension</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION" target="DROP">
      <data key="d4">2.0</data>
      <data key="d5">DROP is a reading comprehension benchmark.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="READING COMPREHENSION" target="LSAT">
      <data key="d4">2.0</data>
      <data key="d5">LSAT is used to evaluate reading comprehension in models.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="READING COMPREHENSION" target="LAW SCHOOL ADMISSION TESTS (LSATS)">
      <data key="d4">1.0</data>
      <data key="d5">The Law School Admission Tests (LSATs) are used to evaluate reading comprehension in models.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="CONTENT TRANSFORMATION FLOW">
      <data key="d4">2.0</data>
      <data key="d5">Content Transformation Flow is a part of agentic flows that converts raw seeds into intermediate representations</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="SEED INSTRUCTION GENERATION FLOW">
      <data key="d4">2.0</data>
      <data key="d5">Seed Instruction Generation Flow is a part of agentic flows that generates diverse instructions</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="AGENTIC FLOWS" target="INSTRUCTION REFINEMENT FLOW">
      <data key="d4">2.0</data>
      <data key="d5">Instruction Refinement Flow is a part of agentic flows that enhances the complexity and quality of instructions</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TOOL USE" target="TEXT MODIFICATION">
      <data key="d4">2.0</data>
      <data key="d5">Text modification can involve the use of tools or APIs</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TOOL USE" target="WEB AGENT">
      <data key="d4">2.0</data>
      <data key="d5">A web agent is a type of tool used to perform tasks on the web</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TOOL USE" target="CONTENT TRANSFORMATION FLOW">
      <data key="d4">2.0</data>
      <data key="d5">Tool use is a task within the Content Transformation Flow</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="ARGUMENT PASSAGE GENERATOR">
      <data key="d4">2.0</data>
      <data key="d5">Argument Passage Generator is a tool within the Content Transformation Flow</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="CONTENT TRANSFORMATION FLOW" target="API RETRIEVAL AGENT">
      <data key="d4">2.0</data>
      <data key="d5">The API Retrieval Agent is used in the Content Transformation Flow to expand the list of APIs</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="READING COMPREHENSION QUESTIONS">
      <data key="d4">2.0</data>
      <data key="d5">The Seed Instruction Generation Flow involves compiling various types of reading comprehension questions.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION GENERATION FLOW" target="PASSAGE-QUESTION PAIRS">
      <data key="d4">2.0</data>
      <data key="d5">The Seed Instruction Generation Flow results in the creation of passage-question pairs.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="SUGGESTER-EDITOR AGENTS">
      <data key="d4">4.0</data>
      <data key="d5">Suggester-Editor Agents are used in the Instruction Refinement Flow to propose and modify instructions
The Instruction Refinement Flow involves suggester-editor agents to refine passage-question pairs.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d,f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="EDITOR AGENT">
      <data key="d4">1.0</data>
      <data key="d5">The Editor Agent is part of the Instruction Refinement Flow, modifying passages, questions, or answer choices.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="INSTRUCTION REFINEMENT FLOW" target="SUGGESTER-EDITOR PAIR">
      <data key="d4">2.0</data>
      <data key="d5">The Suggester-Editor Pair is part of the Instruction Refinement Flow</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="TEXT MODIFICATION TASKS">
      <data key="d4">2.0</data>
      <data key="d5">Text modification involves various tasks such as paraphrasing, expansion, and simplification.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="PARAPHRASING">
      <data key="d4">2.0</data>
      <data key="d5">Paraphrasing is a type of text modification</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="TEXT SIMPLIFICATION">
      <data key="d4">2.0</data>
      <data key="d5">Text Simplification is a type of text modification</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="TEXT EXPANSION">
      <data key="d4">2.0</data>
      <data key="d5">Text Expansion is a type of text modification</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="TEXT TRANSLATION">
      <data key="d4">2.0</data>
      <data key="d5">Text Translation is a type of text modification</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="TEXT FORMATTING">
      <data key="d4">2.0</data>
      <data key="d5">Text Formatting is a type of text modification</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="SENTIMENT MODIFICATION">
      <data key="d4">2.0</data>
      <data key="d5">Sentiment Modification is a type of text modification</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="TEXT ANNOTATION">
      <data key="d4">2.0</data>
      <data key="d5">Text Annotation is a type of text modification</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="KEYWORD REPLACEMENT">
      <data key="d4">2.0</data>
      <data key="d5">Keyword Replacement is a type of text modification</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="TEXT REMOVING">
      <data key="d4">2.0</data>
      <data key="d5">Text Removing is a type of text modification</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="TEXT CAPITALIZATION">
      <data key="d4">2.0</data>
      <data key="d5">Text Capitalization is a type of text modification</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="TEXT STYLING">
      <data key="d4">2.0</data>
      <data key="d5">Text Styling is a type of text modification</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="CONTENT REWRITING">
      <data key="d4">2.0</data>
      <data key="d5">Content Rewriting is a type of text modification</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="DATA NORMALIZATION">
      <data key="d4">2.0</data>
      <data key="d5">Data Normalization is a type of text modification</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="PLAGIARISM REWORDING">
      <data key="d4">2.0</data>
      <data key="d5">Plagiarism Rewording is a type of text modification</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="CODE SWITCHING">
      <data key="d4">2.0</data>
      <data key="d5">Code Switching is a type of text modification</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="TEXT OBFUSCATION">
      <data key="d4">2.0</data>
      <data key="d5">Text Obfuscation is a type of text modification</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="TEXTUAL ENTAILMENT">
      <data key="d4">2.0</data>
      <data key="d5">Textual Entailment is a type of text modification</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TEXT MODIFICATION" target="REWRITING WITH VOCABULARY LIMITATIONS">
      <data key="d4">2.0</data>
      <data key="d5">Rewriting with Vocabulary Limitations is a type of text modification</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="WEB AGENT" target="WEB CONTROL">
      <data key="d4">1.0</data>
      <data key="d5">Web agents are used to perform web control tasks</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="BRAIN TEASER" target="ANALYTICAL REASONING">
      <data key="d4">2.0</data>
      <data key="d5">Brain teasers are used to train analytical reasoning skills</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="ANALYTICAL REASONING" target="FERMI PROBLEMS">
      <data key="d4">2.0</data>
      <data key="d5">Fermi problems require analytical reasoning to solve</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="MULTIPLE CHOICE QUESTIONS" target="EVALUATION METHOD">
      <data key="d4">2.0</data>
      <data key="d5">Multiple Choice Questions is a type of evaluation method</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="DATA TO TEXT" target="TEXT EXTRACTION">
      <data key="d4">2.0</data>
      <data key="d5">Text extraction can be a part of the data-to-text process</data>
      <data key="d6">f7eb89a70f544664546a510e46d5febd</data>
    </edge>
    <edge source="TEXT EXTRACTION" target="NAMED ENTITY RECOGNITION">
      <data key="d4">2.0</data>
      <data key="d5">Named entity recognition is a task within text extraction</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TEXT EXTRACTION" target="KEYWORD EXTRACTION">
      <data key="d4">2.0</data>
      <data key="d5">Keyword extraction is a task within text extraction</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TEXT EXTRACTION" target="DATA FIELDS">
      <data key="d4">2.0</data>
      <data key="d5">Extracting specific data fields from unstructured text is a task within text extraction</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="RETRIEVAL AUGMENTED GENERATION" target="NATURAL LANGUAGE PROCESSING">
      <data key="d4">2.0</data>
      <data key="d5">Retrieval Augmented Generation is a method used in natural language processing</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="RETRIEVAL AUGMENTED GENERATION" target="RETRIEVAL-BASED MODELS">
      <data key="d4">2.0</data>
      <data key="d5">Retrieval Augmented Generation combines retrieval-based models</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="RETRIEVAL AUGMENTED GENERATION" target="GENERATIVE MODELS">
      <data key="d4">2.0</data>
      <data key="d5">Retrieval Augmented Generation combines generative models</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TEXT CLASSIFICATION" target="SPAM DETECTION">
      <data key="d4">2.0</data>
      <data key="d5">Spam detection is an application of text classification</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TEXT CLASSIFICATION" target="SENTIMENT ANALYSIS">
      <data key="d4">2.0</data>
      <data key="d5">Sentiment analysis is an application of text classification</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="TEXT CLASSIFICATION" target="TOPIC LABELING">
      <data key="d4">2.0</data>
      <data key="d5">Topic labeling is an application of text classification</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="URIC ACID" target="PURINE">
      <data key="d4">2.0</data>
      <data key="d5">Uric acid is a byproduct of purine metabolism</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="URIC ACID" target="HYPERURICEMIA">
      <data key="d4">2.0</data>
      <data key="d5">Hyperuricemia is characterized by high levels of uric acid</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="URIC ACID" target="HYPOURICEMIA">
      <data key="d4">4.0</data>
      <data key="d5">Hypouricemia is characterized by low levels of uric acid
Low levels of uric acid in the blood are indicative of hypouricemia.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="URIC ACID" target="LABORATORY BLOOD AND URINE TESTS">
      <data key="d4">2.0</data>
      <data key="d5">Laboratory blood and urine tests are required to diagnose conditions related to uric acid levels.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="URIC ACID" target="LIFESTYLE CHOICES">
      <data key="d4">1.0</data>
      <data key="d5">Lifestyle choices such as alcohol consumption and physical inactivity can affect uric acid levels.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPERURICEMIA" target="CARDIOVASCULAR DISEASE">
      <data key="d4">4.0</data>
      <data key="d5">Hyperuricemia may increase the risk of cardiovascular disease
Hyperuricemia is associated with an increased risk of cardiovascular disease.</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e,1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPERURICEMIA" target="LABORATORY BLOOD AND URINE TESTS">
      <data key="d4">2.0</data>
      <data key="d5">Laboratory blood and urine tests are required to diagnose hyperuricemia</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="HYPERURICEMIA" target="GENETIC PREDISPOSITION">
      <data key="d4">1.0</data>
      <data key="d5">Genetic predisposition can be correlated with hyperuricemia.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="HYPOURICEMIA" target="LABORATORY BLOOD AND URINE TESTS">
      <data key="d4">2.0</data>
      <data key="d5">Laboratory blood and urine tests are required to diagnose hypouricemia</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="HYPOURICEMIA" target="KIDNEY OR LIVER ISSUES">
      <data key="d4">2.0</data>
      <data key="d5">Hypouricemia can indicate underlying kidney or liver issues.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="CARDIOVASCULAR DISEASE" target="GENETIC PREDISPOSITION">
      <data key="d4">1.0</data>
      <data key="d5">Genetic predisposition can be correlated with increased cardiovascular events.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="LSAT LOGICAL REASONING TEST" target="ASSUMPTION QUESTIONS">
      <data key="d4">2.0</data>
      <data key="d5">The LSAT Logical Reasoning test features assumption questions</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="LSAT LOGICAL REASONING TEST" target="STRENGTHENING/WEAKENING QUESTIONS">
      <data key="d4">2.0</data>
      <data key="d5">The LSAT Logical Reasoning test features strengthening/weakening questions</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="LSAT LOGICAL REASONING TEST" target="FLAW QUESTIONS">
      <data key="d4">2.0</data>
      <data key="d5">The LSAT Logical Reasoning test features flaw questions</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="LSAT LOGICAL REASONING TEST" target="INFERENCE QUESTIONS">
      <data key="d4">2.0</data>
      <data key="d5">The LSAT Logical Reasoning test features inference questions</data>
      <data key="d6">0c212c1467564ad33330b1f655a8e27e</data>
    </edge>
    <edge source="READING COMPREHENSION QUESTIONS" target="AGENTS">
      <data key="d4">2.0</data>
      <data key="d5">Agents are defined to target specific categories of reading comprehension questions.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="READING COMPREHENSION QUESTIONS" target="APPENDIX A">
      <data key="d4">1.0</data>
      <data key="d5">Appendix A lists types of reading comprehension questions.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="READING COMPREHENSION QUESTIONS" target="STRENGTHEN TYPE QUESTION">
      <data key="d4">1.0</data>
      <data key="d5">Strengthen type questions are a category of reading comprehension questions.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="AGENTS" target="CONTENT TRANSFORMATION AGENT">
      <data key="d4">2.0</data>
      <data key="d5">The Content Transformation Agent determines which subset of question-generating agents to engage.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="TEXT MODIFICATION TASKS" target="PARAPHRASING AGENT">
      <data key="d4">2.0</data>
      <data key="d5">The Paraphrasing Agent creates paraphrased versions of text as part of text modification tasks.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="TEXT MODIFICATION TASKS" target="APPENDIX A">
      <data key="d4">1.0</data>
      <data key="d5">Appendix A lists types of text modification tasks.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="STRENGTHEN TYPE QUESTION" target="HYPOTHETICAL STUDY">
      <data key="d4">1.0</data>
      <data key="d5">A hypothetical study can be used to add complexity to a strengthen type question.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="STRENGTHEN TYPE QUESTION" target="DISTRACTOR OPTION">
      <data key="d4">1.0</data>
      <data key="d5">A distractor option is used in strengthen type questions to test the ability to discern relevant from irrelevant information.</data>
      <data key="d6">1d8835c0ce90e56be22873bcf2740a5d</data>
    </edge>
    <edge source="SEED INSTRUCTION" target="RANDOM SEED">
      <data key="d4">2.0</data>
      <data key="d5">The Seed Instruction is generated using a Random Seed</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="UNIVERSITY OF IOWA" target="SEA 2017 ANNUAL MEETING">
      <data key="d4">2.0</data>
      <data key="d5">The SEA 2017 Annual Meeting was held at the University of Iowa</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="FINANCIALIZATION" target="NATASCHA VAN DER ZWAN">
      <data key="d4">2.0</data>
      <data key="d5">Natascha van der Zwan identifies three research streams related to financialization</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="FINANCIALIZATION" target="ANTHROPOLOGICAL SKEPTICS">
      <data key="d4">2.0</data>
      <data key="d5">Anthropological skeptics argue against the current understanding of financialization</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="FINANCIALIZATION" target="SUPPLY CHAINS OF FINANCIAL PRODUCTS">
      <data key="d4">2.0</data>
      <data key="d5">Supply chains of financial products are part of the broader concept of financialization</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="AMERICAN ANTHROPOLOGICAL ASSOCIATION" target="SEA 2017 ANNUAL MEETING">
      <data key="d4">2.0</data>
      <data key="d5">The American Anthropological Association organizes the SEA 2017 Annual Meeting</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SEA 2017 ANNUAL MEETING" target="APRIL 6-8, 2017">
      <data key="d4">1.0</data>
      <data key="d5">The SEA 2017 Annual Meeting was held on April 6-8, 2017</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SEA 2017 ANNUAL MEETING" target="DECEMBER 1, 2016">
      <data key="d4">1.0</data>
      <data key="d5">The abstract deadline for the SEA 2017 Annual Meeting was December 1, 2016</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SEA 2017 ANNUAL MEETING" target="MEETING REGISTRATION">
      <data key="d4">1.0</data>
      <data key="d5">Meeting registration is required to attend the SEA 2017 Annual Meeting</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="VIEW ALL FOOD ITEMS" target="LIBRARY RECONSTRUCTION">
      <data key="d4">2.0</data>
      <data key="d5">The "View All Food Items" API is part of the Library Reconstruction scenario</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="VIEW ALL FOOD ITEMS" target="API DESCRIPTION">
      <data key="d4">1.0</data>
      <data key="d5">The "View All Food Items" API includes a detailed description</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="VIEW ALL FOOD ITEMS" target="NUTRITIONAL PROFILES">
      <data key="d4">1.0</data>
      <data key="d5">The "View All Food Items" API provides nutritional profiles</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SEARCH FOOD ITEMS" target="LIBRARY RECONSTRUCTION">
      <data key="d4">2.0</data>
      <data key="d5">The "Search Food Items" API is part of the Library Reconstruction scenario</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SEARCH FOOD ITEMS" target="API DESCRIPTION">
      <data key="d4">1.0</data>
      <data key="d5">The "Search Food Items" API includes a detailed description</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="SEARCH FOOD ITEMS" target="GET FOOD ITEM DETAILS">
      <data key="d4">2.0</data>
      <data key="d5">Search Food Items API can be used to find food items, and Get Food Item Details API can provide detailed information about those items</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="SEARCH FOOD ITEMS" target="ASSISTANT">
      <data key="d4">2.0</data>
      <data key="d5">The assistant can use the Search Food Items API to help the user find food items</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="INSTRUCTION 1" target="SUGGESTION 1">
      <data key="d4">1.0</data>
      <data key="d5">Instruction 1 is based on Suggestion 1</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="INSTRUCTION 2" target="SUGGESTION 2">
      <data key="d4">1.0</data>
      <data key="d5">Instruction 2 is based on Suggestion 2</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="INSTRUCTION 3" target="SUGGESTION 3">
      <data key="d4">1.0</data>
      <data key="d5">Instruction 3 is based on Suggestion 3</data>
      <data key="d6">427e98b00e49b6a8f8649054122dd45b</data>
    </edge>
    <edge source="GET FOOD ITEM DETAILS" target="ASSISTANT">
      <data key="d4">2.0</data>
      <data key="d5">The assistant can use the Get Food Item Details API to provide detailed information about food items</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="CREATE MEAL PLAN" target="TRACK USER MEAL">
      <data key="d4">2.0</data>
      <data key="d5">Create Meal Plan API can be used to create a meal plan, and Track User Meal API can be used to track the meals in that plan</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="CREATE MEAL PLAN" target="GET DIETARY RECOMMENDATIONS">
      <data key="d4">2.0</data>
      <data key="d5">Create Meal Plan API can be used to create a meal plan, and Get Dietary Recommendations API can provide recommendations for that plan</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="CREATE MEAL PLAN" target="ASSISTANT">
      <data key="d4">2.0</data>
      <data key="d5">The assistant can use the Create Meal Plan API to create a meal plan for the user</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="UPDATE FOOD ITEM" target="ADD NEW FOOD ITEM">
      <data key="d4">2.0</data>
      <data key="d5">Add New Food Item API can be used to add new items, and Update Food Item API can be used to update those items</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="UPDATE FOOD ITEM" target="DELETE FOOD ITEM">
      <data key="d4">2.0</data>
      <data key="d5">Delete Food Item API can be used to remove items, and Update Food Item API can be used to modify existing items</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="UPDATE FOOD ITEM" target="ASSISTANT">
      <data key="d4">2.0</data>
      <data key="d5">The assistant can use the Update Food Item API to update food item details</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="TRACK USER MEAL" target="GET USER NUTRITIONAL STATS">
      <data key="d4">2.0</data>
      <data key="d5">Get User Nutritional Stats API can provide nutritional statistics based on the meals tracked using Track User Meal API</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="TRACK USER MEAL" target="ASSISTANT">
      <data key="d4">2.0</data>
      <data key="d5">The assistant can use the Track User Meal API to track the user's meals</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="GET DIETARY RECOMMENDATIONS" target="ASSISTANT">
      <data key="d4">2.0</data>
      <data key="d5">The assistant can use the Get Dietary Recommendations API to provide dietary recommendations</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="ADD NEW FOOD ITEM" target="ASSISTANT">
      <data key="d4">2.0</data>
      <data key="d5">The assistant can use the Add New Food Item API to add new food items</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="DELETE FOOD ITEM" target="ASSISTANT">
      <data key="d4">2.0</data>
      <data key="d5">The assistant can use the Delete Food Item API to delete food items</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="GET USER NUTRITIONAL STATS" target="ASSISTANT">
      <data key="d4">2.0</data>
      <data key="d5">The assistant can use the Get User Nutritional Stats API to provide nutritional statistics</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="SEED INSTRUCTION CREATION FLOW" target="REFINEMENT FLOW">
      <data key="d4">2.0</data>
      <data key="d5">Seed Instruction Creation Flow generates initial tasks, and Refinement Flow increases the complexity of these tasks</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="AGENT-INSTRUCT FLOW" target="SYSTEM MESSAGE">
      <data key="d4">2.0</data>
      <data key="d5">Agent-Instruct Flow creates multi-turn conversations, and System Message provides guidelines for these conversations</data>
      <data key="d6">0922646b93a124514ce2a267d961d229</data>
    </edge>
    <edge source="MEAL PLAN" target="VEGETARIAN MEAL PLAN">
      <data key="d4">2.0</data>
      <data key="d5">The vegetarian meal plan is a specific type of meal plan</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="DAY 1" target="BREAKFAST">
      <data key="d4">2.0</data>
      <data key="d5">Day 1 of the meal plan includes oatmeal with fruits and almond milk for breakfast</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="DAY 1" target="LUNCH">
      <data key="d4">2.0</data>
      <data key="d5">Day 1 of the meal plan includes chickpea salad and whole wheat bread for lunch</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="DAY 1" target="DINNER">
      <data key="d4">2.0</data>
      <data key="d5">Day 1 of the meal plan includes mixed vegetable stir fry and brown rice for dinner</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="QUINOA SALAD" target="DATABASE">
      <data key="d4">2.0</data>
      <data key="d5">The Quinoa Salad recipe is to be added to the database</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="CHANA MASALA" target="DATABASE">
      <data key="d4">2.0</data>
      <data key="d5">The Chana Masala dish is to be updated in the database</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="BUTTER CHICKEN" target="DATABASE">
      <data key="d4">2.0</data>
      <data key="d5">The Butter Chicken dish is to be removed from the database</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-BENCH" target="ODQA">
      <data key="d4">2.0</data>
      <data key="d5">ODQA is a category within the Orca-Bench dataset</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-BENCH" target="COMPLEX ODQA">
      <data key="d4">4.0</data>
      <data key="d5">Complex ODQA is a subset of the ODQA category within the Orca-Bench dataset
Complex ODQA is a subset of the Orca-Bench dataset</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a,bd4eb9459bc29b4c2da4658914fd4635</data>
    </edge>
    <edge source="ORCA-BENCH" target="MULTI-TURN INTERACTION">
      <data key="d4">1.0</data>
      <data key="d5">Some entries within the Orca-Bench dataset involve multi-turn interactions</data>
      <data key="d6">09cb89de3b77d765983cff25b7d74a1a</data>
    </edge>
    <edge source="ORCA-2.5" target="ORCA-3-7B">
      <data key="d4">1.0</data>
      <data key="d5">Orca-3-7B's performance was compared to Orca-2.5</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MISTRAL-INSTRUCT-7B" target="MISTRAL">
      <data key="d4">1.0</data>
      <data key="d5">Mistral shows a 21% gain relative to Mistral-Instruct-7b in reading comprehension.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="ARC" target="ALLENAI">
      <data key="d4">2.0</data>
      <data key="d5">ARC is a benchmark developed by AllenAI.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="GPQA" target="DOMAIN EXPERTS">
      <data key="d4">2.0</data>
      <data key="d5">GPQA questions are created by domain experts pursuing PhDs in their fields.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="DROP" target="DHEERU DUA">
      <data key="d4">1.0</data>
      <data key="d5">Dheeru Dua is an author who contributed to the DROP benchmark</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="DROP" target="EXACT MATCH/SPAN EXTRACTION">
      <data key="d4">2.0</data>
      <data key="d5">Exact match/span extraction is used to evaluate answers in the DROP dataset</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="FOFO" target="DOMAIN-SPECIFIC FORMATS">
      <data key="d4">2.0</data>
      <data key="d5">FoFo evaluates a model&#8217;s ability to follow complex, domain-specific formats.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="FOFO" target="FORMAT FOLLOWING">
      <data key="d4">2.0</data>
      <data key="d5">FoFo is a benchmark used to evaluate the performance of models on format-following tasks</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="FOFO" target="OPEN-ENDED GENERATION">
      <data key="d4">1.0</data>
      <data key="d5">FOFO is a benchmark used to evaluate open-ended generation tasks</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="FOFO" target="VERSION 0613">
      <data key="d4">1.0</data>
      <data key="d5">Version 0613 of GPT-4 is used in the FOFO benchmark for evaluation</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="IFEVAL" target="NATURAL LANGUAGE INSTRUCTIONS">
      <data key="d4">2.0</data>
      <data key="d5">IFEval measures a model&#8217;s ability to follow natural language instructions.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="IFEVAL" target="OPEN-ENDED GENERATION">
      <data key="d4">1.0</data>
      <data key="d5">IFEval is a benchmark used to evaluate open-ended generation tasks</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="INFOBENCH" target="DRFR">
      <data key="d4">2.0</data>
      <data key="d5">InFoBench uses the Decomposed Requirements Following Ratio (DRFR) to evaluate models.</data>
      <data key="d6">86f77e15d41cbd0cb33f635ccb2cb66b</data>
    </edge>
    <edge source="INFOBENCH" target="OPEN-ENDED GENERATION">
      <data key="d4">1.0</data>
      <data key="d5">InfoBench is a benchmark used to evaluate open-ended generation tasks</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="INFOBENCH" target="VERSION 1106-PREVIEW">
      <data key="d4">1.0</data>
      <data key="d5">Version 1106-preview of GPT-4 is used in the InfoBench benchmark for evaluation</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="EQBENCH" target="EMOTION SCORES">
      <data key="d4">2.0</data>
      <data key="d5">EQBench is used to evaluate emotion scores</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="MISTRAL-7B-INSTRUCT" target="ORCA-3-7B">
      <data key="d4">1.0</data>
      <data key="d5">Orca-3-7B's performance was compared to Mistral-7B-Instruct</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MISTRAL" target="ORCA-3-7B">
      <data key="d4">1.0</data>
      <data key="d5">Orca-3-7B is fine-tuned with AgentInstruct data based on the Mistral model family</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="FORMAT FOLLOWING" target="GEMINI PRO">
      <data key="d4">2.0</data>
      <data key="d5">Gemini Pro is used as a baseline for comparison in format-following tasks</data>
      <data key="d6">bb87f82e6a9f1d4da6480ec78a0e3701</data>
    </edge>
    <edge source="GEMINI PRO" target="ORCA-3-7B">
      <data key="d4">1.0</data>
      <data key="d5">Orca-3-7B's performance was compared to Gemini Pro</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="FOFO BENCHMARK" target="ORCA-3-7B">
      <data key="d4">1.0</data>
      <data key="d5">Orca-3-7B was evaluated on the FoFo benchmark</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ABSTRACTIVE SUMMARIZATION" target="HALLUCINATIONS">
      <data key="d4">1.0</data>
      <data key="d5">Hallucinations are a key metric in evaluating abstractive summarization</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ABSTRACTIVE SUMMARIZATION" target="QUALITY">
      <data key="d4">1.0</data>
      <data key="d5">Quality is a key metric in evaluating abstractive summarization</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ABSTRACTIVE SUMMARIZATION" target="GPT4">
      <data key="d4">1.0</data>
      <data key="d5">GPT4 was used to evaluate abstractive summarization</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ABSTRACTIVE SUMMARIZATION" target="ACI-BENCH">
      <data key="d4">1.0</data>
      <data key="d5">ACI-Bench is used to evaluate abstractive summarization</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ABSTRACTIVE SUMMARIZATION" target="INSTRUSUM">
      <data key="d4">1.0</data>
      <data key="d5">InstruSum is used to evaluate abstractive summarization</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="ABSTRACTIVE SUMMARIZATION" target="ORCA-SUM">
      <data key="d4">1.0</data>
      <data key="d5">Orca-Sum is used to evaluate abstractive summarization</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MIRAGE" target="MEDICAL CORPUS">
      <data key="d4">1.0</data>
      <data key="d5">MIRAGE uses a medical corpus to evaluate language models</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MIRAGE" target="MMLU-MED">
      <data key="d4">1.0</data>
      <data key="d5">MMLU-MED is a dataset used in the MIRAGE benchmark</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MIRAGE" target="MEDQA-US">
      <data key="d4">1.0</data>
      <data key="d5">MEDQA-US is a dataset used in the MIRAGE benchmark</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MIRAGE" target="MEDMCQA">
      <data key="d4">1.0</data>
      <data key="d5">MEDMCQA is a dataset used in the MIRAGE benchmark</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MIRAGE" target="PUBMEDQA">
      <data key="d4">1.0</data>
      <data key="d5">PUBMEDQA is a dataset used in the MIRAGE benchmark</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="MIRAGE" target="BIOASQ">
      <data key="d4">1.0</data>
      <data key="d5">BIOASQ is a dataset used in the MIRAGE benchmark</data>
      <data key="d6">8ee9617c145e19fa95f1f9349bfbe69b</data>
    </edge>
    <edge source="PUBMEDQA" target="MIRAGE DATASETS">
      <data key="d4">1.0</data>
      <data key="d5">PubMedQA is one of the datasets within the MIRAGE collection</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="BIOASQ" target="MIRAGE DATASETS">
      <data key="d4">1.0</data>
      <data key="d5">BioASQ is one of the datasets within the MIRAGE collection</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ORCA-3-7B" target="MIRAGE DATASETS">
      <data key="d4">1.0</data>
      <data key="d5">Orca-3-7B is evaluated on the MIRAGE datasets</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ORCA-3-7B" target="COT (CHAIN-OF-THOUGHT)">
      <data key="d4">1.0</data>
      <data key="d5">Orca-3-7B's performance is measured using CoT</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ORCA-3-7B" target="RAG (RETRIEVAL-AUGMENTED GENERATION)">
      <data key="d4">1.0</data>
      <data key="d5">Orca-3-7B's performance is measured using RAG</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ORCA-2.5-7B" target="MIRAGE DATASETS">
      <data key="d4">1.0</data>
      <data key="d5">Orca-2.5-7B is evaluated on the MIRAGE datasets</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ORCA-2.5-7B" target="COT (CHAIN-OF-THOUGHT)">
      <data key="d4">1.0</data>
      <data key="d5">Orca-2.5-7B's performance is measured using CoT</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="ORCA-2.5-7B" target="RAG (RETRIEVAL-AUGMENTED GENERATION)">
      <data key="d4">1.0</data>
      <data key="d5">Orca-2.5-7B's performance is measured using RAG</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MISTRAL-7B-INSTRUCT-V0.1" target="MIRAGE DATASETS">
      <data key="d4">1.0</data>
      <data key="d5">Mistral-7B-Instruct-v0.1 is evaluated on the MIRAGE datasets</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MISTRAL-7B-INSTRUCT-V0.1" target="COT (CHAIN-OF-THOUGHT)">
      <data key="d4">1.0</data>
      <data key="d5">Mistral-7B-Instruct-v0.1's performance is measured using CoT</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MISTRAL-7B-INSTRUCT-V0.1" target="RAG (RETRIEVAL-AUGMENTED GENERATION)">
      <data key="d4">1.0</data>
      <data key="d5">Mistral-7B-Instruct-v0.1's performance is measured using RAG</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MEDRAG" target="MIRAGE DATASETS">
      <data key="d4">1.0</data>
      <data key="d5">MedRAG is used as the retrieval mechanism across all models on the MIRAGE datasets</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="AZURE" target="LACK OF TRANSPARENCY">
      <data key="d4">2.0</data>
      <data key="d5">Azure provides transparency notes to address the lack of transparency in large language models</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MIRAGE DATASETS" target="MEDMEDQA">
      <data key="d4">1.0</data>
      <data key="d5">MedMedQA is one of the datasets within the MIRAGE collection</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="MIRAGE DATASETS" target="USMEDMCQA">
      <data key="d4">1.0</data>
      <data key="d5">USMedMCQA is one of the datasets within the MIRAGE collection</data>
      <data key="d6">ab04427ae0415a1c812a35cf8d3ee1a2</data>
    </edge>
    <edge source="HALLUCINATION" target="SUMMARY">
      <data key="d4">1.0</data>
      <data key="d5">Hallucination is an issue that can occur in AI-generated summaries</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="AI2 REASONING CHALLENGE" target="PETER CLARK">
      <data key="d4">1.0</data>
      <data key="d5">Peter Clark is an author who contributed to the AI2 reasoning challenge</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="VERIFIERS" target="KARL COBBE">
      <data key="d4">1.0</data>
      <data key="d5">Karl Cobbe is an author who contributed to the research on training verifiers to solve math word problems</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="GITHUB-CODE CLEAN DATASET" target="CODEPARROT">
      <data key="d4">1.0</data>
      <data key="d5">CodeParrot is the organization that created the GitHub-code clean dataset</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="CHAT LANGUAGE MODELS" target="NING DING">
      <data key="d4">1.0</data>
      <data key="d5">Ning Ding is an author who contributed to the research on enhancing chat language models</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="QUERY OF CC" target="ZHAOYE FEI">
      <data key="d4">1.0</data>
      <data key="d5">Zhaoye Fei is an author who contributed to the research on Query of CC</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="IMITATING PROPRIETARY LLMS" target="ARNAV GUDIBANDE">
      <data key="d4">1.0</data>
      <data key="d5">Arnav Gudibande is an author who contributed to the research on the false promise of imitating proprietary LLMs</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="MATH DATASET" target="DAN HENDRYCKS">
      <data key="d4">1.0</data>
      <data key="d5">Dan Hendrycks is an author who contributed to the research on the math dataset</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="TULU 2" target="HAMISH IVISON">
      <data key="d4">1.0</data>
      <data key="d5">Hamish Ivison is an author who contributed to the research on Tulu 2</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="MISTRAL 7B" target="ALBERT Q. JIANG">
      <data key="d4">1.0</data>
      <data key="d5">Albert Q. Jiang is an author who contributed to the research on Mistral 7B</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="RLAIF" target="HARRISON LEE">
      <data key="d4">1.0</data>
      <data key="d5">Harrison Lee is an author who contributed to the research on RLAIF</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="CAMEL" target="GUOHAO LI">
      <data key="d4">1.0</data>
      <data key="d5">Guohao Li is an author who contributed to the research on CAMEL</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="WANG" target="PHI-3">
      <data key="d4">1.0</data>
      <data key="d5">Wang is an author who contributed to the technical report on Phi-3</data>
      <data key="d6">cc20c99cad8edecc66b82ac751ff7172</data>
    </edge>
    <edge source="CRITICAL COMPREHENSION QUESTION" target="QUESTION TYPE">
      <data key="d4">2.0</data>
      <data key="d5">Critical Comprehension Question is a type of question</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="EVALUATIVE COMPREHENSION QUESTION" target="QUESTION TYPE">
      <data key="d4">2.0</data>
      <data key="d5">Evaluative Comprehension Question is a type of question</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="VOCABULARY AND LANGUAGE USE" target="QUESTION TYPE">
      <data key="d4">2.0</data>
      <data key="d5">Vocabulary and Language Use is a type of question</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="RELATIONSHIP COMPREHENSION QUESTION" target="QUESTION TYPE">
      <data key="d4">2.0</data>
      <data key="d5">Relationship Comprehension Question is a type of question</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="SEQUENCING EVENTS" target="QUESTION TYPE">
      <data key="d4">2.0</data>
      <data key="d5">Sequencing Events is a type of question</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="STRENGTHEN" target="QUESTION TYPE">
      <data key="d4">2.0</data>
      <data key="d5">Strengthen is a type of question</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="WEAKEN" target="QUESTION TYPE">
      <data key="d4">2.0</data>
      <data key="d5">Weaken is a type of question</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="ASSUMPTION" target="QUESTION TYPE">
      <data key="d4">2.0</data>
      <data key="d5">Assumption is a type of question</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="FLAW" target="QUESTION TYPE">
      <data key="d4">2.0</data>
      <data key="d5">Flaw is a type of question</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="INFERENCE" target="QUESTION TYPE">
      <data key="d4">2.0</data>
      <data key="d5">Inference is a type of question</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="PRINCIPLE" target="QUESTION TYPE">
      <data key="d4">2.0</data>
      <data key="d5">Principle is a type of question</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="METHOD OF REASONING" target="QUESTION TYPE">
      <data key="d4">2.0</data>
      <data key="d5">Method of Reasoning is a type of question</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="RESOLVE THE PARADOX" target="QUESTION TYPE">
      <data key="d4">2.0</data>
      <data key="d5">Resolve the Paradox is a type of question</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="NUMERICAL DISCRETE REASONING" target="QUESTION TYPE">
      <data key="d4">2.0</data>
      <data key="d5">Numerical Discrete Reasoning is a type of question</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="EVALUATION METHOD" target="INSTRUCTION TAXONOMY">
      <data key="d4">1.0</data>
      <data key="d5">Instruction Taxonomy is a type of evaluation method</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="EVALUATION METHOD" target="SEED INSTRUCTION GENERATION">
      <data key="d4">1.0</data>
      <data key="d5">Seed Instruction Generation is a type of evaluation method</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TECHNOLOGY" target="EVALUATOR ASSISTANT">
      <data key="d4">1.0</data>
      <data key="d5">Evaluator Assistant is a type of technology</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="TECHNOLOGY" target="EXTRACTION SYSTEM MESSAGE">
      <data key="d4">1.0</data>
      <data key="d5">Extraction System Message is a type of technology</data>
      <data key="d6">5819b66e04fd77fa705574edc49395bb</data>
    </edge>
    <edge source="EVALUATOR ASSISTANT" target="GENERAL EXTRACTION SYSTEM MESSAGE">
      <data key="d4">1.0</data>
      <data key="d5">The Evaluator Assistant uses the General Extraction System Message to parse and compare answers</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="EVALUATOR ASSISTANT" target="VERDICT">
      <data key="d4">1.0</data>
      <data key="d5">The Evaluator Assistant provides a verdict based on the comparison of the student's answer with the correct answer</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="STUDENT" target="ANSWER">
      <data key="d4">2.0</data>
      <data key="d5">The student provides an answer to the question</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="ANSWER" target="PARSED STUDENT ANSWER">
      <data key="d4">2.0</data>
      <data key="d5">The parsed student answer is extracted from the student's response</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="EMOTION SCORES" target="CRITIQUE">
      <data key="d4">2.0</data>
      <data key="d5">Emotion scores are followed by a critique</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="CRITIQUE" target="REVISED SCORES">
      <data key="d4">2.0</data>
      <data key="d5">The critique leads to revised scores</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="REVISED SCORES" target="RESIGNED">
      <data key="d4">2.0</data>
      <data key="d5">Resigned is one of the emotions that receives a revised score</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="REVISED SCORES" target="ANGRY">
      <data key="d4">2.0</data>
      <data key="d5">Angry is one of the emotions that receives a revised score</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="REVISED SCORES" target="HOPEFUL">
      <data key="d4">2.0</data>
      <data key="d5">Hopeful is one of the emotions that receives a revised score</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="REVISED SCORES" target="EMBARRASSED">
      <data key="d4">2.0</data>
      <data key="d5">Embarrassed is one of the emotions that receives a revised score</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="RESIGNED" target="ELLIOT">
      <data key="d4">1.0</data>
      <data key="d5">Elliot feels resigned because he has confessed his feelings to Alex, knowing that Alex is already in a relationship</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="ANGRY" target="ELLIOT">
      <data key="d4">1.0</data>
      <data key="d5">Elliot feels a bit angry at himself for putting himself in this situation</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="HOPEFUL" target="ELLIOT">
      <data key="d4">1.0</data>
      <data key="d5">Elliot feels a slight sense of hopefulness in his confession, hoping that Alex might reciprocate his feelings</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="EMBARRASSED" target="ELLIOT">
      <data key="d4">1.0</data>
      <data key="d5">Elliot feels embarrassed for putting Alex in an awkward position</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="VERDICT" target="CORRECT">
      <data key="d4">1.0</data>
      <data key="d5">The verdict can be "Correct" if the student's answer matches the correct answer</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="VERDICT" target="INCORRECT">
      <data key="d4">1.0</data>
      <data key="d5">The verdict can be "Incorrect" if the student's answer does not match the correct answer</data>
      <data key="d6">103d98395c393552cc954c89d4e59f50</data>
    </edge>
    <edge source="ALEX" target="ELLIOT">
      <data key="d4">1.0</data>
      <data key="d5">Elliot has confessed his feelings to Alex, who is already in a relationship</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="HALLUCINATION JUDGE" target="QUALITY JUDGE">
      <data key="d4">1.0</data>
      <data key="d5">Both tasks involve evaluating the quality and correctness of AI-generated responses</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="QUALITY JUDGE" target="INSTRUCTION ADHERENCE">
      <data key="d4">1.0</data>
      <data key="d5">Instruction adherence is a criterion used by the quality judge to evaluate AI-generated responses</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="QUALITY JUDGE" target="CONTENT GROUNDING">
      <data key="d4">1.0</data>
      <data key="d5">Content grounding is a criterion used by the quality judge to evaluate AI-generated responses</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
    <edge source="QUALITY JUDGE" target="OVERALL QUALITY">
      <data key="d4">1.0</data>
      <data key="d5">Overall quality is a criterion used by the quality judge to evaluate AI-generated responses</data>
      <data key="d6">0cf2e43f324fa4175b9b00b90e5e90ba</data>
    </edge>
  </graph>
</graphml>