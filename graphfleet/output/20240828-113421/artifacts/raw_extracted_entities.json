{"id":"0c932f7def033fa2b1bf210fbb771e7d","chunk":"From Local to Global: A Graph RAG Approach to\nQuery-Focused Summarization\nDarren Edge1\u2020Ha Trinh1\u2020Newman Cheng2Joshua Bradley2Alex Chao3\nApurva Mody3Steven Truitt2\nJonathan Larson1\n1Microsoft Research\n2Microsoft Strategic Missions and Technologies\n3Microsoft Office of the CTO\n{daedge,trinhha,newmancheng,joshbradley,achao,moapurva,steventruitt,jolarso }\n@microsoft.com\n\u2020These authors contributed equally to this work\nAbstract\nThe use of retrieval-augmented generation (RAG) to retrieve relevant informa-\ntion from an external knowledge source enables large language models (LLMs)\nto answer questions over private and\/or previously unseen document collections.\nHowever, RAG fails on global questions directed at an entire text corpus, such\nas \u201cWhat are the main themes in the dataset?\u201d, since this is inherently a query-\nfocused summarization (QFS) task, rather than an explicit retrieval task. Prior\nQFS methods, meanwhile, fail to scale to the quantities of text indexed by typical\nRAG systems. To combine the strengths of these contrasting methods, we propose\na Graph RAG approach to question answering over private text corpora that scales\nwith both the generality of user questions and the quantity of source text to be in-\ndexed. Our approach uses an LLM to build a graph-based text index in two stages:\nfirst to derive an entity knowledge graph from the source documents, then to pre-\ngenerate community summaries for all groups of closely-related entities. Given a\nquestion, each community summary is used to generate a partial response, before\nall partial responses are again summarized in a final response to the user. For a\nclass of global sensemaking questions over datasets in the 1 million token range,\nwe show that Graph RAG leads to substantial improvements over a na \u00a8\u0131ve RAG\nbaseline for both the comprehensiveness and diversity of generated answers. An\nopen-source, Python-based implementation of both global and local Graph RAG\napproaches is forthcoming at https:\/\/aka .ms\/graphrag .\n1 Introduction\nHuman endeavors across a range of domains rely on our ability to read and reason about large\ncollections of documents, often reaching conclusions that go beyond anything stated in the source\ntexts themselves. With the emergence of large language models (LLMs), we are already witnessing\nattempts to automate human-like sensemaking in complex domains like scientific discovery (Mi-\ncrosoft, 2023) and intelligence analysis (Ranade and Joshi, 2023), where sensemaking is defined as\nPreprint. Under review.arXiv:2404.16130v1  [cs.CL]  24 Apr 2024Source Documents\nText Chunkstext extraction\nand chunking\nElement Instancesdomain-tailored\nsummarization\nElement Summariesdomain-tailored\nsummarization\nGraph Communitiescommunity\ndetectionCommunity Summaries\ndomain-tailored\nsummarizationCommunity Answers\nquery-focused\nsummarizationGlobal Answer\nquery-focused\nsummarization\nIndexing Time Query Time Pipeline Stage\nFigure 1: Graph RAG pipeline using an LLM-derived graph index of source document text. This\nindex spans nodes (e.g., entities), edges (e.g., relationships), and covariates (e.g., claims) that have\nbeen detected, extracted, and summarized by LLM prompts tailored to the domain of the dataset.\nCommunity detection (e.g., Leiden, Traag et al., 2019) is used to partition the graph index into\ngroups of elements (nodes, edges, covariates) that the LLM can summarize in parallel at both index-\ning time and query time. The \u201cglobal answer\u201d to a given query is produced using a final round of\nquery-focused summarization over all community summaries reporting relevance to that query.\n\u201ca motivated, continuous effort to understand connections (which can be among people, places, and\nevents) in order to anticipate their trajectories and act effectively \u201d (Klein et al., 2006a). Supporting\nhuman-led sensemaking over entire text corpora, however, needs a way for people to both apply and\nrefine their mental model of the data (Klein et al., 2006b) by asking questions of a global nature.\nRetrieval-augmented generation (RAG, Lewis et al., 2020) is an established approach to answering\nuser questions over entire datasets, but it is designed for situations where these answers are contained\nlocally within regions of text whose retrieval provides sufficient grounding for the generation task.\nInstead, a more appropriate task framing is query-focused summarization (QFS, Dang, 2006), and in\nparticular, query-focused abstractive summarization that generates natural language summaries and\nnot just concatenated excerpts (Baumel et al., 2018; Laskar et al., 2020; Yao et al., 2017) . In recent\nyears, however, such distinctions between summarization tasks that are abstractive versus extractive,\ngeneric versus query-focused, and single-document versus multi-document, have become less rele-\nvant. While early applications of the transformer architecture showed substantial improvements on\nthe state-of-the-art for all such summarization tasks (Goodwin et al., 2020; Laskar et al., 2022; Liu\nand Lapata, 2019), these tasks are now trivialized by modern LLMs, including the GPT (Achiam\net al., 2023; Brown et al., 2020), Llama (Touvron et al., 2023), and Gemini (Anil et al.,","chunk_id":"0c932f7def033fa2b1bf210fbb771e7d","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":1200,"entities":[{"name":"DARREN EDGE","type":"PERSON","description":"Darren Edge is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"","source_id":"0c932f7def033fa2b1bf210fbb771e7d"},{"name":"HA TRINH","type":"PERSON","description":"Ha Trinh is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"","source_id":"0c932f7def033fa2b1bf210fbb771e7d"},{"name":"NEWMAN CHENG","type":"PERSON","description":"Newman Cheng is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"","source_id":"0c932f7def033fa2b1bf210fbb771e7d"},{"name":"JOSHUA BRADLEY","type":"PERSON","description":"Joshua Bradley is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"","source_id":"0c932f7def033fa2b1bf210fbb771e7d"},{"name":"ALEX CHAO","type":"PERSON","description":"Alex Chao is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"","source_id":"0c932f7def033fa2b1bf210fbb771e7d"},{"name":"APURVA MODY","type":"PERSON","description":"Apurva Mody is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"","source_id":"0c932f7def033fa2b1bf210fbb771e7d"},{"name":"STEVEN TRUITT","type":"PERSON","description":"Steven Truitt is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"","source_id":"0c932f7def033fa2b1bf210fbb771e7d"},{"name":"JONATHAN LARSON","type":"PERSON","description":"Jonathan Larson is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"","source_id":"0c932f7def033fa2b1bf210fbb771e7d"},{"name":"MICROSOFT RESEARCH","type":"ORGANIZATION","description":"Microsoft Research is the organization where Darren Edge, Ha Trinh, and Jonathan Larson are affiliated","source_id":"0c932f7def033fa2b1bf210fbb771e7d"},{"name":"MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES","type":"ORGANIZATION","description":"Microsoft Strategic Missions and Technologies is the organization where Newman Cheng, Joshua Bradley, and Steven Truitt are affiliated","source_id":"0c932f7def033fa2b1bf210fbb771e7d"},{"name":"MICROSOFT OFFICE OF THE CTO","type":"ORGANIZATION","description":"Microsoft Office of the CTO is the organization where Alex Chao and Apurva Mody are affiliated","source_id":"0c932f7def033fa2b1bf210fbb771e7d"},{"name":"GRAPH RAG","type":"METHOD\/APPROACH","description":"Graph RAG is a proposed approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed","source_id":"0c932f7def033fa2b1bf210fbb771e7d"},{"name":"RETRIEVAL-AUGMENTED GENERATION (RAG)","type":"METHOD\/APPROACH","description":"Retrieval-augmented generation (RAG) is a method to retrieve relevant information from an external knowledge source to enable large language models to answer questions over private and\/or previously unseen document collections","source_id":"0c932f7def033fa2b1bf210fbb771e7d","entity_type":"METHOD\/APPROACH"},{"name":"QUERY-FOCUSED SUMMARIZATION (QFS)","type":"METHOD\/APPROACH","description":"Query-focused summarization (QFS) is a task that generates natural language summaries based on specific user queries","source_id":"0c932f7def033fa2b1bf210fbb771e7d","entity_type":"METHOD\/APPROACH"},{"name":"LARGE LANGUAGE MODELS (LLMS)","type":"TECHNOLOGY","description":"Large language models (LLMs) are advanced models used to automate human-like sensemaking in complex domains","source_id":"0c932f7def033fa2b1bf210fbb771e7d","entity_type":"TECHNOLOGY"},{"name":"COMMUNITY DETECTION","type":"PROCESS","description":"Community detection is a process used to partition a graph index into groups of elements that can be summarized in parallel","source_id":"0c932f7def033fa2b1bf210fbb771e7d","entity_type":"PROCESS"},{"name":"LEIDEN","type":"ALGORITHM","description":"Leiden is an algorithm used for community detection in the Graph RAG approach","source_id":"0c932f7def033fa2b1bf210fbb771e7d","entity_type":"ALGORITHM"},{"name":"GLOBAL SENSEMAKING QUESTIONS","type":"CONCEPT","description":"Global sensemaking questions are questions that require understanding connections among people, places, and events to anticipate their trajectories and act effectively","source_id":"0c932f7def033fa2b1bf210fbb771e7d","entity_type":"CONCEPT"},{"name":"OPEN-SOURCE IMPLEMENTATION","type":"RESOURCE","description":"An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming","source_id":"0c932f7def033fa2b1bf210fbb771e7d","entity_type":"RESOURCE"},{"name":"MICROSOFT","type":"ORGANIZATION","description":"Microsoft is the company associated with the research and development of the Graph RAG approach","source_id":"0c932f7def033fa2b1bf210fbb771e7d","entity_type":"ORGANIZATION"},{"name":"RANADE AND JOSHI","type":"PERSON","description":"Ranade and Joshi are researchers mentioned in the context of intelligence analysis using LLMs","source_id":"0c932f7def033fa2b1bf210fbb771e7d","entity_type":"PERSON"},{"name":"KLEIN ET AL.","type":"PERSON","description":"Klein et al. are researchers who defined sensemaking as a motivated, continuous effort to understand connections","source_id":"0c932f7def033fa2b1bf210fbb771e7d","entity_type":"PERSON"},{"name":"LEWIS ET AL.","type":"PERSON","description":"Lewis et al. are researchers associated with the development of retrieval-augmented generation (RAG)","source_id":"0c932f7def033fa2b1bf210fbb771e7d","entity_type":"PERSON"},{"name":"DANG","type":"PERSON","description":"Dang is a researcher associated with query-focused summarization (QFS)","source_id":"0c932f7def033fa2b1bf210fbb771e7d","entity_type":"PERSON"},{"name":"BAUMEL ET AL.","type":"PERSON","description":"Baumel et al. are researchers associated with query-focused abstractive summarization","source_id":"0c932f7def033fa2b1bf210fbb771e7d","entity_type":"PERSON"},{"name":"LASKAR ET AL.","type":"PERSON","description":"Laskar et al. are researchers associated with query-focused abstractive summarization","source_id":"0c932f7def033fa2b1bf210fbb771e7d","entity_type":"PERSON"},{"name":"YAO ET AL.","type":"PERSON","description":"Yao et al. are researchers associated with query-focused abstractive summarization","source_id":"0c932f7def033fa2b1bf210fbb771e7d","entity_type":"PERSON"},{"name":"GOODWIN ET AL.","type":"PERSON","description":"Goodwin et al. are researchers associated with the application of the transformer architecture to summarization tasks","source_id":"0c932f7def033fa2b1bf210fbb771e7d","entity_type":"PERSON"},{"name":"LIU AND LAPATA","type":"PERSON","description":"Liu and Lapata are researchers associated with the application of the transformer architecture to summarization tasks","source_id":"0c932f7def033fa2b1bf210fbb771e7d","entity_type":"PERSON"},{"name":"GPT","type":"MODEL","description":"GPT is a large language model used for various summarization tasks","source_id":"0c932f7def033fa2b1bf210fbb771e7d","entity_type":"MODEL"},{"name":"LLAMA","type":"MODEL","description":"Llama is a large language model used for various summarization tasks","source_id":"0c932f7def033fa2b1bf210fbb771e7d","entity_type":"MODEL"},{"name":"GEMINI","type":"MODEL","description":"Gemini is a large language model used for various summarization tasks","source_id":"0c932f7def033fa2b1bf210fbb771e7d","entity_type":"MODEL"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"DARREN EDGE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Darren Edge is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/node>    <node id=\"HA TRINH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ha Trinh is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/node>    <node id=\"NEWMAN CHENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Newman Cheng is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/node>    <node id=\"JOSHUA BRADLEY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joshua Bradley is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/node>    <node id=\"ALEX CHAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Alex Chao is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/node>    <node id=\"APURVA MODY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Apurva Mody is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/node>    <node id=\"STEVEN TRUITT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Steven Truitt is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/node>    <node id=\"JONATHAN LARSON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jonathan Larson is an author of the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/node>    <node id=\"MICROSOFT RESEARCH\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Microsoft Research is the organization where Darren Edge, Ha Trinh, and Jonathan Larson are affiliated<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/node>    <node id=\"MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Microsoft Strategic Missions and Technologies is the organization where Newman Cheng, Joshua Bradley, and Steven Truitt are affiliated<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/node>    <node id=\"MICROSOFT OFFICE OF THE CTO\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Microsoft Office of the CTO is the organization where Alex Chao and Apurva Mody are affiliated<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/node>    <node id=\"GRAPH RAG\">      <data key=\"d0\">METHOD\/APPROACH<\/data>      <data key=\"d1\">Graph RAG is a proposed approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/node>    <node id=\"RETRIEVAL-AUGMENTED GENERATION (RAG)\">      <data key=\"d0\">METHOD\/APPROACH<\/data>      <data key=\"d1\">Retrieval-augmented generation (RAG) is a method to retrieve relevant information from an external knowledge source to enable large language models to answer questions over private and\/or previously unseen document collections<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>      <data key=\"d3\">METHOD\/APPROACH<\/data>    <\/node>    <node id=\"QUERY-FOCUSED SUMMARIZATION (QFS)\">      <data key=\"d0\">METHOD\/APPROACH<\/data>      <data key=\"d1\">Query-focused summarization (QFS) is a task that generates natural language summaries based on specific user queries<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>      <data key=\"d3\">METHOD\/APPROACH<\/data>    <\/node>    <node id=\"LARGE LANGUAGE MODELS (LLMS)\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Large language models (LLMs) are advanced models used to automate human-like sensemaking in complex domains<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"COMMUNITY DETECTION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Community detection is a process used to partition a graph index into groups of elements that can be summarized in parallel<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>      <data key=\"d3\">PROCESS<\/data>    <\/node>    <node id=\"LEIDEN\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">Leiden is an algorithm used for community detection in the Graph RAG approach<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>      <data key=\"d3\">ALGORITHM<\/data>    <\/node>    <node id=\"GLOBAL SENSEMAKING QUESTIONS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Global sensemaking questions are questions that require understanding connections among people, places, and events to anticipate their trajectories and act effectively<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"OPEN-SOURCE IMPLEMENTATION\">      <data key=\"d0\">RESOURCE<\/data>      <data key=\"d1\">An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>      <data key=\"d3\">RESOURCE<\/data>    <\/node>    <node id=\"MICROSOFT\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Microsoft is the company associated with the research and development of the Graph RAG approach<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"RANADE AND JOSHI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ranade and Joshi are researchers mentioned in the context of intelligence analysis using LLMs<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KLEIN ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Klein et al. are researchers who defined sensemaking as a motivated, continuous effort to understand connections<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LEWIS ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lewis et al. are researchers associated with the development of retrieval-augmented generation (RAG)<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dang is a researcher associated with query-focused summarization (QFS)<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BAUMEL ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Baumel et al. are researchers associated with query-focused abstractive summarization<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LASKAR ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Laskar et al. are researchers associated with query-focused abstractive summarization<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YAO ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yao et al. are researchers associated with query-focused abstractive summarization<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GOODWIN ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Goodwin et al. are researchers associated with the application of the transformer architecture to summarization tasks<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LIU AND LAPATA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liu and Lapata are researchers associated with the application of the transformer architecture to summarization tasks<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GPT\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT is a large language model used for various summarization tasks<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"LLAMA\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Llama is a large language model used for various summarization tasks<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"GEMINI\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Gemini is a large language model used for various summarization tasks<\/data>      <data key=\"d2\">0c932f7def033fa2b1bf210fbb771e7d<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <edge source=\"DARREN EDGE\" target=\"HA TRINH\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Darren Edge and Ha Trinh co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"DARREN EDGE\" target=\"NEWMAN CHENG\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Darren Edge and Newman Cheng co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"DARREN EDGE\" target=\"JOSHUA BRADLEY\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Darren Edge and Joshua Bradley co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"DARREN EDGE\" target=\"ALEX CHAO\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Darren Edge and Alex Chao co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"DARREN EDGE\" target=\"APURVA MODY\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Darren Edge and Apurva Mody co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"DARREN EDGE\" target=\"STEVEN TRUITT\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Darren Edge and Steven Truitt co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"DARREN EDGE\" target=\"JONATHAN LARSON\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Darren Edge and Jonathan Larson co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"HA TRINH\" target=\"NEWMAN CHENG\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Ha Trinh and Newman Cheng co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"HA TRINH\" target=\"JOSHUA BRADLEY\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Ha Trinh and Joshua Bradley co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"HA TRINH\" target=\"ALEX CHAO\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Ha Trinh and Alex Chao co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"HA TRINH\" target=\"APURVA MODY\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Ha Trinh and Apurva Mody co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"HA TRINH\" target=\"STEVEN TRUITT\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Ha Trinh and Steven Truitt co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"HA TRINH\" target=\"JONATHAN LARSON\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Ha Trinh and Jonathan Larson co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"NEWMAN CHENG\" target=\"JOSHUA BRADLEY\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Newman Cheng and Joshua Bradley co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"NEWMAN CHENG\" target=\"ALEX CHAO\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Newman Cheng and Alex Chao co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"NEWMAN CHENG\" target=\"APURVA MODY\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Newman Cheng and Apurva Mody co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"NEWMAN CHENG\" target=\"STEVEN TRUITT\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Newman Cheng and Steven Truitt co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"NEWMAN CHENG\" target=\"JONATHAN LARSON\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Newman Cheng and Jonathan Larson co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"JOSHUA BRADLEY\" target=\"ALEX CHAO\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Joshua Bradley and Alex Chao co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"JOSHUA BRADLEY\" target=\"APURVA MODY\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Joshua Bradley and Apurva Mody co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"JOSHUA BRADLEY\" target=\"STEVEN TRUITT\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Joshua Bradley and Steven Truitt co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"JOSHUA BRADLEY\" target=\"JONATHAN LARSON\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Joshua Bradley and Jonathan Larson co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"ALEX CHAO\" target=\"APURVA MODY\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Alex Chao and Apurva Mody co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"ALEX CHAO\" target=\"STEVEN TRUITT\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Alex Chao and Steven Truitt co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"ALEX CHAO\" target=\"JONATHAN LARSON\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Alex Chao and Jonathan Larson co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"APURVA MODY\" target=\"STEVEN TRUITT\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Apurva Mody and Steven Truitt co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"APURVA MODY\" target=\"JONATHAN LARSON\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Apurva Mody and Jonathan Larson co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"STEVEN TRUITT\" target=\"JONATHAN LARSON\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Steven Truitt and Jonathan Larson co-authored the paper \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\"<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"MICROSOFT RESEARCH\" target=\"MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Microsoft Research and Microsoft Strategic Missions and Technologies are both part of Microsoft and collaborated on the paper<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"MICROSOFT RESEARCH\" target=\"MICROSOFT OFFICE OF THE CTO\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Microsoft Research and Microsoft Office of the CTO are both part of Microsoft and collaborated on the paper<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>    <edge source=\"MICROSOFT STRATEGIC MISSIONS AND TECHNOLOGIES\" target=\"MICROSOFT OFFICE OF THE CTO\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Microsoft Strategic Missions and Technologies and Microsoft Office of the CTO are both part of Microsoft and collaborated on the paper<\/data>      <data key=\"d6\">0c932f7def033fa2b1bf210fbb771e7d<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"64476a39d7d8b87b399e3bd3cead79c7","chunk":" on\nthe state-of-the-art for all such summarization tasks (Goodwin et al., 2020; Laskar et al., 2022; Liu\nand Lapata, 2019), these tasks are now trivialized by modern LLMs, including the GPT (Achiam\net al., 2023; Brown et al., 2020), Llama (Touvron et al., 2023), and Gemini (Anil et al., 2023) series,\nall of which can use in-context learning to summarize any content provided in their context window.\nThe challenge remains, however, for query-focused abstractive summarization over an entire corpus.\nSuch volumes of text can greatly exceed the limits of LLM context windows, and the expansion of\nsuch windows may not be enough given that information can be \u201clost in the middle\u201d of longer\ncontexts (Kuratov et al., 2024; Liu et al., 2023). In addition, although the direct retrieval of text\nchunks in na \u00a8\u0131ve RAG is likely inadequate for QFS tasks, it is possible that an alternative form of\npre-indexing could support a new RAG approach specifically targeting global summarization.\nIn this paper, we present a Graph RAG approach based on global summarization of an LLM-derived\nknowledge graph (Figure 1). In contrast with related work that exploits the structured retrieval\nand traversal affordances of graph indexes (subsection 4.2), we focus on a previously unexplored\nquality of graphs in this context: their inherent modularity (Newman, 2006) and the ability of com-\nmunity detection algorithms to partition graphs into modular communities of closely-related nodes\n(e.g., Louvain, Blondel et al., 2008; Leiden, Traag et al., 2019). LLM-generated summaries of these\n20 1 2 30100002000030000\nNumber of gleanings performedEntity references detected600 chunk size\n1200 chunk size\n2400 chunk size\nFigure 2: How the entity references detected in the HotPotQA dataset (Yang et al., 2018)\nvaries with chunk size and gleanings for our generic entity extraction prompt with gpt-4-turbo .\ncommunity descriptions provide complete coverage of the underlying graph index and the input doc-\numents it represents. Query-focused summarization of an entire corpus is then made possible using\na map-reduce approach: first using each community summary to answer the query independently\nand in parallel, then summarizing all relevant partial answers into a final global answer.\nTo evaluate this approach, we used an LLM to generate a diverse set of activity-centered sense-\nmaking questions from short descriptions of two representative real-world datasets, containing pod-\ncast transcripts and news articles respectively. For the target qualities of comprehensiveness, diver-\nsity, and empowerment (defined in subsection 3.4) that develop understanding of broad issues and\nthemes, we both explore the impact of varying the the hierarchical level of community summaries\nused to answer queries, as well as compare to na \u00a8\u0131ve RAG and global map-reduce summarization\nof source texts. We show that all global approaches outperform na \u00a8\u0131ve RAG on comprehensiveness\nand diversity, and that Graph RAG with intermediate- and low-level community summaries shows\nfavorable performance over source text summarization on these same metrics, at lower token costs.\n2 Graph RAG Approach & Pipeline\nWe now unpack the high-level data flow of the Graph RAG approach (Figure 1) and pipeline, de-\nscribing key design parameters, techniques, and implementation details for each step.\n2.1 Source Documents \u2192Text Chunks\nA fundamental design decision is the granularity with which input texts extracted from source doc-\numents should be split into text chunks for processing. In the following step, each of these chunks\nwill be passed to a set of LLM prompts designed to extract the various elements of a graph index.\nLonger text chunks require fewer LLM calls for such extraction, but suffer from the recall degrada-\ntion of longer LLM context windows (Kuratov et al., 2024; Liu et al., 2023). This behavior can be\nobserved in Figure 2 in the case of a single extraction round (i.e., with zero gleanings): on a sample\ndataset (HotPotQA, Yang et al., 2018), using a chunk size of 600 token extracted almost twice as\nmany entity references as when using a chunk size of 2400. While more references are generally\nbetter, any extraction process needs to balance recall and precision for the target activity.\n2.2 Text Chunks \u2192Element Instances\nThe baseline requirement for this step is to identify and extract instances of graph nodes and edges\nfrom each chunk of source text. We do this using a multipart LLM prompt that first identifies all\nentities in the text, including their name, type, and description, before identifying all relationships\nbetween clearly-related entities, including the source and target entities and a description of their\nrelationship. Both kinds of element instance are output in a single list of delimited tuples.\nThe primary opportunity to tailor this prompt to the domain of the document corpus lies in the\nchoice of few-shot examples provided to the LLM for in-context learning (Brown et al., 2020).\n3For example, while our default prompt extracting the broad class of \u201cnamed entities\u201d like people,\nplaces, and organizations is generally applicable, domains with specialized knowledge (e.g., science,\nmedicine, law) will benefit from few-shot examples specialized to those domains. We also support\na secondary extraction prompt for any additional covariates we would like to associate with the\nextracted node instances. Our","chunk_id":"64476a39d7d8b87b399e3bd3cead79c7","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":1200,"entities":[{"name":"LASKAR ET AL.","type":"PERSON","description":"Laskar et al. are authors referenced for their work on summarization tasks in 2022","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"LIU AND LAPATA","type":"PERSON","description":"Liu and Lapata are authors referenced for their work on summarization tasks in 2019","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"GPT","type":"MODEL","description":"GPT is a series of language models referenced for their ability to perform summarization tasks","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"ACHIAM ET AL.","type":"PERSON","description":"Achiam et al. are authors referenced for their work on GPT in 2023","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"BROWN ET AL.","type":"PERSON","description":"Brown et al. are authors referenced for their work on GPT in 2020","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"LLAMA","type":"MODEL","description":"Llama is a series of language models referenced for their ability to perform summarization tasks","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"TOUVRON ET AL.","type":"PERSON","description":"Touvron et al. are authors referenced for their work on Llama in 2023","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"GEMINI","type":"MODEL","description":"Gemini is a series of language models referenced for their ability to perform summarization tasks","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"ANIL ET AL.","type":"PERSON","description":"Anil et al. are authors referenced for their work on Gemini in 2023","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"KURATOV ET AL.","type":"PERSON","description":"Kuratov et al. are authors referenced for their work on summarization and LLM context windows in 2024","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"LIU ET AL.","type":"PERSON","description":"Liu et al. are authors referenced for their work on summarization and LLM context windows in 2023","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"RAG","type":"TECHNIQUE","description":"RAG (Retrieval-Augmented Generation) is a technique mentioned as inadequate for query-focused summarization tasks","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"GRAPH RAG","type":"TECHNIQUE","description":"Graph RAG is an approach based on global summarization of an LLM-derived knowledge graph","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"NEWMAN","type":"PERSON","description":"Newman is referenced for their work on the modularity of graphs in 2006","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"LOUVAIN","type":"ALGORITHM","description":"Louvain is a community detection algorithm used to partition graphs into modular communities","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"BLONDEL ET AL.","type":"PERSON","description":"Blondel et al. are authors referenced for their work on the Louvain algorithm in 2008","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"LEIDEN","type":"ALGORITHM","description":"Leiden is a community detection algorithm used to partition graphs into modular communities","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"TRAAG ET AL.","type":"PERSON","description":"Traag et al. are authors referenced for their work on the Leiden algorithm in 2019","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"HOTPOTQA","type":"DATASET","description":"HotPotQA is a dataset used to evaluate entity extraction with varying chunk sizes","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"YANG ET AL.","type":"PERSON","description":"Yang et al. are authors referenced for their work on the HotPotQA dataset in 2018","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"GPT-4-TURBO","type":"MODEL","description":"GPT-4-Turbo is a version of OpenAI's language model used for entity extraction in the HotPotQA dataset","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"MAP-REDUCE","type":"TECHNIQUE","description":"Map-Reduce is a technique used for query-focused summarization of an entire corpus","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"PODCAST TRANSCRIPTS","type":"DATASET","description":"Podcast transcripts are one of the real-world datasets used to generate activity-centered sense-making questions","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"NEWS ARTICLES","type":"DATASET","description":"News articles are one of the real-world datasets used to generate activity-centered sense-making questions","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"NAIVE RAG","type":"TECHNIQUE","description":"Naive RAG is a baseline technique compared against global summarization approaches","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"GLOBAL MAP-REDUCE","type":"TECHNIQUE","description":"Global Map-Reduce is a summarization technique compared against Naive RAG","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"GRAPH RAG APPROACH","type":"TECHNIQUE","description":"Graph RAG Approach is a high-level data flow and pipeline for global summarization","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"TEXT CHUNKS","type":"DATA UNIT","description":"Text Chunks are segments of source documents used for processing in the Graph RAG approach","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"ELEMENT INSTANCES","type":"DATA UNIT","description":"Element Instances are graph nodes and edges extracted from text chunks","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"NAMED ENTITIES","type":"DATA UNIT","description":"Named Entities are broad classes of entities like people, places, and organizations extracted from text","source_id":"64476a39d7d8b87b399e3bd3cead79c7","entity_type":"DATA UNIT"},{"name":"GOODWIN ET AL.","type":"","description":"","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"SUMMARIZATION TASKS","type":"","description":"","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"LLM CONTEXT WINDOWS","type":"","description":"","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"QUERY-FOCUSED SUMMARIZATION","type":"","description":"","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"GLOBAL SUMMARIZATION","type":"","description":"","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"GRAPH MODULARITY","type":"","description":"","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"COMMUNITY DETECTION","type":"","description":"","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"ENTITY EXTRACTION","type":"","description":"","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"SENSE-MAKING QUESTIONS","type":"","description":"","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"KNOWLEDGE GRAPH","type":"DATA UNIT","description":"A Knowledge Graph is a structured representation of knowledge used in the Graph RAG approach","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"COMMUNITY DESCRIPTIONS","type":"DATA UNIT","description":"Community Descriptions are summaries of graph communities used in the Graph RAG approach","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"ACTIVITY-CENTERED SENSE-MAKING QUESTIONS","type":"DATA UNIT","description":"Activity-Centered Sense-Making Questions are generated from real-world datasets for evaluation","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"COMPREHENSIVENESS","type":"QUALITY","description":"Comprehensiveness is a target quality for evaluating summarization approaches","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"DIVERSITY","type":"QUALITY","description":"Diversity is a target quality for evaluating summarization approaches","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"EMPOWERMENT","type":"QUALITY","description":"Empowerment is a target quality for evaluating summarization approaches","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"SOURCE TEXTS","type":"DATA UNIT","description":"Source Texts are the original documents used for summarization in the Graph RAG approach","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"HIERARCHICAL LEVEL","type":"QUALITY","description":"Hierarchical Level is a variable in the evaluation of community summaries","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"TOKEN COSTS","type":"QUALITY","description":"Token Costs are a metric used to evaluate the efficiency of summarization approaches","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"GRAPH RAG PIPELINE","type":"TECHNIQUE","description":"Graph RAG Pipeline is the implementation of the Graph RAG approach","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"LLM PROMPTS","type":"TECHNIQUE","description":"LLM Prompts are used to extract elements of a graph index from text chunks","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"FEW-SHOT EXAMPLES","type":"TECHNIQUE","description":"Few-Shot Examples are used in LLM prompts for in-context learning","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"LLM","type":"","description":"","source_id":"64476a39d7d8b87b399e3bd3cead79c7"},{"name":"EVALUATION","type":"","description":"","source_id":"64476a39d7d8b87b399e3bd3cead79c7"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"LASKAR ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Laskar et al. are authors referenced for their work on summarization tasks in 2022<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"LIU AND LAPATA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liu and Lapata are authors referenced for their work on summarization tasks in 2019<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"GPT\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT is a series of language models referenced for their ability to perform summarization tasks<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"ACHIAM ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Achiam et al. are authors referenced for their work on GPT in 2023<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"BROWN ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Brown et al. are authors referenced for their work on GPT in 2020<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"LLAMA\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Llama is a series of language models referenced for their ability to perform summarization tasks<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"TOUVRON ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Touvron et al. are authors referenced for their work on Llama in 2023<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"GEMINI\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Gemini is a series of language models referenced for their ability to perform summarization tasks<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"ANIL ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Anil et al. are authors referenced for their work on Gemini in 2023<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"KURATOV ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kuratov et al. are authors referenced for their work on summarization and LLM context windows in 2024<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"LIU ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liu et al. are authors referenced for their work on summarization and LLM context windows in 2023<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"RAG\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">RAG (Retrieval-Augmented Generation) is a technique mentioned as inadequate for query-focused summarization tasks<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"GRAPH RAG\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Graph RAG is an approach based on global summarization of an LLM-derived knowledge graph<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"NEWMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Newman is referenced for their work on the modularity of graphs in 2006<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"LOUVAIN\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">Louvain is a community detection algorithm used to partition graphs into modular communities<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"BLONDEL ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Blondel et al. are authors referenced for their work on the Louvain algorithm in 2008<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"LEIDEN\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">Leiden is a community detection algorithm used to partition graphs into modular communities<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"TRAAG ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Traag et al. are authors referenced for their work on the Leiden algorithm in 2019<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"HOTPOTQA\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">HotPotQA is a dataset used to evaluate entity extraction with varying chunk sizes<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"YANG ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yang et al. are authors referenced for their work on the HotPotQA dataset in 2018<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"GPT-4-TURBO\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4-Turbo is a version of OpenAI's language model used for entity extraction in the HotPotQA dataset<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"MAP-REDUCE\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Map-Reduce is a technique used for query-focused summarization of an entire corpus<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"PODCAST TRANSCRIPTS\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">Podcast transcripts are one of the real-world datasets used to generate activity-centered sense-making questions<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"NEWS ARTICLES\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">News articles are one of the real-world datasets used to generate activity-centered sense-making questions<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"NAIVE RAG\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Naive RAG is a baseline technique compared against global summarization approaches<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"GLOBAL MAP-REDUCE\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Global Map-Reduce is a summarization technique compared against Naive RAG<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"GRAPH RAG APPROACH\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Graph RAG Approach is a high-level data flow and pipeline for global summarization<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"TEXT CHUNKS\">      <data key=\"d0\">DATA UNIT<\/data>      <data key=\"d1\">Text Chunks are segments of source documents used for processing in the Graph RAG approach<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"ELEMENT INSTANCES\">      <data key=\"d0\">DATA UNIT<\/data>      <data key=\"d1\">Element Instances are graph nodes and edges extracted from text chunks<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"NAMED ENTITIES\">      <data key=\"d0\">DATA UNIT<\/data>      <data key=\"d1\">Named Entities are broad classes of entities like people, places, and organizations extracted from text<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>      <data key=\"d3\">DATA UNIT<\/data>    <\/node>    <node id=\"GOODWIN ET AL.\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"SUMMARIZATION TASKS\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"LLM CONTEXT WINDOWS\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"QUERY-FOCUSED SUMMARIZATION\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"GLOBAL SUMMARIZATION\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"GRAPH MODULARITY\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"COMMUNITY DETECTION\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"ENTITY EXTRACTION\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"SENSE-MAKING QUESTIONS\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"KNOWLEDGE GRAPH\">      <data key=\"d0\">DATA UNIT<\/data>      <data key=\"d1\">A Knowledge Graph is a structured representation of knowledge used in the Graph RAG approach<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"COMMUNITY DESCRIPTIONS\">      <data key=\"d0\">DATA UNIT<\/data>      <data key=\"d1\">Community Descriptions are summaries of graph communities used in the Graph RAG approach<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"ACTIVITY-CENTERED SENSE-MAKING QUESTIONS\">      <data key=\"d0\">DATA UNIT<\/data>      <data key=\"d1\">Activity-Centered Sense-Making Questions are generated from real-world datasets for evaluation<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"COMPREHENSIVENESS\">      <data key=\"d0\">QUALITY<\/data>      <data key=\"d1\">Comprehensiveness is a target quality for evaluating summarization approaches<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"DIVERSITY\">      <data key=\"d0\">QUALITY<\/data>      <data key=\"d1\">Diversity is a target quality for evaluating summarization approaches<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"EMPOWERMENT\">      <data key=\"d0\">QUALITY<\/data>      <data key=\"d1\">Empowerment is a target quality for evaluating summarization approaches<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"SOURCE TEXTS\">      <data key=\"d0\">DATA UNIT<\/data>      <data key=\"d1\">Source Texts are the original documents used for summarization in the Graph RAG approach<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"HIERARCHICAL LEVEL\">      <data key=\"d0\">QUALITY<\/data>      <data key=\"d1\">Hierarchical Level is a variable in the evaluation of community summaries<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"TOKEN COSTS\">      <data key=\"d0\">QUALITY<\/data>      <data key=\"d1\">Token Costs are a metric used to evaluate the efficiency of summarization approaches<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"GRAPH RAG PIPELINE\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Graph RAG Pipeline is the implementation of the Graph RAG approach<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"LLM PROMPTS\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">LLM Prompts are used to extract elements of a graph index from text chunks<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"FEW-SHOT EXAMPLES\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Few-Shot Examples are used in LLM prompts for in-context learning<\/data>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"LLM\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <node id=\"EVALUATION\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/node>    <edge source=\"LASKAR ET AL.\" target=\"SUMMARIZATION TASKS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Laskar et al. are referenced for their work on summarization tasks<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"LIU AND LAPATA\" target=\"SUMMARIZATION TASKS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Liu and Lapata are referenced for their work on summarization tasks<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"GPT\" target=\"SUMMARIZATION TASKS\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">GPT models are referenced for their ability to perform summarization tasks<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"GPT\" target=\"ACHIAM ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Achiam et al. are referenced for their work on GPT in 2023<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"GPT\" target=\"BROWN ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Brown et al. are referenced for their work on GPT in 2020<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"LLAMA\" target=\"SUMMARIZATION TASKS\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Llama models are referenced for their ability to perform summarization tasks<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"LLAMA\" target=\"TOUVRON ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Touvron et al. are referenced for their work on Llama in 2023<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"GEMINI\" target=\"SUMMARIZATION TASKS\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Gemini models are referenced for their ability to perform summarization tasks<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"GEMINI\" target=\"ANIL ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Anil et al. are referenced for their work on Gemini in 2023<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"KURATOV ET AL.\" target=\"LLM CONTEXT WINDOWS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Kuratov et al. are referenced for their work on LLM context windows in 2024<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"LIU ET AL.\" target=\"LLM CONTEXT WINDOWS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Liu et al. are referenced for their work on LLM context windows in 2023<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"RAG\" target=\"QUERY-FOCUSED SUMMARIZATION\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">RAG is mentioned as inadequate for query-focused summarization tasks<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"GLOBAL SUMMARIZATION\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Graph RAG is an approach based on global summarization of an LLM-derived knowledge graph<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"KNOWLEDGE GRAPH\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">A Knowledge Graph is used in the Graph RAG approach<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"COMMUNITY DESCRIPTIONS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Community Descriptions provide complete coverage of the underlying graph index<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"SOURCE TEXTS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Source Texts are the original documents used for summarization in the Graph RAG approach<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"GRAPH RAG PIPELINE\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Graph RAG Pipeline is the implementation of the Graph RAG approach<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"LLM PROMPTS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LLM Prompts are used to extract elements of a graph index from text chunks<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"NEWMAN\" target=\"GRAPH MODULARITY\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Newman is referenced for their work on the modularity of graphs in 2006<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"LOUVAIN\" target=\"COMMUNITY DETECTION\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Louvain is a community detection algorithm used to partition graphs into modular communities<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"LOUVAIN\" target=\"BLONDEL ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Blondel et al. are referenced for their work on the Louvain algorithm in 2008<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"LEIDEN\" target=\"COMMUNITY DETECTION\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Leiden is a community detection algorithm used to partition graphs into modular communities<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"LEIDEN\" target=\"TRAAG ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Traag et al. are referenced for their work on the Leiden algorithm in 2019<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"ENTITY EXTRACTION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">HotPotQA is a dataset used to evaluate entity extraction with varying chunk sizes<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"YANG ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yang et al. are referenced for their work on the HotPotQA dataset in 2018<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"GPT-4-TURBO\" target=\"ENTITY EXTRACTION\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">GPT-4-Turbo is used for entity extraction in the HotPotQA dataset<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"MAP-REDUCE\" target=\"QUERY-FOCUSED SUMMARIZATION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Map-Reduce is a technique used for query-focused summarization of an entire corpus<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"PODCAST TRANSCRIPTS\" target=\"SENSE-MAKING QUESTIONS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Podcast transcripts are used to generate activity-centered sense-making questions<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"NEWS ARTICLES\" target=\"SENSE-MAKING QUESTIONS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">News articles are used to generate activity-centered sense-making questions<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"NAIVE RAG\" target=\"GLOBAL SUMMARIZATION\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Naive RAG is a baseline technique compared against global summarization approaches<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"GLOBAL MAP-REDUCE\" target=\"GLOBAL SUMMARIZATION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Global Map-Reduce is a summarization technique compared against Naive RAG<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"GRAPH RAG APPROACH\" target=\"GLOBAL SUMMARIZATION\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Graph RAG Approach is a high-level data flow and pipeline for global summarization<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"GRAPH RAG APPROACH\" target=\"TEXT CHUNKS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Text Chunks are segments of source documents used for processing in the Graph RAG approach<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"GRAPH RAG APPROACH\" target=\"ELEMENT INSTANCES\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Element Instances are graph nodes and edges extracted from text chunks<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"NAMED ENTITIES\" target=\"ENTITY EXTRACTION\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Named Entities are broad classes of entities like people, places, and organizations extracted from text<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"GOODWIN ET AL.\" target=\"SUMMARIZATION TASKS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Goodwin et al. are referenced for their work on summarization tasks<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"SUMMARIZATION TASKS\" target=\"LLM\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">LLMs are referenced for their ability to perform summarization tasks<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"ACTIVITY-CENTERED SENSE-MAKING QUESTIONS\" target=\"EVALUATION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Activity-Centered Sense-Making Questions are generated from real-world datasets for evaluation<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"COMPREHENSIVENESS\" target=\"EVALUATION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Comprehensiveness is a target quality for evaluating summarization approaches<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"DIVERSITY\" target=\"EVALUATION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Diversity is a target quality for evaluating summarization approaches<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"EMPOWERMENT\" target=\"EVALUATION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Empowerment is a target quality for evaluating summarization approaches<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"HIERARCHICAL LEVEL\" target=\"EVALUATION\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Hierarchical Level is a variable in the evaluation of community summaries<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"TOKEN COSTS\" target=\"EVALUATION\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Token Costs are a metric used to evaluate the efficiency of summarization approaches<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>    <edge source=\"LLM PROMPTS\" target=\"FEW-SHOT EXAMPLES\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Few-Shot Examples are used in LLM prompts for in-context learning<\/data>      <data key=\"d6\">64476a39d7d8b87b399e3bd3cead79c7<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"e66ed885a08f92cc69f4895302c33047","chunk":" examples provided to the LLM for in-context learning (Brown et al., 2020).\n3For example, while our default prompt extracting the broad class of \u201cnamed entities\u201d like people,\nplaces, and organizations is generally applicable, domains with specialized knowledge (e.g., science,\nmedicine, law) will benefit from few-shot examples specialized to those domains. We also support\na secondary extraction prompt for any additional covariates we would like to associate with the\nextracted node instances. Our default covariate prompt aims to extract claims linked to detected\nentities, including the subject, object, type, description, source text span, and start and end dates.\nTo balance the needs of efficiency and quality, we use multiple rounds of \u201cgleanings\u201d, up to a\nspecified maximum, to encourage the LLM to detect any additional entities it may have missed\non prior extraction rounds. This is a multi-stage process in which we first ask the LLM to assess\nwhether all entities were extracted, using a logit bias of 100 to force a yes\/no decision. If the LLM\nresponds that entities were missed, then a continuation indicating that \u201cMANY entities were missed\nin the last extraction\u201d encourages the LLM to glean these missing entities. This approach allows us\nto use larger chunk sizes without a drop in quality (Figure 2) or the forced introduction of noise.\n2.3 Element Instances \u2192Element Summaries\nThe use of an LLM to \u201cextract\u201d descriptions of entities, relationships, and claims represented in\nsource texts is already a form of abstractive summarization, relying on the LLM to create inde-\npendently meaningful summaries of concepts that may be implied but not stated by the text itself\n(e.g., the presence of implied relationships). To convert all such instance-level summaries into sin-\ngle blocks of descriptive text for each graph element (i.e., entity node, relationship edge, and claim\ncovariate) requires a further round of LLM summarization over matching groups of instances.\nA potential concern at this stage is that the LLM may not consistently extract references to the\nsame entity in the same text format, resulting in duplicate entity elements and thus duplicate nodes\nin the entity graph. However, since all closely-related \u201ccommunities\u201d of entities will be detected\nand summarized in the following step, and given that LLMs can understand the common entity\nbehind multiple name variations, our overall approach is resilient to such variations provided there\nis sufficient connectivity from all variations to a shared set of closely-related entities.\nOverall, our use of rich descriptive text for homogeneous nodes in a potentially noisy graph structure\nis aligned with both the capabilities of LLMs and the needs of global, query-focused summarization.\nThese qualities also differentiate our graph index from typical knowledge graphs, which rely on\nconcise and consistent knowledge triples (subject, predicate, object) for downstream reasoning tasks.\n2.4 Element Summaries \u2192Graph Communities\nThe index created in the previous step can be modelled as an homogeneous undirected weighted\ngraph in which entity nodes are connected by relationship edges, with edge weights representing the\nnormalized counts of detected relationship instances. Given such a graph, a variety of community\ndetection algorithms may be used to partition the graph into communities of nodes with stronger\nconnections to one another than to the other nodes in the graph (e.g., see the surveys by Fortu-\nnato, 2010 and Jin et al., 2021). In our pipeline, we use Leiden (Traag et al., 2019) on account of\nits ability to recover hierarchical community structure of large-scale graphs efficiently (Figure 3).\nEach level of this hierarchy provides a community partition that covers the nodes of the graph in a\nmutually-exclusive, collective-exhaustive way, enabling divide-and-conquer global summarization.\n2.5 Graph Communities \u2192Community Summaries\nThe next step is to create report-like summaries of each community in the Leiden hierarchy, using\na method designed to scale to very large datasets. These summaries are independently useful in\ntheir own right as a way to understand the global structure and semantics of the dataset, and may\nthemselves be used to make sense of a corpus in the absence of a question. For example, a user\nmay scan through community summaries at one level looking for general themes of interest, then\nfollow links to the reports at the lower level that provide more details for each of the subtopics. Here,\nhowever, we focus on their utility as part of a graph-based index used for answering global queries.\nCommunity summaries are generated in the following way:\n4(a) Root communities at level 0 (b) Sub-communities at level 1\nFigure 3: Graph communities detected using the Leiden algorithm (Traag et al., 2019) over the\nMultiHop-RAG (Tang and Yang, 2024) dataset as indexed. Circles represent entity nodes with size\nproportional to their degree. Node layout was performed via OpenORD (Martin et al., 2011) and\nForce Atlas 2 (Jacomy et al., 2014). Node colors represent entity communities, shown at two levels\nof hierarchical clustering: (a) Level 0, corresponding to the hierarchical partition with maximum\nmodularity, and (b) Level 1, which reveals internal structure within these root-level communities.\n\u2022Leaf-level communities . The element summaries of a leaf-level community (nodes, edges,\ncovariates) are prioritized and then iteratively added to the LLM context window until\nthe token limit is reached. The prioritization is as follows: for each community edge in\ndecreasing order of combined source and target node degree (i.e., overall prominance), add\ndescriptions of the source node, target node, linked covari","chunk_id":"e66ed885a08f92cc69f4895302c33047","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":1200,"entities":[{"name":"LLM","type":"TECHNOLOGY\/TOOL","description":"LLM (Large Language Model) is used for extracting descriptions of entities, relationships, and claims from source texts, and for creating summaries of these elements","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"NAMED ENTITIES","type":"CONCEPT","description":"Named entities refer to specific categories like people, places, and organizations that are extracted from text","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"FEW-SHOT EXAMPLES","type":"TECHNIQUE","description":"Few-shot examples are specialized examples provided to the LLM to improve its performance in domains with specialized knowledge such as science, medicine, and law","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"COVARIATES","type":"CONCEPT","description":"Covariates are additional variables or attributes associated with extracted node instances, such as claims linked to detected entities","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"LOGIT BIAS","type":"TECHNIQUE","description":"Logit bias is a technique used to force the LLM to make a yes\/no decision during the entity extraction process","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"GLEANINGS","type":"PROCESS","description":"Gleanings refer to multiple rounds of extraction to encourage the LLM to detect any additional entities it may have missed in prior rounds","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"ELEMENT INSTANCES","type":"CONCEPT","description":"Element instances are the initial extracted descriptions of entities, relationships, and claims from source texts","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"ELEMENT SUMMARIES","type":"CONCEPT","description":"Element summaries are single blocks of descriptive text for each graph element, created by further summarizing instance-level summaries","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"GRAPH ELEMENT","type":"CONCEPT","description":"Graph elements include entity nodes, relationship edges, and claim covariates in a graph structure","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"ENTITY GRAPH","type":"CONCEPT","description":"An entity graph is a graph structure where nodes represent entities and edges represent relationships between them","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"KNOWLEDGE GRAPHS","type":"CONCEPT","description":"Knowledge graphs are graph structures that rely on concise and consistent knowledge triples (subject, predicate, object) for reasoning tasks","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"LEIDEN","type":"ALGORITHM","description":"Leiden is an algorithm used for community detection in large-scale graphs, known for its efficiency in recovering hierarchical community structures","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"COMMUNITY DETECTION","type":"PROCESS","description":"Community detection is the process of partitioning a graph into communities of nodes with stronger connections to one another than to other nodes","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"GRAPH COMMUNITIES","type":"CONCEPT","description":"Graph communities are groups of nodes in a graph that are more strongly connected to each other than to other nodes, detected using community detection algorithms","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"COMMUNITY SUMMARIES","type":"CONCEPT","description":"Community summaries are report-like summaries of each community in a graph, providing an understanding of the global structure and semantics of the dataset","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"MULTIHOP-RAG","type":"DATASET","description":"MultiHop-RAG is a dataset used in the context of graph indexing and community detection","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"OPENORD","type":"TOOL","description":"OpenORD is a tool used for node layout in graph visualization","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"FORCE ATLAS 2","type":"TOOL","description":"Force Atlas 2 is a tool used for node layout in graph visualization","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"HIERARCHICAL CLUSTERING","type":"TECHNIQUE","description":"Hierarchical clustering is a technique used to reveal internal structure within root-level communities in a graph","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"ROOT COMMUNITIES","type":"CONCEPT","description":"Root communities are the top-level communities in a hierarchical clustering of a graph","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"LEAF-LEVEL COMMUNITIES","type":"CONCEPT","description":"Leaf-level communities are the bottom-level communities in a hierarchical clustering of a graph, prioritized for summarization","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"TOKEN LIMIT","type":"CONCEPT","description":"Token limit refers to the maximum number of tokens that can be processed in a single context window by the LLM","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"BROWN ET AL., 2020","type":"PUBLICATION","description":"A reference to the work by Brown et al. in 2020, which discusses examples provided to the LLM for in-context learning","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"SCIENCE","type":"DOMAIN","description":"A specialized domain that benefits from few-shot examples for LLM performance improvement","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"MEDICINE","type":"DOMAIN","description":"A specialized domain that benefits from few-shot examples for LLM performance improvement","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"LAW","type":"DOMAIN","description":"A specialized domain that benefits from few-shot examples for LLM performance improvement","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"CLAIMS","type":"CONCEPT","description":"Claims are statements linked to detected entities, including attributes like subject, object, type, description, source text span, and start and end dates","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"FIGURE 2","type":"VISUALIZATION","description":"A figure referenced in the text that shows the impact of using larger chunk sizes without a drop in quality or the forced introduction of noise","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"FORTUNATO, 2010","type":"PUBLICATION","description":"A survey by Fortunato in 2010, referenced in the context of community detection algorithms","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"JIN ET AL., 2021","type":"PUBLICATION","description":"A survey by Jin et al. in 2021, referenced in the context of community detection algorithms","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"TRAAG ET AL., 2019","type":"PUBLICATION","description":"A reference to the work by Traag et al. in 2019, which discusses the Leiden algorithm for community detection","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"TANG AND YANG, 2024","type":"PUBLICATION","description":"A reference to the work by Tang and Yang in 2024, which discusses the MultiHop-RAG dataset","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"MARTIN ET AL., 2011","type":"PUBLICATION","description":"A reference to the work by Martin et al. in 2011, which discusses the OpenORD tool for node layout","source_id":"e66ed885a08f92cc69f4895302c33047"},{"name":"JACOMY ET AL., 2014","type":"PUBLICATION","description":"A reference to the work by Jacomy et al. in 2014, which discusses the Force Atlas 2 tool for node layout","source_id":"e66ed885a08f92cc69f4895302c33047"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"LLM\">      <data key=\"d0\">TECHNOLOGY\/TOOL<\/data>      <data key=\"d1\">LLM (Large Language Model) is used for extracting descriptions of entities, relationships, and claims from source texts, and for creating summaries of these elements<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"NAMED ENTITIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Named entities refer to specific categories like people, places, and organizations that are extracted from text<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"FEW-SHOT EXAMPLES\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Few-shot examples are specialized examples provided to the LLM to improve its performance in domains with specialized knowledge such as science, medicine, and law<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"COVARIATES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Covariates are additional variables or attributes associated with extracted node instances, such as claims linked to detected entities<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"LOGIT BIAS\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Logit bias is a technique used to force the LLM to make a yes\/no decision during the entity extraction process<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"GLEANINGS\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Gleanings refer to multiple rounds of extraction to encourage the LLM to detect any additional entities it may have missed in prior rounds<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"ELEMENT INSTANCES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Element instances are the initial extracted descriptions of entities, relationships, and claims from source texts<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"ELEMENT SUMMARIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Element summaries are single blocks of descriptive text for each graph element, created by further summarizing instance-level summaries<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"GRAPH ELEMENT\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Graph elements include entity nodes, relationship edges, and claim covariates in a graph structure<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"ENTITY GRAPH\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">An entity graph is a graph structure where nodes represent entities and edges represent relationships between them<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"KNOWLEDGE GRAPHS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Knowledge graphs are graph structures that rely on concise and consistent knowledge triples (subject, predicate, object) for reasoning tasks<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"LEIDEN\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">Leiden is an algorithm used for community detection in large-scale graphs, known for its efficiency in recovering hierarchical community structures<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"COMMUNITY DETECTION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Community detection is the process of partitioning a graph into communities of nodes with stronger connections to one another than to other nodes<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"GRAPH COMMUNITIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Graph communities are groups of nodes in a graph that are more strongly connected to each other than to other nodes, detected using community detection algorithms<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"COMMUNITY SUMMARIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Community summaries are report-like summaries of each community in a graph, providing an understanding of the global structure and semantics of the dataset<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"MULTIHOP-RAG\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">MultiHop-RAG is a dataset used in the context of graph indexing and community detection<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"OPENORD\">      <data key=\"d0\">TOOL<\/data>      <data key=\"d1\">OpenORD is a tool used for node layout in graph visualization<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"FORCE ATLAS 2\">      <data key=\"d0\">TOOL<\/data>      <data key=\"d1\">Force Atlas 2 is a tool used for node layout in graph visualization<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"HIERARCHICAL CLUSTERING\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Hierarchical clustering is a technique used to reveal internal structure within root-level communities in a graph<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"ROOT COMMUNITIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Root communities are the top-level communities in a hierarchical clustering of a graph<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"LEAF-LEVEL COMMUNITIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Leaf-level communities are the bottom-level communities in a hierarchical clustering of a graph, prioritized for summarization<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"TOKEN LIMIT\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Token limit refers to the maximum number of tokens that can be processed in a single context window by the LLM<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"BROWN ET AL., 2020\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A reference to the work by Brown et al. in 2020, which discusses examples provided to the LLM for in-context learning<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"SCIENCE\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">A specialized domain that benefits from few-shot examples for LLM performance improvement<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"MEDICINE\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">A specialized domain that benefits from few-shot examples for LLM performance improvement<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"LAW\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">A specialized domain that benefits from few-shot examples for LLM performance improvement<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"CLAIMS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Claims are statements linked to detected entities, including attributes like subject, object, type, description, source text span, and start and end dates<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"FIGURE 2\">      <data key=\"d0\">VISUALIZATION<\/data>      <data key=\"d1\">A figure referenced in the text that shows the impact of using larger chunk sizes without a drop in quality or the forced introduction of noise<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"FORTUNATO, 2010\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A survey by Fortunato in 2010, referenced in the context of community detection algorithms<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"JIN ET AL., 2021\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A survey by Jin et al. in 2021, referenced in the context of community detection algorithms<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"TRAAG ET AL., 2019\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A reference to the work by Traag et al. in 2019, which discusses the Leiden algorithm for community detection<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"TANG AND YANG, 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A reference to the work by Tang and Yang in 2024, which discusses the MultiHop-RAG dataset<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"MARTIN ET AL., 2011\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A reference to the work by Martin et al. in 2011, which discusses the OpenORD tool for node layout<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <node id=\"JACOMY ET AL., 2014\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A reference to the work by Jacomy et al. in 2014, which discusses the Force Atlas 2 tool for node layout<\/data>      <data key=\"d2\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/node>    <edge source=\"LLM\" target=\"NAMED ENTITIES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The LLM is used to extract named entities from text<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"LLM\" target=\"FEW-SHOT EXAMPLES\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Few-shot examples are provided to the LLM to improve its performance in specialized domains<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"LLM\" target=\"COVARIATES\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The LLM extracts covariates associated with detected entities<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"LLM\" target=\"LOGIT BIAS\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Logit bias is used to guide the LLM in making yes\/no decisions during entity extraction<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"LLM\" target=\"GLEANINGS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Gleanings involve multiple rounds of extraction by the LLM to detect additional entities<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"LLM\" target=\"CLAIMS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The LLM extracts claims linked to detected entities<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"LLM\" target=\"FIGURE 2\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Figure 2 shows the impact of using larger chunk sizes without a drop in quality or the forced introduction of noise<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"ELEMENT INSTANCES\" target=\"ELEMENT SUMMARIES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Element instances are further summarized into element summaries<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"ELEMENT SUMMARIES\" target=\"GRAPH ELEMENT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Element summaries are created for each graph element<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"GRAPH ELEMENT\" target=\"ENTITY GRAPH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Graph elements are part of the entity graph<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"ENTITY GRAPH\" target=\"KNOWLEDGE GRAPHS\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Entity graphs are differentiated from typical knowledge graphs<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"LEIDEN\" target=\"COMMUNITY DETECTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Leiden is used for community detection in large-scale graphs<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"LEIDEN\" target=\"MULTIHOP-RAG\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Leiden is used to detect communities in the MultiHop-RAG dataset<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"LEIDEN\" target=\"TRAAG ET AL., 2019\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Traag et al.'s 2019 work discusses the Leiden algorithm<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"COMMUNITY DETECTION\" target=\"GRAPH COMMUNITIES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Community detection results in the formation of graph communities<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"COMMUNITY DETECTION\" target=\"FORTUNATO, 2010\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Fortunato's 2010 survey is referenced in the context of community detection algorithms<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"COMMUNITY DETECTION\" target=\"JIN ET AL., 2021\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Jin et al.'s 2021 survey is referenced in the context of community detection algorithms<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"GRAPH COMMUNITIES\" target=\"COMMUNITY SUMMARIES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Community summaries are created for each graph community<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"GRAPH COMMUNITIES\" target=\"HIERARCHICAL CLUSTERING\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Hierarchical clustering reveals internal structure within graph communities<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"MULTIHOP-RAG\" target=\"OPENORD\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">OpenORD is used for node layout in the visualization of the MultiHop-RAG dataset<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"MULTIHOP-RAG\" target=\"FORCE ATLAS 2\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Force Atlas 2 is used for node layout in the visualization of the MultiHop-RAG dataset<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"MULTIHOP-RAG\" target=\"TANG AND YANG, 2024\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Tang and Yang's 2024 work discusses the MultiHop-RAG dataset<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"OPENORD\" target=\"MARTIN ET AL., 2011\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Martin et al.'s 2011 work discusses the OpenORD tool<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"FORCE ATLAS 2\" target=\"JACOMY ET AL., 2014\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Jacomy et al.'s 2014 work discusses the Force Atlas 2 tool<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"HIERARCHICAL CLUSTERING\" target=\"ROOT COMMUNITIES\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Root communities are identified in the hierarchical clustering<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"HIERARCHICAL CLUSTERING\" target=\"LEAF-LEVEL COMMUNITIES\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Leaf-level communities are identified in the hierarchical clustering<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>    <edge source=\"LEAF-LEVEL COMMUNITIES\" target=\"TOKEN LIMIT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Leaf-level communities are prioritized and added to the LLM context window until the token limit is reached<\/data>      <data key=\"d5\">e66ed885a08f92cc69f4895302c33047<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"4930fce6da868f894757a9da465807ba","chunk":" which reveals internal structure within these root-level communities.\n\u2022Leaf-level communities . The element summaries of a leaf-level community (nodes, edges,\ncovariates) are prioritized and then iteratively added to the LLM context window until\nthe token limit is reached. The prioritization is as follows: for each community edge in\ndecreasing order of combined source and target node degree (i.e., overall prominance), add\ndescriptions of the source node, target node, linked covariates, and the edge itself.\n\u2022Higher-level communities . If all element summaries fit within the token limit of the con-\ntext window, proceed as for leaf-level communities and summarize all element summaries\nwithin the community. Otherwise, rank sub-communities in decreasing order of element\nsummary tokens and iteratively substitute sub-community summaries (shorter) for their\nassociated element summaries (longer) until fit within the context window is achieved.\n2.6 Community Summaries \u2192Community Answers \u2192Global Answer\nGiven a user query, the community summaries generated in the previous step can be used to generate\na final answer in a multi-stage process. The hierarchical nature of the community structure also\nmeans that questions can be answered using the community summaries from different levels, raising\nthe question of whether a particular level in the hierarchical community structure offers the best\nbalance of summary detail and scope for general sensemaking questions (evaluated in section 3).\nFor a given community level, the global answer to any user query is generated as follows:\n\u2022Prepare community summaries . Community summaries are randomly shuffled and divided\ninto chunks of pre-specified token size. This ensures relevant information is distributed\nacross chunks, rather than concentrated (and potentially lost) in a single context window.\n\u2022Map community answers . Generate intermediate answers in parallel, one for each chunk.\nThe LLM is also asked to generate a score between 0-100 indicating how helpful the gen-\nerated answer is in answering the target question. Answers with score 0 are filtered out.\n\u2022Reduce to global answer . Intermediate community answers are sorted in descending order\nof helpfulness score and iteratively added into a new context window until the token limit\nis reached. This final context is used to generate the global answer returned to the user.\n5Dataset Example activity framing and generation of global sensemaking questions\nPodcast\ntranscriptsUser : A tech journalist looking for insights and trends in the tech industry\nTask: Understanding how tech leaders view the role of policy and regulation\nQuestions :\n1. Which episodes deal primarily with tech policy and government regulation?\n2. How do guests perceive the impact of privacy laws on technology development?\n3. Do any guests discuss the balance between innovation and ethical considerations?\n4. What are the suggested changes to current policies mentioned by the guests?\n5. Are collaborations between tech companies and governments discussed and how?\nNews\narticlesUser : Educator incorporating current affairs into curricula\nTask: Teaching about health and wellness\nQuestions :\n1. What current topics in health can be integrated into health education curricula?\n2. How do news articles address the concepts of preventive medicine and wellness?\n3. Are there examples of health articles that contradict each other, and if so, why?\n4. What insights can be gleaned about public health priorities based on news coverage?\n5. How can educators use the dataset to highlight the importance of health literacy?\nTable 1: Examples of potential users, tasks, and questions generated by the LLM based on short\ndescriptions of the target datasets. Questions target global understanding rather than specific details.\n3 Evaluation\n3.1 Datasets\nWe selected two datasets in the one million token range, each equivalent to about 10 novels of text\nand representative of the kind of corpora that users may encounter in their real world activities:\n\u2022Podcast transcripts . Compiled transcripts of podcast conversations between Kevin Scott,\nMicrosoft CTO, and other technology leaders (Behind the Tech, Scott, 2024). Size: 1669\n\u00d7600-token text chunks, with 100-token overlaps between chunks ( \u223c1 million tokens).\n\u2022News articles . Benchmark dataset comprising news articles published from September\n2013 to December 2023 in a range of categories, including entertainment, business, sports,\ntechnology, health, and science (MultiHop-RAG; Tang and Yang, 2024). Size: 3197 \u00d7\n600-token text chunks, with 100-token overlaps between chunks ( \u223c1.7 million tokens).\n3.2 Queries\nMany benchmark datasets for open-domain question answering exist, including HotPotQA (Yang\net al., 2018), MultiHop-RAG (Tang and Yang, 2024), and MT-Bench (Zheng et al., 2024). However,\nthe associated question sets target explicit fact retrieval rather than summarization for the purpose\nof data sensemaking, i.e., the process though which people inspect, engage with, and contextualize\ndata within the broader scope of real-world activities (Koesten et al., 2021). Similarly, methods for\nextracting latent summarization queries from source texts also exist (Xu and Lapata, 2021), but such\nextracted questions can target details that betray prior knowledge of the texts.\nTo evaluate the effectiveness of RAG systems for more global sensemaking tasks, we need questions\nthat convey only a high-level understanding of dataset contents, and not the details of specific texts.\nWe used an activity-centered approach to automate the generation of such questions: given a short\ndescription of a dataset, we asked the LLM to identify Npotential users and Ntasks per user,\nthen for each (user, task) combination, we asked the LLM to generate Nquestions that require\nunderstanding of the entire corpus. For our evaluation, a value of N= 5 resulted in 125 test questions\nper","chunk_id":"4930fce6da868f894757a9da465807ba","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":1200,"entities":[{"name":"ROOT-LEVEL COMMUNITIES","type":"CONCEPT","description":"Root-level communities refer to the primary divisions within a hierarchical community structure, revealing internal structure within these communities.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"LEAF-LEVEL COMMUNITIES","type":"CONCEPT","description":"Leaf-level communities are the most granular divisions within a hierarchical community structure, where element summaries (nodes, edges, covariates) are prioritized and added to the LLM context window until the token limit is reached.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"HIGHER-LEVEL COMMUNITIES","type":"CONCEPT","description":"Higher-level communities are broader divisions within a hierarchical community structure, where sub-communities are ranked and summarized to fit within the context window if element summaries exceed the token limit.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"COMMUNITY SUMMARIES","type":"CONCEPT","description":"Community summaries are generated descriptions of elements within a community, used to create a final answer in a multi-stage process based on hierarchical community structure.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"GLOBAL ANSWER","type":"CONCEPT","description":"The global answer is the final response generated from community summaries to answer a user query, ensuring a balance of summary detail and scope.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"USER QUERY","type":"CONCEPT","description":"A user query is a question posed by the user that the system aims to answer using community summaries and hierarchical community structure.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"PODCAST TRANSCRIPTS","type":"DATASET","description":"A dataset comprising compiled transcripts of podcast conversations between Kevin Scott, Microsoft CTO, and other technology leaders, used for evaluation purposes.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"NEWS ARTICLES","type":"DATASET","description":"A benchmark dataset comprising news articles published from September 2013 to December 2023 in various categories, used for evaluation purposes.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"TECH JOURNALIST","type":"USER","description":"A tech journalist is a potential user looking for insights and trends in the tech industry, particularly regarding the role of policy and regulation.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"EDUCATOR","type":"USER","description":"An educator is a potential user incorporating current affairs into curricula, particularly focusing on health and wellness.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"MULTIHOP-RAG","type":"DATASET","description":"A benchmark dataset used for evaluating open-domain question answering systems, including news articles in various categories.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"HOTPOTQA","type":"DATASET","description":"A benchmark dataset for open-domain question answering, targeting explicit fact retrieval.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"MT-BENCH","type":"DATASET","description":"A benchmark dataset for open-domain question answering, targeting explicit fact retrieval.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"RAG SYSTEMS","type":"TECHNOLOGY","description":"Retrieval-Augmented Generation (RAG) systems are used for generating answers to questions by retrieving relevant information from large datasets.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"DATA SENSEMAKING","type":"PROCESS","description":"Data sensemaking is the process through which people inspect, engage with, and contextualize data within the broader scope of real-world activities.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"KOESTEN ET AL.","type":"REFERENCE","description":"A reference to a study by Koesten et al. (2021) on data sensemaking behaviors.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"XU AND LAPATA","type":"REFERENCE","description":"A reference to a study by Xu and Lapata (2021) on methods for extracting latent summarization queries from source texts.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"LLM","type":"TECHNOLOGY","description":"A large language model (LLM) used to generate community summaries and global answers based on user queries.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"KEVIN SCOTT","type":"PERSON","description":"Kevin Scott is the CTO of Microsoft and a participant in the podcast conversations included in the podcast transcripts dataset.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"MICROSOFT","type":"ORGANIZATION","description":"Microsoft is the company where Kevin Scott serves as CTO, and it is mentioned in the context of the podcast transcripts dataset.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"TANG AND YANG","type":"REFERENCE","description":"A reference to a study by Tang and Yang (2024) on the MultiHop-RAG benchmark dataset.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"TECH LEADERS","type":"PERSON","description":"Tech leaders are participants in the podcast conversations included in the podcast transcripts dataset, discussing various technology-related topics.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"PRIVACY LAWS","type":"CONCEPT","description":"Privacy laws are regulations discussed by guests in the podcast transcripts dataset, focusing on their impact on technology development.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"INNOVATION","type":"CONCEPT","description":"Innovation is a topic discussed by guests in the podcast transcripts dataset, particularly in relation to ethical considerations.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"ETHICAL CONSIDERATIONS","type":"CONCEPT","description":"Ethical considerations are discussed by guests in the podcast transcripts dataset, especially in the context of balancing innovation and ethics.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"POLICY AND REGULATION","type":"CONCEPT","description":"Policy and regulation are topics discussed in the podcast transcripts dataset, focusing on their role in the tech industry.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"COLLABORATIONS","type":"CONCEPT","description":"Collaborations between tech companies and governments are discussed by guests in the podcast transcripts dataset.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"HEALTH EDUCATION","type":"CONCEPT","description":"Health education is a topic of interest for educators using news articles to teach about health and wellness.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"PREVENTIVE MEDICINE","type":"CONCEPT","description":"Preventive medicine is a concept addressed in news articles, relevant to health education curricula.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"WELLNESS","type":"CONCEPT","description":"Wellness is a concept addressed in news articles, relevant to health education curricula.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"PUBLIC HEALTH","type":"CONCEPT","description":"Public health priorities are insights gleaned from news coverage, relevant to health education.","source_id":"4930fce6da868f894757a9da465807ba"},{"name":"HEALTH LITERACY","type":"CONCEPT","description":"Health literacy is an important aspect highlighted by educators using news articles to teach about health and wellness.","source_id":"4930fce6da868f894757a9da465807ba"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"ROOT-LEVEL COMMUNITIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Root-level communities refer to the primary divisions within a hierarchical community structure, revealing internal structure within these communities.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"LEAF-LEVEL COMMUNITIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Leaf-level communities are the most granular divisions within a hierarchical community structure, where element summaries (nodes, edges, covariates) are prioritized and added to the LLM context window until the token limit is reached.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"HIGHER-LEVEL COMMUNITIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Higher-level communities are broader divisions within a hierarchical community structure, where sub-communities are ranked and summarized to fit within the context window if element summaries exceed the token limit.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"COMMUNITY SUMMARIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Community summaries are generated descriptions of elements within a community, used to create a final answer in a multi-stage process based on hierarchical community structure.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"GLOBAL ANSWER\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">The global answer is the final response generated from community summaries to answer a user query, ensuring a balance of summary detail and scope.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"USER QUERY\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A user query is a question posed by the user that the system aims to answer using community summaries and hierarchical community structure.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"PODCAST TRANSCRIPTS\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset comprising compiled transcripts of podcast conversations between Kevin Scott, Microsoft CTO, and other technology leaders, used for evaluation purposes.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"NEWS ARTICLES\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A benchmark dataset comprising news articles published from September 2013 to December 2023 in various categories, used for evaluation purposes.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"TECH JOURNALIST\">      <data key=\"d0\">USER<\/data>      <data key=\"d1\">A tech journalist is a potential user looking for insights and trends in the tech industry, particularly regarding the role of policy and regulation.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"EDUCATOR\">      <data key=\"d0\">USER<\/data>      <data key=\"d1\">An educator is a potential user incorporating current affairs into curricula, particularly focusing on health and wellness.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"MULTIHOP-RAG\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A benchmark dataset used for evaluating open-domain question answering systems, including news articles in various categories.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"HOTPOTQA\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A benchmark dataset for open-domain question answering, targeting explicit fact retrieval.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"MT-BENCH\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A benchmark dataset for open-domain question answering, targeting explicit fact retrieval.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"RAG SYSTEMS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Retrieval-Augmented Generation (RAG) systems are used for generating answers to questions by retrieving relevant information from large datasets.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"DATA SENSEMAKING\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Data sensemaking is the process through which people inspect, engage with, and contextualize data within the broader scope of real-world activities.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"KOESTEN ET AL.\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study by Koesten et al. (2021) on data sensemaking behaviors.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"XU AND LAPATA\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study by Xu and Lapata (2021) on methods for extracting latent summarization queries from source texts.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"LLM\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">A large language model (LLM) used to generate community summaries and global answers based on user queries.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"KEVIN SCOTT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kevin Scott is the CTO of Microsoft and a participant in the podcast conversations included in the podcast transcripts dataset.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"MICROSOFT\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Microsoft is the company where Kevin Scott serves as CTO, and it is mentioned in the context of the podcast transcripts dataset.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"TANG AND YANG\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study by Tang and Yang (2024) on the MultiHop-RAG benchmark dataset.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"TECH LEADERS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tech leaders are participants in the podcast conversations included in the podcast transcripts dataset, discussing various technology-related topics.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"PRIVACY LAWS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Privacy laws are regulations discussed by guests in the podcast transcripts dataset, focusing on their impact on technology development.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"INNOVATION\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Innovation is a topic discussed by guests in the podcast transcripts dataset, particularly in relation to ethical considerations.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"ETHICAL CONSIDERATIONS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Ethical considerations are discussed by guests in the podcast transcripts dataset, especially in the context of balancing innovation and ethics.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"POLICY AND REGULATION\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Policy and regulation are topics discussed in the podcast transcripts dataset, focusing on their role in the tech industry.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"COLLABORATIONS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Collaborations between tech companies and governments are discussed by guests in the podcast transcripts dataset.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"HEALTH EDUCATION\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Health education is a topic of interest for educators using news articles to teach about health and wellness.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"PREVENTIVE MEDICINE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Preventive medicine is a concept addressed in news articles, relevant to health education curricula.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"WELLNESS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Wellness is a concept addressed in news articles, relevant to health education curricula.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"PUBLIC HEALTH\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Public health priorities are insights gleaned from news coverage, relevant to health education.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <node id=\"HEALTH LITERACY\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Health literacy is an important aspect highlighted by educators using news articles to teach about health and wellness.<\/data>      <data key=\"d2\">4930fce6da868f894757a9da465807ba<\/data>    <\/node>    <edge source=\"ROOT-LEVEL COMMUNITIES\" target=\"LEAF-LEVEL COMMUNITIES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Leaf-level communities are subdivisions within root-level communities, focusing on more granular elements.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"ROOT-LEVEL COMMUNITIES\" target=\"HIGHER-LEVEL COMMUNITIES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Higher-level communities are broader divisions within root-level communities, summarizing sub-communities.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"LEAF-LEVEL COMMUNITIES\" target=\"COMMUNITY SUMMARIES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Community summaries are generated from the prioritized elements of leaf-level communities.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"HIGHER-LEVEL COMMUNITIES\" target=\"COMMUNITY SUMMARIES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Community summaries are generated from the ranked sub-communities of higher-level communities.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"GLOBAL ANSWER\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Community summaries are used to generate the global answer to a user query.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"LLM\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The LLM is used to generate community summaries based on the hierarchical community structure.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"GLOBAL ANSWER\" target=\"USER QUERY\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The global answer is generated in response to a user query.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"GLOBAL ANSWER\" target=\"LLM\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The LLM generates the global answer by processing community summaries and user queries.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"PODCAST TRANSCRIPTS\" target=\"TECH JOURNALIST\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">A tech journalist uses podcast transcripts to gain insights and trends in the tech industry.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"PODCAST TRANSCRIPTS\" target=\"KEVIN SCOTT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Kevin Scott is a participant in the podcast conversations included in the podcast transcripts dataset.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"PODCAST TRANSCRIPTS\" target=\"TECH LEADERS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Tech leaders are participants in the podcast conversations included in the podcast transcripts dataset.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"NEWS ARTICLES\" target=\"EDUCATOR\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">An educator uses news articles to teach about health and wellness.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"NEWS ARTICLES\" target=\"MULTIHOP-RAG\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">MultiHop-RAG includes news articles as part of its benchmark dataset.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"NEWS ARTICLES\" target=\"HEALTH EDUCATION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">News articles are used by educators to integrate current topics into health education curricula.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"NEWS ARTICLES\" target=\"PREVENTIVE MEDICINE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">News articles address the concept of preventive medicine, relevant to health education.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"NEWS ARTICLES\" target=\"WELLNESS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">News articles address the concept of wellness, relevant to health education.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"NEWS ARTICLES\" target=\"PUBLIC HEALTH\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">News articles provide insights into public health priorities, relevant to health education.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"NEWS ARTICLES\" target=\"HEALTH LITERACY\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">News articles highlight the importance of health literacy, relevant to health education.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"MULTIHOP-RAG\" target=\"TANG AND YANG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Tang and Yang (2024) conducted a study on the MultiHop-RAG benchmark dataset.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"RAG SYSTEMS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">HotPotQA is used to evaluate RAG systems for open-domain question answering.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"MT-BENCH\" target=\"RAG SYSTEMS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">MT-Bench is used to evaluate RAG systems for open-domain question answering.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"DATA SENSEMAKING\" target=\"KOESTEN ET AL.\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Koesten et al. (2021) studied data sensemaking behaviors.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"DATA SENSEMAKING\" target=\"XU AND LAPATA\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Xu and Lapata (2021) studied methods for extracting latent summarization queries, relevant to data sensemaking.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"KEVIN SCOTT\" target=\"MICROSOFT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Kevin Scott is the CTO of Microsoft.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"TECH LEADERS\" target=\"PRIVACY LAWS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Tech leaders discuss the impact of privacy laws on technology development in the podcast transcripts.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"TECH LEADERS\" target=\"POLICY AND REGULATION\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Tech leaders discuss the role of policy and regulation in the tech industry in the podcast transcripts.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"TECH LEADERS\" target=\"COLLABORATIONS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Tech leaders discuss collaborations between tech companies and governments in the podcast transcripts.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>    <edge source=\"INNOVATION\" target=\"ETHICAL CONSIDERATIONS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Innovation and ethical considerations are topics discussed together by guests in the podcast transcripts.<\/data>      <data key=\"d5\">4930fce6da868f894757a9da465807ba<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"26b2dad01a219bc034ac7d6a32d07582","chunk":" understanding of dataset contents, and not the details of specific texts.\nWe used an activity-centered approach to automate the generation of such questions: given a short\ndescription of a dataset, we asked the LLM to identify Npotential users and Ntasks per user,\nthen for each (user, task) combination, we asked the LLM to generate Nquestions that require\nunderstanding of the entire corpus. For our evaluation, a value of N= 5 resulted in 125 test questions\nper dataset. Table 1 shows example questions for each of the two evaluation datasets.\n63.3 Conditions\nWe compare six different conditions in our analysis, including Graph RAG using four levels of graph\ncommunities ( C0,C1,C2,C3), a text summarization method applying our map-reduce approach\ndirectly to source texts ( TS), and a na \u00a8\u0131ve \u201csemantic search\u201d RAG approach ( SS):\n\u2022CO. Uses root-level community summaries (fewest in number) to answer user queries.\n\u2022C1. Uses high-level community summaries to answer queries. These are sub-communities\nof C0, if present, otherwise C0 communities projected down.\n\u2022C2. Uses intermediate-level community summaries to answer queries. These are sub-\ncommunities of C1, if present, otherwise C1 communities projected down.\n\u2022C3. Uses low-level community summaries (greatest in number) to answer queries. These\nare sub-communities of C2, if present, otherwise C2 communities projected down.\n\u2022TS. The same method as in subsection 2.6, except source texts (rather than community\nsummaries) are shuffled and chunked for the map-reduce summarization stages.\n\u2022SS. An implementation of na \u00a8\u0131ve RAG in which text chunks are retrieved and added to the\navailable context window until the specified token limit is reached.\nThe size of the context window and the prompts used for answer generation are the same across\nall six conditions (except for minor modifications to reference styles to match the types of context\ninformation used). Conditions only differ in how the contents of the context window are created.\nThe graph index supporting conditions C0-C3was created using our generic prompts for entity and\nrelationship extraction only, with entity types and few-shot examples tailored to the domain of the\ndata. The graph indexing process used a context window size of 600 tokens with 1 gleaning for the\nPodcast dataset and 0 gleanings for the News dataset.\n3.4 Metrics\nLLMs have been shown to be good evaluators of natural language generation, achieving state-of-\nthe-art or competitive results compared against human judgements (Wang et al., 2023a; Zheng et al.,\n2024). While this approach can generate reference-based metrics when gold standard answers are\nknown, it is also capable of measuring the qualities of generated texts (e.g., fluency) in a reference-\nfree style (Wang et al., 2023a) as well as in head-to-head comparison of competing outputs (LLM-\nas-a-judge, Zheng et al., 2024). LLMs have also shown promise at evaluating the performance of\nconventional RAG systems, automatically evaluating qualities like context relevance, faithfulness,\nand answer relevance (RAGAS, Es et al., 2023).\nGiven the multi-stage nature of our Graph RAG mechanism, the multiple conditions we wanted to\ncompare, and the lack of gold standard answers to our activity-based sensemaking questions, we\ndecided to adopt a head-to-head comparison approach using an LLM evaluator. We selected three\ntarget metrics capturing qualities that are desirable for sensemaking activities, as well as a control\nmetric (directness) used as a indicator of validity. Since directness is effectively in opposition to\ncomprehensiveness and diversity, we would not expect any method to win across all four metrics.\nOur head-to-head measures computed using an LLM evaluator are as follows:\n\u2022Comprehensiveness . How much detail does the answer provide to cover all aspects and\ndetails of the question?\n\u2022Diversity . How varied and rich is the answer in providing different perspectives and insights\non the question?\n\u2022Empowerment . How well does the answer help the reader understand and make informed\njudgements about the topic?\n\u2022Directness . How specifically and clearly does the answer address the question?\nFor our evaluation, the LLM is provided with the question, target metric, and a pair of answers, and\nasked to assess which answer is better according to the metric, as well as why. It returns the winner\nif one exists, otherwise a tie if they are fundamentally similar and the differences are negligible.\nTo account for the stochasticity of LLMs, we run each comparison five times and use mean scores.\nTable 2 shows an example of LLM-generated assessment.\n7Question Which public figures are repeatedly mentioned across various entertainment articles?\nGraph\nRAGOverview of Prominent Public Figures in Entertainment\nThe entertainment industry is vast and diverse, encompassing film, television, music, sports, and\ndigital media. Certain public figures stand out due to their significant contributions and influence\nacross these sectors. The following summary highlights key individuals who are repeatedly\nmentioned in various entertainment articles, reflecting their impact and presence within the industry.\nActors and Directors [...]Public Figures in Controversy [...]Musicians and Executives [...]\nAthletes and Coaches [...]Influencers and Entrepreneurs [...]\nThe repeated mention of these figures in entertainment articles signifies their ongoing relevance and\nthe public\u2019s interest in their work. Their influence spans across various aspects of entertainment, from\nshaping cultural narratives in film and television to driving trends in music and digital media. These\nindividuals not only contribute to their respective fields but also influence the broader cultural","chunk_id":"26b2dad01a219bc034ac7d6a32d07582","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":1200,"entities":[{"name":"DATASET","type":"DATA\/RESOURCE","description":"A collection of data used for analysis and evaluation in the study","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"LLM","type":"MODEL\/TOOL","description":"Large Language Model used to generate questions and evaluate answers","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"GRAPH RAG","type":"METHOD\/TECHNIQUE","description":"A method using graph communities to answer user queries","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"TEXT SUMMARIZATION (TS)","type":"METHOD\/TECHNIQUE","description":"A method applying map-reduce approach directly to source texts for summarization","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"SEMANTIC SEARCH (SS)","type":"METHOD\/TECHNIQUE","description":"A naive RAG approach where text chunks are retrieved and added to the context window until the token limit is reached","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"CONTEXT WINDOW","type":"CONCEPT\/TECHNIQUE","description":"The size of the text window used for generating answers","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"PODCAST DATASET","type":"DATA\/RESOURCE","description":"A dataset used in the study, indexed with a context window size of 600 tokens and 1 gleaning","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"NEWS DATASET","type":"DATA\/RESOURCE","description":"A dataset used in the study, indexed with a context window size of 600 tokens and 0 gleanings","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"COMPREHENSIVENESS","type":"METRIC","description":"A metric evaluating how much detail an answer provides to cover all aspects and details of the question","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"DIVERSITY","type":"METRIC","description":"A metric evaluating how varied and rich an answer is in providing different perspectives and insights on the question","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"EMPOWERMENT","type":"METRIC","description":"A metric evaluating how well an answer helps the reader understand and make informed judgements about the topic","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"DIRECTNESS","type":"METRIC","description":"A control metric evaluating how specifically and clearly an answer addresses the question","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"LLM EVALUATOR","type":"MODEL\/TOOL","description":"A Large Language Model used to assess the quality of answers based on specific metrics","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"PUBLIC FIGURES","type":"CONCEPT","description":"Individuals repeatedly mentioned in various entertainment articles due to their significant contributions and influence","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"ACTIVITY-CENTERED APPROACH","type":"METHOD\/TECHNIQUE","description":"An approach used to automate the generation of questions based on a short description of a dataset","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"QUESTION GENERATION","type":"PROCESS","description":"The process of generating questions that require understanding of the entire corpus","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"EVALUATION","type":"PROCESS","description":"The process of assessing the quality and effectiveness of generated questions and answers","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"GRAPH COMMUNITIES","type":"CONCEPT","description":"Different levels of graph communities used in the Graph RAG method to answer user queries","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"C0","type":"CONCEPT","description":"Root-level community summaries used in Graph RAG to answer user queries","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"C1","type":"CONCEPT","description":"High-level community summaries used in Graph RAG to answer user queries","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"C2","type":"CONCEPT","description":"Intermediate-level community summaries used in Graph RAG to answer user queries","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"C3","type":"CONCEPT","description":"Low-level community summaries used in Graph RAG to answer user queries","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"MAP-REDUCE","type":"METHOD\/TECHNIQUE","description":"A method used in text summarization to shuffle and chunk source texts for summarization stages","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"RAG","type":"METHOD\/TECHNIQUE","description":"Retrieval-Augmented Generation, a method used to retrieve and add text chunks to the context window","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"ENTITY EXTRACTION","type":"PROCESS","description":"The process of extracting entities from text for graph indexing","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"RELATIONSHIP EXTRACTION","type":"PROCESS","description":"The process of extracting relationships between entities from text for graph indexing","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"TOKEN","type":"CONCEPT","description":"A unit of text used in the context window for generating answers","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"QUESTION","type":"CONCEPT","description":"A query provided to the LLM evaluator to assess the quality of answers","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"ANSWER","type":"CONCEPT","description":"A response generated by the LLM to address a given question","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"ASSESSMENT","type":"PROCESS","description":"The process of evaluating the quality of answers based on specific metrics","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"STOCHASTICITY","type":"CONCEPT","description":"The randomness in the behavior of LLMs during evaluation","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"MEAN SCORES","type":"CONCEPT","description":"The average scores used to account for the stochasticity of LLMs in evaluations","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"ENTERTAINMENT INDUSTRY","type":"CONCEPT","description":"A sector encompassing film, television, music, sports, and digital media","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"ACTORS AND DIRECTORS","type":"CONCEPT","description":"Public figures in the entertainment industry known for their roles in film and television","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"MUSICIANS AND EXECUTIVES","type":"CONCEPT","description":"Public figures in the entertainment industry known for their contributions to music and management","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"ATHLETES AND COACHES","type":"CONCEPT","description":"Public figures in the entertainment industry known for their roles in sports","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"INFLUENCERS AND ENTREPRENEURS","type":"CONCEPT","description":"Public figures in the entertainment industry known for their influence and business ventures","source_id":"26b2dad01a219bc034ac7d6a32d07582"},{"name":"GRAPH INDEXING","type":"","description":"","source_id":"26b2dad01a219bc034ac7d6a32d07582"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"DATASET\">      <data key=\"d0\">DATA\/RESOURCE<\/data>      <data key=\"d1\">A collection of data used for analysis and evaluation in the study<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"LLM\">      <data key=\"d0\">MODEL\/TOOL<\/data>      <data key=\"d1\">Large Language Model used to generate questions and evaluate answers<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"GRAPH RAG\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">A method using graph communities to answer user queries<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"TEXT SUMMARIZATION (TS)\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">A method applying map-reduce approach directly to source texts for summarization<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"SEMANTIC SEARCH (SS)\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">A naive RAG approach where text chunks are retrieved and added to the context window until the token limit is reached<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"CONTEXT WINDOW\">      <data key=\"d0\">CONCEPT\/TECHNIQUE<\/data>      <data key=\"d1\">The size of the text window used for generating answers<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"PODCAST DATASET\">      <data key=\"d0\">DATA\/RESOURCE<\/data>      <data key=\"d1\">A dataset used in the study, indexed with a context window size of 600 tokens and 1 gleaning<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"NEWS DATASET\">      <data key=\"d0\">DATA\/RESOURCE<\/data>      <data key=\"d1\">A dataset used in the study, indexed with a context window size of 600 tokens and 0 gleanings<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"COMPREHENSIVENESS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric evaluating how much detail an answer provides to cover all aspects and details of the question<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"DIVERSITY\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric evaluating how varied and rich an answer is in providing different perspectives and insights on the question<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"EMPOWERMENT\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric evaluating how well an answer helps the reader understand and make informed judgements about the topic<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"DIRECTNESS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A control metric evaluating how specifically and clearly an answer addresses the question<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"LLM EVALUATOR\">      <data key=\"d0\">MODEL\/TOOL<\/data>      <data key=\"d1\">A Large Language Model used to assess the quality of answers based on specific metrics<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"PUBLIC FIGURES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Individuals repeatedly mentioned in various entertainment articles due to their significant contributions and influence<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"ACTIVITY-CENTERED APPROACH\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">An approach used to automate the generation of questions based on a short description of a dataset<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"QUESTION GENERATION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The process of generating questions that require understanding of the entire corpus<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"EVALUATION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The process of assessing the quality and effectiveness of generated questions and answers<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"GRAPH COMMUNITIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Different levels of graph communities used in the Graph RAG method to answer user queries<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"C0\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Root-level community summaries used in Graph RAG to answer user queries<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"C1\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">High-level community summaries used in Graph RAG to answer user queries<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"C2\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Intermediate-level community summaries used in Graph RAG to answer user queries<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"C3\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Low-level community summaries used in Graph RAG to answer user queries<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"MAP-REDUCE\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">A method used in text summarization to shuffle and chunk source texts for summarization stages<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"RAG\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Retrieval-Augmented Generation, a method used to retrieve and add text chunks to the context window<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"ENTITY EXTRACTION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The process of extracting entities from text for graph indexing<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"RELATIONSHIP EXTRACTION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The process of extracting relationships between entities from text for graph indexing<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"TOKEN\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A unit of text used in the context window for generating answers<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"QUESTION\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A query provided to the LLM evaluator to assess the quality of answers<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"ANSWER\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A response generated by the LLM to address a given question<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"ASSESSMENT\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The process of evaluating the quality of answers based on specific metrics<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"STOCHASTICITY\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">The randomness in the behavior of LLMs during evaluation<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"MEAN SCORES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">The average scores used to account for the stochasticity of LLMs in evaluations<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"ENTERTAINMENT INDUSTRY\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A sector encompassing film, television, music, sports, and digital media<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"ACTORS AND DIRECTORS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Public figures in the entertainment industry known for their roles in film and television<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"MUSICIANS AND EXECUTIVES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Public figures in the entertainment industry known for their contributions to music and management<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"ATHLETES AND COACHES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Public figures in the entertainment industry known for their roles in sports<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"INFLUENCERS AND ENTREPRENEURS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Public figures in the entertainment industry known for their influence and business ventures<\/data>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <node id=\"GRAPH INDEXING\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/node>    <edge source=\"DATASET\" target=\"LLM\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The LLM generates questions based on the dataset<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"DATASET\" target=\"GRAPH RAG\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Graph RAG uses dataset summaries to answer user queries<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"DATASET\" target=\"TEXT SUMMARIZATION (TS)\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Text Summarization applies map-reduce approach to source texts in the dataset<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"DATASET\" target=\"SEMANTIC SEARCH (SS)\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Semantic Search retrieves text chunks from the dataset<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"CONTEXT WINDOW\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Graph RAG uses a context window to generate answers<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"PUBLIC FIGURES\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Graph RAG identifies public figures in entertainment articles<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"GRAPH COMMUNITIES\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Graph RAG uses different levels of graph communities to answer user queries<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"TEXT SUMMARIZATION (TS)\" target=\"CONTEXT WINDOW\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Text Summarization uses a context window to generate answers<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"TEXT SUMMARIZATION (TS)\" target=\"MAP-REDUCE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Map-Reduce is used in text summarization to shuffle and chunk source texts<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"SEMANTIC SEARCH (SS)\" target=\"CONTEXT WINDOW\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Semantic Search uses a context window to generate answers<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"SEMANTIC SEARCH (SS)\" target=\"RAG\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">RAG is used in the semantic search approach to retrieve and add text chunks<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"CONTEXT WINDOW\" target=\"PODCAST DATASET\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Podcast dataset is indexed with a context window size of 600 tokens<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"CONTEXT WINDOW\" target=\"NEWS DATASET\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">News dataset is indexed with a context window size of 600 tokens<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"CONTEXT WINDOW\" target=\"TOKEN\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Tokens are units of text used in the context window<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"COMPREHENSIVENESS\" target=\"LLM EVALUATOR\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">LLM Evaluator assesses answers based on comprehensiveness<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"DIVERSITY\" target=\"LLM EVALUATOR\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">LLM Evaluator assesses answers based on diversity<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"EMPOWERMENT\" target=\"LLM EVALUATOR\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">LLM Evaluator assesses answers based on empowerment<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"DIRECTNESS\" target=\"LLM EVALUATOR\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">LLM Evaluator assesses answers based on directness<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"LLM EVALUATOR\" target=\"QUESTION\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The LLM evaluator is provided with the question to assess the quality of answers<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"LLM EVALUATOR\" target=\"ANSWER\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The LLM evaluator assesses the quality of the answer<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"LLM EVALUATOR\" target=\"ASSESSMENT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The LLM evaluator performs the assessment of answers<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"LLM EVALUATOR\" target=\"STOCHASTICITY\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Stochasticity is accounted for in the LLM evaluator's assessments<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"PUBLIC FIGURES\" target=\"ENTERTAINMENT INDUSTRY\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Public figures are repeatedly mentioned in various entertainment articles<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"PUBLIC FIGURES\" target=\"ACTORS AND DIRECTORS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Actors and directors are public figures in the entertainment industry<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"PUBLIC FIGURES\" target=\"MUSICIANS AND EXECUTIVES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Musicians and executives are public figures in the entertainment industry<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"PUBLIC FIGURES\" target=\"ATHLETES AND COACHES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Athletes and coaches are public figures in the entertainment industry<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"PUBLIC FIGURES\" target=\"INFLUENCERS AND ENTREPRENEURS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Influencers and entrepreneurs are public figures in the entertainment industry<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"ACTIVITY-CENTERED APPROACH\" target=\"QUESTION GENERATION\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The activity-centered approach is used to automate the generation of questions<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"QUESTION GENERATION\" target=\"EVALUATION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The generated questions are evaluated for quality and effectiveness<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"GRAPH COMMUNITIES\" target=\"C0\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">C0 is the root-level community summaries in Graph RAG<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"GRAPH COMMUNITIES\" target=\"C1\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">C1 is the high-level community summaries in Graph RAG<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"GRAPH COMMUNITIES\" target=\"C2\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">C2 is the intermediate-level community summaries in Graph RAG<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"GRAPH COMMUNITIES\" target=\"C3\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">C3 is the low-level community summaries in Graph RAG<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"ENTITY EXTRACTION\" target=\"GRAPH INDEXING\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Entity extraction is used in the graph indexing process<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"RELATIONSHIP EXTRACTION\" target=\"GRAPH INDEXING\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Relationship extraction is used in the graph indexing process<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>    <edge source=\"STOCHASTICITY\" target=\"MEAN SCORES\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Mean scores are used to account for the stochasticity of LLMs<\/data>      <data key=\"d5\">26b2dad01a219bc034ac7d6a32d07582<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"c8e8019de153e439d6a79dcf209b943b","chunk":" Directors [...]Public Figures in Controversy [...]Musicians and Executives [...]\nAthletes and Coaches [...]Influencers and Entrepreneurs [...]\nThe repeated mention of these figures in entertainment articles signifies their ongoing relevance and\nthe public\u2019s interest in their work. Their influence spans across various aspects of entertainment, from\nshaping cultural narratives in film and television to driving trends in music and digital media. These\nindividuals not only contribute to their respective fields but also influence the broader cultural\nlandscape, often becoming central figures in social discussions and public discourse.\nNa\u00a8\u0131ve\nRAGPublic figures who are repeatedly mentioned across various entertainment articles include Taylor\nSwift, Travis Kelce, Britney Spears, and Justin Timberlake. These individuals have been highlighted\nfor various reasons, ranging from their professional achievements to their personal lives.\nTaylor Swift [...]Travis Kelce [...]Britney Spears [...]Justin Timberlake [...]\nThese figures are frequently covered due to their high-profile status and the public\u2019s interest in their\ncareers and personal lives. Their activities, whether in music, sports, or personal relationships, have\nsignificant cultural and economic impacts, as evidenced by the media coverage and public reactions.\nLLM\nDecisionComprehensiveness: Winner=1 (Graph RAG)\nAnswer 1 is better because it provides a more comprehensive and detailed list of public figures from a\nwider range of entertainment sectors, including film, television, music, sports, gaming, and digital\nmedia. It also includes specific examples of their contributions and the impact they have on their\nrespective fields, as well as mentions of controversies and their implications. Answer 2, while\ndetailed in its coverage of a few individuals, is limited to a smaller number of public figures and\nfocuses primarily on their personal lives and relationships rather than a broad spectrum of their\nprofessional influence across the entertainment industry.\nDiversity: Winner=1 (Graph RAG)\nAnswer 1 is better because it provides a more varied and rich response by covering a wide range of\npublic figures from different sectors of the entertainment industry, including film, television, music,\nsports, gaming, and digital media. It offers insights into the contributions and influence of these\nfigures, as well as controversies and their impact on public discourse. The answer also cites specific\ndata sources for each mentioned figure, indicating a diverse range of evidence to support the claims.\nIn contrast, Answer 2 focuses on a smaller group of public figures, primarily from the music industry\nand sports, and relies heavily on a single source for data, which makes it less diverse in perspectives\nand insights.\nEmpowerment: Winner=1 (Graph RAG)\nAnswer 1 is better because it provides a comprehensive and structured overview of public figures\nacross various sectors of the entertainment industry, including film, television, music, sports, and\ndigital media. It lists multiple individuals, providing specific examples of their contributions and the\ncontext in which they are mentioned in entertainment articles, along with references to data reports\nfor each claim. This approach helps the reader understand the breadth of the topic and make informed\njudgments without being misled. In contrast, Answer 2 focuses on a smaller group of public figures\nand primarily discusses their personal lives and relationships, which may not provide as broad an\nunderstanding of the topic. While Answer 2 also cites sources, it does not match the depth and variety\nof Answer 1.\nDirectness: Winner=2 (Na \u00a8\u0131ve RAG)\nAnswer 2 is better because it directly lists specific public figures who are repeatedly mentioned\nacross various entertainment articles, such as Taylor Swift, Travis Kelce, Britney Spears, and Justin\nTimberlake, and provides concise explanations for their frequent mentions. Answer 1, while\ncomprehensive, includes a lot of detailed information about various figures in different sectors of\nentertainment, which, while informative, does not directly answer the question with the same level of\nconciseness and specificity as Answer 2.\nTable 2: Example question for the News article dataset, with generated answers from Graph RAG\n(C2) and Na \u00a8\u0131ve RAG, as well as LLM-generated assessments.\n8Podcast transcripts\n501728252221\n835050484344\n725050535049\n755247505250\n785750485052\n795651504850SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nComprehensiveness501823251919\n825050504346\n775050504644\n755050504445\n815754565048\n815456555250SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nDiversity504257524951\n585059555251\n434150494748\n484551504950\n514853515051\n494952504950SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nEmpowerment505665606060\n445055525152\n354550474848\n404853505050\n404952505050\n404852505050SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nDirectness\nNews articles\n502028252121\n805044413836\n725650525452\n755948505855\n796246425059\n796448454150SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nComprehensiveness503338352931\n675053454440\n624750404141\n655560505050\n715659505051\n696059504950SS\nTS\nC0\nC1\nC","chunk_id":"c8e8019de153e439d6a79dcf209b943b","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":1200,"entities":[{"name":"DIRECTORS","type":"PROFESSION","description":"Individuals involved in directing films, television shows, or other media productions","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"PUBLIC FIGURES IN CONTROVERSY","type":"CATEGORY","description":"Individuals who are frequently mentioned in the media due to their involvement in controversies","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"MUSICIANS","type":"PROFESSION","description":"Individuals who create, perform, or produce music","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"EXECUTIVES","type":"PROFESSION","description":"Individuals in high-level management positions within organizations, particularly in the entertainment industry","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"ATHLETES","type":"PROFESSION","description":"Individuals who compete in sports at a professional level","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"COACHES","type":"PROFESSION","description":"Individuals who train and guide athletes or sports teams","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"INFLUENCERS","type":"PROFESSION","description":"Individuals who have the power to affect the purchasing decisions of others because of their authority, knowledge, position, or relationship with their audience","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"ENTREPRENEURS","type":"PROFESSION","description":"Individuals who start and run businesses, often within the entertainment and digital media sectors","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"TAYLOR SWIFT","type":"PERSON","description":"A musician and public figure frequently mentioned in entertainment articles for her professional achievements and personal life","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"TRAVIS KELCE","type":"PERSON","description":"An athlete and public figure frequently mentioned in entertainment articles for his professional achievements and personal life","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"BRITNEY SPEARS","type":"PERSON","description":"A musician and public figure frequently mentioned in entertainment articles for her professional achievements and personal life","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"JUSTIN TIMBERLAKE","type":"PERSON","description":"A musician and public figure frequently mentioned in entertainment articles for his professional achievements and personal life","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"GRAPH RAG","type":"TOOL\/PROCESS","description":"A method used to generate comprehensive and detailed lists of public figures from various entertainment sectors","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"NA\u00cfVE RAG","type":"TOOL\/PROCESS","description":"A method used to generate lists of public figures, focusing on a smaller number of individuals and their personal lives","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"LLM","type":"TOOL\/PROCESS","description":"A language model used to assess the comprehensiveness, diversity, empowerment, and directness of generated answers","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"ENTERTAINMENT ARTICLES","type":"PUBLICATION","description":"Articles that cover various aspects of the entertainment industry, including news about public figures, trends, and cultural narratives","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"CULTURAL NARRATIVES","type":"CATEGORY","description":"Stories and themes that shape and reflect the values, beliefs, and experiences of a culture, often influenced by public figures in entertainment","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"FILM","type":"CATEGORY","description":"A sector of the entertainment industry focused on the production and distribution of movies","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"TELEVISION","type":"CATEGORY","description":"A sector of the entertainment industry focused on the production and distribution of TV shows","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"MUSIC","type":"CATEGORY","description":"A sector of the entertainment industry focused on the creation, performance, and distribution of music","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"DIGITAL MEDIA","type":"CATEGORY","description":"A sector of the entertainment industry that includes online content, social media, and other digital platforms","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"SPORTS","type":"CATEGORY","description":"A sector of the entertainment industry focused on athletic competitions and events","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"GAMING","type":"CATEGORY","description":"A sector of the entertainment industry focused on video games and interactive entertainment","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"SOCIAL DISCUSSIONS","type":"CATEGORY","description":"Public conversations and debates often influenced by the actions and statements of public figures","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"PUBLIC DISCOURSE","type":"CATEGORY","description":"The exchange of ideas and opinions in the public sphere, often shaped by media coverage and public figures","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"MEDIA COVERAGE","type":"CATEGORY","description":"The reporting and analysis of events, trends, and public figures by various media outlets","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"PROFESSIONAL ACHIEVEMENTS","type":"CATEGORY","description":"Notable accomplishments in one's career, often highlighted in media coverage of public figures","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"PERSONAL LIVES","type":"CATEGORY","description":"Aspects of public figures' private lives that are often covered by the media and of interest to the public","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"CULTURAL IMPACT","type":"CATEGORY","description":"The influence that public figures and their activities have on culture and society","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"ECONOMIC IMPACT","type":"CATEGORY","description":"The financial effects that public figures and their activities have on the economy","source_id":"c8e8019de153e439d6a79dcf209b943b"},{"name":"MEDIA REACTIONS","type":"CATEGORY","description":"The responses and opinions expressed by media outlets regarding public figures and their activities","source_id":"c8e8019de153e439d6a79dcf209b943b"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"DIRECTORS\">      <data key=\"d0\">PROFESSION<\/data>      <data key=\"d1\">Individuals involved in directing films, television shows, or other media productions<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"PUBLIC FIGURES IN CONTROVERSY\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">Individuals who are frequently mentioned in the media due to their involvement in controversies<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"MUSICIANS\">      <data key=\"d0\">PROFESSION<\/data>      <data key=\"d1\">Individuals who create, perform, or produce music<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"EXECUTIVES\">      <data key=\"d0\">PROFESSION<\/data>      <data key=\"d1\">Individuals in high-level management positions within organizations, particularly in the entertainment industry<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"ATHLETES\">      <data key=\"d0\">PROFESSION<\/data>      <data key=\"d1\">Individuals who compete in sports at a professional level<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"COACHES\">      <data key=\"d0\">PROFESSION<\/data>      <data key=\"d1\">Individuals who train and guide athletes or sports teams<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"INFLUENCERS\">      <data key=\"d0\">PROFESSION<\/data>      <data key=\"d1\">Individuals who have the power to affect the purchasing decisions of others because of their authority, knowledge, position, or relationship with their audience<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"ENTREPRENEURS\">      <data key=\"d0\">PROFESSION<\/data>      <data key=\"d1\">Individuals who start and run businesses, often within the entertainment and digital media sectors<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"TAYLOR SWIFT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A musician and public figure frequently mentioned in entertainment articles for her professional achievements and personal life<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"TRAVIS KELCE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An athlete and public figure frequently mentioned in entertainment articles for his professional achievements and personal life<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"BRITNEY SPEARS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A musician and public figure frequently mentioned in entertainment articles for her professional achievements and personal life<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"JUSTIN TIMBERLAKE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A musician and public figure frequently mentioned in entertainment articles for his professional achievements and personal life<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"GRAPH RAG\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">A method used to generate comprehensive and detailed lists of public figures from various entertainment sectors<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"NA&#207;VE RAG\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">A method used to generate lists of public figures, focusing on a smaller number of individuals and their personal lives<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"LLM\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">A language model used to assess the comprehensiveness, diversity, empowerment, and directness of generated answers<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"ENTERTAINMENT ARTICLES\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Articles that cover various aspects of the entertainment industry, including news about public figures, trends, and cultural narratives<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"CULTURAL NARRATIVES\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">Stories and themes that shape and reflect the values, beliefs, and experiences of a culture, often influenced by public figures in entertainment<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"FILM\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A sector of the entertainment industry focused on the production and distribution of movies<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"TELEVISION\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A sector of the entertainment industry focused on the production and distribution of TV shows<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"MUSIC\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A sector of the entertainment industry focused on the creation, performance, and distribution of music<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"DIGITAL MEDIA\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A sector of the entertainment industry that includes online content, social media, and other digital platforms<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"SPORTS\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A sector of the entertainment industry focused on athletic competitions and events<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"GAMING\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">A sector of the entertainment industry focused on video games and interactive entertainment<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"SOCIAL DISCUSSIONS\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">Public conversations and debates often influenced by the actions and statements of public figures<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"PUBLIC DISCOURSE\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">The exchange of ideas and opinions in the public sphere, often shaped by media coverage and public figures<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"MEDIA COVERAGE\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">The reporting and analysis of events, trends, and public figures by various media outlets<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"PROFESSIONAL ACHIEVEMENTS\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">Notable accomplishments in one's career, often highlighted in media coverage of public figures<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"PERSONAL LIVES\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">Aspects of public figures' private lives that are often covered by the media and of interest to the public<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"CULTURAL IMPACT\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">The influence that public figures and their activities have on culture and society<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"ECONOMIC IMPACT\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">The financial effects that public figures and their activities have on the economy<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <node id=\"MEDIA REACTIONS\">      <data key=\"d0\">CATEGORY<\/data>      <data key=\"d1\">The responses and opinions expressed by media outlets regarding public figures and their activities<\/data>      <data key=\"d2\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/node>    <edge source=\"PUBLIC FIGURES IN CONTROVERSY\" target=\"TAYLOR SWIFT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Taylor Swift is frequently mentioned in the media due to her high-profile status and public interest in her career and personal life<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"PUBLIC FIGURES IN CONTROVERSY\" target=\"TRAVIS KELCE\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Travis Kelce is frequently mentioned in the media due to his high-profile status and public interest in his career and personal life<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"PUBLIC FIGURES IN CONTROVERSY\" target=\"BRITNEY SPEARS\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Britney Spears is frequently mentioned in the media due to her high-profile status and public interest in her career and personal life<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"PUBLIC FIGURES IN CONTROVERSY\" target=\"JUSTIN TIMBERLAKE\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Justin Timberlake is frequently mentioned in the media due to his high-profile status and public interest in his career and personal life<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"PUBLIC FIGURES IN CONTROVERSY\" target=\"ENTERTAINMENT ARTICLES\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Entertainment articles frequently mention public figures involved in controversies<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"PUBLIC FIGURES IN CONTROVERSY\" target=\"MEDIA COVERAGE\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Public figures in controversy receive significant media coverage<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"PUBLIC FIGURES IN CONTROVERSY\" target=\"GRAPH RAG\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Graph RAG includes public figures involved in controversies<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"PUBLIC FIGURES IN CONTROVERSY\" target=\"NA&#207;VE RAG\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Na&#239;ve RAG includes public figures involved in controversies<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"MUSICIANS\" target=\"TAYLOR SWIFT\">      <data key=\"d3\">10.0<\/data>      <data key=\"d4\">Taylor Swift is a musician<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"MUSICIANS\" target=\"BRITNEY SPEARS\">      <data key=\"d3\">10.0<\/data>      <data key=\"d4\">Britney Spears is a musician<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"MUSICIANS\" target=\"JUSTIN TIMBERLAKE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Justin Timberlake is a musician<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"ATHLETES\" target=\"TRAVIS KELCE\">      <data key=\"d3\">10.0<\/data>      <data key=\"d4\">Travis Kelce is an athlete<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"TAYLOR SWIFT\" target=\"ENTERTAINMENT ARTICLES\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Taylor Swift is frequently mentioned in entertainment articles<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"TAYLOR SWIFT\" target=\"MEDIA COVERAGE\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Taylor Swift receives significant media coverage<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"TAYLOR SWIFT\" target=\"PROFESSIONAL ACHIEVEMENTS\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Taylor Swift is highlighted for her professional achievements<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"TAYLOR SWIFT\" target=\"PERSONAL LIVES\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Taylor Swift's personal life is of public interest<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"TAYLOR SWIFT\" target=\"CULTURAL IMPACT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Taylor Swift has a significant cultural impact<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"TAYLOR SWIFT\" target=\"ECONOMIC IMPACT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Taylor Swift has a significant economic impact<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"TAYLOR SWIFT\" target=\"MEDIA REACTIONS\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Taylor Swift's activities generate media reactions<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"TAYLOR SWIFT\" target=\"GRAPH RAG\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Graph RAG mentions Taylor Swift<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"TAYLOR SWIFT\" target=\"NA&#207;VE RAG\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Na&#239;ve RAG mentions Taylor Swift<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"TRAVIS KELCE\" target=\"ENTERTAINMENT ARTICLES\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Travis Kelce is frequently mentioned in entertainment articles<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"TRAVIS KELCE\" target=\"MEDIA COVERAGE\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Travis Kelce receives significant media coverage<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"TRAVIS KELCE\" target=\"PROFESSIONAL ACHIEVEMENTS\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Travis Kelce is highlighted for his professional achievements<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"TRAVIS KELCE\" target=\"PERSONAL LIVES\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Travis Kelce's personal life is of public interest<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"TRAVIS KELCE\" target=\"CULTURAL IMPACT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Travis Kelce has a significant cultural impact<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"TRAVIS KELCE\" target=\"ECONOMIC IMPACT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Travis Kelce has a significant economic impact<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"TRAVIS KELCE\" target=\"MEDIA REACTIONS\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Travis Kelce's activities generate media reactions<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"TRAVIS KELCE\" target=\"GRAPH RAG\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Graph RAG mentions Travis Kelce<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"TRAVIS KELCE\" target=\"NA&#207;VE RAG\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Na&#239;ve RAG mentions Travis Kelce<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"BRITNEY SPEARS\" target=\"ENTERTAINMENT ARTICLES\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Britney Spears is frequently mentioned in entertainment articles<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"BRITNEY SPEARS\" target=\"MEDIA COVERAGE\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Britney Spears receives significant media coverage<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"BRITNEY SPEARS\" target=\"PROFESSIONAL ACHIEVEMENTS\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Britney Spears is highlighted for her professional achievements<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"BRITNEY SPEARS\" target=\"PERSONAL LIVES\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Britney Spears's personal life is of public interest<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"BRITNEY SPEARS\" target=\"CULTURAL IMPACT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Britney Spears has a significant cultural impact<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"BRITNEY SPEARS\" target=\"ECONOMIC IMPACT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Britney Spears has a significant economic impact<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"BRITNEY SPEARS\" target=\"MEDIA REACTIONS\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Britney Spears's activities generate media reactions<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"BRITNEY SPEARS\" target=\"GRAPH RAG\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Graph RAG mentions Britney Spears<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"BRITNEY SPEARS\" target=\"NA&#207;VE RAG\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Na&#239;ve RAG mentions Britney Spears<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"JUSTIN TIMBERLAKE\" target=\"ENTERTAINMENT ARTICLES\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Justin Timberlake is frequently mentioned in entertainment articles<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"JUSTIN TIMBERLAKE\" target=\"MEDIA COVERAGE\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Justin Timberlake receives significant media coverage<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"JUSTIN TIMBERLAKE\" target=\"PROFESSIONAL ACHIEVEMENTS\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Justin Timberlake is highlighted for his professional achievements<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"JUSTIN TIMBERLAKE\" target=\"PERSONAL LIVES\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Justin Timberlake's personal life is of public interest<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"JUSTIN TIMBERLAKE\" target=\"CULTURAL IMPACT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Justin Timberlake has a significant cultural impact<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"JUSTIN TIMBERLAKE\" target=\"ECONOMIC IMPACT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Justin Timberlake has a significant economic impact<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"JUSTIN TIMBERLAKE\" target=\"MEDIA REACTIONS\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Justin Timberlake's activities generate media reactions<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"JUSTIN TIMBERLAKE\" target=\"GRAPH RAG\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Graph RAG mentions Justin Timberlake<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"JUSTIN TIMBERLAKE\" target=\"NA&#207;VE RAG\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Na&#239;ve RAG mentions Justin Timberlake<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"LLM\">      <data key=\"d3\">16.0<\/data>      <data key=\"d4\">LLM assesses Graph RAGGraph RAG is assessed by the LLM for its comprehensiveness, diversity, empowerment, and directness<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"ENTERTAINMENT ARTICLES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Graph RAG provides a comprehensive list of public figures mentioned in entertainment articles<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"NA&#207;VE RAG\" target=\"LLM\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Na&#239;ve RAG is assessed by the LLM for its comprehensiveness, diversity, empowerment, and directnessLLM assesses Na&#239;ve RAG<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>    <edge source=\"NA&#207;VE RAG\" target=\"ENTERTAINMENT ARTICLES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Na&#239;ve RAG provides a list of public figures mentioned in entertainment articles<\/data>      <data key=\"d5\">c8e8019de153e439d6a79dcf209b943b<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"ede7063998065122cf7a7152979c1909","chunk":"\n502028252121\n805044413836\n725650525452\n755948505855\n796246425059\n796448454150SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nComprehensiveness503338352931\n675053454440\n624750404141\n655560505050\n715659505051\n696059504950SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nDiversity504757495050\n535058505048\n434250424544\n515058505251\n505055485050\n505256495050SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nEmpowerment505459555554\n465055535252\n414550484847\n454752504949\n454852515049\n464853515150SS\nTS\nC0\nC1\nC2\nC3SSTSC0C1C2C3\nDirectness\nFigure 4: Head-to-head win rate percentages of (row condition) over (column condition) across two\ndatasets, four metrics, and 125 questions per comparison (each repeated five times and averaged).\nThe overall winner per dataset and metric is shown in bold. Self-win rates were not computed but\nare shown as the expected 50% for reference. All Graph RAG conditions outperformed na \u00a8\u0131ve RAG\non comprehensiveness and diversity. Conditions C1-C3 also showed slight improvements in answer\ncomprehensiveness and diversity over TS (global text summarization without a graph index).\n3.5 Configuration\nThe effect of context window size on any particular task is unclear, especially for models like\ngpt-4-turbo with a large context size of 128k tokens. Given the potential for information to\nbe \u201clost in the middle\u201d of longer contexts (Kuratov et al., 2024; Liu et al., 2023), we wanted to ex-\nplore the effects of varying the context window size for our combinations of datasets, questions, and\nmetrics. In particular, our goal was to determine the optimum context size for our baseline condition\n(SS) and then use this uniformly for all query-time LLM use. To that end, we tested four context\nwindow sizes: 8k, 16k, 32k and 64k. Surprisingly, the smallest context window size tested (8k)\nwas universally better for all comparisons on comprehensiveness (average win rate of 58.1%), while\nperforming comparably with larger context sizes on diversity (average win rate = 52.4%), and em-\npowerment (average win rate = 51.3%). Given our preference for more comprehensive and diverse\nanswers, we therefore used a fixed context window size of 8k tokens for the final evaluation.\n3.6 Results\nThe indexing process resulted in a graph consisting of 8564 nodes and 20691 edges for the Podcast\ndataset, and a larger graph of 15754 nodes and 19520 edges for the News dataset. Table 3 shows the\nnumber of community summaries at different levels of each graph community hierarchy.\nGlobal approaches vs. na \u00a8\u0131ve RAG . As shown in Figure 4, global approaches consistently out-\nperformed the na \u00a8\u0131ve RAG ( SS) approach in both comprehensiveness and diversity metrics across\ndatasets. Specifically, global approaches achieved comprehensiveness win rates between 72-83%\nfor Podcast transcripts and 72-80% for News articles, while diversity win rates ranged from 75-82%\nand 62-71% respectively. Our use of directness as a validity test also achieved the expected results,\ni.e., that na \u00a8\u0131ve RAG produces the most direct responses across all comparisons.\n9Podcast Transcripts News Articles\nC0 C1 C2 C3 TS C0 C1 C2 C3 TS\nUnits 34 367 969 1310 1669 55 555 1797 2142 3197\nTokens 26657 225756 565720 746100 1014611 39770 352641 980898 1140266 1707694\n% Max 2.6 22.2 55.8 73.5 100 2.3 20.7 57.4 66.8 100\nTable 3: Number of context units (community summaries for C0-C3 and text chunks for TS), corre-\nsponding token counts, and percentage of the maximum token count. Map-reduce summarization of\nsource texts is the most resource-intensive approach requiring the highest number of context tokens.\nRoot-level community summaries ( C0) require dramatically fewer tokens per query (9x-43x).\nCommunity summaries vs. source texts. When comparing community summaries to source texts\nusing Graph RAG, community summaries generally provided a small but consistent improvement\nin answer comprehensiveness and diversity, except for root-level summaries. Intermediate-level\nsummaries in the Podcast dataset and low-level community summaries in the News dataset achieved\ncomprehensiveness win rates of 57% and 64%, respectively. Diversity win rates were 57% for\nPodcast intermediate-level summaries and 60% for News low-level community summaries. Table 3\nalso illustrates the scalability advantages of Graph RAG compared to source text summarization: for\nlow-level community summaries ( C3), Graph RAG required 26-33% fewer context tokens, while\nfor root-level community summaries ( C0), it required over 97% fewer tokens.","chunk_id":"ede7063998065122cf7a7152979c1909","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":1200,"entities":[{"name":"NAIVE RAG","type":"METHOD\/TECHNIQUE","description":"Naive RAG is a baseline approach for summarizing and indexing data, which is outperformed by global approaches in comprehensiveness and diversity","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"PODCAST DATASET","type":"DATASET","description":"The Podcast dataset consists of 8564 nodes and 20691 edges, used for evaluating summarization techniques","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"NEWS DATASET","type":"DATASET","description":"The News dataset consists of 15754 nodes and 19520 edges, used for evaluating summarization techniques","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"COMPREHENSIVENESS","type":"METRIC","description":"Comprehensiveness is a metric used to evaluate the completeness of answers in summarization tasks","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"DIVERSITY","type":"METRIC","description":"Diversity is a metric used to evaluate the variety of answers in summarization tasks","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"EMPOWERMENT","type":"METRIC","description":"Empowerment is a metric used to evaluate the effectiveness of answers in summarization tasks","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"DIRECTNESS","type":"METRIC","description":"Directness is a metric used to evaluate the straightforwardness of answers in summarization tasks","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"CONTEXT WINDOW SIZE","type":"PARAMETER","description":"Context window size refers to the number of tokens used in the context for language model tasks, tested at 8k, 16k, 32k, and 64k sizes","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"GPT-4-TURBO","type":"MODEL","description":"GPT-4-Turbo is a language model with a large context size of 128k tokens, used in the evaluation of context window sizes","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"KURATOV ET AL., 2024","type":"REFERENCE","description":"A reference to a study by Kuratov et al. in 2024, discussing the potential for information to be lost in the middle of longer contexts","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"LIU ET AL., 2023","type":"REFERENCE","description":"A reference to a study by Liu et al. in 2023, discussing the potential for information to be lost in the middle of longer contexts","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"COMMUNITY SUMMARIES","type":"OUTPUT","description":"Community summaries are summaries generated at different levels of a graph community hierarchy, used in the Graph RAG method","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"SOURCE TEXTS","type":"INPUT","description":"Source texts are the original texts used for summarization in the Graph RAG method","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"C0","type":"CONDITION","description":"C0 is a condition representing root-level community summaries in the Graph RAG method","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"C1","type":"CONDITION","description":"C1 is a condition representing intermediate-level community summaries in the Graph RAG method","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"C2","type":"CONDITION","description":"C2 is a condition representing intermediate-level community summaries in the Graph RAG method","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"C3","type":"CONDITION","description":"C3 is a condition representing low-level community summaries in the Graph RAG method","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"TS","type":"CONDITION","description":"TS is a condition representing global text summarization without a graph index in the Graph RAG method","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"GRAPH RAG","type":"","description":"","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"GPT-4","type":"MODEL","description":"GPT-4 is a version of OpenAI's language model used to evaluate InfoBench","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"HALLUCINATION JUDGE","type":"TOOL\/PROCESS","description":"A process where a judge determines if there is any hallucination in a generated summary","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"KOESTEN, L.","type":"PERSON","description":"Koesten, L. is an author of the paper \"Talking datasets\u2013understanding data sensemaking behaviours\"","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"GREGORY, K.","type":"PERSON","description":"Gregory, K. is an author of the paper \"Talking datasets\u2013understanding data sensemaking behaviours\"","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"GROTH, P.","type":"PERSON","description":"Groth, P. is an author of the paper \"Talking datasets\u2013understanding data sensemaking behaviours\"","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"SIMPERL, E.","type":"PERSON","description":"Simperl, E. is an author of the paper \"Talking datasets\u2013understanding data sensemaking behaviours\"","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES","type":"PUBLICATION","description":"The journal where the paper \"Talking datasets\u2013understanding data sensemaking behaviours\" was published","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"KURATOV, Y.","type":"PERSON","description":"Kuratov, Y. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"BULATOV, A.","type":"PERSON","description":"Bulatov, A. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"ANOKHIN, P.","type":"PERSON","description":"Anokhin, P. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"SOROKIN, D.","type":"PERSON","description":"Sorokin, D. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"SOROKIN, A.","type":"PERSON","description":"Sorokin, A. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"BURTSEV, M.","type":"PERSON","description":"Burtsev, M. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"LANGCHAIN","type":"ORGANIZATION","description":"LangChain is the organization behind the LangChain graphs project","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"LASKAR, M. T. R.","type":"PERSON","description":"Laskar, M. T. R. is an author of the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"HOQUE, E.","type":"PERSON","description":"Hoque, E. is an author of the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"HUANG, J.","type":"PERSON","description":"Huang, J. is an author of the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"","source_id":"ede7063998065122cf7a7152979c1909"},{"name":"ADVANCES IN ARTIFICIAL INTELLIGENCE","type":"PUBLICATION","description":"The conference where the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\" was presented","source_id":"ede7063998065122cf7a7152979c1909"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"NAIVE RAG\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Naive RAG is a baseline approach for summarizing and indexing data, which is outperformed by global approaches in comprehensiveness and diversity<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"PODCAST DATASET\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">The Podcast dataset consists of 8564 nodes and 20691 edges, used for evaluating summarization techniques<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"NEWS DATASET\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">The News dataset consists of 15754 nodes and 19520 edges, used for evaluating summarization techniques<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"COMPREHENSIVENESS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Comprehensiveness is a metric used to evaluate the completeness of answers in summarization tasks<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"DIVERSITY\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Diversity is a metric used to evaluate the variety of answers in summarization tasks<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"EMPOWERMENT\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Empowerment is a metric used to evaluate the effectiveness of answers in summarization tasks<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"DIRECTNESS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Directness is a metric used to evaluate the straightforwardness of answers in summarization tasks<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"CONTEXT WINDOW SIZE\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Context window size refers to the number of tokens used in the context for language model tasks, tested at 8k, 16k, 32k, and 64k sizes<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"GPT-4-TURBO\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4-Turbo is a language model with a large context size of 128k tokens, used in the evaluation of context window sizes<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"KURATOV ET AL., 2024\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study by Kuratov et al. in 2024, discussing the potential for information to be lost in the middle of longer contexts<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"LIU ET AL., 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study by Liu et al. in 2023, discussing the potential for information to be lost in the middle of longer contexts<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"COMMUNITY SUMMARIES\">      <data key=\"d0\">OUTPUT<\/data>      <data key=\"d1\">Community summaries are summaries generated at different levels of a graph community hierarchy, used in the Graph RAG method<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"SOURCE TEXTS\">      <data key=\"d0\">INPUT<\/data>      <data key=\"d1\">Source texts are the original texts used for summarization in the Graph RAG method<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"C0\">      <data key=\"d0\">CONDITION<\/data>      <data key=\"d1\">C0 is a condition representing root-level community summaries in the Graph RAG method<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"C1\">      <data key=\"d0\">CONDITION<\/data>      <data key=\"d1\">C1 is a condition representing intermediate-level community summaries in the Graph RAG method<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"C2\">      <data key=\"d0\">CONDITION<\/data>      <data key=\"d1\">C2 is a condition representing intermediate-level community summaries in the Graph RAG method<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"C3\">      <data key=\"d0\">CONDITION<\/data>      <data key=\"d1\">C3 is a condition representing low-level community summaries in the Graph RAG method<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"TS\">      <data key=\"d0\">CONDITION<\/data>      <data key=\"d1\">TS is a condition representing global text summarization without a graph index in the Graph RAG method<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"GRAPH RAG\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4 is a version of OpenAI's language model used to evaluate InfoBench<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"HALLUCINATION JUDGE\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">A process where a judge determines if there is any hallucination in a generated summary<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"KOESTEN, L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Koesten, L. is an author of the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"GREGORY, K.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gregory, K. is an author of the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"GROTH, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Groth, P. is an author of the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"SIMPERL, E.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Simperl, E. is an author of the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The journal where the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\" was published<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"KURATOV, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kuratov, Y. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"BULATOV, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bulatov, A. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"ANOKHIN, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Anokhin, P. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"SOROKIN, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sorokin, D. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"SOROKIN, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sorokin, A. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"BURTSEV, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Burtsev, M. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"LANGCHAIN\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">LangChain is the organization behind the LangChain graphs project<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"LASKAR, M. T. R.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Laskar, M. T. R. is an author of the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"HOQUE, E.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hoque, E. is an author of the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"HUANG, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Huang, J. is an author of the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <node id=\"ADVANCES IN ARTIFICIAL INTELLIGENCE\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The conference where the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\" was presented<\/data>      <data key=\"d2\">ede7063998065122cf7a7152979c1909<\/data>    <\/node>    <edge source=\"NAIVE RAG\" target=\"DIRECTNESS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Naive RAG produces the most direct responses<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"PODCAST DATASET\" target=\"GRAPH RAG\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Podcast dataset is used to evaluate the performance of the Graph RAG method<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"NEWS DATASET\" target=\"GRAPH RAG\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The News dataset is used to evaluate the performance of the Graph RAG method<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"COMPREHENSIVENESS\" target=\"GRAPH RAG\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Graph RAG achieves high comprehensiveness win rates<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"DIVERSITY\" target=\"GRAPH RAG\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Graph RAG achieves high diversity win rates<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"EMPOWERMENT\" target=\"GRAPH RAG\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Graph RAG performs comparably on empowerment<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"CONTEXT WINDOW SIZE\" target=\"GPT-4-TURBO\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Context window size is tested on GPT-4-Turbo<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"CONTEXT WINDOW SIZE\" target=\"KURATOV ET AL., 2024\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Kuratov et al. discuss the potential for information to be lost in the middle of longer contexts<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"CONTEXT WINDOW SIZE\" target=\"LIU ET AL., 2023\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Liu et al. discuss the potential for information to be lost in the middle of longer contexts<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"GRAPH RAG\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Community summaries are used in the Graph RAG method<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"C0\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">C0 represents root-level community summaries<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"C1\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">C1 represents intermediate-level community summaries<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"C2\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">C2 represents intermediate-level community summaries<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"C3\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">C3 represents low-level community summaries<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"SOURCE TEXTS\" target=\"GRAPH RAG\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Source texts are used for summarization in the Graph RAG method<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"TS\" target=\"GRAPH RAG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">TS represents global text summarization without a graph index in the Graph RAG method<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"HALLUCINATION JUDGE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">GPT-4 is used in the Hallucination Judge process to evaluate generated summaries<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"KOESTEN, L.\" target=\"GREGORY, K.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Koesten, L. and Gregory, K. co-authored the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"KOESTEN, L.\" target=\"GROTH, P.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Koesten, L. and Groth, P. co-authored the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"KOESTEN, L.\" target=\"SIMPERL, E.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Koesten, L. and Simperl, E. co-authored the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"GREGORY, K.\" target=\"GROTH, P.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Gregory, K. and Groth, P. co-authored the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"GREGORY, K.\" target=\"SIMPERL, E.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Gregory, K. and Simperl, E. co-authored the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"GROTH, P.\" target=\"SIMPERL, E.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Groth, P. and Simperl, E. co-authored the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"KURATOV, Y.\" target=\"BULATOV, A.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Kuratov, Y. and Bulatov, A. co-authored the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"KURATOV, Y.\" target=\"ANOKHIN, P.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Kuratov, Y. and Anokhin, P. co-authored the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"KURATOV, Y.\" target=\"SOROKIN, D.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Kuratov, Y. and Sorokin, D. co-authored the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"KURATOV, Y.\" target=\"SOROKIN, A.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Kuratov, Y. and Sorokin, A. co-authored the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"KURATOV, Y.\" target=\"BURTSEV, M.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Kuratov, Y. and Burtsev, M. co-authored the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"BULATOV, A.\" target=\"ANOKHIN, P.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Bulatov, A. and Anokhin, P. co-authored the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"BULATOV, A.\" target=\"SOROKIN, D.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Bulatov, A. and Sorokin, D. co-authored the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"BULATOV, A.\" target=\"SOROKIN, A.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Bulatov, A. and Sorokin, A. co-authored the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"BULATOV, A.\" target=\"BURTSEV, M.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Bulatov, A. and Burtsev, M. co-authored the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"ANOKHIN, P.\" target=\"SOROKIN, D.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Anokhin, P. and Sorokin, D. co-authored the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"ANOKHIN, P.\" target=\"SOROKIN, A.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Anokhin, P. and Sorokin, A. co-authored the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"ANOKHIN, P.\" target=\"BURTSEV, M.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Anokhin, P. and Burtsev, M. co-authored the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"SOROKIN, D.\" target=\"SOROKIN, A.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Sorokin, D. and Sorokin, A. co-authored the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"SOROKIN, D.\" target=\"BURTSEV, M.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Sorokin, D. and Burtsev, M. co-authored the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"SOROKIN, A.\" target=\"BURTSEV, M.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Sorokin, A. and Burtsev, M. co-authored the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"LASKAR, M. T. R.\" target=\"HOQUE, E.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Laskar, M. T. R. and Hoque, E. co-authored the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"LASKAR, M. T. R.\" target=\"HUANG, J.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Laskar, M. T. R. and Huang, J. co-authored the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>    <edge source=\"HOQUE, E.\" target=\"HUANG, J.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Hoque, E. and Huang, J. co-authored the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"<\/data>      <data key=\"d5\">ede7063998065122cf7a7152979c1909<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"edab4014b8f55e5b25bd7f396314be1f","chunk":" win rates of 57% and 64%, respectively. Diversity win rates were 57% for\nPodcast intermediate-level summaries and 60% for News low-level community summaries. Table 3\nalso illustrates the scalability advantages of Graph RAG compared to source text summarization: for\nlow-level community summaries ( C3), Graph RAG required 26-33% fewer context tokens, while\nfor root-level community summaries ( C0), it required over 97% fewer tokens. For a modest drop in\nperformance compared with other global methods, root-level Graph RAG offers a highly efficient\nmethod for the iterative question answering that characterizes sensemaking activity, while retaining\nadvantages in comprehensiveness (72% win rate) and diversity (62% win rate) over na \u00a8\u0131ve RAG.\nEmpowerment . Empowerment comparisons showed mixed results for both global approaches versus\nna\u00a8\u0131ve RAG ( SS) and Graph RAG approaches versus source text summarization ( TS). Ad-hoc LLM\nuse to analyze LLM reasoning for this measure indicated that the ability to provide specific exam-\nples, quotes, and citations was judged to be key to helping users reach an informed understanding.\nTuning element extraction prompts may help to retain more of these details in the Graph RAG index.\n4 Related Work\n4.1 RAG Approaches and Systems\nWhen using LLMs, RAG involves first retrieving relevant information from external data sources,\nthen adding this information to the context window of the LLM along with the original query (Ram\net al., 2023). Na \u00a8\u0131ve RAG approaches (Gao et al., 2023) do this by converting documents to text,\nsplitting text into chunks, and embedding these chunks into a vector space in which similar positions\nrepresent similar semantics. Queries are then embedded into the same vector space, with the text\nchunks of the nearest kvectors used as context. More advanced variations exist, but all solve the\nproblem of what to do when an external dataset of interest exceeds the LLM\u2019s context window.\nAdvanced RAG systems include pre-retrieval, retrieval, post-retrieval strategies designed to over-\ncome the drawbacks of Na \u00a8\u0131ve RAG, while Modular RAG systems include patterns for iterative and\ndynamic cycles of interleaved retrieval and generation (Gao et al., 2023). Our implementation of\nGraph RAG incorporates multiple concepts related to other systems. For example, our community\nsummaries are a kind of self-memory (Selfmem, Cheng et al., 2024) for generation-augmented re-\ntrieval (GAR, Mao et al., 2020) that facilitates future generation cycles, while our parallel generation\nof community answers from these summaries is a kind of iterative (Iter-RetGen, Shao et al., 2023)\nor federated (FeB4RAG, Wang et al., 2024) retrieval-generation strategy. Other systems have also\ncombined these concepts for multi-document summarization (CAiRE-COVID, Su et al., 2020) and\nmulti-hop question answering (ITRG, Feng et al., 2023; IR-CoT, Trivedi et al., 2022; DSP, Khattab\net al., 2022). Our use of a hierarchical index and summarization also bears resemblance to further\napproaches, such as generating a hierarchical index of text chunks by clustering the vectors of text\nembeddings (RAPTOR, Sarthi et al., 2024) or generating a \u201ctree of clarifications\u201d to answer mul-\ntiple interpretations of ambiguous questions (Kim et al., 2023). However, none of these iterative or\nhierarchical approaches use the kind of self-generated graph index that enables Graph RAG.\n104.2 Graphs and LLMs\nUse of graphs in connection with LLMs and RAG is a developing research area, with multiple\ndirections already established. These include using LLMs for knowledge graph creation (Tra-\njanoska et al., 2023) and completion (Yao et al., 2023), as well as for the extraction of causal\ngraphs (Ban et al., 2023; Zhang et al., 2024) from source texts. They also include forms of ad-\nvanced RAG (Gao et al., 2023) where the index is a knowledge graph (KAPING, Baek et al., 2023),\nwhere subsets of the graph structure (G-Retriever, He et al., 2024) or derived graph metrics (Graph-\nToolFormer, Zhang, 2023) are the objects of enquiry, where narrative outputs are strongly grounded\nin the facts of retrieved subgraphs (SURGE, Kang et al., 2023), where retrieved event-plot sub-\ngraphs are serialized using narrative templates (FABULA, Ranade and Joshi, 2023), and where the\nsystem supports both creation and traversal of text-relationship graphs for multi-hop question an-\nswering (Wang et al., 2023b). In terms of open-source software, a variety a graph databases are\nsupported by both the LangChain (LangChain, 2024) and LlamaIndex (LlamaIndex, 2024) libraries,\nwhile a more general class of graph-based RAG applications is also emerging, including systems that\ncan create and reason over knowledge graphs in both Neo4J (NaLLM, Neo4J, 2024) and Nebula-\nGraph (GraphRAG, NebulaGraph, 2024) formats. Unlike our Graph RAG approach, however, none\nof these systems use the natural modularity of graphs to partition data for global summarization","chunk_id":"edab4014b8f55e5b25bd7f396314be1f","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":1200,"entities":[{"name":"GRAPH RAG","type":"TOOL\/METHOD","description":"Graph RAG is a method that uses a self-generated graph index to enable efficient and comprehensive summarization and iterative question answering","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"NA\u00cfVE RAG","type":"TOOL\/METHOD","description":"Na\u00efve RAG is a basic approach to retrieval-augmented generation that converts documents to text, splits them into chunks, and embeds these chunks into a vector space for context retrieval","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"LLM","type":"TOOL\/TECHNOLOGY","description":"LLM stands for Large Language Model, which is used in various RAG approaches to process and generate text based on retrieved information","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"COMMUNITY SUMMARIES","type":"OUTPUT\/RESULT","description":"Community summaries are a type of self-memory used in Graph RAG for generation-augmented retrieval, facilitating future generation cycles","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"GENERATION-AUGMENTED RETRIEVAL (GAR)","type":"METHOD","description":"GAR is a method that combines retrieval and generation processes to enhance the performance of information retrieval systems","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"MODULAR RAG","type":"TOOL\/METHOD","description":"Modular RAG includes patterns for iterative and dynamic cycles of interleaved retrieval and generation to improve upon Na\u00efve RAG","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"SELF-MEMORY (SELFMEM)","type":"CONCEPT","description":"Self-memory is a concept used in generation-augmented retrieval to store and utilize past generated content for future retrieval and generation cycles","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"ITERATIVE RETRIEVAL-GENERATION (ITER-RETGEN)","type":"METHOD","description":"Iter-RetGen is a strategy for iterative retrieval and generation, used in advanced RAG systems","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"FEDERATED RETRIEVAL-GENERATION (FEB4RAG)","type":"METHOD","description":"FeB4RAG is a federated strategy for retrieval and generation, used in advanced RAG systems","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"MULTI-DOCUMENT SUMMARIZATION","type":"TASK","description":"Multi-document summarization is the process of creating a summary from multiple documents, often using advanced RAG systems","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"MULTI-HOP QUESTION ANSWERING","type":"TASK","description":"Multi-hop question answering involves answering questions that require reasoning over multiple pieces of information, often using advanced RAG systems","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"HIERARCHICAL INDEX","type":"TOOL\/STRUCTURE","description":"A hierarchical index is a structure used to organize text chunks by clustering their vector embeddings, facilitating efficient retrieval and summarization","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"KNOWLEDGE GRAPH","type":"TOOL\/STRUCTURE","description":"A knowledge graph is a structured representation of information, used in various advanced RAG systems for retrieval and reasoning","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"LANGCHAIN","type":"SOFTWARE\/LIBRARY","description":"LangChain is a library that supports various graph databases and graph-based RAG applications","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"LLAMAINDEX","type":"SOFTWARE\/LIBRARY","description":"LlamaIndex is a library that supports various graph databases and graph-based RAG applications","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"NEO4J","type":"SOFTWARE\/TOOL","description":"Neo4J is a graph database supported by LangChain and LlamaIndex for creating and reasoning over knowledge graphs","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"NEBULAGRAPH","type":"SOFTWARE\/TOOL","description":"NebulaGraph is a graph database supported by LangChain and LlamaIndex for creating and reasoning over knowledge graphs","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"EMPOWERMENT","type":"CONCEPT","description":"Empowerment refers to the ability of a system to help users reach an informed understanding, often by providing specific examples, quotes, and citations","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"SENSEMAKING","type":"ACTIVITY","description":"Sensemaking is the activity of understanding and making sense of information, often facilitated by iterative question answering and summarization methods like Graph RAG","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"SCALABILITY","type":"ATTRIBUTE","description":"Scalability refers to the ability of a system to handle increasing amounts of work or data efficiently, as demonstrated by Graph RAG's reduced context token requirements","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"COMPREHENSIVENESS","type":"ATTRIBUTE","description":"Comprehensiveness refers to the extent to which a system covers all relevant information, as indicated by Graph RAG's win rate in comprehensiveness","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"DIVERSITY","type":"ATTRIBUTE","description":"Diversity refers to the variety of information or perspectives included in a summary, as indicated by Graph RAG's win rate in diversity","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"TUNING ELEMENT EXTRACTION PROMPTS","type":"METHOD","description":"Tuning element extraction prompts is a method to improve the retention of specific details in the Graph RAG index","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"RAPTOR","type":"TOOL\/METHOD","description":"RAPTOR is a method that generates a hierarchical index of text chunks by clustering their vector embeddings","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"TREE OF CLARIFICATIONS","type":"TOOL\/STRUCTURE","description":"A tree of clarifications is a structure used to answer multiple interpretations of ambiguous questions","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"KAPING","type":"TOOL\/METHOD","description":"KAPING is an advanced RAG method where the index is a knowledge graph","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"G-RETRIEVER","type":"TOOL\/METHOD","description":"G-Retriever is a method where subsets of the graph structure are the objects of enquiry","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"GRAPH-TOOLFORMER","type":"TOOL\/METHOD","description":"Graph-ToolFormer is a method where derived graph metrics are the objects of enquiry","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"SURGE","type":"TOOL\/METHOD","description":"SURGE is a method where narrative outputs are strongly grounded in the facts of retrieved subgraphs","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"FABULA","type":"TOOL\/METHOD","description":"FABULA is a method where retrieved event-plot subgraphs are serialized using narrative templates","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"NALLM","type":"TOOL\/METHOD","description":"NaLLM is a system that can create and reason over knowledge graphs in Neo4J format","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"GRAPHRAG","type":"TOOL\/METHOD","description":"GraphRAG is a system that can create and reason over knowledge graphs in NebulaGraph format","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"CAIRE-COVID","type":"TOOL\/METHOD","description":"CAiRE-COVID is a system that combines various concepts for multi-document summarization","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"ITRG","type":"TOOL\/METHOD","description":"ITRG is a system for multi-hop question answering","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"IR-COT","type":"TOOL\/METHOD","description":"IR-CoT is a system for multi-hop question answering","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"DSP","type":"TOOL\/METHOD","description":"DSP is a system for multi-hop question answering","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"TRAJANOSKA ET AL., 2023","type":"PUBLICATION","description":"A study on using LLMs for knowledge graph creation and completion","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"YAO ET AL., 2023","type":"PUBLICATION","description":"A study on using LLMs for knowledge graph completion","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"BAN ET AL., 2023","type":"PUBLICATION","description":"A study on using LLMs for the extraction of causal graphs from source texts","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"ZHANG ET AL., 2024","type":"PUBLICATION","description":"A study on using LLMs for the extraction of causal graphs from source texts","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"BAEK ET AL., 2023","type":"PUBLICATION","description":"A study on advanced RAG methods where the index is a knowledge graph","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"HE ET AL., 2024","type":"PUBLICATION","description":"A study on advanced RAG methods where subsets of the graph structure are the objects of enquiry","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"ZHANG, 2023","type":"PUBLICATION","description":"A study on advanced RAG methods where derived graph metrics are the objects of enquiry","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"KANG ET AL., 2023","type":"PUBLICATION","description":"A study on advanced RAG methods where narrative outputs are strongly grounded in the facts of retrieved subgraphs","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"RANADE AND JOSHI, 2023","type":"PUBLICATION","description":"A study on advanced RAG methods where retrieved event-plot subgraphs are serialized using narrative templates","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"WANG ET AL., 2023B","type":"PUBLICATION","description":"A study on advanced RAG methods that support both creation and traversal of text-relationship graphs for multi-hop question answering","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"NEO4J, 2024","type":"PUBLICATION","description":"A study on systems that can create and reason over knowledge graphs in Neo4J format","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"NEBULAGRAPH, 2024","type":"PUBLICATION","description":"A study on systems that can create and reason over knowledge graphs in NebulaGraph format","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"RAM ET AL., 2023","type":"PUBLICATION","description":"A study on RAG approaches and systems","source_id":"edab4014b8f55e5b25bd7f396314be1f","entity_type":"PUBLICATION"},{"name":"GAO ET AL., 2023","type":"PUBLICATION","description":"A study on Na\u00efve RAG and advanced RAG systems","source_id":"edab4014b8f55e5b25bd7f396314be1f","entity_type":"PUBLICATION"},{"name":"CHENG ET AL., 2024","type":"PUBLICATION","description":"A study on self-memory for generation-augmented retrieval","source_id":"edab4014b8f55e5b25bd7f396314be1f","entity_type":"PUBLICATION"},{"name":"MAO ET AL., 2020","type":"PUBLICATION","description":"A study on generation-augmented retrieval","source_id":"edab4014b8f55e5b25bd7f396314be1f","entity_type":"PUBLICATION"},{"name":"SHAO ET AL., 2023","type":"PUBLICATION","description":"A study on iterative retrieval-generation strategies","source_id":"edab4014b8f55e5b25bd7f396314be1f","entity_type":"PUBLICATION"},{"name":"WANG ET AL., 2024","type":"PUBLICATION","description":"A study on federated retrieval-generation strategies","source_id":"edab4014b8f55e5b25bd7f396314be1f","entity_type":"PUBLICATION"},{"name":"SU ET AL., 2020","type":"PUBLICATION","description":"A study on multi-document summarization","source_id":"edab4014b8f55e5b25bd7f396314be1f","entity_type":"PUBLICATION"},{"name":"FENG ET AL., 2023","type":"PUBLICATION","description":"A study on multi-hop question answering","source_id":"edab4014b8f55e5b25bd7f396314be1f","entity_type":"PUBLICATION"},{"name":"TRIVEDI ET AL., 2022","type":"PUBLICATION","description":"A study on multi-hop question answering","source_id":"edab4014b8f55e5b25bd7f396314be1f","entity_type":"PUBLICATION"},{"name":"KHATTAB ET AL., 2022","type":"PUBLICATION","description":"A study on multi-hop question answering","source_id":"edab4014b8f55e5b25bd7f396314be1f","entity_type":"PUBLICATION"},{"name":"SARTHI ET AL., 2024","type":"PUBLICATION","description":"A study on generating a hierarchical index of text chunks by clustering their vector embeddings","source_id":"edab4014b8f55e5b25bd7f396314be1f","entity_type":"PUBLICATION"},{"name":"KIM ET AL., 2023","type":"PUBLICATION","description":"A study on generating a tree of clarifications to answer multiple interpretations of ambiguous questions","source_id":"edab4014b8f55e5b25bd7f396314be1f","entity_type":"PUBLICATION"},{"name":"PODCAST INTERMEDIATE-LEVEL SUMMARIES","type":"OUTPUT\/RESULT","description":"Podcast intermediate-level summaries are summaries generated for podcasts at an intermediate level of detail","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"NEWS LOW-LEVEL COMMUNITY SUMMARIES","type":"OUTPUT\/RESULT","description":"News low-level community summaries are summaries generated for news articles at a low level of detail","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"TABLE 3","type":"DATA\/RESULT","description":"Table 3 illustrates the scalability advantages of Graph RAG compared to source text summarization","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"ROOT-LEVEL COMMUNITY SUMMARIES","type":"OUTPUT\/RESULT","description":"Root-level community summaries are summaries generated at the root level of detail","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"ITERATIVE QUESTION ANSWERING","type":"TASK","description":"Iterative question answering is a process characterized by repeated cycles of asking and answering questions to facilitate sensemaking","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"AD-HOC LLM USE","type":"METHOD","description":"Ad-hoc LLM use refers to the spontaneous use of large language models to analyze reasoning and provide specific examples, quotes, and citations","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"RAG APPROACHES AND SYSTEMS","type":"CONCEPT","description":"RAG approaches and systems involve retrieving relevant information from external data sources and adding it to the context window of an LLM along with the original query","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"PRE-RETRIEVAL STRATEGIES","type":"METHOD","description":"Pre-retrieval strategies are techniques used before the retrieval process to enhance the performance of RAG systems","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"POST-RETRIEVAL STRATEGIES","type":"METHOD","description":"Post-retrieval strategies are techniques used after the retrieval process to enhance the performance of RAG systems","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"COMMUNITY ANSWERS","type":"OUTPUT\/RESULT","description":"Community answers are generated from community summaries in a parallel generation process","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"MULTI-HOP QUESTION ANSWERING (ITRG)","type":"TOOL\/METHOD","description":"ITRG is a system for multi-hop question answering","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"MULTI-HOP QUESTION ANSWERING (IR-COT)","type":"TOOL\/METHOD","description":"IR-CoT is a system for multi-hop question answering","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"MULTI-HOP QUESTION ANSWERING (DSP)","type":"TOOL\/METHOD","description":"DSP is a system for multi-hop question answering","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"HIERARCHICAL INDEX OF TEXT CHUNKS","type":"TOOL\/STRUCTURE","description":"A hierarchical index of text chunks is a structure used to organize text chunks by clustering their vector embeddings","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"TEXT-RELATIONSHIP GRAPHS","type":"TOOL\/STRUCTURE","description":"Text-relationship graphs are structures that support both creation and traversal for multi-hop question answering","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"GRAPH DATABASES","type":"TOOL\/STRUCTURE","description":"Graph databases are databases that use graph structures for semantic queries, supported by LangChain and LlamaIndex","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"GRAPH-BASED RAG APPLICATIONS","type":"TOOL\/STRUCTURE","description":"Graph-based RAG applications are systems that use graph structures for retrieval-augmented generation","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"SENSEMAKING ACTIVITY","type":"ACTIVITY","description":"Sensemaking activity involves understanding and making sense of information, often facilitated by iterative question answering and summarization methods like Graph RAG","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"QUOTES","type":"DATA\/RESULT","description":"Quotes are specific excerpts from texts used to support reasoning and understanding in LLM analyses","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"CITATIONS","type":"DATA\/RESULT","description":"Citations are references to sources used to support reasoning and understanding in LLM analyses","source_id":"edab4014b8f55e5b25bd7f396314be1f"},{"name":"EXAMPLES","type":"DATA\/RESULT","description":"Examples are specific instances used to illustrate points and support reasoning in LLM analyses","source_id":"edab4014b8f55e5b25bd7f396314be1f"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"GRAPH RAG\">      <data key=\"d0\">TOOL\/METHOD<\/data>      <data key=\"d1\">Graph RAG is a method that uses a self-generated graph index to enable efficient and comprehensive summarization and iterative question answering<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"NA&#207;VE RAG\">      <data key=\"d0\">TOOL\/METHOD<\/data>      <data key=\"d1\">Na&#239;ve RAG is a basic approach to retrieval-augmented generation that converts documents to text, splits them into chunks, and embeds these chunks into a vector space for context retrieval<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"LLM\">      <data key=\"d0\">TOOL\/TECHNOLOGY<\/data>      <data key=\"d1\">LLM stands for Large Language Model, which is used in various RAG approaches to process and generate text based on retrieved information<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"COMMUNITY SUMMARIES\">      <data key=\"d0\">OUTPUT\/RESULT<\/data>      <data key=\"d1\">Community summaries are a type of self-memory used in Graph RAG for generation-augmented retrieval, facilitating future generation cycles<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"GENERATION-AUGMENTED RETRIEVAL (GAR)\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">GAR is a method that combines retrieval and generation processes to enhance the performance of information retrieval systems<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"MODULAR RAG\">      <data key=\"d0\">TOOL\/METHOD<\/data>      <data key=\"d1\">Modular RAG includes patterns for iterative and dynamic cycles of interleaved retrieval and generation to improve upon Na&#239;ve RAG<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"SELF-MEMORY (SELFMEM)\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Self-memory is a concept used in generation-augmented retrieval to store and utilize past generated content for future retrieval and generation cycles<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"ITERATIVE RETRIEVAL-GENERATION (ITER-RETGEN)\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Iter-RetGen is a strategy for iterative retrieval and generation, used in advanced RAG systems<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"FEDERATED RETRIEVAL-GENERATION (FEB4RAG)\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">FeB4RAG is a federated strategy for retrieval and generation, used in advanced RAG systems<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"MULTI-DOCUMENT SUMMARIZATION\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">Multi-document summarization is the process of creating a summary from multiple documents, often using advanced RAG systems<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"MULTI-HOP QUESTION ANSWERING\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">Multi-hop question answering involves answering questions that require reasoning over multiple pieces of information, often using advanced RAG systems<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"HIERARCHICAL INDEX\">      <data key=\"d0\">TOOL\/STRUCTURE<\/data>      <data key=\"d1\">A hierarchical index is a structure used to organize text chunks by clustering their vector embeddings, facilitating efficient retrieval and summarization<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"KNOWLEDGE GRAPH\">      <data key=\"d0\">TOOL\/STRUCTURE<\/data>      <data key=\"d1\">A knowledge graph is a structured representation of information, used in various advanced RAG systems for retrieval and reasoning<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"LANGCHAIN\">      <data key=\"d0\">SOFTWARE\/LIBRARY<\/data>      <data key=\"d1\">LangChain is a library that supports various graph databases and graph-based RAG applications<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"LLAMAINDEX\">      <data key=\"d0\">SOFTWARE\/LIBRARY<\/data>      <data key=\"d1\">LlamaIndex is a library that supports various graph databases and graph-based RAG applications<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"NEO4J\">      <data key=\"d0\">SOFTWARE\/TOOL<\/data>      <data key=\"d1\">Neo4J is a graph database supported by LangChain and LlamaIndex for creating and reasoning over knowledge graphs<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"NEBULAGRAPH\">      <data key=\"d0\">SOFTWARE\/TOOL<\/data>      <data key=\"d1\">NebulaGraph is a graph database supported by LangChain and LlamaIndex for creating and reasoning over knowledge graphs<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"EMPOWERMENT\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Empowerment refers to the ability of a system to help users reach an informed understanding, often by providing specific examples, quotes, and citations<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"SENSEMAKING\">      <data key=\"d0\">ACTIVITY<\/data>      <data key=\"d1\">Sensemaking is the activity of understanding and making sense of information, often facilitated by iterative question answering and summarization methods like Graph RAG<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"SCALABILITY\">      <data key=\"d0\">ATTRIBUTE<\/data>      <data key=\"d1\">Scalability refers to the ability of a system to handle increasing amounts of work or data efficiently, as demonstrated by Graph RAG's reduced context token requirements<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"COMPREHENSIVENESS\">      <data key=\"d0\">ATTRIBUTE<\/data>      <data key=\"d1\">Comprehensiveness refers to the extent to which a system covers all relevant information, as indicated by Graph RAG's win rate in comprehensiveness<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"DIVERSITY\">      <data key=\"d0\">ATTRIBUTE<\/data>      <data key=\"d1\">Diversity refers to the variety of information or perspectives included in a summary, as indicated by Graph RAG's win rate in diversity<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"TUNING ELEMENT EXTRACTION PROMPTS\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Tuning element extraction prompts is a method to improve the retention of specific details in the Graph RAG index<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"RAPTOR\">      <data key=\"d0\">TOOL\/METHOD<\/data>      <data key=\"d1\">RAPTOR is a method that generates a hierarchical index of text chunks by clustering their vector embeddings<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"TREE OF CLARIFICATIONS\">      <data key=\"d0\">TOOL\/STRUCTURE<\/data>      <data key=\"d1\">A tree of clarifications is a structure used to answer multiple interpretations of ambiguous questions<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"KAPING\">      <data key=\"d0\">TOOL\/METHOD<\/data>      <data key=\"d1\">KAPING is an advanced RAG method where the index is a knowledge graph<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"G-RETRIEVER\">      <data key=\"d0\">TOOL\/METHOD<\/data>      <data key=\"d1\">G-Retriever is a method where subsets of the graph structure are the objects of enquiry<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"GRAPH-TOOLFORMER\">      <data key=\"d0\">TOOL\/METHOD<\/data>      <data key=\"d1\">Graph-ToolFormer is a method where derived graph metrics are the objects of enquiry<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"SURGE\">      <data key=\"d0\">TOOL\/METHOD<\/data>      <data key=\"d1\">SURGE is a method where narrative outputs are strongly grounded in the facts of retrieved subgraphs<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"FABULA\">      <data key=\"d0\">TOOL\/METHOD<\/data>      <data key=\"d1\">FABULA is a method where retrieved event-plot subgraphs are serialized using narrative templates<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"NALLM\">      <data key=\"d0\">TOOL\/METHOD<\/data>      <data key=\"d1\">NaLLM is a system that can create and reason over knowledge graphs in Neo4J format<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"GRAPHRAG\">      <data key=\"d0\">TOOL\/METHOD<\/data>      <data key=\"d1\">GraphRAG is a system that can create and reason over knowledge graphs in NebulaGraph format<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"CAIRE-COVID\">      <data key=\"d0\">TOOL\/METHOD<\/data>      <data key=\"d1\">CAiRE-COVID is a system that combines various concepts for multi-document summarization<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"ITRG\">      <data key=\"d0\">TOOL\/METHOD<\/data>      <data key=\"d1\">ITRG is a system for multi-hop question answering<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"IR-COT\">      <data key=\"d0\">TOOL\/METHOD<\/data>      <data key=\"d1\">IR-CoT is a system for multi-hop question answering<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"DSP\">      <data key=\"d0\">TOOL\/METHOD<\/data>      <data key=\"d1\">DSP is a system for multi-hop question answering<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"TRAJANOSKA ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on using LLMs for knowledge graph creation and completion<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"YAO ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on using LLMs for knowledge graph completion<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"BAN ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on using LLMs for the extraction of causal graphs from source texts<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"ZHANG ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on using LLMs for the extraction of causal graphs from source texts<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"BAEK ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on advanced RAG methods where the index is a knowledge graph<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"HE ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on advanced RAG methods where subsets of the graph structure are the objects of enquiry<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"ZHANG, 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on advanced RAG methods where derived graph metrics are the objects of enquiry<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"KANG ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on advanced RAG methods where narrative outputs are strongly grounded in the facts of retrieved subgraphs<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"RANADE AND JOSHI, 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on advanced RAG methods where retrieved event-plot subgraphs are serialized using narrative templates<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"WANG ET AL., 2023B\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on advanced RAG methods that support both creation and traversal of text-relationship graphs for multi-hop question answering<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"NEO4J, 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on systems that can create and reason over knowledge graphs in Neo4J format<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"NEBULAGRAPH, 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on systems that can create and reason over knowledge graphs in NebulaGraph format<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"RAM ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on RAG approaches and systems<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"GAO ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on Na&#239;ve RAG and advanced RAG systems<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"CHENG ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on self-memory for generation-augmented retrieval<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"MAO ET AL., 2020\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on generation-augmented retrieval<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"SHAO ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on iterative retrieval-generation strategies<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"WANG ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on federated retrieval-generation strategies<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"SU ET AL., 2020\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on multi-document summarization<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"FENG ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on multi-hop question answering<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"TRIVEDI ET AL., 2022\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on multi-hop question answering<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"KHATTAB ET AL., 2022\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on multi-hop question answering<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"SARTHI ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on generating a hierarchical index of text chunks by clustering their vector embeddings<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"KIM ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A study on generating a tree of clarifications to answer multiple interpretations of ambiguous questions<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"PODCAST INTERMEDIATE-LEVEL SUMMARIES\">      <data key=\"d0\">OUTPUT\/RESULT<\/data>      <data key=\"d1\">Podcast intermediate-level summaries are summaries generated for podcasts at an intermediate level of detail<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"NEWS LOW-LEVEL COMMUNITY SUMMARIES\">      <data key=\"d0\">OUTPUT\/RESULT<\/data>      <data key=\"d1\">News low-level community summaries are summaries generated for news articles at a low level of detail<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"TABLE 3\">      <data key=\"d0\">DATA\/RESULT<\/data>      <data key=\"d1\">Table 3 illustrates the scalability advantages of Graph RAG compared to source text summarization<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"ROOT-LEVEL COMMUNITY SUMMARIES\">      <data key=\"d0\">OUTPUT\/RESULT<\/data>      <data key=\"d1\">Root-level community summaries are summaries generated at the root level of detail<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"ITERATIVE QUESTION ANSWERING\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">Iterative question answering is a process characterized by repeated cycles of asking and answering questions to facilitate sensemaking<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"AD-HOC LLM USE\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Ad-hoc LLM use refers to the spontaneous use of large language models to analyze reasoning and provide specific examples, quotes, and citations<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"RAG APPROACHES AND SYSTEMS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">RAG approaches and systems involve retrieving relevant information from external data sources and adding it to the context window of an LLM along with the original query<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"PRE-RETRIEVAL STRATEGIES\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Pre-retrieval strategies are techniques used before the retrieval process to enhance the performance of RAG systems<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"POST-RETRIEVAL STRATEGIES\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Post-retrieval strategies are techniques used after the retrieval process to enhance the performance of RAG systems<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"COMMUNITY ANSWERS\">      <data key=\"d0\">OUTPUT\/RESULT<\/data>      <data key=\"d1\">Community answers are generated from community summaries in a parallel generation process<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"MULTI-HOP QUESTION ANSWERING (ITRG)\">      <data key=\"d0\">TOOL\/METHOD<\/data>      <data key=\"d1\">ITRG is a system for multi-hop question answering<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"MULTI-HOP QUESTION ANSWERING (IR-COT)\">      <data key=\"d0\">TOOL\/METHOD<\/data>      <data key=\"d1\">IR-CoT is a system for multi-hop question answering<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"MULTI-HOP QUESTION ANSWERING (DSP)\">      <data key=\"d0\">TOOL\/METHOD<\/data>      <data key=\"d1\">DSP is a system for multi-hop question answering<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"HIERARCHICAL INDEX OF TEXT CHUNKS\">      <data key=\"d0\">TOOL\/STRUCTURE<\/data>      <data key=\"d1\">A hierarchical index of text chunks is a structure used to organize text chunks by clustering their vector embeddings<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"TEXT-RELATIONSHIP GRAPHS\">      <data key=\"d0\">TOOL\/STRUCTURE<\/data>      <data key=\"d1\">Text-relationship graphs are structures that support both creation and traversal for multi-hop question answering<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"GRAPH DATABASES\">      <data key=\"d0\">TOOL\/STRUCTURE<\/data>      <data key=\"d1\">Graph databases are databases that use graph structures for semantic queries, supported by LangChain and LlamaIndex<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"GRAPH-BASED RAG APPLICATIONS\">      <data key=\"d0\">TOOL\/STRUCTURE<\/data>      <data key=\"d1\">Graph-based RAG applications are systems that use graph structures for retrieval-augmented generation<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"SENSEMAKING ACTIVITY\">      <data key=\"d0\">ACTIVITY<\/data>      <data key=\"d1\">Sensemaking activity involves understanding and making sense of information, often facilitated by iterative question answering and summarization methods like Graph RAG<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"QUOTES\">      <data key=\"d0\">DATA\/RESULT<\/data>      <data key=\"d1\">Quotes are specific excerpts from texts used to support reasoning and understanding in LLM analyses<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"CITATIONS\">      <data key=\"d0\">DATA\/RESULT<\/data>      <data key=\"d1\">Citations are references to sources used to support reasoning and understanding in LLM analyses<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <node id=\"EXAMPLES\">      <data key=\"d0\">DATA\/RESULT<\/data>      <data key=\"d1\">Examples are specific instances used to illustrate points and support reasoning in LLM analyses<\/data>      <data key=\"d2\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/node>    <edge source=\"GRAPH RAG\" target=\"NA&#207;VE RAG\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Graph RAG is an advanced method that improves upon Na&#239;ve RAG by using a self-generated graph index<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"LLM\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Graph RAG uses LLMs to process and generate text based on retrieved information<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"COMMUNITY SUMMARIES\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Graph RAG uses community summaries as a type of self-memory for generation-augmented retrieval<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"GENERATION-AUGMENTED RETRIEVAL (GAR)\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Graph RAG incorporates concepts from generation-augmented retrieval (GAR)<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"MODULAR RAG\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Graph RAG includes patterns from Modular RAG for iterative and dynamic cycles of interleaved retrieval and generation<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"SELF-MEMORY (SELFMEM)\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Graph RAG uses the concept of self-memory for generation-augmented retrieval<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"ITERATIVE RETRIEVAL-GENERATION (ITER-RETGEN)\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Graph RAG uses iterative retrieval-generation strategies<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"FEDERATED RETRIEVAL-GENERATION (FEB4RAG)\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Graph RAG uses federated retrieval-generation strategies<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"MULTI-DOCUMENT SUMMARIZATION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Graph RAG can be used for multi-document summarization<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"MULTI-HOP QUESTION ANSWERING\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Graph RAG can be used for multi-hop question answering<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"HIERARCHICAL INDEX\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Graph RAG uses a hierarchical index to organize text chunks<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"KNOWLEDGE GRAPH\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Graph RAG can create and reason over knowledge graphs<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"SCALABILITY\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Graph RAG demonstrates scalability by reducing context token requirements<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"COMPREHENSIVENESS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Graph RAG has a high win rate in comprehensiveness<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"DIVERSITY\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Graph RAG has a high win rate in diversity<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"TUNING ELEMENT EXTRACTION PROMPTS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Tuning element extraction prompts can improve the retention of specific details in the Graph RAG index<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"RAPTOR\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Graph RAG's hierarchical index is similar to RAPTOR's method of clustering text chunk vectors<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"TREE OF CLARIFICATIONS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Graph RAG's hierarchical approach is similar to generating a tree of clarifications<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"KAPING\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Graph RAG's use of a knowledge graph index is similar to KAPING<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"G-RETRIEVER\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Graph RAG's use of graph structures is similar to G-Retriever<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"GRAPH-TOOLFORMER\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Graph RAG's use of graph metrics is similar to Graph-ToolFormer<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"SURGE\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Graph RAG's narrative grounding is similar to SURGE<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"FABULA\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Graph RAG's use of narrative templates is similar to FABULA<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"NALLM\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Graph RAG's ability to create and reason over knowledge graphs is similar to NaLLM<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"GRAPHRAG\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Graph RAG's ability to create and reason over knowledge graphs is similar to GraphRAG<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"CAIRE-COVID\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Graph RAG's multi-document summarization is similar to CAiRE-COVID<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"ITRG\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Graph RAG's multi-hop question answering is similar to ITRG<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"IR-COT\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Graph RAG's multi-hop question answering is similar to IR-CoT<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"DSP\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Graph RAG's multi-hop question answering is similar to DSP<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"PODCAST INTERMEDIATE-LEVEL SUMMARIES\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Graph RAG generates podcast intermediate-level summaries<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"NEWS LOW-LEVEL COMMUNITY SUMMARIES\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Graph RAG generates news low-level community summaries<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"TABLE 3\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Table 3 illustrates the scalability advantages of Graph RAG<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"ROOT-LEVEL COMMUNITY SUMMARIES\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Graph RAG generates root-level community summaries<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"ITERATIVE QUESTION ANSWERING\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Graph RAG is used for iterative question answering<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"NA&#207;VE RAG\" target=\"GAO ET AL., 2023\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Gao et al., 2023 is a study on Na&#239;ve RAG<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"LLM\" target=\"AD-HOC LLM USE\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Ad-hoc LLM use involves the spontaneous use of large language models<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"LLM\" target=\"RAG APPROACHES AND SYSTEMS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">RAG approaches and systems involve using LLMs<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"COMMUNITY SUMMARIES\" target=\"COMMUNITY ANSWERS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Community answers are generated from community summaries<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"GENERATION-AUGMENTED RETRIEVAL (GAR)\" target=\"MAO ET AL., 2020\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Mao et al., 2020 is a study on generation-augmented retrieval<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"SELF-MEMORY (SELFMEM)\" target=\"CHENG ET AL., 2024\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Cheng et al., 2024 is a study on self-memory<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"ITERATIVE RETRIEVAL-GENERATION (ITER-RETGEN)\" target=\"SHAO ET AL., 2023\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Shao et al., 2023 is a study on iterative retrieval-generation<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"FEDERATED RETRIEVAL-GENERATION (FEB4RAG)\" target=\"WANG ET AL., 2024\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang et al., 2024 is a study on federated retrieval-generation<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"MULTI-DOCUMENT SUMMARIZATION\" target=\"SU ET AL., 2020\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Su et al., 2020 is a study on multi-document summarization<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"MULTI-HOP QUESTION ANSWERING\" target=\"MULTI-HOP QUESTION ANSWERING (ITRG)\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">ITRG is a system for multi-hop question answering<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"MULTI-HOP QUESTION ANSWERING\" target=\"MULTI-HOP QUESTION ANSWERING (IR-COT)\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">IR-CoT is a system for multi-hop question answering<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"MULTI-HOP QUESTION ANSWERING\" target=\"MULTI-HOP QUESTION ANSWERING (DSP)\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">DSP is a system for multi-hop question answering<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"MULTI-HOP QUESTION ANSWERING\" target=\"FENG ET AL., 2023\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Feng et al., 2023 is a study on multi-hop question answering<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"MULTI-HOP QUESTION ANSWERING\" target=\"TRIVEDI ET AL., 2022\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Trivedi et al., 2022 is a study on multi-hop question answering<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"MULTI-HOP QUESTION ANSWERING\" target=\"KHATTAB ET AL., 2022\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Khattab et al., 2022 is a study on multi-hop question answering<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"HIERARCHICAL INDEX\" target=\"HIERARCHICAL INDEX OF TEXT CHUNKS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">A hierarchical index of text chunks is a type of hierarchical index<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"HIERARCHICAL INDEX\" target=\"SARTHI ET AL., 2024\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Sarthi et al., 2024 is a study on hierarchical index<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"LANGCHAIN\" target=\"LLAMAINDEX\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">LangChain and LlamaIndex both support various graph databases and graph-based RAG applications<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"LANGCHAIN\" target=\"NEO4J\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">LangChain supports the Neo4J graph database<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"LANGCHAIN\" target=\"NEBULAGRAPH\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">LangChain supports the NebulaGraph graph database<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"LANGCHAIN\" target=\"GRAPH DATABASES\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">LangChain supports various graph databases<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"LANGCHAIN\" target=\"GRAPH-BASED RAG APPLICATIONS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">LangChain supports graph-based RAG applications<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"LLAMAINDEX\" target=\"NEO4J\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">LlamaIndex supports the Neo4J graph database<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"LLAMAINDEX\" target=\"NEBULAGRAPH\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">LlamaIndex supports the NebulaGraph graph database<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"LLAMAINDEX\" target=\"GRAPH DATABASES\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">LlamaIndex supports various graph databases<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"LLAMAINDEX\" target=\"GRAPH-BASED RAG APPLICATIONS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">LlamaIndex supports graph-based RAG applications<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"EMPOWERMENT\" target=\"SENSEMAKING\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Empowerment is key to helping users reach an informed understanding during sensemaking activities<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"SENSEMAKING\" target=\"SENSEMAKING ACTIVITY\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Sensemaking activity involves sensemaking<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"TREE OF CLARIFICATIONS\" target=\"KIM ET AL., 2023\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Kim et al., 2023 is a study on tree of clarifications<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"TRAJANOSKA ET AL., 2023\" target=\"YAO ET AL., 2023\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Both studies focus on using LLMs for knowledge graph creation and completion<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"BAN ET AL., 2023\" target=\"ZHANG ET AL., 2024\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Both studies focus on using LLMs for the extraction of causal graphs<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"BAEK ET AL., 2023\" target=\"HE ET AL., 2024\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Both studies focus on advanced RAG methods<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"ZHANG, 2023\" target=\"KANG ET AL., 2023\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Both studies focus on advanced RAG methods<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"RANADE AND JOSHI, 2023\" target=\"WANG ET AL., 2023B\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Both studies focus on advanced RAG methods<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"RAM ET AL., 2023\" target=\"RAG APPROACHES AND SYSTEMS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Ram et al., 2023 is a study on RAG approaches and systems<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"AD-HOC LLM USE\" target=\"QUOTES\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Quotes are used in ad-hoc LLM use<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"AD-HOC LLM USE\" target=\"CITATIONS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Citations are used in ad-hoc LLM use<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"AD-HOC LLM USE\" target=\"EXAMPLES\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Examples are used in ad-hoc LLM use<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"RAG APPROACHES AND SYSTEMS\" target=\"PRE-RETRIEVAL STRATEGIES\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Pre-retrieval strategies are part of RAG approaches and systems<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"RAG APPROACHES AND SYSTEMS\" target=\"POST-RETRIEVAL STRATEGIES\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Post-retrieval strategies are part of RAG approaches and systems<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>    <edge source=\"TEXT-RELATIONSHIP GRAPHS\" target=\"GRAPH DATABASES\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Text-relationship graphs are supported by graph databases<\/data>      <data key=\"d6\">edab4014b8f55e5b25bd7f396314be1f<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"ac21ebe9a9d70d691c717f961d3f10c8","chunk":"Index, 2024) libraries,\nwhile a more general class of graph-based RAG applications is also emerging, including systems that\ncan create and reason over knowledge graphs in both Neo4J (NaLLM, Neo4J, 2024) and Nebula-\nGraph (GraphRAG, NebulaGraph, 2024) formats. Unlike our Graph RAG approach, however, none\nof these systems use the natural modularity of graphs to partition data for global summarization.\n5 Discussion\nLimitations of evaluation approach . Our evaluation to date has only examined a certain class of\nsensemaking questions for two corpora in the region of 1 million tokens. More work is needed\nto understand how performance varies across different ranges of question types, data types, and\ndataset sizes, as well as to validate our sensemaking questions and target metrics with end users.\nComparison of fabrication rates, e.g., using approaches like SelfCheckGPT (Manakul et al., 2023),\nwould also improve on the current analysis.\nTrade-offs of building a graph index . We consistently observed Graph RAG achieve the best head-\nto-head results against other methods, but in many cases the graph-free approach to global summa-\nrization of source texts performed competitively. The real-world decision about whether to invest in\nbuilding a graph index depends on multiple factors, including the compute budget, expected number\nof lifetime queries per dataset, and value obtained from other aspects of the graph index (including\nthe generic community summaries and the use of other graph-related RAG approaches).\nFuture work . The graph index, rich text annotations, and hierarchical community structure support-\ning the current Graph RAG approach offer many possibilities for refinement and adaptation. This\nincludes RAG approaches that operate in a more local manner, via embedding-based matching of\nuser queries and graph annotations, as well as the possibility of hybrid RAG schemes that combine\nembedding-based matching against community reports before employing our map-reduce summa-\nrization mechanisms. This \u201croll-up\u201d operation could also be extended across more levels of the\ncommunity hierarchy, as well as implemented as a more exploratory \u201cdrill down\u201d mechanism that\nfollows the information scent contained in higher-level community summaries.\n6 Conclusion\nWe have presented a global approach to Graph RAG, combining knowledge graph generation,\nretrieval-augmented generation (RAG), and query-focused summarization (QFS) to support human\nsensemaking over entire text corpora. Initial evaluations show substantial improvements over a\nna\u00a8\u0131ve RAG baseline for both the comprehensiveness and diversity of answers, as well as favorable\ncomparisons to a global but graph-free approach using map-reduce source text summarization. For\nsituations requiring many global queries over the same dataset, summaries of root-level communi-\nties in the entity-based graph index provide a data index that is both superior to na \u00a8\u0131ve RAG and\nachieves competitive performance to other global methods at a fraction of the token cost.\nAn open-source, Python-based implementation of both global and local Graph RAG approaches is\nforthcoming at https:\/\/aka .ms\/graphrag .\n11Acknowledgements\nWe would also like to thank the following people who contributed to the work: Alonso Guevara\nFern \u00b4andez, Amber Hoak, Andr \u00b4es Morales Esquivel, Ben Cutler, Billie Rinaldi, Chris Sanchez,\nChris Trevino, Christine Caggiano, David Tittsworth, Dayenne de Souza, Douglas Orbaker, Ed\nClark, Gabriel Nieves-Ponce, Gaudy Blanco Meneses, Kate Lytvynets, Katy Smith, M \u00b4onica Carva-\njal, Nathan Evans, Richard Ortega, Rodrigo Racanicci, Sarah Smith, and Shane Solomon.\nReferences\nAchiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F. L., Almeida, D., Al-\ntenschmidt, J., Altman, S., Anadkat, S., et al. (2023). Gpt-4 technical report. arXiv preprint\narXiv:2303.08774 .\nAnil, R., Borgeaud, S., Wu, Y ., Alayrac, J.-B., Yu, J., Soricut, R., Schalkwyk, J., Dai, A. M.,\nHauth, A., et al. (2023). Gemini: a family of highly capable multimodal models. arXiv preprint\narXiv:2312.11805 .\nBaek, J., Aji, A. F., and Saffari, A. (2023). Knowledge-augmented language model prompting for\nzero-shot knowledge graph question answering. arXiv preprint arXiv:2306.04136 .\nBan, T., Chen, L., Wang, X., and Chen, H. (2023). From query tools to causal architects: Harnessing\nlarge language models for advanced causal discovery from data.\nBaumel, T., Eyal, M., and Elhadad, M. (2018). Query focused abstractive summarization: Incorpo-\nrating query relevance, multi-document coverage, and summary length constraints into seq2seq\nmodels. arXiv preprint arXiv:1801.07704 .\nBlondel, V . D., Guillaume, J.-L., Lambiotte, R., and Lefebvre, E. (2008). Fast unfolding of\ncommunities in large networks. Journal of statistical mechanics: theory and experiment ,\n2008(10):P10008.\nBrown, T., Mann, B., Ryder, N., Subbia","chunk_id":"ac21ebe9a9d70d691c717f961d3f10c8","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":1200,"entities":[{"name":"INDEX","type":"PUBLICATION","description":"Index is a publication mentioned in the context of libraries and graph-based RAG applications","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"GRAPH-BASED RAG APPLICATIONS","type":"TECHNOLOGY","description":"Graph-based RAG applications are systems that create and reason over knowledge graphs in various formats","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"NEO4J","type":"TECHNOLOGY","description":"Neo4J is a format used for creating and reasoning over knowledge graphs","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"NEBULA-GRAPH","type":"TECHNOLOGY","description":"Nebula-Graph is another format used for creating and reasoning over knowledge graphs","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"GRAPH RAG","type":"TECHNOLOGY","description":"Graph RAG is an approach that uses the natural modularity of graphs to partition data for global summarization","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"SELF-CHECKGPT","type":"TOOL","description":"SelfCheckGPT is a tool used for comparing fabrication rates in analysis","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"GRAPH INDEX","type":"TECHNOLOGY","description":"Graph index is a method used in Graph RAG for building a data index that supports global summarization","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"RAG","type":"TECHNOLOGY","description":"RAG stands for Retrieval-Augmented Generation, a method used in query-focused summarization","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"QFS","type":"TECHNOLOGY","description":"QFS stands for Query-Focused Summarization, a method used to support human sensemaking over text corpora","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"MAP-REDUCE","type":"TECHNOLOGY","description":"Map-Reduce is a method used for global summarization of source texts","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"ALONSO GUEVARA FERN\u00c1NDEZ","type":"PERSON","description":"Alonso Guevara Fern\u00e1ndez is a contributor to the work on Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"AMBER HOAK","type":"PERSON","description":"Amber Hoak is a contributor to the work on Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"ANDR\u00c9S MORALES ESQUIVEL","type":"PERSON","description":"Andr\u00e9s Morales Esquivel is a contributor to the work on Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"BEN CUTLER","type":"PERSON","description":"Ben Cutler is a contributor to the work on Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"BILLIE RINALDI","type":"PERSON","description":"Billie Rinaldi is a contributor to the work on Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"CHRIS SANCHEZ","type":"PERSON","description":"Chris Sanchez is a contributor to the work on Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"CHRIS TREVINO","type":"PERSON","description":"Chris Trevino is a contributor to the work on Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"CHRISTINE CAGGIANO","type":"PERSON","description":"Christine Caggiano is a contributor to the work on Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"DAVID TITTSWORTH","type":"PERSON","description":"David Tittsworth is a contributor to the work on Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"DAYENNE DE SOUZA","type":"PERSON","description":"Dayenne de Souza is a contributor to the work on Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"DOUGLAS ORBAKER","type":"PERSON","description":"Douglas Orbaker is a contributor to the work on Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"ED CLARK","type":"PERSON","description":"Ed Clark is a contributor to the work on Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"GABRIEL NIEVES-PONCE","type":"PERSON","description":"Gabriel Nieves-Ponce is a contributor to the work on Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"GAUDY BLANCO MENESES","type":"PERSON","description":"Gaudy Blanco Meneses is a contributor to the work on Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"KATE LYTVYNETS","type":"PERSON","description":"Kate Lytvynets is a contributor to the work on Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"KATY SMITH","type":"PERSON","description":"Katy Smith is a contributor to the work on Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"M\u00d3NICA CARVAJAL","type":"PERSON","description":"M\u00f3nica Carvajal is a contributor to the work on Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"NATHAN EVANS","type":"PERSON","description":"Nathan Evans is a contributor to the work on Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"RICHARD ORTEGA","type":"PERSON","description":"Richard Ortega is a contributor to the work on Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"RODRIGO RACANICCI","type":"PERSON","description":"Rodrigo Racanicci is a contributor to the work on Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"SARAH SMITH","type":"PERSON","description":"Sarah Smith is a contributor to the work on Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"SHANE SOLOMON","type":"PERSON","description":"Shane Solomon is a contributor to the work on Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"GPT-4 TECHNICAL REPORT","type":"PUBLICATION","description":"The GPT-4 technical report is a document detailing the capabilities and features of GPT-4","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"GEMINI","type":"TECHNOLOGY","description":"Gemini is a family of highly capable multimodal models","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"KNOWLEDGE-AUGMENTED LANGUAGE MODEL PROMPTING","type":"TECHNOLOGY","description":"A method for zero-shot knowledge graph question answering","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"QUERY TOOLS","type":"TECHNOLOGY","description":"Tools used for querying data and discovering causal relationships","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"QUERY FOCUSED ABSTRACTIVE SUMMARIZATION","type":"TECHNOLOGY","description":"A method that incorporates query relevance, multi-document coverage, and summary length constraints into seq2seq models","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"FAST UNFOLDING OF COMMUNITIES","type":"TECHNOLOGY","description":"A method for detecting communities in large networks","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"NALLM","type":"TECHNOLOGY","description":"NaLLM is a system that can create and reason over knowledge graphs in Neo4J format","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"GRAPHRAG","type":"TECHNOLOGY","description":"GraphRAG is a system that can create and reason over knowledge graphs in Nebula-Graph format","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"SENSEMAKING QUESTIONS","type":"CONCEPT","description":"Sensemaking questions are a class of questions used to evaluate the performance of Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"CORPORA","type":"DATA","description":"Corpora refer to collections of text data used in the evaluation of Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"DATASET","type":"DATA","description":"Dataset refers to the collection of data used for evaluating Graph RAG","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"USER QUERIES","type":"CONCEPT","description":"User queries are questions or requests made by users to retrieve information from the graph index","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"COMMUNITY SUMMARIES","type":"DATA","description":"Community summaries are summaries of root-level communities in the entity-based graph index","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"COMMUNITY HIERARCHY","type":"CONCEPT","description":"Community hierarchy refers to the hierarchical structure of communities in the graph index","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"MAP-REDUCE SUMMARIZATION","type":"TECHNOLOGY","description":"Map-Reduce summarization is a method used for global summarization of source texts","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"PYTHON","type":"TECHNOLOGY","description":"Python is the programming language used for the implementation of Graph RAG approaches","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"ARXIV","type":"PUBLICATION","description":"arXiv is a repository where the GPT-4 technical report and other related papers are published","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"J. ACHIAM","type":"PERSON","description":"J. Achiam is an author of the GPT-4 technical report","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"S. ADLER","type":"PERSON","description":"S. Adler is an author of the GPT-4 technical report","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"S. AGARWAL","type":"PERSON","description":"S. Agarwal is an author of the GPT-4 technical report","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"L. AHMAD","type":"PERSON","description":"L. Ahmad is an author of the GPT-4 technical report","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"I. AKKAYA","type":"PERSON","description":"I. Akkaya is an author of the GPT-4 technical report","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"F. L. ALEMAN","type":"PERSON","description":"F. L. Aleman is an author of the GPT-4 technical report","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"D. ALMEIDA","type":"PERSON","description":"D. Almeida is an author of the GPT-4 technical report","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"J. ALTENSCHMIDT","type":"PERSON","description":"J. Altenschmidt is an author of the GPT-4 technical report","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"S. ALTMAN","type":"PERSON","description":"S. Altman is an author of the GPT-4 technical report","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"S. ANADKAT","type":"PERSON","description":"S. Anadkat is an author of the GPT-4 technical report","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"R. ANIL","type":"PERSON","description":"R. Anil is an author of the Gemini paper","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"S. BORGEAUD","type":"PERSON","description":"S. Borgeaud is an author of the Gemini paper","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"Y. WU","type":"PERSON","description":"Y. Wu is an author of the Gemini paper","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"J.-B. ALAYRAC","type":"PERSON","description":"J.-B. Alayrac is an author of the Gemini paper","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"J. YU","type":"PERSON","description":"J. Yu is an author of the Gemini paper","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"R. SORICUT","type":"PERSON","description":"R. Soricut is an author of the Gemini paper","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"J. SCHALKWYK","type":"PERSON","description":"J. Schalkwyk is an author of the Gemini paper","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"A. M. DAI","type":"PERSON","description":"A. M. Dai is an author of the Gemini paper","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"A. HAUTH","type":"PERSON","description":"A. Hauth is an author of the Gemini paper","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"J. BAEK","type":"PERSON","description":"J. Baek is an author of the paper on knowledge-augmented language model prompting","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"A. F. AJI","type":"PERSON","description":"A. F. Aji is an author of the paper on knowledge-augmented language model prompting","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"A. SAFFARI","type":"PERSON","description":"A. Saffari is an author of the paper on knowledge-augmented language model prompting","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"T. BAN","type":"PERSON","description":"T. Ban is an author of the paper on harnessing large language models for advanced causal discovery","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"L. CHEN","type":"PERSON","description":"L. Chen is an author of the paper on harnessing large language models for advanced causal discovery","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"X. WANG","type":"PERSON","description":"X. Wang is an author of the paper on harnessing large language models for advanced causal discovery","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"H. CHEN","type":"PERSON","description":"H. Chen is an author of the paper on harnessing large language models for advanced causal discovery","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"T. BAUMEL","type":"PERSON","description":"T. Baumel is an author of the paper on query focused abstractive summarization","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"M. EYAL","type":"PERSON","description":"M. Eyal is an author of the paper on query focused abstractive summarization","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"M. ELHADAD","type":"PERSON","description":"M. Elhadad is an author of the paper on query focused abstractive summarization","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"V. D. BLONDEL","type":"PERSON","description":"V. D. Blondel is an author of the paper on fast unfolding of communities in large networks","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"J.-L. GUILLAUME","type":"PERSON","description":"J.-L. Guillaume is an author of the paper on fast unfolding of communities in large networks","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"R. LAMBIOTTE","type":"PERSON","description":"R. Lambiotte is an author of the paper on fast unfolding of communities in large networks","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"},{"name":"E. LEFEBVRE","type":"PERSON","description":"E. Lefebvre is an author of the paper on fast unfolding of communities in large networks","source_id":"ac21ebe9a9d70d691c717f961d3f10c8"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"INDEX\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Index is a publication mentioned in the context of libraries and graph-based RAG applications<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"GRAPH-BASED RAG APPLICATIONS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Graph-based RAG applications are systems that create and reason over knowledge graphs in various formats<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"NEO4J\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Neo4J is a format used for creating and reasoning over knowledge graphs<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"NEBULA-GRAPH\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Nebula-Graph is another format used for creating and reasoning over knowledge graphs<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"GRAPH RAG\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Graph RAG is an approach that uses the natural modularity of graphs to partition data for global summarization<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"SELF-CHECKGPT\">      <data key=\"d0\">TOOL<\/data>      <data key=\"d1\">SelfCheckGPT is a tool used for comparing fabrication rates in analysis<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"GRAPH INDEX\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Graph index is a method used in Graph RAG for building a data index that supports global summarization<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"RAG\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">RAG stands for Retrieval-Augmented Generation, a method used in query-focused summarization<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"QFS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">QFS stands for Query-Focused Summarization, a method used to support human sensemaking over text corpora<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"MAP-REDUCE\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Map-Reduce is a method used for global summarization of source texts<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"ALONSO GUEVARA FERN&#193;NDEZ\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Alonso Guevara Fern&#225;ndez is a contributor to the work on Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"AMBER HOAK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Amber Hoak is a contributor to the work on Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"ANDR&#201;S MORALES ESQUIVEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Andr&#233;s Morales Esquivel is a contributor to the work on Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"BEN CUTLER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ben Cutler is a contributor to the work on Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"BILLIE RINALDI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Billie Rinaldi is a contributor to the work on Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"CHRIS SANCHEZ\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chris Sanchez is a contributor to the work on Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"CHRIS TREVINO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chris Trevino is a contributor to the work on Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"CHRISTINE CAGGIANO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Christine Caggiano is a contributor to the work on Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"DAVID TITTSWORTH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">David Tittsworth is a contributor to the work on Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"DAYENNE DE SOUZA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dayenne de Souza is a contributor to the work on Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"DOUGLAS ORBAKER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Douglas Orbaker is a contributor to the work on Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"ED CLARK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ed Clark is a contributor to the work on Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"GABRIEL NIEVES-PONCE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gabriel Nieves-Ponce is a contributor to the work on Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"GAUDY BLANCO MENESES\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gaudy Blanco Meneses is a contributor to the work on Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"KATE LYTVYNETS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kate Lytvynets is a contributor to the work on Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"KATY SMITH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Katy Smith is a contributor to the work on Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"M&#211;NICA CARVAJAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">M&#243;nica Carvajal is a contributor to the work on Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"NATHAN EVANS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nathan Evans is a contributor to the work on Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"RICHARD ORTEGA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Richard Ortega is a contributor to the work on Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"RODRIGO RACANICCI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Rodrigo Racanicci is a contributor to the work on Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"SARAH SMITH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sarah Smith is a contributor to the work on Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"SHANE SOLOMON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shane Solomon is a contributor to the work on Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"GPT-4 TECHNICAL REPORT\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The GPT-4 technical report is a document detailing the capabilities and features of GPT-4<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"GEMINI\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Gemini is a family of highly capable multimodal models<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"KNOWLEDGE-AUGMENTED LANGUAGE MODEL PROMPTING\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">A method for zero-shot knowledge graph question answering<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"QUERY TOOLS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Tools used for querying data and discovering causal relationships<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"QUERY FOCUSED ABSTRACTIVE SUMMARIZATION\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">A method that incorporates query relevance, multi-document coverage, and summary length constraints into seq2seq models<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"FAST UNFOLDING OF COMMUNITIES\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">A method for detecting communities in large networks<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"NALLM\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">NaLLM is a system that can create and reason over knowledge graphs in Neo4J format<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"GRAPHRAG\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">GraphRAG is a system that can create and reason over knowledge graphs in Nebula-Graph format<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"SENSEMAKING QUESTIONS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Sensemaking questions are a class of questions used to evaluate the performance of Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"CORPORA\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Corpora refer to collections of text data used in the evaluation of Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"DATASET\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Dataset refers to the collection of data used for evaluating Graph RAG<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"USER QUERIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">User queries are questions or requests made by users to retrieve information from the graph index<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"COMMUNITY SUMMARIES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Community summaries are summaries of root-level communities in the entity-based graph index<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"COMMUNITY HIERARCHY\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Community hierarchy refers to the hierarchical structure of communities in the graph index<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"MAP-REDUCE SUMMARIZATION\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Map-Reduce summarization is a method used for global summarization of source texts<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"PYTHON\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Python is the programming language used for the implementation of Graph RAG approaches<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"ARXIV\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">arXiv is a repository where the GPT-4 technical report and other related papers are published<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"J. ACHIAM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">J. Achiam is an author of the GPT-4 technical report<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"S. ADLER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">S. Adler is an author of the GPT-4 technical report<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"S. AGARWAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">S. Agarwal is an author of the GPT-4 technical report<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"L. AHMAD\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">L. Ahmad is an author of the GPT-4 technical report<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"I. AKKAYA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">I. Akkaya is an author of the GPT-4 technical report<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"F. L. ALEMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">F. L. Aleman is an author of the GPT-4 technical report<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"D. ALMEIDA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">D. Almeida is an author of the GPT-4 technical report<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"J. ALTENSCHMIDT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">J. Altenschmidt is an author of the GPT-4 technical report<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"S. ALTMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">S. Altman is an author of the GPT-4 technical report<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"S. ANADKAT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">S. Anadkat is an author of the GPT-4 technical report<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"R. ANIL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">R. Anil is an author of the Gemini paper<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"S. BORGEAUD\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">S. Borgeaud is an author of the Gemini paper<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"Y. WU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Y. Wu is an author of the Gemini paper<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"J.-B. ALAYRAC\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">J.-B. Alayrac is an author of the Gemini paper<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"J. YU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">J. Yu is an author of the Gemini paper<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"R. SORICUT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">R. Soricut is an author of the Gemini paper<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"J. SCHALKWYK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">J. Schalkwyk is an author of the Gemini paper<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"A. M. DAI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A. M. Dai is an author of the Gemini paper<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"A. HAUTH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A. Hauth is an author of the Gemini paper<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"J. BAEK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">J. Baek is an author of the paper on knowledge-augmented language model prompting<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"A. F. AJI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A. F. Aji is an author of the paper on knowledge-augmented language model prompting<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"A. SAFFARI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A. Saffari is an author of the paper on knowledge-augmented language model prompting<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"T. BAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">T. Ban is an author of the paper on harnessing large language models for advanced causal discovery<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"L. CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">L. Chen is an author of the paper on harnessing large language models for advanced causal discovery<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"X. WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">X. Wang is an author of the paper on harnessing large language models for advanced causal discovery<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"H. CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">H. Chen is an author of the paper on harnessing large language models for advanced causal discovery<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"T. BAUMEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">T. Baumel is an author of the paper on query focused abstractive summarization<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"M. EYAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">M. Eyal is an author of the paper on query focused abstractive summarization<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"M. ELHADAD\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">M. Elhadad is an author of the paper on query focused abstractive summarization<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"V. D. BLONDEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">V. D. Blondel is an author of the paper on fast unfolding of communities in large networks<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"J.-L. GUILLAUME\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">J.-L. Guillaume is an author of the paper on fast unfolding of communities in large networks<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"R. LAMBIOTTE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">R. Lambiotte is an author of the paper on fast unfolding of communities in large networks<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <node id=\"E. LEFEBVRE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">E. Lefebvre is an author of the paper on fast unfolding of communities in large networks<\/data>      <data key=\"d2\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/node>    <edge source=\"GRAPH-BASED RAG APPLICATIONS\" target=\"NEO4J\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Neo4J is a format used in graph-based RAG applications<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH-BASED RAG APPLICATIONS\" target=\"NEBULA-GRAPH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Nebula-Graph is a format used in graph-based RAG applications<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"NEO4J\" target=\"NALLM\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">NaLLM uses Neo4J format for creating and reasoning over knowledge graphs<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"NEBULA-GRAPH\" target=\"GRAPHRAG\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">GraphRAG uses Nebula-Graph format for creating and reasoning over knowledge graphs<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"GRAPH INDEX\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Graph RAG uses a graph index to partition data for global summarization<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"RAG\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Graph RAG combines knowledge graph generation with Retrieval-Augmented Generation (RAG)<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"QFS\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Graph RAG uses Query-Focused Summarization (QFS) to support human sensemaking<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"MAP-REDUCE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Graph RAG is compared to a graph-free approach using map-reduce for global summarization<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"SELF-CHECKGPT\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">SelfCheckGPT is suggested for comparing fabrication rates in the analysis of Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"ALONSO GUEVARA FERN&#193;NDEZ\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Alonso Guevara Fern&#225;ndez contributed to the work on Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"AMBER HOAK\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Amber Hoak contributed to the work on Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"ANDR&#201;S MORALES ESQUIVEL\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Andr&#233;s Morales Esquivel contributed to the work on Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"BEN CUTLER\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Ben Cutler contributed to the work on Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"BILLIE RINALDI\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Billie Rinaldi contributed to the work on Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"CHRIS SANCHEZ\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Chris Sanchez contributed to the work on Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"CHRIS TREVINO\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Chris Trevino contributed to the work on Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"CHRISTINE CAGGIANO\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Christine Caggiano contributed to the work on Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"DAVID TITTSWORTH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">David Tittsworth contributed to the work on Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"DAYENNE DE SOUZA\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Dayenne de Souza contributed to the work on Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"DOUGLAS ORBAKER\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Douglas Orbaker contributed to the work on Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"ED CLARK\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Ed Clark contributed to the work on Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"GABRIEL NIEVES-PONCE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Gabriel Nieves-Ponce contributed to the work on Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"GAUDY BLANCO MENESES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Gaudy Blanco Meneses contributed to the work on Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"KATE LYTVYNETS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Kate Lytvynets contributed to the work on Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"KATY SMITH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Katy Smith contributed to the work on Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"M&#211;NICA CARVAJAL\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">M&#243;nica Carvajal contributed to the work on Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"NATHAN EVANS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Nathan Evans contributed to the work on Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"RICHARD ORTEGA\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Richard Ortega contributed to the work on Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"RODRIGO RACANICCI\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Rodrigo Racanicci contributed to the work on Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"SARAH SMITH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Sarah Smith contributed to the work on Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"SHANE SOLOMON\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Shane Solomon contributed to the work on Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"SENSEMAKING QUESTIONS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Sensemaking questions are used to evaluate the performance of Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"CORPORA\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Corpora are collections of text data used in the evaluation of Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"DATASET\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Dataset refers to the collection of data used for evaluating Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"USER QUERIES\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">User queries are used to retrieve information from the graph index in Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"COMMUNITY SUMMARIES\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Community summaries are summaries of root-level communities in the entity-based graph index used in Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"COMMUNITY HIERARCHY\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Community hierarchy refers to the hierarchical structure of communities in the graph index used in Graph RAG<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"MAP-REDUCE SUMMARIZATION\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Map-Reduce summarization is a method compared to Graph RAG for global summarization<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GRAPH RAG\" target=\"PYTHON\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Python is the programming language used for the implementation of Graph RAG approaches<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GPT-4 TECHNICAL REPORT\" target=\"ARXIV\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">arXiv is the repository where the GPT-4 technical report is published<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GPT-4 TECHNICAL REPORT\" target=\"J. ACHIAM\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">J. Achiam is an author of the GPT-4 technical report<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GPT-4 TECHNICAL REPORT\" target=\"S. ADLER\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">S. Adler is an author of the GPT-4 technical report<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GPT-4 TECHNICAL REPORT\" target=\"S. AGARWAL\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">S. Agarwal is an author of the GPT-4 technical report<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GPT-4 TECHNICAL REPORT\" target=\"L. AHMAD\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">L. Ahmad is an author of the GPT-4 technical report<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GPT-4 TECHNICAL REPORT\" target=\"I. AKKAYA\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">I. Akkaya is an author of the GPT-4 technical report<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GPT-4 TECHNICAL REPORT\" target=\"F. L. ALEMAN\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">F. L. Aleman is an author of the GPT-4 technical report<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GPT-4 TECHNICAL REPORT\" target=\"D. ALMEIDA\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">D. Almeida is an author of the GPT-4 technical report<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GPT-4 TECHNICAL REPORT\" target=\"J. ALTENSCHMIDT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">J. Altenschmidt is an author of the GPT-4 technical report<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GPT-4 TECHNICAL REPORT\" target=\"S. ALTMAN\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">S. Altman is an author of the GPT-4 technical report<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GPT-4 TECHNICAL REPORT\" target=\"S. ANADKAT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">S. Anadkat is an author of the GPT-4 technical report<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GEMINI\" target=\"R. ANIL\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">R. Anil is an author of the Gemini paper<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GEMINI\" target=\"S. BORGEAUD\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">S. Borgeaud is an author of the Gemini paper<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GEMINI\" target=\"Y. WU\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Y. Wu is an author of the Gemini paper<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GEMINI\" target=\"J.-B. ALAYRAC\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">J.-B. Alayrac is an author of the Gemini paper<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GEMINI\" target=\"J. YU\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">J. Yu is an author of the Gemini paper<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GEMINI\" target=\"R. SORICUT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">R. Soricut is an author of the Gemini paper<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GEMINI\" target=\"J. SCHALKWYK\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">J. Schalkwyk is an author of the Gemini paper<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GEMINI\" target=\"A. M. DAI\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">A. M. Dai is an author of the Gemini paper<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"GEMINI\" target=\"A. HAUTH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">A. Hauth is an author of the Gemini paper<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"KNOWLEDGE-AUGMENTED LANGUAGE MODEL PROMPTING\" target=\"J. BAEK\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">J. Baek is an author of the paper on knowledge-augmented language model prompting<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"KNOWLEDGE-AUGMENTED LANGUAGE MODEL PROMPTING\" target=\"A. F. AJI\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">A. F. Aji is an author of the paper on knowledge-augmented language model prompting<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"KNOWLEDGE-AUGMENTED LANGUAGE MODEL PROMPTING\" target=\"A. SAFFARI\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">A. Saffari is an author of the paper on knowledge-augmented language model prompting<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"QUERY TOOLS\" target=\"T. BAN\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">T. Ban is an author of the paper on harnessing large language models for advanced causal discovery<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"QUERY TOOLS\" target=\"L. CHEN\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">L. Chen is an author of the paper on harnessing large language models for advanced causal discovery<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"QUERY TOOLS\" target=\"X. WANG\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">X. Wang is an author of the paper on harnessing large language models for advanced causal discovery<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"QUERY TOOLS\" target=\"H. CHEN\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">H. Chen is an author of the paper on harnessing large language models for advanced causal discovery<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"QUERY FOCUSED ABSTRACTIVE SUMMARIZATION\" target=\"T. BAUMEL\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">T. Baumel is an author of the paper on query focused abstractive summarization<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"QUERY FOCUSED ABSTRACTIVE SUMMARIZATION\" target=\"M. EYAL\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">M. Eyal is an author of the paper on query focused abstractive summarization<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"QUERY FOCUSED ABSTRACTIVE SUMMARIZATION\" target=\"M. ELHADAD\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">M. Elhadad is an author of the paper on query focused abstractive summarization<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"FAST UNFOLDING OF COMMUNITIES\" target=\"V. D. BLONDEL\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">V. D. Blondel is an author of the paper on fast unfolding of communities in large networks<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"FAST UNFOLDING OF COMMUNITIES\" target=\"J.-L. GUILLAUME\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">J.-L. Guillaume is an author of the paper on fast unfolding of communities in large networks<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"FAST UNFOLDING OF COMMUNITIES\" target=\"R. LAMBIOTTE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">R. Lambiotte is an author of the paper on fast unfolding of communities in large networks<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>    <edge source=\"FAST UNFOLDING OF COMMUNITIES\" target=\"E. LEFEBVRE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">E. Lefebvre is an author of the paper on fast unfolding of communities in large networks<\/data>      <data key=\"d5\">ac21ebe9a9d70d691c717f961d3f10c8<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"aa79049289e6532592eec17b9e76adfb","chunk":" summary length constraints into seq2seq\nmodels. arXiv preprint arXiv:1801.07704 .\nBlondel, V . D., Guillaume, J.-L., Lambiotte, R., and Lefebvre, E. (2008). Fast unfolding of\ncommunities in large networks. Journal of statistical mechanics: theory and experiment ,\n2008(10):P10008.\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam,\nP., Sastry, G., Askell, A., et al. (2020). Language models are few-shot learners. Advances in\nneural information processing systems , 33:1877\u20131901.\nCheng, X., Luo, D., Chen, X., Liu, L., Zhao, D., and Yan, R. (2024). Lift yourself up: Retrieval-\naugmented text generation with self-memory. Advances in Neural Information Processing Sys-\ntems, 36.\nDang, H. T. (2006). Duc 2005: Evaluation of question-focused summarization systems. In Proceed-\nings of the Workshop on Task-Focused Summarization and Question Answering , pages 48\u201355.\nEs, S., James, J., Espinosa-Anke, L., and Schockaert, S. (2023). Ragas: Automated evaluation of\nretrieval augmented generation. arXiv preprint arXiv:2309.15217 .\nFeng, Z., Feng, X., Zhao, D., Yang, M., and Qin, B. (2023). Retrieval-generation synergy augmented\nlarge language models. arXiv preprint arXiv:2310.05149 .\nFortunato, S. (2010). Community detection in graphs. Physics reports , 486(3-5):75\u2013174.\nGao, Y ., Xiong, Y ., Gao, X., Jia, K., Pan, J., Bi, Y ., Dai, Y ., Sun, J., and Wang, H. (2023). Retrieval-\naugmented generation for large language models: A survey. arXiv preprint arXiv:2312.10997 .\nGoodwin, T. R., Savery, M. E., and Demner-Fushman, D. (2020). Flight of the pegasus? comparing\ntransformers on few-shot and zero-shot multi-document abstractive summarization. In Proceed-\nings of COLING. International Conference on Computational Linguistics , volume 2020, page\n5640. NIH Public Access.\nHe, X., Tian, Y ., Sun, Y ., Chawla, N. V ., Laurent, T., LeCun, Y ., Bresson, X., and Hooi, B. (2024).\nG-retriever: Retrieval-augmented generation for textual graph understanding and question an-\nswering. arXiv preprint arXiv:2402.07630 .\n12Jacomy, M., Venturini, T., Heymann, S., and Bastian, M. (2014). Forceatlas2, a continuous graph\nlayout algorithm for handy network visualization designed for the gephi software. PLoS ONE\n9(6): e98679. https:\/\/doi.org\/10.1371\/journal.pone.0098679 .\nJin, D., Yu, Z., Jiao, P., Pan, S., He, D., Wu, J., Philip, S. Y ., and Zhang, W. (2021). A survey of\ncommunity detection approaches: From statistical modeling to deep learning. IEEE Transactions\non Knowledge and Data Engineering , 35(2):1149\u20131170.\nKang, M., Kwak, J. M., Baek, J., and Hwang, S. J. (2023). Knowledge graph-augmented language\nmodels for knowledge-grounded dialogue generation. arXiv preprint arXiv:2305.18846 .\nKhattab, O., Santhanam, K., Li, X. L., Hall, D., Liang, P., Potts, C., and Zaharia, M. (2022).\nDemonstrate-search-predict: Composing retrieval and language models for knowledge-intensive\nnlp. arXiv preprint arXiv:2212.14024 .\nKim, G., Kim, S., Jeon, B., Park, J., and Kang, J. (2023). Tree of clarifications: Answering ambigu-\nous questions with retrieval-augmented large language models. arXiv preprint arXiv:2310.14696 .\nKlein, G., Moon, B., and Hoffman, R. R. (2006a). Making sense of sensemaking 1: Alternative\nperspectives. IEEE intelligent systems , 21(4):70\u201373.\nKlein, G., Moon, B., and Hoffman, R. R. (2006b). Making sense of sensemaking 2: A macrocogni-\ntive model. IEEE Intelligent systems , 21(5):88\u201392.\nKoesten, L., Gregory, K., Groth, P., and Simperl, E. (2021). Talking datasets\u2013understanding data\nsensemaking behaviours. International journal of human-computer studies , 146:102562.\nKuratov, Y ., Bulatov, A., Anokhin, P., Sorokin, D., Sorokin, A., and Burtsev, M. (202","chunk_id":"aa79049289e6532592eec17b9e76adfb","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":1200,"entities":[{"name":"BLONDEL, V. D.","type":"PERSON","description":"Blondel, V. D. is an author of the paper \"Fast unfolding of communities in large networks\"","source_id":"aa79049289e6532592eec17b9e76adfb"},{"name":"GUILLAUME, J.-L.","type":"PERSON","description":"Guillaume, J.-L. is an author of the paper \"Fast unfolding of communities in large networks\"","source_id":"aa79049289e6532592eec17b9e76adfb"},{"name":"LAMBIOTTE, R.","type":"PERSON","description":"Lambiotte, R. is an author of the paper \"Fast unfolding of communities in large networks\"","source_id":"aa79049289e6532592eec17b9e76adfb"},{"name":"LEFEBVRE, E.","type":"PERSON","description":"Lefebvre, E. is an author of the paper \"Fast unfolding of communities in large networks\"","source_id":"aa79049289e6532592eec17b9e76adfb"},{"name":"JOURNAL OF STATISTICAL MECHANICS: THEORY AND EXPERIMENT","type":"PUBLICATION","description":"The journal where the paper \"Fast unfolding of communities in large networks\" was published","source_id":"aa79049289e6532592eec17b9e76adfb"},{"name":"BROWN, T.","type":"PERSON","description":"Brown, T. is an author of the paper \"Language models are few-shot learners\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"MANN, B.","type":"PERSON","description":"Mann, B. is an author of the paper \"Language models are few-shot learners\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"RYDER, N.","type":"PERSON","description":"Ryder, N. is an author of the paper \"Language models are few-shot learners\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"SUBBIAH, M.","type":"PERSON","description":"Subbiah, M. is an author of the paper \"Language models are few-shot learners\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"KAPLAN, J. D.","type":"PERSON","description":"Kaplan, J. D. is an author of the paper \"Language models are few-shot learners\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"DHARIWAL, P.","type":"PERSON","description":"Dhariwal, P. is an author of the paper \"Language models are few-shot learners\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"NEELAKANTAN, A.","type":"PERSON","description":"Neelakantan, A. is an author of the paper \"Language models are few-shot learners\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"SHYAM, P.","type":"PERSON","description":"Shyam, P. is an author of the paper \"Language models are few-shot learners\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"SASTRY, G.","type":"PERSON","description":"Sastry, G. is an author of the paper \"Language models are few-shot learners\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"ASKELL, A.","type":"PERSON","description":"Askell, A. is an author of the paper \"Language models are few-shot learners\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS","type":"PUBLICATION","description":"The conference where the paper \"Language models are few-shot learners\" was presented","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PUBLICATION"},{"name":"CHENG, X.","type":"PERSON","description":"Cheng, X. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"LUO, D.","type":"PERSON","description":"Luo, D. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"CHEN, X.","type":"PERSON","description":"Chen, X. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"LIU, L.","type":"PERSON","description":"Liu, L. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"ZHAO, D.","type":"PERSON","description":"Zhao, D. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"\nZhao, D. is an author of the paper \"Retrieval-generation synergy augmented large language models\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"YAN, R.","type":"PERSON","description":"Yan, R. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"DANG, H. T.","type":"PERSON","description":"Dang, H. T. is an author of the paper \"Duc 2005: Evaluation of question-focused summarization systems\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"PROCEEDINGS OF THE WORKSHOP ON TASK-FOCUSED SUMMARIZATION AND QUESTION ANSWERING","type":"PUBLICATION","description":"The workshop where the paper \"Duc 2005: Evaluation of question-focused summarization systems\" was presented","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PUBLICATION"},{"name":"ES, S.","type":"PERSON","description":"Es, S. is an author of the paper \"Ragas: Automated evaluation of retrieval augmented generation\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"JAMES, J.","type":"PERSON","description":"James, J. is an author of the paper \"Ragas: Automated evaluation of retrieval augmented generation\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"ESPINOSA-ANKE, L.","type":"PERSON","description":"Espinosa-Anke, L. is an author of the paper \"Ragas: Automated evaluation of retrieval augmented generation\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"SCHOCKAERT, S.","type":"PERSON","description":"Schockaert, S. is an author of the paper \"Ragas: Automated evaluation of retrieval augmented generation\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"FENG, Z.","type":"PERSON","description":"Feng, Z. is an author of the paper \"Retrieval-generation synergy augmented large language models\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"FENG, X.","type":"PERSON","description":"Feng, X. is an author of the paper \"Retrieval-generation synergy augmented large language models\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"YANG, M.","type":"PERSON","description":"Yang, M. is an author of the paper \"Retrieval-generation synergy augmented large language models\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"QIN, B.","type":"PERSON","description":"Qin, B. is an author of the paper \"Retrieval-generation synergy augmented large language models\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"FORTUNATO, S.","type":"PERSON","description":"Fortunato, S. is an author of the paper \"Community detection in graphs\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"PHYSICS REPORTS","type":"PUBLICATION","description":"The journal where the paper \"Community detection in graphs\" was published","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PUBLICATION"},{"name":"GAO, Y.","type":"PERSON","description":"Gao, Y. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"XIONG, Y.","type":"PERSON","description":"Xiong, Y. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"GAO, X.","type":"PERSON","description":"Gao, X. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"JIA, K.","type":"PERSON","description":"Jia, K. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"PAN, J.","type":"PERSON","description":"Pan, J. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"BI, Y.","type":"PERSON","description":"Bi, Y. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"DAI, Y.","type":"PERSON","description":"Dai, Y. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"SUN, J.","type":"PERSON","description":"Sun, J. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"WANG, H.","type":"PERSON","description":"Wang, H. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"GOODWIN, T. R.","type":"PERSON","description":"Goodwin, T. R. is an author of the paper \"Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"SAVERY, M. E.","type":"PERSON","description":"Savery, M. E. is an author of the paper \"Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"DEMNER-FUSHMAN, D.","type":"PERSON","description":"Demner-Fushman, D. is an author of the paper \"Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"PROCEEDINGS OF COLING. INTERNATIONAL CONFERENCE ON COMPUTATIONAL LINGUISTICS","type":"PUBLICATION","description":"The conference where the paper \"Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization\" was presented","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PUBLICATION"},{"name":"HE, X.","type":"PERSON","description":"He, X. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"TIAN, Y.","type":"PERSON","description":"Tian, Y. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"SUN, Y.","type":"PERSON","description":"Sun, Y. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"CHAWLA, N. V.","type":"PERSON","description":"Chawla, N. V. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"LAURENT, T.","type":"PERSON","description":"Laurent, T. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"LECUN, Y.","type":"PERSON","description":"LeCun, Y. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"BRESSON, X.","type":"PERSON","description":"Bresson, X. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"HOOI, B.","type":"PERSON","description":"Hooi, B. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"JACOMY, M.","type":"PERSON","description":"Jacomy, M. is an author of the paper \"Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"VENTURINI, T.","type":"PERSON","description":"Venturini, T. is an author of the paper \"Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"HEYMANN, S.","type":"PERSON","description":"Heymann, S. is an author of the paper \"Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"BASTIAN, M.","type":"PERSON","description":"Bastian, M. is an author of the paper \"Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"PLOS ONE","type":"PUBLICATION","description":"The journal where the paper \"Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software\" was published","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PUBLICATION"},{"name":"JIN, D.","type":"PERSON","description":"Jin, D. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"YU, Z.","type":"PERSON","description":"Yu, Z. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"JIAO, P.","type":"PERSON","description":"Jiao, P. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"PAN, S.","type":"PERSON","description":"Pan, S. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"HE, D.","type":"PERSON","description":"He, D. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"WU, J.","type":"PERSON","description":"Wu, J. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"PHILIP, S. Y.","type":"PERSON","description":"Philip, S. Y. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"ZHANG, W.","type":"PERSON","description":"Zhang, W. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING","type":"PUBLICATION","description":"The journal where the paper \"A survey of community detection approaches: From statistical modeling to deep learning\" was published","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PUBLICATION"},{"name":"KANG, M.","type":"PERSON","description":"Kang, M. is an author of the paper \"Knowledge graph-augmented language models for knowledge-grounded dialogue generation\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"KWAK, J. M.","type":"PERSON","description":"Kwak, J. M. is an author of the paper \"Knowledge graph-augmented language models for knowledge-grounded dialogue generation\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"BAEK, J.","type":"PERSON","description":"Baek, J. is an author of the paper \"Knowledge graph-augmented language models for knowledge-grounded dialogue generation\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"HWANG, S. J.","type":"PERSON","description":"Hwang, S. J. is an author of the paper \"Knowledge graph-augmented language models for knowledge-grounded dialogue generation\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"KHATTAB, O.","type":"PERSON","description":"Khattab, O. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"SANTHANAM, K.","type":"PERSON","description":"Santhanam, K. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"LI, X. L.","type":"PERSON","description":"Li, X. L. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"HALL, D.","type":"PERSON","description":"Hall, D. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"LIANG, P.","type":"PERSON","description":"Liang, P. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"POTTS, C.","type":"PERSON","description":"Potts, C. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"ZAHARIA, M.","type":"PERSON","description":"Zaharia, M. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"KIM, G.","type":"PERSON","description":"Kim, G. is an author of the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"KIM, S.","type":"PERSON","description":"Kim, S. is an author of the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"JEON, B.","type":"PERSON","description":"Jeon, B. is an author of the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"PARK, J.","type":"PERSON","description":"Park, J. is an author of the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"KANG, J.","type":"PERSON","description":"Kang, J. is an author of the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"KLEIN, G.","type":"PERSON","description":"Klein, G. is an author of the paper \"Making sense of sensemaking 1: Alternative perspectives\"\nKlein, G. is\nKlein, G. is an author of the paper \"Making sense of sensemaking 2: A macrocognitive model\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"MOON, B.","type":"PERSON","description":"Moon, B. is an author of the paper \"Making sense of sensemaking 1: Alternative perspectives\"\nMoon, B. is an author of the paper \"Making sense of sensemaking 2: A macrocognitive model\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"HOFFMAN, R. R.","type":"PERSON","description":"Hoffman, R. R. is an author of the paper \"Making sense of sensemaking 2: A macrocognitive model\"\nHoffman, R. R. is an author of the paper \"Making sense of sensemaking 1: Alternative perspectives\"","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PERSON"},{"name":"IEEE INTELLIGENT SYSTEMS","type":"PUBLICATION","description":"The journal where the paper \"Making sense of sensemaking 1: Alternative perspectives\" was published\nThe journal where the paper \"Making sense of sensemaking 2: A macrocognitive model\" was published","source_id":"aa79049289e6532592eec17b9e76adfb","entity_type":"PUBLICATION"},{"name":"ARXIV","type":"PUBLICATION","description":"The platform where the paper \"summary length constraints into seq2seq models\" was published","source_id":"aa79049289e6532592eec17b9e76adfb"},{"name":"KOESTEN, L.","type":"PERSON","description":"Koesten, L. is","source_id":"aa79049289e6532592eec17b9e76adfb"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"BLONDEL, V. D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Blondel, V. D. is an author of the paper \"Fast unfolding of communities in large networks\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>    <\/node>    <node id=\"GUILLAUME, J.-L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Guillaume, J.-L. is an author of the paper \"Fast unfolding of communities in large networks\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>    <\/node>    <node id=\"LAMBIOTTE, R.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lambiotte, R. is an author of the paper \"Fast unfolding of communities in large networks\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>    <\/node>    <node id=\"LEFEBVRE, E.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lefebvre, E. is an author of the paper \"Fast unfolding of communities in large networks\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>    <\/node>    <node id=\"JOURNAL OF STATISTICAL MECHANICS: THEORY AND EXPERIMENT\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The journal where the paper \"Fast unfolding of communities in large networks\" was published<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>    <\/node>    <node id=\"BROWN, T.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Brown, T. is an author of the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MANN, B.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mann, B. is an author of the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"RYDER, N.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ryder, N. is an author of the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SUBBIAH, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Subbiah, M. is an author of the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KAPLAN, J. D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kaplan, J. D. is an author of the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DHARIWAL, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dhariwal, P. is an author of the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NEELAKANTAN, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Neelakantan, A. is an author of the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHYAM, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shyam, P. is an author of the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SASTRY, G.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sastry, G. is an author of the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ASKELL, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Askell, A. is an author of the paper \"Language models are few-shot learners\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The conference where the paper \"Language models are few-shot learners\" was presented<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"CHENG, X.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Cheng, X. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LUO, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Luo, D. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHEN, X.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chen, X. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LIU, L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liu, L. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHAO, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhao, D. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"Zhao, D. is an author of the paper \"Retrieval-generation synergy augmented large language models\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YAN, R.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yan, R. is an author of the paper \"Lift yourself up: Retrieval-augmented text generation with self-memory\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DANG, H. T.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dang, H. T. is an author of the paper \"Duc 2005: Evaluation of question-focused summarization systems\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PROCEEDINGS OF THE WORKSHOP ON TASK-FOCUSED SUMMARIZATION AND QUESTION ANSWERING\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The workshop where the paper \"Duc 2005: Evaluation of question-focused summarization systems\" was presented<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"ES, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Es, S. is an author of the paper \"Ragas: Automated evaluation of retrieval augmented generation\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JAMES, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">James, J. is an author of the paper \"Ragas: Automated evaluation of retrieval augmented generation\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ESPINOSA-ANKE, L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Espinosa-Anke, L. is an author of the paper \"Ragas: Automated evaluation of retrieval augmented generation\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SCHOCKAERT, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Schockaert, S. is an author of the paper \"Ragas: Automated evaluation of retrieval augmented generation\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"FENG, Z.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Feng, Z. is an author of the paper \"Retrieval-generation synergy augmented large language models\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"FENG, X.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Feng, X. is an author of the paper \"Retrieval-generation synergy augmented large language models\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YANG, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yang, M. is an author of the paper \"Retrieval-generation synergy augmented large language models\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"QIN, B.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Qin, B. is an author of the paper \"Retrieval-generation synergy augmented large language models\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"FORTUNATO, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Fortunato, S. is an author of the paper \"Community detection in graphs\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PHYSICS REPORTS\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The journal where the paper \"Community detection in graphs\" was published<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"GAO, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gao, Y. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XIONG, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xiong, Y. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GAO, X.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gao, X. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JIA, K.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jia, K. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PAN, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pan, J. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BI, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bi, Y. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DAI, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dai, Y. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SUN, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sun, J. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WANG, H.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wang, H. is an author of the paper \"Retrieval-augmented generation for large language models: A survey\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GOODWIN, T. R.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Goodwin, T. R. is an author of the paper \"Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SAVERY, M. E.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Savery, M. E. is an author of the paper \"Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DEMNER-FUSHMAN, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Demner-Fushman, D. is an author of the paper \"Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PROCEEDINGS OF COLING. INTERNATIONAL CONFERENCE ON COMPUTATIONAL LINGUISTICS\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The conference where the paper \"Flight of the pegasus? comparing transformers on few-shot and zero-shot multi-document abstractive summarization\" was presented<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"HE, X.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">He, X. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TIAN, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tian, Y. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SUN, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sun, Y. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHAWLA, N. V.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chawla, N. V. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LAURENT, T.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Laurent, T. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LECUN, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">LeCun, Y. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BRESSON, X.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bresson, X. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HOOI, B.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hooi, B. is an author of the paper \"G-retriever: Retrieval-augmented generation for textual graph understanding and question answering\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JACOMY, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jacomy, M. is an author of the paper \"Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"VENTURINI, T.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Venturini, T. is an author of the paper \"Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HEYMANN, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Heymann, S. is an author of the paper \"Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BASTIAN, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bastian, M. is an author of the paper \"Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PLOS ONE\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The journal where the paper \"Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software\" was published<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"JIN, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jin, D. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YU, Z.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yu, Z. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JIAO, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jiao, P. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PAN, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pan, S. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HE, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">He, D. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WU, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wu, J. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PHILIP, S. Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Philip, S. Y. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHANG, W.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhang, W. is an author of the paper \"A survey of community detection approaches: From statistical modeling to deep learning\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The journal where the paper \"A survey of community detection approaches: From statistical modeling to deep learning\" was published<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"KANG, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kang, M. is an author of the paper \"Knowledge graph-augmented language models for knowledge-grounded dialogue generation\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KWAK, J. M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kwak, J. M. is an author of the paper \"Knowledge graph-augmented language models for knowledge-grounded dialogue generation\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BAEK, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Baek, J. is an author of the paper \"Knowledge graph-augmented language models for knowledge-grounded dialogue generation\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HWANG, S. J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hwang, S. J. is an author of the paper \"Knowledge graph-augmented language models for knowledge-grounded dialogue generation\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KHATTAB, O.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Khattab, O. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SANTHANAM, K.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Santhanam, K. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LI, X. L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Li, X. L. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HALL, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hall, D. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LIANG, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liang, P. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"POTTS, C.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Potts, C. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZAHARIA, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zaharia, M. is an author of the paper \"Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KIM, G.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kim, G. is an author of the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KIM, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kim, S. is an author of the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JEON, B.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jeon, B. is an author of the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PARK, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Park, J. is an author of the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KANG, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kang, J. is an author of the paper \"Tree of clarifications: Answering ambiguous questions with retrieval-augmented large language models\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KLEIN, G.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Klein, G. is an author of the paper \"Making sense of sensemaking 1: Alternative perspectives\"Klein, G. isKlein, G. is an author of the paper \"Making sense of sensemaking 2: A macrocognitive model\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MOON, B.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Moon, B. is an author of the paper \"Making sense of sensemaking 1: Alternative perspectives\"Moon, B. is an author of the paper \"Making sense of sensemaking 2: A macrocognitive model\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HOFFMAN, R. R.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hoffman, R. R. is an author of the paper \"Making sense of sensemaking 2: A macrocognitive model\"Hoffman, R. R. is an author of the paper \"Making sense of sensemaking 1: Alternative perspectives\"<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"IEEE INTELLIGENT SYSTEMS\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The journal where the paper \"Making sense of sensemaking 1: Alternative perspectives\" was publishedThe journal where the paper \"Making sense of sensemaking 2: A macrocognitive model\" was published<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"ARXIV\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The platform where the paper \"summary length constraints into seq2seq models\" was published<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>    <\/node>    <node id=\"KOESTEN, L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Koesten, L. is<\/data>      <data key=\"d2\">aa79049289e6532592eec17b9e76adfb<\/data>    <\/node>  <\/graph><\/graphml>"}
{"id":"df50c95dff7da074cbb2f68e88686f88","chunk":" , 21(5):88\u201392.\nKoesten, L., Gregory, K., Groth, P., and Simperl, E. (2021). Talking datasets\u2013understanding data\nsensemaking behaviours. International journal of human-computer studies , 146:102562.\nKuratov, Y ., Bulatov, A., Anokhin, P., Sorokin, D., Sorokin, A., and Burtsev, M. (2024). In search\nof needles in a 11m haystack: Recurrent memory finds what llms miss.\nLangChain (2024). Langchain graphs. https:\/\/python .langchain .com\/docs\/use cases\/graph\/.\nLaskar, M. T. R., Hoque, E., and Huang, J. (2020). Query focused abstractive summarization via\nincorporating query relevance and transfer learning with transformer models. In Advances in\nArtificial Intelligence: 33rd Canadian Conference on Artificial Intelligence, Canadian AI 2020,\nOttawa, ON, Canada, May 13\u201315, 2020, Proceedings 33 , pages 342\u2013348. Springer.\nLaskar, M. T. R., Hoque, E., and Huang, J. X. (2022). Domain adaptation with pre-trained transform-\ners for query-focused abstractive text summarization. Computational Linguistics , 48(2):279\u2013320.\nLewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V ., Goyal, N., K \u00a8uttler, H., Lewis, M., Yih,\nW.-t., Rockt \u00a8aschel, T., et al. (2020). Retrieval-augmented generation for knowledge-intensive nlp\ntasks. Advances in Neural Information Processing Systems , 33:9459\u20139474.\nLiu, N. F., Lin, K., Hewitt, J., Paranjape, A., Bevilacqua, M., Petroni, F., and Liang, P. (2023). Lost\nin the middle: How language models use long contexts. arXiv:2307.03172.\nLiu, Y . and Lapata, M. (2019). Hierarchical transformers for multi-document summarization. arXiv\npreprint arXiv:1905.13164 .\nLlamaIndex (2024). LlamaIndex Knowledge Graph Index. https:\/\/docs .llamaindex .ai\/en\/stable\/\nexamples\/index structs\/knowledge graph\/KnowledgeGraphDemo .html.\nManakul, P., Liusie, A., and Gales, M. J. (2023). Selfcheckgpt: Zero-resource black-box hallucina-\ntion detection for generative large language models. arXiv preprint arXiv:2303.08896 .\nMao, Y ., He, P., Liu, X., Shen, Y ., Gao, J., Han, J., and Chen, W. (2020). Generation-augmented\nretrieval for open-domain question answering. arXiv preprint arXiv:2009.08553 .\nMartin, S., Brown, W. M., Klavans, R., and Boyack, K. (2011). Openord: An open-source toolbox\nfor large graph layout. SPIE Conference on Visualization and Data Analysis (VDA) .\nMicrosoft (2023). The impact of large language models on scientific discovery: a preliminary study\nusing gpt-4.\n13NebulaGraph (2024). Nebulagraph launches industry-first graph rag: Retrieval-augmented genera-\ntion with llm based on knowledge graphs. https:\/\/www .nebula-graph .io\/posts\/graph-RAG.\nNeo4J (2024). Project NaLLM. https:\/\/github .com\/neo4j\/NaLLM.\nNewman, M. E. (2006). Modularity and community structure in networks. Proceedings of the\nnational academy of sciences , 103(23):8577\u20138582.\nRam, O., Levine, Y ., Dalmedigos, I., Muhlgay, D., Shashua, A., Leyton-Brown, K., and Shoham,\nY . (2023). In-context retrieval-augmented language models. Transactions of the Association for\nComputational Linguistics , 11:1316\u20131331.\nRanade, P. and Joshi, A. (2023). Fabula: Intelligence report generation using retrieval-augmented\nnarrative construction. arXiv preprint arXiv:2310.13848 .\nSarthi, P., Abdullah, S., Tuli, A., Khanna, S., Goldie, A., and Manning, C. D. (2024). Raptor:\nRecursive abstractive processing for tree-organized retrieval. arXiv preprint arXiv:2401.18059 .\nScott, K. (2024). Behind the Tech. https:\/\/www .microsoft .com\/en-us\/behind-the-tech.\nShao, Z., Gong, Y ., Shen, Y ., Huang, M., Duan, N., and Chen, W. (2023). Enhancing retrieval-\naugmented large language models with iterative retrieval-generation synergy. arXiv preprint\narXiv:2305.15294 .\nSu, D., Xu, Y ., Yu, T., Siddique, F. B., Barezi, E. J., and Fung, P. (2020). Caire-covid: A ques-\ntion answering and query-focused multi-document summarization","chunk_id":"df50c95dff7da074cbb2f68e88686f88","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":1200,"entities":[{"name":"KOESTEN, L.","type":"PERSON","description":"Koesten, L. is an author of the paper \"Talking datasets\u2013understanding data sensemaking behaviours\"","source_id":"df50c95dff7da074cbb2f68e88686f88"},{"name":"GREGORY, K.","type":"PERSON","description":"Gregory, K. is an author of the paper \"Talking datasets\u2013understanding data sensemaking behaviours\"","source_id":"df50c95dff7da074cbb2f68e88686f88"},{"name":"GROTH, P.","type":"PERSON","description":"Groth, P. is an author of the paper \"Talking datasets\u2013understanding data sensemaking behaviours\"","source_id":"df50c95dff7da074cbb2f68e88686f88"},{"name":"SIMPERL, E.","type":"PERSON","description":"Simperl, E. is an author of the paper \"Talking datasets\u2013understanding data sensemaking behaviours\"","source_id":"df50c95dff7da074cbb2f68e88686f88"},{"name":"INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES","type":"PUBLICATION","description":"The journal where the paper \"Talking datasets\u2013understanding data sensemaking behaviours\" was published","source_id":"df50c95dff7da074cbb2f68e88686f88"},{"name":"KURATOV, Y.","type":"PERSON","description":"Kuratov, Y. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"","source_id":"df50c95dff7da074cbb2f68e88686f88"},{"name":"BULATOV, A.","type":"PERSON","description":"Bulatov, A. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"","source_id":"df50c95dff7da074cbb2f68e88686f88"},{"name":"ANOKHIN, P.","type":"PERSON","description":"Anokhin, P. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"","source_id":"df50c95dff7da074cbb2f68e88686f88"},{"name":"SOROKIN, D.","type":"PERSON","description":"Sorokin, D. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"","source_id":"df50c95dff7da074cbb2f68e88686f88"},{"name":"SOROKIN, A.","type":"PERSON","description":"Sorokin, A. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"","source_id":"df50c95dff7da074cbb2f68e88686f88"},{"name":"BURTSEV, M.","type":"PERSON","description":"Burtsev, M. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"","source_id":"df50c95dff7da074cbb2f68e88686f88"},{"name":"LANGCHAIN","type":"ORGANIZATION","description":"LangChain is the organization behind the LangChain graphs project","source_id":"df50c95dff7da074cbb2f68e88686f88"},{"name":"LASKAR, M. T. R.","type":"PERSON","description":"Laskar, M. T. R. is an author of the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"","source_id":"df50c95dff7da074cbb2f68e88686f88"},{"name":"HOQUE, E.","type":"PERSON","description":"Hoque, E. is an author of the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"","source_id":"df50c95dff7da074cbb2f68e88686f88"},{"name":"HUANG, J.","type":"PERSON","description":"Huang, J. is an author of the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"","source_id":"df50c95dff7da074cbb2f68e88686f88"},{"name":"ADVANCES IN ARTIFICIAL INTELLIGENCE","type":"PUBLICATION","description":"The conference where the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\" was presented","source_id":"df50c95dff7da074cbb2f68e88686f88"},{"name":"COMPUTATIONAL LINGUISTICS","type":"PUBLICATION","description":"The journal where the paper \"Domain adaptation with pre-trained transformers for query-focused abstractive text summarization\" was published","source_id":"df50c95dff7da074cbb2f68e88686f88"},{"name":"LEWIS, P.","type":"PERSON","description":"Lewis, P. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"PEREZ, E.","type":"PERSON","description":"Perez, E. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"PIKTUS, A.","type":"PERSON","description":"Piktus, A. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"PETRONI, F.","type":"PERSON","description":"Petroni, F. is an author of the paper \"Lost in the middle: How language models use long contexts\"\nPetroni, F. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"KARPUKHIN, V.","type":"PERSON","description":"Karpukhin, V. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"GOYAL, N.","type":"PERSON","description":"Goyal, N. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"K\u00dcTTLER, H.","type":"PERSON","description":"K\u00fcttler, H. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"LEWIS, M.","type":"PERSON","description":"Lewis, M. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"YIH, W.-T.","type":"PERSON","description":"Yih, W.-T. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"ROCKT\u00c4SCHEL, T.","type":"PERSON","description":"Rockt\u00e4schel, T. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS","type":"PUBLICATION","description":"The conference where the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\" was presented","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"CONFERENCE"},{"name":"LIU, N. F.","type":"PERSON","description":"Liu, N. F. is an author of the paper \"Lost in the middle: How language models use long contexts\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"LIN, K.","type":"PERSON","description":"Lin, K. is an author of the paper \"Lost in the middle: How language models use long contexts\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"HEWITT, J.","type":"PERSON","description":"Hewitt, J. is an author of the paper \"Lost in the middle: How language models use long contexts\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"PARANJAPE, A.","type":"PERSON","description":"Paranjape, A. is an author of the paper \"Lost in the middle: How language models use long contexts\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"BEVILACQUA, M.","type":"PERSON","description":"Bevilacqua, M. is an author of the paper \"Lost in the middle: How language models use long contexts\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"LIANG, P.","type":"PERSON","description":"Liang, P. is an author of the paper \"Lost in the middle: How language models use long contexts\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"ARXIV","type":"PUBLICATION","description":"The repository where the paper \"Fabula: Intelligence report generation using retrieval-augmented narrative construction\" was published\nThe repository where the paper \"Lost in the middle: How language models use long contexts\" was published\nThe repository where the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\" was published","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"REPOSITORY"},{"name":"LIU, Y.","type":"PERSON","description":"Liu, Y. is an author of the paper \"Hierarchical transformers for multi-document summarization\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"LAPATA, M.","type":"PERSON","description":"Lapata, M. is an author of the paper \"Hierarchical transformers for multi-document summarization\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"LLAMAINDEX","type":"ORGANIZATION","description":"LlamaIndex is the organization behind the LlamaIndex Knowledge Graph Index project","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"ORGANIZATION"},{"name":"MANAKUL, P.","type":"PERSON","description":"Manakul, P. is an author of the paper \"Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"LIUSIE, A.","type":"PERSON","description":"Liusie, A. is an author of the paper \"Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"GALES, M. J.","type":"PERSON","description":"Gales, M. J. is an author of the paper \"Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"MAO, Y.","type":"PERSON","description":"Mao, Y. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"HE, P.","type":"PERSON","description":"He, P. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"LIU, X.","type":"PERSON","description":"Liu, X. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"SHEN, Y.","type":"PERSON","description":"Shen, Y. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"\nShen, Y. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"GAO, J.","type":"PERSON","description":"Gao, J. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"HAN, J.","type":"PERSON","description":"Han, J. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"CHEN, W.","type":"PERSON","description":"Chen, W. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"\nChen, W. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"SPIE CONFERENCE ON VISUALIZATION AND DATA ANALYSIS (VDA)","type":"PUBLICATION","description":"The conference where the paper \"Openord: An open-source toolbox for large graph layout\" was presented","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"CONFERENCE"},{"name":"MARTIN, S.","type":"PERSON","description":"Martin, S. is an author of the paper \"Openord: An open-source toolbox for large graph layout\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"BROWN, W. M.","type":"PERSON","description":"Brown, W. M. is an author of the paper \"Openord: An open-source toolbox for large graph layout\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"KLAVANS, R.","type":"PERSON","description":"Klavans, R. is an author of the paper \"Openord: An open-source toolbox for large graph layout\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"BOYACK, K.","type":"PERSON","description":"Boyack, K. is an author of the paper \"Openord: An open-source toolbox for large graph layout\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"MICROSOFT","type":"ORGANIZATION","description":"Microsoft is the organization behind the study \"The impact of large language models on scientific discovery: a preliminary study using gpt-4\"\nMicrosoft is the organization behind the podcast \"Behind the Tech\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"ORGANIZATION"},{"name":"NEBULAGRAPH","type":"ORGANIZATION","description":"NebulaGraph is the organization behind the project \"Nebulagraph launches industry-first graph rag: Retrieval-augmented generation with llm based on knowledge graphs\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"ORGANIZATION"},{"name":"NEO4J","type":"ORGANIZATION","description":"Neo4J is the organization behind the project \"Project NaLLM\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"ORGANIZATION"},{"name":"NEWMAN, M. E.","type":"PERSON","description":"Newman, M. E. is an author of the paper \"Modularity and community structure in networks\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES","type":"PUBLICATION","description":"The journal where the paper \"Modularity and community structure in networks\" was published","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"JOURNAL"},{"name":"RAM, O.","type":"PERSON","description":"Ram, O. is an author of the paper \"In-context retrieval-augmented language models\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"LEVINE, Y.","type":"PERSON","description":"Levine, Y. is an author of the paper \"In-context retrieval-augmented language models\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"DALMEDIGOS, I.","type":"PERSON","description":"Dalmedigos, I. is an author of the paper \"In-context retrieval-augmented language models\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"MUHLGAY, D.","type":"PERSON","description":"Muhlgay, D. is an author of the paper \"In-context retrieval-augmented language models\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"SHASHUA, A.","type":"PERSON","description":"Shashua, A. is an author of the paper \"In-context retrieval-augmented language models\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"LEYTON-BROWN, K.","type":"PERSON","description":"Leyton-Brown, K. is an author of the paper \"In-context retrieval-augmented language models\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"SHOHAM, Y.","type":"PERSON","description":"Shoham, Y. is an author of the paper \"In-context retrieval-augmented language models\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS","type":"PUBLICATION","description":"The journal where the paper \"In-context retrieval-augmented language models\" was published","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"JOURNAL"},{"name":"RANADE, P.","type":"PERSON","description":"Ranade, P. is an author of the paper \"Fabula: Intelligence report generation using retrieval-augmented narrative construction\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"JOSHI, A.","type":"PERSON","description":"Joshi, A. is an author of the paper \"Fabula: Intelligence report generation using retrieval-augmented narrative construction\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"SARTHI, P.","type":"PERSON","description":"Sarthi, P. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"ABDULLAH, S.","type":"PERSON","description":"Abdullah, S. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"TULI, A.","type":"PERSON","description":"Tuli, A. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"KHANNA, S.","type":"PERSON","description":"Khanna, S. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"GOLDIE, A.","type":"PERSON","description":"Goldie, A. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"MANNING, C. D.","type":"PERSON","description":"Manning, C. D. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"SCOTT, K.","type":"PERSON","description":"Scott, K. is the host of the podcast \"Behind the Tech\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"SHAO, Z.","type":"PERSON","description":"Shao, Z. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"GONG, Y.","type":"PERSON","description":"Gong, Y. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"HUANG, M.","type":"PERSON","description":"Huang, M. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"DUAN, N.","type":"PERSON","description":"Duan, N. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"SU, D.","type":"PERSON","description":"Su, D. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"XU, Y.","type":"PERSON","description":"Xu, Y. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"YU, T.","type":"PERSON","description":"Yu, T. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"SIDDIQUE, F. B.","type":"PERSON","description":"Siddique, F. B. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"BAREZI, E. J.","type":"PERSON","description":"Barezi, E. J. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"FUNG, P.","type":"PERSON","description":"Fung, P. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization\"","source_id":"df50c95dff7da074cbb2f68e88686f88","entity_type":"PERSON"},{"name":"CANADIAN AI 2020","type":"CONFERENCE","description":"The conference where the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\" was presented","source_id":"df50c95dff7da074cbb2f68e88686f88"},{"name":"SPRINGER","type":"PUBLISHER","description":"The publisher of the proceedings for the 33rd Canadian Conference on Artificial Intelligence, Canadian AI 2020","source_id":"df50c95dff7da074cbb2f68e88686f88"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"KOESTEN, L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Koesten, L. is an author of the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/node>    <node id=\"GREGORY, K.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gregory, K. is an author of the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/node>    <node id=\"GROTH, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Groth, P. is an author of the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/node>    <node id=\"SIMPERL, E.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Simperl, E. is an author of the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/node>    <node id=\"INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The journal where the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\" was published<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/node>    <node id=\"KURATOV, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kuratov, Y. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/node>    <node id=\"BULATOV, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bulatov, A. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/node>    <node id=\"ANOKHIN, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Anokhin, P. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/node>    <node id=\"SOROKIN, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sorokin, D. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/node>    <node id=\"SOROKIN, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sorokin, A. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/node>    <node id=\"BURTSEV, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Burtsev, M. is an author of the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/node>    <node id=\"LANGCHAIN\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">LangChain is the organization behind the LangChain graphs project<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/node>    <node id=\"LASKAR, M. T. R.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Laskar, M. T. R. is an author of the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/node>    <node id=\"HOQUE, E.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hoque, E. is an author of the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/node>    <node id=\"HUANG, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Huang, J. is an author of the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/node>    <node id=\"ADVANCES IN ARTIFICIAL INTELLIGENCE\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The conference where the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\" was presented<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/node>    <node id=\"COMPUTATIONAL LINGUISTICS\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The journal where the paper \"Domain adaptation with pre-trained transformers for query-focused abstractive text summarization\" was published<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/node>    <node id=\"LEWIS, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lewis, P. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PEREZ, E.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Perez, E. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PIKTUS, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Piktus, A. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PETRONI, F.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Petroni, F. is an author of the paper \"Lost in the middle: How language models use long contexts\"Petroni, F. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KARPUKHIN, V.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Karpukhin, V. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GOYAL, N.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Goyal, N. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"K&#220;TTLER, H.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">K&#252;ttler, H. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LEWIS, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lewis, M. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YIH, W.-T.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yih, W.-T. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ROCKT&#196;SCHEL, T.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Rockt&#228;schel, T. is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The conference where the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\" was presented<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">CONFERENCE<\/data>    <\/node>    <node id=\"LIU, N. F.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liu, N. F. is an author of the paper \"Lost in the middle: How language models use long contexts\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LIN, K.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lin, K. is an author of the paper \"Lost in the middle: How language models use long contexts\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HEWITT, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hewitt, J. is an author of the paper \"Lost in the middle: How language models use long contexts\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PARANJAPE, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Paranjape, A. is an author of the paper \"Lost in the middle: How language models use long contexts\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BEVILACQUA, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bevilacqua, M. is an author of the paper \"Lost in the middle: How language models use long contexts\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LIANG, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liang, P. is an author of the paper \"Lost in the middle: How language models use long contexts\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ARXIV\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The repository where the paper \"Fabula: Intelligence report generation using retrieval-augmented narrative construction\" was publishedThe repository where the paper \"Lost in the middle: How language models use long contexts\" was publishedThe repository where the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\" was published<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">REPOSITORY<\/data>    <\/node>    <node id=\"LIU, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liu, Y. is an author of the paper \"Hierarchical transformers for multi-document summarization\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LAPATA, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lapata, M. is an author of the paper \"Hierarchical transformers for multi-document summarization\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LLAMAINDEX\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">LlamaIndex is the organization behind the LlamaIndex Knowledge Graph Index project<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"MANAKUL, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Manakul, P. is an author of the paper \"Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LIUSIE, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liusie, A. is an author of the paper \"Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GALES, M. J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gales, M. J. is an author of the paper \"Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MAO, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mao, Y. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HE, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">He, P. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LIU, X.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liu, X. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHEN, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shen, Y. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"Shen, Y. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GAO, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gao, J. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HAN, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Han, J. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHEN, W.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chen, W. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"Chen, W. is an author of the paper \"Generation-augmented retrieval for open-domain question answering\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SPIE CONFERENCE ON VISUALIZATION AND DATA ANALYSIS (VDA)\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The conference where the paper \"Openord: An open-source toolbox for large graph layout\" was presented<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">CONFERENCE<\/data>    <\/node>    <node id=\"MARTIN, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Martin, S. is an author of the paper \"Openord: An open-source toolbox for large graph layout\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BROWN, W. M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Brown, W. M. is an author of the paper \"Openord: An open-source toolbox for large graph layout\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KLAVANS, R.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Klavans, R. is an author of the paper \"Openord: An open-source toolbox for large graph layout\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BOYACK, K.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Boyack, K. is an author of the paper \"Openord: An open-source toolbox for large graph layout\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MICROSOFT\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Microsoft is the organization behind the study \"The impact of large language models on scientific discovery: a preliminary study using gpt-4\"Microsoft is the organization behind the podcast \"Behind the Tech\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"NEBULAGRAPH\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">NebulaGraph is the organization behind the project \"Nebulagraph launches industry-first graph rag: Retrieval-augmented generation with llm based on knowledge graphs\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"NEO4J\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Neo4J is the organization behind the project \"Project NaLLM\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"NEWMAN, M. E.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Newman, M. E. is an author of the paper \"Modularity and community structure in networks\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The journal where the paper \"Modularity and community structure in networks\" was published<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">JOURNAL<\/data>    <\/node>    <node id=\"RAM, O.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ram, O. is an author of the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LEVINE, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Levine, Y. is an author of the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DALMEDIGOS, I.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dalmedigos, I. is an author of the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MUHLGAY, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Muhlgay, D. is an author of the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHASHUA, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shashua, A. is an author of the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LEYTON-BROWN, K.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Leyton-Brown, K. is an author of the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHOHAM, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shoham, Y. is an author of the paper \"In-context retrieval-augmented language models\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The journal where the paper \"In-context retrieval-augmented language models\" was published<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">JOURNAL<\/data>    <\/node>    <node id=\"RANADE, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ranade, P. is an author of the paper \"Fabula: Intelligence report generation using retrieval-augmented narrative construction\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JOSHI, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joshi, A. is an author of the paper \"Fabula: Intelligence report generation using retrieval-augmented narrative construction\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SARTHI, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sarthi, P. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ABDULLAH, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Abdullah, S. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TULI, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tuli, A. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KHANNA, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Khanna, S. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GOLDIE, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Goldie, A. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MANNING, C. D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Manning, C. D. is an author of the paper \"Raptor: Recursive abstractive processing for tree-organized retrieval\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SCOTT, K.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Scott, K. is the host of the podcast \"Behind the Tech\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHAO, Z.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shao, Z. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GONG, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gong, Y. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HUANG, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Huang, M. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DUAN, N.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Duan, N. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SU, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Su, D. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XU, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xu, Y. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YU, T.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yu, T. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SIDDIQUE, F. B.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Siddique, F. B. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BAREZI, E. J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Barezi, E. J. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"FUNG, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Fung, P. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization\"<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CANADIAN AI 2020\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">The conference where the paper \"Query focused abstractive summarization via incorporating query relevance and transfer learning with transformer models\" was presented<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/node>    <node id=\"SPRINGER\">      <data key=\"d0\">PUBLISHER<\/data>      <data key=\"d1\">The publisher of the proceedings for the 33rd Canadian Conference on Artificial Intelligence, Canadian AI 2020<\/data>      <data key=\"d2\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/node>    <edge source=\"KOESTEN, L.\" target=\"GREGORY, K.\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Koesten, L. and Gregory, K. co-authored the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d6\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/edge>    <edge source=\"KOESTEN, L.\" target=\"GROTH, P.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Koesten, L. and Groth, P. co-authored the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d6\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/edge>    <edge source=\"KOESTEN, L.\" target=\"SIMPERL, E.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Koesten, L. and Simperl, E. co-authored the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d6\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/edge>    <edge source=\"GREGORY, K.\" target=\"GROTH, P.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Gregory, K. and Groth, P. co-authored the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d6\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/edge>    <edge source=\"GREGORY, K.\" target=\"SIMPERL, E.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Gregory, K. and Simperl, E. co-authored the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d6\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/edge>    <edge source=\"GROTH, P.\" target=\"SIMPERL, E.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Groth, P. and Simperl, E. co-authored the paper \"Talking datasets&#8211;understanding data sensemaking behaviours\"<\/data>      <data key=\"d6\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/edge>    <edge source=\"KURATOV, Y.\" target=\"BULATOV, A.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Kuratov, Y. and Bulatov, A. co-authored the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d6\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/edge>    <edge source=\"KURATOV, Y.\" target=\"ANOKHIN, P.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Kuratov, Y. and Anokhin, P. co-authored the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d6\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/edge>    <edge source=\"KURATOV, Y.\" target=\"SOROKIN, D.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Kuratov, Y. and Sorokin, D. co-authored the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d6\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/edge>    <edge source=\"KURATOV, Y.\" target=\"SOROKIN, A.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Kuratov, Y. and Sorokin, A. co-authored the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d6\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/edge>    <edge source=\"KURATOV, Y.\" target=\"BURTSEV, M.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Kuratov, Y. and Burtsev, M. co-authored the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d6\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/edge>    <edge source=\"BULATOV, A.\" target=\"ANOKHIN, P.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Bulatov, A. and Anokhin, P. co-authored the paper \"In search of needles in a 11m haystack: Recurrent memory finds what llms miss\"<\/data>      <data key=\"d6\">df50c95dff7da074cbb2f68e88686f88<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","chunk":"., Duan, N., and Chen, W. (2023). Enhancing retrieval-\naugmented large language models with iterative retrieval-generation synergy. arXiv preprint\narXiv:2305.15294 .\nSu, D., Xu, Y ., Yu, T., Siddique, F. B., Barezi, E. J., and Fung, P. (2020). Caire-covid: A ques-\ntion answering and query-focused multi-document summarization system for covid-19 scholarly\ninformation management. arXiv preprint arXiv:2005.03975 .\nTang, Y . and Yang, Y . (2024). MultiHop-RAG: Benchmarking retrieval-augmented generation for\nmulti-hop queries. arXiv preprint arXiv:2401.15391 .\nTouvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y ., Bashlykov, N., Batra, S.,\nBhargava, P., Bhosale, S., et al. (2023). Llama 2: Open foundation and fine-tuned chat models.\narXiv preprint arXiv:2307.09288 .\nTraag, V . A., Waltman, L., and Van Eck, N. J. (2019). From Louvain to Leiden: guaranteeing\nwell-connected communities. Scientific Reports , 9(1).\nTrajanoska, M., Stojanov, R., and Trajanov, D. (2023). Enhancing knowledge graph construction\nusing large language models. ArXiv , abs\/2305.04676.\nTrivedi, H., Balasubramanian, N., Khot, T., and Sabharwal, A. (2022). Interleaving retrieval\nwith chain-of-thought reasoning for knowledge-intensive multi-step questions. arXiv preprint\narXiv:2212.10509 .\nWang, J., Liang, Y ., Meng, F., Sun, Z., Shi, H., Li, Z., Xu, J., Qu, J., and Zhou, J. (2023a). Is chatgpt\na good nlg evaluator? a preliminary study. arXiv preprint arXiv:2303.04048 .\nWang, S., Khramtsova, E., Zhuang, S., and Zuccon, G. (2024). Feb4rag: Evaluating federated search\nin the context of retrieval augmented generation. arXiv preprint arXiv:2402.11891 .\nWang, Y ., Lipka, N., Rossi, R. A., Siu, A., Zhang, R., and Derr, T. (2023b). Knowledge graph\nprompting for multi-document question answering.\nXu, Y . and Lapata, M. (2021). Text summarization with latent queries. arXiv preprint\narXiv:2106.00104 .\nYang, Z., Qi, P., Zhang, S., Bengio, Y ., Cohen, W. W., Salakhutdinov, R., and Manning, C. D. (2018).\nHotpotQA: A dataset for diverse, explainable multi-hop question answering. In Conference on\nEmpirical Methods in Natural Language Processing (EMNLP) .\nYao, J.-g., Wan, X., and Xiao, J. (2017). Recent advances in document summarization. Knowledge\nand Information Systems , 53:297\u2013336.\n14Yao, L., Peng, J., Mao, C., and Luo, Y . (2023). Exploring large language models for knowledge\ngraph completion.\nZhang, J. (2023). Graph-toolformer: To empower llms with graph reasoning ability via prompt\naugmented by chatgpt. arXiv preprint arXiv:2304.11116 .\nZhang, Y ., Zhang, Y ., Gan, Y ., Yao, L., and Wang, C. (2024). Causal graph discovery with retrieval-\naugmented generation based large language models. arXiv preprint arXiv:2402.15301 .\nZheng, L., Chiang, W.-L., Sheng, Y ., Zhuang, S., Wu, Z., Zhuang, Y ., Lin, Z., Li, Z., Li, D., Xing,\nE., et al. (2024). Judging llm-as-a-judge with mt-bench and chatbot arena. Advances in Neural\nInformation Processing Systems , 36.\n15","chunk_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","document_ids":["0668cddc5f873265ba50da5a0a06edad"],"n_tokens":987,"entities":[{"name":"DUAN, N.","type":"PERSON","description":"Duan, N. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"CHEN, W.","type":"PERSON","description":"Chen, W. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"SU, D.","type":"PERSON","description":"Su, D. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"XU, Y.","type":"PERSON","description":"Xu, Y. is an author of the paper \"Text summarization with latent queries\"\nXu, Y. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"YU, T.","type":"PERSON","description":"Yu, T. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"SIDDIQUE, F. B.","type":"PERSON","description":"Siddique, F. B. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"BAREZI, E. J.","type":"PERSON","description":"Barezi, E. J. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"FUNG, P.","type":"PERSON","description":"Fung, P. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"TANG, Y.","type":"PERSON","description":"Tang, Y. is an author of the paper \"MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"YANG, Y.","type":"PERSON","description":"Yang, Y. is an author of the paper \"MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"TOUVRON, H.","type":"PERSON","description":"Touvron, H. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"MARTIN, L.","type":"PERSON","description":"Martin, L. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"STONE, K.","type":"PERSON","description":"Stone, K. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"ALBERT, P.","type":"PERSON","description":"Albert, P. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"ALMAHAIRI, A.","type":"PERSON","description":"Almahairi, A. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"BABAEI, Y.","type":"PERSON","description":"Babaei, Y. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"BASHLYKOV, N.","type":"PERSON","description":"Bashlykov, N. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"BATRA, S.","type":"PERSON","description":"Batra, S. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"BHARGAVA, P.","type":"PERSON","description":"Bhargava, P. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"BHOSALE, S.","type":"PERSON","description":"Bhosale, S. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"TRAAG, V. A.","type":"PERSON","description":"Traag, V. A. is an author of the paper \"From Louvain to Leiden: guaranteeing well-connected communities\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"WALTMAN, L.","type":"PERSON","description":"Waltman, L. is an author of the paper \"From Louvain to Leiden: guaranteeing well-connected communities\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"VAN ECK, N. J.","type":"PERSON","description":"Van Eck, N. J. is an author of the paper \"From Louvain to Leiden: guaranteeing well-connected communities\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"TRAJANOSKA, M.","type":"PERSON","description":"Trajanoska, M. is an author of the paper \"Enhancing knowledge graph construction using large language models\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"STOJANOV, R.","type":"PERSON","description":"Stojanov, R. is an author of the paper \"Enhancing knowledge graph construction using large language models\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"TRAJANOV, D.","type":"PERSON","description":"Trajanov, D. is an author of the paper \"Enhancing knowledge graph construction using large language models\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"TRIVEDI, H.","type":"PERSON","description":"Trivedi, H. is an author of the paper \"Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"BALASUBRAMANIAN, N.","type":"PERSON","description":"Balasubramanian, N. is an author of the paper \"Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"KHOT, T.","type":"PERSON","description":"Khot, T. is an author of the paper \"Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"SABHARWAL, A.","type":"PERSON","description":"Sabharwal, A. is an author of the paper \"Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"WANG, J.","type":"PERSON","description":"Wang, J. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"LIANG, Y.","type":"PERSON","description":"Liang, Y. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"MENG, F.","type":"PERSON","description":"Meng, F. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"SUN, Z.","type":"PERSON","description":"Sun, Z. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"SHI, H.","type":"PERSON","description":"Shi, H. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"LI, Z.","type":"PERSON","description":"Li, Z. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"\nLi, Z. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"XU, J.","type":"PERSON","description":"Xu, J. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"QU, J.","type":"PERSON","description":"Qu, J. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"ZHOU, J.","type":"PERSON","description":"Zhou, J. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"WANG, S.","type":"PERSON","description":"Wang, S. is an author of the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"KHRAMTSOVA, E.","type":"PERSON","description":"Khramtsova, E. is an author of the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"ZHUANG, S.","type":"PERSON","description":"Zhuang, S. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"\nZhuang, S. is an author of the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"ZUCCON, G.","type":"PERSON","description":"Zuccon, G. is an author of the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"WANG, Y.","type":"PERSON","description":"Wang, Y. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"LIPKA, N.","type":"PERSON","description":"Lipka, N. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"ROSSI, R. A.","type":"PERSON","description":"Rossi, R. A. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"SIU, A.","type":"PERSON","description":"Siu, A. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"ZHANG, R.","type":"PERSON","description":"Zhang, R. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"DERR, T.","type":"PERSON","description":"Derr, T. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"LAPATA, M.","type":"PERSON","description":"Lapata, M. is an author of the paper \"Text summarization with latent queries\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"YANG, Z.","type":"PERSON","description":"Yang, Z. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"QI, P.","type":"PERSON","description":"Qi, P. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"ZHANG, S.","type":"PERSON","description":"Zhang, S. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"BENGIO, Y.","type":"PERSON","description":"Bengio, Y. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"COHEN, W. W.","type":"PERSON","description":"Cohen, W. W. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"SALAKHUTDINOV, R.","type":"PERSON","description":"Salakhutdinov, R. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"MANNING, C. D.","type":"PERSON","description":"Manning, C. D. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"YAO, J.-G.","type":"PERSON","description":"Yao, J.-g. is an author of the paper \"Recent advances in document summarization\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"WAN, X.","type":"PERSON","description":"Wan, X. is an author of the paper \"Recent advances in document summarization\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"XIAO, J.","type":"PERSON","description":"Xiao, J. is an author of the paper \"Recent advances in document summarization\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"YAO, L.","type":"PERSON","description":"Yao, L. is an author of the paper \"Causal graph discovery with retrieval-augmented generation based large language models\"\nYao, L. is an author of the paper \"Exploring large language models for knowledge graph completion\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"PENG, J.","type":"PERSON","description":"Peng, J. is an author of the paper \"Exploring large language models for knowledge graph completion\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"MAO, C.","type":"PERSON","description":"Mao, C. is an author of the paper \"Exploring large language models for knowledge graph completion\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"LUO, Y.","type":"PERSON","description":"Luo, Y. is an author of the paper \"Exploring large language models for knowledge graph completion\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"ZHANG, J.","type":"PERSON","description":"Zhang, J. is an author of the paper \"Graph-toolformer: To empower llms with graph reasoning ability via prompt augmented by chatgpt\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"ZHANG, Y.","type":"PERSON","description":"Zhang, Y. is an author of the paper \"Causal graph discovery with retrieval-augmented generation based large language models\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"GAN, Y.","type":"PERSON","description":"Gan, Y. is an author of the paper \"Causal graph discovery with retrieval-augmented generation based large language models\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"WANG, C.","type":"PERSON","description":"Wang, C. is an author of the paper \"Causal graph discovery with retrieval-augmented generation based large language models\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"ZHENG, L.","type":"PERSON","description":"Zheng, L. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"CHIANG, W.-L.","type":"PERSON","description":"Chiang, W.-L. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"SHENG, Y.","type":"PERSON","description":"Sheng, Y. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"WU, Z.","type":"PERSON","description":"Wu, Z. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"ZHUANG, Y.","type":"PERSON","description":"Zhuang, Y. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"LIN, Z.","type":"PERSON","description":"Lin, Z. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"LI, D.","type":"PERSON","description":"Li, D. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"XING, E.","type":"PERSON","description":"Xing, E. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PERSON"},{"name":"ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS","type":"PUBLICATION","description":"The conference where the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\" was presented","source_id":"d4c8ce26fd0f9a7bc6dad0efa1ce98e3","entity_type":"PUBLICATION"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"DUAN, N.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Duan, N. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHEN, W.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chen, W. is an author of the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SU, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Su, D. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XU, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xu, Y. is an author of the paper \"Text summarization with latent queries\"Xu, Y. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YU, T.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yu, T. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SIDDIQUE, F. B.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Siddique, F. B. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BAREZI, E. J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Barezi, E. J. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"FUNG, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Fung, P. is an author of the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TANG, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tang, Y. is an author of the paper \"MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YANG, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yang, Y. is an author of the paper \"MultiHop-RAG: Benchmarking retrieval-augmented generation for multi-hop queries\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TOUVRON, H.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Touvron, H. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MARTIN, L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Martin, L. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"STONE, K.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Stone, K. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ALBERT, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Albert, P. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ALMAHAIRI, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Almahairi, A. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BABAEI, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Babaei, Y. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BASHLYKOV, N.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bashlykov, N. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BATRA, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Batra, S. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BHARGAVA, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bhargava, P. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BHOSALE, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bhosale, S. is an author of the paper \"Llama 2: Open foundation and fine-tuned chat models\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TRAAG, V. A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Traag, V. A. is an author of the paper \"From Louvain to Leiden: guaranteeing well-connected communities\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WALTMAN, L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Waltman, L. is an author of the paper \"From Louvain to Leiden: guaranteeing well-connected communities\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"VAN ECK, N. J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Van Eck, N. J. is an author of the paper \"From Louvain to Leiden: guaranteeing well-connected communities\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TRAJANOSKA, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Trajanoska, M. is an author of the paper \"Enhancing knowledge graph construction using large language models\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"STOJANOV, R.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Stojanov, R. is an author of the paper \"Enhancing knowledge graph construction using large language models\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TRAJANOV, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Trajanov, D. is an author of the paper \"Enhancing knowledge graph construction using large language models\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TRIVEDI, H.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Trivedi, H. is an author of the paper \"Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BALASUBRAMANIAN, N.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Balasubramanian, N. is an author of the paper \"Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KHOT, T.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Khot, T. is an author of the paper \"Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SABHARWAL, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sabharwal, A. is an author of the paper \"Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WANG, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wang, J. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LIANG, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liang, Y. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MENG, F.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Meng, F. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SUN, Z.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sun, Z. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHI, H.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shi, H. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LI, Z.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Li, Z. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"Li, Z. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XU, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xu, J. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"QU, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Qu, J. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHOU, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhou, J. is an author of the paper \"Is chatgpt a good nlg evaluator? a preliminary study\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WANG, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wang, S. is an author of the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KHRAMTSOVA, E.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Khramtsova, E. is an author of the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHUANG, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhuang, S. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"Zhuang, S. is an author of the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZUCCON, G.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zuccon, G. is an author of the paper \"Feb4rag: Evaluating federated search in the context of retrieval augmented generation\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WANG, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wang, Y. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LIPKA, N.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lipka, N. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ROSSI, R. A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Rossi, R. A. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SIU, A.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Siu, A. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHANG, R.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhang, R. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DERR, T.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Derr, T. is an author of the paper \"Knowledge graph prompting for multi-document question answering\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LAPATA, M.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lapata, M. is an author of the paper \"Text summarization with latent queries\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YANG, Z.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yang, Z. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"QI, P.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Qi, P. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHANG, S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhang, S. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BENGIO, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bengio, Y. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"COHEN, W. W.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Cohen, W. W. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SALAKHUTDINOV, R.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Salakhutdinov, R. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MANNING, C. D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Manning, C. D. is an author of the paper \"HotpotQA: A dataset for diverse, explainable multi-hop question answering\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YAO, J.-G.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yao, J.-g. is an author of the paper \"Recent advances in document summarization\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WAN, X.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wan, X. is an author of the paper \"Recent advances in document summarization\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XIAO, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xiao, J. is an author of the paper \"Recent advances in document summarization\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YAO, L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yao, L. is an author of the paper \"Causal graph discovery with retrieval-augmented generation based large language models\"Yao, L. is an author of the paper \"Exploring large language models for knowledge graph completion\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PENG, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Peng, J. is an author of the paper \"Exploring large language models for knowledge graph completion\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MAO, C.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mao, C. is an author of the paper \"Exploring large language models for knowledge graph completion\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LUO, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Luo, Y. is an author of the paper \"Exploring large language models for knowledge graph completion\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHANG, J.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhang, J. is an author of the paper \"Graph-toolformer: To empower llms with graph reasoning ability via prompt augmented by chatgpt\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHANG, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhang, Y. is an author of the paper \"Causal graph discovery with retrieval-augmented generation based large language models\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GAN, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gan, Y. is an author of the paper \"Causal graph discovery with retrieval-augmented generation based large language models\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WANG, C.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wang, C. is an author of the paper \"Causal graph discovery with retrieval-augmented generation based large language models\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHENG, L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zheng, L. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHIANG, W.-L.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chiang, W.-L. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHENG, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sheng, Y. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WU, Z.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wu, Z. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHUANG, Y.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhuang, Y. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LIN, Z.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lin, Z. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LI, D.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Li, D. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XING, E.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xing, E. is an author of the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\"<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The conference where the paper \"Judging llm-as-a-judge with mt-bench and chatbot arena\" was presented<\/data>      <data key=\"d2\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <edge source=\"DUAN, N.\" target=\"CHEN, W.\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Duan, N. and Chen, W. co-authored the paper \"Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy\"<\/data>      <data key=\"d6\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>    <\/edge>    <edge source=\"SU, D.\" target=\"XU, Y.\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Su, D. and Xu, Y. co-authored the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d6\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>    <\/edge>    <edge source=\"SU, D.\" target=\"YU, T.\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Su, D. and Yu, T. co-authored the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d6\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>    <\/edge>    <edge source=\"SU, D.\" target=\"SIDDIQUE, F. B.\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Su, D. and Siddique, F. B. co-authored the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d6\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>    <\/edge>    <edge source=\"SU, D.\" target=\"BAREZI, E. J.\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Su, D. and Barezi, E. J. co-authored the paper \"Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management\"<\/data>      <data key=\"d6\">d4c8ce26fd0f9a7bc6dad0efa1ce98e3<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"93cb0d0456e0822b5fe30a3e627405f8","chunk":"Language Agent Tree Search Unifies Reasoning, Acting, and Planning in\nLanguage Models\nAndy Zhou1 2Kai Yan1Michal Shlapentokh-Rothman1Haohan Wang1Yu-Xiong Wang1\nAbstract\nWhile language models (LMs) have shown po-\ntential across a range of decision-making tasks,\ntheir reliance on simple acting processes limits\ntheir broad deployment as autonomous agents. In\nthis paper, we introduce Language Agent Tree\nSearch (LATS) \u2013 the first general framework that\nsynergizes the capabilities of LMs in reasoning,\nacting, and planning. By leveraging the in-context\nlearning ability of LMs, we integrate Monte Carlo\nTree Search into LATS to enable LMs as agents,\nalong with LM-powered value functions and\nself-reflections for proficient exploration and en-\nhanced decision-making. A key feature of our ap-\nproach is the incorporation of an environment for\nexternal feedback, which offers a more deliberate\nand adaptive problem-solving mechanism that sur-\npasses the constraints of existing techniques. Our\nexperimental evaluation across diverse domains,\nincluding programming, interactive question-\nanswering (QA), web navigation, and math, val-\nidates the effectiveness and generality of LATS\nin decision-making while maintaining compet-\nitive or improved reasoning performance. No-\ntably, LATS achieves state-of-the-art pass@1 ac-\ncuracy (92.7%) for programming on HumanEval\nwith GPT-4 and demonstrates gradient-free per-\nformance (average score of 75.9) comparable to\ngradient-based fine-tuning for web navigation on\nWebShop with GPT-3.5. Code can be found\nathttps:\/\/github.com\/lapisrocks\/\nLanguageAgentTreeSearch .\n1. Introduction\nGeneral autonomous agents capable of reasoning and\ndecision-making in a variety of environments (Wooldridge\n1University of Illinois Urbana-Champaign.2Lapis Labs. Corre-\nspondence to: Andy Zhou <andyz3@illinois.edu >.\nProceedings of the 41stInternational Conference on Machine\nLearning , Vienna, Austria. PMLR 235, 2024. Copyright 2024 by\nthe author(s).\nFigure 1. Overview of LATS. Serving as a unified framework,\nLATS leverages an external environment and an MCTS-based\nsearch algorithm to improve reasoning and decision-making.\nand Jennings, 1995) have been of longstanding interest in\nthe field of artificial intelligence. While this has tradition-\nally been studied in reinforcement learning, the recent rise\nof language models (LMs) (Brown et al., 2020; Chowdh-\nery et al., 2023; Touvron et al., 2023; OpenAI, 2023) with\nstrong reasoning and general adaptability offers an alter-\nnative paradigm. Not only have LMs excelled in standard\nnatural language processing (NLP) tasks such as summariza-\ntion (Nallapati et al., 2016) and language inference (Bow-\nman et al., 2015), but they have also been adapted to an\nincreasingly diverse set of tasks that often require advanced\ncommon-sense reasoning or quantitative skills (Cobbe et al.,\n2021; Saparov and He, 2023). In addition, LMs are capable\nof performing in complex environments that involve knowl-\nedge and reasoning, such as web navigation (Yao et al.,\n2022; Deng et al., 2023), tool-use (Schick et al., 2023), and\nopen-ended games (Fan et al., 2022).\nReasoning and acting abilities have been further improved\nby prompting techniques that augment LMs with feedback\nor observations from an external environment, as exempli-\nfied by ReAct (Yao et al., 2023b) and other work (Gao et al.,\n2023; Shinn et al., 2023). This eliminates the need to rely en-\ntirely on the base abilities of LMs, enhancing them through\nexternal tools or semantic feedback. Despite such strengths,\nthese methods are reflexive and fall short of humans\u2019 deliber-\nate and thoughtful decision-making characteristics to solve\nproblems (Sloman, 1996; Evans, 2010). In particular, they\nfail to consider multiple reasoning paths or to plan ahead.\nRecent search-guided LM work (Xie et al., 2023; Yao et al.,\n2023a; Hao et al., 2023) addresses this issue by searching\nover multiple reasoning chains. While enabling planning,\n1arXiv:2310.04406v3  [cs.AI]  6 Jun 2024Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nsuch methods operate in isolation, lacking the incorporation\nof external feedback that can improve reasoning.\nTo overcome these challenges, we propose Language Agent\nTree Search (LATS) \u2013 a unified framework for decision-\nmaking and reasoning with language models. As illustrated\nin Fig. 1, LATS synergizes LM reasoning, acting, and plan-\nning strategies by expanding ReAct (Yao et al., 2023b) into a\nsearch over a combinatorial space of possible reasoning and\nacting steps. This effort is nontrivial \u2013 adapting search algo-\nrithms to language agents and shifting from non-interactive\ntasks to interactive ones requires a substantial novel design\non nodes, prompts, and search algorithms. In particular,\nnodes and prompts must effectively store and retrieve ex-\nternal feedback, with the search algorithm incorporating\nthis information into useful heuristics for value assignment.\nIndeed, our empirical evaluation, as demonstrated on Hot-\nPotQA (Yang et al., 2018)","chunk_id":"93cb0d0456e0822b5fe30a3e627405f8","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"LANGUAGE AGENT TREE SEARCH (LATS)","type":"FRAMEWORK\/TECHNOLOGY","description":"Language Agent Tree Search (LATS) is a general framework that integrates the capabilities of language models (LMs) in reasoning, acting, and planning by leveraging Monte Carlo Tree Search and LM-powered value functions and self-reflections for proficient exploration and enhanced decision-making.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"ANDY ZHOU","type":"PERSON","description":"Andy Zhou is one of the authors of the paper \"Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\" and is affiliated with the University of Illinois Urbana-Champaign and Lapis Labs.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"KAI YAN","type":"PERSON","description":"Kai Yan is one of the authors of the paper \"Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\" and is affiliated with the University of Illinois Urbana-Champaign.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"MICHAL SHLAPENTOKH-ROTHMAN","type":"PERSON","description":"Michal Shlapentokh-Rothman is one of the authors of the paper \"Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\" and is affiliated with the University of Illinois Urbana-Champaign.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"HAOHAN WANG","type":"PERSON","description":"Haohan Wang is one of the authors of the paper \"Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\" and is affiliated with the University of Illinois Urbana-Champaign.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"YU-XIONG WANG","type":"PERSON","description":"Yu-Xiong Wang is one of the authors of the paper \"Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\" and is affiliated with the University of Illinois Urbana-Champaign.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN","type":"ORGANIZATION","description":"The University of Illinois Urbana-Champaign is an educational institution where several authors of the paper \"Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\" are affiliated.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"LAPIS LABS","type":"ORGANIZATION","description":"Lapis Labs is an organization affiliated with Andy Zhou, one of the authors of the paper \"Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\".","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"GPT-4","type":"MODEL","description":"GPT-4 is a version of OpenAI's language model used in the experimental evaluation of LATS, achieving state-of-the-art pass@1 accuracy for programming on HumanEval.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"GPT-3.5","type":"MODEL","description":"GPT-3.5 is a version of OpenAI's language model used in the experimental evaluation of LATS, demonstrating gradient-free performance comparable to gradient-based fine-tuning for web navigation on WebShop.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"MONTE CARLO TREE SEARCH (MCTS)","type":"ALGORITHM","description":"Monte Carlo Tree Search (MCTS) is an algorithm integrated into LATS to enable language models as agents, enhancing their decision-making capabilities.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"REACT","type":"TECHNIQUE","description":"ReAct is a prompting technique that augments language models with feedback or observations from an external environment, which LATS expands upon to improve reasoning and decision-making.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"HUMANEVAL","type":"BENCHMARK","description":"HumanEval is a benchmark used to evaluate the programming capabilities of language models, where LATS achieved state-of-the-art pass@1 accuracy with GPT-4.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"WEBSHOP","type":"BENCHMARK","description":"WebShop is a benchmark used to evaluate web navigation capabilities of language models, where LATS demonstrated gradient-free performance with GPT-3.5.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"HOTPOTQA","type":"BENCHMARK","description":"HotPotQA is a benchmark used in the empirical evaluation of LATS to demonstrate its effectiveness in decision-making and reasoning.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"PROCEEDINGS OF THE 41ST INTERNATIONAL CONFERENCE ON MACHINE LEARNING","type":"PUBLICATION","description":"The conference where the paper \"Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\" was presented.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"PMLR 235","type":"PUBLICATION","description":"The volume of the Proceedings of the 41st International Conference on Machine Learning where the paper \"Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\" was published.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"2024","type":"YEAR","description":"The year when the paper \"Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\" was published.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"GITHUB","type":"PLATFORM","description":"GitHub is the platform where the code for Language Agent Tree Search (LATS) can be found.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"HTTPS:\/\/GITHUB.COM\/LAPISROCKS\/LANGUAGEAGENTTREESEARCH","type":"URL","description":"The URL where the code for Language Agent Tree Search (LATS) is available on GitHub.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"WOOLDRIDGE","type":"PERSON","description":"Wooldridge is referenced in the context of general autonomous agents capable of reasoning and decision-making in a variety of environments.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"JENNINGS","type":"PERSON","description":"Jennings is referenced in the context of general autonomous agents capable of reasoning and decision-making in a variety of environments.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"BROWN ET AL.","type":"PERSON","description":"Brown et al. are referenced in the context of the rise of language models with strong reasoning and general adaptability.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"CHOWDHERY ET AL.","type":"PERSON","description":"Chowdhery et al. are referenced in the context of the rise of language models with strong reasoning and general adaptability.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"TOUVRON ET AL.","type":"PERSON","description":"Touvron et al. are referenced in the context of the rise of language models with strong reasoning and general adaptability.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"OPENAI","type":"ORGANIZATION","description":"OpenAI is referenced in the context of the rise of language models with strong reasoning and general adaptability.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"NALLAPATI ET AL.","type":"PERSON","description":"Nallapati et al. are referenced in the context of language models excelling in standard natural language processing tasks such as summarization.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"BOWMAN ET AL.","type":"PERSON","description":"Bowman et al. are referenced in the context of language models excelling in standard natural language processing tasks such as language inference.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"COBBE ET AL.","type":"PERSON","description":"Cobbe et al. are referenced in the context of language models being adapted to tasks requiring advanced common-sense reasoning or quantitative skills.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"SAPAROV AND HE","type":"PERSON","description":"Saparov and He are referenced in the context of language models being adapted to tasks requiring advanced common-sense reasoning or quantitative skills.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"YAO ET AL.","type":"PERSON","description":"Yao et al. are referenced multiple times in the context of web navigation, prompting techniques, and search-guided language model work.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"DENG ET AL.","type":"PERSON","description":"Deng et al. are referenced in the context of language models performing in complex environments such as web navigation.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"SCHICK ET AL.","type":"PERSON","description":"Schick et al. are referenced in the context of language models performing in complex environments such as tool-use.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"FAN ET AL.","type":"PERSON","description":"Fan et al. are referenced in the context of language models performing in complex environments such as open-ended games.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"GAO ET AL.","type":"PERSON","description":"Gao et al. are referenced in the context of prompting techniques that augment language models with feedback or observations from an external environment.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"SHINN ET AL.","type":"PERSON","description":"Shinn et al. are referenced in the context of prompting techniques that augment language models with feedback or observations from an external environment.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"SLOMAN","type":"PERSON","description":"Sloman is referenced in the context of the limitations of reflexive methods in language models compared to humans' deliberate and thoughtful decision-making characteristics.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"EVANS","type":"PERSON","description":"Evans is referenced in the context of the limitations of reflexive methods in language models compared to humans' deliberate and thoughtful decision-making characteristics.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"XIE ET AL.","type":"PERSON","description":"Xie et al. are referenced in the context of recent search-guided language model work that addresses the issue of planning and multiple reasoning paths.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"HAO ET AL.","type":"PERSON","description":"Hao et al. are referenced in the context of recent search-guided language model work that addresses the issue of planning and multiple reasoning paths.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"YANG ET AL.","type":"PERSON","description":"Yang et al. are referenced in the context of the HotPotQA benchmark used in the empirical evaluation of LATS.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"},{"name":"PMLR","type":"ORGANIZATION","description":"PMLR is the organization that published the Proceedings of the 41st International Conference on Machine Learning where the paper on LATS was presented.","source_id":"93cb0d0456e0822b5fe30a3e627405f8"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"LANGUAGE AGENT TREE SEARCH (LATS)\">      <data key=\"d0\">FRAMEWORK\/TECHNOLOGY<\/data>      <data key=\"d1\">Language Agent Tree Search (LATS) is a general framework that integrates the capabilities of language models (LMs) in reasoning, acting, and planning by leveraging Monte Carlo Tree Search and LM-powered value functions and self-reflections for proficient exploration and enhanced decision-making.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"ANDY ZHOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Andy Zhou is one of the authors of the paper \"Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\" and is affiliated with the University of Illinois Urbana-Champaign and Lapis Labs.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"KAI YAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kai Yan is one of the authors of the paper \"Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\" and is affiliated with the University of Illinois Urbana-Champaign.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"MICHAL SHLAPENTOKH-ROTHMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Michal Shlapentokh-Rothman is one of the authors of the paper \"Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\" and is affiliated with the University of Illinois Urbana-Champaign.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"HAOHAN WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Haohan Wang is one of the authors of the paper \"Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\" and is affiliated with the University of Illinois Urbana-Champaign.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"YU-XIONG WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yu-Xiong Wang is one of the authors of the paper \"Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\" and is affiliated with the University of Illinois Urbana-Champaign.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">The University of Illinois Urbana-Champaign is an educational institution where several authors of the paper \"Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\" are affiliated.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"LAPIS LABS\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Lapis Labs is an organization affiliated with Andy Zhou, one of the authors of the paper \"Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\".<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4 is a version of OpenAI's language model used in the experimental evaluation of LATS, achieving state-of-the-art pass@1 accuracy for programming on HumanEval.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"GPT-3.5\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-3.5 is a version of OpenAI's language model used in the experimental evaluation of LATS, demonstrating gradient-free performance comparable to gradient-based fine-tuning for web navigation on WebShop.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"MONTE CARLO TREE SEARCH (MCTS)\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">Monte Carlo Tree Search (MCTS) is an algorithm integrated into LATS to enable language models as agents, enhancing their decision-making capabilities.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"REACT\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">ReAct is a prompting technique that augments language models with feedback or observations from an external environment, which LATS expands upon to improve reasoning and decision-making.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"HUMANEVAL\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">HumanEval is a benchmark used to evaluate the programming capabilities of language models, where LATS achieved state-of-the-art pass@1 accuracy with GPT-4.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"WEBSHOP\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">WebShop is a benchmark used to evaluate web navigation capabilities of language models, where LATS demonstrated gradient-free performance with GPT-3.5.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"HOTPOTQA\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">HotPotQA is a benchmark used in the empirical evaluation of LATS to demonstrate its effectiveness in decision-making and reasoning.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"PROCEEDINGS OF THE 41ST INTERNATIONAL CONFERENCE ON MACHINE LEARNING\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The conference where the paper \"Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\" was presented.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"PMLR 235\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The volume of the Proceedings of the 41st International Conference on Machine Learning where the paper \"Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\" was published.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"2024\">      <data key=\"d0\">YEAR<\/data>      <data key=\"d1\">The year when the paper \"Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\" was published.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"GITHUB\">      <data key=\"d0\">PLATFORM<\/data>      <data key=\"d1\">GitHub is the platform where the code for Language Agent Tree Search (LATS) can be found.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"HTTPS:\/\/GITHUB.COM\/LAPISROCKS\/LANGUAGEAGENTTREESEARCH\">      <data key=\"d0\">URL<\/data>      <data key=\"d1\">The URL where the code for Language Agent Tree Search (LATS) is available on GitHub.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"WOOLDRIDGE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wooldridge is referenced in the context of general autonomous agents capable of reasoning and decision-making in a variety of environments.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"JENNINGS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jennings is referenced in the context of general autonomous agents capable of reasoning and decision-making in a variety of environments.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"BROWN ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Brown et al. are referenced in the context of the rise of language models with strong reasoning and general adaptability.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"CHOWDHERY ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chowdhery et al. are referenced in the context of the rise of language models with strong reasoning and general adaptability.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"TOUVRON ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Touvron et al. are referenced in the context of the rise of language models with strong reasoning and general adaptability.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"OPENAI\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">OpenAI is referenced in the context of the rise of language models with strong reasoning and general adaptability.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"NALLAPATI ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nallapati et al. are referenced in the context of language models excelling in standard natural language processing tasks such as summarization.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"BOWMAN ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bowman et al. are referenced in the context of language models excelling in standard natural language processing tasks such as language inference.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"COBBE ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Cobbe et al. are referenced in the context of language models being adapted to tasks requiring advanced common-sense reasoning or quantitative skills.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"SAPAROV AND HE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Saparov and He are referenced in the context of language models being adapted to tasks requiring advanced common-sense reasoning or quantitative skills.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"YAO ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yao et al. are referenced multiple times in the context of web navigation, prompting techniques, and search-guided language model work.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"DENG ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Deng et al. are referenced in the context of language models performing in complex environments such as web navigation.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"SCHICK ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Schick et al. are referenced in the context of language models performing in complex environments such as tool-use.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"FAN ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Fan et al. are referenced in the context of language models performing in complex environments such as open-ended games.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"GAO ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gao et al. are referenced in the context of prompting techniques that augment language models with feedback or observations from an external environment.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"SHINN ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shinn et al. are referenced in the context of prompting techniques that augment language models with feedback or observations from an external environment.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"SLOMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sloman is referenced in the context of the limitations of reflexive methods in language models compared to humans' deliberate and thoughtful decision-making characteristics.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"EVANS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Evans is referenced in the context of the limitations of reflexive methods in language models compared to humans' deliberate and thoughtful decision-making characteristics.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"XIE ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xie et al. are referenced in the context of recent search-guided language model work that addresses the issue of planning and multiple reasoning paths.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"HAO ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hao et al. are referenced in the context of recent search-guided language model work that addresses the issue of planning and multiple reasoning paths.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"YANG ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yang et al. are referenced in the context of the HotPotQA benchmark used in the empirical evaluation of LATS.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <node id=\"PMLR\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">PMLR is the organization that published the Proceedings of the 41st International Conference on Machine Learning where the paper on LATS was presented.<\/data>      <data key=\"d2\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/node>    <edge source=\"LANGUAGE AGENT TREE SEARCH (LATS)\" target=\"GPT-4\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">LATS uses GPT-4 in its experimental evaluation, achieving state-of-the-art pass@1 accuracy for programming on HumanEval.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"LANGUAGE AGENT TREE SEARCH (LATS)\" target=\"GPT-3.5\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">LATS uses GPT-3.5 in its experimental evaluation, demonstrating gradient-free performance for web navigation on WebShop.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"LANGUAGE AGENT TREE SEARCH (LATS)\" target=\"MONTE CARLO TREE SEARCH (MCTS)\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">LATS integrates Monte Carlo Tree Search (MCTS) to enhance decision-making capabilities of language models.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"LANGUAGE AGENT TREE SEARCH (LATS)\" target=\"REACT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS expands upon the ReAct technique to improve reasoning and decision-making.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"LANGUAGE AGENT TREE SEARCH (LATS)\" target=\"HUMANEVAL\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS was evaluated on the HumanEval benchmark, achieving state-of-the-art pass@1 accuracy for programming with GPT-4.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"LANGUAGE AGENT TREE SEARCH (LATS)\" target=\"WEBSHOP\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS was evaluated on the WebShop benchmark, demonstrating gradient-free performance for web navigation with GPT-3.5.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"LANGUAGE AGENT TREE SEARCH (LATS)\" target=\"HOTPOTQA\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS was evaluated on the HotPotQA benchmark to demonstrate its effectiveness in decision-making and reasoning.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"LANGUAGE AGENT TREE SEARCH (LATS)\" target=\"GITHUB\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The code for LATS is available on GitHub.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"LANGUAGE AGENT TREE SEARCH (LATS)\" target=\"PROCEEDINGS OF THE 41ST INTERNATIONAL CONFERENCE ON MACHINE LEARNING\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The paper on LATS was presented at the Proceedings of the 41st International Conference on Machine Learning.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"ANDY ZHOU\" target=\"UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Andy Zhou is affiliated with the University of Illinois Urbana-Champaign.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"ANDY ZHOU\" target=\"LAPIS LABS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Andy Zhou is affiliated with Lapis Labs.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"KAI YAN\" target=\"UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Kai Yan is affiliated with the University of Illinois Urbana-Champaign.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"MICHAL SHLAPENTOKH-ROTHMAN\" target=\"UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Michal Shlapentokh-Rothman is affiliated with the University of Illinois Urbana-Champaign.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"HAOHAN WANG\" target=\"UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Haohan Wang is affiliated with the University of Illinois Urbana-Champaign.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"YU-XIONG WANG\" target=\"UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Yu-Xiong Wang is affiliated with the University of Illinois Urbana-Champaign.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"YANG ET AL.\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Yang et al. is referenced in the context of the HotPotQA benchmark used in the empirical evaluation of LATS.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"PROCEEDINGS OF THE 41ST INTERNATIONAL CONFERENCE ON MACHINE LEARNING\" target=\"PMLR 235\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The paper on LATS was published in volume 235 of the Proceedings of the 41st International Conference on Machine Learning.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"PROCEEDINGS OF THE 41ST INTERNATIONAL CONFERENCE ON MACHINE LEARNING\" target=\"2024\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The paper on LATS was presented in the year 2024.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"PROCEEDINGS OF THE 41ST INTERNATIONAL CONFERENCE ON MACHINE LEARNING\" target=\"PMLR\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">PMLR published the Proceedings of the 41st International Conference on Machine Learning where the paper on LATS was presented.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"GITHUB\" target=\"HTTPS:\/\/GITHUB.COM\/LAPISROCKS\/LANGUAGEAGENTTREESEARCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The URL where the code for LATS is available on GitHub.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"WOOLDRIDGE\" target=\"JENNINGS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Wooldridge and Jennings are co-referenced in the context of general autonomous agents capable of reasoning and decision-making in a variety of environments.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"BROWN ET AL.\" target=\"CHOWDHERY ET AL.\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Brown et al. and Chowdhery et al. are co-referenced in the context of the rise of language models with strong reasoning and general adaptability.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"BROWN ET AL.\" target=\"TOUVRON ET AL.\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Brown et al. and Touvron et al. are co-referenced in the context of the rise of language models with strong reasoning and general adaptability.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"BROWN ET AL.\" target=\"OPENAI\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Brown et al. and OpenAI are co-referenced in the context of the rise of language models with strong reasoning and general adaptability.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"CHOWDHERY ET AL.\" target=\"TOUVRON ET AL.\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Chowdhery et al. and Touvron et al. are co-referenced in the context of the rise of language models with strong reasoning and general adaptability.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"CHOWDHERY ET AL.\" target=\"OPENAI\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Chowdhery et al. and OpenAI are co-referenced in the context of the rise of language models with strong reasoning and general adaptability.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"TOUVRON ET AL.\" target=\"OPENAI\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Touvron et al. and OpenAI are co-referenced in the context of the rise of language models with strong reasoning and general adaptability.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"NALLAPATI ET AL.\" target=\"BOWMAN ET AL.\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Nallapati et al. and Bowman et al. are co-referenced in the context of language models excelling in standard natural language processing tasks.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"COBBE ET AL.\" target=\"SAPAROV AND HE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Cobbe et al. and Saparov and He are co-referenced in the context of language models being adapted to tasks requiring advanced common-sense reasoning or quantitative skills.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"YAO ET AL.\" target=\"DENG ET AL.\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Yao et al. and Deng et al. are co-referenced in the context of language models performing in complex environments such as web navigation.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"YAO ET AL.\" target=\"SCHICK ET AL.\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Yao et al. and Schick et al. are co-referenced in the context of language models performing in complex environments such as tool-use.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"YAO ET AL.\" target=\"FAN ET AL.\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Yao et al. and Fan et al. are co-referenced in the context of language models performing in complex environments such as open-ended games.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"GAO ET AL.\" target=\"SHINN ET AL.\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Gao et al. and Shinn et al. are co-referenced in the context of prompting techniques that augment language models with feedback or observations from an external environment.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"SLOMAN\" target=\"EVANS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Sloman and Evans are co-referenced in the context of the limitations of reflexive methods in language models compared to humans' deliberate and thoughtful decision-making characteristics.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>    <edge source=\"XIE ET AL.\" target=\"HAO ET AL.\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Xie et al. and Hao et al. are co-referenced in the context of recent search-guided language model work that addresses the issue of planning and multiple reasoning paths.<\/data>      <data key=\"d5\">93cb0d0456e0822b5fe30a3e627405f8<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"f8e7ed806916bf15245bcb4d52570c26","chunk":" steps. This effort is nontrivial \u2013 adapting search algo-\nrithms to language agents and shifting from non-interactive\ntasks to interactive ones requires a substantial novel design\non nodes, prompts, and search algorithms. In particular,\nnodes and prompts must effectively store and retrieve ex-\nternal feedback, with the search algorithm incorporating\nthis information into useful heuristics for value assignment.\nIndeed, our empirical evaluation, as demonstrated on Hot-\nPotQA (Yang et al., 2018) in Sec. 5.1, reveals that a simple\ncombination of existing methods is inadequate, even failing\nto surpass internal reasoning performance, despite having\naccess to the ground truth answer from the environment.\nOurkey insight underpinning LATS is adapting Monte Carlo\nTree Search (MCTS), inspired by its success in model-based\nreinforcement learning (Silver et al., 2017) and the obser-\nvation that many LM tasks allow reverting to earlier steps ,\nto language agents, repurposing pretrained LMs as agents\nwith LM-powered value functions and self-reflections for\ncleverer exploration. Leveraging the general capabilities\nand in-context learning abilities of modern LMs, we use\nlanguage as an interface between each component, allowing\nLATS to adapt planning to environmental conditions with-\nout additional training . To the best of our knowledge, LATS\nisthe first framework that incorporates reasoning, acting,\nand planning to enhance LM performance. Notably, LATS\ndoubles the performance of ReAct (Yao et al., 2023b) on\nHotPotQA (Yang et al., 2018) and raises the average score\nby22.1on WebShop (Yao et al., 2022) with GPT-3.5. When\nused with GPT-4, LATS achieves a 92.7Pass@1 rate on\nHumanEval (Chen et al., 2021), setting the state of the art.\nOurcontributions are the following: 1) We introduce LATS,\na framework based on Monte Carlo Tree Search to construct\nthe best trajectory from sampled actions, enabling more flex-\nible and adaptive problem-solving compared with reflexive\nprompting methods. 2) We propose a novel value function\nthat guides the search process and incorporates successful\nheuristics such as self-refinement and self-consistency. 3)\nBy integrating external feedback and self-reflection, LATS\nenhances model sensibility and enables agents to learn from\nexperience, surpassing reasoning-based search methods.\nThrough experiments across diverse domains, including pro-\ngramming, interactive question-answering (QA), web navi-\ngation, and math, we demonstrate the versatility of LATS\nfor enhancing autonomous reasoning and decision-making.2. Related Work\nLMs for reasoning. For LMs, reasoning involves decom-\nposing complex inputs into sequential intermediate steps\ntowards a final answer (Cobbe et al., 2021), demonstrated\nwith chain-of-thought (CoT) prompting (Wei et al., 2022)\nand its variants (Wei et al., 2022; Kojima et al., 2022; Wang\net al., 2022). However, these methods, which create chains\nautoregressively in a single step, often suffer from error\npropagation as the number of steps increases (Guo et al.,\n2018; Chen et al., 2023b), due to compound errors. Various\nadvancements aim to mitigate this issue; some approaches,\nsuch as self-consistency (Wang et al., 2022), employ ma-\njority voting over sampled chains, while others focus on\nmulti-step decomposition, such as least-to-most prompt-\ning (Zhou et al., 2022). Recently, CoT has been improved\nwith search algorithms (Yao et al., 2023a; Hao et al., 2023;\nBesta et al., 2023) that can sample trajectories more effec-\ntively. Tree-of-thought (ToT) prompting (Yao et al., 2023a)\nuses DFS or BFS-based (depth\/breadth-first) search guided\nby an LM-generated heuristic, while reasoning via planning\n(RAP) (Hao et al., 2023) uses MCTS with rollouts simu-\nlated by LMs. However, they rely solely on LM internal\nknowledge and cannot adapt to useful external feedback.\nLMs for acting. The strong reasoning and common-sense\nabilities of LMs have been further adapted for decision-\nmaking or acting tasks as a policy model in interactive\nenvironments. In robotics, LMs have been employed as\nhigh-level controllers of control policies (Ahn et al., 2022;\nHuang et al., 2022; Driess et al., 2023). Similar work (Baker\net al., 2022; Wang et al., 2023) has also adapted LM agents\nto complex multimodal games such as Minecraft (Guss et al.,\n2019; Fan et al., 2022). LMs are particularly useful in text-\nbased environments (Liu et al., 2018; Shridhar et al., 2020;\nLiu et al., 2024), where acting-based prompting techniques\nsuch as ReAct (Yao et al., 2023b) have seen success. Sim-\nilar to CoT, ReAct is limited by its simplicity and cannot\neffectively adapt to environment conditions. Many exten-\nsions have been proposed to address this issue, including\nself-refine (Madaan et al., 2023) and Reflexion (Shinn et al.,\n2023), which use self-improvement","chunk_id":"f8e7ed806916bf15245bcb4d52570c26","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"LATS","type":"FRAMEWORK","description":"LATS is a framework based on Monte Carlo Tree Search designed to enhance language model performance by incorporating reasoning, acting, and planning","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"MONTE CARLO TREE SEARCH (MCTS)","type":"ALGORITHM","description":"Monte Carlo Tree Search is an algorithm used in model-based reinforcement learning and adapted in LATS for better exploration and decision-making","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"HOTPOTQA","type":"DATASET","description":"HotPotQA is a dataset used to evaluate the performance of LATS, demonstrating its effectiveness in interactive question-answering tasks","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"REACT","type":"METHOD","description":"ReAct is a prompting technique for language models that LATS outperforms, particularly in interactive environments","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"WEBSHOP","type":"DATASET","description":"WebShop is a dataset used to evaluate LATS, where it significantly improved performance with GPT-3.5","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"GPT-3.5","type":"MODEL","description":"GPT-3.5 is a version of OpenAI's language model used in conjunction with LATS to achieve high performance on WebShop","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"GPT-4","type":"MODEL","description":"GPT-4 is a version of OpenAI's language model used with LATS to achieve a 92.7 Pass@1 rate on HumanEval","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"HUMANEVAL","type":"DATASET","description":"HumanEval is a dataset where LATS, when used with GPT-4, set the state of the art with a 92.7 Pass@1 rate","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"CHAIN-OF-THOUGHT (COT) PROMPTING","type":"METHOD","description":"Chain-of-Thought prompting is a method for decomposing complex inputs into sequential steps, often suffering from error propagation","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"SELF-CONSISTENCY","type":"METHOD","description":"Self-consistency is a method that employs majority voting over sampled chains to mitigate error propagation in Chain-of-Thought prompting","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"LEAST-TO-MOST PROMPTING","type":"METHOD","description":"Least-to-most prompting is a multi-step decomposition method aimed at improving Chain-of-Thought prompting","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"TREE-OF-THOUGHT (TOT) PROMPTING","type":"METHOD","description":"Tree-of-Thought prompting uses depth-first or breadth-first search guided by an LM-generated heuristic to improve Chain-of-Thought prompting","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"REASONING VIA PLANNING (RAP)","type":"METHOD","description":"Reasoning via Planning uses Monte Carlo Tree Search with rollouts simulated by language models to improve reasoning tasks","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"SELF-REFINE","type":"METHOD","description":"Self-refine is a method that uses self-improvement techniques to enhance language model performance in acting tasks","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"REFLEXION","type":"METHOD","description":"Reflexion is a method that uses self-improvement techniques to enhance language model performance in acting tasks","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"YANG ET AL., 2018","type":"REFERENCE","description":"Yang et al., 2018 is a reference for the HotPotQA dataset used in evaluating LATS","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"SILVER ET AL., 2017","type":"REFERENCE","description":"Silver et al., 2017 is a reference for the success of Monte Carlo Tree Search in model-based reinforcement learning","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"YAO ET AL., 2023B","type":"REFERENCE","description":"Yao et al., 2023b is a reference for the ReAct method that LATS outperforms","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"YAO ET AL., 2022","type":"REFERENCE","description":"Yao et al., 2022 is a reference for the WebShop dataset used in evaluating LATS","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"CHEN ET AL., 2021","type":"REFERENCE","description":"Chen et al., 2021 is a reference for the HumanEval dataset where LATS set the state of the art with GPT-4","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"COBBE ET AL., 2021","type":"REFERENCE","description":"Cobbe et al., 2021 is a reference for reasoning in language models involving decomposing complex inputs into sequential steps","source_id":"f8e7ed806916bf15245bcb4d52570c26","entity_type":"REFERENCE"},{"name":"WEI ET AL., 2022","type":"REFERENCE","description":"Wei et al., 2022 is a reference for Chain-of-Thought prompting and its variants","source_id":"f8e7ed806916bf15245bcb4d52570c26","entity_type":"REFERENCE"},{"name":"KOJIMA ET AL., 2022","type":"REFERENCE","description":"Kojima et al., 2022 is a reference for a variant of Chain-of-Thought prompting","source_id":"f8e7ed806916bf15245bcb4d52570c26","entity_type":"REFERENCE"},{"name":"WANG ET AL., 2022","type":"REFERENCE","description":"Wang et al., 2022 is a reference for self-consistency and Chain-of-Thought prompting","source_id":"f8e7ed806916bf15245bcb4d52570c26","entity_type":"REFERENCE"},{"name":"GUO ET AL., 2018","type":"REFERENCE","description":"Guo et al., 2018 is a reference for the issue of error propagation in Chain-of-Thought prompting","source_id":"f8e7ed806916bf15245bcb4d52570c26","entity_type":"REFERENCE"},{"name":"CHEN ET AL., 2023B","type":"REFERENCE","description":"Chen et al., 2023b is a reference for the issue of error propagation in Chain-of-Thought prompting","source_id":"f8e7ed806916bf15245bcb4d52570c26","entity_type":"REFERENCE"},{"name":"YAO ET AL., 2023A","type":"REFERENCE","description":"Yao et al., 2023a is a reference for Tree-of-Thought prompting and search algorithms in Chain-of-Thought prompting","source_id":"f8e7ed806916bf15245bcb4d52570c26","entity_type":"REFERENCE"},{"name":"HAO ET AL., 2023","type":"REFERENCE","description":"Hao et al., 2023 is a reference for Reasoning via Planning using Monte Carlo Tree Search","source_id":"f8e7ed806916bf15245bcb4d52570c26","entity_type":"REFERENCE"},{"name":"BESTA ET AL., 2023","type":"REFERENCE","description":"Besta et al., 2023 is a reference for search algorithms in Chain-of-Thought prompting","source_id":"f8e7ed806916bf15245bcb4d52570c26","entity_type":"REFERENCE"},{"name":"AHN ET AL., 2022","type":"REFERENCE","description":"Ahn et al., 2022 is a reference for using language models as high-level controllers in robotics","source_id":"f8e7ed806916bf15245bcb4d52570c26","entity_type":"REFERENCE"},{"name":"HUANG ET AL., 2022","type":"REFERENCE","description":"Huang et al., 2022 is a reference for using language models as high-level controllers in robotics","source_id":"f8e7ed806916bf15245bcb4d52570c26","entity_type":"REFERENCE"},{"name":"DRIESS ET AL., 2023","type":"REFERENCE","description":"Driess et al., 2023 is a reference for using language models as high-level controllers in robotics","source_id":"f8e7ed806916bf15245bcb4d52570c26","entity_type":"REFERENCE"},{"name":"BAKER ET AL., 2022","type":"REFERENCE","description":"Baker et al., 2022 is a reference for adapting language model agents to complex multimodal games","source_id":"f8e7ed806916bf15245bcb4d52570c26","entity_type":"REFERENCE"},{"name":"WANG ET AL., 2023","type":"REFERENCE","description":"Wang et al., 2023 is a reference for adapting language model agents to complex multimodal games","source_id":"f8e7ed806916bf15245bcb4d52570c26","entity_type":"REFERENCE"},{"name":"GUSS ET AL., 2019","type":"REFERENCE","description":"Guss et al., 2019 is a reference for the game Minecraft used in adapting language model agents","source_id":"f8e7ed806916bf15245bcb4d52570c26","entity_type":"REFERENCE"},{"name":"FAN ET AL., 2022","type":"REFERENCE","description":"Fan et al., 2022 is a reference for the game Minecraft used in adapting language model agents","source_id":"f8e7ed806916bf15245bcb4d52570c26","entity_type":"REFERENCE"},{"name":"LIU ET AL., 2018","type":"REFERENCE","description":"Liu et al., 2018 is a reference for using language models in text-based environments","source_id":"f8e7ed806916bf15245bcb4d52570c26","entity_type":"REFERENCE"},{"name":"SHRIDHAR ET AL., 2020","type":"REFERENCE","description":"Shridhar et al., 2020 is a reference for using language models in text-based environments","source_id":"f8e7ed806916bf15245bcb4d52570c26","entity_type":"REFERENCE"},{"name":"LIU ET AL., 2024","type":"REFERENCE","description":"Liu et al., 2024 is a reference for using language models in text-based environments","source_id":"f8e7ed806916bf15245bcb4d52570c26","entity_type":"REFERENCE"},{"name":"MADAAN ET AL., 2023","type":"REFERENCE","description":"Madaan et al., 2023 is a reference for the self-refine method","source_id":"f8e7ed806916bf15245bcb4d52570c26","entity_type":"REFERENCE"},{"name":"SHINN ET AL., 2023","type":"REFERENCE","description":"Shinn et al., 2023 is a reference for the Reflexion method","source_id":"f8e7ed806916bf15245bcb4d52570c26","entity_type":"REFERENCE"},{"name":"LMS FOR ACTING","type":"","description":"","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"SEARCH ALGORITHMS","type":"METHOD","description":"Search algorithms are methods used to explore and find solutions in various tasks, including language models and interactive environments","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"NODES","type":"COMPONENT","description":"Nodes are components in search algorithms that store and retrieve external feedback, contributing to value assignment heuristics","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"PROMPTS","type":"COMPONENT","description":"Prompts are components in search algorithms that store and retrieve external feedback, contributing to value assignment heuristics","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"EXTERNAL FEEDBACK","type":"CONCEPT","description":"External feedback is information from the environment that is incorporated into search algorithms to improve performance","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"INTERNAL REASONING PERFORMANCE","type":"CONCEPT","description":"Internal reasoning performance refers to the ability of a model to reason and solve tasks without external feedback","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"PRETRAINED LMS","type":"MODEL","description":"Pretrained language models are models that have been trained on large datasets and are repurposed in LATS for value functions and self-reflections","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"LM-POWERED VALUE FUNCTIONS","type":"COMPONENT","description":"LM-powered value functions are components in LATS that use language models to assign values and guide exploration","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"SELF-REFLECTIONS","type":"COMPONENT","description":"Self-reflections are components in LATS that allow language models to reflect on their actions and improve exploration","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"IN-CONTEXT LEARNING","type":"CONCEPT","description":"In-context learning is the ability of language models to learn and adapt to new tasks based on the context provided","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"ENVIRONMENTAL CONDITIONS","type":"CONCEPT","description":"Environmental conditions refer to the external factors and feedback that influence the performance of language models in LATS","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"REASONING","type":"CONCEPT","description":"Reasoning involves decomposing complex inputs into sequential intermediate steps towards a final answer","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"ACTING","type":"CONCEPT","description":"Acting involves decision-making and performing tasks in interactive environments using language models","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"PLANNING","type":"CONCEPT","description":"Planning involves creating strategies and trajectories to achieve goals in language models and interactive environments","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"AUTONOMOUS REASONING","type":"CONCEPT","description":"Autonomous reasoning refers to the ability of language models to reason and make decisions independently","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"DECISION-MAKING","type":"CONCEPT","description":"Decision-making involves choosing actions and strategies in interactive environments using language models","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"INTERACTIVE QUESTION-ANSWERING (QA)","type":"TASK","description":"Interactive question-answering is a task where language models answer questions based on interaction with the environment","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"WEB NAVIGATION","type":"TASK","description":"Web navigation is a task where language models interact with web environments to retrieve information and perform actions","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"MATH","type":"TASK","description":"Math is a task where language models solve mathematical problems and equations","source_id":"f8e7ed806916bf15245bcb4d52570c26"},{"name":"PROGRAMMING","type":"TASK","description":"Programming is a task where language models write and debug code","source_id":"f8e7ed806916bf15245bcb4d52570c26"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"LATS\">      <data key=\"d0\">FRAMEWORK<\/data>      <data key=\"d1\">LATS is a framework based on Monte Carlo Tree Search designed to enhance language model performance by incorporating reasoning, acting, and planning<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"MONTE CARLO TREE SEARCH (MCTS)\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">Monte Carlo Tree Search is an algorithm used in model-based reinforcement learning and adapted in LATS for better exploration and decision-making<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"HOTPOTQA\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">HotPotQA is a dataset used to evaluate the performance of LATS, demonstrating its effectiveness in interactive question-answering tasks<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"REACT\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">ReAct is a prompting technique for language models that LATS outperforms, particularly in interactive environments<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"WEBSHOP\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">WebShop is a dataset used to evaluate LATS, where it significantly improved performance with GPT-3.5<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"GPT-3.5\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-3.5 is a version of OpenAI's language model used in conjunction with LATS to achieve high performance on WebShop<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4 is a version of OpenAI's language model used with LATS to achieve a 92.7 Pass@1 rate on HumanEval<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"HUMANEVAL\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">HumanEval is a dataset where LATS, when used with GPT-4, set the state of the art with a 92.7 Pass@1 rate<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"CHAIN-OF-THOUGHT (COT) PROMPTING\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Chain-of-Thought prompting is a method for decomposing complex inputs into sequential steps, often suffering from error propagation<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"SELF-CONSISTENCY\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Self-consistency is a method that employs majority voting over sampled chains to mitigate error propagation in Chain-of-Thought prompting<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"LEAST-TO-MOST PROMPTING\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Least-to-most prompting is a multi-step decomposition method aimed at improving Chain-of-Thought prompting<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"TREE-OF-THOUGHT (TOT) PROMPTING\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Tree-of-Thought prompting uses depth-first or breadth-first search guided by an LM-generated heuristic to improve Chain-of-Thought prompting<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"REASONING VIA PLANNING (RAP)\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Reasoning via Planning uses Monte Carlo Tree Search with rollouts simulated by language models to improve reasoning tasks<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"SELF-REFINE\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Self-refine is a method that uses self-improvement techniques to enhance language model performance in acting tasks<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"REFLEXION\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Reflexion is a method that uses self-improvement techniques to enhance language model performance in acting tasks<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"YANG ET AL., 2018\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Yang et al., 2018 is a reference for the HotPotQA dataset used in evaluating LATS<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"SILVER ET AL., 2017\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Silver et al., 2017 is a reference for the success of Monte Carlo Tree Search in model-based reinforcement learning<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"YAO ET AL., 2023B\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Yao et al., 2023b is a reference for the ReAct method that LATS outperforms<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"YAO ET AL., 2022\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Yao et al., 2022 is a reference for the WebShop dataset used in evaluating LATS<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"CHEN ET AL., 2021\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Chen et al., 2021 is a reference for the HumanEval dataset where LATS set the state of the art with GPT-4<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"COBBE ET AL., 2021\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Cobbe et al., 2021 is a reference for reasoning in language models involving decomposing complex inputs into sequential steps<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"WEI ET AL., 2022\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Wei et al., 2022 is a reference for Chain-of-Thought prompting and its variants<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"KOJIMA ET AL., 2022\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Kojima et al., 2022 is a reference for a variant of Chain-of-Thought prompting<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"WANG ET AL., 2022\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Wang et al., 2022 is a reference for self-consistency and Chain-of-Thought prompting<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"GUO ET AL., 2018\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Guo et al., 2018 is a reference for the issue of error propagation in Chain-of-Thought prompting<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"CHEN ET AL., 2023B\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Chen et al., 2023b is a reference for the issue of error propagation in Chain-of-Thought prompting<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"YAO ET AL., 2023A\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Yao et al., 2023a is a reference for Tree-of-Thought prompting and search algorithms in Chain-of-Thought prompting<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"HAO ET AL., 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Hao et al., 2023 is a reference for Reasoning via Planning using Monte Carlo Tree Search<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"BESTA ET AL., 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Besta et al., 2023 is a reference for search algorithms in Chain-of-Thought prompting<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"AHN ET AL., 2022\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Ahn et al., 2022 is a reference for using language models as high-level controllers in robotics<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"HUANG ET AL., 2022\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Huang et al., 2022 is a reference for using language models as high-level controllers in robotics<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"DRIESS ET AL., 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Driess et al., 2023 is a reference for using language models as high-level controllers in robotics<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"BAKER ET AL., 2022\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Baker et al., 2022 is a reference for adapting language model agents to complex multimodal games<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"WANG ET AL., 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Wang et al., 2023 is a reference for adapting language model agents to complex multimodal games<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"GUSS ET AL., 2019\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Guss et al., 2019 is a reference for the game Minecraft used in adapting language model agents<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"FAN ET AL., 2022\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Fan et al., 2022 is a reference for the game Minecraft used in adapting language model agents<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"LIU ET AL., 2018\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Liu et al., 2018 is a reference for using language models in text-based environments<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"SHRIDHAR ET AL., 2020\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Shridhar et al., 2020 is a reference for using language models in text-based environments<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"LIU ET AL., 2024\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Liu et al., 2024 is a reference for using language models in text-based environments<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"MADAAN ET AL., 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Madaan et al., 2023 is a reference for the self-refine method<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"SHINN ET AL., 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Shinn et al., 2023 is a reference for the Reflexion method<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"LMS FOR ACTING\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"SEARCH ALGORITHMS\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Search algorithms are methods used to explore and find solutions in various tasks, including language models and interactive environments<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"NODES\">      <data key=\"d0\">COMPONENT<\/data>      <data key=\"d1\">Nodes are components in search algorithms that store and retrieve external feedback, contributing to value assignment heuristics<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"PROMPTS\">      <data key=\"d0\">COMPONENT<\/data>      <data key=\"d1\">Prompts are components in search algorithms that store and retrieve external feedback, contributing to value assignment heuristics<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"EXTERNAL FEEDBACK\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">External feedback is information from the environment that is incorporated into search algorithms to improve performance<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"INTERNAL REASONING PERFORMANCE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Internal reasoning performance refers to the ability of a model to reason and solve tasks without external feedback<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"PRETRAINED LMS\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Pretrained language models are models that have been trained on large datasets and are repurposed in LATS for value functions and self-reflections<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"LM-POWERED VALUE FUNCTIONS\">      <data key=\"d0\">COMPONENT<\/data>      <data key=\"d1\">LM-powered value functions are components in LATS that use language models to assign values and guide exploration<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"SELF-REFLECTIONS\">      <data key=\"d0\">COMPONENT<\/data>      <data key=\"d1\">Self-reflections are components in LATS that allow language models to reflect on their actions and improve exploration<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"IN-CONTEXT LEARNING\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">In-context learning is the ability of language models to learn and adapt to new tasks based on the context provided<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"ENVIRONMENTAL CONDITIONS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Environmental conditions refer to the external factors and feedback that influence the performance of language models in LATS<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"REASONING\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Reasoning involves decomposing complex inputs into sequential intermediate steps towards a final answer<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"ACTING\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Acting involves decision-making and performing tasks in interactive environments using language models<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"PLANNING\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Planning involves creating strategies and trajectories to achieve goals in language models and interactive environments<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"AUTONOMOUS REASONING\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Autonomous reasoning refers to the ability of language models to reason and make decisions independently<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"DECISION-MAKING\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Decision-making involves choosing actions and strategies in interactive environments using language models<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"INTERACTIVE QUESTION-ANSWERING (QA)\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">Interactive question-answering is a task where language models answer questions based on interaction with the environment<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"WEB NAVIGATION\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">Web navigation is a task where language models interact with web environments to retrieve information and perform actions<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"MATH\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">Math is a task where language models solve mathematical problems and equations<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <node id=\"PROGRAMMING\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">Programming is a task where language models write and debug code<\/data>      <data key=\"d2\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/node>    <edge source=\"LATS\" target=\"MONTE CARLO TREE SEARCH (MCTS)\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">LATS is based on Monte Carlo Tree Search to enhance language model performance<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"HOTPOTQA\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS was evaluated on the HotPotQA dataset<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"REACT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS outperforms the ReAct method<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"WEBSHOP\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS significantly improved performance on the WebShop dataset<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"GPT-3.5\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS was used with GPT-3.5 to achieve high performance on WebShop<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"GPT-4\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">LATS was used with GPT-4 to achieve a 92.7 Pass@1 rate on HumanEval<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"HUMANEVAL\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">LATS set the state of the art on HumanEval with GPT-4<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"SEARCH ALGORITHMS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS adapts search algorithms to language agents for better performance<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"NODES\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Nodes in LATS store and retrieve external feedback<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"PROMPTS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Prompts in LATS store and retrieve external feedback<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"EXTERNAL FEEDBACK\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS incorporates external feedback to improve performance<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"INTERNAL REASONING PERFORMANCE\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">LATS aims to surpass internal reasoning performance<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"PRETRAINED LMS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS repurposes pretrained language models for value functions and self-reflections<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"LM-POWERED VALUE FUNCTIONS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS uses LM-powered value functions to guide exploration<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"SELF-REFLECTIONS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS uses self-reflections to improve exploration<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"IN-CONTEXT LEARNING\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS leverages in-context learning abilities of modern language models<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"ENVIRONMENTAL CONDITIONS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS adapts planning to environmental conditions<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"REASONING\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS incorporates reasoning to enhance language model performance<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"ACTING\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS incorporates acting to enhance language model performance<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"PLANNING\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS incorporates planning to enhance language model performance<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"AUTONOMOUS REASONING\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS enhances autonomous reasoning in language models<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"DECISION-MAKING\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS enhances decision-making in language models<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"INTERACTIVE QUESTION-ANSWERING (QA)\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS is evaluated on interactive question-answering tasks<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"WEB NAVIGATION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS is evaluated on web navigation tasks<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"MATH\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS is evaluated on math tasks<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LATS\" target=\"PROGRAMMING\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS is evaluated on programming tasks<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"MONTE CARLO TREE SEARCH (MCTS)\" target=\"SILVER ET AL., 2017\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Silver et al., 2017 is the reference for the success of Monte Carlo Tree Search in model-based reinforcement learning<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"YANG ET AL., 2018\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yang et al., 2018 is the reference for the HotPotQA dataset<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"REACT\" target=\"YAO ET AL., 2023B\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yao et al., 2023b is the reference for the ReAct method<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"YAO ET AL., 2022\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yao et al., 2022 is the reference for the WebShop dataset<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"HUMANEVAL\" target=\"CHEN ET AL., 2021\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Chen et al., 2021 is the reference for the HumanEval dataset<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT (COT) PROMPTING\" target=\"SELF-CONSISTENCY\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Self-consistency is a method to improve Chain-of-Thought prompting<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT (COT) PROMPTING\" target=\"LEAST-TO-MOST PROMPTING\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Least-to-most prompting is a method to improve Chain-of-Thought prompting<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT (COT) PROMPTING\" target=\"TREE-OF-THOUGHT (TOT) PROMPTING\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Tree-of-Thought prompting is a method to improve Chain-of-Thought prompting<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT (COT) PROMPTING\" target=\"REASONING VIA PLANNING (RAP)\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Reasoning via Planning is a method to improve Chain-of-Thought prompting<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT (COT) PROMPTING\" target=\"COBBE ET AL., 2021\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Cobbe et al., 2021 is the reference for reasoning in language models involving decomposing complex inputs into sequential steps<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT (COT) PROMPTING\" target=\"WEI ET AL., 2022\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Wei et al., 2022 is the reference for Chain-of-Thought prompting and its variants<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT (COT) PROMPTING\" target=\"KOJIMA ET AL., 2022\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Kojima et al., 2022 is the reference for a variant of Chain-of-Thought prompting<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT (COT) PROMPTING\" target=\"WANG ET AL., 2022\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Wang et al., 2022 is the reference for self-consistency and Chain-of-Thought prompting<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT (COT) PROMPTING\" target=\"GUO ET AL., 2018\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Guo et al., 2018 is the reference for the issue of error propagation in Chain-of-Thought prompting<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT (COT) PROMPTING\" target=\"CHEN ET AL., 2023B\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Chen et al., 2023b is the reference for the issue of error propagation in Chain-of-Thought prompting<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT (COT) PROMPTING\" target=\"BESTA ET AL., 2023\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Besta et al., 2023 is the reference for search algorithms in Chain-of-Thought prompting<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT (COT) PROMPTING\" target=\"YAO ET AL., 2023A\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yao et al., 2023a is the reference for Tree-of-Thought prompting and search algorithms in Chain-of-Thought prompting<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT (COT) PROMPTING\" target=\"HAO ET AL., 2023\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Hao et al., 2023 is the reference for Reasoning via Planning using Monte Carlo Tree Search<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"TREE-OF-THOUGHT (TOT) PROMPTING\" target=\"YAO ET AL., 2023A\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yao et al., 2023a is the reference for Tree-of-Thought prompting and search algorithms in Chain-of-Thought prompting<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"REASONING VIA PLANNING (RAP)\" target=\"HAO ET AL., 2023\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Hao et al., 2023 is the reference for Reasoning via Planning using Monte Carlo Tree Search<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"SELF-REFINE\" target=\"REFLEXION\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Both Self-refine and Reflexion are methods that use self-improvement techniques to enhance language model performance<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"SELF-REFINE\" target=\"MADAAN ET AL., 2023\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Madaan et al., 2023 is the reference for the self-refine method<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"REFLEXION\" target=\"SHINN ET AL., 2023\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Shinn et al., 2023 is the reference for the Reflexion method<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"AHN ET AL., 2022\" target=\"LMS FOR ACTING\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Ahn et al., 2022 is the reference for using language models as high-level controllers in robotics<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"HUANG ET AL., 2022\" target=\"LMS FOR ACTING\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Huang et al., 2022 is the reference for using language models as high-level controllers in robotics<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"DRIESS ET AL., 2023\" target=\"LMS FOR ACTING\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Driess et al., 2023 is the reference for using language models as high-level controllers in robotics<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"BAKER ET AL., 2022\" target=\"LMS FOR ACTING\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Baker et al., 2022 is the reference for adapting language model agents to complex multimodal games<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"WANG ET AL., 2023\" target=\"LMS FOR ACTING\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Wang et al., 2023 is the reference for adapting language model agents to complex multimodal games<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"GUSS ET AL., 2019\" target=\"LMS FOR ACTING\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Guss et al., 2019 is the reference for the game Minecraft used in adapting language model agents<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"FAN ET AL., 2022\" target=\"LMS FOR ACTING\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Fan et al., 2022 is the reference for the game Minecraft used in adapting language model agents<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LIU ET AL., 2018\" target=\"LMS FOR ACTING\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Liu et al., 2018 is the reference for using language models in text-based environments<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"SHRIDHAR ET AL., 2020\" target=\"LMS FOR ACTING\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Shridhar et al., 2020 is the reference for using language models in text-based environments<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>    <edge source=\"LIU ET AL., 2024\" target=\"LMS FOR ACTING\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Liu et al., 2024 is the reference for using language models in text-based environments<\/data>      <data key=\"d6\">f8e7ed806916bf15245bcb4d52570c26<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"c95e02c0dca4a4a36b701cbc7dd14da6","chunk":"2024), where acting-based prompting techniques\nsuch as ReAct (Yao et al., 2023b) have seen success. Sim-\nilar to CoT, ReAct is limited by its simplicity and cannot\neffectively adapt to environment conditions. Many exten-\nsions have been proposed to address this issue, including\nself-refine (Madaan et al., 2023) and Reflexion (Shinn et al.,\n2023), which use self-improvement to enhance reasoning\nand decision-making, and AdaPlanner (Sun et al., 2023),\nwhich incorporates both positive and negative feedback.\nHowever, these methods focus on refining an individual tra-\njectory and do not consider alternative choices at each step.\nIn addition, recent work (Huang et al., 2024) has suggested\nthat LMs cannot self-correct their internal reasoning, mak-\ning it critical to use external feedback. Alternatively, to pure\ndecision-making environments, the reasoning and practical\nabilities of LMs have been enhanced by providing access\nto external tools, such as APIs, search engines, calculators,\nand other models (Schick et al., 2023; Shen et al., 2023;\nSur\u00b4\u0131s et al., 2023). We summarize prior work in Tab. 1.\nTree-based search. Tree-based search, where multiple\n2Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nApproach Reasoning Acting Planning Self- External\nReflection Memory\nCoT (Wei et al., 2022) \u2713 \u00d7 \u00d7 \u00d7 \u00d7\nReAct (Yao et al., 2023b) \u2713 \u2713 \u00d7 \u00d7 \u00d7\nToT (Yao et al., 2023a) \u2713 \u00d7 \u2713 \u2713 \u2713\nRAP (Hao et al., 2023) \u2713 \u00d7 \u2713 \u00d7 \u2713\nSelf-Refine (Madaan et al., 2023) \u2713 \u00d7 \u00d7 \u2713 \u00d7\nBeam Search (Xie et al., 2023) \u2713 \u00d7 \u00d7 \u2713 \u00d7\nReflexion (Shinn et al., 2023) \u2713 \u2713 \u00d7 \u2713 \u2713\nLATS (Ours) \u2713 \u2713 \u2713 \u2713 \u2713\nTable 1. Summary of related work on reasoning, acting, and planning. LATS is the firstwork incorporating designs from allthree domains,\nallowing broad applicability in all corresponding tasks. We refer to reasoning as LM internal reasoning, acting as external decision-making,\nplanning as the use of a search algorithm, self-reflection as the use of LM-generated feedback, and external memory as storing past text\ncontext for future updates of the solution.\nbranches of outcomes are explored during search, is widely\nused in many planning algorithms (Swiechowski et al., 2021;\nLaValle, 1998) and reinforcement learning (RL) (Hafner\net al., 2019; Du et al., 2023; Wu et al., 2023) algorithms for\nits good exploration-exploitation trade-off. Note that though\ntree-based search necessitates an environment model that\ncan expand from an arbitrary state (V odopivec et al., 2017),\noften requiring extra training in RL (Hafner et al., 2023),\nsuch a problem does not exist for most LM tasks. This is\nbecause we can conveniently revert to any state by setting\nthe input to be the context and the corresponding previous\noutput from the LM for many tasks. Thus, we operate on the\ntree-based framework and use MCTS (Swiechowski et al.,\n2021) to fully unlock the potential of LMs. In addition, we\navoid the cost of training a value function over language\ndescriptions by leveraging the in-context learning (Brown\net al., 2020) abilities of LMs. Concurrent work (Liu et al.,\n2023) also explores combining search algorithms with LM\nagents but uses an off-the-shelf search algorithm, which\nmay not be optimal for LMs. Finally, following Yao et al.\n(2023a) and Hao et al. (2023), we note that we use planning\nandsearch algorithms interchangeably in this paper.\n3. Preliminaries\n3.1. Problem Setting and Prompting\nWe first define our problem and outline a few established\nmethods that leverage language models for reasoning or\ndecision-making. In LM reasoning or decision making,\nwe are given an input xin natural language and a pre-\ntrained language model p\u03b8(x)parameterized by \u03b8; our goal\nis to generate a final output y\u223cp\u03b8(x)that corresponds\nto the answer (reasoning) or completes the task (decision-\nmaking). Both xandyare language sequences , which are\ncomprised of a list of tokens (the basic elements of natural\nlanguage, often words), denoted as x= (x[1], . . . , x [lx])\nandy= (y[1], . . . , y [ly])where lxandlyare the length.The LM decodes text autoregressively, i.e., without other\ninputs, the probability for an LM to generate a sequence y\nis given by p\u03b8(x) =Qlx\ni=1p\u03b8(x[i]|x[1. . . i\u22121]). Usually,\nto improve reasoning, prompts are provided along with the\ninput x, which are specific instructions or few-shot input-\noutput examples. We denote the generic process where an\ninput prompt IO(x)is transformed into an output yby LM:\ny\u223cp\u03b8(prompt IO(x)).\nChain-of-thought (CoT) prompting (Wei et al., 2022)\ncaters to scenarios where the direct mapping from xtoyis\nintricate, e.g","chunk_id":"c95e02c0dca4a4a36b701cbc7dd14da6","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"REACT","type":"TECHNIQUE","description":"ReAct is an acting-based prompting technique that has seen success but is limited by its simplicity and inability to adapt to environment conditions","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"COT","type":"TECHNIQUE","description":"Chain-of-thought (CoT) prompting is a technique that caters to scenarios where the direct mapping from input to output is intricate","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"SELF-REFINE","type":"TECHNIQUE","description":"Self-Refine is a technique that uses self-improvement to enhance reasoning and decision-making","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"REFLEXION","type":"TECHNIQUE","description":"Reflexion is a technique that uses self-improvement to enhance reasoning and decision-making","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"ADAPLANNER","type":"TECHNIQUE","description":"AdaPlanner is a technique that incorporates both positive and negative feedback to enhance reasoning and decision-making","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"HUANG ET AL.","type":"AUTHOR","description":"Huang et al. are authors who suggested that language models cannot self-correct their internal reasoning, making it critical to use external feedback","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"EXTERNAL TOOLS","type":"RESOURCE","description":"External tools such as APIs, search engines, calculators, and other models are used to enhance the reasoning and practical abilities of language models","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"TREE-BASED SEARCH","type":"TECHNIQUE","description":"Tree-based search is a method where multiple branches of outcomes are explored during search, widely used in planning and reinforcement learning algorithms","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"MCTS","type":"TECHNIQUE","description":"Monte Carlo Tree Search (MCTS) is a tree-based search algorithm used to fully unlock the potential of language models","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"IN-CONTEXT LEARNING","type":"TECHNIQUE","description":"In-context learning leverages the abilities of language models to learn from the context without additional training","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"LM","type":"MODEL","description":"Language Model (LM) is a pre-trained model parameterized to generate outputs corresponding to answers or task completions based on given inputs","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"PROMPTS","type":"RESOURCE","description":"Prompts are specific instructions or few-shot input-output examples provided along with the input to improve reasoning in language models","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"YA0 ET AL.","type":"AUTHOR","description":"Yao et al. are authors who have contributed to the development of techniques like ReAct and ToT","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6","entity_type":"AUTHOR"},{"name":"HAO ET AL.","type":"AUTHOR","description":"Hao et al. are authors who have contributed to the development of techniques like RAP","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6","entity_type":"AUTHOR"},{"name":"SELF-REFLECTION","type":"TECHNIQUE","description":"Self-reflection is the use of language model-generated feedback to improve reasoning and decision-making","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"EXTERNAL MEMORY","type":"RESOURCE","description":"External memory is used to store past text context for future updates of the solution in language models","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"LATS","type":"TECHNIQUE","description":"Language Agent Tree Search (LATS) is a technique that unifies reasoning, acting, and planning in language models, incorporating designs from all three domains","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"REINFORCEMENT LEARNING","type":"TECHNIQUE","description":"Reinforcement learning is a type of machine learning algorithm used for its good exploration-exploitation trade-off in planning algorithms","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"VODOPIVEC ET AL.","type":"AUTHOR","description":"Vodopivec et al. are authors who have contributed to the understanding of tree-based search in reinforcement learning","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"BROWN ET AL.","type":"AUTHOR","description":"Brown et al. are authors who have contributed to the understanding of in-context learning in language models","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"LIU ET AL.","type":"AUTHOR","description":"Liu et al. are authors who have explored combining search algorithms with language model agents","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"WEI ET AL.","type":"AUTHOR","description":"Wei et al. are authors who have contributed to the development of Chain-of-thought (CoT) prompting","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"SWIECHOWSKI ET AL.","type":"AUTHOR","description":"Swiechowski et al. are authors who have contributed to the understanding of tree-based search in planning algorithms","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"LAVALLE","type":"AUTHOR","description":"LaValle is an author who has contributed to the understanding of tree-based search in planning algorithms","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"HAFNER ET AL.","type":"AUTHOR","description":"Hafner et al. are authors who have contributed to the understanding of tree-based search in reinforcement learning","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"DU ET AL.","type":"AUTHOR","description":"Du et al. are authors who have contributed to the understanding of tree-based search in reinforcement learning","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"WU ET AL.","type":"AUTHOR","description":"Wu et al. are authors who have contributed to the understanding of tree-based search in reinforcement learning","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6"},{"name":"SHICK ET AL.","type":"AUTHOR","description":"Schick et al. are authors who have contributed to the understanding of using external tools to enhance language models","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6","entity_type":"AUTHOR"},{"name":"SHEN ET AL.","type":"AUTHOR","description":"Shen et al. are authors who have contributed to the understanding of using external tools to enhance language models","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6","entity_type":"AUTHOR"},{"name":"SURIS ET AL.","type":"AUTHOR","description":"Suris et al. are authors who have contributed to the understanding of using external tools to enhance language models","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6","entity_type":"AUTHOR"},{"name":"XIE ET AL.","type":"AUTHOR","description":"Xie et al. are authors who have contributed to the understanding of beam search in language models","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6","entity_type":"AUTHOR"},{"name":"LM TASKS","type":"TASK","description":"LM tasks refer to the various tasks that language models can perform, such as reasoning, decision-making, and planning","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6","entity_type":"TASK"},{"name":"PLANNING","type":"TECHNIQUE","description":"Planning refers to the use of a search algorithm to determine the best course of action in language models","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6","entity_type":"TECHNIQUE"},{"name":"SEARCH ALGORITHMS","type":"TECHNIQUE","description":"Search algorithms are used to explore multiple branches of outcomes and determine the best course of action in language models","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6","entity_type":"TECHNIQUE"},{"name":"RAP","type":"TECHNIQUE","description":"RAP is a technique that incorporates planning and search algorithms to enhance reasoning and decision-making in language models","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6","entity_type":"TECHNIQUE"},{"name":"TOT","type":"TECHNIQUE","description":"ToT is a technique that incorporates planning and search algorithms to enhance reasoning and decision-making in language models","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6","entity_type":"TECHNIQUE"},{"name":"BEAM SEARCH","type":"TECHNIQUE","description":"Beam search is a technique that uses self-improvement to enhance reasoning and decision-making in language models","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6","entity_type":"TECHNIQUE"},{"name":"LM INTERNAL REASONING","type":"TECHNIQUE","description":"LM internal reasoning refers to the reasoning capabilities of language models without external inputs","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6","entity_type":"TECHNIQUE"},{"name":"DECISION-MAKING","type":"TECHNIQUE","description":"Decision-making refers to the process of making choices based on reasoning and planning in language models","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6","entity_type":"TECHNIQUE"},{"name":"PROMPT IO","type":"RESOURCE","description":"Prompt IO refers to the process where an input prompt is transformed into an output by a language model","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6","entity_type":"RESOURCE"},{"name":"TOKEN","type":"RESOURCE","description":"Tokens are the basic elements of natural language, often words, used in language models","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6","entity_type":"RESOURCE"},{"name":"INPUT X","type":"RESOURCE","description":"Input X refers to the initial input provided to a language model for reasoning or decision-making","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6","entity_type":"RESOURCE"},{"name":"OUTPUT Y","type":"RESOURCE","description":"Output Y refers to the final output generated by a language model based on the given input","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6","entity_type":"RESOURCE"},{"name":"P\u0398(X)","type":"MODEL","description":"P\u03b8(X) refers to the pre-trained language model parameterized by \u03b8 used to generate outputs based on given inputs","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6","entity_type":"MODEL"},{"name":"AUTOREGRESSIVE DECODING","type":"TECHNIQUE","description":"Autoregressive decoding is a method where the language model generates text sequentially, predicting the next token based on previous tokens","source_id":"c95e02c0dca4a4a36b701cbc7dd14da6","entity_type":"TECHNIQUE"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"REACT\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">ReAct is an acting-based prompting technique that has seen success but is limited by its simplicity and inability to adapt to environment conditions<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"COT\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Chain-of-thought (CoT) prompting is a technique that caters to scenarios where the direct mapping from input to output is intricate<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"SELF-REFINE\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Self-Refine is a technique that uses self-improvement to enhance reasoning and decision-making<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"REFLEXION\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Reflexion is a technique that uses self-improvement to enhance reasoning and decision-making<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"ADAPLANNER\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">AdaPlanner is a technique that incorporates both positive and negative feedback to enhance reasoning and decision-making<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"HUANG ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Huang et al. are authors who suggested that language models cannot self-correct their internal reasoning, making it critical to use external feedback<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"EXTERNAL TOOLS\">      <data key=\"d0\">RESOURCE<\/data>      <data key=\"d1\">External tools such as APIs, search engines, calculators, and other models are used to enhance the reasoning and practical abilities of language models<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"TREE-BASED SEARCH\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Tree-based search is a method where multiple branches of outcomes are explored during search, widely used in planning and reinforcement learning algorithms<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"MCTS\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Monte Carlo Tree Search (MCTS) is a tree-based search algorithm used to fully unlock the potential of language models<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"IN-CONTEXT LEARNING\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">In-context learning leverages the abilities of language models to learn from the context without additional training<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"LM\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Language Model (LM) is a pre-trained model parameterized to generate outputs corresponding to answers or task completions based on given inputs<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"PROMPTS\">      <data key=\"d0\">RESOURCE<\/data>      <data key=\"d1\">Prompts are specific instructions or few-shot input-output examples provided along with the input to improve reasoning in language models<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"YA0 ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Yao et al. are authors who have contributed to the development of techniques like ReAct and ToT<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"HAO ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Hao et al. are authors who have contributed to the development of techniques like RAP<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"SELF-REFLECTION\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Self-reflection is the use of language model-generated feedback to improve reasoning and decision-making<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"EXTERNAL MEMORY\">      <data key=\"d0\">RESOURCE<\/data>      <data key=\"d1\">External memory is used to store past text context for future updates of the solution in language models<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"LATS\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Language Agent Tree Search (LATS) is a technique that unifies reasoning, acting, and planning in language models, incorporating designs from all three domains<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"REINFORCEMENT LEARNING\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Reinforcement learning is a type of machine learning algorithm used for its good exploration-exploitation trade-off in planning algorithms<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"VODOPIVEC ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Vodopivec et al. are authors who have contributed to the understanding of tree-based search in reinforcement learning<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"BROWN ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Brown et al. are authors who have contributed to the understanding of in-context learning in language models<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"LIU ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Liu et al. are authors who have explored combining search algorithms with language model agents<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"WEI ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Wei et al. are authors who have contributed to the development of Chain-of-thought (CoT) prompting<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"SWIECHOWSKI ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Swiechowski et al. are authors who have contributed to the understanding of tree-based search in planning algorithms<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"LAVALLE\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">LaValle is an author who has contributed to the understanding of tree-based search in planning algorithms<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"HAFNER ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Hafner et al. are authors who have contributed to the understanding of tree-based search in reinforcement learning<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"DU ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Du et al. are authors who have contributed to the understanding of tree-based search in reinforcement learning<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"WU ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Wu et al. are authors who have contributed to the understanding of tree-based search in reinforcement learning<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/node>    <node id=\"SHICK ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Schick et al. are authors who have contributed to the understanding of using external tools to enhance language models<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"SHEN ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Shen et al. are authors who have contributed to the understanding of using external tools to enhance language models<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"SURIS ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Suris et al. are authors who have contributed to the understanding of using external tools to enhance language models<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"XIE ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Xie et al. are authors who have contributed to the understanding of beam search in language models<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"LM TASKS\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">LM tasks refer to the various tasks that language models can perform, such as reasoning, decision-making, and planning<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>      <data key=\"d3\">TASK<\/data>    <\/node>    <node id=\"PLANNING\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Planning refers to the use of a search algorithm to determine the best course of action in language models<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>      <data key=\"d3\">TECHNIQUE<\/data>    <\/node>    <node id=\"SEARCH ALGORITHMS\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Search algorithms are used to explore multiple branches of outcomes and determine the best course of action in language models<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>      <data key=\"d3\">TECHNIQUE<\/data>    <\/node>    <node id=\"RAP\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">RAP is a technique that incorporates planning and search algorithms to enhance reasoning and decision-making in language models<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>      <data key=\"d3\">TECHNIQUE<\/data>    <\/node>    <node id=\"TOT\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">ToT is a technique that incorporates planning and search algorithms to enhance reasoning and decision-making in language models<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>      <data key=\"d3\">TECHNIQUE<\/data>    <\/node>    <node id=\"BEAM SEARCH\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Beam search is a technique that uses self-improvement to enhance reasoning and decision-making in language models<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>      <data key=\"d3\">TECHNIQUE<\/data>    <\/node>    <node id=\"LM INTERNAL REASONING\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">LM internal reasoning refers to the reasoning capabilities of language models without external inputs<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>      <data key=\"d3\">TECHNIQUE<\/data>    <\/node>    <node id=\"DECISION-MAKING\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Decision-making refers to the process of making choices based on reasoning and planning in language models<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>      <data key=\"d3\">TECHNIQUE<\/data>    <\/node>    <node id=\"PROMPT IO\">      <data key=\"d0\">RESOURCE<\/data>      <data key=\"d1\">Prompt IO refers to the process where an input prompt is transformed into an output by a language model<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>      <data key=\"d3\">RESOURCE<\/data>    <\/node>    <node id=\"TOKEN\">      <data key=\"d0\">RESOURCE<\/data>      <data key=\"d1\">Tokens are the basic elements of natural language, often words, used in language models<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>      <data key=\"d3\">RESOURCE<\/data>    <\/node>    <node id=\"INPUT X\">      <data key=\"d0\">RESOURCE<\/data>      <data key=\"d1\">Input X refers to the initial input provided to a language model for reasoning or decision-making<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>      <data key=\"d3\">RESOURCE<\/data>    <\/node>    <node id=\"OUTPUT Y\">      <data key=\"d0\">RESOURCE<\/data>      <data key=\"d1\">Output Y refers to the final output generated by a language model based on the given input<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>      <data key=\"d3\">RESOURCE<\/data>    <\/node>    <node id=\"P&#920;(X)\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">P&#952;(X) refers to the pre-trained language model parameterized by &#952; used to generate outputs based on given inputs<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"AUTOREGRESSIVE DECODING\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Autoregressive decoding is a method where the language model generates text sequentially, predicting the next token based on previous tokens<\/data>      <data key=\"d2\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>      <data key=\"d3\">TECHNIQUE<\/data>    <\/node>    <edge source=\"REACT\" target=\"COT\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">ReAct and CoT are both prompting techniques used in language models<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"REACT\" target=\"YA0 ET AL.\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">Yao et al. contributed to the development of the ReAct technique<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"REACT\" target=\"LATS\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">LATS incorporates designs from ReAct for reasoning, acting, and planning<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"COT\" target=\"LATS\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">LATS incorporates designs from CoT for reasoning, acting, and planning<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"COT\" target=\"WEI ET AL.\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">Wei et al. contributed to the development of Chain-of-thought (CoT) prompting<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"SELF-REFINE\" target=\"REFLEXION\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Self-Refine and Reflexion both use self-improvement to enhance reasoning and decision-making<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"SELF-REFINE\" target=\"ADAPLANNER\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">AdaPlanner and Self-Refine both aim to enhance reasoning and decision-making<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"SELF-REFINE\" target=\"LATS\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">LATS incorporates designs from Self-Refine for reasoning, acting, and planning<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"SELF-REFINE\" target=\"BEAM SEARCH\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Beam search uses self-improvement to enhance reasoning and decision-making in language models<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"REFLEXION\" target=\"ADAPLANNER\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">AdaPlanner and Reflexion both aim to enhance reasoning and decision-making<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"REFLEXION\" target=\"LATS\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">LATS incorporates designs from Reflexion for reasoning, acting, and planning<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"ADAPLANNER\" target=\"LATS\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">LATS incorporates designs from AdaPlanner for reasoning, acting, and planning<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"HUANG ET AL.\" target=\"EXTERNAL TOOLS\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Huang et al. suggested the use of external tools to enhance the reasoning and practical abilities of language models<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"EXTERNAL TOOLS\" target=\"SHICK ET AL.\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Schick et al. contributed to the understanding of using external tools to enhance language models<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"EXTERNAL TOOLS\" target=\"SHEN ET AL.\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Shen et al. contributed to the understanding of using external tools to enhance language models<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"EXTERNAL TOOLS\" target=\"SURIS ET AL.\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Suris et al. contributed to the understanding of using external tools to enhance language models<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"TREE-BASED SEARCH\" target=\"MCTS\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">Tree-based search and MCTS are both search algorithms used to explore multiple branches of outcomes<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"TREE-BASED SEARCH\" target=\"REINFORCEMENT LEARNING\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Reinforcement learning and tree-based search are both used for their good exploration-exploitation trade-off in planning algorithms<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"TREE-BASED SEARCH\" target=\"VODOPIVEC ET AL.\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Vodopivec et al. contributed to the understanding of tree-based search in reinforcement learning<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"TREE-BASED SEARCH\" target=\"SWIECHOWSKI ET AL.\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Swiechowski et al. contributed to the understanding of tree-based search in planning algorithms<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"TREE-BASED SEARCH\" target=\"LAVALLE\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">LaValle contributed to the understanding of tree-based search in planning algorithms<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"TREE-BASED SEARCH\" target=\"HAFNER ET AL.\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Hafner et al. contributed to the understanding of tree-based search in reinforcement learning<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"TREE-BASED SEARCH\" target=\"DU ET AL.\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Du et al. contributed to the understanding of tree-based search in reinforcement learning<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"TREE-BASED SEARCH\" target=\"WU ET AL.\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Wu et al. contributed to the understanding of tree-based search in reinforcement learning<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"IN-CONTEXT LEARNING\" target=\"LM\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">In-context learning leverages the abilities of language models to learn from the context<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"IN-CONTEXT LEARNING\" target=\"BROWN ET AL.\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Brown et al. contributed to the understanding of in-context learning in language models<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"LM\" target=\"PROMPTS\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Prompts are provided along with the input to improve reasoning in language models<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"LM\" target=\"SELF-REFLECTION\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Self-reflection uses language model-generated feedback to improve reasoning and decision-making<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"LM\" target=\"EXTERNAL MEMORY\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">External memory is used to store past text context for future updates of the solution in language models<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"LM\" target=\"LM TASKS\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">LM tasks refer to the various tasks that language models can perform<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"LM\" target=\"LM INTERNAL REASONING\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">LM internal reasoning refers to the reasoning capabilities of language models without external inputs<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"LM\" target=\"DECISION-MAKING\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Decision-making refers to the process of making choices based on reasoning and planning in language models<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"LM\" target=\"PROMPT IO\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Prompt IO refers to the process where an input prompt is transformed into an output by a language model<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"LM\" target=\"TOKEN\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Tokens are the basic elements of natural language used in language models<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"LM\" target=\"INPUT X\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Input X refers to the initial input provided to a language model for reasoning or decision-making<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"LM\" target=\"OUTPUT Y\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Output Y refers to the final output generated by a language model based on the given input<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"LM\" target=\"P&#920;(X)\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">P&#952;(X) refers to the pre-trained language model parameterized by &#952; used to generate outputs based on given inputs<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"LM\" target=\"AUTOREGRESSIVE DECODING\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Autoregressive decoding is a method where the language model generates text sequentially<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"YA0 ET AL.\" target=\"TOT\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">Yao et al. contributed to the development of the ToT technique<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"HAO ET AL.\" target=\"RAP\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">Hao et al. contributed to the development of the RAP technique<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"LIU ET AL.\" target=\"SEARCH ALGORITHMS\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Liu et al. explored combining search algorithms with language model agents<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"XIE ET AL.\" target=\"BEAM SEARCH\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Xie et al. contributed to the understanding of beam search in language models<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"PLANNING\" target=\"SEARCH ALGORITHMS\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Planning refers to the use of a search algorithm to determine the best course of action in language models<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"SEARCH ALGORITHMS\" target=\"RAP\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">RAP incorporates planning and search algorithms to enhance reasoning and decision-making in language models<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>    <edge source=\"SEARCH ALGORITHMS\" target=\"TOT\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">ToT incorporates planning and search algorithms to enhance reasoning and decision-making in language models<\/data>      <data key=\"d6\">c95e02c0dca4a4a36b701cbc7dd14da6<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"9bb90746134619cad9a3e649b8b35f24","chunk":" . i\u22121]). Usually,\nto improve reasoning, prompts are provided along with the\ninput x, which are specific instructions or few-shot input-\noutput examples. We denote the generic process where an\ninput prompt IO(x)is transformed into an output yby LM:\ny\u223cp\u03b8(prompt IO(x)).\nChain-of-thought (CoT) prompting (Wei et al., 2022)\ncaters to scenarios where the direct mapping from xtoyis\nintricate, e.g., when xis from a mathematical query or chal-\nlenging question. It hinges on creating thoughts z1, . . . , z l\nthat act as stepping stones between xandy; each thought zi\nis a language sequence. To employ CoT prompting, thoughts\nare extracted sequentially as zi\u223cpCoT\n\u03b8(x, z1\u00b7\u00b7\u00b7i\u22121), with\nthe final output being y\u223cpCoT\n\u03b8(x, z1\u00b7\u00b7\u00b7l).\nTree-of-thought (ToT) prompting (Yao et al., 2023a) ex-\ntends CoT prompting by exploring multiple reasoning paths\nover thoughts. It frames problems as a search over a tree,\nwhere each node s= [x, z1\u00b7i]represents a partial solution\nstate comprising the original input xand the thought se-\nquence z1\u00b7\u00b7\u00b7i. Thoughts ziare generated by proposal or\nsampling with CoT zi\u223cpCoT\n\u03b8(x, z1\u00b7\u00b7\u00b7i\u22121). Search algo-\nrithms like depth-first (DFS) or breadth-first (BFS) search\nare used to systematically explore the tree, guided by heuris-\ntics based on LM evaluations V(s)of each state.\nReAct (Yao et al., 2023b) extends language models to\ntasks where the mapping from xtoyis enhanced by or\nrequires interactions with an external environment, such\nas a game or API. This technique constructs an action\nspace \u02c6A=A\u222aZthat adds permissible actions a\u2208A\nto the reasoning traces z\u2208Zfrom CoT. Observations o\nfrom the environment are used to improve both reasoning\nand acting. To solve problems with ReAct, after each ob-\nservation, actions are generated from p\u03b8sequentially as\nai\u223cpReAct\n\u03b8 (x, o1\u00b7\u00b7\u00b7i\u22121, a1\u00b7\u00b7\u00b7i\u22121), with the final output be-\n3Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\ningy\u223cpReAct\n\u03b8 (x, o1\u00b7\u00b7\u00b7l, a1\u00b7\u00b7\u00b7l). In this paper, consistent\nwith other LM agent methods such as ReAct and Reflexion\n(Shinn et al., 2023), we focus on decision-making tasks\nwhere reverting between iterations is feasible .\nWhile the previously described prompting techniques im-\nprove LM performance on reasoning tasks, they falter on\ndifficult tasks that involve multifaceted decision-making\ndue to several shortcomings: 1) Flexibility : Base prompting\ndesigns (CoT or ReAct) autoregressively sample from the\nLM, neglecting potential alternative continuations from spe-\ncific states. 2) Sensibility : Reasoning-based methods (CoT,\nRAP (Hao et al., 2023), or ToT) rely solely on the inter-\nnal representations of the LM and cannot consider external\nobservations. This dependency risks fact hallucination and\nerror propagation while setting a performance ceiling. 3)\nAdaptability : Current planning strategies (RAP or ToT) use\nsimple search algorithms such as BFS or cannot leverage\nenvironmental feedback to improve planning. Additionally,\nthe agent is static and cannot reuse previous experience or\nlearn from trial and error. While RAP also adopts MCTS, it\nis constrained to tasks where the LM can become a world\nmodel and accurately predict states. These shortcomings\nlimit the ability of LMs to be deployed as general problem-\nsolving agents and form the motivation for LATS.\n3.2. Monte Carlo Tree Search (MCTS)\nMonte Carlo Tree Search (MCTS) is a heuristic search al-\ngorithm that is proved successful on many decision-making\nenvironments, such as Atari (Ye et al., 2021) and Go (Silver\net al., 2016). MCTS builds a decision tree where every node\nin the tree is a state and edge is an action. MCTS runs for k\nepisodes; for each episode, it starts from the root (i.e., initial\nstate) and iteratively conducts two steps to expand the tree:\n1)Expansion , where multiple children states sare explored\nfrom the current parent state pby sampling nactions, and 2)\nSelection , where the children with the highest UCT (Upper\nConfidence bounds applied to Trees) (Kocsis and Szepesv \u00b4ari,\n2006) value is selected for expansion by the next iteration.\nThe UCT of a child state sis calculated as follows:\nUCT (s) =V(s) +ws\nlnN(p)\nN(s), (1)\nwhere N(s)is the number of visits to a node s,V(s)is the\nvalue function (expected return) from the subtree of s,wis\nthe exploration weight, and pis the parent node of s. When\nthe end of an episode is reached, a backpropagation is car-\nried out: the return ris used for updating every V(s)along\nthe path with the formula V(s) =Vold(s)(N(s)\u22121)+r\nN(s), where\nVold(s)is the old value function. Normally, the major short-\ncoming of","chunk_id":"9bb90746134619cad9a3e649b8b35f24","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"CHAIN-OF-THOUGHT (COT) PROMPTING","type":"TECHNIQUE\/METHOD","description":"Chain-of-thought (CoT) prompting is a technique that caters to scenarios where the direct mapping from input to output is intricate, such as mathematical queries or challenging questions. It involves creating intermediate thoughts that act as stepping stones between the input and the output.","source_id":"9bb90746134619cad9a3e649b8b35f24"},{"name":"TREE-OF-THOUGHT (TOT) PROMPTING","type":"TECHNIQUE\/METHOD","description":"Tree-of-thought (ToT) prompting extends CoT prompting by exploring multiple reasoning paths over thoughts. It frames problems as a search over a tree, where each node represents a partial solution state. Search algorithms like depth-first or breadth-first search are used to explore the tree systematically.","source_id":"9bb90746134619cad9a3e649b8b35f24"},{"name":"REACT","type":"TECHNIQUE\/METHOD","description":"ReAct extends language models to tasks where the mapping from input to output is enhanced by or requires interactions with an external environment, such as a game or API. It constructs an action space that adds permissible actions to the reasoning traces from CoT, using observations from the environment to improve reasoning and acting.","source_id":"9bb90746134619cad9a3e649b8b35f24"},{"name":"MONTE CARLO TREE SEARCH (MCTS)","type":"ALGORITHM","description":"Monte Carlo Tree Search (MCTS) is a heuristic search algorithm used in many decision-making environments. It builds a decision tree where every node is a state and every edge is an action. MCTS runs for multiple episodes, expanding the tree by exploring multiple children states and selecting the best ones based on the UCT value.","source_id":"9bb90746134619cad9a3e649b8b35f24"},{"name":"LANGUAGE MODEL (LM)","type":"MODEL","description":"A language model (LM) is a type of model used to generate outputs based on given inputs. It is used in various prompting techniques like CoT, ToT, and ReAct to improve reasoning and decision-making tasks.","source_id":"9bb90746134619cad9a3e649b8b35f24"},{"name":"UPPER CONFIDENCE BOUNDS APPLIED TO TREES (UCT)","type":"METRIC","description":"Upper Confidence bounds applied to Trees (UCT) is a metric used in MCTS to select the best child state for expansion. It is calculated based on the value function, the number of visits to a node, and an exploration weight.","source_id":"9bb90746134619cad9a3e649b8b35f24"},{"name":"RAP","type":"TECHNIQUE\/METHOD","description":"RAP is a reasoning-based method that relies on the internal representations of the language model. It is used in planning strategies but has limitations in flexibility, sensibility, and adaptability.","source_id":"9bb90746134619cad9a3e649b8b35f24"},{"name":"REFLEXION","type":"TECHNIQUE\/METHOD","description":"Reflexion is a method similar to ReAct, focusing on decision-making tasks where reverting between iterations is feasible. It aims to improve reasoning and acting by leveraging environmental feedback.","source_id":"9bb90746134619cad9a3e649b8b35f24"},{"name":"PROMPT","type":"TECHNIQUE\/METHOD","description":"A prompt is a specific instruction or few-shot input-output example provided along with the input to improve reasoning in language models.","source_id":"9bb90746134619cad9a3e649b8b35f24"},{"name":"INPUT X","type":"CONCEPT","description":"Input x is the initial data or query provided to the language model for processing.","source_id":"9bb90746134619cad9a3e649b8b35f24"},{"name":"OUTPUT Y","type":"CONCEPT","description":"Output y is the final result generated by the language model after processing the input and any intermediate steps.","source_id":"9bb90746134619cad9a3e649b8b35f24"},{"name":"THOUGHT Z","type":"CONCEPT","description":"Thought z is an intermediate language sequence created during the Chain-of-thought (CoT) prompting process to bridge the gap between input x and output y.","source_id":"9bb90746134619cad9a3e649b8b35f24"},{"name":"DEPTH-FIRST SEARCH (DFS)","type":"ALGORITHM","description":"Depth-first search (DFS) is a search algorithm used in Tree-of-thought (ToT) prompting to systematically explore the tree of reasoning paths.","source_id":"9bb90746134619cad9a3e649b8b35f24"},{"name":"BREADTH-FIRST SEARCH (BFS)","type":"ALGORITHM","description":"Breadth-first search (BFS) is a search algorithm used in Tree-of-thought (ToT) prompting to systematically explore the tree of reasoning paths.","source_id":"9bb90746134619cad9a3e649b8b35f24"},{"name":"OBSERVATION O","type":"CONCEPT","description":"Observation o is the feedback or data received from the external environment during the ReAct process, used to improve reasoning and acting.","source_id":"9bb90746134619cad9a3e649b8b35f24"},{"name":"ACTION A","type":"CONCEPT","description":"Action a is a permissible action added to the reasoning traces in the ReAct process, generated based on observations from the environment.","source_id":"9bb90746134619cad9a3e649b8b35f24"},{"name":"LANGUAGE AGENT TREE SEARCH (LATS)","type":"TECHNIQUE\/METHOD","description":"Language Agent Tree Search (LATS) is a method that unifies reasoning, acting, and planning in language models, addressing the shortcomings of previous techniques like CoT, ToT, and ReAct.","source_id":"9bb90746134619cad9a3e649b8b35f24"},{"name":"RAP (HAO ET AL., 2023)","type":"TECHNIQUE\/METHOD","description":"RAP is a reasoning-based method that relies on the internal representations of the language model and is used in planning strategies. It has limitations in flexibility, sensibility, and adaptability.","source_id":"9bb90746134619cad9a3e649b8b35f24"},{"name":"ATARI","type":"ENVIRONMENT","description":"Atari is a decision-making environment where Monte Carlo Tree Search (MCTS) has been successfully applied.","source_id":"9bb90746134619cad9a3e649b8b35f24"},{"name":"GO","type":"ENVIRONMENT","description":"Go is a decision-making environment where Monte Carlo Tree Search (MCTS) has been successfully applied.","source_id":"9bb90746134619cad9a3e649b8b35f24"},{"name":"KOCSIS AND SZEPESV\u00c1RI (2006)","type":"PERSON","description":"Kocsis and Szepesv\u00e1ri are the researchers who developed the Upper Confidence bounds applied to Trees (UCT) metric used in MCTS.","source_id":"9bb90746134619cad9a3e649b8b35f24"},{"name":"SILVER ET AL. (2016)","type":"PERSON","description":"Silver et al. are the researchers who demonstrated the success of Monte Carlo Tree Search (MCTS) in the game of Go.","source_id":"9bb90746134619cad9a3e649b8b35f24"},{"name":"YE ET AL. (2021)","type":"PERSON","description":"Ye et al. are the researchers who demonstrated the success of Monte Carlo Tree Search (MCTS) in the Atari environment.","source_id":"9bb90746134619cad9a3e649b8b35f24"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"CHAIN-OF-THOUGHT (COT) PROMPTING\">      <data key=\"d0\">TECHNIQUE\/METHOD<\/data>      <data key=\"d1\">Chain-of-thought (CoT) prompting is a technique that caters to scenarios where the direct mapping from input to output is intricate, such as mathematical queries or challenging questions. It involves creating intermediate thoughts that act as stepping stones between the input and the output.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <node id=\"TREE-OF-THOUGHT (TOT) PROMPTING\">      <data key=\"d0\">TECHNIQUE\/METHOD<\/data>      <data key=\"d1\">Tree-of-thought (ToT) prompting extends CoT prompting by exploring multiple reasoning paths over thoughts. It frames problems as a search over a tree, where each node represents a partial solution state. Search algorithms like depth-first or breadth-first search are used to explore the tree systematically.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <node id=\"REACT\">      <data key=\"d0\">TECHNIQUE\/METHOD<\/data>      <data key=\"d1\">ReAct extends language models to tasks where the mapping from input to output is enhanced by or requires interactions with an external environment, such as a game or API. It constructs an action space that adds permissible actions to the reasoning traces from CoT, using observations from the environment to improve reasoning and acting.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <node id=\"MONTE CARLO TREE SEARCH (MCTS)\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">Monte Carlo Tree Search (MCTS) is a heuristic search algorithm used in many decision-making environments. It builds a decision tree where every node is a state and every edge is an action. MCTS runs for multiple episodes, expanding the tree by exploring multiple children states and selecting the best ones based on the UCT value.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <node id=\"LANGUAGE MODEL (LM)\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">A language model (LM) is a type of model used to generate outputs based on given inputs. It is used in various prompting techniques like CoT, ToT, and ReAct to improve reasoning and decision-making tasks.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <node id=\"UPPER CONFIDENCE BOUNDS APPLIED TO TREES (UCT)\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Upper Confidence bounds applied to Trees (UCT) is a metric used in MCTS to select the best child state for expansion. It is calculated based on the value function, the number of visits to a node, and an exploration weight.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <node id=\"RAP\">      <data key=\"d0\">TECHNIQUE\/METHOD<\/data>      <data key=\"d1\">RAP is a reasoning-based method that relies on the internal representations of the language model. It is used in planning strategies but has limitations in flexibility, sensibility, and adaptability.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <node id=\"REFLEXION\">      <data key=\"d0\">TECHNIQUE\/METHOD<\/data>      <data key=\"d1\">Reflexion is a method similar to ReAct, focusing on decision-making tasks where reverting between iterations is feasible. It aims to improve reasoning and acting by leveraging environmental feedback.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <node id=\"PROMPT\">      <data key=\"d0\">TECHNIQUE\/METHOD<\/data>      <data key=\"d1\">A prompt is a specific instruction or few-shot input-output example provided along with the input to improve reasoning in language models.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <node id=\"INPUT X\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Input x is the initial data or query provided to the language model for processing.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <node id=\"OUTPUT Y\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Output y is the final result generated by the language model after processing the input and any intermediate steps.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <node id=\"THOUGHT Z\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Thought z is an intermediate language sequence created during the Chain-of-thought (CoT) prompting process to bridge the gap between input x and output y.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <node id=\"DEPTH-FIRST SEARCH (DFS)\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">Depth-first search (DFS) is a search algorithm used in Tree-of-thought (ToT) prompting to systematically explore the tree of reasoning paths.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <node id=\"BREADTH-FIRST SEARCH (BFS)\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">Breadth-first search (BFS) is a search algorithm used in Tree-of-thought (ToT) prompting to systematically explore the tree of reasoning paths.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <node id=\"OBSERVATION O\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Observation o is the feedback or data received from the external environment during the ReAct process, used to improve reasoning and acting.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <node id=\"ACTION A\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Action a is a permissible action added to the reasoning traces in the ReAct process, generated based on observations from the environment.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <node id=\"LANGUAGE AGENT TREE SEARCH (LATS)\">      <data key=\"d0\">TECHNIQUE\/METHOD<\/data>      <data key=\"d1\">Language Agent Tree Search (LATS) is a method that unifies reasoning, acting, and planning in language models, addressing the shortcomings of previous techniques like CoT, ToT, and ReAct.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <node id=\"RAP (HAO ET AL., 2023)\">      <data key=\"d0\">TECHNIQUE\/METHOD<\/data>      <data key=\"d1\">RAP is a reasoning-based method that relies on the internal representations of the language model and is used in planning strategies. It has limitations in flexibility, sensibility, and adaptability.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <node id=\"ATARI\">      <data key=\"d0\">ENVIRONMENT<\/data>      <data key=\"d1\">Atari is a decision-making environment where Monte Carlo Tree Search (MCTS) has been successfully applied.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <node id=\"GO\">      <data key=\"d0\">ENVIRONMENT<\/data>      <data key=\"d1\">Go is a decision-making environment where Monte Carlo Tree Search (MCTS) has been successfully applied.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <node id=\"KOCSIS AND SZEPESV&#193;RI (2006)\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kocsis and Szepesv&#225;ri are the researchers who developed the Upper Confidence bounds applied to Trees (UCT) metric used in MCTS.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <node id=\"SILVER ET AL. (2016)\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Silver et al. are the researchers who demonstrated the success of Monte Carlo Tree Search (MCTS) in the game of Go.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <node id=\"YE ET AL. (2021)\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ye et al. are the researchers who demonstrated the success of Monte Carlo Tree Search (MCTS) in the Atari environment.<\/data>      <data key=\"d2\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/node>    <edge source=\"CHAIN-OF-THOUGHT (COT) PROMPTING\" target=\"TREE-OF-THOUGHT (TOT) PROMPTING\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Tree-of-thought (ToT) prompting extends Chain-of-thought (CoT) prompting by exploring multiple reasoning paths over thoughts.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT (COT) PROMPTING\" target=\"REACT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">ReAct builds on the principles of Chain-of-thought (CoT) prompting by adding interactions with an external environment to the reasoning process.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT (COT) PROMPTING\" target=\"LANGUAGE MODEL (LM)\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Chain-of-thought (CoT) prompting uses a language model (LM) to generate intermediate thoughts that act as stepping stones between the input and the output.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT (COT) PROMPTING\" target=\"LANGUAGE AGENT TREE SEARCH (LATS)\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Language Agent Tree Search (LATS) addresses the shortcomings of Chain-of-thought (CoT) prompting.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT (COT) PROMPTING\" target=\"RAP (HAO ET AL., 2023)\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">RAP is a reasoning-based method similar to Chain-of-thought (CoT) prompting.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"TREE-OF-THOUGHT (TOT) PROMPTING\" target=\"REACT\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Both Tree-of-thought (ToT) prompting and ReAct extend the basic principles of Chain-of-thought (CoT) prompting to improve reasoning and decision-making.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"TREE-OF-THOUGHT (TOT) PROMPTING\" target=\"MONTE CARLO TREE SEARCH (MCTS)\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Tree-of-thought (ToT) prompting uses search algorithms like those in Monte Carlo Tree Search (MCTS) to explore multiple reasoning paths.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"TREE-OF-THOUGHT (TOT) PROMPTING\" target=\"LANGUAGE MODEL (LM)\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Tree-of-thought (ToT) prompting uses a language model (LM) to generate thoughts and explore multiple reasoning paths.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"TREE-OF-THOUGHT (TOT) PROMPTING\" target=\"DEPTH-FIRST SEARCH (DFS)\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Depth-first search (DFS) is used in Tree-of-thought (ToT) prompting to explore the tree of reasoning paths.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"TREE-OF-THOUGHT (TOT) PROMPTING\" target=\"BREADTH-FIRST SEARCH (BFS)\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Breadth-first search (BFS) is used in Tree-of-thought (ToT) prompting to explore the tree of reasoning paths.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"TREE-OF-THOUGHT (TOT) PROMPTING\" target=\"LANGUAGE AGENT TREE SEARCH (LATS)\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Language Agent Tree Search (LATS) addresses the shortcomings of Tree-of-thought (ToT) prompting.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"TREE-OF-THOUGHT (TOT) PROMPTING\" target=\"RAP (HAO ET AL., 2023)\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">RAP is a reasoning-based method similar to Tree-of-thought (ToT) prompting.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"REACT\" target=\"LANGUAGE MODEL (LM)\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">ReAct uses a language model (LM) to generate actions and reasoning traces, enhanced by interactions with an external environment.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"REACT\" target=\"OBSERVATION O\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Observation o is used in the ReAct process to improve reasoning and acting.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"REACT\" target=\"ACTION A\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Action a is generated in the ReAct process based on observations from the environment.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"REACT\" target=\"LANGUAGE AGENT TREE SEARCH (LATS)\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Language Agent Tree Search (LATS) addresses the shortcomings of ReAct.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"REACT\" target=\"RAP (HAO ET AL., 2023)\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">RAP is a reasoning-based method similar to ReAct.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"MONTE CARLO TREE SEARCH (MCTS)\" target=\"UPPER CONFIDENCE BOUNDS APPLIED TO TREES (UCT)\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Upper Confidence bounds applied to Trees (UCT) is a metric used in Monte Carlo Tree Search (MCTS) to select the best child state for expansion.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"MONTE CARLO TREE SEARCH (MCTS)\" target=\"ATARI\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Monte Carlo Tree Search (MCTS) has been successfully applied in the Atari decision-making environment.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"MONTE CARLO TREE SEARCH (MCTS)\" target=\"GO\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Monte Carlo Tree Search (MCTS) has been successfully applied in the Go decision-making environment.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"MONTE CARLO TREE SEARCH (MCTS)\" target=\"SILVER ET AL. (2016)\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Silver et al. demonstrated the success of Monte Carlo Tree Search (MCTS) in the game of Go.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"MONTE CARLO TREE SEARCH (MCTS)\" target=\"YE ET AL. (2021)\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Ye et al. demonstrated the success of Monte Carlo Tree Search (MCTS) in the Atari environment.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"LANGUAGE MODEL (LM)\" target=\"RAP\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">RAP relies on the internal representations of the language model (LM) for reasoning and planning.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"LANGUAGE MODEL (LM)\" target=\"REFLEXION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Reflexion uses a language model (LM) for decision-making tasks, similar to ReAct.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"UPPER CONFIDENCE BOUNDS APPLIED TO TREES (UCT)\" target=\"KOCSIS AND SZEPESV&#193;RI (2006)\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Kocsis and Szepesv&#225;ri developed the Upper Confidence bounds applied to Trees (UCT) metric used in MCTS.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"PROMPT\" target=\"INPUT X\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">A prompt is provided along with input x to improve reasoning in language models.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"INPUT X\" target=\"OUTPUT Y\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Input x is transformed into output y by the language model.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"INPUT X\" target=\"THOUGHT Z\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Thought z is created as an intermediate step between input x and output y in Chain-of-thought (CoT) prompting.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>    <edge source=\"OUTPUT Y\" target=\"THOUGHT Z\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Thought z is created as an intermediate step between input x and output y in Chain-of-thought (CoT) prompting.<\/data>      <data key=\"d5\">9bb90746134619cad9a3e649b8b35f24<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"c234cb83764b899335af0950677ad024","chunk":" (expected return) from the subtree of s,wis\nthe exploration weight, and pis the parent node of s. When\nthe end of an episode is reached, a backpropagation is car-\nried out: the return ris used for updating every V(s)along\nthe path with the formula V(s) =Vold(s)(N(s)\u22121)+r\nN(s), where\nVold(s)is the old value function. Normally, the major short-\ncoming of MCTS is that it requires an environment model to\nundo previous steps and form a searching tree, which could\nbe a strong assumption. However, this limitation does not\nexist for many LM tasks, as we can conveniently reset toany step by simply copy-pasting historical text input. Such\na special property is the key motivation of our work.\n4. Unifying Reasoning, Acting, and Planning\n4.1. LM Agent\nDepending on the base prompting framework design, LATS\nsupports sequential reasoning or decision-making tasks. At\ntime step t, an agent receives an observation ot\u2208Ofrom\nthe environment and takes an action at\u2208Afollowing some\npolicy \u03c0(at|x, o1\u00b7\u00b7\u00b7t\u22121, a1\u00b7\u00b7\u00b7t\u22121). We initialize the agent\nwithp\u03b8to leverage the useful language representations of\nan LM as a base decision-maker. We follow the ReAct in-\nstantiation, in which the action space \u02c6A=A\u222aZconsists\nof both the space of permissible actions Aand the language\nspace of reasoning traces Z. Actions directly affect the envi-\nronment and result in observation, while thoughts are used\nto formalize decisions by organizing information, planning\nfuture actions, or injecting internal knowledge. The exact\ninstantiation of the action space depends on the particular\nenvironment \u2013 for decision-making tasks actions might con-\nsist of commands on a website, while for reasoning tasks\nthe action space might be limited to a few external tools or\nAPIs. In environments without feedback, such as reasoning\ntasks, we use CoT as the base prompting framework.\nInstead of greedily decoding one trajectory or solution, we\nsample nactions from p\u03b8using the current state. This is\nbased on the intuition that for complex decision-making\ntasks, there is likely to be a range of potential trajectories or\nreasoning paths that are correct (Evans, 2010). Sampling a\ndiverse set of candidates at each step mitigates the stochastic\nnature of LM text generation and enables greater exploration\nin both the decision-making and reasoning space. We wrap\np\u03b8within our proposed search algorithm to deliberately\nconstruct the best trajectory from sampled actions.\n4.2. LATS\nThe main component of LATS is a search algorithm that\ncontrols the problem-solving process with planning. To find\nthe most promising trajectory and systemically balance ex-\nploration with exploitation, we adopt a variant of MCTS that\nframes decision-making as a tree search, in which each node\ns= [x, a1\u00b7\u00b7\u00b7i, o1\u00b7\u00b7\u00b7i]represents a state comprising the origi-\nnal input x, action sequence a1\u00b7i, and observation sequence\no1\u00b7i, where iis a token in the text sequence.\nOur main technical contribution is adapting MCTS to lan-\nguage agents . LATS repurposes p\u03b8as an agent, state evalua-\ntor, and feedback generator, leveraging the useful language\nrepresentations of modern LMs to facilitate planning. While\nstandard MCTS and RAP (Hao et al., 2023) rely on internal\ndynamics models to facilitate simulation, LATS uses envi-\nronment interaction and does not require a world model. As\n4Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nFigure 2. Overview of the six operations in LATS. A node is selected ,expanded ,evaluated , then simulated until a terminal node is reached,\nand then the resulting value is backpropagated . If the trajectory fails, a reflection is generated and used as additional context for future\ntrials. These operations are performed in succession until the budget is reached or the task is successful.\ndepicted in Fig. 2, LATS consists of a series of operations\n\u2013selection, expansion, evaluation, simulation, backpropa-\ngation, and reflection \u2013 performed in succession until the\ntask is successfully completed or a computational limit is\nreached after sampling ktrajectories. The full pseudocode\nof LATS can be found in Sec. A in the Appendix.\nSelection. In the first operation, the algorithm identifies\na segment of the current tree most suitable for subsequent\nexpansion. Starting from the root node, denoted as the initial\nstates0, a child node is selected at each tree level until a leaf\nnode is reached. To balance exploration and exploitation,\nwe use the UCT algorithm as shown in Eq. 1.\nExpansion. After selecting a node, the second operation\nexpands the tree by sampling nactions from p\u03b8, as described\nin the prior section. The environment receives each action\nand returns corresponding feedback as an observation. This\nresults in nnew child nodes added to the tree. This tree is\nstored in an external long-term memory structure.\nEvaluation. The third operation assigns a scalar value to\neach new child node for selection and backpropagation.\nThis value effectively quantifies the agent\u2019s progress in task\ncompletion, serving as a heuristic to steer the search algo-\nrithm towards the most promising regions of the tree. As\nLATS does not involve training, we propose a novel value\nfunction for this setting based on two components: (1) a\nself-generated LM score and (2)","chunk_id":"c234cb83764b899335af0950677ad024","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"MCTS","type":"ALGORITHM\/TECHNIQUE","description":"MCTS (Monte Carlo Tree Search) is a search algorithm that requires an environment model to undo previous steps and form a searching tree","source_id":"c234cb83764b899335af0950677ad024"},{"name":"LM TASKS","type":"TASK","description":"LM tasks refer to tasks involving language models, which can conveniently reset to any step by simply copy-pasting historical text input","source_id":"c234cb83764b899335af0950677ad024"},{"name":"LM AGENT","type":"AGENT","description":"An LM Agent is initialized with a language model to leverage useful language representations for sequential reasoning or decision-making tasks","source_id":"c234cb83764b899335af0950677ad024"},{"name":"LATS","type":"ALGORITHM\/TECHNIQUE","description":"LATS (Language Agent Tree Search) is a search algorithm that unifies reasoning, acting, and planning in language models","source_id":"c234cb83764b899335af0950677ad024"},{"name":"ENVIRONMENT","type":"CONTEXT","description":"The environment provides observations to the agent and receives actions from the agent, resulting in feedback","source_id":"c234cb83764b899335af0950677ad024"},{"name":"COT","type":"FRAMEWORK","description":"CoT (Chain of Thought) is used as the base prompting framework in environments without feedback, such as reasoning tasks","source_id":"c234cb83764b899335af0950677ad024"},{"name":"P\u0398","type":"MODEL","description":"P\u03b8 is a language model used as a base decision-maker, agent, state evaluator, and feedback generator in LATS","source_id":"c234cb83764b899335af0950677ad024"},{"name":"UCT ALGORITHM","type":"ALGORITHM\/TECHNIQUE","description":"The UCT (Upper Confidence bounds applied to Trees) algorithm is used to balance exploration and exploitation in the selection operation of LATS","source_id":"c234cb83764b899335af0950677ad024"},{"name":"SELECTION","type":"OPERATION","description":"Selection is the first operation in LATS where the algorithm identifies a segment of the current tree most suitable for subsequent expansion","source_id":"c234cb83764b899335af0950677ad024"},{"name":"EXPANSION","type":"OPERATION","description":"Expansion is the second operation in LATS where the tree is expanded by sampling actions from P\u03b8 and adding new child nodes to the tree","source_id":"c234cb83764b899335af0950677ad024"},{"name":"EVALUATION","type":"OPERATION","description":"Evaluation is the third operation in LATS where a scalar value is assigned to each new child node to quantify the agent\u2019s progress in task completion","source_id":"c234cb83764b899335af0950677ad024"},{"name":"SIMULATION","type":"OPERATION","description":"Simulation is an operation in LATS where the algorithm simulates the selected node until a terminal node is reached","source_id":"c234cb83764b899335af0950677ad024"},{"name":"BACKPROPAGATION","type":"OPERATION","description":"Backpropagation is an operation in LATS where the resulting value from the simulation is used to update the value of nodes along the path","source_id":"c234cb83764b899335af0950677ad024"},{"name":"REFLECTION","type":"OPERATION","description":"Reflection is an operation in LATS where a reflection is generated if the trajectory fails and used as additional context for future trials","source_id":"c234cb83764b899335af0950677ad024"},{"name":"LONG-TERM MEMORY STRUCTURE","type":"DATA STRUCTURE","description":"An external structure where the expanded tree is stored in LATS","source_id":"c234cb83764b899335af0950677ad024"},{"name":"TASK","type":"CONTEXT","description":"A task in LATS is successfully completed when the series of operations result in a solution or a computational limit is reached","source_id":"c234cb83764b899335af0950677ad024"},{"name":"TRAJECTORY","type":"CONCEPT","description":"A trajectory in LATS refers to a sequence of actions and observations sampled from P\u03b8 to construct the best path for task completion","source_id":"c234cb83764b899335af0950677ad024"},{"name":"FEEDBACK","type":"CONCEPT","description":"Feedback in LATS is the response from the environment to the agent's actions, used to guide the search algorithm","source_id":"c234cb83764b899335af0950677ad024"},{"name":"REASONING TASKS","type":"TASK","description":"Reasoning tasks are a type of task in LATS where the action space might be limited to a few external tools or APIs","source_id":"c234cb83764b899335af0950677ad024"},{"name":"DECISION-MAKING TASKS","type":"TASK","description":"Decision-making tasks are a type of task in LATS where actions might consist of commands on a website","source_id":"c234cb83764b899335af0950677ad024"},{"name":"PLANNING","type":"CONCEPT","description":"Planning in LATS involves organizing information, planning future actions, or injecting internal knowledge to formalize decisions","source_id":"c234cb83764b899335af0950677ad024"},{"name":"SAMPLING","type":"TECHNIQUE","description":"Sampling in LATS involves selecting a diverse set of candidates at each step to mitigate the stochastic nature of LM text generation","source_id":"c234cb83764b899335af0950677ad024"},{"name":"SEARCH ALGORITHM","type":"ALGORITHM\/TECHNIQUE","description":"A search algorithm in LATS controls the problem-solving process with planning to find the most promising trajectory","source_id":"c234cb83764b899335af0950677ad024"},{"name":"PSEUDOCODE","type":"DOCUMENTATION","description":"The full pseudocode of LATS can be found in the Appendix, detailing the operations and process","source_id":"c234cb83764b899335af0950677ad024"},{"name":"FIGURE 2","type":"ILLUSTRATION","description":"Figure 2 provides an overview of the six operations in LATS, depicting the sequence of operations performed","source_id":"c234cb83764b899335af0950677ad024"},{"name":"SEC. A","type":"DOCUMENTATION","description":"Section A in the Appendix contains the full pseudocode of LATS","source_id":"c234cb83764b899335af0950677ad024"},{"name":"EVANS, 2010","type":"REFERENCE","description":"Evans, 2010 is a reference cited in the context of sampling diverse candidates for complex decision-making tasks","source_id":"c234cb83764b899335af0950677ad024"},{"name":"HAO ET AL., 2023","type":"REFERENCE","description":"Hao et al., 2023 is a reference cited in the context of standard MCTS and RAP relying on internal dynamics models","source_id":"c234cb83764b899335af0950677ad024"},{"name":"RAP","type":"ALGORITHM\/TECHNIQUE","description":"RAP (Reinforcement Learning with Augmented Planning) is an algorithm that relies on internal dynamics models to facilitate simulation","source_id":"c234cb83764b899335af0950677ad024"},{"name":"MODERN LMS","type":"TECHNOLOGY","description":"Modern LMs (Language Models) provide useful language representations that facilitate planning in LATS","source_id":"c234cb83764b899335af0950677ad024"},{"name":"EXPLORATION WEIGHT","type":"CONCEPT","description":"Exploration weight is a parameter used in the MCTS algorithm to balance exploration and exploitation","source_id":"c234cb83764b899335af0950677ad024"},{"name":"PARENT NODE","type":"CONCEPT","description":"Parent node is a node in the tree structure from which child nodes are derived in MCTS","source_id":"c234cb83764b899335af0950677ad024"},{"name":"EPISODE","type":"CONCEPT","description":"An episode refers to a complete sequence of actions and observations in a task, ending in a terminal state","source_id":"c234cb83764b899335af0950677ad024"},{"name":"RETURN","type":"CONCEPT","description":"Return is the reward or feedback used for updating the value function in MCTS","source_id":"c234cb83764b899335af0950677ad024"},{"name":"VALUE FUNCTION","type":"CONCEPT","description":"Value function is a function used to estimate the expected return of a state in MCTS","source_id":"c234cb83764b899335af0950677ad024"},{"name":"VOLD(S)","type":"CONCEPT","description":"Vold(s) is the old value function before it is updated with the new return in MCTS","source_id":"c234cb83764b899335af0950677ad024"},{"name":"N(S)","type":"CONCEPT","description":"N(s) is the number of times a state has been visited in MCTS","source_id":"c234cb83764b899335af0950677ad024"},{"name":"RESET","type":"CONCEPT","description":"Reset refers to the ability to revert to a previous state or step in LM tasks","source_id":"c234cb83764b899335af0950677ad024"},{"name":"REACT","type":"FRAMEWORK","description":"ReAct is a framework used in LATS where the action space consists of permissible actions and reasoning traces","source_id":"c234cb83764b899335af0950677ad024"},{"name":"ACTION SPACE","type":"CONCEPT","description":"Action space refers to the set of all possible actions an agent can take in a given environment","source_id":"c234cb83764b899335af0950677ad024"},{"name":"PERMISSIBLE ACTIONS","type":"CONCEPT","description":"Permissible actions are the actions that an agent is allowed to take in a given environment","source_id":"c234cb83764b899335af0950677ad024"},{"name":"REASONING TRACES","type":"CONCEPT","description":"Reasoning traces are the language-based thoughts used to formalize decisions in LATS","source_id":"c234cb83764b899335af0950677ad024"},{"name":"OBSERVATION","type":"CONCEPT","description":"Observation is the feedback received from the environment after an action is taken by the agent","source_id":"c234cb83764b899335af0950677ad024"},{"name":"POLICY","type":"CONCEPT","description":"Policy is a strategy or rule followed by an agent to decide actions based on observations and past actions","source_id":"c234cb83764b899335af0950677ad024"},{"name":"COMMANDS","type":"CONCEPT","description":"Commands are specific actions taken by an agent in decision-making tasks, such as interacting with a website","source_id":"c234cb83764b899335af0950677ad024"},{"name":"EXTERNAL TOOLS","type":"CONCEPT","description":"External tools are tools or APIs used by an agent in reasoning tasks to perform specific actions","source_id":"c234cb83764b899335af0950677ad024"},{"name":"STOCHASTIC NATURE","type":"CONCEPT","description":"Stochastic nature refers to the randomness inherent in LM text generation","source_id":"c234cb83764b899335af0950677ad024"},{"name":"COMPUTATIONAL LIMIT","type":"CONCEPT","description":"Computational limit is the maximum amount of computational resources allocated for completing a task in LATS","source_id":"c234cb83764b899335af0950677ad024"},{"name":"SCALAR VALUE","type":"CONCEPT","description":"Scalar value is a numerical value assigned to a node in LATS to quantify the agent\u2019s progress in task completion","source_id":"c234cb83764b899335af0950677ad024"},{"name":"HEURISTIC","type":"CONCEPT","description":"Heuristic is a method used to guide the search algorithm towards the most promising regions of the tree in LATS","source_id":"c234cb83764b899335af0950677ad024"},{"name":"SELF-GENERATED LM SCORE","type":"CONCEPT","description":"Self-generated LM score is a component of the value function in LATS, generated by the language model itself","source_id":"c234cb83764b899335af0950677ad024"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"MCTS\">      <data key=\"d0\">ALGORITHM\/TECHNIQUE<\/data>      <data key=\"d1\">MCTS (Monte Carlo Tree Search) is a search algorithm that requires an environment model to undo previous steps and form a searching tree<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"LM TASKS\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">LM tasks refer to tasks involving language models, which can conveniently reset to any step by simply copy-pasting historical text input<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"LM AGENT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">An LM Agent is initialized with a language model to leverage useful language representations for sequential reasoning or decision-making tasks<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"LATS\">      <data key=\"d0\">ALGORITHM\/TECHNIQUE<\/data>      <data key=\"d1\">LATS (Language Agent Tree Search) is a search algorithm that unifies reasoning, acting, and planning in language models<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"ENVIRONMENT\">      <data key=\"d0\">CONTEXT<\/data>      <data key=\"d1\">The environment provides observations to the agent and receives actions from the agent, resulting in feedback<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"COT\">      <data key=\"d0\">FRAMEWORK<\/data>      <data key=\"d1\">CoT (Chain of Thought) is used as the base prompting framework in environments without feedback, such as reasoning tasks<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"P&#920;\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">P&#952; is a language model used as a base decision-maker, agent, state evaluator, and feedback generator in LATS<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"UCT ALGORITHM\">      <data key=\"d0\">ALGORITHM\/TECHNIQUE<\/data>      <data key=\"d1\">The UCT (Upper Confidence bounds applied to Trees) algorithm is used to balance exploration and exploitation in the selection operation of LATS<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"SELECTION\">      <data key=\"d0\">OPERATION<\/data>      <data key=\"d1\">Selection is the first operation in LATS where the algorithm identifies a segment of the current tree most suitable for subsequent expansion<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"EXPANSION\">      <data key=\"d0\">OPERATION<\/data>      <data key=\"d1\">Expansion is the second operation in LATS where the tree is expanded by sampling actions from P&#952; and adding new child nodes to the tree<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"EVALUATION\">      <data key=\"d0\">OPERATION<\/data>      <data key=\"d1\">Evaluation is the third operation in LATS where a scalar value is assigned to each new child node to quantify the agent&#8217;s progress in task completion<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"SIMULATION\">      <data key=\"d0\">OPERATION<\/data>      <data key=\"d1\">Simulation is an operation in LATS where the algorithm simulates the selected node until a terminal node is reached<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"BACKPROPAGATION\">      <data key=\"d0\">OPERATION<\/data>      <data key=\"d1\">Backpropagation is an operation in LATS where the resulting value from the simulation is used to update the value of nodes along the path<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"REFLECTION\">      <data key=\"d0\">OPERATION<\/data>      <data key=\"d1\">Reflection is an operation in LATS where a reflection is generated if the trajectory fails and used as additional context for future trials<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"LONG-TERM MEMORY STRUCTURE\">      <data key=\"d0\">DATA STRUCTURE<\/data>      <data key=\"d1\">An external structure where the expanded tree is stored in LATS<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"TASK\">      <data key=\"d0\">CONTEXT<\/data>      <data key=\"d1\">A task in LATS is successfully completed when the series of operations result in a solution or a computational limit is reached<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"TRAJECTORY\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A trajectory in LATS refers to a sequence of actions and observations sampled from P&#952; to construct the best path for task completion<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"FEEDBACK\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Feedback in LATS is the response from the environment to the agent's actions, used to guide the search algorithm<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"REASONING TASKS\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">Reasoning tasks are a type of task in LATS where the action space might be limited to a few external tools or APIs<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"DECISION-MAKING TASKS\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">Decision-making tasks are a type of task in LATS where actions might consist of commands on a website<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"PLANNING\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Planning in LATS involves organizing information, planning future actions, or injecting internal knowledge to formalize decisions<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"SAMPLING\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Sampling in LATS involves selecting a diverse set of candidates at each step to mitigate the stochastic nature of LM text generation<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"SEARCH ALGORITHM\">      <data key=\"d0\">ALGORITHM\/TECHNIQUE<\/data>      <data key=\"d1\">A search algorithm in LATS controls the problem-solving process with planning to find the most promising trajectory<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"PSEUDOCODE\">      <data key=\"d0\">DOCUMENTATION<\/data>      <data key=\"d1\">The full pseudocode of LATS can be found in the Appendix, detailing the operations and process<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"FIGURE 2\">      <data key=\"d0\">ILLUSTRATION<\/data>      <data key=\"d1\">Figure 2 provides an overview of the six operations in LATS, depicting the sequence of operations performed<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"SEC. A\">      <data key=\"d0\">DOCUMENTATION<\/data>      <data key=\"d1\">Section A in the Appendix contains the full pseudocode of LATS<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"EVANS, 2010\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Evans, 2010 is a reference cited in the context of sampling diverse candidates for complex decision-making tasks<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"HAO ET AL., 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Hao et al., 2023 is a reference cited in the context of standard MCTS and RAP relying on internal dynamics models<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"RAP\">      <data key=\"d0\">ALGORITHM\/TECHNIQUE<\/data>      <data key=\"d1\">RAP (Reinforcement Learning with Augmented Planning) is an algorithm that relies on internal dynamics models to facilitate simulation<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"MODERN LMS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Modern LMs (Language Models) provide useful language representations that facilitate planning in LATS<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"EXPLORATION WEIGHT\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Exploration weight is a parameter used in the MCTS algorithm to balance exploration and exploitation<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"PARENT NODE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Parent node is a node in the tree structure from which child nodes are derived in MCTS<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"EPISODE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">An episode refers to a complete sequence of actions and observations in a task, ending in a terminal state<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"RETURN\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Return is the reward or feedback used for updating the value function in MCTS<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"VALUE FUNCTION\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Value function is a function used to estimate the expected return of a state in MCTS<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"VOLD(S)\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Vold(s) is the old value function before it is updated with the new return in MCTS<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"N(S)\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">N(s) is the number of times a state has been visited in MCTS<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"RESET\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Reset refers to the ability to revert to a previous state or step in LM tasks<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"REACT\">      <data key=\"d0\">FRAMEWORK<\/data>      <data key=\"d1\">ReAct is a framework used in LATS where the action space consists of permissible actions and reasoning traces<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"ACTION SPACE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Action space refers to the set of all possible actions an agent can take in a given environment<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"PERMISSIBLE ACTIONS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Permissible actions are the actions that an agent is allowed to take in a given environment<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"REASONING TRACES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Reasoning traces are the language-based thoughts used to formalize decisions in LATS<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"OBSERVATION\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Observation is the feedback received from the environment after an action is taken by the agent<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"POLICY\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Policy is a strategy or rule followed by an agent to decide actions based on observations and past actions<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"COMMANDS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Commands are specific actions taken by an agent in decision-making tasks, such as interacting with a website<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"EXTERNAL TOOLS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">External tools are tools or APIs used by an agent in reasoning tasks to perform specific actions<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"STOCHASTIC NATURE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Stochastic nature refers to the randomness inherent in LM text generation<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"COMPUTATIONAL LIMIT\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Computational limit is the maximum amount of computational resources allocated for completing a task in LATS<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"SCALAR VALUE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Scalar value is a numerical value assigned to a node in LATS to quantify the agent&#8217;s progress in task completion<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"HEURISTIC\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Heuristic is a method used to guide the search algorithm towards the most promising regions of the tree in LATS<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <node id=\"SELF-GENERATED LM SCORE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Self-generated LM score is a component of the value function in LATS, generated by the language model itself<\/data>      <data key=\"d2\">c234cb83764b899335af0950677ad024<\/data>    <\/node>    <edge source=\"MCTS\" target=\"LATS\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">LATS adopts a variant of MCTS to frame decision-making as a tree search<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"MCTS\" target=\"LM TASKS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">LM tasks do not have the limitation of requiring an environment model, unlike MCTS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"MCTS\" target=\"EXPLORATION WEIGHT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Exploration weight is a parameter used in MCTS to balance exploration and exploitation<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"MCTS\" target=\"PARENT NODE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Parent node is a node in the tree structure from which child nodes are derived in MCTS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"MCTS\" target=\"EPISODE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">An episode refers to a complete sequence of actions and observations in MCTS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"MCTS\" target=\"RETURN\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Return is the reward or feedback used for updating the value function in MCTS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"MCTS\" target=\"VALUE FUNCTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Value function is used to estimate the expected return of a state in MCTS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LM TASKS\" target=\"RESET\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Reset refers to the ability to revert to a previous state or step in LM tasks<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LM AGENT\" target=\"LATS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LM Agent is initialized with a language model and used within LATS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LM AGENT\" target=\"ENVIRONMENT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The environment provides observations to the LM Agent and receives actions from it<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LM AGENT\" target=\"COT\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">CoT is used as the base prompting framework for LM Agent in environments without feedback<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LM AGENT\" target=\"P&#920;\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">P&#952; is the language model used to initialize the LM Agent<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LM AGENT\" target=\"POLICY\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Policy is a strategy followed by the LM Agent to decide actions based on observations and past actions<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"P&#920;\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">P&#952; is repurposed as an agent, state evaluator, and feedback generator in LATS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"SELECTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Selection is the first operation in LATS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"EXPANSION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Expansion is the second operation in LATS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"EVALUATION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Evaluation is the third operation in LATS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"SIMULATION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Simulation is an operation in LATS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"BACKPROPAGATION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Backpropagation is an operation in LATS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"REFLECTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Reflection is an operation in LATS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"TASK\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">A task in LATS is successfully completed when the series of operations result in a solution or a computational limit is reached<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"TRAJECTORY\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">A trajectory in LATS refers to a sequence of actions and observations sampled from P&#952;<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"FEEDBACK\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Feedback in LATS is the response from the environment to the agent's actions<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"REASONING TASKS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Reasoning tasks are a type of task in LATS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"DECISION-MAKING TASKS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Decision-making tasks are a type of task in LATS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"PLANNING\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Planning in LATS involves organizing information, planning future actions, or injecting internal knowledge<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"SAMPLING\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Sampling in LATS involves selecting a diverse set of candidates at each step<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"SEARCH ALGORITHM\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">A search algorithm in LATS controls the problem-solving process with planning<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"PSEUDOCODE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The full pseudocode of LATS can be found in the Appendix<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"FIGURE 2\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Figure 2 provides an overview of the six operations in LATS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"SEC. A\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Section A in the Appendix contains the full pseudocode of LATS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"EVANS, 2010\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Evans, 2010 is a reference cited in the context of sampling diverse candidates for complex decision-making tasks in LATS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"HAO ET AL., 2023\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Hao et al., 2023 is a reference cited in the context of standard MCTS and RAP in LATS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"RAP\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">RAP is an algorithm that relies on internal dynamics models, unlike LATS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"MODERN LMS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Modern LMs provide useful language representations that facilitate planning in LATS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"REACT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">ReAct is a framework used in LATS where the action space consists of permissible actions and reasoning traces<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"LATS\" target=\"ACTION SPACE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Action space refers to the set of all possible actions an agent can take in LATS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"ENVIRONMENT\" target=\"OBSERVATION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Observation is the feedback received from the environment after an action is taken by the agent<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"UCT ALGORITHM\" target=\"SELECTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The UCT algorithm is used in the selection operation of LATS to balance exploration and exploitation<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"EXPANSION\" target=\"LONG-TERM MEMORY STRUCTURE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The expanded tree in LATS is stored in a long-term memory structure<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"EVALUATION\" target=\"SCALAR VALUE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Scalar value is assigned to each new child node during the evaluation operation in LATS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"EVALUATION\" target=\"HEURISTIC\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Heuristic is used to guide the search algorithm during the evaluation operation in LATS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"EVALUATION\" target=\"SELF-GENERATED LM SCORE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Self-generated LM score is a component of the value function used in the evaluation operation in LATS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"TASK\" target=\"COMPUTATIONAL LIMIT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">A task in LATS is completed when a solution is found or a computational limit is reached<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"REASONING TASKS\" target=\"EXTERNAL TOOLS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">External tools are tools or APIs used by an agent in reasoning tasks<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"DECISION-MAKING TASKS\" target=\"COMMANDS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Commands are specific actions taken by an agent in decision-making tasks<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"SAMPLING\" target=\"STOCHASTIC NATURE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Sampling in LATS involves selecting a diverse set of candidates to mitigate the stochastic nature of LM text generation<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"VALUE FUNCTION\" target=\"VOLD(S)\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Vold(s) is the old value function before it is updated with the new return in MCTS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"VALUE FUNCTION\" target=\"N(S)\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">N(s) is the number of times a state has been visited, used in the value function update in MCTS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"ACTION SPACE\" target=\"PERMISSIBLE ACTIONS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Permissible actions are the actions that an agent is allowed to take in the action space of LATS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>    <edge source=\"ACTION SPACE\" target=\"REASONING TRACES\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Reasoning traces are the language-based thoughts used in the action space of LATS<\/data>      <data key=\"d5\">c234cb83764b899335af0950677ad024<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"02ef0185bbeaaef92c3a8ee18b7a38cf","chunk":" long-term memory structure.\nEvaluation. The third operation assigns a scalar value to\neach new child node for selection and backpropagation.\nThis value effectively quantifies the agent\u2019s progress in task\ncompletion, serving as a heuristic to steer the search algo-\nrithm towards the most promising regions of the tree. As\nLATS does not involve training, we propose a novel value\nfunction for this setting based on two components: (1) a\nself-generated LM score and (2) a self-consistency score.\nInspired by ToT, we repurpose p\u03b8into a value function by\nprompting it to reason about a given state. To obtain a scalar\nvalue, we instruct p\u03b8to end its reasoning trace with a score\nindicating the correctness of the trajectory. Our key distinc-\ntion from ToT is that we obtain this value after obtaining\nthe environmental feedback, improving value assignment.\nThis also enables scaling to more challenging environments,as it is difficult for LMs to improve their responses with-\nout external feedback (Huang et al., 2024). Additionally,\nto further improve value assignment, we introduce an ad-\nditional heuristic based on self-consistency (Wang et al.,\n2022), in which actions sampled multiple times at the same\nstate tend to be more accurate. This results in the overall\nvalue function:\nV(s) =\u03bb\u2217LM(s) + (1\u2212\u03bb)\u2217SC(s), (2)\nwhere \u03bbis a hyperparameter. Notably, our method offers\nenhanced flexibility over programmed heuristics (Campbell\net al., 2002) and greater efficiency than learned heuristics\n(Silver et al., 2017).\nSimulation. The fourth operation expands the currently se-\nlected node until a terminal state is reached. At each depth\nlevel, we sample and evaluate nodes with the same opera-\ntions but prioritize nodes of the highest value. Reaching a\nterminal state provides objective feedback on the correct-\nness of a trajectory. If the task is completed successfully,\nthen LATS terminates the search. If the solution is partially\nsuccessful or unsuccessful, then we perform two additional\noperations as described below. The success of a trajectory is\ndetermined by the design of the specific environment, such\nas finalizing a purchase in web navigation environments.\nBackpropagation. This operation updates the values of the\ntree based on the outcome of a trajectory. For each node\ns0, s1, . . . , s lin the trajectory from root (initial state s0)\nof the searching tree to leaf (terminal state sl), its value is\nupdated to reflect the outcome of the simulation by N(si) =\nN(si\u22121)+1 andV(si) =V(si\u22121)N(si\u22121)+r\nN(si), where ris the\nreward. These updated values are used in the UCT formula\n(Eq. 1) to guide the selection of the next node.\nReflection. In addition to the environmental feedback, we\nleverage self-reflection to further refine the decision-making\n5Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nPrompt Method HotpotQA (EM) \u2191\nBase LM 0.32\nCoT (Wei et al., 2022) 0.34\nCoT - SC (Wang et al., 2022) 0.38\nToT (Yao et al., 2023a) 0.55\nRAP (Hao et al., 2023) 0.60\nRAP ( n= 10 ) 0.60\nLATS (CoT) 0.62\nTable 2. GPT-3.5 reasoning -based prompting results on HotpotQA.\nLATS achieves the highest exact match (EM) for reasoning. We\nsample n= 5nodes during expansion and k= 50 trajectories.\nprocess (Shinn et al., 2023; Madaan et al., 2023). Upon\nencountering an unsuccessful terminal node, p\u03b8is prompted\nwith the trajectory and final reward to provide a verbal self-\nreflection that summarizes the errors in the reasoning or\nacting process and proposes superior alternatives. We store\nboth failed trajectories and corresponding reflections in the\nmemory. In subsequent iterations, these are integrated as\nadditional context to the agent and value function, refining\nboth through in-context learning. This imparts a semantic\ngradient signal more useful than a scalar value, enabling\nthe agent to learn from trial and error without the cost of\nexpensive optimization such as reinforcement learning.\nDiscussion. Conceptually, LATS has several notable advan-\ntages as a general framework for reasoning and decision-\nmaking with LM agents. (1) Generality : LATS supports\nboth reasoning and decision-making tasks by defining a\nshared space of thoughts and actions. (2) Deliberation :\nLeveraging MCTS and LM value function in LATS en-\nsures a principled search that selects options with high value\nwhile exploring promising alternatives. (3) Adaptability :\nIncorporating external feedback through observations and\nself-reflection in LATS enables greater adaptation during\nproblem-solving. (4) Flexibility : LATS can accommodate\ndifferent scenarios, environments, and resource stipulations\nby modifying state design and tree dimensions. (5) Modu-\nlarity : The base LM agent, reflection generator, and value\nfunction can be independently altered and adapted to indi-\nvidual LM properties.\n5. Experiments\nTo demonstrate the general applicability of LATS, we eval-\nuate our method on a variety of domains that require rea-\nsoning and acting: programming (Chen et al., 2021; Austin\net al., 202","chunk_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"LONG-TERM MEMORY STRUCTURE","type":"CONCEPT","description":"A structure used to store information over an extended period","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf"},{"name":"EVALUATION","type":"PROCESS","description":"The process of assigning a scalar value to each new child node for selection and backpropagation","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf"},{"name":"AGENT","type":"ACTOR","description":"An entity that performs tasks and makes decisions in a given environment","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf"},{"name":"TASK COMPLETION","type":"PROCESS","description":"The process of finishing a given task successfully","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf"},{"name":"SEARCH ALGORITHM","type":"ALGORITHM","description":"An algorithm used to explore and find the most promising regions of a tree","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf"},{"name":"LATS","type":"METHOD","description":"Language Agent Tree Search, a method that unifies reasoning, acting, and planning in language models","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf"},{"name":"VALUE FUNCTION","type":"FUNCTION","description":"A function that assigns a value to a state based on certain criteria","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf"},{"name":"SELF-GENERATED LM SCORE","type":"METRIC","description":"A score generated by the language model to evaluate a state","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf"},{"name":"SELF-CONSISTENCY SCORE","type":"METRIC","description":"A score based on the consistency of actions sampled multiple times at the same state","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf"},{"name":"P\u0398","type":"MODEL","description":"A language model used to reason about a given state and provide a score","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf"},{"name":"ENVIRONMENTAL FEEDBACK","type":"FEEDBACK","description":"Feedback obtained from the environment to improve value assignment","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf"},{"name":"HEURISTIC","type":"CONCEPT","description":"A method used to guide the search algorithm towards the most promising regions of the tree","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"CONCEPT"},{"name":"SIMULATION","type":"PROCESS","description":"The process of expanding the currently selected node until a terminal state is reached","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf"},{"name":"TERMINAL STATE","type":"STATE","description":"A state where the task is either completed successfully or not","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"STATE"},{"name":"TRAJECTORY","type":"PATH","description":"The sequence of states from the root to the terminal state in the search tree","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"PATH"},{"name":"BACKPROPAGATION","type":"PROCESS","description":"The process of updating the values of the tree based on the outcome of a trajectory\nThe process of updating the values of nodes based on the outcome of a trajectory","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"PROCESS"},{"name":"REWARD","type":"METRIC","description":"A value that reflects the outcome of a simulation","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"METRIC"},{"name":"UCT FORMULA","type":"FORMULA","description":"A formula used to guide the selection of the next node","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"FORMULA"},{"name":"REFLECTION","type":"PROCESS","description":"The process of using self-reflection to refine decision-making","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"PROCESS"},{"name":"SELF-REFLECTION","type":"PROCESS","description":"A method where the agent reflects on its actions and proposes superior alternatives","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"PROCESS"},{"name":"MEMORY","type":"STORAGE","description":"A storage for failed trajectories and corresponding reflections","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"STORAGE"},{"name":"IN-CONTEXT LEARNING","type":"LEARNING METHOD","description":"A method where the agent learns from trial and error using context","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"LEARNING METHOD"},{"name":"MCTS","type":"ALGORITHM","description":"Monte Carlo Tree Search, an algorithm used in LATS for principled search","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"ALGORITHM"},{"name":"HOTPOTQA","type":"DATASET","description":"A dataset used to evaluate reasoning-based prompting results","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"DATASET"},{"name":"GPT-3.5","type":"MODEL","description":"A version of OpenAI's language model used in the experiments","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"MODEL"},{"name":"COT","type":"METHOD","description":"Chain of Thought, a reasoning method","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"METHOD"},{"name":"RAP","type":"METHOD","description":"Reasoning and Planning, a method used in the experiments","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"METHOD"},{"name":"EXACT MATCH (EM)","type":"METRIC","description":"A metric used to evaluate the accuracy of reasoning","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"METRIC"},{"name":"PROGRAMMING","type":"DOMAIN","description":"A domain that requires reasoning and acting","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"DOMAIN"},{"name":"CHEN ET AL., 2021","type":"REFERENCE","description":"A reference to a study or paper related to programming","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"REFERENCE"},{"name":"AUSTIN ET AL.","type":"REFERENCE","description":"A reference to a study or paper related to programming","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"REFERENCE"},{"name":"WEI ET AL., 2022","type":"REFERENCE","description":"A reference to a study or paper related to Chain of Thought","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"REFERENCE"},{"name":"WANG ET AL., 2022","type":"REFERENCE","description":"A reference to a study or paper related to self-consistency","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"REFERENCE"},{"name":"YAO ET AL., 2023A","type":"REFERENCE","description":"A reference to a study or paper related to Tree of Thought","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"REFERENCE"},{"name":"HAO ET AL., 2023","type":"REFERENCE","description":"A reference to a study or paper related to Reasoning and Planning","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"REFERENCE"},{"name":"SHINN ET AL., 2023","type":"REFERENCE","description":"A reference to a study or paper related to self-reflection","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"REFERENCE"},{"name":"MADAAN ET AL., 2023","type":"REFERENCE","description":"A reference to a study or paper related to self-reflection","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"REFERENCE"},{"name":"CAMPBELL ET AL., 2002","type":"REFERENCE","description":"A reference to a study or paper related to programmed heuristics","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"REFERENCE"},{"name":"SILVER ET AL., 2017","type":"REFERENCE","description":"A reference to a study or paper related to learned heuristics","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf","entity_type":"REFERENCE"},{"name":"TOT","type":"","description":"","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf"},{"name":"SCALAR VALUE","type":"METRIC","description":"A numeric value assigned to each new child node for selection and backpropagation","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf"},{"name":"SELECTION","type":"PROCESS","description":"The process of choosing nodes based on their assigned scalar values","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf"},{"name":"SELF-CONSISTENCY","type":"CONCEPT","description":"A heuristic where actions sampled multiple times at the same state tend to be more accurate","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf"},{"name":"HYPERPARAMETER","type":"METRIC","description":"A parameter whose value is set before the learning process begins","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf"},{"name":"PROGRAMMED HEURISTICS","type":"CONCEPT","description":"Heuristics that are manually designed and implemented","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf"},{"name":"LEARNED HEURISTICS","type":"CONCEPT","description":"Heuristics that are learned through machine learning techniques","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf"},{"name":"NODE","type":"CONCEPT","description":"A point in the search tree representing a state","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf"},{"name":"DEPTH LEVEL","type":"METRIC","description":"The level of a node in the search tree, indicating its distance from the root","source_id":"02ef0185bbeaaef92c3a8ee18b7a38cf"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"LONG-TERM MEMORY STRUCTURE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A structure used to store information over an extended period<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/node>    <node id=\"EVALUATION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The process of assigning a scalar value to each new child node for selection and backpropagation<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/node>    <node id=\"AGENT\">      <data key=\"d0\">ACTOR<\/data>      <data key=\"d1\">An entity that performs tasks and makes decisions in a given environment<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/node>    <node id=\"TASK COMPLETION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The process of finishing a given task successfully<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/node>    <node id=\"SEARCH ALGORITHM\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">An algorithm used to explore and find the most promising regions of a tree<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/node>    <node id=\"LATS\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Language Agent Tree Search, a method that unifies reasoning, acting, and planning in language models<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/node>    <node id=\"VALUE FUNCTION\">      <data key=\"d0\">FUNCTION<\/data>      <data key=\"d1\">A function that assigns a value to a state based on certain criteria<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/node>    <node id=\"SELF-GENERATED LM SCORE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A score generated by the language model to evaluate a state<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/node>    <node id=\"SELF-CONSISTENCY SCORE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A score based on the consistency of actions sampled multiple times at the same state<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/node>    <node id=\"P&#920;\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">A language model used to reason about a given state and provide a score<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/node>    <node id=\"ENVIRONMENTAL FEEDBACK\">      <data key=\"d0\">FEEDBACK<\/data>      <data key=\"d1\">Feedback obtained from the environment to improve value assignment<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/node>    <node id=\"HEURISTIC\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A method used to guide the search algorithm towards the most promising regions of the tree<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"SIMULATION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The process of expanding the currently selected node until a terminal state is reached<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/node>    <node id=\"TERMINAL STATE\">      <data key=\"d0\">STATE<\/data>      <data key=\"d1\">A state where the task is either completed successfully or not<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">STATE<\/data>    <\/node>    <node id=\"TRAJECTORY\">      <data key=\"d0\">PATH<\/data>      <data key=\"d1\">The sequence of states from the root to the terminal state in the search tree<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">PATH<\/data>    <\/node>    <node id=\"BACKPROPAGATION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The process of updating the values of the tree based on the outcome of a trajectoryThe process of updating the values of nodes based on the outcome of a trajectory<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">PROCESS<\/data>    <\/node>    <node id=\"REWARD\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A value that reflects the outcome of a simulation<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">METRIC<\/data>    <\/node>    <node id=\"UCT FORMULA\">      <data key=\"d0\">FORMULA<\/data>      <data key=\"d1\">A formula used to guide the selection of the next node<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">FORMULA<\/data>    <\/node>    <node id=\"REFLECTION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The process of using self-reflection to refine decision-making<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">PROCESS<\/data>    <\/node>    <node id=\"SELF-REFLECTION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">A method where the agent reflects on its actions and proposes superior alternatives<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">PROCESS<\/data>    <\/node>    <node id=\"MEMORY\">      <data key=\"d0\">STORAGE<\/data>      <data key=\"d1\">A storage for failed trajectories and corresponding reflections<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">STORAGE<\/data>    <\/node>    <node id=\"IN-CONTEXT LEARNING\">      <data key=\"d0\">LEARNING METHOD<\/data>      <data key=\"d1\">A method where the agent learns from trial and error using context<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">LEARNING METHOD<\/data>    <\/node>    <node id=\"MCTS\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">Monte Carlo Tree Search, an algorithm used in LATS for principled search<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">ALGORITHM<\/data>    <\/node>    <node id=\"HOTPOTQA\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset used to evaluate reasoning-based prompting results<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">DATASET<\/data>    <\/node>    <node id=\"GPT-3.5\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">A version of OpenAI's language model used in the experiments<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"COT\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Chain of Thought, a reasoning method<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">METHOD<\/data>    <\/node>    <node id=\"RAP\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Reasoning and Planning, a method used in the experiments<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">METHOD<\/data>    <\/node>    <node id=\"EXACT MATCH (EM)\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric used to evaluate the accuracy of reasoning<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">METRIC<\/data>    <\/node>    <node id=\"PROGRAMMING\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">A domain that requires reasoning and acting<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">DOMAIN<\/data>    <\/node>    <node id=\"CHEN ET AL., 2021\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study or paper related to programming<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"AUSTIN ET AL.\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study or paper related to programming<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"WEI ET AL., 2022\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study or paper related to Chain of Thought<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"WANG ET AL., 2022\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study or paper related to self-consistency<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"YAO ET AL., 2023A\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study or paper related to Tree of Thought<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"HAO ET AL., 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study or paper related to Reasoning and Planning<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"SHINN ET AL., 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study or paper related to self-reflection<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"MADAAN ET AL., 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study or paper related to self-reflection<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"CAMPBELL ET AL., 2002\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study or paper related to programmed heuristics<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"SILVER ET AL., 2017\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study or paper related to learned heuristics<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>      <data key=\"d3\">REFERENCE<\/data>    <\/node>    <node id=\"TOT\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/node>    <node id=\"SCALAR VALUE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A numeric value assigned to each new child node for selection and backpropagation<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/node>    <node id=\"SELECTION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The process of choosing nodes based on their assigned scalar values<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/node>    <node id=\"SELF-CONSISTENCY\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A heuristic where actions sampled multiple times at the same state tend to be more accurate<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/node>    <node id=\"HYPERPARAMETER\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A parameter whose value is set before the learning process begins<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/node>    <node id=\"PROGRAMMED HEURISTICS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Heuristics that are manually designed and implemented<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/node>    <node id=\"LEARNED HEURISTICS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Heuristics that are learned through machine learning techniques<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/node>    <node id=\"NODE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A point in the search tree representing a state<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/node>    <node id=\"DEPTH LEVEL\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">The level of a node in the search tree, indicating its distance from the root<\/data>      <data key=\"d2\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/node>    <edge source=\"EVALUATION\" target=\"AGENT\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">The agent's progress in task completion is quantified during the evaluation process<\/data>      <data key=\"d6\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/edge>    <edge source=\"LATS\" target=\"VALUE FUNCTION\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">LATS uses a novel value function based on self-generated LM score and self-consistency score<\/data>      <data key=\"d6\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/edge>    <edge source=\"LATS\" target=\"MCTS\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">LATS leverages MCTS for principled search<\/data>      <data key=\"d6\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/edge>    <edge source=\"VALUE FUNCTION\" target=\"P&#920;\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">P&#952; is repurposed into a value function by reasoning about a given state<\/data>      <data key=\"d6\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/edge>    <edge source=\"VALUE FUNCTION\" target=\"ENVIRONMENTAL FEEDBACK\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Environmental feedback is used to improve value assignment<\/data>      <data key=\"d6\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/edge>    <edge source=\"SELF-CONSISTENCY SCORE\" target=\"WANG ET AL., 2022\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Self-consistency score is a metric referenced in Wang et al., 2022<\/data>      <data key=\"d6\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/edge>    <edge source=\"HEURISTIC\" target=\"CAMPBELL ET AL., 2002\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Heuristic is a concept referenced in Campbell et al., 2002<\/data>      <data key=\"d6\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/edge>    <edge source=\"HEURISTIC\" target=\"SILVER ET AL., 2017\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Heuristic is a concept referenced in Silver et al., 2017<\/data>      <data key=\"d6\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/edge>    <edge source=\"SIMULATION\" target=\"TERMINAL STATE\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Simulation expands the selected node until a terminal state is reached<\/data>      <data key=\"d6\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/edge>    <edge source=\"TERMINAL STATE\" target=\"TRAJECTORY\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">A trajectory is the sequence of states from the root to the terminal state<\/data>      <data key=\"d6\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/edge>    <edge source=\"TRAJECTORY\" target=\"BACKPROPAGATION\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">Backpropagation updates the values of the tree based on the outcome of a trajectory<\/data>      <data key=\"d6\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/edge>    <edge source=\"BACKPROPAGATION\" target=\"REWARD\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Reward is used in backpropagation to update the values of the tree<\/data>      <data key=\"d6\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/edge>    <edge source=\"BACKPROPAGATION\" target=\"UCT FORMULA\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">The UCT formula uses updated values from backpropagation to guide node selection<\/data>      <data key=\"d6\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/edge>    <edge source=\"REFLECTION\" target=\"SELF-REFLECTION\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">Reflection leverages self-reflection to refine decision-making<\/data>      <data key=\"d6\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/edge>    <edge source=\"SELF-REFLECTION\" target=\"MEMORY\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Failed trajectories and reflections are stored in memory<\/data>      <data key=\"d6\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/edge>    <edge source=\"SELF-REFLECTION\" target=\"SHINN ET AL., 2023\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Self-reflection is a process referenced in Shinn et al., 2023<\/data>      <data key=\"d6\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/edge>    <edge source=\"SELF-REFLECTION\" target=\"MADAAN ET AL., 2023\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Self-reflection is a process referenced in Madaan et al., 2023<\/data>      <data key=\"d6\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/edge>    <edge source=\"MEMORY\" target=\"IN-CONTEXT LEARNING\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">In-context learning integrates stored trajectories and reflections as additional context<\/data>      <data key=\"d6\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"GPT-3.5\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">GPT-3.5 is used to evaluate reasoning-based prompting results on HotpotQA<\/data>      <data key=\"d6\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/edge>    <edge source=\"COT\" target=\"WEI ET AL., 2022\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">CoT is a method referenced in Wei et al., 2022<\/data>      <data key=\"d6\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/edge>    <edge source=\"RAP\" target=\"HAO ET AL., 2023\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">RAP is a method referenced in Hao et al., 2023<\/data>      <data key=\"d6\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/edge>    <edge source=\"YAO ET AL., 2023A\" target=\"TOT\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">ToT is a method referenced in Yao et al., 2023a<\/data>      <data key=\"d6\">02ef0185bbeaaef92c3a8ee18b7a38cf<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"fb9cb0c0984d44c3da881886ed637e55","chunk":"ulations\nby modifying state design and tree dimensions. (5) Modu-\nlarity : The base LM agent, reflection generator, and value\nfunction can be independently altered and adapted to indi-\nvidual LM properties.\n5. Experiments\nTo demonstrate the general applicability of LATS, we eval-\nuate our method on a variety of domains that require rea-\nsoning and acting: programming (Chen et al., 2021; Austin\net al., 2022), HotPotQA (Yang et al., 2018), WebShop (Yao\net al., 2022), and Game of 24 (Yao et al., 2023a).Prompt Method HotpotQA (EM) \u2191\nReAct (Yao et al., 2023b) 0.32\nReAct (best of k) 0.38\nReflexion (Shinn et al., 2023) 0.51\nToT (ReAct) 0.39\nRAP (ReAct) 0.54\nLATS (ReAct) 0.63\nLATS ( n= 3) 0.58\nLATS ( n= 10 ) 0.65\nLATS (CoT + ReAct) 0.71\nTable 3. GPT-3.5 acting -based prompting results on HotpotQA.\nLATS achieves the highest exact match (EM) for acting. We\nsample n= 5nodes and use k= 50 trajectories. We also evaluate\nsampling ReAct ktimes and using both CoT and ReAct base\nprompting designs for LATS, which achieves the best performance.\nNote that LATS outperforms ToT and RAP with ReAct prompting,\nwhich are the simple adaptations of search algorithms to decision-\nmaking.\n5.1. HotPotQA\nFor a task that can be approached with both reasoning-based\nand acting-based strategies, we consider HotPotQA (Yang\net al., 2018), a multi-hop question-answering benchmark\nthat requires retrieval over two or more Wikipedia passages.\nFor the action space, in addition to LM thoughts, we follow\nthe setup from Yao et al. (2023b), which provides the agent\nwith API calls to search and retrieve information. The output\nof these API calls and self-generated reflections form the\nobservation space. Note that consistent with previous work\n(Yao et al., 2023b; Shinn et al., 2023), we use an oracle\nsetup for HotPotQA, in which the environment provides\nfeedback about the answer\u2019s correctness upon receiving an\nanswer. This enables a fair comparison between our method\nand baselines in scenarios where the quality of feedback is\nhigh, allowing us to focus our evaluation on how well the\nagent incorporates external feedback. We use a subset of\n100 questions and three few-shot examples for each method.\nFor ToT, we use DFS as the base search algorithm. For all\nmethods that involve sampling, including LATS, we sample\nk= 50 trajectories. More details are in Appendix Sec. D.\nWe evaluate internal reasoning strategies by removing ac-\ntions and observations from the context, corresponding to\nCoT (Wei et al., 2022) and its variants, CoT-SC (Wang et al.,\n2022), ToT (Yao et al., 2023a), and RAP (Hao et al., 2023).\nThese methods rely solely on the agent\u2019s existing knowledge\nto answer the question. We further consider acting-based\nmethods ReAct, Reflexion, and LATS, which augment the\nagent with the interactive API environment and primarily\nevaluate its information retrieval abilities. We also design\na simple integration of search algorithms with LM agents,\nextending ToT and RAP with ReAct prompting to handle\n6Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nPrompt Method Model Pass@1 \u2191\nCoT (Wei et al., 2022) GPT-3.5 46.9\nReAct (Yao et al., 2023b) GPT-3.5 56.9\nReflexion (Shinn et al., 2023) GPT-3.5 68.1\nToT (Yao et al., 2023a) GPT-3.5 54.4\nRAP (Hao et al., 2023) GPT-3.5 63.1\nLATS (ReAct) GPT-3.5 83.8\nBase LM GPT-4 80.1\nReflexion GPT-4 91.0\nLATS (ReAct) GPT-4 92.7\nTable 4. GPT-3.5 and GPT-4 Pass@1 accuracy on HumanEval.\nPrompting with LATS achieves the best performance. We sample\n5 solutions during expansion for 8 iterations.\nexternal observations. In addition, while LATS is designed\nfor scenarios where external feedback can enhance reason-\ning, we also implement a reasoning-only version with CoT\nas the base prompting framework. Moreover, we combine\ninternal and external reasoning in LATS by first prompting\nwith a CoT-based prompt and then switching to a ReAct-\nbased prompt upon failure. This is closer to how humans\nmight approach this task by using tools to retrieve additional\ninformation only when the answer is not already known.\nResults. We observe in Tab. 2 and Tab. 3 that both in-\nternal reasoning and external retrieval strategies perform\nwell on HotPotQA. Due to their large-scale training corpus,\nmodern LMs already encode factual","chunk_id":"fb9cb0c0984d44c3da881886ed637e55","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"LATS","type":"METHOD\/TECHNIQUE","description":"LATS (Language Agent Tree Search) is a method designed to unify reasoning, acting, and planning in language models. It achieves high performance in various domains by sampling nodes and using trajectories.","source_id":"fb9cb0c0984d44c3da881886ed637e55"},{"name":"HOTPOTQA","type":"BENCHMARK","description":"HotPotQA is a multi-hop question-answering benchmark that requires retrieval over two or more Wikipedia passages. It is used to evaluate reasoning and acting strategies in language models.","source_id":"fb9cb0c0984d44c3da881886ed637e55"},{"name":"GPT-3.5","type":"MODEL","description":"GPT-3.5 is a version of OpenAI's language model used in various experiments to evaluate different prompting methods, including LATS, ReAct, Reflexion, and others.","source_id":"fb9cb0c0984d44c3da881886ed637e55"},{"name":"GPT-4","type":"MODEL","description":"GPT-4 is a more advanced version of OpenAI's language model, used to evaluate the performance of different prompting methods, including LATS and Reflexion.","source_id":"fb9cb0c0984d44c3da881886ed637e55"},{"name":"REACT","type":"METHOD\/TECHNIQUE","description":"ReAct is a prompting method used in language models to enhance reasoning and acting capabilities. It is evaluated in various experiments, including those involving HotPotQA.","source_id":"fb9cb0c0984d44c3da881886ed637e55"},{"name":"REFLEXION","type":"METHOD\/TECHNIQUE","description":"Reflexion is a prompting method that enhances the reasoning capabilities of language models. It is evaluated in experiments involving HotPotQA and other benchmarks.","source_id":"fb9cb0c0984d44c3da881886ed637e55"},{"name":"TOT","type":"METHOD\/TECHNIQUE","description":"ToT (Tree of Thoughts) is a prompting method that uses search algorithms to enhance decision-making in language models. It is evaluated in experiments involving HotPotQA and other benchmarks.","source_id":"fb9cb0c0984d44c3da881886ed637e55"},{"name":"RAP","type":"METHOD\/TECHNIQUE","description":"RAP (ReAct Prompting) is a method that combines ReAct prompting with search algorithms to enhance decision-making in language models. It is evaluated in experiments involving HotPotQA and other benchmarks.","source_id":"fb9cb0c0984d44c3da881886ed637e55"},{"name":"COT","type":"METHOD\/TECHNIQUE","description":"CoT (Chain of Thought) is a prompting method that relies on the agent's existing knowledge to answer questions. It is evaluated in experiments involving HotPotQA and other benchmarks.","source_id":"fb9cb0c0984d44c3da881886ed637e55"},{"name":"COT-SC","type":"METHOD\/TECHNIQUE","description":"CoT-SC (Chain of Thought with Self-Consistency) is a variant of the CoT method that enhances reasoning capabilities in language models. It is evaluated in experiments involving HotPotQA and other benchmarks.","source_id":"fb9cb0c0984d44c3da881886ed637e55"},{"name":"HUMANEVAL","type":"BENCHMARK","description":"HumanEval is a benchmark used to evaluate the Pass@1 accuracy of language models like GPT-3.5 and GPT-4. It involves tasks that require reasoning and acting capabilities.","source_id":"fb9cb0c0984d44c3da881886ed637e55"},{"name":"YAO ET AL., 2023A","type":"PUBLICATION","description":"A paper by Yao et al. published in 2023 that discusses the ToT (Tree of Thoughts) method and its application in language models.","source_id":"fb9cb0c0984d44c3da881886ed637e55"},{"name":"YAO ET AL., 2023B","type":"PUBLICATION","description":"A paper by Yao et al. published in 2023 that discusses the ReAct method and its application in language models.","source_id":"fb9cb0c0984d44c3da881886ed637e55"},{"name":"SHINN ET AL., 2023","type":"PUBLICATION","description":"A paper by Shinn et al. published in 2023 that discusses the Reflexion method and its application in language models.","source_id":"fb9cb0c0984d44c3da881886ed637e55","entity_type":"PUBLICATION"},{"name":"HAO ET AL., 2023","type":"PUBLICATION","description":"A paper by Hao et al. published in 2023 that discusses the RAP (ReAct Prompting) method and its application in language models.","source_id":"fb9cb0c0984d44c3da881886ed637e55","entity_type":"PUBLICATION"},{"name":"WEI ET AL., 2022","type":"PUBLICATION","description":"A paper by Wei et al. published in 2022 that discusses the CoT (Chain of Thought) method and its application in language models.","source_id":"fb9cb0c0984d44c3da881886ed637e55","entity_type":"PUBLICATION"},{"name":"WANG ET AL., 2022","type":"PUBLICATION","description":"A paper by Wang et al. published in 2022 that discusses the CoT-SC (Chain of Thought with Self-Consistency) method and its application in language models.","source_id":"fb9cb0c0984d44c3da881886ed637e55","entity_type":"PUBLICATION"},{"name":"CHEN ET AL., 2021","type":"PUBLICATION","description":"A paper by Chen et al. published in 2021 that is referenced in the context of evaluating LATS on programming tasks.","source_id":"fb9cb0c0984d44c3da881886ed637e55"},{"name":"AUSTIN ET AL., 2022","type":"PUBLICATION","description":"A paper by Austin et al. published in 2022 that is referenced in the context of evaluating LATS on programming tasks.","source_id":"fb9cb0c0984d44c3da881886ed637e55"},{"name":"WEBSHOP","type":"BENCHMARK","description":"WebShop is a benchmark used to evaluate reasoning and acting strategies in language models. It is referenced in the context of LATS evaluation.","source_id":"fb9cb0c0984d44c3da881886ed637e55"},{"name":"GAME OF 24","type":"BENCHMARK","description":"Game of 24 is a benchmark used to evaluate reasoning and acting strategies in language models. It is referenced in the context of LATS evaluation.","source_id":"fb9cb0c0984d44c3da881886ed637e55"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"LATS\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">LATS (Language Agent Tree Search) is a method designed to unify reasoning, acting, and planning in language models. It achieves high performance in various domains by sampling nodes and using trajectories.<\/data>      <data key=\"d2\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/node>    <node id=\"HOTPOTQA\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">HotPotQA is a multi-hop question-answering benchmark that requires retrieval over two or more Wikipedia passages. It is used to evaluate reasoning and acting strategies in language models.<\/data>      <data key=\"d2\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/node>    <node id=\"GPT-3.5\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-3.5 is a version of OpenAI's language model used in various experiments to evaluate different prompting methods, including LATS, ReAct, Reflexion, and others.<\/data>      <data key=\"d2\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4 is a more advanced version of OpenAI's language model, used to evaluate the performance of different prompting methods, including LATS and Reflexion.<\/data>      <data key=\"d2\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/node>    <node id=\"REACT\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">ReAct is a prompting method used in language models to enhance reasoning and acting capabilities. It is evaluated in various experiments, including those involving HotPotQA.<\/data>      <data key=\"d2\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/node>    <node id=\"REFLEXION\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Reflexion is a prompting method that enhances the reasoning capabilities of language models. It is evaluated in experiments involving HotPotQA and other benchmarks.<\/data>      <data key=\"d2\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/node>    <node id=\"TOT\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">ToT (Tree of Thoughts) is a prompting method that uses search algorithms to enhance decision-making in language models. It is evaluated in experiments involving HotPotQA and other benchmarks.<\/data>      <data key=\"d2\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/node>    <node id=\"RAP\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">RAP (ReAct Prompting) is a method that combines ReAct prompting with search algorithms to enhance decision-making in language models. It is evaluated in experiments involving HotPotQA and other benchmarks.<\/data>      <data key=\"d2\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/node>    <node id=\"COT\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">CoT (Chain of Thought) is a prompting method that relies on the agent's existing knowledge to answer questions. It is evaluated in experiments involving HotPotQA and other benchmarks.<\/data>      <data key=\"d2\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/node>    <node id=\"COT-SC\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">CoT-SC (Chain of Thought with Self-Consistency) is a variant of the CoT method that enhances reasoning capabilities in language models. It is evaluated in experiments involving HotPotQA and other benchmarks.<\/data>      <data key=\"d2\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/node>    <node id=\"HUMANEVAL\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">HumanEval is a benchmark used to evaluate the Pass@1 accuracy of language models like GPT-3.5 and GPT-4. It involves tasks that require reasoning and acting capabilities.<\/data>      <data key=\"d2\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/node>    <node id=\"YAO ET AL., 2023A\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper by Yao et al. published in 2023 that discusses the ToT (Tree of Thoughts) method and its application in language models.<\/data>      <data key=\"d2\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/node>    <node id=\"YAO ET AL., 2023B\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper by Yao et al. published in 2023 that discusses the ReAct method and its application in language models.<\/data>      <data key=\"d2\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/node>    <node id=\"SHINN ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper by Shinn et al. published in 2023 that discusses the Reflexion method and its application in language models.<\/data>      <data key=\"d2\">fb9cb0c0984d44c3da881886ed637e55<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"HAO ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper by Hao et al. published in 2023 that discusses the RAP (ReAct Prompting) method and its application in language models.<\/data>      <data key=\"d2\">fb9cb0c0984d44c3da881886ed637e55<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"WEI ET AL., 2022\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper by Wei et al. published in 2022 that discusses the CoT (Chain of Thought) method and its application in language models.<\/data>      <data key=\"d2\">fb9cb0c0984d44c3da881886ed637e55<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"WANG ET AL., 2022\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper by Wang et al. published in 2022 that discusses the CoT-SC (Chain of Thought with Self-Consistency) method and its application in language models.<\/data>      <data key=\"d2\">fb9cb0c0984d44c3da881886ed637e55<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"CHEN ET AL., 2021\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper by Chen et al. published in 2021 that is referenced in the context of evaluating LATS on programming tasks.<\/data>      <data key=\"d2\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/node>    <node id=\"AUSTIN ET AL., 2022\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper by Austin et al. published in 2022 that is referenced in the context of evaluating LATS on programming tasks.<\/data>      <data key=\"d2\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/node>    <node id=\"WEBSHOP\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">WebShop is a benchmark used to evaluate reasoning and acting strategies in language models. It is referenced in the context of LATS evaluation.<\/data>      <data key=\"d2\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/node>    <node id=\"GAME OF 24\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">Game of 24 is a benchmark used to evaluate reasoning and acting strategies in language models. It is referenced in the context of LATS evaluation.<\/data>      <data key=\"d2\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/node>    <edge source=\"LATS\" target=\"HOTPOTQA\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">LATS is evaluated on the HotPotQA benchmark to demonstrate its reasoning and acting capabilities.<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"LATS\" target=\"GPT-3.5\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">LATS is used with GPT-3.5 to achieve high performance in various benchmarks, including HotPotQA and HumanEval.<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"LATS\" target=\"GPT-4\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">LATS is used with GPT-4 to achieve high performance in various benchmarks, including HotPotQA and HumanEval.<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"LATS\" target=\"CHEN ET AL., 2021\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">LATS is evaluated on programming tasks as referenced in the paper by Chen et al. (2021).<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"LATS\" target=\"AUSTIN ET AL., 2022\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">LATS is evaluated on programming tasks as referenced in the paper by Austin et al. (2022).<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"LATS\" target=\"WEBSHOP\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS is evaluated on the WebShop benchmark to demonstrate its reasoning and acting capabilities.<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"LATS\" target=\"GAME OF 24\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS is evaluated on the Game of 24 benchmark to demonstrate its reasoning and acting capabilities.<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"YAO ET AL., 2023B\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">The setup for HotPotQA follows the method described in the paper by Yao et al. (2023b).<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"SHINN ET AL., 2023\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">The setup for HotPotQA follows the method described in the paper by Shinn et al. (2023).<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"HAO ET AL., 2023\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">The setup for HotPotQA follows the method described in the paper by Hao et al. (2023).<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"WEI ET AL., 2022\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">The setup for HotPotQA follows the method described in the paper by Wei et al. (2022).<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"WANG ET AL., 2022\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">The setup for HotPotQA follows the method described in the paper by Wang et al. (2022).<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"YAO ET AL., 2023A\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">The setup for HotPotQA follows the method described in the paper by Yao et al. (2023a).<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"GPT-3.5\" target=\"REACT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">ReAct is used with GPT-3.5 to enhance reasoning and acting capabilities in various benchmarks, including HotPotQA.<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"GPT-3.5\" target=\"REFLEXION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Reflexion is used with GPT-3.5 to enhance reasoning capabilities in various benchmarks, including HotPotQA.<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"GPT-3.5\" target=\"TOT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">ToT is used with GPT-3.5 to enhance decision-making capabilities in various benchmarks, including HotPotQA.<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"GPT-3.5\" target=\"RAP\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">RAP is used with GPT-3.5 to enhance decision-making capabilities in various benchmarks, including HotPotQA.<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"GPT-3.5\" target=\"COT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">CoT is used with GPT-3.5 to enhance reasoning capabilities in various benchmarks, including HotPotQA.<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"GPT-3.5\" target=\"COT-SC\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">CoT-SC is used with GPT-3.5 to enhance reasoning capabilities in various benchmarks, including HotPotQA.<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"GPT-3.5\" target=\"HUMANEVAL\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">GPT-3.5 is evaluated on the HumanEval benchmark to measure its Pass@1 accuracy.<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"REACT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">ReAct is used with GPT-4 to enhance reasoning and acting capabilities in various benchmarks, including HotPotQA.<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"REFLEXION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Reflexion is used with GPT-4 to enhance reasoning capabilities in various benchmarks, including HotPotQA.<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"HUMANEVAL\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">GPT-4 is evaluated on the HumanEval benchmark to measure its Pass@1 accuracy.<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"REACT\" target=\"YAO ET AL., 2023B\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">The paper by Yao et al. (2023b) discusses the ReAct method and its application in language models.<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"REFLEXION\" target=\"SHINN ET AL., 2023\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">The paper by Shinn et al. (2023) discusses the Reflexion method and its application in language models.<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"TOT\" target=\"YAO ET AL., 2023A\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">The paper by Yao et al. (2023a) discusses the ToT method and its application in language models.<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"RAP\" target=\"HAO ET AL., 2023\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">The paper by Hao et al. (2023) discusses the RAP method and its application in language models.<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"COT\" target=\"WEI ET AL., 2022\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">The paper by Wei et al. (2022) discusses the CoT method and its application in language models.<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>    <edge source=\"COT-SC\" target=\"WANG ET AL., 2022\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">The paper by Wang et al. (2022) discusses the CoT-SC method and its application in language models.<\/data>      <data key=\"d6\">fb9cb0c0984d44c3da881886ed637e55<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"99d90aededb61e04241516ed9ec656cc","chunk":" in LATS by first prompting\nwith a CoT-based prompt and then switching to a ReAct-\nbased prompt upon failure. This is closer to how humans\nmight approach this task by using tools to retrieve additional\ninformation only when the answer is not already known.\nResults. We observe in Tab. 2 and Tab. 3 that both in-\nternal reasoning and external retrieval strategies perform\nwell on HotPotQA. Due to their large-scale training corpus,\nmodern LMs already encode factual knowledge and can\noften directly answer the question correctly. While CoT can\nslightly enhance performance on questions requiring rea-\nsoning, larger gains are observed with search methods ToT\nand RAP (Tab. 2, Row 4, 5), which can sample and explore\nmore outputs. We observe similar results for acting-based\nmethods. LATS surpasses ReAct, even when sampling the\nsame number of trajectories, by expanding more nodes with\nprincipled search. This is demonstrated when modifying\nn, the number of nodes expanded during each iteration. In-\ncreasing ncan consistently improve performance, although\nat greater computational and inference costs. LATS also\noutperforms RAP on internal reasoning, but has higher per-\nformance on the decision-making setting of HotPotQA than\nthe reasoning setting. Contrary to LATS, the ReAct versions\nof ToT and RAP (Tab. 3, Row 4, 5) perform even worse than\nthe reasoning-only setting of HotPotQA, which indicates\nthat the acting-based setting is more challenging and adap-\ntation of search algorithms to decision-making scenarios\nis non-trivial . Combining internal and external reasoning\nin LATS results in the highest performance, indicating the\nimportance of external feedback in augmenting reasoning\neven in tasks where the base LM can already perform.Prompt Method Pass@1 \u2191\nCoT (Wei et al., 2022) 54.9\nReAct (Wei et al., 2022) 67.0\nReflexion (Shinn et al., 2023) 70.0\nToT (Yao et al., 2023a) 65.8\nRAP (Hao et al., 2023) 71.4\nLATS (ReAct) 81.1\nTable 5. GPT-3.5 Pass@1 accuracy on MBPP. Prompting with\nLATS achieves the highest performance. We sample 5 solutions\nduring expansion for 8 iterations.\n5.2. Programming\nTo demonstrate the importance of external observations\nfor complex reasoning tasks, we evaluate the baselines\nand LATS on programming with HumanEval (Chen et al.,\n2021)1and MBPP (Austin et al., 2022). Both datasets mea-\nsure the correctness of synthesized programs in Python from\nnatural language docstrings. We use individual solutions\nas the action space and test suite and compiler feedback as\nthe external observation. We follow Chen et al. (2023a) and\nuse an LM to generate a synthetic test suite of syntactically\nvalid \u201cassert\u201d statements for each question. For each step,\nthe solution is evaluated on this test suite, and the results,\nincluding successful and failed tests and compiler output,\nare added to the context as an observation.\nFor this task, the reasoning and acting baselines share an\naction space, but acting methods are able to incorporate\nobservations as additional context. For LATS, since each\naction corresponds to a complete solution, we skip the sim-\nulation step of LATS and directly use the percentage of\npassed tests as the backpropagated reward. We use k= 8\niterations, set the number of generated tests at 4, and sam-\nplen= 5solutions during expansion. After the search is\ncompleted, we select the solution with the highest value and\nevaluate it on the real test suite for the pass@1 accuracy\nevaluation. More details can be found in Appendix Sec. D.\nResults. Tab. 4 and Tab. 5 show that both search and seman-\ntic feedback are crucial for better performance. Despite not\nusing observations, ToT and RAP are competitive with Re-\nflexion. LATS has the highest performance on both datasets.\nRAP uses a search algorithm similar to LATS, which reveals\nthe importance of external feedback for difficult reasoning\ntasks such as programming. With GPT-4, using LATS sets\nthe state of the art for HumanEval, validating that LATS can\nbe used with more advanced LMs for higher performance.\n1Some baselines use 161 questions from HumanEval. We\nuse all 164 questions for LATS and find minimal performance\ndifferences, so we report baselines for both settings.\n7Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nMethod Score\u2191SR\u2191\nReAct (Yao et al., 2023b) 53.8 28.0\nReAct (best of k) 59.1 32.0\nReflexion (Shinn et al., 2023) 64.2 35.0\nLATS (ReAct) 75.9 38.0\nIL(Yao et al., 2022) 59.9 29.1\nIL+RL (Yao et al., 2022) 62.4 28.7\nFine-tuning (Furuta et al., 2024) 67.5 45.0\nExpert 82.1 59.6\nTable 6. Score and success rate (SR) on WebShop. Results are\norganized into prompting, RL-based training, and human","chunk_id":"99d90aededb61e04241516ed9ec656cc","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"LATS","type":"METHOD\/ALGORITHM","description":"LATS (Language Agent Tree Search) is a method that combines internal reasoning and external retrieval strategies to improve performance on tasks like HotPotQA and programming challenges","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"COT","type":"METHOD\/ALGORITHM","description":"CoT (Chain of Thought) is a prompting method that enhances performance on questions requiring reasoning","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"REACT","type":"METHOD\/ALGORITHM","description":"ReAct is a prompting method that combines reasoning and acting to improve task performance","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"TOT","type":"METHOD\/ALGORITHM","description":"ToT (Tree of Thoughts) is a search method that samples and explores multiple outputs to improve performance on reasoning tasks","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"RAP","type":"METHOD\/ALGORITHM","description":"RAP (Reasoning and Planning) is a search method that enhances performance by sampling and exploring multiple outputs","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"REFLEXION","type":"METHOD\/ALGORITHM","description":"Reflexion is a prompting method that incorporates external observations to improve performance on reasoning tasks","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"GPT-3.5","type":"MODEL","description":"GPT-3.5 is a version of OpenAI's language model used to evaluate the performance of various prompting methods on MBPP","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"GPT-4","type":"MODEL","description":"GPT-4 is a version of OpenAI's language model used to set the state of the art for HumanEval when combined with LATS","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"MBPP","type":"DATASET","description":"MBPP (Mostly Basic Python Problems) is a dataset used to measure the correctness of synthesized programs in Python from natural language docstrings","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"HUMANEVAL","type":"DATASET","description":"HumanEval is a dataset used to measure the correctness of synthesized programs in Python from natural language docstrings","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"HOTPOTQA","type":"DATASET","description":"HotPotQA is a dataset used to evaluate the performance of internal reasoning and external retrieval strategies","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"WEBSHOP","type":"DATASET","description":"WebShop is a dataset used to evaluate the performance of various methods on tasks involving reasoning, acting, and planning","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"IL","type":"METHOD\/ALGORITHM","description":"IL (Imitation Learning) is a method used to train models based on expert demonstrations","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"RL","type":"METHOD\/ALGORITHM","description":"RL (Reinforcement Learning) is a method used to train models based on reward signals","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"FINE-TUNING","type":"METHOD\/ALGORITHM","description":"Fine-tuning is a method used to improve model performance by training on specific datasets","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"EXPERT","type":"HUMAN","description":"Expert refers to human performance benchmarks used for comparison with model performance on WebShop","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"TAB. 2","type":"DATASET","description":"Tab. 2 is a table that shows the performance of internal reasoning and external retrieval strategies on HotPotQA","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"TAB. 3","type":"DATASET","description":"Tab. 3 is a table that shows the performance of various methods on HotPotQA in different settings","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"TAB. 4","type":"DATASET","description":"Tab. 4 is a table that shows the performance of various methods on programming tasks using HumanEval and MBPP datasets","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"TAB. 5","type":"DATASET","description":"Tab. 5 is a table that shows the GPT-3.5 Pass@1 accuracy on MBPP for various prompting methods","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"APPENDIX SEC. D","type":"DATASET","description":"Appendix Sec. D provides additional details on the evaluation of LATS and other methods on programming tasks","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"CHEN ET AL., 2021","type":"PUBLICATION","description":"Chen et al., 2021 is a publication that introduced the HumanEval dataset for evaluating the correctness of synthesized programs in Python","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"AUSTIN ET AL., 2022","type":"PUBLICATION","description":"Austin et al., 2022 is a publication that introduced the MBPP dataset for evaluating the correctness of synthesized programs in Python","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"CHEN ET AL., 2023A","type":"PUBLICATION","description":"Chen et al., 2023a is a publication that discusses the use of an LM to generate a synthetic test suite for evaluating programming tasks","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"WEI ET AL., 2022","type":"PUBLICATION","description":"Wei et al., 2022 is a publication that introduced the CoT and ReAct prompting methods","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"SHINN ET AL., 2023","type":"PUBLICATION","description":"Shinn et al., 2023 is a publication that introduced the Reflexion prompting method","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"YAO ET AL., 2023A","type":"PUBLICATION","description":"Yao et al., 2023a is a publication that introduced the ToT search method","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"HAO ET AL., 2023","type":"PUBLICATION","description":"Hao et al., 2023 is a publication that introduced the RAP search method","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"YAO ET AL., 2023B","type":"PUBLICATION","description":"Yao et al., 2023b is a publication that discusses the ReAct method and its performance on WebShop","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"YAO ET AL., 2022","type":"PUBLICATION","description":"Yao et al., 2022 is a publication that discusses the IL and IL+RL methods and their performance on WebShop","source_id":"99d90aededb61e04241516ed9ec656cc"},{"name":"FURUTA ET AL., 2024","type":"PUBLICATION","description":"Furuta et al., 2024 is a publication that discusses the fine-tuning method and its performance on WebShop","source_id":"99d90aededb61e04241516ed9ec656cc"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"LATS\">      <data key=\"d0\">METHOD\/ALGORITHM<\/data>      <data key=\"d1\">LATS (Language Agent Tree Search) is a method that combines internal reasoning and external retrieval strategies to improve performance on tasks like HotPotQA and programming challenges<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"COT\">      <data key=\"d0\">METHOD\/ALGORITHM<\/data>      <data key=\"d1\">CoT (Chain of Thought) is a prompting method that enhances performance on questions requiring reasoning<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"REACT\">      <data key=\"d0\">METHOD\/ALGORITHM<\/data>      <data key=\"d1\">ReAct is a prompting method that combines reasoning and acting to improve task performance<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"TOT\">      <data key=\"d0\">METHOD\/ALGORITHM<\/data>      <data key=\"d1\">ToT (Tree of Thoughts) is a search method that samples and explores multiple outputs to improve performance on reasoning tasks<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"RAP\">      <data key=\"d0\">METHOD\/ALGORITHM<\/data>      <data key=\"d1\">RAP (Reasoning and Planning) is a search method that enhances performance by sampling and exploring multiple outputs<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"REFLEXION\">      <data key=\"d0\">METHOD\/ALGORITHM<\/data>      <data key=\"d1\">Reflexion is a prompting method that incorporates external observations to improve performance on reasoning tasks<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"GPT-3.5\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-3.5 is a version of OpenAI's language model used to evaluate the performance of various prompting methods on MBPP<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4 is a version of OpenAI's language model used to set the state of the art for HumanEval when combined with LATS<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"MBPP\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">MBPP (Mostly Basic Python Problems) is a dataset used to measure the correctness of synthesized programs in Python from natural language docstrings<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"HUMANEVAL\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">HumanEval is a dataset used to measure the correctness of synthesized programs in Python from natural language docstrings<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"HOTPOTQA\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">HotPotQA is a dataset used to evaluate the performance of internal reasoning and external retrieval strategies<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"WEBSHOP\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">WebShop is a dataset used to evaluate the performance of various methods on tasks involving reasoning, acting, and planning<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"IL\">      <data key=\"d0\">METHOD\/ALGORITHM<\/data>      <data key=\"d1\">IL (Imitation Learning) is a method used to train models based on expert demonstrations<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"RL\">      <data key=\"d0\">METHOD\/ALGORITHM<\/data>      <data key=\"d1\">RL (Reinforcement Learning) is a method used to train models based on reward signals<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"FINE-TUNING\">      <data key=\"d0\">METHOD\/ALGORITHM<\/data>      <data key=\"d1\">Fine-tuning is a method used to improve model performance by training on specific datasets<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"EXPERT\">      <data key=\"d0\">HUMAN<\/data>      <data key=\"d1\">Expert refers to human performance benchmarks used for comparison with model performance on WebShop<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"TAB. 2\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">Tab. 2 is a table that shows the performance of internal reasoning and external retrieval strategies on HotPotQA<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"TAB. 3\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">Tab. 3 is a table that shows the performance of various methods on HotPotQA in different settings<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"TAB. 4\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">Tab. 4 is a table that shows the performance of various methods on programming tasks using HumanEval and MBPP datasets<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"TAB. 5\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">Tab. 5 is a table that shows the GPT-3.5 Pass@1 accuracy on MBPP for various prompting methods<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"APPENDIX SEC. D\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">Appendix Sec. D provides additional details on the evaluation of LATS and other methods on programming tasks<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"CHEN ET AL., 2021\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Chen et al., 2021 is a publication that introduced the HumanEval dataset for evaluating the correctness of synthesized programs in Python<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"AUSTIN ET AL., 2022\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Austin et al., 2022 is a publication that introduced the MBPP dataset for evaluating the correctness of synthesized programs in Python<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"CHEN ET AL., 2023A\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Chen et al., 2023a is a publication that discusses the use of an LM to generate a synthetic test suite for evaluating programming tasks<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"WEI ET AL., 2022\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Wei et al., 2022 is a publication that introduced the CoT and ReAct prompting methods<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"SHINN ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Shinn et al., 2023 is a publication that introduced the Reflexion prompting method<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"YAO ET AL., 2023A\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Yao et al., 2023a is a publication that introduced the ToT search method<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"HAO ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Hao et al., 2023 is a publication that introduced the RAP search method<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"YAO ET AL., 2023B\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Yao et al., 2023b is a publication that discusses the ReAct method and its performance on WebShop<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"YAO ET AL., 2022\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Yao et al., 2022 is a publication that discusses the IL and IL+RL methods and their performance on WebShop<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <node id=\"FURUTA ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Furuta et al., 2024 is a publication that discusses the fine-tuning method and its performance on WebShop<\/data>      <data key=\"d2\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/node>    <edge source=\"LATS\" target=\"REACT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS surpasses ReAct in performance by expanding more nodes with principled search<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"LATS\" target=\"RAP\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">LATS outperforms RAP on internal reasoning tasks<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"LATS\" target=\"HOTPOTQA\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS achieves high performance on the decision-making setting of HotPotQA<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"LATS\" target=\"MBPP\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">LATS achieves the highest performance on MBPP<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"LATS\" target=\"HUMANEVAL\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">LATS sets the state of the art for HumanEval with GPT-4<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"COT\" target=\"HOTPOTQA\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">CoT slightly enhances performance on questions requiring reasoning in HotPotQA<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"COT\" target=\"WEI ET AL., 2022\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Wei et al., 2022 introduced the CoT prompting method<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"REACT\" target=\"HOTPOTQA\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">ReAct is used as a prompting method in HotPotQA<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"REACT\" target=\"WEI ET AL., 2022\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Wei et al., 2022 introduced the ReAct prompting method<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"REACT\" target=\"YAO ET AL., 2023B\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Yao et al., 2023b discusses the ReAct method and its performance on WebShop<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"TOT\" target=\"HOTPOTQA\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">ToT shows larger gains in performance on HotPotQA<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"TOT\" target=\"YAO ET AL., 2023A\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Yao et al., 2023a introduced the ToT search method<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"RAP\" target=\"HOTPOTQA\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">RAP shows larger gains in performance on HotPotQA<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"RAP\" target=\"HAO ET AL., 2023\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Hao et al., 2023 introduced the RAP search method<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"REFLEXION\" target=\"HOTPOTQA\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Reflexion is competitive with other methods on HotPotQA<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"REFLEXION\" target=\"SHINN ET AL., 2023\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Shinn et al., 2023 introduced the Reflexion prompting method<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"GPT-3.5\" target=\"MBPP\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">GPT-3.5 is used to evaluate the performance of various prompting methods on MBPP<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"HUMANEVAL\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">GPT-4 is used to set the state of the art for HumanEval with LATS<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"MBPP\" target=\"TAB. 4\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Tab. 4 shows the performance of various methods on programming tasks using the MBPP dataset<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"MBPP\" target=\"TAB. 5\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Tab. 5 shows the GPT-3.5 Pass@1 accuracy on MBPP for various prompting methods<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"MBPP\" target=\"APPENDIX SEC. D\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Appendix Sec. D provides additional details on the evaluation of LATS and other methods on programming tasks using the MBPP dataset<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"MBPP\" target=\"AUSTIN ET AL., 2022\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Austin et al., 2022 introduced the MBPP dataset<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"MBPP\" target=\"CHEN ET AL., 2023A\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Chen et al., 2023a discusses the use of an LM to generate a synthetic test suite for evaluating programming tasks using the MBPP dataset<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"HUMANEVAL\" target=\"TAB. 4\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Tab. 4 shows the performance of various methods on programming tasks using the HumanEval dataset<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"HUMANEVAL\" target=\"APPENDIX SEC. D\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Appendix Sec. D provides additional details on the evaluation of LATS and other methods on programming tasks using the HumanEval dataset<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"HUMANEVAL\" target=\"CHEN ET AL., 2021\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Chen et al., 2021 introduced the HumanEval dataset<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"HUMANEVAL\" target=\"CHEN ET AL., 2023A\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Chen et al., 2023a discusses the use of an LM to generate a synthetic test suite for evaluating programming tasks using the HumanEval dataset<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"TAB. 2\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Tab. 2 shows the performance of internal reasoning and external retrieval strategies on HotPotQA<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"TAB. 3\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Tab. 3 shows the performance of various methods on HotPotQA in different settings<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"IL\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">IL is used to train models for tasks in WebShop<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"RL\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">RL is used to train models for tasks in WebShop<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"FINE-TUNING\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Fine-tuning is used to improve model performance on WebShop<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"EXPERT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Expert performance is used as a benchmark for comparison on WebShop<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"IL\" target=\"YAO ET AL., 2022\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Yao et al., 2022 discusses the IL method and its performance on WebShop<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"RL\" target=\"YAO ET AL., 2022\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Yao et al., 2022 discusses the RL method and its performance on WebShop<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>    <edge source=\"FINE-TUNING\" target=\"FURUTA ET AL., 2024\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Furuta et al., 2024 discusses the fine-tuning method and its performance on WebShop<\/data>      <data key=\"d5\">99d90aededb61e04241516ed9ec656cc<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"594449768ae2dea9b2efbe677075096b","chunk":"ao et al., 2022) 59.9 29.1\nIL+RL (Yao et al., 2022) 62.4 28.7\nFine-tuning (Furuta et al., 2024) 67.5 45.0\nExpert 82.1 59.6\nTable 6. Score and success rate (SR) on WebShop. Results are\norganized into prompting, RL-based training, and human perfor-\nmance. For the same number of iterations, LATS improves both\nscore and SR and surpasses RL-based training.\n5.3. WebShop\nFor a complex decision-making environment with practi-\ncal applications, we consider WebShop (Yao et al., 2022),\nan online shopping environment composed of a website\nwith 1.18M real-world products and 12k human instructions.\nAgents must navigate a website through a variety of com-\nmands to purchase an item matching a user specification.\nWe use the preconstructed action space of search and click\ncommands and browser feedback and reflections for the\nobservation. The performance is gauged using two metrics:\nan average score, reflecting the percentage of user-specified\nattributes met by the selected product, and a success rate,\nindicating the frequency with which the chosen product ful-\nfills all given conditions. We compare against acting-based\nprompting methods and RL-based approaches. We evaluate\non 50 instructions, expand n= 5children for LATS, and set\nk= 30 for LATS, ReAct (best of k), and Reflexion. More\ndetails and prompts are in Appendix Sec. D and Sec. G.\nResults. We find in Tab. 6 that GPT-3.5 with ReAct is\ncompetitive to imitation learning (IL) and can exceed re-\ninforcement learning techniques with stronger prompting\nstrategies. Sampling k= 30 trajectories with ReAct and\nReflexion results in a similar performance, suggesting the se-\nmantic feedback is not as helpful in complex environments\nlike WebShop. Similar to Shinn et al. (2023), we find that\ngenerated reflections are often generic and do not provide\nuseful feedback, resulting in a tendency for the agent to\nbecome stuck in local minima. However, using LATS in-\ndeed results in a noticeable improvement, indicating a more\neffective exploration for the same number of iterations.\n5.4. Ablation Study and Additional Analysis\nWe further test the reasoning ability of LATS on Game of 24,\nand also conduct additional experiments on HotPotQA to\ndemonstrate the effect of each component of LATS (resultsPrompt Method Game of 24 (Success Rate) \u2191\nCoT (Wei et al., 2022) 0.08\nReflexion (Shinn et al., 2023) 0.12\nToT (Yao et al., 2023a) 0.20\nRAP (Hao et al., 2023) 0.40\nLATS (CoT) 0.44\nTable 7. Results on Game of 24 with GPT-3.5. We sample n= 5\nnodes and k= 30 trajectories.\nPrompt Method HotPotQA (EM) \u2191\nToT (ReAct) 0.39\nRAP (ReAct) 0.54\nLATS (No LM Heuristic) 0.37\nLATS (DFS) 0.42\nLATS (No Reflection) 0.58\nLATS (ReAct) 0.63\nTable 8. Ablation results on LATS and baseline variants in Hot-\nPotQA. We use ReAct as the base prompt and sample n= 5\nchildren and k= 50 trajectories. LATS requires every component\nand operation for optimal performance.\nshown in Tab. 8). More ablations for token consumption on\nHotPotQA are in Tab. 9 in Appendix Sec. C.\nReasoning on Game of 24. To show how LATS can be\napplied to purely internal reasoning tasks, we additionally\nevaluate on Game of 24 (Yao et al., 2023a), a mathematical\nreasoning task where the agent must construct 24 out of a\nset of numbers and basic operations. We use CoT as the\nbase prompting design and employ the same operations as\nin other settings. We find in Tab. 7 that LATS outperforms\nprevious methods proposed specifically for reasoning. This\nis due to our proposed value function, which incorporates\nself-consistency as an additional heuristic.\nSelf-reflection. LATS uses self-reflection to provide addi-\ntional semantic signals for the agent. In Tab. 8 (Row 5, 6),\nwe observe a 0.05performance drop when self-reflection\nis removed from LATS, validating its usefulness. This is a\nsmaller gain than the 0.19gain that Reflexion has over Re-\nAct as shown in Tab. 3, suggesting overlap between the ques-\ntions where an answer can be improved by self-reflection\nand search. This variant outperforms RAP (ReAct), reflect-\ning our improvements to MCTS.\nSearch algorithm. MCTS is a more principled search algo-\nrithm than variants like A* (Zhuang et al., 2023) or DFS and\nis the basis for observed performance gains. We observe\nthe effects of using DFS, and incorporate the LM-based\nheuristic used in ToT in which branches with low values are\npruned. This removes the selection and backpropagation\noperations, and we observe a 0","chunk_id":"594449768ae2dea9b2efbe677075096b","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"WEBSHOP","type":"ENVIRONMENT\/PLATFORM","description":"WebShop is an online shopping environment composed of a website with 1.18M real-world products and 12k human instructions, where agents must navigate a website through various commands to purchase an item matching a user specification","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"LATS","type":"METHOD\/TECHNIQUE","description":"LATS is a method that improves both score and success rate in WebShop, surpassing RL-based training and using a preconstructed action space of search and click commands, browser feedback, and reflections for observation","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"GPT-3.5","type":"MODEL","description":"GPT-3.5 is a version of OpenAI's language model used in WebShop for acting-based prompting methods and evaluated on 50 instructions","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"REACT","type":"METHOD\/TECHNIQUE","description":"ReAct is a prompting method used with GPT-3.5 in WebShop, sampling 30 trajectories and providing competitive performance to imitation learning and reinforcement learning techniques","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"REFLEXION","type":"METHOD\/TECHNIQUE","description":"Reflexion is a prompting method used in WebShop, similar to ReAct, but its semantic feedback is not as helpful in complex environments like WebShop","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"GAME OF 24","type":"TASK","description":"Game of 24 is a mathematical reasoning task where the agent must construct 24 out of a set of numbers and basic operations, used to test the reasoning ability of LATS","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"HOTPOTQA","type":"TASK","description":"HotPotQA is a task used to demonstrate the effect of each component of LATS, involving reasoning and question answering","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"COT","type":"METHOD\/TECHNIQUE","description":"CoT (Chain of Thought) is a base prompting design used in the Game of 24 with LATS","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"TOT","type":"METHOD\/TECHNIQUE","description":"ToT (Tree of Thoughts) is a prompting method used in HotPotQA and Game of 24, incorporating LM-based heuristics for pruning branches with low values","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"RAP","type":"METHOD\/TECHNIQUE","description":"RAP is a prompting method used in HotPotQA and Game of 24, showing competitive performance in reasoning tasks","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"MCTS","type":"ALGORITHM","description":"MCTS (Monte Carlo Tree Search) is a search algorithm used in LATS, providing principled search and observed performance gains over other variants like A* and DFS","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"DFS","type":"ALGORITHM","description":"DFS (Depth-First Search) is a search algorithm variant compared with MCTS in LATS, used to observe the effects of different search strategies","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"YAO ET AL., 2022","type":"PUBLICATION","description":"A reference to a study or paper by Yao et al. in 2022, related to WebShop and other methods","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"FURUTA ET AL., 2024","type":"PUBLICATION","description":"A reference to a study or paper by Furuta et al. in 2024, related to fine-tuning methods","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"SHINN ET AL., 2023","type":"PUBLICATION","description":"A reference to a study or paper by Shinn et al. in 2023, related to Reflexion and its performance","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"HAO ET AL., 2023","type":"PUBLICATION","description":"A reference to a study or paper by Hao et al. in 2023, related to RAP and its performance","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"ZHUANG ET AL., 2023","type":"PUBLICATION","description":"A reference to a study or paper by Zhuang et al. in 2023, related to search algorithms like A* and DFS","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"FINE-TUNING","type":"","description":"\nFine-tuning is a method mentioned in the context of improving performance in WebShop, specifically referenced in Furuta et al., 2024","source_id":"594449768ae2dea9b2efbe677075096b","entity_type":"METHOD\/TECHNIQUE"},{"name":"SEARCH ALGORITHMS","type":"","description":"","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"IMPROVEMENT LEARNING (IL)","type":"METHOD\/TECHNIQUE","description":"IL (Improvement Learning) is a method used in WebShop for training agents, mentioned in comparison with other methods like RL-based training","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"REINFORCEMENT LEARNING (RL)","type":"METHOD\/TECHNIQUE","description":"RL (Reinforcement Learning) is a method used in WebShop for training agents, mentioned in comparison with other methods like IL and LATS","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"EXPERT","type":"PERSON","description":"Expert refers to human performance metrics used as a benchmark in WebShop","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"PROMPTING","type":"METHOD\/TECHNIQUE","description":"Prompting refers to methods used to guide the behavior of models like GPT-3.5 in WebShop, including techniques like ReAct and Reflexion","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"SEARCH AND CLICK COMMANDS","type":"METHOD\/TECHNIQUE","description":"Search and click commands are part of the preconstructed action space used in WebShop for agent navigation","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"BROWSER FEEDBACK","type":"METHOD\/TECHNIQUE","description":"Browser feedback is used in WebShop as part of the observation mechanism for agents","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"REFLECTIONS","type":"METHOD\/TECHNIQUE","description":"Reflections are used in WebShop as part of the observation mechanism for agents, providing feedback for decision-making","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"SUCCESS RATE (SR)","type":"METRIC","description":"Success Rate (SR) is a metric used in WebShop to indicate the frequency with which the chosen product fulfills all given conditions","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"AVERAGE SCORE","type":"METRIC","description":"Average Score is a metric used in WebShop to reflect the percentage of user-specified attributes met by the selected product","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"SELF-REFLECTION","type":"METHOD\/TECHNIQUE","description":"Self-reflection is a technique used in LATS to provide additional semantic signals for the agent, improving performance","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"VALUE FUNCTION","type":"METHOD\/TECHNIQUE","description":"Value function is a component of LATS that incorporates self-consistency as an additional heuristic for reasoning tasks","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"MCTS (MONTE CARLO TREE SEARCH)","type":"ALGORITHM","description":"MCTS (Monte Carlo Tree Search) is a search algorithm used in LATS, providing principled search and observed performance gains over other variants like A* and DFS","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"A*","type":"ALGORITHM","description":"A* is a search algorithm variant compared with MCTS in LATS, used to observe the effects of different search strategies","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"TOKEN CONSUMPTION","type":"METRIC","description":"Token consumption is a metric used in the ablation study of LATS to measure the efficiency of different components","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"NODES","type":"METRIC","description":"Nodes refer to the sampled points in the search space used in the evaluation of LATS on Game of 24","source_id":"594449768ae2dea9b2efbe677075096b"},{"name":"TRAJECTORIES","type":"METRIC","description":"Trajectories refer to the sampled paths in the search space used in the evaluation of LATS on Game of 24 and HotPotQA","source_id":"594449768ae2dea9b2efbe677075096b"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"WEBSHOP\">      <data key=\"d0\">ENVIRONMENT\/PLATFORM<\/data>      <data key=\"d1\">WebShop is an online shopping environment composed of a website with 1.18M real-world products and 12k human instructions, where agents must navigate a website through various commands to purchase an item matching a user specification<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"LATS\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">LATS is a method that improves both score and success rate in WebShop, surpassing RL-based training and using a preconstructed action space of search and click commands, browser feedback, and reflections for observation<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"GPT-3.5\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-3.5 is a version of OpenAI's language model used in WebShop for acting-based prompting methods and evaluated on 50 instructions<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"REACT\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">ReAct is a prompting method used with GPT-3.5 in WebShop, sampling 30 trajectories and providing competitive performance to imitation learning and reinforcement learning techniques<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"REFLEXION\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Reflexion is a prompting method used in WebShop, similar to ReAct, but its semantic feedback is not as helpful in complex environments like WebShop<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"GAME OF 24\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">Game of 24 is a mathematical reasoning task where the agent must construct 24 out of a set of numbers and basic operations, used to test the reasoning ability of LATS<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"HOTPOTQA\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">HotPotQA is a task used to demonstrate the effect of each component of LATS, involving reasoning and question answering<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"COT\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">CoT (Chain of Thought) is a base prompting design used in the Game of 24 with LATS<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"TOT\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">ToT (Tree of Thoughts) is a prompting method used in HotPotQA and Game of 24, incorporating LM-based heuristics for pruning branches with low values<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"RAP\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">RAP is a prompting method used in HotPotQA and Game of 24, showing competitive performance in reasoning tasks<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"MCTS\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">MCTS (Monte Carlo Tree Search) is a search algorithm used in LATS, providing principled search and observed performance gains over other variants like A* and DFS<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"DFS\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">DFS (Depth-First Search) is a search algorithm variant compared with MCTS in LATS, used to observe the effects of different search strategies<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"YAO ET AL., 2022\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A reference to a study or paper by Yao et al. in 2022, related to WebShop and other methods<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"FURUTA ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A reference to a study or paper by Furuta et al. in 2024, related to fine-tuning methods<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"SHINN ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A reference to a study or paper by Shinn et al. in 2023, related to Reflexion and its performance<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"HAO ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A reference to a study or paper by Hao et al. in 2023, related to RAP and its performance<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"ZHUANG ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A reference to a study or paper by Zhuang et al. in 2023, related to search algorithms like A* and DFS<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"FINE-TUNING\">      <data key=\"d0\" \/>      <data key=\"d1\">Fine-tuning is a method mentioned in the context of improving performance in WebShop, specifically referenced in Furuta et al., 2024<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>      <data key=\"d3\">METHOD\/TECHNIQUE<\/data>    <\/node>    <node id=\"SEARCH ALGORITHMS\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"IMPROVEMENT LEARNING (IL)\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">IL (Improvement Learning) is a method used in WebShop for training agents, mentioned in comparison with other methods like RL-based training<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"REINFORCEMENT LEARNING (RL)\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">RL (Reinforcement Learning) is a method used in WebShop for training agents, mentioned in comparison with other methods like IL and LATS<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"EXPERT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Expert refers to human performance metrics used as a benchmark in WebShop<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"PROMPTING\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Prompting refers to methods used to guide the behavior of models like GPT-3.5 in WebShop, including techniques like ReAct and Reflexion<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"SEARCH AND CLICK COMMANDS\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Search and click commands are part of the preconstructed action space used in WebShop for agent navigation<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"BROWSER FEEDBACK\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Browser feedback is used in WebShop as part of the observation mechanism for agents<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"REFLECTIONS\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Reflections are used in WebShop as part of the observation mechanism for agents, providing feedback for decision-making<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"SUCCESS RATE (SR)\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Success Rate (SR) is a metric used in WebShop to indicate the frequency with which the chosen product fulfills all given conditions<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"AVERAGE SCORE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Average Score is a metric used in WebShop to reflect the percentage of user-specified attributes met by the selected product<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"SELF-REFLECTION\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Self-reflection is a technique used in LATS to provide additional semantic signals for the agent, improving performance<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"VALUE FUNCTION\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Value function is a component of LATS that incorporates self-consistency as an additional heuristic for reasoning tasks<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"MCTS (MONTE CARLO TREE SEARCH)\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">MCTS (Monte Carlo Tree Search) is a search algorithm used in LATS, providing principled search and observed performance gains over other variants like A* and DFS<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"A*\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">A* is a search algorithm variant compared with MCTS in LATS, used to observe the effects of different search strategies<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"TOKEN CONSUMPTION\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Token consumption is a metric used in the ablation study of LATS to measure the efficiency of different components<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"NODES\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Nodes refer to the sampled points in the search space used in the evaluation of LATS on Game of 24<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <node id=\"TRAJECTORIES\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Trajectories refer to the sampled paths in the search space used in the evaluation of LATS on Game of 24 and HotPotQA<\/data>      <data key=\"d2\">594449768ae2dea9b2efbe677075096b<\/data>    <\/node>    <edge source=\"WEBSHOP\" target=\"LATS\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">LATS is used in WebShop to improve score and success rate, surpassing RL-based training<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"GPT-3.5\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">GPT-3.5 is used in WebShop for acting-based prompting methods<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"REACT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">ReAct is a prompting method used in WebShop with GPT-3.5<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"REFLEXION\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Reflexion is a prompting method used in WebShop, similar to ReAct<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"YAO ET AL., 2022\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">Yao et al., 2022 is a reference related to WebShop<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"IMPROVEMENT LEARNING (IL)\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">IL is a method used in WebShop for training agents, mentioned in comparison with other methods<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"REINFORCEMENT LEARNING (RL)\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">RL is a method used in WebShop for training agents, mentioned in comparison with other methods<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"EXPERT\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">Expert refers to human performance metrics used as a benchmark in WebShop<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"FINE-TUNING\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Fine-tuning is a method mentioned in the context of improving performance in WebShop<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"PROMPTING\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Prompting methods are used to guide the behavior of models like GPT-3.5 in WebShop<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"SEARCH AND CLICK COMMANDS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Search and click commands are part of the preconstructed action space used in WebShop<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"BROWSER FEEDBACK\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Browser feedback is used in WebShop as part of the observation mechanism for agents<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"REFLECTIONS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Reflections are used in WebShop as part of the observation mechanism for agents<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"SUCCESS RATE (SR)\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Success Rate (SR) is a metric used in WebShop to indicate the frequency with which the chosen product fulfills all given conditions<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"AVERAGE SCORE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Average Score is a metric used in WebShop to reflect the percentage of user-specified attributes met by the selected product<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"GAME OF 24\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS is tested on Game of 24 to evaluate its reasoning ability<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"HOTPOTQA\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">LATS is tested on HotPotQA to demonstrate the effect of each component<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"COT\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">CoT is used as the base prompting design in LATS for the Game of 24<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"TOT\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">ToT is a prompting method compared with LATS in HotPotQA<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"RAP\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">RAP is a prompting method compared with LATS in HotPotQA and Game of 24<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"MCTS\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">MCTS is the search algorithm used in LATS<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"DFS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">DFS is a search algorithm variant compared with MCTS in LATS<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"SELF-REFLECTION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Self-reflection is a technique used in LATS to provide additional semantic signals for the agent<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"VALUE FUNCTION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Value function is a component of LATS that incorporates self-consistency as an additional heuristic<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"MCTS (MONTE CARLO TREE SEARCH)\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">MCTS is the search algorithm used in LATS<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"A*\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">A* is a search algorithm variant compared with MCTS in LATS<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"TOKEN CONSUMPTION\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Token consumption is a metric used in the ablation study of LATS<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"NODES\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Nodes refer to the sampled points in the search space used in the evaluation of LATS on Game of 24<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"TRAJECTORIES\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Trajectories refer to the sampled paths in the search space used in the evaluation of LATS on Game of 24 and HotPotQA<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"REFLEXION\" target=\"SHINN ET AL., 2023\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">Shinn et al., 2023 is a reference related to Reflexion and its performance<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"RAP\" target=\"HAO ET AL., 2023\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">Hao et al., 2023 is a reference related to RAP and its performance<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"FURUTA ET AL., 2024\" target=\"FINE-TUNING\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">Furuta et al., 2024 is a reference related to fine-tuning methods<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>    <edge source=\"ZHUANG ET AL., 2023\" target=\"SEARCH ALGORITHMS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Zhuang et al., 2023 is a reference related to search algorithms like A* and DFS<\/data>      <data key=\"d6\">594449768ae2dea9b2efbe677075096b<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"faa2bd677c7f052136479e0175da3e5b","chunk":"ing our improvements to MCTS.\nSearch algorithm. MCTS is a more principled search algo-\nrithm than variants like A* (Zhuang et al., 2023) or DFS and\nis the basis for observed performance gains. We observe\nthe effects of using DFS, and incorporate the LM-based\nheuristic used in ToT in which branches with low values are\npruned. This removes the selection and backpropagation\noperations, and we observe a 0.21drop in performance in\n8Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nMethod Performance \u2191Sample complexity \u2193Token Consumption \u2193\nReAct (Best k= 250 ) 0.42 O(k) -\nCoT-SC ( n= 1, k= 250 ) 0.40 O(k) -\nLATS ( n= 1, k= 50 ) 0.48 O(k) -\nToT (ReAct, n= 5, k= 50 ) 0.49 O(kn) 210,215\nRAP (ReAct, n= 5, k= 50 ) 0.54 O(kn) 176,500\nLATS ( n= 5, k= 50 ) 0.63 O(kn) 173,290\nTable 9. Performance, sample complexity of different methods, average number of nodes expanded, and token consumption upon success\nby methods with tree-based search. nis the number of children nodes expanded at every step and kis the number of trajectories. LATS\nhas the same sample complexity as other methods with tree-based search and expands less nodes upon success, which indicates lower\ntoken cost.\nMethod k HotPotQA \u2191# of Nodes \u2193\nToT 10 0.34 33.97\nRAP 10 0.44 31.53\nLATS 10 0.44 28.42\nToT 30 0.39 47.54\nRAP 30 0.50 37.71\nLATS 30 0.52 34.12\nToT 50 0.49 84.05\nRAP 50 0.54 70.60\nLATS 50 0.61 66.65\nTable 10. Comparison of the cost of different methods on Hot-\nPotQA. LATS achieves the highest accuracy and the lowest av-\nerage number of nodes\/states required for success at various k\ntrajectories sampled.\nTab. 8 (Row 4) when sampling the same number of nodes\nbut outperforms ToT (ReAct). Despite also benefiting from\nground-truth feedback, LATS uses it better than ToT and\nRAP and can outperform these methods. We also find in\nTab. 8 (Row 3) that LM scoring, the main component of our\nvalue function, is crucial for leveraging external feedback\nand strong performance.\nSample complexity and token consumption. One pos-\nsible concern of LATS is that the tree-structured search\nmight consume much more tokens than existing methods.\nTo further study the computational cost of LATS compared\nto prior methods, we examine the sample complexity (i.e.,\nasymptotic token cost) of all methods considered in this\npaper and count the average number of nodes expanded\nby our method and other tree-structured methods (ToT and\nRAP) upon successful search on HotPotQA. We present the\nresults in Tab. 9 and Tab. 10, which show that our method\nhas the same sample complexity as other tree-based search\nmethods and requires fewer overall tokens and states. The\ntoken cost gap will be even larger when taking failed trajec-\ntories into account, since our method has a higher success\nrate and reaches the computational budget limit less often.\nThis is also true when sampling a smaller number of trajec-\ntories; on average, LATS requires 3.55 fewer nodes thanRAP and 12.12 fewer nodes than ToT. These findings un-\nderscore our improvements to MCTS and adaptation to LM\nagents, resulting in a more principled and efficient search\nmechanism.\n6. Conclusion\nThis work introduces Language Agent Tree Search (LATS),\nthe first framework to unify reasoning, acting, and plan-\nning for enhanced LM problem-solving. LATS addresses\nkey limitations of prior prompting techniques by deliber-\nately constructing trajectories with search algorithms, in-\ncorporating external feedback, and enabling agents to learn\nfrom experience. Our evaluation demonstrates the ability\nof LATS to harness LM capabilities for various decision-\nmaking tasks while maintaining its reasoning ability without\nadditional training . The proposed synergies between search,\ninteraction, and reflection offer a versatile approach to au-\ntonomous decision-making, highlighting the potential of\nLMs as generalist agents.\nLimitations and future directions. LATS has two main\nlimitations that should be considered before its application.\nFirst, it has a higher computational cost compared to simpler\nprompting methods like ReAct or Reflexion, which may\nlimit its practicality in certain situations. Second, LATS\nassumes the ability to revert to earlier states in decision-\nmaking environments, which may not be universally ap-\nplicable in all possible environments. Despite these limi-\ntations, it is worth noting that LATS still achieves better\nperformance and efficiency compared to similar methods,\nand the number of nodes expanded at each step provides a\ntrade-off between performance and efficiency. Additionally,\nwe expect inference-time compute costs to decrease over\ntime, thereby increasing the usefulness of LATS and other\n\u201cSystem-2\u201d LM approaches. Finally, the reversion prop-\nerty is feasible in many real-world applications, opening up\n","chunk_id":"faa2bd677c7f052136479e0175da3e5b","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"MCTS","type":"ALGORITHM","description":"MCTS (Monte Carlo Tree Search) is a principled search algorithm used as the basis for observed performance gains in the study","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"A*","type":"ALGORITHM","description":"A* is a search algorithm mentioned as a variant compared to MCTS","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"DFS","type":"ALGORITHM","description":"DFS (Depth-First Search) is another search algorithm mentioned as a variant compared to MCTS","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"LM-BASED HEURISTIC","type":"TECHNIQUE","description":"A heuristic used in ToT that prunes branches with low values, removing selection and backpropagation operations","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"TOT","type":"METHOD","description":"ToT (Tree of Thoughts) is a method that uses the LM-based heuristic and is compared with other methods in the study","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"REACT","type":"METHOD","description":"ReAct is a method evaluated in the study, with different configurations for performance and token consumption","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"COT-SC","type":"METHOD","description":"CoT-SC is another method evaluated in the study, with different configurations for performance and token consumption","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"LATS","type":"METHOD","description":"LATS (Language Agent Tree Search) is a framework introduced to unify reasoning, acting, and planning in language models","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"RAP","type":"METHOD","description":"RAP is a method evaluated in the study, with different configurations for performance and token consumption","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"HOTPOTQA","type":"DATASET","description":"HotPotQA is a dataset used to compare the cost and performance of different methods","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"LANGUAGE AGENT TREE SEARCH","type":"FRAMEWORK","description":"Language Agent Tree Search (LATS) is a framework that unifies reasoning, acting, and planning for enhanced LM problem-solving","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"LM AGENTS","type":"AGENT","description":"LM agents are language model agents that benefit from the improvements in MCTS and LATS","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"SEARCH ALGORITHMS","type":"TECHNIQUE","description":"Search algorithms are techniques used to construct trajectories and incorporate external feedback in LATS","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"EXTERNAL FEEDBACK","type":"TECHNIQUE","description":"External feedback is used in LATS to improve performance and efficiency","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"TRAJECTORIES","type":"CONCEPT","description":"Trajectories are paths constructed by search algorithms in LATS to enhance decision-making","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"REVERSION PROPERTY","type":"CONCEPT","description":"The reversion property allows reverting to earlier states in decision-making environments, which is assumed by LATS","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"SYSTEM-2 LM APPROACHES","type":"CONCEPT","description":"System-2 LM approaches refer to advanced language model techniques that involve reasoning and planning, like LATS","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"PERFORMANCE","type":"METRIC","description":"Performance is a metric used to evaluate the effectiveness of different methods in the study","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"SAMPLE COMPLEXITY","type":"METRIC","description":"Sample complexity is a metric used to measure the asymptotic token cost of different methods","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"TOKEN CONSUMPTION","type":"METRIC","description":"Token consumption is a metric used to measure the number of tokens used by different methods","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"NODES EXPANDED","type":"METRIC","description":"Nodes expanded is a metric used to measure the number of nodes expanded by different methods upon success","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"COMPUTATIONAL COST","type":"METRIC","description":"Computational cost is a metric used to measure the computational resources required by different methods","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"INFERENCE-TIME COMPUTE COSTS","type":"METRIC","description":"Inference-time compute costs refer to the computational costs incurred during the inference phase of language models","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"REFLEXION","type":"METHOD","description":"Reflexion is a simpler prompting method compared to LATS, mentioned in the limitations","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"ZHUANG ET AL., 2023","type":"REFERENCE","description":"Zhuang et al., 2023 is a reference cited in the context of search algorithms like A* and DFS","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"TAB. 8","type":"REFERENCE","description":"Tab. 8 is a reference to a table in the document that shows performance comparisons","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"TAB. 9","type":"REFERENCE","description":"Tab. 9 is a reference to a table in the document that shows sample complexity and token consumption comparisons","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"TAB. 10","type":"REFERENCE","description":"Tab. 10 is a reference to a table in the document that shows the cost of different methods on HotPotQA","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"CONCLUSION","type":"SECTION","description":"The conclusion section summarizes the contributions and findings of the study","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"LIMITATIONS AND FUTURE DIRECTIONS","type":"SECTION","description":"The limitations and future directions section discusses the constraints and potential future work for LATS","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"LANGUAGE MODELS","type":"AGENT","description":"Language models (LMs) are AI models capable of understanding and generating human language, used in various decision-making tasks","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"REASONING","type":"CONCEPT","description":"Reasoning is the process of thinking about something in a logical way to form a conclusion or judgment, a key component in LATS","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"ACTING","type":"CONCEPT","description":"Acting refers to the execution of actions based on decisions made by language models, a key component in LATS","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"PLANNING","type":"CONCEPT","description":"Planning involves creating a sequence of actions to achieve a specific goal, a key component in LATS","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"DECISION-MAKING","type":"CONCEPT","description":"Decision-making is the cognitive process of selecting a course of action from multiple alternatives, enhanced by LATS","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"PROMPTING TECHNIQUES","type":"TECHNIQUE","description":"Prompting techniques are methods used to guide language models in generating responses, such as ReAct and Reflexion","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"TRAJECTORY CONSTRUCTION","type":"TECHNIQUE","description":"Trajectory construction is the process of creating paths or sequences of actions in LATS to improve decision-making","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"INTERACTION","type":"CONCEPT","description":"Interaction refers to the communication between language models and their environment or users, a component in LATS","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"REFLECTION","type":"CONCEPT","description":"Reflection involves thinking about past actions and decisions to improve future performance, a component in LATS","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"AUTONOMOUS DECISION-MAKING","type":"CONCEPT","description":"Autonomous decision-making is the ability of language models to make decisions without human intervention, enabled by LATS","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"COMPUTATIONAL BUDGET","type":"CONCEPT","description":"Computational budget refers to the limit on computational resources available for a task, relevant to the efficiency of LATS","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"GROUND-TRUTH FEEDBACK","type":"TECHNIQUE","description":"Ground-truth feedback is accurate information used to guide and improve the performance of language models","source_id":"faa2bd677c7f052136479e0175da3e5b"},{"name":"SYSTEM-1 LM APPROACHES","type":"CONCEPT","description":"System-1 LM approaches refer to simpler, more intuitive language model techniques that do not involve complex reasoning or planning","source_id":"faa2bd677c7f052136479e0175da3e5b"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"MCTS\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">MCTS (Monte Carlo Tree Search) is a principled search algorithm used as the basis for observed performance gains in the study<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"A*\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">A* is a search algorithm mentioned as a variant compared to MCTS<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"DFS\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">DFS (Depth-First Search) is another search algorithm mentioned as a variant compared to MCTS<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"LM-BASED HEURISTIC\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">A heuristic used in ToT that prunes branches with low values, removing selection and backpropagation operations<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"TOT\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">ToT (Tree of Thoughts) is a method that uses the LM-based heuristic and is compared with other methods in the study<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"REACT\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">ReAct is a method evaluated in the study, with different configurations for performance and token consumption<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"COT-SC\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">CoT-SC is another method evaluated in the study, with different configurations for performance and token consumption<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"LATS\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">LATS (Language Agent Tree Search) is a framework introduced to unify reasoning, acting, and planning in language models<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"RAP\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">RAP is a method evaluated in the study, with different configurations for performance and token consumption<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"HOTPOTQA\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">HotPotQA is a dataset used to compare the cost and performance of different methods<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"LANGUAGE AGENT TREE SEARCH\">      <data key=\"d0\">FRAMEWORK<\/data>      <data key=\"d1\">Language Agent Tree Search (LATS) is a framework that unifies reasoning, acting, and planning for enhanced LM problem-solving<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"LM AGENTS\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">LM agents are language model agents that benefit from the improvements in MCTS and LATS<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"SEARCH ALGORITHMS\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Search algorithms are techniques used to construct trajectories and incorporate external feedback in LATS<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"EXTERNAL FEEDBACK\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">External feedback is used in LATS to improve performance and efficiency<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"TRAJECTORIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Trajectories are paths constructed by search algorithms in LATS to enhance decision-making<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"REVERSION PROPERTY\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">The reversion property allows reverting to earlier states in decision-making environments, which is assumed by LATS<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"SYSTEM-2 LM APPROACHES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">System-2 LM approaches refer to advanced language model techniques that involve reasoning and planning, like LATS<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"PERFORMANCE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Performance is a metric used to evaluate the effectiveness of different methods in the study<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"SAMPLE COMPLEXITY\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Sample complexity is a metric used to measure the asymptotic token cost of different methods<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"TOKEN CONSUMPTION\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Token consumption is a metric used to measure the number of tokens used by different methods<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"NODES EXPANDED\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Nodes expanded is a metric used to measure the number of nodes expanded by different methods upon success<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"COMPUTATIONAL COST\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Computational cost is a metric used to measure the computational resources required by different methods<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"INFERENCE-TIME COMPUTE COSTS\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Inference-time compute costs refer to the computational costs incurred during the inference phase of language models<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"REFLEXION\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Reflexion is a simpler prompting method compared to LATS, mentioned in the limitations<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"ZHUANG ET AL., 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Zhuang et al., 2023 is a reference cited in the context of search algorithms like A* and DFS<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"TAB. 8\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Tab. 8 is a reference to a table in the document that shows performance comparisons<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"TAB. 9\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Tab. 9 is a reference to a table in the document that shows sample complexity and token consumption comparisons<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"TAB. 10\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">Tab. 10 is a reference to a table in the document that shows the cost of different methods on HotPotQA<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"CONCLUSION\">      <data key=\"d0\">SECTION<\/data>      <data key=\"d1\">The conclusion section summarizes the contributions and findings of the study<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"LIMITATIONS AND FUTURE DIRECTIONS\">      <data key=\"d0\">SECTION<\/data>      <data key=\"d1\">The limitations and future directions section discusses the constraints and potential future work for LATS<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"LANGUAGE MODELS\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Language models (LMs) are AI models capable of understanding and generating human language, used in various decision-making tasks<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"REASONING\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Reasoning is the process of thinking about something in a logical way to form a conclusion or judgment, a key component in LATS<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"ACTING\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Acting refers to the execution of actions based on decisions made by language models, a key component in LATS<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"PLANNING\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Planning involves creating a sequence of actions to achieve a specific goal, a key component in LATS<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"DECISION-MAKING\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Decision-making is the cognitive process of selecting a course of action from multiple alternatives, enhanced by LATS<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"PROMPTING TECHNIQUES\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Prompting techniques are methods used to guide language models in generating responses, such as ReAct and Reflexion<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"TRAJECTORY CONSTRUCTION\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Trajectory construction is the process of creating paths or sequences of actions in LATS to improve decision-making<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"INTERACTION\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Interaction refers to the communication between language models and their environment or users, a component in LATS<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"REFLECTION\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Reflection involves thinking about past actions and decisions to improve future performance, a component in LATS<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"AUTONOMOUS DECISION-MAKING\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Autonomous decision-making is the ability of language models to make decisions without human intervention, enabled by LATS<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"COMPUTATIONAL BUDGET\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Computational budget refers to the limit on computational resources available for a task, relevant to the efficiency of LATS<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"GROUND-TRUTH FEEDBACK\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Ground-truth feedback is accurate information used to guide and improve the performance of language models<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <node id=\"SYSTEM-1 LM APPROACHES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">System-1 LM approaches refer to simpler, more intuitive language model techniques that do not involve complex reasoning or planning<\/data>      <data key=\"d2\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/node>    <edge source=\"MCTS\" target=\"LM-BASED HEURISTIC\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">MCTS incorporates the LM-based heuristic used in ToT to improve performance<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"MCTS\" target=\"LATS\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">LATS incorporates improvements to MCTS for better performance and efficiency<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"A*\" target=\"ZHUANG ET AL., 2023\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Zhuang et al., 2023 is a reference that mentions A*<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"DFS\" target=\"ZHUANG ET AL., 2023\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Zhuang et al., 2023 is a reference that mentions DFS<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LM-BASED HEURISTIC\" target=\"TOT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">ToT uses the LM-based heuristic to prune branches with low values<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"TOT\" target=\"LATS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS outperforms ToT in terms of performance and efficiency<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"REACT\" target=\"PERFORMANCE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">ReAct is evaluated for performance in the study<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"REACT\" target=\"TOKEN CONSUMPTION\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">ReAct is evaluated for token consumption in the study<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"COT-SC\" target=\"PERFORMANCE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">CoT-SC is evaluated for performance in the study<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"COT-SC\" target=\"TOKEN CONSUMPTION\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">CoT-SC is evaluated for token consumption in the study<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"RAP\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS outperforms RAP in terms of performance and efficiency<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"SEARCH ALGORITHMS\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">LATS uses search algorithms to construct trajectories and incorporate external feedback<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"EXTERNAL FEEDBACK\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS incorporates external feedback to improve performance<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"TRAJECTORIES\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">LATS constructs trajectories using search algorithms for enhanced decision-making<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"REVERSION PROPERTY\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">LATS assumes the ability to revert to earlier states in decision-making environments<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"SYSTEM-2 LM APPROACHES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS is an example of a System-2 LM approach that involves reasoning and planning<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"PERFORMANCE\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">LATS achieves better performance compared to other methods<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"SAMPLE COMPLEXITY\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS has the same sample complexity as other tree-based search methods<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"TOKEN CONSUMPTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS requires fewer tokens compared to other methods<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"NODES EXPANDED\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS expands fewer nodes compared to other methods<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"COMPUTATIONAL COST\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">LATS has a higher computational cost compared to simpler prompting methods<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"INFERENCE-TIME COMPUTE COSTS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">LATS is expected to have reduced inference-time compute costs over time<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"HOTPOTQA\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS is evaluated on the HotPotQA dataset for performance and cost<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"CONCLUSION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The conclusion section summarizes the contributions and findings related to LATS<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LATS\" target=\"LIMITATIONS AND FUTURE DIRECTIONS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The limitations and future directions section discusses the constraints and potential future work for LATS<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"RAP\" target=\"PERFORMANCE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">RAP is evaluated for performance in the study<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"RAP\" target=\"TOKEN CONSUMPTION\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">RAP is evaluated for token consumption in the study<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"TAB. 10\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Tab. 10 shows the cost of different methods on HotPotQA<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LANGUAGE AGENT TREE SEARCH\" target=\"REASONING\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">LATS unifies reasoning, acting, and planning for enhanced LM problem-solving<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LANGUAGE AGENT TREE SEARCH\" target=\"ACTING\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">LATS unifies reasoning, acting, and planning for enhanced LM problem-solving<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LANGUAGE AGENT TREE SEARCH\" target=\"PLANNING\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">LATS unifies reasoning, acting, and planning for enhanced LM problem-solving<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LANGUAGE AGENT TREE SEARCH\" target=\"DECISION-MAKING\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">LATS enhances decision-making capabilities of language models<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LANGUAGE AGENT TREE SEARCH\" target=\"PROMPTING TECHNIQUES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS addresses key limitations of prior prompting techniques<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LANGUAGE AGENT TREE SEARCH\" target=\"TRAJECTORY CONSTRUCTION\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">LATS constructs trajectories with search algorithms to improve decision-making<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LANGUAGE AGENT TREE SEARCH\" target=\"INTERACTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS incorporates interaction to enhance decision-making<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LANGUAGE AGENT TREE SEARCH\" target=\"REFLECTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS incorporates reflection to enhance decision-making<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LANGUAGE AGENT TREE SEARCH\" target=\"AUTONOMOUS DECISION-MAKING\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">LATS enables autonomous decision-making in language models<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LANGUAGE AGENT TREE SEARCH\" target=\"COMPUTATIONAL BUDGET\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS manages computational budget efficiently compared to other methods<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LANGUAGE AGENT TREE SEARCH\" target=\"GROUND-TRUTH FEEDBACK\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS uses ground-truth feedback to improve performance<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LANGUAGE AGENT TREE SEARCH\" target=\"SYSTEM-2 LM APPROACHES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS is an example of a System-2 LM approach<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LANGUAGE AGENT TREE SEARCH\" target=\"SYSTEM-1 LM APPROACHES\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">LATS has a higher computational cost compared to System-1 LM approaches<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"SEARCH ALGORITHMS\" target=\"TRAJECTORY CONSTRUCTION\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Trajectory construction in LATS is done using search algorithms<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"SYSTEM-2 LM APPROACHES\" target=\"PROMPTING TECHNIQUES\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Advanced prompting techniques like LATS are examples of System-2 LM approaches<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"SYSTEM-2 LM APPROACHES\" target=\"COMPUTATIONAL COST\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">System-2 LM approaches have higher computational cost compared to System-1 approaches<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"PERFORMANCE\" target=\"TAB. 8\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Tab. 8 shows performance comparisons of different methods<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"PERFORMANCE\" target=\"GROUND-TRUTH FEEDBACK\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Ground-truth feedback improves the performance of language models<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"SAMPLE COMPLEXITY\" target=\"TAB. 9\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Tab. 9 shows sample complexity comparisons of different methods<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"TOKEN CONSUMPTION\" target=\"TAB. 9\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Tab. 9 shows token consumption comparisons of different methods<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"COMPUTATIONAL COST\" target=\"COMPUTATIONAL BUDGET\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Managing computational budget is crucial for controlling computational cost<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"COMPUTATIONAL COST\" target=\"SYSTEM-1 LM APPROACHES\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">System-1 LM approaches have lower computational cost compared to System-2 approaches<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LANGUAGE MODELS\" target=\"REASONING\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Language models use reasoning to solve problems<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LANGUAGE MODELS\" target=\"ACTING\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Language models execute actions based on decisions<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LANGUAGE MODELS\" target=\"PLANNING\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Language models create plans to achieve goals<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LANGUAGE MODELS\" target=\"DECISION-MAKING\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Language models are used for decision-making tasks<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"LANGUAGE MODELS\" target=\"AUTONOMOUS DECISION-MAKING\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Language models can make autonomous decisions<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"REASONING\" target=\"DECISION-MAKING\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Reasoning is a key component of decision-making<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"ACTING\" target=\"DECISION-MAKING\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Acting is a key component of decision-making<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"PLANNING\" target=\"DECISION-MAKING\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Planning is a key component of decision-making<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"DECISION-MAKING\" target=\"INTERACTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Interaction enhances decision-making in LATS<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"DECISION-MAKING\" target=\"REFLECTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Reflection enhances decision-making in LATS<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>    <edge source=\"PROMPTING TECHNIQUES\" target=\"SYSTEM-1 LM APPROACHES\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Simpler prompting techniques like ReAct and Reflexion are examples of System-1 LM approaches<\/data>      <data key=\"d5\">faa2bd677c7f052136479e0175da3e5b<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"4ae237a491bc8a84cc720e40c59a7464","chunk":" possible environments. Despite these limi-\ntations, it is worth noting that LATS still achieves better\nperformance and efficiency compared to similar methods,\nand the number of nodes expanded at each step provides a\ntrade-off between performance and efficiency. Additionally,\nwe expect inference-time compute costs to decrease over\ntime, thereby increasing the usefulness of LATS and other\n\u201cSystem-2\u201d LM approaches. Finally, the reversion prop-\nerty is feasible in many real-world applications, opening up\nnew opportunities in the LM decision-making community.\nFuture directions include scaling LATS to more complex\nenvironments or multi-agent frameworks and improving ef-\nficiency to reduce costs. A more detailed discussion about\nthe limitations of LATS can be found in Appendix Sec. B.\n9Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nImpact Statement\nLATS is a framework that enhances LM performance\nthrough interactions with an environment. This improve-\nment in autonomous decision-making may facilitate harm-\nful uses of LMs. On the other hand, LATS enhances in-\nterpretability and the potential for greater alignment, as it\ninvolves high-level linguistic reasoning and actions through\nseveral rounds of decision-making and reflection rather than\nrelying on autoregressive generation. Finally, enhancing the\ncapabilities of LM agents may raise security risks, such as\nexecuting malware. We encourage further research to fully\nunderstand and mitigate the risks of LMs.\nAcknowledgements\nWe thank Daniel Campos for useful feedback on earlier ver-\nsions of this paper. This work was supported in part by NSF\nGrant 2106825, NIFA Award 2020-67021-32799, the Jump\nARCHES endowment through the Health Care Engineering\nSystems Center at Illinois and the OSF Foundation, and the\nIBM-Illinois Discovery Accelerator Institute. This work\nused NVIDIA GPUs at NCSA Delta through allocations\nCIS220014, CIS230012, and CIS230218 from the ACCESS\nprogram.\nReferences\nMichael Ahn, Anthony Brohan, Noah Brown, Yevgen Cheb-\notar, Omar Cortes, Byron David, Chelsea Finn, Chuyuan\nFu, Keerthana Gopalakrishnan, Karol Hausman, Alex\nHerzog, Daniel Ho, Jasmine Hsu, Julian Ibarz, Brian\nIchter, Alex Irpan, Eric Jang, Rosario Jauregui Ruano,\nKyle Jeffrey, Sally Jesmonth, Nikhil J Joshi, Ryan Julian,\nDmitry Kalashnikov, Yuheng Kuang, Kuang-Huei Lee,\nSergey Levine, Yao Lu, Linda Luu, Carolina Parada, Peter\nPastor, Jornell Quiambao, Kanishka Rao, Jarek Retting-\nhouse, Diego Reyes, Pierre Sermanet, Nicolas Sievers,\nClayton Tan, Alexander Toshev, Vincent Vanhoucke, Fei\nXia, Ted Xiao, Peng Xu, Sichun Xu, Mengyuan Yan, and\nAndy Zeng. Do as I can, not as I say: Grounding language\nin robotic affordances. In CoRL , 2022.\nJacob Austin, Augustus Odena, Maxwell Nye, Maarten\nBosma, Henryk Michalewski, David Dohan, Ellen Jiang,\nCarrie Cai, Michael Terry, Quoc Le, and Charles Sut-\nton. Program synthesis with large language models. In\nNeurIPS , 2022.\nBowen Baker, Ilge Akkaya, Peter Zhokhov, Joost Huizinga,\nJie Tang, Adrien Ecoffet, Brandon Houghton, Raul\nSampedro, and Jeff Clune. Video pretraining (VPT):\nLearning to act by watching unlabeled online videos. In\nNeurIPS , 2022.\nMaciej Besta, Nils Blach, Ales Kubicek, Robert Ger-stenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz\nLehmann, Michal Podstawski, Hubert Niewiadomski, Pi-\notr Nyczyk, and Torsten Hoefler. Graph of thoughts:\nSolving elaborate problems with large language models.\narXiv:2308.09687 , 2023.\nSamuel R Bowman, Gabor Angeli, Christopher Potts, and\nChristopher D Manning. A large annotated corpus for\nlearning natural language inference. In EMNLP , 2015.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Nee-\nlakantan, Pranav Shyam, Girish Sastry, Amanda Askell,\nSandhini Agarwal, Ariel Herbert-V oss, Gretchen Krueger,\nTom Henighan, Rewon Child, Aditya Ramesh, Daniel M.\nZiegler, Jeffrey Wu, Clemens Winter, Christopher Hesse,\nMark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,\nBenjamin Chess, Jack Clark, Christopher Berner, Sam\nMcCandlish, Alec Radford, Ilya Sutskever, and Dario\nAmodei. Language models are few-shot learners. In\nNeurIPS , 2020.\nMurray Campbell, A Joseph Hoane Jr, and Feng-hsiung\nHsu. Deep blue. Artificial intelligence , 2002.\nBei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi\nLin, Jian-Guang Lou, and Weizhu Chen. CodeT: Code\ngeneration with generated tests. In ICLR , 202","chunk_id":"4ae237a491bc8a84cc720e40c59a7464","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"LATS","type":"FRAMEWORK","description":"LATS is a framework that enhances language model (LM) performance through interactions with an environment, improving autonomous decision-making and interpretability.","source_id":"4ae237a491bc8a84cc720e40c59a7464"},{"name":"SYSTEM-2 LM APPROACHES","type":"APPROACH","description":"System-2 LM approaches involve high-level linguistic reasoning and actions through several rounds of decision-making and reflection, rather than relying on autoregressive generation.","source_id":"4ae237a491bc8a84cc720e40c59a7464"},{"name":"DANIEL CAMPOS","type":"PERSON","description":"Daniel Campos provided useful feedback on earlier versions of the paper.","source_id":"4ae237a491bc8a84cc720e40c59a7464"},{"name":"NSF GRANT 2106825","type":"FUNDING","description":"A grant from the National Science Foundation that supported the work.","source_id":"4ae237a491bc8a84cc720e40c59a7464"},{"name":"NIFA AWARD 2020-67021-32799","type":"FUNDING","description":"An award from the National Institute of Food and Agriculture that supported the work.","source_id":"4ae237a491bc8a84cc720e40c59a7464"},{"name":"JUMP ARCHES ENDOWMENT","type":"FUNDING","description":"An endowment through the Health Care Engineering Systems Center at Illinois and the OSF Foundation that supported the work.","source_id":"4ae237a491bc8a84cc720e40c59a7464"},{"name":"IBM-ILLINOIS DISCOVERY ACCELERATOR INSTITUTE","type":"ORGANIZATION","description":"An institute that supported the work.","source_id":"4ae237a491bc8a84cc720e40c59a7464"},{"name":"NVIDIA GPUS","type":"HARDWARE","description":"NVIDIA GPUs were used at NCSA Delta through allocations from the ACCESS program.","source_id":"4ae237a491bc8a84cc720e40c59a7464"},{"name":"NCSA DELTA","type":"FACILITY","description":"A facility where NVIDIA GPUs were used for the work.","source_id":"4ae237a491bc8a84cc720e40c59a7464"},{"name":"ACCESS PROGRAM","type":"PROGRAM","description":"A program that provided allocations for using NVIDIA GPUs at NCSA Delta.","source_id":"4ae237a491bc8a84cc720e40c59a7464"},{"name":"MICHAEL AHN","type":"PERSON","description":"Michael Ahn is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464"},{"name":"ANTHONY BROHAN","type":"PERSON","description":"Anthony Brohan is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"NOAH BROWN","type":"PERSON","description":"Noah Brown is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"YEVGEN CHEBOTAR","type":"PERSON","description":"Yevgen Chebotar is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"OMAR CORTES","type":"PERSON","description":"Omar Cortes is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"BYRON DAVID","type":"PERSON","description":"Byron David is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"CHELSEA FINN","type":"PERSON","description":"Chelsea Finn is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"CHUYUAN FU","type":"PERSON","description":"Chuyuan Fu is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"KEERTHANA GOPALAKRISHNAN","type":"PERSON","description":"Keerthana Gopalakrishnan is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"KAROL HAUSMAN","type":"PERSON","description":"Karol Hausman is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"ALEX HERZOG","type":"PERSON","description":"Alex Herzog is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"DANIEL HO","type":"PERSON","description":"Daniel Ho is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"JASMINE HSU","type":"PERSON","description":"Jasmine Hsu is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"JULIAN IBARZ","type":"PERSON","description":"Julian Ibarz is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"BRIAN ICHTER","type":"PERSON","description":"Brian Ichter is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"ALEX IRPAN","type":"PERSON","description":"Alex Irpan is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"ROSARIO JAUREGUI RUANO","type":"PERSON","description":"Rosario Jauregui Ruano is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"KYLE JEFFREY","type":"PERSON","description":"Kyle Jeffrey is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"SALLY JESMONTH","type":"PERSON","description":"Sally Jesmonth is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"NIKHIL J JOSHI","type":"PERSON","description":"Nikhil J Joshi is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"RYAN JULIAN","type":"PERSON","description":"Ryan Julian is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"DMITRY KALASHNIKOV","type":"PERSON","description":"Dmitry Kalashnikov is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"YUHENG KUANG","type":"PERSON","description":"Yuheng Kuang is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"KUANG-HUEI LEE","type":"PERSON","description":"Kuang-Huei Lee is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"SERGEY LEVINE","type":"PERSON","description":"Sergey Levine is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"YAO LU","type":"PERSON","description":"Yao Lu is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"LINDA LUU","type":"PERSON","description":"Linda Luu is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"CAROLINA PARADA","type":"PERSON","description":"Carolina Parada is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"PETER PASTOR","type":"PERSON","description":"Peter Pastor is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"JORNELL QUIAMBAO","type":"PERSON","description":"Jornell Quiambao is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"KANISHKA RAO","type":"PERSON","description":"Kanishka Rao is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"JAREK RETTINGHOUSE","type":"PERSON","description":"Jarek Rettinghouse is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"DIEGO REYES","type":"PERSON","description":"Diego Reyes is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"PIERRE SERMANET","type":"PERSON","description":"Pierre Sermanet is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"NICOLAS SIEVERS","type":"PERSON","description":"Nicolas Sievers is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"CLAYTON TAN","type":"PERSON","description":"Clayton Tan is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"ALEXANDER TOSHEV","type":"PERSON","description":"Alexander Toshev is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"VINCENT VANHOUCKE","type":"PERSON","description":"Vincent Vanhoucke is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"FEI XIA","type":"PERSON","description":"Fei Xia is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"TED XIAO","type":"PERSON","description":"Ted Xiao is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"PENG XU","type":"PERSON","description":"Peng Xu is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"SICHUN XU","type":"PERSON","description":"Sichun Xu is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"MENGYUAN YAN","type":"PERSON","description":"Mengyuan Yan is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"ANDY ZENG","type":"PERSON","description":"Andy Zeng is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"JACOB AUSTIN","type":"PERSON","description":"Jacob Austin is an author of the paper \"Program synthesis with large language models.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"AUGUSTUS ODENA","type":"PERSON","description":"Augustus Odena is an author of the paper \"Program synthesis with large language models.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"MAXWELL NYE","type":"PERSON","description":"Maxwell Nye is an author of the paper \"Program synthesis with large language models.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"MAARTEN BOSMA","type":"PERSON","description":"Maarten Bosma is an author of the paper \"Program synthesis with large language models.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"HENRYK MICHALEWSKI","type":"PERSON","description":"Henryk Michalewski is an author of the paper \"Program synthesis with large language models.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"DAVID DOHAN","type":"PERSON","description":"David Dohan is an author of the paper \"Program synthesis with large language models.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"ELLEN JIANG","type":"PERSON","description":"Ellen Jiang is an author of the paper \"Program synthesis with large language models.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"CARRIE CAI","type":"PERSON","description":"Carrie Cai is an author of the paper \"Program synthesis with large language models.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"MICHAEL TERRY","type":"PERSON","description":"Michael Terry is an author of the paper \"Program synthesis with large language models.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"QUOC LE","type":"PERSON","description":"Quoc Le is an author of the paper \"Program synthesis with large language models.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"CHARLES SUTTON","type":"PERSON","description":"Charles Sutton is an author of the paper \"Program synthesis with large language models.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"BOWEN BAKER","type":"PERSON","description":"Bowen Baker is an author of the paper \"Video pretraining (VPT): Learning to act by watching unlabeled online videos.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"ILGE AKKAYA","type":"PERSON","description":"Ilge Akkaya is an author of the paper \"Video pretraining (VPT): Learning to act by watching unlabeled online videos.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"PETER ZHOKHOV","type":"PERSON","description":"Peter Zhokhov is an author of the paper \"Video pretraining (VPT): Learning to act by watching unlabeled online videos.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"JOOST HUIZINGA","type":"PERSON","description":"Joost Huizinga is an author of the paper \"Video pretraining (VPT): Learning to act by watching unlabeled online videos.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"JIE TANG","type":"PERSON","description":"Jie Tang is an author of the paper \"Video pretraining (VPT): Learning to act by watching unlabeled online videos.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"ADRIEN ECOFFET","type":"PERSON","description":"Adrien Ecoffet is an author of the paper \"Video pretraining (VPT): Learning to act by watching unlabeled online videos.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"BRANDON HOUGHTON","type":"PERSON","description":"Brandon Houghton is an author of the paper \"Video pretraining (VPT): Learning to act by watching unlabeled online videos.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"RAUL SAMPEDRO","type":"PERSON","description":"Raul Sampedro is an author of the paper \"Video pretraining (VPT): Learning to act by watching unlabeled online videos.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"JEFF CLUNE","type":"PERSON","description":"Jeff Clune is an author of the paper \"Video pretraining (VPT): Learning to act by watching unlabeled online videos.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"MACIEJ BESTA","type":"PERSON","description":"Maciej Besta is an author of the paper \"Graph of thoughts: Solving elaborate problems with large language models.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"NILS BLACH","type":"PERSON","description":"Nils Blach is an author of the paper \"Graph of thoughts: Solving elaborate problems with large language models.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"ALES KUBICEK","type":"PERSON","description":"Ales Kubicek is an author of the paper \"Graph of thoughts: Solving elaborate problems with large language models.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"ROBERT GERSTENBERGER","type":"PERSON","description":"Robert Gerstenberger is an author of the paper \"Graph of thoughts: Solving elaborate problems with large language models.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"LUKAS GIANINAZZI","type":"PERSON","description":"Lukas Gianinazzi is an author of the paper \"Graph of thoughts: Solving elaborate problems with large language models.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"JOANNA GAJDA","type":"PERSON","description":"Joanna Gajda is an author of the paper \"Graph of thoughts: Solving elaborate problems with large language models.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"TOMASZ LEHMANN","type":"PERSON","description":"Tomasz Lehmann is an author of the paper \"Graph of thoughts: Solving elaborate problems with large language models.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"MICHAL PODSTAWSKI","type":"PERSON","description":"Michal Podstawski is an author of the paper \"Graph of thoughts: Solving elaborate problems with large language models.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"HUBERT NIEWIADOMSKI","type":"PERSON","description":"Hubert Niewiadomski is an author of the paper \"Graph of thoughts: Solving elaborate problems with large language models.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"PIOTR NYCZYK","type":"PERSON","description":"Piotr Nyczyk is an author of the paper \"Graph of thoughts: Solving elaborate problems with large language models.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"TORSTEN HOEFLER","type":"PERSON","description":"Torsten Hoefler is an author of the paper \"Graph of thoughts: Solving elaborate problems with large language models.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"SAMUEL R BOWMAN","type":"PERSON","description":"Samuel R Bowman is an author of the paper \"A large annotated corpus for learning natural language inference.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"GABOR ANGELI","type":"PERSON","description":"Gabor Angeli is an author of the paper \"A large annotated corpus for learning natural language inference.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"CHRISTOPHER POTTS","type":"PERSON","description":"Christopher Potts is an author of the paper \"A large annotated corpus for learning natural language inference.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"CHRISTOPHER D MANNING","type":"PERSON","description":"Christopher D Manning is an author of the paper \"A large annotated corpus for learning natural language inference.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"TOM B. BROWN","type":"PERSON","description":"Tom B. Brown is an author of the paper \"Language models are few-shot learners.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"BENJAMIN MANN","type":"PERSON","description":"Benjamin Mann is an author of the paper \"Language models are few-shot learners.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464","entity_type":"PERSON"},{"name":"NICK RYDER","type":"PERSON","description":"Nick Ryder is an author of the paper \"Language models are few-shot learners.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464"},{"name":"MELANIE SUBBIAH","type":"PERSON","description":"Melanie Subbiah is an author of the paper \"Language models are few-shot learners.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464"},{"name":"JARED KAPLAN","type":"PERSON","description":"Jared Kaplan is an author of the paper \"Language models are few-shot learners.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464"},{"name":"PRAFULLA DHARIWAL","type":"PERSON","description":"Prafulla Dhariwal is an author of the paper \"Language models are few-shot learners.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464"},{"name":"ARVIND NEELAKANTAN","type":"PERSON","description":"Arvind Neelakantan is an author of the paper \"Language models are few-shot learners.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464"},{"name":"PRANAV SHYAM","type":"PERSON","description":"Pranav Shyam is an author of the paper \"Language models are few-shot learners.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464"},{"name":"GIRISH SASTRY","type":"PERSON","description":"Girish Sastry is an author of the paper \"Language models are few-shot learners.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464"},{"name":"AMANDA ASKELL","type":"PERSON","description":"Amanda Askell is an author of the paper \"Language models are few-shot learners.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464"},{"name":"SANDHINI AGARWAL","type":"PERSON","description":"Sandhini Agarwal is an author of the paper \"Language models are few-shot learners.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464"},{"name":"ARIEL HERBERT-VOSS","type":"PERSON","description":"Ariel Herbert-Voss is an author of the paper \"Language models are few-shot learners.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464"},{"name":"GRETCHEN KRUEGER","type":"PERSON","description":"Gretchen Krueger is an author of the paper \"Language models are few-shot learners.\"","source_id":"4ae237a491bc8a84cc720e40c59a7464"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"LATS\">      <data key=\"d0\">FRAMEWORK<\/data>      <data key=\"d1\">LATS is a framework that enhances language model (LM) performance through interactions with an environment, improving autonomous decision-making and interpretability.<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>    <\/node>    <node id=\"SYSTEM-2 LM APPROACHES\">      <data key=\"d0\">APPROACH<\/data>      <data key=\"d1\">System-2 LM approaches involve high-level linguistic reasoning and actions through several rounds of decision-making and reflection, rather than relying on autoregressive generation.<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>    <\/node>    <node id=\"DANIEL CAMPOS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Daniel Campos provided useful feedback on earlier versions of the paper.<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>    <\/node>    <node id=\"NSF GRANT 2106825\">      <data key=\"d0\">FUNDING<\/data>      <data key=\"d1\">A grant from the National Science Foundation that supported the work.<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>    <\/node>    <node id=\"NIFA AWARD 2020-67021-32799\">      <data key=\"d0\">FUNDING<\/data>      <data key=\"d1\">An award from the National Institute of Food and Agriculture that supported the work.<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>    <\/node>    <node id=\"JUMP ARCHES ENDOWMENT\">      <data key=\"d0\">FUNDING<\/data>      <data key=\"d1\">An endowment through the Health Care Engineering Systems Center at Illinois and the OSF Foundation that supported the work.<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>    <\/node>    <node id=\"IBM-ILLINOIS DISCOVERY ACCELERATOR INSTITUTE\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">An institute that supported the work.<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>    <\/node>    <node id=\"NVIDIA GPUS\">      <data key=\"d0\">HARDWARE<\/data>      <data key=\"d1\">NVIDIA GPUs were used at NCSA Delta through allocations from the ACCESS program.<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>    <\/node>    <node id=\"NCSA DELTA\">      <data key=\"d0\">FACILITY<\/data>      <data key=\"d1\">A facility where NVIDIA GPUs were used for the work.<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>    <\/node>    <node id=\"ACCESS PROGRAM\">      <data key=\"d0\">PROGRAM<\/data>      <data key=\"d1\">A program that provided allocations for using NVIDIA GPUs at NCSA Delta.<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>    <\/node>    <node id=\"MICHAEL AHN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Michael Ahn is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>    <\/node>    <node id=\"ANTHONY BROHAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Anthony Brohan is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NOAH BROWN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Noah Brown is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YEVGEN CHEBOTAR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yevgen Chebotar is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"OMAR CORTES\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Omar Cortes is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BYRON DAVID\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Byron David is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHELSEA FINN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chelsea Finn is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHUYUAN FU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chuyuan Fu is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KEERTHANA GOPALAKRISHNAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Keerthana Gopalakrishnan is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KAROL HAUSMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Karol Hausman is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ALEX HERZOG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Alex Herzog is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DANIEL HO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Daniel Ho is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JASMINE HSU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jasmine Hsu is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JULIAN IBARZ\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Julian Ibarz is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BRIAN ICHTER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Brian Ichter is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ALEX IRPAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Alex Irpan is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ROSARIO JAUREGUI RUANO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Rosario Jauregui Ruano is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KYLE JEFFREY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kyle Jeffrey is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SALLY JESMONTH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sally Jesmonth is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NIKHIL J JOSHI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nikhil J Joshi is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"RYAN JULIAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ryan Julian is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DMITRY KALASHNIKOV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dmitry Kalashnikov is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YUHENG KUANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yuheng Kuang is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KUANG-HUEI LEE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kuang-Huei Lee is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SERGEY LEVINE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sergey Levine is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YAO LU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yao Lu is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LINDA LUU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Linda Luu is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CAROLINA PARADA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Carolina Parada is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PETER PASTOR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Peter Pastor is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JORNELL QUIAMBAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jornell Quiambao is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KANISHKA RAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kanishka Rao is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JAREK RETTINGHOUSE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jarek Rettinghouse is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DIEGO REYES\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Diego Reyes is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PIERRE SERMANET\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pierre Sermanet is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NICOLAS SIEVERS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nicolas Sievers is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CLAYTON TAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Clayton Tan is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ALEXANDER TOSHEV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Alexander Toshev is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"VINCENT VANHOUCKE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Vincent Vanhoucke is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"FEI XIA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Fei Xia is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TED XIAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ted Xiao is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PENG XU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Peng Xu is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SICHUN XU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sichun Xu is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MENGYUAN YAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mengyuan Yan is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ANDY ZENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Andy Zeng is an author of the paper \"Do as I can, not as I say: Grounding language in robotic affordances.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JACOB AUSTIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jacob Austin is an author of the paper \"Program synthesis with large language models.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"AUGUSTUS ODENA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Augustus Odena is an author of the paper \"Program synthesis with large language models.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MAXWELL NYE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Maxwell Nye is an author of the paper \"Program synthesis with large language models.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MAARTEN BOSMA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Maarten Bosma is an author of the paper \"Program synthesis with large language models.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HENRYK MICHALEWSKI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Henryk Michalewski is an author of the paper \"Program synthesis with large language models.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DAVID DOHAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">David Dohan is an author of the paper \"Program synthesis with large language models.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ELLEN JIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ellen Jiang is an author of the paper \"Program synthesis with large language models.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CARRIE CAI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Carrie Cai is an author of the paper \"Program synthesis with large language models.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MICHAEL TERRY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Michael Terry is an author of the paper \"Program synthesis with large language models.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"QUOC LE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Quoc Le is an author of the paper \"Program synthesis with large language models.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHARLES SUTTON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Charles Sutton is an author of the paper \"Program synthesis with large language models.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BOWEN BAKER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bowen Baker is an author of the paper \"Video pretraining (VPT): Learning to act by watching unlabeled online videos.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ILGE AKKAYA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ilge Akkaya is an author of the paper \"Video pretraining (VPT): Learning to act by watching unlabeled online videos.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PETER ZHOKHOV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Peter Zhokhov is an author of the paper \"Video pretraining (VPT): Learning to act by watching unlabeled online videos.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JOOST HUIZINGA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joost Huizinga is an author of the paper \"Video pretraining (VPT): Learning to act by watching unlabeled online videos.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JIE TANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jie Tang is an author of the paper \"Video pretraining (VPT): Learning to act by watching unlabeled online videos.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ADRIEN ECOFFET\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Adrien Ecoffet is an author of the paper \"Video pretraining (VPT): Learning to act by watching unlabeled online videos.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BRANDON HOUGHTON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Brandon Houghton is an author of the paper \"Video pretraining (VPT): Learning to act by watching unlabeled online videos.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"RAUL SAMPEDRO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Raul Sampedro is an author of the paper \"Video pretraining (VPT): Learning to act by watching unlabeled online videos.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JEFF CLUNE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jeff Clune is an author of the paper \"Video pretraining (VPT): Learning to act by watching unlabeled online videos.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MACIEJ BESTA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Maciej Besta is an author of the paper \"Graph of thoughts: Solving elaborate problems with large language models.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NILS BLACH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nils Blach is an author of the paper \"Graph of thoughts: Solving elaborate problems with large language models.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ALES KUBICEK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ales Kubicek is an author of the paper \"Graph of thoughts: Solving elaborate problems with large language models.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ROBERT GERSTENBERGER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Robert Gerstenberger is an author of the paper \"Graph of thoughts: Solving elaborate problems with large language models.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LUKAS GIANINAZZI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lukas Gianinazzi is an author of the paper \"Graph of thoughts: Solving elaborate problems with large language models.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JOANNA GAJDA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joanna Gajda is an author of the paper \"Graph of thoughts: Solving elaborate problems with large language models.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TOMASZ LEHMANN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tomasz Lehmann is an author of the paper \"Graph of thoughts: Solving elaborate problems with large language models.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MICHAL PODSTAWSKI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Michal Podstawski is an author of the paper \"Graph of thoughts: Solving elaborate problems with large language models.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HUBERT NIEWIADOMSKI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hubert Niewiadomski is an author of the paper \"Graph of thoughts: Solving elaborate problems with large language models.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PIOTR NYCZYK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Piotr Nyczyk is an author of the paper \"Graph of thoughts: Solving elaborate problems with large language models.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TORSTEN HOEFLER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Torsten Hoefler is an author of the paper \"Graph of thoughts: Solving elaborate problems with large language models.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SAMUEL R BOWMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Samuel R Bowman is an author of the paper \"A large annotated corpus for learning natural language inference.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GABOR ANGELI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gabor Angeli is an author of the paper \"A large annotated corpus for learning natural language inference.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHRISTOPHER POTTS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Christopher Potts is an author of the paper \"A large annotated corpus for learning natural language inference.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHRISTOPHER D MANNING\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Christopher D Manning is an author of the paper \"A large annotated corpus for learning natural language inference.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TOM B. BROWN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tom B. Brown is an author of the paper \"Language models are few-shot learners.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BENJAMIN MANN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Benjamin Mann is an author of the paper \"Language models are few-shot learners.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NICK RYDER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nick Ryder is an author of the paper \"Language models are few-shot learners.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>    <\/node>    <node id=\"MELANIE SUBBIAH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Melanie Subbiah is an author of the paper \"Language models are few-shot learners.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>    <\/node>    <node id=\"JARED KAPLAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jared Kaplan is an author of the paper \"Language models are few-shot learners.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>    <\/node>    <node id=\"PRAFULLA DHARIWAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Prafulla Dhariwal is an author of the paper \"Language models are few-shot learners.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>    <\/node>    <node id=\"ARVIND NEELAKANTAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Arvind Neelakantan is an author of the paper \"Language models are few-shot learners.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>    <\/node>    <node id=\"PRANAV SHYAM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pranav Shyam is an author of the paper \"Language models are few-shot learners.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>    <\/node>    <node id=\"GIRISH SASTRY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Girish Sastry is an author of the paper \"Language models are few-shot learners.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>    <\/node>    <node id=\"AMANDA ASKELL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Amanda Askell is an author of the paper \"Language models are few-shot learners.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>    <\/node>    <node id=\"SANDHINI AGARWAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sandhini Agarwal is an author of the paper \"Language models are few-shot learners.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>    <\/node>    <node id=\"ARIEL HERBERT-VOSS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ariel Herbert-Voss is an author of the paper \"Language models are few-shot learners.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>    <\/node>    <node id=\"GRETCHEN KRUEGER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gretchen Krueger is an author of the paper \"Language models are few-shot learners.\"<\/data>      <data key=\"d2\">4ae237a491bc8a84cc720e40c59a7464<\/data>    <\/node>  <\/graph><\/graphml>"}
{"id":"7a48515e86161237c03c9a8373197126","chunk":"\nAmodei. Language models are few-shot learners. In\nNeurIPS , 2020.\nMurray Campbell, A Joseph Hoane Jr, and Feng-hsiung\nHsu. Deep blue. Artificial intelligence , 2002.\nBei Chen, Fengji Zhang, Anh Nguyen, Daoguang Zan, Zeqi\nLin, Jian-Guang Lou, and Weizhu Chen. CodeT: Code\ngeneration with generated tests. In ICLR , 2023a.\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan,\nHenrique Ponde, Jared Kaplan, Harrison Edwards, Yura\nBurda, Nicholas Joseph, Greg Brockman, Alex Ray,\nRaul Puri, Gretchen Krueger, Michael Petrov, Heidy\nKhlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan,\nScott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power,\nLukasz Kaiser, Mohammad Bavarian, Clemens Winter,\nPhilippe Tillet, Felipe Petroski Such, David W. Cum-\nmings, Matthias Plappert, Fotios Chantzis, Elizabeth\nBarnes, Ariel Herbert-V oss, William H. Guss, Alex\nNichol, Igor Babuschkin, Suchir Balaji, Shantanu Jain,\nAndrew Carr, Jan Leike, Joshua Achiam, Vedant Misra,\nEvan Morikawa, Alec Radford, Matthew M. Knight,\nMiles Brundage, Mira Murati, Katie Mayer, Peter Welin-\nder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya\nSutskever, and Wojciech Zaremba. Evaluating large lan-\nguage models trained on code. arXiv:2107.03374 , 2021.\nWenhu Chen, Xueguang Ma, Xinyi Wang, and William W.\nCohen. Program of thoughts prompting: disentangling\ncomputation from reasoning for numerical reasoning\ntasks. TMLR , 2023b. ISSN 2835-8856.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts, Paul\nBarham, Hyung Won Chung, Charles Sutton, Sebas-\ntian Gehrmann, Parker Schuh, Kensen Shi, Sasha\nTsvyashchenko, Joshua Maynez, Abhishek Rao, Parker\n10Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nBarnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran,\nEmily Reif, Nan Du, Ben Hutchinson, Reiner Pope,\nJames Bradbury, Jacob Austin, Michael Isard, Guy Gur-\nAri, Pengcheng Yin, Toju Duke, Anselm Levskaya, San-\njay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier\nGarcia, Vedant Misra, Kevin Robinson, Liam Fedus,\nDenny Zhou, Daphne Ippolito, David Luan, Hyeontaek\nLim, Barret Zoph, Alexander Spiridonov, Ryan Sepa-\nssi, David Dohan, Shivani Agrawal, Mark Omernick,\nAndrew M. Dai, Thanumalayan Sankaranarayana Pillai,\nMarie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon\nChild, Oleksandr Polozov, Katherine Lee, Zongwei Zhou,\nXuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat,\nMichele Catasta, Jason Wei, Kathy Meier-Hellstern, Dou-\nglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. PaLM:\nScaling language modeling with pathways. JMLR , 24\n(240):1\u2013113, 2023.\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark\nChen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert,\nJerry Tworek, Jacob Hilton, Reiichiro Nakano, Christo-\npher Hesse, and John Schulman. Training verifiers to\nsolve math word problems. arXiv:2110.14168 , 2021.\nXiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel\nStevens, Boshi Wang, Huan Sun, and Yu Su. Mind2Web:\nTowards a generalist agent for the web. In NeurIPS\nDatasets and Benchmarks Track , 2023.\nDanny Driess, Fei Xia, Mehdi S. M. Sajjadi, Corey Lynch,\nAakanksha Chowdhery, Brian Ichter, Ayzaan Wahid,\nJonathan Tompson, Quan Vuong, Tianhe Yu, Wenlong\nHuang, Yevgen Chebotar, Pierre Sermanet, Daniel Duck-\nworth, Sergey Levine, Vincent Vanhoucke, Karol Haus-\nman, Marc Toussaint, Klaus Greff, Andy Zeng, Igor Mor-\ndatch, and Pete Florence. PaLM-E: An embodied multi-\nmodal language model. In ICML , 2023.\nYilun Du, Mengjiao Yang, Bo Dai, Hanjun Dai, Ofir\nNachum, Joshua B. Tenenbaum, Dale Schuurmans, and\nPieter Abbeel. Learning universal policies via text-guided\nvideo generation. In NeurIPS , 2023.\nJonathan St BT Evans. Intuition and reasoning: A dual-\nprocess perspective. Psychological Inquiry , pages ","chunk_id":"7a48515e86161237c03c9a8373197126","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"AMODEI","type":"PERSON","description":"Amodei is an author of the paper \"Language models are few-shot learners\" presented at NeurIPS in 2020","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"NEURIPS","type":"CONFERENCE","description":"NeurIPS is a conference where the paper \"Language models are few-shot learners\" was presented in 2020","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"MURRAY CAMPBELL","type":"PERSON","description":"Murray Campbell is an author of the paper \"Deep blue\" published in Artificial Intelligence in 2002","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"A JOSEPH HOANE JR","type":"PERSON","description":"A Joseph Hoane Jr is an author of the paper \"Deep blue\" published in Artificial Intelligence in 2002","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"FENG-HSIUNG HSU","type":"PERSON","description":"Feng-hsiung Hsu is an author of the paper \"Deep blue\" published in Artificial Intelligence in 2002","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"ARTIFICIAL INTELLIGENCE","type":"PUBLICATION","description":"Artificial Intelligence is the journal where the paper \"Deep blue\" was published in 2002","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"BEI CHEN","type":"PERSON","description":"Bei Chen is an author of the paper \"CodeT: Code generation with generated tests\" presented at ICLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"FENGJI ZHANG","type":"PERSON","description":"Fengji Zhang is an author of the paper \"CodeT: Code generation with generated tests\" presented at ICLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"ANH NGUYEN","type":"PERSON","description":"Anh Nguyen is an author of the paper \"CodeT: Code generation with generated tests\" presented at ICLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"DAOGUANG ZAN","type":"PERSON","description":"Daoguang Zan is an author of the paper \"CodeT: Code generation with generated tests\" presented at ICLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"ZEQI LIN","type":"PERSON","description":"Zeqi Lin is an author of the paper \"CodeT: Code generation with generated tests\" presented at ICLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"JIAN-GUANG LOU","type":"PERSON","description":"Jian-Guang Lou is an author of the paper \"CodeT: Code generation with generated tests\" presented at ICLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"WEIZHU CHEN","type":"PERSON","description":"Weizhu Chen is an author of the paper \"CodeT: Code generation with generated tests\" presented at ICLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"ICLR","type":"CONFERENCE","description":"ICLR is a conference where the paper \"CodeT: Code generation with generated tests\" was presented in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"MARK CHEN","type":"PERSON","description":"Mark Chen is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021\nMark Chen is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126","entity_type":"PERSON"},{"name":"JERRY TWOREK","type":"PERSON","description":"Jerry Tworek is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021\nJerry Tworek is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126","entity_type":"PERSON"},{"name":"HEEWOO JUN","type":"PERSON","description":"Heewoo Jun is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021\nHeewoo Jun is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126","entity_type":"PERSON"},{"name":"QIMING YUAN","type":"PERSON","description":"Qiming Yuan is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"HENRIQUE PONDE","type":"PERSON","description":"Henrique Ponde is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"JARED KAPLAN","type":"PERSON","description":"Jared Kaplan is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"HARRISON EDWARDS","type":"PERSON","description":"Harrison Edwards is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"YURA BURDA","type":"PERSON","description":"Yura Burda is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"NICHOLAS JOSEPH","type":"PERSON","description":"Nicholas Joseph is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"GREG BROCKMAN","type":"PERSON","description":"Greg Brockman is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"ALEX RAY","type":"PERSON","description":"Alex Ray is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"RAUL PURI","type":"PERSON","description":"Raul Puri is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"GRETCHEN KRUEGER","type":"PERSON","description":"Gretchen Krueger is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"MICHAEL PETROV","type":"PERSON","description":"Michael Petrov is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"HEIDY KHLAAF","type":"PERSON","description":"Heidy Khlaaf is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"GIRISH SASTRY","type":"PERSON","description":"Girish Sastry is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"PAMELA MISHKIN","type":"PERSON","description":"Pamela Mishkin is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"BROOKE CHAN","type":"PERSON","description":"Brooke Chan is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"SCOTT GRAY","type":"PERSON","description":"Scott Gray is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"NICK RYDER","type":"PERSON","description":"Nick Ryder is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"MIKHAIL PAVLOV","type":"PERSON","description":"Mikhail Pavlov is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"ALETHEA POWER","type":"PERSON","description":"Alethea Power is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"LUKASZ KAISER","type":"PERSON","description":"Lukasz Kaiser is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021\nLukasz Kaiser is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126","entity_type":"PERSON"},{"name":"MOHAMMAD BAVARIAN","type":"PERSON","description":"Mohammad Bavarian is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021\nMohammad Bavarian is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126","entity_type":"PERSON"},{"name":"CLEMENS WINTER","type":"PERSON","description":"Clemens Winter is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"PHILIPPE TILLET","type":"PERSON","description":"Philippe Tillet is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"FELIPE PETROSKI SUCH","type":"PERSON","description":"Felipe Petroski Such is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"DAVID W. CUMMINGS","type":"PERSON","description":"David W. Cummings is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"MATTHIAS PLAPPERT","type":"PERSON","description":"Matthias Plappert is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021\nMatthias Plappert is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126","entity_type":"PERSON"},{"name":"FOTIOS CHANTZIS","type":"PERSON","description":"Fotios Chantzis is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"ELIZABETH BARNES","type":"PERSON","description":"Elizabeth Barnes is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"ARIEL HERBERT-VOSS","type":"PERSON","description":"Ariel Herbert-Voss is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"WILLIAM H. GUSS","type":"PERSON","description":"William H. Guss is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"ALEX NICHOL","type":"PERSON","description":"Alex Nichol is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"IGOR BABUSCHKIN","type":"PERSON","description":"Igor Babuschkin is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"SUCHIR BALAJI","type":"PERSON","description":"Suchir Balaji is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"SHANTANU JAIN","type":"PERSON","description":"Shantanu Jain is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"ANDREW CARR","type":"PERSON","description":"Andrew Carr is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"JAN LEIKE","type":"PERSON","description":"Jan Leike is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"JOSHUA ACHIAM","type":"PERSON","description":"Joshua Achiam is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"VEDANT MISRA","type":"PERSON","description":"Vedant Misra is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021\nVedant Misra is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126","entity_type":"PERSON"},{"name":"EVAN MORIKAWA","type":"PERSON","description":"Evan Morikawa is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"ALEC RADFORD","type":"PERSON","description":"Alec Radford is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"MATTHEW M. KNIGHT","type":"PERSON","description":"Matthew M. Knight is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"MILES BRUNDAGE","type":"PERSON","description":"Miles Brundage is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"MIRA MURATI","type":"PERSON","description":"Mira Murati is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"KATIE MAYER","type":"PERSON","description":"Katie Mayer is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"PETER WELINDER","type":"PERSON","description":"Peter Welinder is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"BOB MCGREW","type":"PERSON","description":"Bob McGrew is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"DARIO AMODEI","type":"PERSON","description":"Dario Amodei is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"SAM MCCANDLISH","type":"PERSON","description":"Sam McCandlish is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"ILYA SUTSKEVER","type":"PERSON","description":"Ilya Sutskever is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"WOJCIECH ZAREMBA","type":"PERSON","description":"Wojciech Zaremba is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"ARXIV","type":"PUBLICATION","description":"arXiv is the platform where the paper \"Evaluating large language models trained on code\" was published in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"WENHU CHEN","type":"PERSON","description":"Wenhu Chen is an author of the paper \"Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks\" published in TMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"XUEGUANG MA","type":"PERSON","description":"Xueguang Ma is an author of the paper \"Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks\" published in TMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"XINYI WANG","type":"PERSON","description":"Xinyi Wang is an author of the paper \"Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks\" published in TMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"WILLIAM W. COHEN","type":"PERSON","description":"William W. Cohen is an author of the paper \"Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks\" published in TMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"TMLR","type":"PUBLICATION","description":"TMLR is the journal where the paper \"Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks\" was published in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"AAKANKSHA CHOWDHERY","type":"PERSON","description":"Aakanksha Chowdhery is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023\nAakanksha Chowdhery is an author of the paper \"","source_id":"7a48515e86161237c03c9a8373197126","entity_type":"PERSON"},{"name":"SHARAN NARANG","type":"PERSON","description":"Sharan Narang is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"JACOB DEVLIN","type":"PERSON","description":"Jacob Devlin is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"MAARTEN BOSMA","type":"PERSON","description":"Maarten Bosma is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"GAURAV MISHRA","type":"PERSON","description":"Gaurav Mishra is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"ADAM ROBERTS","type":"PERSON","description":"Adam Roberts is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"PAUL BARHAM","type":"PERSON","description":"Paul Barham is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"HYUNG WON CHUNG","type":"PERSON","description":"Hyung Won Chung is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"CHARLES SUTTON","type":"PERSON","description":"Charles Sutton is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"SEBASTIAN GEHRMANN","type":"PERSON","description":"Sebastian Gehrmann is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"JOSHUA MAYNEZ","type":"PERSON","description":"Joshua Maynez is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"ABHISHEK RAO","type":"PERSON","description":"Abhishek Rao is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"PARKER BARNES","type":"PERSON","description":"Parker Barnes is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"YI TAY","type":"PERSON","description":"Yi Tay is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"NOAM SHAZEER","type":"PERSON","description":"Noam Shazeer is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"VINODKUMAR PRABHAKARAN","type":"PERSON","description":"Vinodkumar Prabhakaran is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"EMILY REIF","type":"PERSON","description":"Emily Reif is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"NAN DU","type":"PERSON","description":"Nan Du is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"BEN HUTCHINSON","type":"PERSON","description":"Ben Hutchinson is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"REINER POPE","type":"PERSON","description":"Reiner Pope is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"JAMES BRADBURY","type":"PERSON","description":"James Bradbury is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"JACOB AUSTIN","type":"PERSON","description":"Jacob Austin is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"MICHAEL ISARD","type":"PERSON","description":"Michael Isard is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"GUY GUR-ARI","type":"PERSON","description":"Guy Gur-Ari is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"PENGCHENG YIN","type":"PERSON","description":"Pengcheng Yin is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"TOJU DUKE","type":"PERSON","description":"Toju Duke is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"ANSELM LEVSKAYA","type":"PERSON","description":"Anselm Levskaya is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"SANJAY GHEMAWAT","type":"PERSON","description":"Sanjay Ghemawat is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"SUNIPA DEV","type":"PERSON","description":"Sunipa Dev is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"HENRYK MICHALEWSKI","type":"PERSON","description":"Henryk Michalewski is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"XAVIER GARCIA","type":"PERSON","description":"Xavier Garcia is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"KEVIN ROBINSON","type":"PERSON","description":"Kevin Robinson is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"LIAM FEDUS","type":"PERSON","description":"Liam Fedus is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"DENNY ZHOU","type":"PERSON","description":"Denny Zhou is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"DAPHNE IPPOLITO","type":"PERSON","description":"Daphne Ippolito is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"DAVID LUAN","type":"PERSON","description":"David Luan is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"HYEONTAEK LIM","type":"PERSON","description":"Hyeontaek Lim is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"BARRET ZOPH","type":"PERSON","description":"Barret Zoph is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"ALEXANDER SPIRIDONOV","type":"PERSON","description":"Alexander Spiridonov is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"RYAN SEPASSI","type":"PERSON","description":"Ryan Sepassi is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"DAVID DOHAN","type":"PERSON","description":"David Dohan is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"SHIVANI AGRAWAL","type":"PERSON","description":"Shivani Agrawal is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"MARK OMERNICK","type":"PERSON","description":"Mark Omernick is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"ANDREW M. DAI","type":"PERSON","description":"Andrew M. Dai is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"THANUMALAYAN SANKARANARAYANA PILLAI","type":"PERSON","description":"Thanumalayan Sankaranarayana Pillai is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"MARIE PELLAT","type":"PERSON","description":"Marie Pellat is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"AITOR LEWKOWYCZ","type":"PERSON","description":"Aitor Lewkowycz is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"ERICA MOREIRA","type":"PERSON","description":"Erica Moreira is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"REWON CHILD","type":"PERSON","description":"Rewon Child is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"OLEKSANDR POLOZOV","type":"PERSON","description":"Oleksandr Polozov is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"KATHERINE LEE","type":"PERSON","description":"Katherine Lee is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"ZONGWEI ZHOU","type":"PERSON","description":"Zongwei Zhou is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"XUEZHI WANG","type":"PERSON","description":"Xuezhi Wang is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"BRENNAN SAETA","type":"PERSON","description":"Brennan Saeta is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"MARK DIAZ","type":"PERSON","description":"Mark Diaz is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"ORHAN FIRAT","type":"PERSON","description":"Orhan Firat is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"MICHELE CATASTA","type":"PERSON","description":"Michele Catasta is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"JASON WEI","type":"PERSON","description":"Jason Wei is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"KATHY MEIER-HELLSTERN","type":"PERSON","description":"Kathy Meier-Hellstern is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"DOUGLAS ECK","type":"PERSON","description":"Douglas Eck is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"JEFF DEAN","type":"PERSON","description":"Jeff Dean is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"SLAV PETROV","type":"PERSON","description":"Slav Petrov is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"NOAH FIEDEL","type":"PERSON","description":"Noah Fiedel is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"JMLR","type":"PUBLICATION","description":"JMLR is the journal where the paper \"PaLM: Scaling language modeling with pathways\" was published in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"KARL COBBE","type":"PERSON","description":"Karl Cobbe is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"VINEET KOSARAJU","type":"PERSON","description":"Vineet Kosaraju is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"JACOB HILTON","type":"PERSON","description":"Jacob Hilton is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"REIICHIRO NAKANO","type":"PERSON","description":"Reiichiro Nakano is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"CHRISTOPHER HESSE","type":"PERSON","description":"Christopher Hesse is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"JOHN SCHULMAN","type":"PERSON","description":"John Schulman is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"XIANG DENG","type":"PERSON","description":"Xiang Deng is an author of the paper \"Mind2Web: Towards a generalist agent for the web\" presented at NeurIPS Datasets and Benchmarks Track in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"YU GU","type":"PERSON","description":"Yu Gu is an author of the paper \"Mind2Web: Towards a generalist agent for the web\" presented at NeurIPS Datasets and Benchmarks Track in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"BOYUAN ZHENG","type":"PERSON","description":"Boyuan Zheng is an author of the paper \"Mind2Web: Towards a generalist agent for the web\" presented at NeurIPS Datasets and Benchmarks Track in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"SHIJIE CHEN","type":"PERSON","description":"Shijie Chen is an author of the paper \"Mind2Web: Towards a generalist agent for the web\" presented at NeurIPS Datasets and Benchmarks Track in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"SAMUEL STEVENS","type":"PERSON","description":"Samuel Stevens is an author of the paper \"Mind2Web: Towards a generalist agent for the web\" presented at NeurIPS Datasets and Benchmarks Track in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"BOSHI WANG","type":"PERSON","description":"Boshi Wang is an author of the paper \"Mind2Web: Towards a generalist agent for the web\" presented at NeurIPS Datasets and Benchmarks Track in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"HUAN SUN","type":"PERSON","description":"Huan Sun is an author of the paper \"Mind2Web: Towards a generalist agent for the web\" presented at NeurIPS Datasets and Benchmarks Track in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"YU SU","type":"PERSON","description":"Yu Su is an author of the paper \"Mind2Web: Towards a generalist agent for the web\" presented at NeurIPS Datasets and Benchmarks Track in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"NEURIPS DATASETS AND BENCHMARKS TRACK","type":"CONFERENCE","description":"NeurIPS Datasets and Benchmarks Track is a conference where the paper \"Mind2Web: Towards a generalist agent for the web\" was presented in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"DANNY DRIESS","type":"PERSON","description":"Danny Driess is an author of the paper \"PaLM-E: An embodied multimodal language model\" presented at ICML in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"FEI XIA","type":"PERSON","description":"Fei Xia is an author of the paper \"PaLM-E: An embodied multimodal language model\" presented at ICML in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"MEHDI S. M. SAJJADI","type":"PERSON","description":"Mehdi S. M. Sajjadi is an author of the paper \"PaLM-E: An embodied multimodal language model\" presented at ICML in 2023","source_id":"7a48515e86161237c03c9a8373197126"},{"name":"COREY LYNCH","type":"PERSON","description":"Corey Lynch is an author of the paper \"PaLM-E: An embodied multimodal language model\" presented at ICML in 2023","source_id":"7a48515e86161237c03c9a8373197126"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"AMODEI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Amodei is an author of the paper \"Language models are few-shot learners\" presented at NeurIPS in 2020<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"NEURIPS\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">NeurIPS is a conference where the paper \"Language models are few-shot learners\" was presented in 2020<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"MURRAY CAMPBELL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Murray Campbell is an author of the paper \"Deep blue\" published in Artificial Intelligence in 2002<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"A JOSEPH HOANE JR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A Joseph Hoane Jr is an author of the paper \"Deep blue\" published in Artificial Intelligence in 2002<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"FENG-HSIUNG HSU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Feng-hsiung Hsu is an author of the paper \"Deep blue\" published in Artificial Intelligence in 2002<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"ARTIFICIAL INTELLIGENCE\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Artificial Intelligence is the journal where the paper \"Deep blue\" was published in 2002<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"BEI CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bei Chen is an author of the paper \"CodeT: Code generation with generated tests\" presented at ICLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"FENGJI ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Fengji Zhang is an author of the paper \"CodeT: Code generation with generated tests\" presented at ICLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"ANH NGUYEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Anh Nguyen is an author of the paper \"CodeT: Code generation with generated tests\" presented at ICLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"DAOGUANG ZAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Daoguang Zan is an author of the paper \"CodeT: Code generation with generated tests\" presented at ICLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"ZEQI LIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zeqi Lin is an author of the paper \"CodeT: Code generation with generated tests\" presented at ICLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"JIAN-GUANG LOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jian-Guang Lou is an author of the paper \"CodeT: Code generation with generated tests\" presented at ICLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"WEIZHU CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Weizhu Chen is an author of the paper \"CodeT: Code generation with generated tests\" presented at ICLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"ICLR\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">ICLR is a conference where the paper \"CodeT: Code generation with generated tests\" was presented in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"MARK CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mark Chen is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021Mark Chen is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JERRY TWOREK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jerry Tworek is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021Jerry Tworek is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HEEWOO JUN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Heewoo Jun is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021Heewoo Jun is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"QIMING YUAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Qiming Yuan is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"HENRIQUE PONDE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Henrique Ponde is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"JARED KAPLAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jared Kaplan is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"HARRISON EDWARDS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Harrison Edwards is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"YURA BURDA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yura Burda is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"NICHOLAS JOSEPH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nicholas Joseph is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"GREG BROCKMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Greg Brockman is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"ALEX RAY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Alex Ray is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"RAUL PURI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Raul Puri is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"GRETCHEN KRUEGER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gretchen Krueger is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"MICHAEL PETROV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Michael Petrov is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"HEIDY KHLAAF\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Heidy Khlaaf is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"GIRISH SASTRY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Girish Sastry is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"PAMELA MISHKIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pamela Mishkin is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"BROOKE CHAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Brooke Chan is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"SCOTT GRAY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Scott Gray is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"NICK RYDER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nick Ryder is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"MIKHAIL PAVLOV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mikhail Pavlov is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"ALETHEA POWER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Alethea Power is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"LUKASZ KAISER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lukasz Kaiser is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021Lukasz Kaiser is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MOHAMMAD BAVARIAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mohammad Bavarian is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021Mohammad Bavarian is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CLEMENS WINTER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Clemens Winter is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"PHILIPPE TILLET\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Philippe Tillet is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"FELIPE PETROSKI SUCH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Felipe Petroski Such is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"DAVID W. CUMMINGS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">David W. Cummings is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"MATTHIAS PLAPPERT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Matthias Plappert is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021Matthias Plappert is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"FOTIOS CHANTZIS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Fotios Chantzis is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"ELIZABETH BARNES\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Elizabeth Barnes is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"ARIEL HERBERT-VOSS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ariel Herbert-Voss is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"WILLIAM H. GUSS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">William H. Guss is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"ALEX NICHOL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Alex Nichol is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"IGOR BABUSCHKIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Igor Babuschkin is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"SUCHIR BALAJI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Suchir Balaji is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"SHANTANU JAIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shantanu Jain is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"ANDREW CARR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Andrew Carr is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"JAN LEIKE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jan Leike is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"JOSHUA ACHIAM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joshua Achiam is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"VEDANT MISRA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Vedant Misra is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021Vedant Misra is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"EVAN MORIKAWA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Evan Morikawa is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"ALEC RADFORD\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Alec Radford is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"MATTHEW M. KNIGHT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Matthew M. Knight is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"MILES BRUNDAGE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Miles Brundage is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"MIRA MURATI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mira Murati is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"KATIE MAYER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Katie Mayer is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"PETER WELINDER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Peter Welinder is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"BOB MCGREW\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bob McGrew is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"DARIO AMODEI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dario Amodei is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"SAM MCCANDLISH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sam McCandlish is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"ILYA SUTSKEVER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ilya Sutskever is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"WOJCIECH ZAREMBA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wojciech Zaremba is an author of the paper \"Evaluating large language models trained on code\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"ARXIV\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">arXiv is the platform where the paper \"Evaluating large language models trained on code\" was published in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"WENHU CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wenhu Chen is an author of the paper \"Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks\" published in TMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"XUEGUANG MA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xueguang Ma is an author of the paper \"Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks\" published in TMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"XINYI WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xinyi Wang is an author of the paper \"Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks\" published in TMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"WILLIAM W. COHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">William W. Cohen is an author of the paper \"Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks\" published in TMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"TMLR\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">TMLR is the journal where the paper \"Program of thoughts prompting: disentangling computation from reasoning for numerical reasoning tasks\" was published in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"AAKANKSHA CHOWDHERY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Aakanksha Chowdhery is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023Aakanksha Chowdhery is an author of the paper \"<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHARAN NARANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sharan Narang is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"JACOB DEVLIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jacob Devlin is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"MAARTEN BOSMA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Maarten Bosma is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"GAURAV MISHRA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gaurav Mishra is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"ADAM ROBERTS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Adam Roberts is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"PAUL BARHAM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Paul Barham is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"HYUNG WON CHUNG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hyung Won Chung is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"CHARLES SUTTON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Charles Sutton is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"SEBASTIAN GEHRMANN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sebastian Gehrmann is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"JOSHUA MAYNEZ\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joshua Maynez is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"ABHISHEK RAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Abhishek Rao is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"PARKER BARNES\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Parker Barnes is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"YI TAY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yi Tay is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"NOAM SHAZEER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Noam Shazeer is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"VINODKUMAR PRABHAKARAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Vinodkumar Prabhakaran is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"EMILY REIF\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Emily Reif is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"NAN DU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nan Du is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"BEN HUTCHINSON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ben Hutchinson is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"REINER POPE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Reiner Pope is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"JAMES BRADBURY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">James Bradbury is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"JACOB AUSTIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jacob Austin is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"MICHAEL ISARD\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Michael Isard is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"GUY GUR-ARI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Guy Gur-Ari is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"PENGCHENG YIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pengcheng Yin is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"TOJU DUKE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Toju Duke is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"ANSELM LEVSKAYA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Anselm Levskaya is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"SANJAY GHEMAWAT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sanjay Ghemawat is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"SUNIPA DEV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sunipa Dev is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"HENRYK MICHALEWSKI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Henryk Michalewski is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"XAVIER GARCIA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xavier Garcia is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"KEVIN ROBINSON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kevin Robinson is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"LIAM FEDUS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liam Fedus is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"DENNY ZHOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Denny Zhou is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"DAPHNE IPPOLITO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Daphne Ippolito is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"DAVID LUAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">David Luan is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"HYEONTAEK LIM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hyeontaek Lim is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"BARRET ZOPH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Barret Zoph is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"ALEXANDER SPIRIDONOV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Alexander Spiridonov is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"RYAN SEPASSI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ryan Sepassi is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"DAVID DOHAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">David Dohan is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"SHIVANI AGRAWAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shivani Agrawal is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"MARK OMERNICK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mark Omernick is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"ANDREW M. DAI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Andrew M. Dai is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"THANUMALAYAN SANKARANARAYANA PILLAI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Thanumalayan Sankaranarayana Pillai is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"MARIE PELLAT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Marie Pellat is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"AITOR LEWKOWYCZ\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Aitor Lewkowycz is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"ERICA MOREIRA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Erica Moreira is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"REWON CHILD\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Rewon Child is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"OLEKSANDR POLOZOV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Oleksandr Polozov is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"KATHERINE LEE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Katherine Lee is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"ZONGWEI ZHOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zongwei Zhou is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"XUEZHI WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xuezhi Wang is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"BRENNAN SAETA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Brennan Saeta is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"MARK DIAZ\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mark Diaz is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"ORHAN FIRAT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Orhan Firat is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"MICHELE CATASTA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Michele Catasta is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"JASON WEI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jason Wei is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"KATHY MEIER-HELLSTERN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kathy Meier-Hellstern is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"DOUGLAS ECK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Douglas Eck is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"JEFF DEAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jeff Dean is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"SLAV PETROV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Slav Petrov is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"NOAH FIEDEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Noah Fiedel is an author of the paper \"PaLM: Scaling language modeling with pathways\" published in JMLR in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"JMLR\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">JMLR is the journal where the paper \"PaLM: Scaling language modeling with pathways\" was published in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"KARL COBBE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Karl Cobbe is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"VINEET KOSARAJU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Vineet Kosaraju is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"JACOB HILTON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jacob Hilton is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"REIICHIRO NAKANO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Reiichiro Nakano is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"CHRISTOPHER HESSE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Christopher Hesse is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"JOHN SCHULMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">John Schulman is an author of the paper \"Training verifiers to solve math word problems\" published on arXiv in 2021<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"XIANG DENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xiang Deng is an author of the paper \"Mind2Web: Towards a generalist agent for the web\" presented at NeurIPS Datasets and Benchmarks Track in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"YU GU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yu Gu is an author of the paper \"Mind2Web: Towards a generalist agent for the web\" presented at NeurIPS Datasets and Benchmarks Track in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"BOYUAN ZHENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Boyuan Zheng is an author of the paper \"Mind2Web: Towards a generalist agent for the web\" presented at NeurIPS Datasets and Benchmarks Track in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"SHIJIE CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shijie Chen is an author of the paper \"Mind2Web: Towards a generalist agent for the web\" presented at NeurIPS Datasets and Benchmarks Track in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"SAMUEL STEVENS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Samuel Stevens is an author of the paper \"Mind2Web: Towards a generalist agent for the web\" presented at NeurIPS Datasets and Benchmarks Track in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"BOSHI WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Boshi Wang is an author of the paper \"Mind2Web: Towards a generalist agent for the web\" presented at NeurIPS Datasets and Benchmarks Track in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"HUAN SUN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Huan Sun is an author of the paper \"Mind2Web: Towards a generalist agent for the web\" presented at NeurIPS Datasets and Benchmarks Track in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"YU SU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yu Su is an author of the paper \"Mind2Web: Towards a generalist agent for the web\" presented at NeurIPS Datasets and Benchmarks Track in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"NEURIPS DATASETS AND BENCHMARKS TRACK\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">NeurIPS Datasets and Benchmarks Track is a conference where the paper \"Mind2Web: Towards a generalist agent for the web\" was presented in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"DANNY DRIESS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Danny Driess is an author of the paper \"PaLM-E: An embodied multimodal language model\" presented at ICML in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"FEI XIA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Fei Xia is an author of the paper \"PaLM-E: An embodied multimodal language model\" presented at ICML in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"MEHDI S. M. SAJJADI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mehdi S. M. Sajjadi is an author of the paper \"PaLM-E: An embodied multimodal language model\" presented at ICML in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>    <node id=\"COREY LYNCH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Corey Lynch is an author of the paper \"PaLM-E: An embodied multimodal language model\" presented at ICML in 2023<\/data>      <data key=\"d2\">7a48515e86161237c03c9a8373197126<\/data>    <\/node>  <\/graph><\/graphml>"}
{"id":"68e5573b596d253a03047b1e41988598","chunk":" An embodied multi-\nmodal language model. In ICML , 2023.\nYilun Du, Mengjiao Yang, Bo Dai, Hanjun Dai, Ofir\nNachum, Joshua B. Tenenbaum, Dale Schuurmans, and\nPieter Abbeel. Learning universal policies via text-guided\nvideo generation. In NeurIPS , 2023.\nJonathan St BT Evans. Intuition and reasoning: A dual-\nprocess perspective. Psychological Inquiry , pages 313 \u2013\n326, 2010.\nLinxi Fan, Guanzhi Wang, Yunfan Jiang, Ajay Mandlekar,\nYuncong Yang, Haoyi Zhu, Andrew Tang, De-An Huang,\nYuke Zhu, and Anima Anandkumar. MineDojo: Building\nopen-ended embodied agents with internet-scale knowl-\nedge. In NeurIPS Datasets and Benchmarks Track , 2022.\nHiroki Furuta, Ofir Nachum, Kuang-Huei Lee, Yutaka Mat-\nsuo, Shixiang Shane Gu, and Izzeddin Gur. Multimodal\nweb navigation with instruction-finetuned foundation\nmodels. In ICLR , 2024.Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei\nLiu, Yiming Yang, Jamie Callan, and Graham Neubig.\nPAL: Program-aided language models. In ICML , 2023.\nJiaxian Guo, Sidi Lu, Han Cai, Weinan Zhang, Yong Yu, and\nJun Wang. Long text generation via adversarial training\nwith leaked information. In AAAI , 2018.\nWilliam H. Guss, Brandon Houghton, Nicholay Topin,\nPhillip Wang, Cayden Codel, Manuela Veloso, and Rus-\nlan Salakhutdinov. MineRL: A large-scale dataset of\nMinecraft demonstrations. In IJCAI , 2019.\nDanijar Hafner, Timothy Lillicrap, Ian Fischer, Ruben Ville-\ngas, David Ha, Honglak Lee, and James Davidson. Learn-\ning latent dynamics for planning from pixels. In ICML ,\n2019.\nDanijar Hafner, Jurgis Pasukonis, Jimmy Ba, and Timo-\nthy Lillicrap. Mastering diverse domains through world\nmodels. arXiv:2301.04104 , 2023.\nShibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen\nWang, Daisy Zhe Wang, and Zhiting Hu. Reasoning\nwith language model is planning with world model. In\nEMNLP , 2023.\nJie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu Steven\nZheng, Adams Wei Yu, Xinying Song, and Denny Zhou.\nLarge language models cannot self-correct reasoning yet.\nInICLR , 2024.\nWenlong Huang, F. Xia, Ted Xiao, Harris Chan, Jacky\nLiang, Peter R. Florence, Andy Zeng, Jonathan Tompson,\nIgor Mordatch, Yevgen Chebotar, Pierre Sermanet, Noah\nBrown, Tomas Jackson, Linda Luu, Sergey Levine, Karol\nHausman, and Brian Ichter. Inner monologue: Embodied\nreasoning through planning with language models. In\nCoRL , 2022.\nLevente Kocsis and Csaba Szepesv \u00b4ari. Bandit based monte-\ncarlo planning. In ECML , 2006.\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka\nMatsuo, and Yusuke Iwasawa. Large language models\nare zero-shot reasoners. In NeurIPS , 2022.\nSteven M. LaValle. Rapidly-exploring random trees : A\nnew tool for path planning. The Annual Research Report ,\n1998.\nEvan Zheran Liu, Kelvin Guu, Panupong Pasupat, Tianlin\nShi, and Percy Liang. Reinforcement learning on web\ninterfaces using workflow-guided exploration. In ICLR ,\n2018.\nXiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu\nLei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen Men,\n11Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nKejuan Yang, Shudan Zhang, Xiang Deng, Aohan Zeng,\nZhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun\nZhang, Yu Su, Huan Sun, Minlie Huang, Yuxiao Dong,\nand Jie Tang. AgentBench: Evaluating LLMs as agents.\nInICLR , 2024.\nZhihan Liu, Hao Hu, Shenao Zhang, Hongyi Guo, Shuqi\nKe, Boyi Liu, and Zhaoran Wang. Reason for fu-\nture, act for now: A principled framework for au-\ntonomous LLM agents with provable sample efficiency.\narXiv:2309.17382 , 2023.\nAman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hal-\nlinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha\nDziri, Shrimai Prabhumoye, Yiming Yang, Shashank\nGupta, Bodhisattwa Prasad Majumder, Katherine Her-\nmann, Sean Welle","chunk_id":"68e5573b596d253a03047b1e41988598","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"MENGJIAO YANG","type":"PERSON","description":"Mengjiao Yang is an author of the paper \"Learning universal policies via text-guided video generation\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"BO DAI","type":"PERSON","description":"Bo Dai is an author of the paper \"Learning universal policies via text-guided video generation\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"HANJUN DAI","type":"PERSON","description":"Hanjun Dai is an author of the paper \"Learning universal policies via text-guided video generation\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"OFIR NACHUM","type":"PERSON","description":"Ofir Nachum is an author of the paper \"Multimodal web navigation with instruction-finetuned foundation models\"\nOfir Nachum is an author of the paper \"Learning universal policies via text-guided video generation\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"JOSHUA B. TENENBAUM","type":"PERSON","description":"Joshua B. Tenenbaum is an author of the paper \"Learning universal policies via text-guided video generation\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"DALE SCHUURMANS","type":"PERSON","description":"Dale Schuurmans is an author of the paper \"Learning universal policies via text-guided video generation\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"PIETER ABBEEL","type":"PERSON","description":"Pieter Abbeel is an author of the paper \"Learning universal policies via text-guided video generation\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"NEURIPS","type":"CONFERENCE","description":"NeurIPS is the conference where the paper \"Learning universal policies via text-guided video generation\" was presented\nNeurIPS is the conference where the paper \"Large language models are zero-shot reasoners\" was presented","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"CONFERENCE"},{"name":"JONATHAN ST BT EVANS","type":"PERSON","description":"Jonathan St BT Evans is the author of the paper \"Intuition and reasoning: A dual-process perspective\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"PSYCHOLOGICAL INQUIRY","type":"PUBLICATION","description":"Psychological Inquiry is the journal where the paper \"Intuition and reasoning: A dual-process perspective\" was published","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PUBLICATION"},{"name":"LINXI FAN","type":"PERSON","description":"Linxi Fan is an author of the paper \"MineDojo: Building open-ended embodied agents with internet-scale knowledge\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"GUANZHI WANG","type":"PERSON","description":"Guanzhi Wang is an author of the paper \"MineDojo: Building open-ended embodied agents with internet-scale knowledge\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"YUNFAN JIANG","type":"PERSON","description":"Yunfan Jiang is an author of the paper \"MineDojo: Building open-ended embodied agents with internet-scale knowledge\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"AJAY MANDLEKAR","type":"PERSON","description":"Ajay Mandlekar is an author of the paper \"MineDojo: Building open-ended embodied agents with internet-scale knowledge\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"YUNCONG YANG","type":"PERSON","description":"Yuncong Yang is an author of the paper \"MineDojo: Building open-ended embodied agents with internet-scale knowledge\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"HAOYI ZHU","type":"PERSON","description":"Haoyi Zhu is an author of the paper \"MineDojo: Building open-ended embodied agents with internet-scale knowledge\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"ANDREW TANG","type":"PERSON","description":"Andrew Tang is an author of the paper \"MineDojo: Building open-ended embodied agents with internet-scale knowledge\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"DE-AN HUANG","type":"PERSON","description":"De-An Huang is an author of the paper \"MineDojo: Building open-ended embodied agents with internet-scale knowledge\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"YUKE ZHU","type":"PERSON","description":"Yuke Zhu is an author of the paper \"MineDojo: Building open-ended embodied agents with internet-scale knowledge\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"ANIMA ANANDKUMAR","type":"PERSON","description":"Anima Anandkumar is an author of the paper \"MineDojo: Building open-ended embodied agents with internet-scale knowledge\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"NEURIPS DATASETS AND BENCHMARKS TRACK","type":"CONFERENCE","description":"NeurIPS Datasets and Benchmarks Track is the conference where the paper \"MineDojo: Building open-ended embodied agents with internet-scale knowledge\" was presented","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"HIROKI FURUTA","type":"PERSON","description":"Hiroki Furuta is an author of the paper \"Multimodal web navigation with instruction-finetuned foundation models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"KUANG-HUEI LEE","type":"PERSON","description":"Kuang-Huei Lee is an author of the paper \"Multimodal web navigation with instruction-finetuned foundation models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"YUTAKA MATSUO","type":"PERSON","description":"Yutaka Matsuo is an author of the paper \"Large language models are zero-shot reasoners\"\nYutaka Matsuo is an author of the paper \"Multimodal web navigation with instruction-finetuned foundation models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"SHIXIANG SHANE GU","type":"PERSON","description":"Shixiang Shane Gu is an author of the paper \"Multimodal web navigation with instruction-finetuned foundation models\"\nShixiang Shane Gu is an author of the paper \"Large language models are zero-shot reasoners\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"IZZEDDIN GUR","type":"PERSON","description":"Izzeddin Gur is an author of the paper \"Multimodal web navigation with instruction-finetuned foundation models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"ICLR","type":"CONFERENCE","description":"ICLR is the conference where the paper \"Reinforcement learning on web interfaces using workflow-guided exploration\" was presented\nICLR is the conference where the paper \"Multimodal web navigation with instruction-finetuned foundation models\" was presented\nICLR is the conference where the paper \"Large language models cannot self-correct reasoning yet\" was presented","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"CONFERENCE"},{"name":"LUYU GAO","type":"PERSON","description":"Luyu Gao is an author of the paper \"PAL: Program-aided language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"AMAN MADAAN","type":"PERSON","description":"Aman Madaan is an author of the paper \"PAL: Program-aided language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"SHUYAN ZHOU","type":"PERSON","description":"Shuyan Zhou is an author of the paper \"PAL: Program-aided language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"URI ALON","type":"PERSON","description":"Uri Alon is an author of the paper \"PAL: Program-aided language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"PENGFEI LIU","type":"PERSON","description":"Pengfei Liu is an author of the paper \"PAL: Program-aided language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"YIMING YANG","type":"PERSON","description":"Yiming Yang is an author of the paper \"PAL: Program-aided language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"JAMIE CALLAN","type":"PERSON","description":"Jamie Callan is an author of the paper \"PAL: Program-aided language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"GRAHAM NEUBIG","type":"PERSON","description":"Graham Neubig is an author of the paper \"PAL: Program-aided language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"ICML","type":"CONFERENCE","description":"ICML is the conference where the paper \"PAL: Program-aided language models\" was presented\nICML is the conference where the paper \"An embodied multi-modal language model\" was presented\nICML is the conference where the paper \"Learning latent dynamics for planning from pixels\" was presented","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"CONFERENCE"},{"name":"JIANXIAN GUO","type":"PERSON","description":"Jiaxian Guo is an author of the paper \"Long text generation via adversarial training with leaked information\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"SIDI LU","type":"PERSON","description":"Sidi Lu is an author of the paper \"Long text generation via adversarial training with leaked information\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"HAN CAI","type":"PERSON","description":"Han Cai is an author of the paper \"Long text generation via adversarial training with leaked information\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"WEINAN ZHANG","type":"PERSON","description":"Weinan Zhang is an author of the paper \"Long text generation via adversarial training with leaked information\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"YONG YU","type":"PERSON","description":"Yong Yu is an author of the paper \"Long text generation via adversarial training with leaked information\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"JUN WANG","type":"PERSON","description":"Jun Wang is an author of the paper \"Long text generation via adversarial training with leaked information\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"AAAI","type":"CONFERENCE","description":"AAAI is the conference where the paper \"Long text generation via adversarial training with leaked information\" was presented","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"CONFERENCE"},{"name":"WILLIAM H. GUSS","type":"PERSON","description":"William H. Guss is an author of the paper \"MineRL: A large-scale dataset of Minecraft demonstrations\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"BRANDON HOUGHTON","type":"PERSON","description":"Brandon Houghton is an author of the paper \"MineRL: A large-scale dataset of Minecraft demonstrations\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"NICHOLAY TOPIN","type":"PERSON","description":"Nicholay Topin is an author of the paper \"MineRL: A large-scale dataset of Minecraft demonstrations\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"PHILLIP WANG","type":"PERSON","description":"Phillip Wang is an author of the paper \"MineRL: A large-scale dataset of Minecraft demonstrations\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"CAYDEN CODEL","type":"PERSON","description":"Cayden Codel is an author of the paper \"MineRL: A large-scale dataset of Minecraft demonstrations\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"MANUELA VELOSO","type":"PERSON","description":"Manuela Veloso is an author of the paper \"MineRL: A large-scale dataset of Minecraft demonstrations\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"RUSLAN SALAKHUTDINOV","type":"PERSON","description":"Ruslan Salakhutdinov is an author of the paper \"MineRL: A large-scale dataset of Minecraft demonstrations\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"IJCAI","type":"CONFERENCE","description":"IJCAI is the conference where the paper \"MineRL: A large-scale dataset of Minecraft demonstrations\" was presented","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"CONFERENCE"},{"name":"DANIJAR HAFNER","type":"PERSON","description":"Danijar Hafner is an author of the paper \"Mastering diverse domains through world models\"\nDanijar Hafner is an author of the paper \"Learning latent dynamics for planning from pixels\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"TIMOTHY LILLICRAP","type":"PERSON","description":"Timothy Lillicrap is an author of the paper \"Learning latent dynamics for planning from pixels\"\nTimothy Lillicrap is an author of the paper \"Mastering diverse domains through world models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"IAN FISCHER","type":"PERSON","description":"Ian Fischer is an author of the paper \"Learning latent dynamics for planning from pixels\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"RUBEN VILLEGAS","type":"PERSON","description":"Ruben Villegas is an author of the paper \"Learning latent dynamics for planning from pixels\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"DAVID HA","type":"PERSON","description":"David Ha is an author of the paper \"Learning latent dynamics for planning from pixels\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"HONGLAK LEE","type":"PERSON","description":"Honglak Lee is an author of the paper \"Learning latent dynamics for planning from pixels\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"JAMES DAVIDSON","type":"PERSON","description":"James Davidson is an author of the paper \"Learning latent dynamics for planning from pixels\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"JURGIS PASUKONIS","type":"PERSON","description":"Jurgis Pasukonis is an author of the paper \"Mastering diverse domains through world models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"JIMMY BA","type":"PERSON","description":"Jimmy Ba is an author of the paper \"Mastering diverse domains through world models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"ARXIV","type":"PUBLICATION","description":"arXiv is the platform where the paper \"Mastering diverse domains through world models\" was published","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PUBLICATION"},{"name":"SHIBO HAO","type":"PERSON","description":"Shibo Hao is an author of the paper \"Reasoning with language model is planning with world model\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"YI GU","type":"PERSON","description":"Yi Gu is an author of the paper \"Reasoning with language model is planning with world model\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"HAODI MA","type":"PERSON","description":"Haodi Ma is an author of the paper \"Reasoning with language model is planning with world model\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"JOSHUA JIAHUA HONG","type":"PERSON","description":"Joshua Jiahua Hong is an author of the paper \"Reasoning with language model is planning with world model\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"ZHEN WANG","type":"PERSON","description":"Zhen Wang is an author of the paper \"Reasoning with language model is planning with world model\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"DAISY ZHE WANG","type":"PERSON","description":"Daisy Zhe Wang is an author of the paper \"Reasoning with language model is planning with world model\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"ZHTING HU","type":"PERSON","description":"Zhiting Hu is an author of the paper \"Reasoning with language model is planning with world model\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"EMNLP","type":"CONFERENCE","description":"EMNLP is the conference where the paper \"Reasoning with language model is planning with world model\" was presented","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"CONFERENCE"},{"name":"JIE HUANG","type":"PERSON","description":"Jie Huang is an author of the paper \"Large language models cannot self-correct reasoning yet\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"XINYUN CHEN","type":"PERSON","description":"Xinyun Chen is an author of the paper \"Large language models cannot self-correct reasoning yet\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"SWAROOP MISHRA","type":"PERSON","description":"Swaroop Mishra is an author of the paper \"Large language models cannot self-correct reasoning yet\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"HUAIXIU STEVEN ZHENG","type":"PERSON","description":"Huaixiu Steven Zheng is an author of the paper \"Large language models cannot self-correct reasoning yet\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"ADAMS WEI YU","type":"PERSON","description":"Adams Wei Yu is an author of the paper \"Large language models cannot self-correct reasoning yet\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"XINYING SONG","type":"PERSON","description":"Xinying Song is an author of the paper \"Large language models cannot self-correct reasoning yet\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"DENNY ZHOU","type":"PERSON","description":"Denny Zhou is an author of the paper \"Large language models cannot self-correct reasoning yet\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"WENLONG HUANG","type":"PERSON","description":"Wenlong Huang is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"F. XIA","type":"PERSON","description":"F. Xia is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"TED XIAO","type":"PERSON","description":"Ted Xiao is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"HARRIS CHAN","type":"PERSON","description":"Harris Chan is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"JACKY LIANG","type":"PERSON","description":"Jacky Liang is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"PETER R. FLORENCE","type":"PERSON","description":"Peter R. Florence is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"ANDY ZENG","type":"PERSON","description":"Andy Zeng is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"JONATHAN TOMPSON","type":"PERSON","description":"Jonathan Tompson is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"IGOR MORDATCH","type":"PERSON","description":"Igor Mordatch is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"YEVGEN CHEBOTAR","type":"PERSON","description":"Yevgen Chebotar is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"PIERRE SERMANET","type":"PERSON","description":"Pierre Sermanet is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"NOAH BROWN","type":"PERSON","description":"Noah Brown is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"TOMAS JACKSON","type":"PERSON","description":"Tomas Jackson is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"LINDA LUU","type":"PERSON","description":"Linda Luu is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"SERGEY LEVINE","type":"PERSON","description":"Sergey Levine is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"KAROL HAUSMAN","type":"PERSON","description":"Karol Hausman is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"BRIAN ICHTER","type":"PERSON","description":"Brian Ichter is an author of the paper \"Inner monologue: Embodied reasoning through planning with\nBrian Ichter is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"","source_id":"68e5573b596d253a03047b1e41988598","entity_type":"PERSON"},{"name":"JIAXIAN GUO","type":"PERSON","description":"Jiaxian Guo is an author of the paper \"Long text generation via adversarial training with leaked information\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"CORL","type":"CONFERENCE","description":"CoRL is the conference where the paper \"Inner monologue: Embodied reasoning through planning with language models\" was presented","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"LEVENTE KOCSIS","type":"PERSON","description":"Levente Kocsis is an author of the paper \"Bandit based monte-carlo planning\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"CSABA SZEPESVARI","type":"PERSON","description":"Csaba Szepesvari is an author of the paper \"Bandit based monte-carlo planning\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"ECML","type":"CONFERENCE","description":"ECML is the conference where the paper \"Bandit based monte-carlo planning\" was presented","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"TAKESHI KOJIMA","type":"PERSON","description":"Takeshi Kojima is an author of the paper \"Large language models are zero-shot reasoners\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"MACHEL REID","type":"PERSON","description":"Machel Reid is an author of the paper \"Large language models are zero-shot reasoners\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"YUSUKE IWASAWA","type":"PERSON","description":"Yusuke Iwasawa is an author of the paper \"Large language models are zero-shot reasoners\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"STEVEN M. LAVALLE","type":"PERSON","description":"Steven M. LaValle is the author of the paper \"Rapidly-exploring random trees: A new tool for path planning\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"THE ANNUAL RESEARCH REPORT","type":"PUBLICATION","description":"The Annual Research Report is the publication where the paper \"Rapidly-exploring random trees: A new tool for path planning\" was published","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"EVAN ZHERAN LIU","type":"PERSON","description":"Evan Zheran Liu is an author of the paper \"Reinforcement learning on web interfaces using workflow-guided exploration\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"KELVIN GUU","type":"PERSON","description":"Kelvin Guu is an author of the paper \"Reinforcement learning on web interfaces using workflow-guided exploration\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"PANUPONG PASUPAT","type":"PERSON","description":"Panupong Pasupat is an author of the paper \"Reinforcement learning on web interfaces using workflow-guided exploration\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"TIANLIN SHI","type":"PERSON","description":"Tianlin Shi is an author of the paper \"Reinforcement learning on web interfaces using workflow-guided exploration\"","source_id":"68e5573b596d253a03047b1e41988598"},{"name":"PERCY LIANG","type":"PERSON","description":"Percy Liang is an author of the paper \"Reinforcement learning on web interfaces using workflow-guided exploration\"","source_id":"68e5573b596d253a03047b1e41988598"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"MENGJIAO YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mengjiao Yang is an author of the paper \"Learning universal policies via text-guided video generation\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"BO DAI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bo Dai is an author of the paper \"Learning universal policies via text-guided video generation\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"HANJUN DAI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hanjun Dai is an author of the paper \"Learning universal policies via text-guided video generation\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"OFIR NACHUM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ofir Nachum is an author of the paper \"Multimodal web navigation with instruction-finetuned foundation models\"Ofir Nachum is an author of the paper \"Learning universal policies via text-guided video generation\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JOSHUA B. TENENBAUM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joshua B. Tenenbaum is an author of the paper \"Learning universal policies via text-guided video generation\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"DALE SCHUURMANS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dale Schuurmans is an author of the paper \"Learning universal policies via text-guided video generation\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"PIETER ABBEEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pieter Abbeel is an author of the paper \"Learning universal policies via text-guided video generation\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"NEURIPS\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">NeurIPS is the conference where the paper \"Learning universal policies via text-guided video generation\" was presentedNeurIPS is the conference where the paper \"Large language models are zero-shot reasoners\" was presented<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">CONFERENCE<\/data>    <\/node>    <node id=\"JONATHAN ST BT EVANS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jonathan St BT Evans is the author of the paper \"Intuition and reasoning: A dual-process perspective\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PSYCHOLOGICAL INQUIRY\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Psychological Inquiry is the journal where the paper \"Intuition and reasoning: A dual-process perspective\" was published<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"LINXI FAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Linxi Fan is an author of the paper \"MineDojo: Building open-ended embodied agents with internet-scale knowledge\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"GUANZHI WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Guanzhi Wang is an author of the paper \"MineDojo: Building open-ended embodied agents with internet-scale knowledge\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"YUNFAN JIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yunfan Jiang is an author of the paper \"MineDojo: Building open-ended embodied agents with internet-scale knowledge\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"AJAY MANDLEKAR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ajay Mandlekar is an author of the paper \"MineDojo: Building open-ended embodied agents with internet-scale knowledge\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"YUNCONG YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yuncong Yang is an author of the paper \"MineDojo: Building open-ended embodied agents with internet-scale knowledge\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"HAOYI ZHU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Haoyi Zhu is an author of the paper \"MineDojo: Building open-ended embodied agents with internet-scale knowledge\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"ANDREW TANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Andrew Tang is an author of the paper \"MineDojo: Building open-ended embodied agents with internet-scale knowledge\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"DE-AN HUANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">De-An Huang is an author of the paper \"MineDojo: Building open-ended embodied agents with internet-scale knowledge\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"YUKE ZHU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yuke Zhu is an author of the paper \"MineDojo: Building open-ended embodied agents with internet-scale knowledge\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"ANIMA ANANDKUMAR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Anima Anandkumar is an author of the paper \"MineDojo: Building open-ended embodied agents with internet-scale knowledge\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"NEURIPS DATASETS AND BENCHMARKS TRACK\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">NeurIPS Datasets and Benchmarks Track is the conference where the paper \"MineDojo: Building open-ended embodied agents with internet-scale knowledge\" was presented<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"HIROKI FURUTA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hiroki Furuta is an author of the paper \"Multimodal web navigation with instruction-finetuned foundation models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KUANG-HUEI LEE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kuang-Huei Lee is an author of the paper \"Multimodal web navigation with instruction-finetuned foundation models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YUTAKA MATSUO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yutaka Matsuo is an author of the paper \"Large language models are zero-shot reasoners\"Yutaka Matsuo is an author of the paper \"Multimodal web navigation with instruction-finetuned foundation models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHIXIANG SHANE GU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shixiang Shane Gu is an author of the paper \"Multimodal web navigation with instruction-finetuned foundation models\"Shixiang Shane Gu is an author of the paper \"Large language models are zero-shot reasoners\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"IZZEDDIN GUR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Izzeddin Gur is an author of the paper \"Multimodal web navigation with instruction-finetuned foundation models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ICLR\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">ICLR is the conference where the paper \"Reinforcement learning on web interfaces using workflow-guided exploration\" was presentedICLR is the conference where the paper \"Multimodal web navigation with instruction-finetuned foundation models\" was presentedICLR is the conference where the paper \"Large language models cannot self-correct reasoning yet\" was presented<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">CONFERENCE<\/data>    <\/node>    <node id=\"LUYU GAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Luyu Gao is an author of the paper \"PAL: Program-aided language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"AMAN MADAAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Aman Madaan is an author of the paper \"PAL: Program-aided language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHUYAN ZHOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shuyan Zhou is an author of the paper \"PAL: Program-aided language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"URI ALON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Uri Alon is an author of the paper \"PAL: Program-aided language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PENGFEI LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pengfei Liu is an author of the paper \"PAL: Program-aided language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YIMING YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yiming Yang is an author of the paper \"PAL: Program-aided language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JAMIE CALLAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jamie Callan is an author of the paper \"PAL: Program-aided language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GRAHAM NEUBIG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Graham Neubig is an author of the paper \"PAL: Program-aided language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ICML\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">ICML is the conference where the paper \"PAL: Program-aided language models\" was presentedICML is the conference where the paper \"An embodied multi-modal language model\" was presentedICML is the conference where the paper \"Learning latent dynamics for planning from pixels\" was presented<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">CONFERENCE<\/data>    <\/node>    <node id=\"JIANXIAN GUO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jiaxian Guo is an author of the paper \"Long text generation via adversarial training with leaked information\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"SIDI LU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sidi Lu is an author of the paper \"Long text generation via adversarial training with leaked information\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HAN CAI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Han Cai is an author of the paper \"Long text generation via adversarial training with leaked information\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WEINAN ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Weinan Zhang is an author of the paper \"Long text generation via adversarial training with leaked information\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YONG YU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yong Yu is an author of the paper \"Long text generation via adversarial training with leaked information\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JUN WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jun Wang is an author of the paper \"Long text generation via adversarial training with leaked information\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"AAAI\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">AAAI is the conference where the paper \"Long text generation via adversarial training with leaked information\" was presented<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">CONFERENCE<\/data>    <\/node>    <node id=\"WILLIAM H. GUSS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">William H. Guss is an author of the paper \"MineRL: A large-scale dataset of Minecraft demonstrations\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BRANDON HOUGHTON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Brandon Houghton is an author of the paper \"MineRL: A large-scale dataset of Minecraft demonstrations\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NICHOLAY TOPIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nicholay Topin is an author of the paper \"MineRL: A large-scale dataset of Minecraft demonstrations\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PHILLIP WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Phillip Wang is an author of the paper \"MineRL: A large-scale dataset of Minecraft demonstrations\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CAYDEN CODEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Cayden Codel is an author of the paper \"MineRL: A large-scale dataset of Minecraft demonstrations\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MANUELA VELOSO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Manuela Veloso is an author of the paper \"MineRL: A large-scale dataset of Minecraft demonstrations\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"RUSLAN SALAKHUTDINOV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ruslan Salakhutdinov is an author of the paper \"MineRL: A large-scale dataset of Minecraft demonstrations\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"IJCAI\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">IJCAI is the conference where the paper \"MineRL: A large-scale dataset of Minecraft demonstrations\" was presented<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">CONFERENCE<\/data>    <\/node>    <node id=\"DANIJAR HAFNER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Danijar Hafner is an author of the paper \"Mastering diverse domains through world models\"Danijar Hafner is an author of the paper \"Learning latent dynamics for planning from pixels\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TIMOTHY LILLICRAP\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Timothy Lillicrap is an author of the paper \"Learning latent dynamics for planning from pixels\"Timothy Lillicrap is an author of the paper \"Mastering diverse domains through world models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"IAN FISCHER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ian Fischer is an author of the paper \"Learning latent dynamics for planning from pixels\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"RUBEN VILLEGAS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ruben Villegas is an author of the paper \"Learning latent dynamics for planning from pixels\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DAVID HA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">David Ha is an author of the paper \"Learning latent dynamics for planning from pixels\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HONGLAK LEE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Honglak Lee is an author of the paper \"Learning latent dynamics for planning from pixels\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JAMES DAVIDSON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">James Davidson is an author of the paper \"Learning latent dynamics for planning from pixels\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JURGIS PASUKONIS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jurgis Pasukonis is an author of the paper \"Mastering diverse domains through world models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JIMMY BA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jimmy Ba is an author of the paper \"Mastering diverse domains through world models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ARXIV\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">arXiv is the platform where the paper \"Mastering diverse domains through world models\" was published<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"SHIBO HAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shibo Hao is an author of the paper \"Reasoning with language model is planning with world model\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YI GU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yi Gu is an author of the paper \"Reasoning with language model is planning with world model\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HAODI MA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Haodi Ma is an author of the paper \"Reasoning with language model is planning with world model\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JOSHUA JIAHUA HONG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joshua Jiahua Hong is an author of the paper \"Reasoning with language model is planning with world model\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHEN WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhen Wang is an author of the paper \"Reasoning with language model is planning with world model\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DAISY ZHE WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Daisy Zhe Wang is an author of the paper \"Reasoning with language model is planning with world model\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHTING HU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhiting Hu is an author of the paper \"Reasoning with language model is planning with world model\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"EMNLP\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">EMNLP is the conference where the paper \"Reasoning with language model is planning with world model\" was presented<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">CONFERENCE<\/data>    <\/node>    <node id=\"JIE HUANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jie Huang is an author of the paper \"Large language models cannot self-correct reasoning yet\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XINYUN CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xinyun Chen is an author of the paper \"Large language models cannot self-correct reasoning yet\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SWAROOP MISHRA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Swaroop Mishra is an author of the paper \"Large language models cannot self-correct reasoning yet\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HUAIXIU STEVEN ZHENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Huaixiu Steven Zheng is an author of the paper \"Large language models cannot self-correct reasoning yet\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ADAMS WEI YU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Adams Wei Yu is an author of the paper \"Large language models cannot self-correct reasoning yet\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XINYING SONG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xinying Song is an author of the paper \"Large language models cannot self-correct reasoning yet\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DENNY ZHOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Denny Zhou is an author of the paper \"Large language models cannot self-correct reasoning yet\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WENLONG HUANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wenlong Huang is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"F. XIA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">F. Xia is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TED XIAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ted Xiao is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HARRIS CHAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Harris Chan is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JACKY LIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jacky Liang is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PETER R. FLORENCE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Peter R. Florence is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ANDY ZENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Andy Zeng is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JONATHAN TOMPSON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jonathan Tompson is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"IGOR MORDATCH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Igor Mordatch is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YEVGEN CHEBOTAR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yevgen Chebotar is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PIERRE SERMANET\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pierre Sermanet is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NOAH BROWN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Noah Brown is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TOMAS JACKSON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tomas Jackson is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LINDA LUU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Linda Luu is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SERGEY LEVINE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sergey Levine is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KAROL HAUSMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Karol Hausman is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BRIAN ICHTER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Brian Ichter is an author of the paper \"Inner monologue: Embodied reasoning through planning withBrian Ichter is an author of the paper \"Inner monologue: Embodied reasoning through planning with language models\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JIAXIAN GUO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jiaxian Guo is an author of the paper \"Long text generation via adversarial training with leaked information\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"CORL\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">CoRL is the conference where the paper \"Inner monologue: Embodied reasoning through planning with language models\" was presented<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"LEVENTE KOCSIS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Levente Kocsis is an author of the paper \"Bandit based monte-carlo planning\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"CSABA SZEPESVARI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Csaba Szepesvari is an author of the paper \"Bandit based monte-carlo planning\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"ECML\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">ECML is the conference where the paper \"Bandit based monte-carlo planning\" was presented<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"TAKESHI KOJIMA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Takeshi Kojima is an author of the paper \"Large language models are zero-shot reasoners\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"MACHEL REID\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Machel Reid is an author of the paper \"Large language models are zero-shot reasoners\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"YUSUKE IWASAWA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yusuke Iwasawa is an author of the paper \"Large language models are zero-shot reasoners\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"STEVEN M. LAVALLE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Steven M. LaValle is the author of the paper \"Rapidly-exploring random trees: A new tool for path planning\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"THE ANNUAL RESEARCH REPORT\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The Annual Research Report is the publication where the paper \"Rapidly-exploring random trees: A new tool for path planning\" was published<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"EVAN ZHERAN LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Evan Zheran Liu is an author of the paper \"Reinforcement learning on web interfaces using workflow-guided exploration\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"KELVIN GUU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kelvin Guu is an author of the paper \"Reinforcement learning on web interfaces using workflow-guided exploration\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"PANUPONG PASUPAT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Panupong Pasupat is an author of the paper \"Reinforcement learning on web interfaces using workflow-guided exploration\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"TIANLIN SHI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tianlin Shi is an author of the paper \"Reinforcement learning on web interfaces using workflow-guided exploration\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>    <node id=\"PERCY LIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Percy Liang is an author of the paper \"Reinforcement learning on web interfaces using workflow-guided exploration\"<\/data>      <data key=\"d2\">68e5573b596d253a03047b1e41988598<\/data>    <\/node>  <\/graph><\/graphml>"}
{"id":"2d4672dfb7bd4283f0b5f23ab4f26653","chunk":" efficiency.\narXiv:2309.17382 , 2023.\nAman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hal-\nlinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha\nDziri, Shrimai Prabhumoye, Yiming Yang, Shashank\nGupta, Bodhisattwa Prasad Majumder, Katherine Her-\nmann, Sean Welleck, Amir Yazdanbakhsh, and Peter\nClark. Self-refine: Iterative refinement with self-feedback.\nInNeurIPS , 2023.\nRamesh Nallapati, Bowen Zhou, Cicero dos Santos, Caglar\nGulcehre, and Bing Xiang. Abstractive text summariza-\ntion using sequence-to-sequence RNNs and beyond. In\nSpecial Interest Group on Natural Language Learning ,\n2016.\nOpenAI. GPT-4 technical report. arXiv:2303.08774 , 2023.\nYujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan\nYan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill\nQian, Sihan Zhao, Runchu Tian, Ruobing Xie, Jie Zhou,\nMark Gerstein, Dahai Li, Zhiyuan Liu, and Maosong Sun.\nToolLLM: Facilitating large language models to master\n16000+ real-world APIs. In ICLR , 2024.\nAbulhair Saparov and He He. Language models are greedy\nreasoners: A systematic formal analysis of chain-of-\nthought. In ICLR , 2023.\nTimo Schick, Jane Dwivedi-Yu, Roberto Dess `\u0131, Roberta\nRaileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Can-\ncedda, and Thomas Scialom. Toolformer: Language\nmodels can teach themselves to use tools. In NeurIPS ,\n2023.\nYongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li,\nWeiming Lu, and Yueting Zhuang. HuggingGPT: Solving\nAI tasks with ChatGPT and its friends in Hugging Face.\nInNeurIPS , 2023.\nNoah Shinn, Federico Cassano, Beck Labash, Ashwin\nGopinath, Karthik Narasimhan, and Shunyu Yao. Reflex-\nion: Language agents with verbal reinforcement learning.\nInNeurIPS , 2023.\nMohit Shridhar, Xingdi Yuan, Marc-Alexandre C \u02c6ot\u00b4e,\nYonatan Bisk, Adam Trischler, and Matthew Hausknecht.\nALFWorld: Aligning text and embodied environments\nfor interactive learning. In ICLR , 2020.David Silver, Aja Huang, Chris J. Maddison, Arthur Guez,\nL. Sifre, George van den Driessche, Julian Schrittwieser,\nIoannis Antonoglou, Vedavyas Panneershelvam, Marc\nLanctot, Sander Dieleman, Dominik Grewe, John Nham,\nNal Kalchbrenner, Ilya Sutskever, Timothy P. Lillicrap,\nMadeleine Leach, Koray Kavukcuoglu, Thore Graepel,\nand Demis Hassabis. Mastering the game of Go with deep\nneural networks and tree search. Nature , 529:484\u2013489,\n2016.\nDavid Silver, Aja Huang, Chris J. Maddison, Arthur Guez,\nL. Sifre, George van den Driessche, Julian Schrittwieser,\nIoannis Antonoglou, Vedavyas Panneershelvam, Marc\nLanctot, Sander Dieleman, Dominik Grewe, John Nham,\nNal Kalchbrenner, Ilya Sutskever, Timothy P. Lillicrap,\nMadeleine Leach, Koray Kavukcuoglu, Thore Graepel,\nand Demis Hassabis. Mastering chess and Shogi by self-\nplay with a general reinforcement learning algorithm.\narXiv:1712.01815 , 2017.\nSteven A. Sloman. The empirical case for two systems of\nreasoning. Psychological Bulletin , 119:3\u201322, 1996.\nHaotian Sun, Yuchen Zhuang, Lingkai Kong, Bo Dai, and\nChao Zhang. AdaPlanner: Adaptive planning from feed-\nback with language models. In NeurIPS , 2023.\nD\u00b4\u0131dac Sur \u00b4\u0131s, Sachit Menon, and Carl V ondrick. ViperGPT:\nVisual inference via Python execution for reasoning. In\nICCV , 2023.\nMaciej Swiechowski, Konrad Godlewski, Bartosz Sawicki,\nand Jacek Ma\u2019ndziuk. Monte Carlo tree search: A re-\nview of recent modifications and applications. Artificial\nIntelligence Review , 56:2497\u20132562, 2021.\nHugo Touvron, Louis Martin, Kevin R. Stone, Peter Al-\nbert, Amjad Almahairi, Yasmine Babaei, Nikolay Bash-\nlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhos-\nale, Daniel M. Bikel, Lukas Blecher, Cristian Cant \u00b4on\nFerrer, Moya Chen, Guillem Cucurull","chunk_id":"2d4672dfb7bd4283f0b5f23ab4f26653","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"AMAN MADAAN","type":"PERSON","description":"Aman Madaan is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"NIKET TANDON","type":"PERSON","description":"Niket Tandon is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"PRAKHAR GUPTA","type":"PERSON","description":"Prakhar Gupta is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"SKYLER HALLINAN","type":"PERSON","description":"Skyler Hallinan is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"LUYU GAO","type":"PERSON","description":"Luyu Gao is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"SARAH WIEGREFFE","type":"PERSON","description":"Sarah Wiegreffe is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"URI ALON","type":"PERSON","description":"Uri Alon is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"NOUHA DZIRI","type":"PERSON","description":"Nouha Dziri is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"SHRIMAI PRABHUMOYE","type":"PERSON","description":"Shrimai Prabhumoye is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"YIMING YANG","type":"PERSON","description":"Yiming Yang is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"SHASHANK GUPTA","type":"PERSON","description":"Shashank Gupta is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"BODHISATTWA PRASAD MAJUMDER","type":"PERSON","description":"Bodhisattwa Prasad Majumder is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"KATHERINE HERMANN","type":"PERSON","description":"Katherine Hermann is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"SEAN WELLECK","type":"PERSON","description":"Sean Welleck is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"AMIR YAZDANBAKHSH","type":"PERSON","description":"Amir Yazdanbakhsh is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"PETER CLARK","type":"PERSON","description":"Peter Clark is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"NEURIPS","type":"CONFERENCE","description":"NeurIPS is the conference where the paper \"LLaMA: Open and efficient foundation language models\" was presented\nNeurIPS is the conference where the paper \"AdaPlanner: Adaptive planning from feedback with language models\" was presented\nNeurIPS is the conference where the paper \"Self-refine: Iterative refinement with self-feedback\" was presented","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653","entity_type":"CONFERENCE"},{"name":"RAMESH NALLAPATI","type":"PERSON","description":"Ramesh Nallapati is an author of the paper \"Abstractive text summarization using sequence-to-sequence RNNs and beyond\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"BOWEN ZHOU","type":"PERSON","description":"Bowen Zhou is an author of the paper \"Abstractive text summarization using sequence-to-sequence RNNs and beyond\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"CICERO DOS SANTOS","type":"PERSON","description":"Cicero dos Santos is an author of the paper \"Abstractive text summarization using sequence-to-sequence RNNs and beyond\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"CAGLAR GULCEHRE","type":"PERSON","description":"Caglar Gulcehre is an author of the paper \"Abstractive text summarization using sequence-to-sequence RNNs and beyond\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"BING XIANG","type":"PERSON","description":"Bing Xiang is an author of the paper \"Abstractive text summarization using sequence-to-sequence RNNs and beyond\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"SPECIAL INTEREST GROUP ON NATURAL LANGUAGE LEARNING","type":"CONFERENCE","description":"The conference where the paper \"Abstractive text summarization using sequence-to-sequence RNNs and beyond\" was presented","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"OPENAI","type":"ORGANIZATION","description":"OpenAI is the organization behind the GPT-4 technical report","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"GPT-4","type":"MODEL","description":"GPT-4 is a language model developed by OpenAI, as described in the technical report","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"YUJIA QIN","type":"PERSON","description":"Yujia Qin is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"SHIHAO LIANG","type":"PERSON","description":"Shihao Liang is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"YINING YE","type":"PERSON","description":"Yining Ye is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"KUNLUN ZHU","type":"PERSON","description":"Kunlun Zhu is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"LAN YAN","type":"PERSON","description":"Lan Yan is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"YAXI LU","type":"PERSON","description":"Yaxi Lu is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"YANKAI LIN","type":"PERSON","description":"Yankai Lin is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"XIN CONG","type":"PERSON","description":"Xin Cong is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"XIANGRU TANG","type":"PERSON","description":"Xiangru Tang is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"BILL QIAN","type":"PERSON","description":"Bill Qian is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"SIHAN ZHAO","type":"PERSON","description":"Sihan Zhao is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"RUNCHU TIAN","type":"PERSON","description":"Runchu Tian is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"RUOBING XIE","type":"PERSON","description":"Ruobing Xie is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"JIE ZHOU","type":"PERSON","description":"Jie Zhou is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"MARK GERSTEIN","type":"PERSON","description":"Mark Gerstein is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"DAHAI LI","type":"PERSON","description":"Dahai Li is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"ZHIYUAN LIU","type":"PERSON","description":"Zhiyuan Liu is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"MAOSONG SUN","type":"PERSON","description":"Maosong Sun is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"ICLR","type":"CONFERENCE","description":"ICLR is the conference where the paper \"ALFWorld: Aligning text and embodied environments for interactive learning\" was presented\nICLR is the conference where the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\" was presented","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653","entity_type":"CONFERENCE"},{"name":"ABULHAIR SAPAROV","type":"PERSON","description":"Abulhair Saparov is an author of the paper \"Language models are greedy reasoners: A systematic formal analysis of chain-of-thought\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"HE HE","type":"PERSON","description":"He He is an author of the paper \"Language models are greedy reasoners: A systematic formal analysis of chain-of-thought\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"TIMO SCHICK","type":"PERSON","description":"Timo Schick is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"JANE DWIVEDI-YU","type":"PERSON","description":"Jane Dwivedi-Yu is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"ROBERTO DESSI","type":"PERSON","description":"Roberto Dessi is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"ROBERTA RAILEANU","type":"PERSON","description":"Roberta Raileanu is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"MARIA LOMELI","type":"PERSON","description":"Maria Lomeli is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"LUKE ZETTLEMOYER","type":"PERSON","description":"Luke Zettlemoyer is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"NICOLA CANCEDDA","type":"PERSON","description":"Nicola Cancedda is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"THOMAS SCIALOM","type":"PERSON","description":"Thomas Scialom is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"YONGLIANG SHEN","type":"PERSON","description":"Yongliang Shen is an author of the paper \"HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"KAITAO SONG","type":"PERSON","description":"Kaitao Song is an author of the paper \"HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"XU TAN","type":"PERSON","description":"Xu Tan is an author of the paper \"HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"DONGSHENG LI","type":"PERSON","description":"Dongsheng Li is an author of the paper \"HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"WEIMING LU","type":"PERSON","description":"Weiming Lu is an author of the paper \"HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"YUETING ZHUANG","type":"PERSON","description":"Yueting Zhuang is an author of the paper \"HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"NOAH SHINN","type":"PERSON","description":"Noah Shinn is an author of the paper \"Reflexion: Language agents with verbal reinforcement learning\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"FEDERICO CASSANO","type":"PERSON","description":"Federico Cassano is an author of the paper \"Reflexion: Language agents with verbal reinforcement learning\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"BECK LABASH","type":"PERSON","description":"Beck Labash is an author of the paper \"Reflexion: Language agents with verbal reinforcement learning\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"ASHWIN GOPINATH","type":"PERSON","description":"Ashwin Gopinath is an author of the paper \"Reflexion: Language agents with verbal reinforcement learning\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"KARTHIK NARASIMHAN","type":"PERSON","description":"Karthik Narasimhan is an author of the paper \"Reflexion: Language agents with verbal reinforcement learning\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"SHUNYU YAO","type":"PERSON","description":"Shunyu Yao is an author of the paper \"Reflexion: Language agents with verbal reinforcement learning\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"MOHIT SHRIDHAR","type":"PERSON","description":"Mohit Shridhar is an author of the paper \"ALFWorld: Aligning text and embodied environments for interactive learning\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"XINGDI YUAN","type":"PERSON","description":"Xingdi Yuan is an author of the paper \"ALFWorld: Aligning text and embodied environments for interactive learning\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"MARC-ALEXANDRE COTE","type":"PERSON","description":"Marc-Alexandre Cote is an author of the paper \"ALFWorld: Aligning text and embodied environments for interactive learning\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"YONATAN BISK","type":"PERSON","description":"Yonatan Bisk is an author of the paper \"ALFWorld: Aligning text and embodied environments for interactive learning\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"ADAM TRISCHLER","type":"PERSON","description":"Adam Trischler is an author of the paper \"ALFWorld: Aligning text and embodied environments for interactive learning\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"MATTHEW HAUSKNECHT","type":"PERSON","description":"Matthew Hausknecht is an author of the paper \"ALFWorld: Aligning text and embodied environments for interactive learning\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"DAVID SILVER","type":"PERSON","description":"David Silver is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"\nDavid Silver is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653","entity_type":"PERSON"},{"name":"AJA HUANG","type":"PERSON","description":"Aja Huang is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"\nAja Huang is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653","entity_type":"PERSON"},{"name":"CHRIS J. MADDISON","type":"PERSON","description":"Chris J. Maddison is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"\nChris J. Maddison is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653","entity_type":"PERSON"},{"name":"ARTHUR GUEZ","type":"PERSON","description":"Arthur Guez is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"\nArthur Guez is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653","entity_type":"PERSON"},{"name":"L. SIFRE","type":"PERSON","description":"L. Sifre is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"\nL. Sifre is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653","entity_type":"PERSON"},{"name":"GEORGE VAN DEN DRIESSCHE","type":"PERSON","description":"George van den Driessche is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"\nGeorge van den Driessche is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653","entity_type":"PERSON"},{"name":"JULIAN SCHRITTWIESER","type":"PERSON","description":"Julian Schrittwieser is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"\nJulian Schrittwieser is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653","entity_type":"PERSON"},{"name":"IOANNIS ANTONOGLOU","type":"PERSON","description":"Ioannis Antonoglou is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"\nIoannis Antonoglou is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653","entity_type":"PERSON"},{"name":"VEDAVYAS PANNEERSHELVAM","type":"PERSON","description":"Vedavyas Panneershelvam is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"\nVedavyas Panneershelvam is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653","entity_type":"PERSON"},{"name":"MARC LANCTOT","type":"PERSON","description":"Marc Lanctot is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"\nMarc Lanctot is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653","entity_type":"PERSON"},{"name":"SANDER DIELEMAN","type":"PERSON","description":"Sander Dieleman is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"\nSander Dieleman is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653","entity_type":"PERSON"},{"name":"DOMINIK GREWE","type":"PERSON","description":"Dominik Grewe is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"\nDominik Grewe is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653","entity_type":"PERSON"},{"name":"JOHN NHAM","type":"PERSON","description":"John Nham is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"\nJohn Nham is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653","entity_type":"PERSON"},{"name":"NAL KALCHBRENNER","type":"PERSON","description":"Nal Kalchbrenner is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"\nNal Kalchbrenner is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653","entity_type":"PERSON"},{"name":"ILYA SUTSKEVER","type":"PERSON","description":"Ilya Sutskever is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"\nIlya Sutskever is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653","entity_type":"PERSON"},{"name":"TIMOTHY P. LILLICRAP","type":"PERSON","description":"Timothy P. Lillicrap is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"\nTimothy P. Lillicrap is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653","entity_type":"PERSON"},{"name":"MADELEINE LEACH","type":"PERSON","description":"Madeleine Leach is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"\nMadeleine Leach is an author of the paper \"Master","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653","entity_type":"PERSON"},{"name":"NATURE","type":"PUBLICATION","description":"Nature is the journal where the paper \"Mastering the game of Go with deep neural networks and tree search\" was published","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"KORAY KAVUKCUOGLU","type":"PERSON","description":"Koray Kavukcuoglu is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"THORE GRAEPEL","type":"PERSON","description":"Thore Graepel is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"DEMIS HASSABIS","type":"PERSON","description":"Demis Hassabis is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"ARXIV","type":"PUBLICATION","description":"arXiv is the repository where the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\" was published","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"STEVEN A. SLOMAN","type":"PERSON","description":"Steven A. Sloman is the author of the paper \"The empirical case for two systems of reasoning\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"PSYCHOLOGICAL BULLETIN","type":"PUBLICATION","description":"Psychological Bulletin is the journal where the paper \"The empirical case for two systems of reasoning\" was published","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"HAOTIAN SUN","type":"PERSON","description":"Haotian Sun is an author of the paper \"AdaPlanner: Adaptive planning from feedback with language models\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"YUCHEN ZHUANG","type":"PERSON","description":"Yuchen Zhuang is an author of the paper \"AdaPlanner: Adaptive planning from feedback with language models\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"LINGKAI KONG","type":"PERSON","description":"Lingkai Kong is an author of the paper \"AdaPlanner: Adaptive planning from feedback with language models\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"BO DAI","type":"PERSON","description":"Bo Dai is an author of the paper \"AdaPlanner: Adaptive planning from feedback with language models\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"CHAO ZHANG","type":"PERSON","description":"Chao Zhang is an author of the paper \"AdaPlanner: Adaptive planning from feedback with language models\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"DIDAC SURIS","type":"PERSON","description":"Didac Suris is an author of the paper \"ViperGPT: Visual inference via Python execution for reasoning\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"SACHIT MENON","type":"PERSON","description":"Sachit Menon is an author of the paper \"ViperGPT: Visual inference via Python execution for reasoning\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"CARL VONDRICK","type":"PERSON","description":"Carl Vondrick is an author of the paper \"ViperGPT: Visual inference via Python execution for reasoning\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"ICCV","type":"CONFERENCE","description":"ICCV is the conference where the paper \"ViperGPT: Visual inference via Python execution for reasoning\" was presented","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"MACIEJ SWIECHOWSKI","type":"PERSON","description":"Maciej Swiechowski is an author of the paper \"Monte Carlo tree search: A review of recent modifications and applications\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"KONRAD GODLEWSKI","type":"PERSON","description":"Konrad Godlewski is an author of the paper \"Monte Carlo tree search: A review of recent modifications and applications\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"BARTOSZ SAWICKI","type":"PERSON","description":"Bartosz Sawicki is an author of the paper \"Monte Carlo tree search: A review of recent modifications and applications\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"JACEK MA'NDZIUK","type":"PERSON","description":"Jacek Ma'ndziuk is an author of the paper \"Monte Carlo tree search: A review of recent modifications and applications\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"ARTIFICIAL INTELLIGENCE REVIEW","type":"PUBLICATION","description":"Artificial Intelligence Review is the journal where the paper \"Monte Carlo tree search: A review of recent modifications and applications\" was published","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"HUGO TOUVRON","type":"PERSON","description":"Hugo Touvron is an author of the paper \"LLaMA: Open and efficient foundation language models\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"LOUIS MARTIN","type":"PERSON","description":"Louis Martin is an author of the paper \"LLaMA: Open and efficient foundation language models\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"KEVIN R. STONE","type":"PERSON","description":"Kevin R. Stone is an author of the paper \"LLaMA: Open and efficient foundation language models\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"PETER ALBERT","type":"PERSON","description":"Peter Albert is an author of the paper \"LLaMA: Open and efficient foundation language models\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"AMJAD ALMAHAIRI","type":"PERSON","description":"Amjad Almahairi is an author of the paper \"LLaMA: Open and efficient foundation language models\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"YASMINE BABAEI","type":"PERSON","description":"Yasmine Babaei is an author of the paper \"LLaMA: Open and efficient foundation language models\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"NIKOLAY BASHLYKOV","type":"PERSON","description":"Nikolay Bashlykov is an author of the paper \"LLaMA: Open and efficient foundation language models\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"SOUMYA BATRA","type":"PERSON","description":"Soumya Batra is an author of the paper \"LLaMA: Open and efficient foundation language models\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"PRAJJWAL BHARGAVA","type":"PERSON","description":"Prajjwal Bhargava is an author of the paper \"LLaMA: Open and efficient foundation language models\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"SHRUTI BHOSALE","type":"PERSON","description":"Shruti Bhosale is an author of the paper \"LLaMA: Open and efficient foundation language models\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"DANIEL M. BIKEL","type":"PERSON","description":"Daniel M. Bikel is an author of the paper \"LLaMA: Open and efficient foundation language models\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"LUKAS BLECHER","type":"PERSON","description":"Lukas Blecher is an author of the paper \"LLaMA: Open and efficient foundation language models\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"CRISTIAN CANTON FERRER","type":"PERSON","description":"Cristian Canton Ferrer is an author of the paper \"LLaMA: Open and efficient foundation language models\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"MOYA CHEN","type":"PERSON","description":"Moya Chen is an author of the paper \"LLaMA: Open and efficient foundation language models\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"},{"name":"GUILLEM CUCURULL","type":"PERSON","description":"Guillem Cucurull is an author of the paper \"LLaMA: Open and efficient foundation language models\"","source_id":"2d4672dfb7bd4283f0b5f23ab4f26653"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"AMAN MADAAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Aman Madaan is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"NIKET TANDON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Niket Tandon is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"PRAKHAR GUPTA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Prakhar Gupta is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"SKYLER HALLINAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Skyler Hallinan is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"LUYU GAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Luyu Gao is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"SARAH WIEGREFFE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sarah Wiegreffe is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"URI ALON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Uri Alon is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"NOUHA DZIRI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nouha Dziri is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"SHRIMAI PRABHUMOYE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shrimai Prabhumoye is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"YIMING YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yiming Yang is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"SHASHANK GUPTA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shashank Gupta is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"BODHISATTWA PRASAD MAJUMDER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bodhisattwa Prasad Majumder is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"KATHERINE HERMANN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Katherine Hermann is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"SEAN WELLECK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sean Welleck is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"AMIR YAZDANBAKHSH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Amir Yazdanbakhsh is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"PETER CLARK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Peter Clark is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"NEURIPS\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">NeurIPS is the conference where the paper \"LLaMA: Open and efficient foundation language models\" was presentedNeurIPS is the conference where the paper \"AdaPlanner: Adaptive planning from feedback with language models\" was presentedNeurIPS is the conference where the paper \"Self-refine: Iterative refinement with self-feedback\" was presented<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>      <data key=\"d3\">CONFERENCE<\/data>    <\/node>    <node id=\"RAMESH NALLAPATI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ramesh Nallapati is an author of the paper \"Abstractive text summarization using sequence-to-sequence RNNs and beyond\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"BOWEN ZHOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bowen Zhou is an author of the paper \"Abstractive text summarization using sequence-to-sequence RNNs and beyond\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"CICERO DOS SANTOS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Cicero dos Santos is an author of the paper \"Abstractive text summarization using sequence-to-sequence RNNs and beyond\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"CAGLAR GULCEHRE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Caglar Gulcehre is an author of the paper \"Abstractive text summarization using sequence-to-sequence RNNs and beyond\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"BING XIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bing Xiang is an author of the paper \"Abstractive text summarization using sequence-to-sequence RNNs and beyond\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"SPECIAL INTEREST GROUP ON NATURAL LANGUAGE LEARNING\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">The conference where the paper \"Abstractive text summarization using sequence-to-sequence RNNs and beyond\" was presented<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"OPENAI\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">OpenAI is the organization behind the GPT-4 technical report<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4 is a language model developed by OpenAI, as described in the technical report<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"YUJIA QIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yujia Qin is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"SHIHAO LIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shihao Liang is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"YINING YE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yining Ye is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"KUNLUN ZHU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kunlun Zhu is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"LAN YAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lan Yan is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"YAXI LU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yaxi Lu is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"YANKAI LIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yankai Lin is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"XIN CONG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xin Cong is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"XIANGRU TANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xiangru Tang is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"BILL QIAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bill Qian is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"SIHAN ZHAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sihan Zhao is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"RUNCHU TIAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Runchu Tian is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"RUOBING XIE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ruobing Xie is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"JIE ZHOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jie Zhou is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"MARK GERSTEIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mark Gerstein is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"DAHAI LI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dahai Li is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"ZHIYUAN LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhiyuan Liu is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"MAOSONG SUN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Maosong Sun is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"ICLR\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">ICLR is the conference where the paper \"ALFWorld: Aligning text and embodied environments for interactive learning\" was presentedICLR is the conference where the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\" was presented<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>      <data key=\"d3\">CONFERENCE<\/data>    <\/node>    <node id=\"ABULHAIR SAPAROV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Abulhair Saparov is an author of the paper \"Language models are greedy reasoners: A systematic formal analysis of chain-of-thought\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"HE HE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">He He is an author of the paper \"Language models are greedy reasoners: A systematic formal analysis of chain-of-thought\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"TIMO SCHICK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Timo Schick is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"JANE DWIVEDI-YU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jane Dwivedi-Yu is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"ROBERTO DESSI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Roberto Dessi is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"ROBERTA RAILEANU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Roberta Raileanu is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"MARIA LOMELI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Maria Lomeli is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"LUKE ZETTLEMOYER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Luke Zettlemoyer is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"NICOLA CANCEDDA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nicola Cancedda is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"THOMAS SCIALOM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Thomas Scialom is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"YONGLIANG SHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yongliang Shen is an author of the paper \"HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"KAITAO SONG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kaitao Song is an author of the paper \"HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"XU TAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xu Tan is an author of the paper \"HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"DONGSHENG LI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dongsheng Li is an author of the paper \"HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"WEIMING LU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Weiming Lu is an author of the paper \"HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"YUETING ZHUANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yueting Zhuang is an author of the paper \"HuggingGPT: Solving AI tasks with ChatGPT and its friends in Hugging Face\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"NOAH SHINN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Noah Shinn is an author of the paper \"Reflexion: Language agents with verbal reinforcement learning\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"FEDERICO CASSANO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Federico Cassano is an author of the paper \"Reflexion: Language agents with verbal reinforcement learning\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"BECK LABASH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Beck Labash is an author of the paper \"Reflexion: Language agents with verbal reinforcement learning\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"ASHWIN GOPINATH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ashwin Gopinath is an author of the paper \"Reflexion: Language agents with verbal reinforcement learning\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"KARTHIK NARASIMHAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Karthik Narasimhan is an author of the paper \"Reflexion: Language agents with verbal reinforcement learning\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"SHUNYU YAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shunyu Yao is an author of the paper \"Reflexion: Language agents with verbal reinforcement learning\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"MOHIT SHRIDHAR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mohit Shridhar is an author of the paper \"ALFWorld: Aligning text and embodied environments for interactive learning\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"XINGDI YUAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xingdi Yuan is an author of the paper \"ALFWorld: Aligning text and embodied environments for interactive learning\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"MARC-ALEXANDRE COTE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Marc-Alexandre Cote is an author of the paper \"ALFWorld: Aligning text and embodied environments for interactive learning\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"YONATAN BISK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yonatan Bisk is an author of the paper \"ALFWorld: Aligning text and embodied environments for interactive learning\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"ADAM TRISCHLER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Adam Trischler is an author of the paper \"ALFWorld: Aligning text and embodied environments for interactive learning\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"MATTHEW HAUSKNECHT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Matthew Hausknecht is an author of the paper \"ALFWorld: Aligning text and embodied environments for interactive learning\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"DAVID SILVER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">David Silver is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"David Silver is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"AJA HUANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Aja Huang is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"Aja Huang is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHRIS J. MADDISON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chris J. Maddison is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"Chris J. Maddison is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ARTHUR GUEZ\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Arthur Guez is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"Arthur Guez is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"L. SIFRE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">L. Sifre is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"L. Sifre is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GEORGE VAN DEN DRIESSCHE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">George van den Driessche is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"George van den Driessche is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JULIAN SCHRITTWIESER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Julian Schrittwieser is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"Julian Schrittwieser is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"IOANNIS ANTONOGLOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ioannis Antonoglou is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"Ioannis Antonoglou is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"VEDAVYAS PANNEERSHELVAM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Vedavyas Panneershelvam is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"Vedavyas Panneershelvam is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MARC LANCTOT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Marc Lanctot is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"Marc Lanctot is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SANDER DIELEMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sander Dieleman is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"Sander Dieleman is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DOMINIK GREWE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dominik Grewe is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"Dominik Grewe is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JOHN NHAM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">John Nham is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"John Nham is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NAL KALCHBRENNER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nal Kalchbrenner is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"Nal Kalchbrenner is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ILYA SUTSKEVER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ilya Sutskever is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"Ilya Sutskever is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TIMOTHY P. LILLICRAP\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Timothy P. Lillicrap is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"Timothy P. Lillicrap is an author of the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MADELEINE LEACH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Madeleine Leach is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"Madeleine Leach is an author of the paper \"Master<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NATURE\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Nature is the journal where the paper \"Mastering the game of Go with deep neural networks and tree search\" was published<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"KORAY KAVUKCUOGLU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Koray Kavukcuoglu is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"THORE GRAEPEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Thore Graepel is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"DEMIS HASSABIS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Demis Hassabis is an author of the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"ARXIV\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">arXiv is the repository where the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\" was published<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"STEVEN A. SLOMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Steven A. Sloman is the author of the paper \"The empirical case for two systems of reasoning\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"PSYCHOLOGICAL BULLETIN\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Psychological Bulletin is the journal where the paper \"The empirical case for two systems of reasoning\" was published<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"HAOTIAN SUN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Haotian Sun is an author of the paper \"AdaPlanner: Adaptive planning from feedback with language models\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"YUCHEN ZHUANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yuchen Zhuang is an author of the paper \"AdaPlanner: Adaptive planning from feedback with language models\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"LINGKAI KONG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lingkai Kong is an author of the paper \"AdaPlanner: Adaptive planning from feedback with language models\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"BO DAI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bo Dai is an author of the paper \"AdaPlanner: Adaptive planning from feedback with language models\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"CHAO ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chao Zhang is an author of the paper \"AdaPlanner: Adaptive planning from feedback with language models\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"DIDAC SURIS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Didac Suris is an author of the paper \"ViperGPT: Visual inference via Python execution for reasoning\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"SACHIT MENON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sachit Menon is an author of the paper \"ViperGPT: Visual inference via Python execution for reasoning\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"CARL VONDRICK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Carl Vondrick is an author of the paper \"ViperGPT: Visual inference via Python execution for reasoning\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"ICCV\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">ICCV is the conference where the paper \"ViperGPT: Visual inference via Python execution for reasoning\" was presented<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"MACIEJ SWIECHOWSKI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Maciej Swiechowski is an author of the paper \"Monte Carlo tree search: A review of recent modifications and applications\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"KONRAD GODLEWSKI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Konrad Godlewski is an author of the paper \"Monte Carlo tree search: A review of recent modifications and applications\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"BARTOSZ SAWICKI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bartosz Sawicki is an author of the paper \"Monte Carlo tree search: A review of recent modifications and applications\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"JACEK MA'NDZIUK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jacek Ma'ndziuk is an author of the paper \"Monte Carlo tree search: A review of recent modifications and applications\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"ARTIFICIAL INTELLIGENCE REVIEW\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Artificial Intelligence Review is the journal where the paper \"Monte Carlo tree search: A review of recent modifications and applications\" was published<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"HUGO TOUVRON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hugo Touvron is an author of the paper \"LLaMA: Open and efficient foundation language models\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"LOUIS MARTIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Louis Martin is an author of the paper \"LLaMA: Open and efficient foundation language models\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"KEVIN R. STONE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kevin R. Stone is an author of the paper \"LLaMA: Open and efficient foundation language models\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"PETER ALBERT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Peter Albert is an author of the paper \"LLaMA: Open and efficient foundation language models\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"AMJAD ALMAHAIRI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Amjad Almahairi is an author of the paper \"LLaMA: Open and efficient foundation language models\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"YASMINE BABAEI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yasmine Babaei is an author of the paper \"LLaMA: Open and efficient foundation language models\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"NIKOLAY BASHLYKOV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nikolay Bashlykov is an author of the paper \"LLaMA: Open and efficient foundation language models\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"SOUMYA BATRA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Soumya Batra is an author of the paper \"LLaMA: Open and efficient foundation language models\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"PRAJJWAL BHARGAVA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Prajjwal Bhargava is an author of the paper \"LLaMA: Open and efficient foundation language models\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"SHRUTI BHOSALE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shruti Bhosale is an author of the paper \"LLaMA: Open and efficient foundation language models\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"DANIEL M. BIKEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Daniel M. Bikel is an author of the paper \"LLaMA: Open and efficient foundation language models\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"LUKAS BLECHER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lukas Blecher is an author of the paper \"LLaMA: Open and efficient foundation language models\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"CRISTIAN CANTON FERRER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Cristian Canton Ferrer is an author of the paper \"LLaMA: Open and efficient foundation language models\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"MOYA CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Moya Chen is an author of the paper \"LLaMA: Open and efficient foundation language models\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <node id=\"GUILLEM CUCURULL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Guillem Cucurull is an author of the paper \"LLaMA: Open and efficient foundation language models\"<\/data>      <data key=\"d2\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/node>    <edge source=\"DAVID SILVER\" target=\"AJA HUANG\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">David Silver and Aja Huang co-authored the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"David Silver and Aja Huang co-authored the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d6\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/edge>    <edge source=\"DAVID SILVER\" target=\"CHRIS J. MADDISON\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">David Silver and Chris J. Maddison co-authored the paper \"Mastering the game of Go with deep neural networks and tree search\"David Silver and Chris J. Maddison co-authored the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"<\/data>      <data key=\"d6\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/edge>    <edge source=\"DAVID SILVER\" target=\"ARTHUR GUEZ\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">David Silver and Arthur Guez co-authored the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"David Silver and Arthur Guez co-authored the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d6\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/edge>    <edge source=\"DAVID SILVER\" target=\"L. SIFRE\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">David Silver and L. Sifre co-authored the paper \"Mastering the game of Go with deep neural networks and tree search\"David Silver and L. Sifre co-authored the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"<\/data>      <data key=\"d6\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/edge>    <edge source=\"DAVID SILVER\" target=\"GEORGE VAN DEN DRIESSCHE\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">David Silver and George van den Driessche co-authored the paper \"Mastering the game of Go with deep neural networks and tree search\"David Silver and George van den Driessche co-authored the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"<\/data>      <data key=\"d6\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/edge>    <edge source=\"DAVID SILVER\" target=\"JULIAN SCHRITTWIESER\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">David Silver and Julian Schrittwieser co-authored the paper \"Mastering the game of Go with deep neural networks and tree search\"David Silver and Julian Schrittwieser co-authored the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"<\/data>      <data key=\"d6\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/edge>    <edge source=\"DAVID SILVER\" target=\"IOANNIS ANTONOGLOU\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">David Silver and Ioannis Antonoglou co-authored the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"David Silver and Ioannis Antonoglou co-authored the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d6\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/edge>    <edge source=\"DAVID SILVER\" target=\"VEDAVYAS PANNEERSHELVAM\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">David Silver and Vedavyas Panneershelvam co-authored the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"David Silver and Vedavyas Panneershelvam co-authored the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d6\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/edge>    <edge source=\"DAVID SILVER\" target=\"MARC LANCTOT\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">David Silver and Marc Lanctot co-authored the paper \"Mastering chess and Shogi by self-play with a general reinforcement learning algorithm\"David Silver and Marc Lanctot co-authored the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d6\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/edge>    <edge source=\"DAVID SILVER\" target=\"SANDER DIELEMAN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">David Silver and Sander Dieleman co-authored the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d6\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/edge>    <edge source=\"DAVID SILVER\" target=\"DOMINIK GREWE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">David Silver and Dominik Grewe co-authored the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d6\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/edge>    <edge source=\"DAVID SILVER\" target=\"JOHN NHAM\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">David Silver and John Nham co-authored the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d6\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/edge>    <edge source=\"DAVID SILVER\" target=\"NAL KALCHBRENNER\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">David Silver and Nal Kalchbrenner co-authored the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d6\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/edge>    <edge source=\"DAVID SILVER\" target=\"ILYA SUTSKEVER\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">David Silver and Ilya Sutskever co-authored the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d6\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/edge>    <edge source=\"DAVID SILVER\" target=\"TIMOTHY P. LILLICRAP\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">David Silver and Timothy P. Lillicrap co-authored the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d6\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/edge>    <edge source=\"DAVID SILVER\" target=\"MADELEINE LEACH\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">David Silver and Madeleine Leach co-authored the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d6\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/edge>    <edge source=\"DAVID SILVER\" target=\"KORAY KAVUKCUOGLU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">David Silver and Koray Kavukcuoglu co-authored the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d6\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/edge>    <edge source=\"DAVID SILVER\" target=\"THORE GRAEPEL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">David Silver and Thore Graepel co-authored the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d6\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/edge>    <edge source=\"DAVID SILVER\" target=\"DEMIS HASSABIS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">David Silver and Demis Hassabis co-authored the paper \"Mastering the game of Go with deep neural networks and tree search\"<\/data>      <data key=\"d6\">2d4672dfb7bd4283f0b5f23ab4f26653<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"8180bf20b7577f3eee40df5991e2886d","chunk":":2497\u20132562, 2021.\nHugo Touvron, Louis Martin, Kevin R. Stone, Peter Al-\nbert, Amjad Almahairi, Yasmine Babaei, Nikolay Bash-\nlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhos-\nale, Daniel M. Bikel, Lukas Blecher, Cristian Cant \u00b4on\nFerrer, Moya Chen, Guillem Cucurull, David Esiobu,\nJude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,\nCynthia Gao, Vedanuj Goswami, Naman Goyal, An-\nthony S. Hartshorn, Saghar Hosseini, Rui Hou, Hakan\nInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Is-\nabel M. Kloumann, A. V . Korenev, Punit Singh Koura,\nMarie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana\nLiskovich, Yinghai Lu, Yuning Mao, Xavier Martinet,\nTodor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin\nNie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta,\nKalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael\nSmith, R. Subramanian, Xia Tan, Binh Tang, Ross\nTaylor, Adina Williams, Jian Xiang Kuan, Puxin Xu,\nZhengxu Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,\nMelanie Kambadur, Sharan Narang, Aurelien Rodriguez,\nRobert Stojnic, Sergey Edunov, and Thomas Scialom.\n12Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nLlama 2: Open foundation and fine-tuned chat models.\narXiv:2307.09288 , 2023.\nTom V odopivec, Spyridon Samothrakis, and Branko Ster.\nOn Monte Carlo tree search and reinforcement learning.\nJournal of Artificial Intelligence Research , 60:881\u2013936,\n2017.\nGuanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar,\nChaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anand-\nkumar. V oyager: An open-ended embodied agent with\nlarge language models. arXiv:2305.16291 , 2023.\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le,\nEd Chi, and Denny Zhou. Self-consistency improves\nchain of thought reasoning in language models. In ICLR ,\n2022.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Ed Chi, Quoc Le, and Denny Zhou. Chain of\nthought prompting elicits reasoning in large language\nmodels. In NeurIPS , 2022.\nMichael Wooldridge and Nicholas R Jennings. Intelligent\nagents: Theory and practice. The Knowledge Engineering\nReview , 10:115 \u2013 152, 1995.\nPhilipp Wu, Alejandro Escontrela, Danijar Hafner, Pieter\nAbbeel, and Ken Goldberg. Daydreamer: World models\nfor physical robot learning. In CoRL , 2023.\nYuxi Xie, Kenji Kawaguchi, Yiran Zhao, Xu Zhao, Min-\nYen Kan, Junxian He, and Qizhe Xie. Decomposition\nenhances reasoning via self-evaluation guided decoding.\narXiv:2305.00633 , 2023.\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio,\nWilliam W Cohen, Ruslan Salakhutdinov, and Christo-\npher D Manning. HotpotQA: A dataset for diverse, ex-\nplainable multi-hop question answering. In EMNLP ,\n2018.\nShunyu Yao, Howard Chen, John Yang, and Karthik R\nNarasimhan. WebShop: Towards scalable real-world web\ninteraction with grounded language agents. In NeurIPS ,\n2022.\nShunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran,\nThomas L. Griffiths, Yuan Cao, and Karthik Narasimhan.\nTree of thoughts: deliberate problem solving with large\nlanguage models. In NeurIPS , 2023a.\nShunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,\nKarthik Narasimhan, and Yuan Cao. ReAct: Synergizing\nreasoning and acting in language models. In ICLR , 2023b.\nWeirui Ye, Shaohuai Liu, Thanard Kurutach, Pieter Abbeel,\nand Yang Gao. Mastering Atari games with limited data.\nInNeurIPS , 2021.Denny Zhou, Nathanael Sch \u00a8arli, Le Hou, Jason Wei, Nathan\nScales, Xuezhi Wang, Dale Schuurmans, Olivier Bous-\nquet, Quoc Le, and Ed Chi. Least-to-most prompting\nenables complex reasoning in large language models. In\nICLR , 2022.\nYuchen Zhuang, Xiang Chen, Tong Yu, Saayan Mitra, Victor\nBursztyn, Ryan A. Rossi, Somdeb Sarkhel, and Chao\nZhang. ToolChain*: Efficient action space navigation in\nlarge language models with A* search. In ICLR , ","chunk_id":"8180bf20b7577f3eee40df5991e2886d","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"HUGO TOUVRON","type":"PERSON","description":"Hugo Touvron is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"LOUIS MARTIN","type":"PERSON","description":"Louis Martin is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"KEVIN R. STONE","type":"PERSON","description":"Kevin R. Stone is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"PETER ALBERT","type":"PERSON","description":"Peter Albert is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"AMJAD ALMAHAIRI","type":"PERSON","description":"Amjad Almahairi is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"YASMINE BABAEI","type":"PERSON","description":"Yasmine Babaei is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"NIKOLAY BASHLYKOV","type":"PERSON","description":"Nikolay Bashlykov is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"SOUMYA BATRA","type":"PERSON","description":"Soumya Batra is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"PRAJJWAL BHARGAVA","type":"PERSON","description":"Prajjwal Bhargava is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"SHRUTI BHOSALE","type":"PERSON","description":"Shruti Bhosale is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"DANIEL M. BIKEL","type":"PERSON","description":"Daniel M. Bikel is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"LUKAS BLECHER","type":"PERSON","description":"Lukas Blecher is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"CRISTIAN CANT\u00d3N FERRER","type":"PERSON","description":"Cristian Cant\u00f3n Ferrer is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"MOYA CHEN","type":"PERSON","description":"Moya Chen is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"GUILLEM CUCURULL","type":"PERSON","description":"Guillem Cucurull is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"DAVID ESIOBU","type":"PERSON","description":"David Esiobu is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"JUDE FERNANDES","type":"PERSON","description":"Jude Fernandes is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"JEREMY FU","type":"PERSON","description":"Jeremy Fu is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"WENYIN FU","type":"PERSON","description":"Wenyin Fu is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"BRIAN FULLER","type":"PERSON","description":"Brian Fuller is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"CYNTHIA GAO","type":"PERSON","description":"Cynthia Gao is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"VEDANUJ GOSWAMI","type":"PERSON","description":"Vedanuj Goswami is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"NAMAN GOYAL","type":"PERSON","description":"Naman Goyal is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"ANTHONY S. HARTSHORN","type":"PERSON","description":"Anthony S. Hartshorn is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"SAGHAR HOSSEINI","type":"PERSON","description":"Saghar Hosseini is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"RUI HOU","type":"PERSON","description":"Rui Hou is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"HAKAN INAN","type":"PERSON","description":"Hakan Inan is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"MARCIN KARDAS","type":"PERSON","description":"Marcin Kardas is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"VIKTOR KERKEZ","type":"PERSON","description":"Viktor Kerkez is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"MADIAN KHABSA","type":"PERSON","description":"Madian Khabsa is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"ISABEL M. KLOUMANN","type":"PERSON","description":"Isabel M. Kloumann is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"A. V. KORENEV","type":"PERSON","description":"A. V. Korenev is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"PUNIT SINGH KOURA","type":"PERSON","description":"Punit Singh Koura is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"MARIE-ANNE LACHAUX","type":"PERSON","description":"Marie-Anne Lachaux is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"THIBAUT LAVRIL","type":"PERSON","description":"Thibaut Lavril is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"JENYA LEE","type":"PERSON","description":"Jenya Lee is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"DIANA LISKOVICH","type":"PERSON","description":"Diana Liskovich is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"YINGHAI LU","type":"PERSON","description":"Yinghai Lu is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"YUNING MAO","type":"PERSON","description":"Yuning Mao is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"XAVIER MARTINET","type":"PERSON","description":"Xavier Martinet is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"TODOR MIHAYLOV","type":"PERSON","description":"Todor Mihaylov is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"PUSHKAR MISHRA","type":"PERSON","description":"Pushkar Mishra is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"IGOR MOLYBOG","type":"PERSON","description":"Igor Molybog is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"YIXIN NIE","type":"PERSON","description":"Yixin Nie is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"ANDREW POULTON","type":"PERSON","description":"Andrew Poulton is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"JEREMY REIZENSTEIN","type":"PERSON","description":"Jeremy Reizenstein is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"RASHI RUNGTA","type":"PERSON","description":"Rashi Rungta is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"KALYAN SALADI","type":"PERSON","description":"Kalyan Saladi is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"ALAN SCHELTEN","type":"PERSON","description":"Alan Schelten is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"RUAN SILVA","type":"PERSON","description":"Ruan Silva is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"ERIC MICHAEL SMITH","type":"PERSON","description":"Eric Michael Smith is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"R. SUBRAMANIAN","type":"PERSON","description":"R. Subramanian is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"XIA TAN","type":"PERSON","description":"Xia Tan is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"BINH TANG","type":"PERSON","description":"Binh Tang is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"ROSS TAYLOR","type":"PERSON","description":"Ross Taylor is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"ADINA WILLIAMS","type":"PERSON","description":"Adina Williams is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"JIAN XIANG KUAN","type":"PERSON","description":"Jian Xiang Kuan is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"PUXIN XU","type":"PERSON","description":"Puxin Xu is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"ZHENGXU YAN","type":"PERSON","description":"Zhengxu Yan is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"ILIYAN ZAROV","type":"PERSON","description":"Iliyan Zarov is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"YUCHEN ZHANG","type":"PERSON","description":"Yuchen Zhang is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"ANGELA FAN","type":"PERSON","description":"Angela Fan is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"MELANIE KAMBADUR","type":"PERSON","description":"Melanie Kambadur is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"SHARAN NARANG","type":"PERSON","description":"Sharan Narang is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"AURELIEN RODRIGUEZ","type":"PERSON","description":"Aurelien Rodriguez is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"ROBERT STOJNIC","type":"PERSON","description":"Robert Stojnic is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"SERGEY EDUNOV","type":"PERSON","description":"Sergey Edunov is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"THOMAS SCIALOM","type":"PERSON","description":"Thomas Scialom is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"LLAMA 2","type":"MODEL","description":"Llama 2 is an open foundation and fine-tuned chat model mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"TOM VODOPIVEC","type":"PERSON","description":"Tom Vodopivec is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"SPYRIDON SAMOTHRAKIS","type":"PERSON","description":"Spyridon Samothrakis is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"BRANKO STER","type":"PERSON","description":"Branko Ster is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"GUANZHI WANG","type":"PERSON","description":"Guanzhi Wang is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"YUQI XIE","type":"PERSON","description":"Yuqi Xie is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"YUNFAN JIANG","type":"PERSON","description":"Yunfan Jiang is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"AJAY MANDLEKAR","type":"PERSON","description":"Ajay Mandlekar is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"CHAOWEI XIAO","type":"PERSON","description":"Chaowei Xiao is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"YUKE ZHU","type":"PERSON","description":"Yuke Zhu is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"LINXI FAN","type":"PERSON","description":"Linxi Fan is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"ANIMA ANANDKUMAR","type":"PERSON","description":"Anima Anandkumar is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"VOYAGER","type":"TOOL\/AGENT","description":"Voyager is an open-ended embodied agent with large language models mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"TOOL\/AGENT"},{"name":"XUEZHI WANG","type":"PERSON","description":"Xuezhi Wang is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"JASON WEI","type":"PERSON","description":"Jason Wei is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"DALE SCHUURMANS","type":"PERSON","description":"Dale Schuurmans is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"QUOC LE","type":"PERSON","description":"Quoc Le is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"ED CHI","type":"PERSON","description":"Ed Chi is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"DENNY ZHOU","type":"PERSON","description":"Denny Zhou is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"ICLR","type":"CONFERENCE","description":"ICLR is a conference where some of the mentioned papers were presented","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"CONFERENCE"},{"name":"MAARTEN BOSMA","type":"PERSON","description":"Maarten Bosma is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"NEURIPS","type":"CONFERENCE","description":"NeurIPS is a conference where some of the mentioned papers were presented","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"CONFERENCE"},{"name":"MICHAEL WOOLDRIDGE","type":"PERSON","description":"Michael Wooldridge is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"NICHOLAS R JENNINGS","type":"PERSON","description":"Nicholas R Jennings is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"THE KNOWLEDGE ENGINEERING REVIEW","type":"PUBLICATION","description":"The Knowledge Engineering Review is a publication where the paper by Michael Wooldridge and Nicholas R Jennings was published","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PUBLICATION"},{"name":"PHILIPP WU","type":"PERSON","description":"Philipp Wu is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"ALEJANDRO ESCONTRELA","type":"PERSON","description":"Alejandro Escontrela is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"DANIJAR HAFNER","type":"PERSON","description":"Danijar Hafner is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"PIETER ABBEEL","type":"PERSON","description":"Pieter Abbeel is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"KEN GOLDBERG","type":"PERSON","description":"Ken Goldberg is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"DAYDREAMER","type":"TOOL\/AGENT","description":"Daydreamer is a world model for physical robot learning mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"TOOL\/AGENT"},{"name":"CORL","type":"CONFERENCE","description":"CoRL is a conference where the paper on Daydreamer was presented","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"CONFERENCE"},{"name":"YUXI XIE","type":"PERSON","description":"Yuxi Xie is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"KENJI KAWAGUCHI","type":"PERSON","description":"Kenji Kawaguchi is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"YIRAN ZHAO","type":"PERSON","description":"Yiran Zhao is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"XU ZHAO","type":"PERSON","description":"Xu Zhao is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"MIN-YEN KAN","type":"PERSON","description":"Min-Yen Kan is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"JUNXIAN HE","type":"PERSON","description":"Junxian He is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"QIZHE XIE","type":"PERSON","description":"Qizhe Xie is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"ZHILIN YANG","type":"PERSON","description":"Zhilin Yang is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"PENG QI","type":"PERSON","description":"Peng Qi is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"SAIZHENG ZHANG","type":"PERSON","description":"Saizheng Zhang is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"YOSHUA BENGIO","type":"PERSON","description":"Yoshua Bengio is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"WILLIAM W COHEN","type":"PERSON","description":"William W Cohen is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"RUSLAN SALAKHUTDINOV","type":"PERSON","description":"Ruslan Salakhutdinov is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"CHRISTOPHER D MANNING","type":"PERSON","description":"Christopher D Manning is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"HOTPOTQA","type":"DATASET","description":"HotpotQA is a dataset for diverse, explainable multi-hop question answering mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"DATASET"},{"name":"EMNLP","type":"CONFERENCE","description":"EMNLP is a conference where the paper on HotpotQA was presented","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"CONFERENCE"},{"name":"SHUNYU YAO","type":"PERSON","description":"Shunyu Yao is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"HOWARD CHEN","type":"PERSON","description":"Howard Chen is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"JOHN YANG","type":"PERSON","description":"John Yang is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"KARTHIK R NARASIMHAN","type":"PERSON","description":"Karthik R Narasimhan is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"WEBSHOP","type":"TOOL\/AGENT","description":"WebShop is a tool for scalable real-world web interaction with grounded language agents mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"TOOL\/AGENT"},{"name":"DIAN YU","type":"PERSON","description":"Dian Yu is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"JEFFREY ZHAO","type":"PERSON","description":"Jeffrey Zhao is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"IZHAK SHAFRAN","type":"PERSON","description":"Izhak Shafran is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"THOMAS L. GRIFFITHS","type":"PERSON","description":"Thomas L. Griffiths is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"YUAN CAO","type":"PERSON","description":"Yuan Cao is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"PERSON"},{"name":"TREE OF THOUGHTS","type":"TOOL\/PROCESS","description":"Tree of Thoughts is a deliberate problem-solving method with large language models mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d","entity_type":"TOOL\/PROCESS"},{"name":"REACT","type":"TOOL\/PROCESS","description":"ReAct is a method for synergizing reasoning and acting in language models mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"WEIRUI YE","type":"PERSON","description":"Weirui Ye is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"SHAOHUAI LIU","type":"PERSON","description":"Shaohuai Liu is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"THANARD KURUTACH","type":"PERSON","description":"Thanard Kurutach is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"YANG GAO","type":"PERSON","description":"Yang Gao is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"NATHANAEL SCHARLI","type":"PERSON","description":"Nathanael Sch\u00e4rli is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"LE HOU","type":"PERSON","description":"Le Hou is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"NATHAN SCALES","type":"PERSON","description":"Nathan Scales is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"OLIVIER BOUSQUET","type":"PERSON","description":"Olivier Bousquet is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"YUCHEN ZHUANG","type":"PERSON","description":"Yuchen Zhuang is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"XIANG CHEN","type":"PERSON","description":"Xiang Chen is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"TONG YU","type":"PERSON","description":"Tong Yu is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"SAAYAN MITRA","type":"PERSON","description":"Saayan Mitra is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"VICTOR BURSZTYN","type":"PERSON","description":"Victor Bursztyn is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"RYAN A. ROSSI","type":"PERSON","description":"Ryan A. Rossi is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"SOMDEB SARKHEL","type":"PERSON","description":"Somdeb Sarkhel is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"CHAO ZHANG","type":"PERSON","description":"Chao Zhang is an author mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"},{"name":"TOOLCHAIN*","type":"TOOL\/PROCESS","description":"ToolChain* is a method for efficient action space navigation in large language models with A* search mentioned in the text","source_id":"8180bf20b7577f3eee40df5991e2886d"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"HUGO TOUVRON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hugo Touvron is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"LOUIS MARTIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Louis Martin is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"KEVIN R. STONE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kevin R. Stone is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"PETER ALBERT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Peter Albert is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"AMJAD ALMAHAIRI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Amjad Almahairi is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"YASMINE BABAEI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yasmine Babaei is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"NIKOLAY BASHLYKOV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nikolay Bashlykov is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"SOUMYA BATRA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Soumya Batra is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"PRAJJWAL BHARGAVA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Prajjwal Bhargava is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"SHRUTI BHOSALE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shruti Bhosale is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"DANIEL M. BIKEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Daniel M. Bikel is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"LUKAS BLECHER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lukas Blecher is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"CRISTIAN CANT&#211;N FERRER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Cristian Cant&#243;n Ferrer is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"MOYA CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Moya Chen is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"GUILLEM CUCURULL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Guillem Cucurull is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"DAVID ESIOBU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">David Esiobu is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"JUDE FERNANDES\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jude Fernandes is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"JEREMY FU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jeremy Fu is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"WENYIN FU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wenyin Fu is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"BRIAN FULLER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Brian Fuller is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"CYNTHIA GAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Cynthia Gao is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"VEDANUJ GOSWAMI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Vedanuj Goswami is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"NAMAN GOYAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Naman Goyal is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"ANTHONY S. HARTSHORN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Anthony S. Hartshorn is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"SAGHAR HOSSEINI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Saghar Hosseini is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"RUI HOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Rui Hou is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"HAKAN INAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hakan Inan is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"MARCIN KARDAS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Marcin Kardas is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"VIKTOR KERKEZ\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Viktor Kerkez is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"MADIAN KHABSA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Madian Khabsa is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"ISABEL M. KLOUMANN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Isabel M. Kloumann is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"A. V. KORENEV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A. V. Korenev is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"PUNIT SINGH KOURA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Punit Singh Koura is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"MARIE-ANNE LACHAUX\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Marie-Anne Lachaux is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"THIBAUT LAVRIL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Thibaut Lavril is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"JENYA LEE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jenya Lee is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"DIANA LISKOVICH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Diana Liskovich is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"YINGHAI LU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yinghai Lu is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"YUNING MAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yuning Mao is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"XAVIER MARTINET\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xavier Martinet is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"TODOR MIHAYLOV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Todor Mihaylov is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"PUSHKAR MISHRA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pushkar Mishra is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"IGOR MOLYBOG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Igor Molybog is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"YIXIN NIE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yixin Nie is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"ANDREW POULTON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Andrew Poulton is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"JEREMY REIZENSTEIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jeremy Reizenstein is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"RASHI RUNGTA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Rashi Rungta is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"KALYAN SALADI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kalyan Saladi is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"ALAN SCHELTEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Alan Schelten is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"RUAN SILVA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ruan Silva is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"ERIC MICHAEL SMITH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Eric Michael Smith is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"R. SUBRAMANIAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">R. Subramanian is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"XIA TAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xia Tan is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"BINH TANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Binh Tang is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"ROSS TAYLOR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ross Taylor is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"ADINA WILLIAMS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Adina Williams is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"JIAN XIANG KUAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jian Xiang Kuan is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"PUXIN XU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Puxin Xu is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"ZHENGXU YAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhengxu Yan is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"ILIYAN ZAROV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Iliyan Zarov is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"YUCHEN ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yuchen Zhang is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"ANGELA FAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Angela Fan is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"MELANIE KAMBADUR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Melanie Kambadur is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"SHARAN NARANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sharan Narang is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"AURELIEN RODRIGUEZ\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Aurelien Rodriguez is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"ROBERT STOJNIC\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Robert Stojnic is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"SERGEY EDUNOV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sergey Edunov is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"THOMAS SCIALOM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Thomas Scialom is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"LLAMA 2\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Llama 2 is an open foundation and fine-tuned chat model mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"TOM VODOPIVEC\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tom Vodopivec is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SPYRIDON SAMOTHRAKIS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Spyridon Samothrakis is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BRANKO STER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Branko Ster is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GUANZHI WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Guanzhi Wang is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YUQI XIE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yuqi Xie is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YUNFAN JIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yunfan Jiang is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"AJAY MANDLEKAR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ajay Mandlekar is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHAOWEI XIAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chaowei Xiao is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YUKE ZHU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yuke Zhu is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LINXI FAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Linxi Fan is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ANIMA ANANDKUMAR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Anima Anandkumar is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"VOYAGER\">      <data key=\"d0\">TOOL\/AGENT<\/data>      <data key=\"d1\">Voyager is an open-ended embodied agent with large language models mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">TOOL\/AGENT<\/data>    <\/node>    <node id=\"XUEZHI WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xuezhi Wang is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JASON WEI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jason Wei is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DALE SCHUURMANS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dale Schuurmans is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"QUOC LE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Quoc Le is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ED CHI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ed Chi is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DENNY ZHOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Denny Zhou is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ICLR\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">ICLR is a conference where some of the mentioned papers were presented<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">CONFERENCE<\/data>    <\/node>    <node id=\"MAARTEN BOSMA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Maarten Bosma is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NEURIPS\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">NeurIPS is a conference where some of the mentioned papers were presented<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">CONFERENCE<\/data>    <\/node>    <node id=\"MICHAEL WOOLDRIDGE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Michael Wooldridge is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NICHOLAS R JENNINGS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nicholas R Jennings is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"THE KNOWLEDGE ENGINEERING REVIEW\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The Knowledge Engineering Review is a publication where the paper by Michael Wooldridge and Nicholas R Jennings was published<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"PHILIPP WU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Philipp Wu is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ALEJANDRO ESCONTRELA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Alejandro Escontrela is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DANIJAR HAFNER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Danijar Hafner is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PIETER ABBEEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pieter Abbeel is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KEN GOLDBERG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ken Goldberg is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DAYDREAMER\">      <data key=\"d0\">TOOL\/AGENT<\/data>      <data key=\"d1\">Daydreamer is a world model for physical robot learning mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">TOOL\/AGENT<\/data>    <\/node>    <node id=\"CORL\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">CoRL is a conference where the paper on Daydreamer was presented<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">CONFERENCE<\/data>    <\/node>    <node id=\"YUXI XIE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yuxi Xie is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KENJI KAWAGUCHI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kenji Kawaguchi is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YIRAN ZHAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yiran Zhao is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XU ZHAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xu Zhao is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MIN-YEN KAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Min-Yen Kan is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JUNXIAN HE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Junxian He is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"QIZHE XIE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Qizhe Xie is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHILIN YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhilin Yang is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PENG QI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Peng Qi is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SAIZHENG ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Saizheng Zhang is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YOSHUA BENGIO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yoshua Bengio is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WILLIAM W COHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">William W Cohen is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"RUSLAN SALAKHUTDINOV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ruslan Salakhutdinov is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHRISTOPHER D MANNING\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Christopher D Manning is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HOTPOTQA\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">HotpotQA is a dataset for diverse, explainable multi-hop question answering mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">DATASET<\/data>    <\/node>    <node id=\"EMNLP\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">EMNLP is a conference where the paper on HotpotQA was presented<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">CONFERENCE<\/data>    <\/node>    <node id=\"SHUNYU YAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shunyu Yao is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HOWARD CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Howard Chen is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JOHN YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">John Yang is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KARTHIK R NARASIMHAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Karthik R Narasimhan is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WEBSHOP\">      <data key=\"d0\">TOOL\/AGENT<\/data>      <data key=\"d1\">WebShop is a tool for scalable real-world web interaction with grounded language agents mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">TOOL\/AGENT<\/data>    <\/node>    <node id=\"DIAN YU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dian Yu is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JEFFREY ZHAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jeffrey Zhao is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"IZHAK SHAFRAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Izhak Shafran is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"THOMAS L. GRIFFITHS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Thomas L. Griffiths is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YUAN CAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yuan Cao is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TREE OF THOUGHTS\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">Tree of Thoughts is a deliberate problem-solving method with large language models mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>      <data key=\"d3\">TOOL\/PROCESS<\/data>    <\/node>    <node id=\"REACT\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">ReAct is a method for synergizing reasoning and acting in language models mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"WEIRUI YE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Weirui Ye is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"SHAOHUAI LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shaohuai Liu is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"THANARD KURUTACH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Thanard Kurutach is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"YANG GAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yang Gao is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"NATHANAEL SCHARLI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nathanael Sch&#228;rli is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"LE HOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Le Hou is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"NATHAN SCALES\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nathan Scales is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"OLIVIER BOUSQUET\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Olivier Bousquet is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"YUCHEN ZHUANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yuchen Zhuang is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"XIANG CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xiang Chen is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"TONG YU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tong Yu is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"SAAYAN MITRA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Saayan Mitra is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"VICTOR BURSZTYN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Victor Bursztyn is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"RYAN A. ROSSI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ryan A. Rossi is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"SOMDEB SARKHEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Somdeb Sarkhel is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"CHAO ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chao Zhang is an author mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <node id=\"TOOLCHAIN*\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">ToolChain* is a method for efficient action space navigation in large language models with A* search mentioned in the text<\/data>      <data key=\"d2\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/node>    <edge source=\"TOM VODOPIVEC\" target=\"SPYRIDON SAMOTHRAKIS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Tom Vodopivec and Spyridon Samothrakis co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"TOM VODOPIVEC\" target=\"BRANKO STER\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Tom Vodopivec and Branko Ster co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"SPYRIDON SAMOTHRAKIS\" target=\"BRANKO STER\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Spyridon Samothrakis and Branko Ster co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"GUANZHI WANG\" target=\"YUQI XIE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Guanzhi Wang and Yuqi Xie co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"GUANZHI WANG\" target=\"YUNFAN JIANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Guanzhi Wang and Yunfan Jiang co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"GUANZHI WANG\" target=\"AJAY MANDLEKAR\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Guanzhi Wang and Ajay Mandlekar co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"GUANZHI WANG\" target=\"CHAOWEI XIAO\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Guanzhi Wang and Chaowei Xiao co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"GUANZHI WANG\" target=\"YUKE ZHU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Guanzhi Wang and Yuke Zhu co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"GUANZHI WANG\" target=\"LINXI FAN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Guanzhi Wang and Linxi Fan co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"GUANZHI WANG\" target=\"ANIMA ANANDKUMAR\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Guanzhi Wang and Anima Anandkumar co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"XUEZHI WANG\" target=\"JASON WEI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Xuezhi Wang and Jason Wei co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"XUEZHI WANG\" target=\"DALE SCHUURMANS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Xuezhi Wang and Dale Schuurmans co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"XUEZHI WANG\" target=\"QUOC LE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Xuezhi Wang and Quoc Le co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"XUEZHI WANG\" target=\"ED CHI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Xuezhi Wang and Ed Chi co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"XUEZHI WANG\" target=\"DENNY ZHOU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Xuezhi Wang and Denny Zhou co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"JASON WEI\" target=\"DALE SCHUURMANS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Jason Wei and Dale Schuurmans co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"JASON WEI\" target=\"QUOC LE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Jason Wei and Quoc Le co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"JASON WEI\" target=\"ED CHI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Jason Wei and Ed Chi co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"JASON WEI\" target=\"DENNY ZHOU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Jason Wei and Denny Zhou co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"DALE SCHUURMANS\" target=\"QUOC LE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Dale Schuurmans and Quoc Le co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"DALE SCHUURMANS\" target=\"ED CHI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Dale Schuurmans and Ed Chi co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"DALE SCHUURMANS\" target=\"DENNY ZHOU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Dale Schuurmans and Denny Zhou co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"QUOC LE\" target=\"ED CHI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Quoc Le and Ed Chi co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"QUOC LE\" target=\"DENNY ZHOU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Quoc Le and Denny Zhou co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"ED CHI\" target=\"DENNY ZHOU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Ed Chi and Denny Zhou co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"MICHAEL WOOLDRIDGE\" target=\"NICHOLAS R JENNINGS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Michael Wooldridge and Nicholas R Jennings co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"PHILIPP WU\" target=\"ALEJANDRO ESCONTRELA\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Philipp Wu and Alejandro Escontrela co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"PHILIPP WU\" target=\"DANIJAR HAFNER\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Philipp Wu and Danijar Hafner co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"PHILIPP WU\" target=\"PIETER ABBEEL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Philipp Wu and Pieter Abbeel co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"PHILIPP WU\" target=\"KEN GOLDBERG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Philipp Wu and Ken Goldberg co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"ALEJANDRO ESCONTRELA\" target=\"DANIJAR HAFNER\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Alejandro Escontrela and Danijar Hafner co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"ALEJANDRO ESCONTRELA\" target=\"PIETER ABBEEL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Alejandro Escontrela and Pieter Abbeel co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>    <edge source=\"ALEJANDRO ESCONTRELA\" target=\"KEN GOLDBERG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Alejandro Escontrela and Ken Goldberg co-authored a paper<\/data>      <data key=\"d6\">8180bf20b7577f3eee40df5991e2886d<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"42de130f5b6144472a86a4c8260a87c7","chunk":" Olivier Bous-\nquet, Quoc Le, and Ed Chi. Least-to-most prompting\nenables complex reasoning in large language models. In\nICLR , 2022.\nYuchen Zhuang, Xiang Chen, Tong Yu, Saayan Mitra, Victor\nBursztyn, Ryan A. Rossi, Somdeb Sarkhel, and Chao\nZhang. ToolChain*: Efficient action space navigation in\nlarge language models with A* search. In ICLR , 2023.\n13Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nAppendix of LATS\nThe appendix is organized as follows. First in Sec. A, we\nshow the pseudocode of our proposed algorithm, LATS. In\nSec. B, we provide further discussion of the limitations of\nour method. In Sec. C, we present additional experimental\nresults. In Sec. D, we specify the environment details in our\nexperiments. Finally, we list our prompts used for the three\nenvironments in Sec. E (HotPotQA), Sec. F (Programming),\nand Sec. G (WebShop), respectively.\nA. LATS Pseudocode\nAlg. 1 shows the pseudocode of our algorithm LATS. Nodes\nare stored explicitly in the memory. Unless otherwise speci-\nfied, in all experiments, we set the number of sampled nodes\nton= 5 and the exploration weight to w= 1. We use\na self-consistency weight of \u03bb= 0.5for HotPotQA and\nGame of 24, and \u03bb= 0.8for Programming and WebShop.\nB. More Discussion on Limitations\nAs stated in Sec. 6, LATS has two main limitations:\nComputational cost. Although LATS can improve rea-\nsoning and decision-making, this arrives at a higher com-\nputational cost relative to simpler prompting methods like\nReAct or Reflexion. However, the following facts serve as\nmitigations to this issue:\n\u2022Asymptotically, our method has the same sample com-\nplexity as ToT (Yao et al., 2023a) and RAP (Hao et al.,\n2023), but achieves better performance, expands fewer\nnodes, and uses fewer tokens on average upon success.\nThis suggests that our method is not only stronger\nin problem-solving but also has higher efficiency. A\nfull analysis of the cost can be found in Tab. 9 in Ap-\npendix C.\n\u2022The number of nodes nexpanded at every step provides\na natural trade-off between performance and efficiency.\nIn fact, setting n= 1 makes the method as efficient\nas ReAct (Yao et al., 2023b) with multiple trials or\nCoT-SC (Wang et al., 2022).\nIn general, we recommend using LATS for difficult tasks\nlike programming or for situations where performance is\nprioritized over efficiency in practice. We hope that contin-\nued advancements in LMs will reduce costs and increase\nthe applicability of LATS.\nAdditionally, there exists a minor cost from querying the en-\nvironment, which we find to be trivial for the environments\nwe study. Most LM-based environments involve API-based\ntools, which are inexpensive and fast to use. It is also worthnoting that this is cheaper than the inference cost associ-\nated with using LMs as world models, as in previous search\napproaches (Hao et al., 2023; Liu et al., 2023).\nAssumption of environment reversion in decision-\nmaking. Since our method is based on Monte Carlo\nTree Search and is model-free, one limitation of LATS on\ndecision-making tasks is that it requires the agent to be\nable to revert to earlier states in the environments. How-\never, this reversion property is feasible in many real-world\nenvironments and applications (despite being not univer-\nsally applicable in all possible environments), including\nprogramming (HumanEval (Chen et al., 2021)), web search\n(WebShop (Yao et al., 2022)), text-based manipulation tasks\n(Alfworld (Shridhar et al., 2020)), and LMs with tool use\n(ToolBench (Qin et al., 2024)). Therefore, we believe that\nleveraging the reversion property is not a shortcoming but\nrather a feature that has not been explicitly given notice\nby the LM decision-making community \u2013 it opens up new\nopportunities in the emerging LM agent community.\nAdditionally, the benchmarks we use in this paper are rel-\natively simple and focused on decision-making compared\nto the complexity of real-world interactive environments.\nMoreover, some environments might not easily support roll-\nbacks to previous states. However, the design of LATS is\nflexible and can be adjusted to various resource constraints.\nUsing planning-based prompting methods like LATS in\nenvironments like Minecraft (Fan et al., 2022) and more rea-\nsoning benchmarks would be interesting avenues for future\nwork.\nC. Additional Ablations\nIn this section, we ablate various designs of LATS. Ex-\nperiments are conducted on HotPotQA with a maximum\nofk= 50 trajectories and sampling size of n= 5 and\nHumanEval with a maximum of k= 8trajectories and sam-\npling size of n= 5. The result for HotPotQA is shown in\nTab. 8 and HumanEval in Fig. 3.\nExploration weight. We find that there is lower perfor-\nmance on HotPotQA when the exploration weight win the\nselection formula is decreased to 0.5, suggesting that this\nreduces the effectiveness of the search. Increasing w","chunk_id":"42de130f5b6144472a86a4c8260a87c7","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"OLIVIER BOUSQUET","type":"PERSON","description":"Olivier Bousquet is an author of the paper \"Least-to-most prompting enables complex reasoning in large language models\"","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"QUOC LE","type":"PERSON","description":"Quoc Le is an author of the paper \"Least-to-most prompting enables complex reasoning in large language models\"","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"ED CHI","type":"PERSON","description":"Ed Chi is an author of the paper \"Least-to-most prompting enables complex reasoning in large language models\"","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"ICLR 2022","type":"EVENT","description":"The conference where the paper \"Least-to-most prompting enables complex reasoning in large language models\" was presented","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"YUCHEN ZHUANG","type":"PERSON","description":"Yuchen Zhuang is an author of the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"XIANG CHEN","type":"PERSON","description":"Xiang Chen is an author of the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"TONG YU","type":"PERSON","description":"Tong Yu is an author of the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"SAAYAN MITRA","type":"PERSON","description":"Saayan Mitra is an author of the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"VICTOR BURSZTYN","type":"PERSON","description":"Victor Bursztyn is an author of the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"RYAN A. ROSSI","type":"PERSON","description":"Ryan A. Rossi is an author of the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"SOMDEB SARKHEL","type":"PERSON","description":"Somdeb Sarkhel is an author of the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"CHAO ZHANG","type":"PERSON","description":"Chao Zhang is an author of the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"ICLR 2023","type":"EVENT","description":"The conference where the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\" was presented","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"LATS","type":"ALGORITHM","description":"LATS (Language Agent Tree Search) is an algorithm that unifies reasoning, acting, and planning in language models","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"HOTPOTQA","type":"DATASET","description":"HotPotQA is a dataset used in experiments with the LATS algorithm","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"PROGRAMMING","type":"TASK","description":"Programming is one of the tasks used in experiments with the LATS algorithm","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"WEBSHOP","type":"ENVIRONMENT","description":"WebShop is an environment used in experiments with the LATS algorithm","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"REACT","type":"METHOD","description":"ReAct is a simpler prompting method compared to LATS","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"REFLEXION","type":"METHOD","description":"Reflexion is a simpler prompting method compared to LATS","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"TOT","type":"METHOD","description":"ToT (Tree of Thoughts) is a method compared to LATS in terms of sample complexity and performance","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"RAP","type":"METHOD","description":"RAP (Reasoning and Planning) is a method compared to LATS in terms of sample complexity and performance","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"COT-SC","type":"METHOD","description":"CoT-SC (Chain of Thought with Self-Consistency) is a method compared to LATS in terms of efficiency","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"HUMANEVAL","type":"DATASET","description":"HumanEval is a dataset used in experiments with the LATS algorithm","source_id":"42de130f5b6144472a86a4c8260a87c7","entity_type":"DATASET"},{"name":"MINECRAFT","type":"ENVIRONMENT","description":"Minecraft is an environment suggested for future work with planning-based prompting methods like LATS","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"FAN ET AL. 2022","type":"REFERENCE","description":"A reference to a study or paper by Fan et al. in 2022, related to the use of LATS in environments like Minecraft","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"ALFWORLD","type":"ENVIRONMENT","description":"Alfworld is an environment used in experiments with the LATS algorithm","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"TOOLBENCH","type":"TOOL","description":"ToolBench is a tool used in experiments with the LATS algorithm","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"QIN ET AL. 2024","type":"REFERENCE","description":"A reference to a study or paper by Qin et al. in 2024, related to the use of LATS in environments like ToolBench","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"CHEN ET AL. 2021","type":"REFERENCE","description":"A reference to a study or paper by Chen et al. in 2021, related to the use of LATS in environments like HumanEval","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"YAO ET AL. 2022","type":"REFERENCE","description":"A reference to a study or paper by Yao et al. in 2022, related to the use of LATS in environments like WebShop","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"SHRIDHAR ET AL. 2020","type":"REFERENCE","description":"A reference to a study or paper by Shridhar et al. in 2020, related to the use of LATS in environments like Alfworld","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"HAO ET AL. 2023","type":"REFERENCE","description":"A reference to a study or paper by Hao et al. in 2023, related to the use of LATS in environments like ToolBench","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"LIU ET AL. 2023","type":"REFERENCE","description":"A reference to a study or paper by Liu et al. in 2023, related to the use of LATS in environments like ToolBench","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"LANGUAGE AGENT TREE SEARCH (LATS)","type":"ALGORITHM","description":"Language Agent Tree Search (LATS) is an algorithm that unifies reasoning, acting, and planning in language models","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"SEC. A","type":"SECTION","description":"Section A of the appendix shows the pseudocode of the proposed algorithm, LATS","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"SEC. B","type":"SECTION","description":"Section B of the appendix provides further discussion of the limitations of the LATS method","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"SEC. C","type":"SECTION","description":"Section C of the appendix presents additional experimental results of the LATS method","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"SEC. D","type":"SECTION","description":"Section D of the appendix specifies the environment details in the experiments with the LATS method","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"SEC. E","type":"SECTION","description":"Section E of the appendix lists the prompts used for the HotPotQA environment in the experiments with the LATS method","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"SEC. F","type":"SECTION","description":"Section F of the appendix lists the prompts used for the Programming environment in the experiments with the LATS method","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"SEC. G","type":"SECTION","description":"Section G of the appendix lists the prompts used for the WebShop environment in the experiments with the LATS method","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"GAME OF 24","type":"TASK","description":"Game of 24 is one of the tasks used in experiments with the LATS algorithm","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"PSEUDOCODE","type":"DOCUMENT","description":"The pseudocode of the LATS algorithm is provided in the appendix","source_id":"42de130f5b6144472a86a4c8260a87c7"},{"name":"MONTE CARLO TREE SEARCH","type":"METHOD","description":"Monte Carlo Tree Search is a method used in the LATS algorithm for decision-making tasks","source_id":"42de130f5b6144472a86a4c8260a87c7"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"OLIVIER BOUSQUET\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Olivier Bousquet is an author of the paper \"Least-to-most prompting enables complex reasoning in large language models\"<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"QUOC LE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Quoc Le is an author of the paper \"Least-to-most prompting enables complex reasoning in large language models\"<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"ED CHI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ed Chi is an author of the paper \"Least-to-most prompting enables complex reasoning in large language models\"<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"ICLR 2022\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">The conference where the paper \"Least-to-most prompting enables complex reasoning in large language models\" was presented<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"YUCHEN ZHUANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yuchen Zhuang is an author of the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"XIANG CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xiang Chen is an author of the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"TONG YU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tong Yu is an author of the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"SAAYAN MITRA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Saayan Mitra is an author of the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"VICTOR BURSZTYN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Victor Bursztyn is an author of the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"RYAN A. ROSSI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ryan A. Rossi is an author of the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"SOMDEB SARKHEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Somdeb Sarkhel is an author of the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"CHAO ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chao Zhang is an author of the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"ICLR 2023\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">The conference where the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\" was presented<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"LATS\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">LATS (Language Agent Tree Search) is an algorithm that unifies reasoning, acting, and planning in language models<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"HOTPOTQA\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">HotPotQA is a dataset used in experiments with the LATS algorithm<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"PROGRAMMING\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">Programming is one of the tasks used in experiments with the LATS algorithm<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"WEBSHOP\">      <data key=\"d0\">ENVIRONMENT<\/data>      <data key=\"d1\">WebShop is an environment used in experiments with the LATS algorithm<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"REACT\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">ReAct is a simpler prompting method compared to LATS<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"REFLEXION\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Reflexion is a simpler prompting method compared to LATS<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"TOT\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">ToT (Tree of Thoughts) is a method compared to LATS in terms of sample complexity and performance<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"RAP\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">RAP (Reasoning and Planning) is a method compared to LATS in terms of sample complexity and performance<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"COT-SC\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">CoT-SC (Chain of Thought with Self-Consistency) is a method compared to LATS in terms of efficiency<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"HUMANEVAL\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">HumanEval is a dataset used in experiments with the LATS algorithm<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>      <data key=\"d3\">DATASET<\/data>    <\/node>    <node id=\"MINECRAFT\">      <data key=\"d0\">ENVIRONMENT<\/data>      <data key=\"d1\">Minecraft is an environment suggested for future work with planning-based prompting methods like LATS<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"FAN ET AL. 2022\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study or paper by Fan et al. in 2022, related to the use of LATS in environments like Minecraft<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"ALFWORLD\">      <data key=\"d0\">ENVIRONMENT<\/data>      <data key=\"d1\">Alfworld is an environment used in experiments with the LATS algorithm<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"TOOLBENCH\">      <data key=\"d0\">TOOL<\/data>      <data key=\"d1\">ToolBench is a tool used in experiments with the LATS algorithm<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"QIN ET AL. 2024\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study or paper by Qin et al. in 2024, related to the use of LATS in environments like ToolBench<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"CHEN ET AL. 2021\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study or paper by Chen et al. in 2021, related to the use of LATS in environments like HumanEval<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"YAO ET AL. 2022\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study or paper by Yao et al. in 2022, related to the use of LATS in environments like WebShop<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"SHRIDHAR ET AL. 2020\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study or paper by Shridhar et al. in 2020, related to the use of LATS in environments like Alfworld<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"HAO ET AL. 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study or paper by Hao et al. in 2023, related to the use of LATS in environments like ToolBench<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"LIU ET AL. 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a study or paper by Liu et al. in 2023, related to the use of LATS in environments like ToolBench<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"LANGUAGE AGENT TREE SEARCH (LATS)\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">Language Agent Tree Search (LATS) is an algorithm that unifies reasoning, acting, and planning in language models<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"SEC. A\">      <data key=\"d0\">SECTION<\/data>      <data key=\"d1\">Section A of the appendix shows the pseudocode of the proposed algorithm, LATS<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"SEC. B\">      <data key=\"d0\">SECTION<\/data>      <data key=\"d1\">Section B of the appendix provides further discussion of the limitations of the LATS method<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"SEC. C\">      <data key=\"d0\">SECTION<\/data>      <data key=\"d1\">Section C of the appendix presents additional experimental results of the LATS method<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"SEC. D\">      <data key=\"d0\">SECTION<\/data>      <data key=\"d1\">Section D of the appendix specifies the environment details in the experiments with the LATS method<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"SEC. E\">      <data key=\"d0\">SECTION<\/data>      <data key=\"d1\">Section E of the appendix lists the prompts used for the HotPotQA environment in the experiments with the LATS method<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"SEC. F\">      <data key=\"d0\">SECTION<\/data>      <data key=\"d1\">Section F of the appendix lists the prompts used for the Programming environment in the experiments with the LATS method<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"SEC. G\">      <data key=\"d0\">SECTION<\/data>      <data key=\"d1\">Section G of the appendix lists the prompts used for the WebShop environment in the experiments with the LATS method<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"GAME OF 24\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">Game of 24 is one of the tasks used in experiments with the LATS algorithm<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"PSEUDOCODE\">      <data key=\"d0\">DOCUMENT<\/data>      <data key=\"d1\">The pseudocode of the LATS algorithm is provided in the appendix<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <node id=\"MONTE CARLO TREE SEARCH\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Monte Carlo Tree Search is a method used in the LATS algorithm for decision-making tasks<\/data>      <data key=\"d2\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/node>    <edge source=\"OLIVIER BOUSQUET\" target=\"QUOC LE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Olivier Bousquet and Quoc Le co-authored the paper \"Least-to-most prompting enables complex reasoning in large language models\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"OLIVIER BOUSQUET\" target=\"ED CHI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Olivier Bousquet and Ed Chi co-authored the paper \"Least-to-most prompting enables complex reasoning in large language models\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"QUOC LE\" target=\"ED CHI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Quoc Le and Ed Chi co-authored the paper \"Least-to-most prompting enables complex reasoning in large language models\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"YUCHEN ZHUANG\" target=\"XIANG CHEN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yuchen Zhuang and Xiang Chen co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"YUCHEN ZHUANG\" target=\"TONG YU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yuchen Zhuang and Tong Yu co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"YUCHEN ZHUANG\" target=\"SAAYAN MITRA\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yuchen Zhuang and Saayan Mitra co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"YUCHEN ZHUANG\" target=\"VICTOR BURSZTYN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yuchen Zhuang and Victor Bursztyn co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"YUCHEN ZHUANG\" target=\"RYAN A. ROSSI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yuchen Zhuang and Ryan A. Rossi co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"YUCHEN ZHUANG\" target=\"SOMDEB SARKHEL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yuchen Zhuang and Somdeb Sarkhel co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"YUCHEN ZHUANG\" target=\"CHAO ZHANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yuchen Zhuang and Chao Zhang co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"XIANG CHEN\" target=\"TONG YU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Xiang Chen and Tong Yu co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"XIANG CHEN\" target=\"SAAYAN MITRA\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Xiang Chen and Saayan Mitra co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"XIANG CHEN\" target=\"VICTOR BURSZTYN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Xiang Chen and Victor Bursztyn co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"XIANG CHEN\" target=\"RYAN A. ROSSI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Xiang Chen and Ryan A. Rossi co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"XIANG CHEN\" target=\"SOMDEB SARKHEL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Xiang Chen and Somdeb Sarkhel co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"XIANG CHEN\" target=\"CHAO ZHANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Xiang Chen and Chao Zhang co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"TONG YU\" target=\"SAAYAN MITRA\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Tong Yu and Saayan Mitra co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"TONG YU\" target=\"VICTOR BURSZTYN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Tong Yu and Victor Bursztyn co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"TONG YU\" target=\"RYAN A. ROSSI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Tong Yu and Ryan A. Rossi co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"TONG YU\" target=\"SOMDEB SARKHEL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Tong Yu and Somdeb Sarkhel co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"TONG YU\" target=\"CHAO ZHANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Tong Yu and Chao Zhang co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"SAAYAN MITRA\" target=\"VICTOR BURSZTYN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Saayan Mitra and Victor Bursztyn co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"SAAYAN MITRA\" target=\"RYAN A. ROSSI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Saayan Mitra and Ryan A. Rossi co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"SAAYAN MITRA\" target=\"SOMDEB SARKHEL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Saayan Mitra and Somdeb Sarkhel co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"SAAYAN MITRA\" target=\"CHAO ZHANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Saayan Mitra and Chao Zhang co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"VICTOR BURSZTYN\" target=\"RYAN A. ROSSI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Victor Bursztyn and Ryan A. Rossi co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"VICTOR BURSZTYN\" target=\"SOMDEB SARKHEL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Victor Bursztyn and Somdeb Sarkhel co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"VICTOR BURSZTYN\" target=\"CHAO ZHANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Victor Bursztyn and Chao Zhang co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"RYAN A. ROSSI\" target=\"SOMDEB SARKHEL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Ryan A. Rossi and Somdeb Sarkhel co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"RYAN A. ROSSI\" target=\"CHAO ZHANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Ryan A. Rossi and Chao Zhang co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>    <edge source=\"SOMDEB SARKHEL\" target=\"CHAO ZHANG\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Somdeb Sarkhel and Chao Zhang co-authored the paper \"ToolChain*: Efficient action space navigation in large language models with A* search\"<\/data>      <data key=\"d6\">42de130f5b6144472a86a4c8260a87c7<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"48e423e2baf2ed485872756f5b4d87d8","chunk":" 5 and\nHumanEval with a maximum of k= 8trajectories and sam-\npling size of n= 5. The result for HotPotQA is shown in\nTab. 8 and HumanEval in Fig. 3.\nExploration weight. We find that there is lower perfor-\nmance on HotPotQA when the exploration weight win the\nselection formula is decreased to 0.5, suggesting that this\nreduces the effectiveness of the search. Increasing wto2.0\ndoes not lead to a performance improvement, but we tend\nto observe faster convergence. The optimal setting depends\non the particular environment and complexity of the state\nspace.\nDepth. In our main experiments we use a maximum depth\nofd= 7on HotPotQA for all methods, following previous\nwork (Yao et al., 2023b). We ablate the effect on LATS after\nreducing it to d= 4. This results in only a slight drop in\nperformance. We find that most questions can be answered\nwithin four steps, and using a greater number of steps tends\n14Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nAlgorithm 1 LATS( s, p\u03b8, pV, pref, d, k, n, w, a, b )\nRequire: Initial state s, action generator p\u03b8, value function pV, reflection generator pref, number of generated actions n,\ndepth limit L, number of roll-outs K, context c, exploration weight w, and value function weight \u03bb\nInitialize action space A, observation space O\nInitialize the state-action value function pV:S\u00d7A7\u2192Rand visit counter N:S7\u2192Nto one\nfork\u21900, . . . , K \u22121do\nfort\u21900, . . . , L \u22121do\nifstnot terminal then \u25b7Expansion & Simulation\nfori\u21901, . . . , n do\nSample a(i)\nt\u223cp\u03b8(st)\nGeto(i)\ntfrom environment, s(i)\nt+1\u2190(c(i)\nt, o(i)\nt, a(i)\nt),c(i)\nt+1\u2190(o(i)\nt, a(i)\nt)\nEvaluate V(i)\nt\u223c\u03bb\u2217pV(s(i)\nt) + (1\u2212\u03bb)\u2217SC(s(i)\nt) \u25b7Evaluation\nV(st)\u2190V(i)\nt\nAdds(i)\ntto children\nend for\nend if\nifstis terminal then \u25b7Reflection\nGetrfrom environment\nifrnot success then\nreflection \u2190pref(ct)\nc\u2190reflection\nend if\nend if\nat\u2190arg max a\u2208e(st)h\nV(st) +wq\nlnN(st)\nN(st+1)i\n\u25b7Selection\nGet corresponding otfrom memory, st+1\u2190(ct, ot, at), ct+1\u2190(ot, at)\nN(st+1)\u2190N(st+1) + 1\nifatis an output action then break\nend for\nT\u2190the actual number of steps\nfort\u2190T\u22121, . . . , 0do \u25b7Backpropagation\nV(st)\u2190V(st)(N(st)\u22121)+r\nN(st)\nend for\nend for\nto force the agent into local minima and rarely improves\nsuccess.\nLM value function. The LM value function scores states\nbased on expected future reward. Without this heuristic,\nthe only signal to guide search would be from environment\nrewards for completed trajectories, which are scarce and\noften binary. When we remove the evaluation operation, we\nobserve a dramatic 0.26drop in performance.\nPerformance over time. To see the effects of increasing\nthe number of trajectories sampled, we change kto different\nvalues. We conduct this experiment on HumanEval, which\nhas a more noticeable difference due to sampling less tra-\njectories. The results are shown in Fig. 3, in which LATS\nscales better with more iterations than Reflexion.\nD. Environment Details\nD.1. HotPotQA\nHotPotQA (Yang et al., 2018) is a question-answering\ndataset that requires reasoning over multiple supporting\ndocuments to answer questions. It contains 113k Wikipedia-based question-answer pairs crafted by crowdworkers to\nbe diverse, multi-hop, and explainable. Questions cover a\nrange of types like entities, locations, dates, and comparison\nof shared properties between two entities. Crowdworkers\nalso provide supporting facts from the documents that justify\nthe answer. We use the HotPotQA benchmark setting with\nall the Wikipedia paragraphs to test retrieval. We use a ran-\ndomly selected subset of 100 questions for our experiments\nand a maximum depth limit of 6. Fig. 4 illustrates how\nReAct and LATS work on an example task of HotPotQA,\nand gives a qualitative example on how LATS outperforms\nReAct on the task. For value function hyperparameters, we\nuse\u03bb= 0.5for the LM score and self-consistency score.\nAction Space. We adopt the Wikipedia web API proposed\nin Yao et al. (2023b), with three types of actions to support\ninteractive information retrieval:\n(1)search [entity ], which returns the first 5 sentences\nfrom the corresponding entity wiki page if it exists,\nor else suggests top-5 similar entities from the Wikipedia\nsearch engine,\n(2)lookup [string ], which returns the next sentence in\n15Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nPrompt Method HotpotQA (EM) \u2191\nLATS ( w= 0.5) 0.55","chunk_id":"48e423e2baf2ed485872756f5b4d87d8","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"HUMANEVAL","type":"DATASET","description":"HumanEval is a dataset used for evaluating the performance of models, with a maximum of k=8 trajectories and a sampling size of n=5","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"HOTPOTQA","type":"DATASET","description":"HotPotQA is a question-answering dataset that requires reasoning over multiple supporting documents to answer questions. It contains 113k Wikipedia-based question-answer pairs crafted by crowdworkers","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"LATS","type":"ALGORITHM","description":"LATS (Language Agent Tree Search) is an algorithm used for reasoning, acting, and planning in language models","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"EXPLORATION WEIGHT","type":"PARAMETER","description":"Exploration weight is a parameter in the selection formula that affects the performance of the search in HotPotQA","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"DEPTH","type":"PARAMETER","description":"Depth is a parameter that defines the maximum number of steps in the search process for HotPotQA","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"LM VALUE FUNCTION","type":"FUNCTION","description":"The LM value function scores states based on expected future reward and guides the search process","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"YAO ET AL., 2023B","type":"REFERENCE","description":"A previous work referenced for setting the maximum depth in HotPotQA experiments","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"WIKIPEDIA WEB API","type":"TOOL","description":"The Wikipedia web API is used for interactive information retrieval in the HotPotQA dataset","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"REACT","type":"ALGORITHM","description":"ReAct is an algorithm compared with LATS in the HotPotQA experiments","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"LANGUAGE MODELS","type":"TECHNOLOGY","description":"Language models are used for reasoning, acting, and planning in the LATS algorithm","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"CROWDWORKERS","type":"PERSON","description":"Crowdworkers are individuals who crafted the question-answer pairs in the HotPotQA dataset","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"WIKIPEDIA","type":"SOURCE","description":"Wikipedia is the source of the documents used in the HotPotQA dataset","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"HYPERPARAMETERS","type":"PARAMETER","description":"Hyperparameters are settings used in the value function for the LATS algorithm","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"REFLEXION","type":"ALGORITHM","description":"Reflexion is an algorithm compared with LATS in the HumanEval experiments","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"FIG. 3","type":"FIGURE","description":"Figure 3 shows the results of the HumanEval experiments and the performance of LATS over time","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"FIG. 4","type":"FIGURE","description":"Figure 4 illustrates how ReAct and LATS work on an example task of HotPotQA","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"ALGORITHM 1","type":"ALGORITHM","description":"Algorithm 1 describes the LATS process, including initialization, expansion, simulation, evaluation, selection, and backpropagation","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"TAB. 8","type":"FIGURE","description":"Table 8 shows the results for HotPotQA","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"SAMPLING SIZE","type":"PARAMETER","description":"Sampling size is a parameter used in the HumanEval dataset, with a value of n=5","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"TRAJECTORIES","type":"PARAMETER","description":"Trajectories refer to the number of paths sampled in the HumanEval and HotPotQA experiments, with a maximum of k=8","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"SELECTION FORMULA","type":"PARAMETER","description":"Selection formula is used in the LATS algorithm to choose actions based on exploration weight and value function","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"STATE SPACE","type":"PARAMETER","description":"State space refers to the complexity of the environment in which the LATS algorithm operates","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"ROLL-OUTS","type":"PARAMETER","description":"Roll-outs refer to the number of iterations (K) in the LATS algorithm","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"CONTEXT","type":"PARAMETER","description":"Context (c) is part of the state in the LATS algorithm","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"VISIT COUNTER","type":"PARAMETER","description":"Visit counter (N) is used in the LATS algorithm to track the number of visits to each state","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"ACTION SPACE","type":"PARAMETER","description":"Action space (A) is the set of possible actions in the LATS algorithm","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"OBSERVATION SPACE","type":"PARAMETER","description":"Observation space (O) is the set of possible observations in the LATS algorithm","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"INITIAL STATE","type":"PARAMETER","description":"Initial state (s) is the starting point in the LATS algorithm","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"ACTION GENERATOR","type":"PARAMETER","description":"Action generator (p\u03b8) is used to sample actions in the LATS algorithm","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"VALUE FUNCTION","type":"PARAMETER","description":"Value function (pV) is used to evaluate states in the LATS algorithm","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"REFLECTION GENERATOR","type":"PARAMETER","description":"Reflection generator (pref) is used to generate reflections in the LATS algorithm","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"ENVIRONMENT","type":"PARAMETER","description":"Environment provides the context and rewards for the LATS algorithm","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"REWARD","type":"PARAMETER","description":"Reward (r) is the feedback from the environment in the LATS algorithm","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"TERMINAL STATE","type":"PARAMETER","description":"Terminal state (st) is a state where the process ends in the LATS algorithm","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"SUCCESS","type":"PARAMETER","description":"Success is a condition checked in the reflection phase of the LATS algorithm","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"EVALUATION OPERATION","type":"PARAMETER","description":"Evaluation operation is used to score states in the LATS algorithm","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"TRAJECTORY","type":"PARAMETER","description":"Trajectory refers to the path taken through the state space in the LATS algorithm","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"ITERATIONS","type":"PARAMETER","description":"Iterations refer to the number of times the LATS algorithm is run","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"SUPPORTING FACTS","type":"PARAMETER","description":"Supporting facts are provided by crowdworkers in the HotPotQA dataset to justify answers","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"ENTITY","type":"PARAMETER","description":"Entity is a type of question in the HotPotQA dataset","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"LOCATION","type":"PARAMETER","description":"Location is a type of question in the HotPotQA dataset","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"DATE","type":"PARAMETER","description":"Date is a type of question in the HotPotQA dataset","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"COMPARISON","type":"PARAMETER","description":"Comparison is a type of question in the HotPotQA dataset","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"SHARED PROPERTIES","type":"PARAMETER","description":"Shared properties are compared between two entities in the HotPotQA dataset","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"SUPPORTING DOCUMENTS","type":"PARAMETER","description":"Supporting documents are used to answer questions in the HotPotQA dataset","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"QUESTION-ANSWER PAIRS","type":"PARAMETER","description":"Question-answer pairs are crafted by crowdworkers in the HotPotQA dataset","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"WIKIPEDIA PARAGRAPHS","type":"PARAMETER","description":"Wikipedia paragraphs are used in the HotPotQA benchmark setting","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"SUBSET OF 100 QUESTIONS","type":"PARAMETER","description":"A randomly selected subset of 100 questions is used in the HotPotQA experiments","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"MAXIMUM DEPTH LIMIT","type":"PARAMETER","description":"Maximum depth limit is set to 6 in the HotPotQA experiments","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"VALUE FUNCTION HYPERPARAMETERS","type":"PARAMETER","description":"Value function hyperparameters include \u03bb=0.5 for the LM score and self-consistency score in the LATS algorithm","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"SEARCH [ENTITY]","type":"PARAMETER","description":"Search [entity] is an action type in the Wikipedia web API used in the LATS algorithm","source_id":"48e423e2baf2ed485872756f5b4d87d8"},{"name":"LOOKUP [STRING]","type":"PARAMETER","description":"Lookup [string] is an action type in the Wikipedia web API used in the LATS algorithm","source_id":"48e423e2baf2ed485872756f5b4d87d8"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"HUMANEVAL\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">HumanEval is a dataset used for evaluating the performance of models, with a maximum of k=8 trajectories and a sampling size of n=5<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"HOTPOTQA\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">HotPotQA is a question-answering dataset that requires reasoning over multiple supporting documents to answer questions. It contains 113k Wikipedia-based question-answer pairs crafted by crowdworkers<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"LATS\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">LATS (Language Agent Tree Search) is an algorithm used for reasoning, acting, and planning in language models<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"EXPLORATION WEIGHT\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Exploration weight is a parameter in the selection formula that affects the performance of the search in HotPotQA<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"DEPTH\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Depth is a parameter that defines the maximum number of steps in the search process for HotPotQA<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"LM VALUE FUNCTION\">      <data key=\"d0\">FUNCTION<\/data>      <data key=\"d1\">The LM value function scores states based on expected future reward and guides the search process<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"YAO ET AL., 2023B\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A previous work referenced for setting the maximum depth in HotPotQA experiments<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"WIKIPEDIA WEB API\">      <data key=\"d0\">TOOL<\/data>      <data key=\"d1\">The Wikipedia web API is used for interactive information retrieval in the HotPotQA dataset<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"REACT\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">ReAct is an algorithm compared with LATS in the HotPotQA experiments<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"LANGUAGE MODELS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Language models are used for reasoning, acting, and planning in the LATS algorithm<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"CROWDWORKERS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Crowdworkers are individuals who crafted the question-answer pairs in the HotPotQA dataset<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"WIKIPEDIA\">      <data key=\"d0\">SOURCE<\/data>      <data key=\"d1\">Wikipedia is the source of the documents used in the HotPotQA dataset<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"HYPERPARAMETERS\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Hyperparameters are settings used in the value function for the LATS algorithm<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"REFLEXION\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">Reflexion is an algorithm compared with LATS in the HumanEval experiments<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"FIG. 3\">      <data key=\"d0\">FIGURE<\/data>      <data key=\"d1\">Figure 3 shows the results of the HumanEval experiments and the performance of LATS over time<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"FIG. 4\">      <data key=\"d0\">FIGURE<\/data>      <data key=\"d1\">Figure 4 illustrates how ReAct and LATS work on an example task of HotPotQA<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"ALGORITHM 1\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">Algorithm 1 describes the LATS process, including initialization, expansion, simulation, evaluation, selection, and backpropagation<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"TAB. 8\">      <data key=\"d0\">FIGURE<\/data>      <data key=\"d1\">Table 8 shows the results for HotPotQA<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"SAMPLING SIZE\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Sampling size is a parameter used in the HumanEval dataset, with a value of n=5<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"TRAJECTORIES\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Trajectories refer to the number of paths sampled in the HumanEval and HotPotQA experiments, with a maximum of k=8<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"SELECTION FORMULA\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Selection formula is used in the LATS algorithm to choose actions based on exploration weight and value function<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"STATE SPACE\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">State space refers to the complexity of the environment in which the LATS algorithm operates<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"ROLL-OUTS\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Roll-outs refer to the number of iterations (K) in the LATS algorithm<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"CONTEXT\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Context (c) is part of the state in the LATS algorithm<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"VISIT COUNTER\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Visit counter (N) is used in the LATS algorithm to track the number of visits to each state<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"ACTION SPACE\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Action space (A) is the set of possible actions in the LATS algorithm<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"OBSERVATION SPACE\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Observation space (O) is the set of possible observations in the LATS algorithm<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"INITIAL STATE\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Initial state (s) is the starting point in the LATS algorithm<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"ACTION GENERATOR\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Action generator (p&#952;) is used to sample actions in the LATS algorithm<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"VALUE FUNCTION\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Value function (pV) is used to evaluate states in the LATS algorithm<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"REFLECTION GENERATOR\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Reflection generator (pref) is used to generate reflections in the LATS algorithm<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"ENVIRONMENT\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Environment provides the context and rewards for the LATS algorithm<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"REWARD\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Reward (r) is the feedback from the environment in the LATS algorithm<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"TERMINAL STATE\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Terminal state (st) is a state where the process ends in the LATS algorithm<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"SUCCESS\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Success is a condition checked in the reflection phase of the LATS algorithm<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"EVALUATION OPERATION\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Evaluation operation is used to score states in the LATS algorithm<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"TRAJECTORY\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Trajectory refers to the path taken through the state space in the LATS algorithm<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"ITERATIONS\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Iterations refer to the number of times the LATS algorithm is run<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"SUPPORTING FACTS\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Supporting facts are provided by crowdworkers in the HotPotQA dataset to justify answers<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"ENTITY\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Entity is a type of question in the HotPotQA dataset<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"LOCATION\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Location is a type of question in the HotPotQA dataset<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"DATE\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Date is a type of question in the HotPotQA dataset<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"COMPARISON\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Comparison is a type of question in the HotPotQA dataset<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"SHARED PROPERTIES\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Shared properties are compared between two entities in the HotPotQA dataset<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"SUPPORTING DOCUMENTS\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Supporting documents are used to answer questions in the HotPotQA dataset<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"QUESTION-ANSWER PAIRS\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Question-answer pairs are crafted by crowdworkers in the HotPotQA dataset<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"WIKIPEDIA PARAGRAPHS\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Wikipedia paragraphs are used in the HotPotQA benchmark setting<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"SUBSET OF 100 QUESTIONS\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">A randomly selected subset of 100 questions is used in the HotPotQA experiments<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"MAXIMUM DEPTH LIMIT\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Maximum depth limit is set to 6 in the HotPotQA experiments<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"VALUE FUNCTION HYPERPARAMETERS\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Value function hyperparameters include &#955;=0.5 for the LM score and self-consistency score in the LATS algorithm<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"SEARCH [ENTITY]\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Search [entity] is an action type in the Wikipedia web API used in the LATS algorithm<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <node id=\"LOOKUP [STRING]\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Lookup [string] is an action type in the Wikipedia web API used in the LATS algorithm<\/data>      <data key=\"d2\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/node>    <edge source=\"HUMANEVAL\" target=\"LATS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS is evaluated using the HumanEval dataset<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"HUMANEVAL\" target=\"REFLEXION\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Reflexion is compared with LATS in the HumanEval experiments<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"HUMANEVAL\" target=\"FIG. 3\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Figure 3 shows the results of the HumanEval experiments<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"HUMANEVAL\" target=\"SAMPLING SIZE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Sampling size is a parameter used in the HumanEval dataset<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"HUMANEVAL\" target=\"TRAJECTORIES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Trajectories refer to the number of paths sampled in the HumanEval experiments<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"LATS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS is evaluated using the HotPotQA dataset<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"CROWDWORKERS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Crowdworkers crafted the question-answer pairs in the HotPotQA dataset<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"WIKIPEDIA\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Wikipedia is the source of the documents used in the HotPotQA dataset<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"FIG. 4\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Figure 4 illustrates an example task of HotPotQA<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"TAB. 8\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Table 8 shows the results for HotPotQA<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"TRAJECTORIES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Trajectories refer to the number of paths sampled in the HotPotQA experiments<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"SUPPORTING FACTS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Supporting facts are provided by crowdworkers in the HotPotQA dataset to justify answers<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"ENTITY\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Entity is a type of question in the HotPotQA dataset<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"LOCATION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Location is a type of question in the HotPotQA dataset<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"DATE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Date is a type of question in the HotPotQA dataset<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"COMPARISON\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Comparison is a type of question in the HotPotQA dataset<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"SHARED PROPERTIES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Shared properties are compared between two entities in the HotPotQA dataset<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"SUPPORTING DOCUMENTS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Supporting documents are used to answer questions in the HotPotQA dataset<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"QUESTION-ANSWER PAIRS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Question-answer pairs are crafted by crowdworkers in the HotPotQA dataset<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"WIKIPEDIA PARAGRAPHS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Wikipedia paragraphs are used in the HotPotQA benchmark setting<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"SUBSET OF 100 QUESTIONS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">A randomly selected subset of 100 questions is used in the HotPotQA experiments<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"HOTPOTQA\" target=\"MAXIMUM DEPTH LIMIT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Maximum depth limit is set to 6 in the HotPotQA experiments<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"EXPLORATION WEIGHT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Exploration weight is a parameter in the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"DEPTH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Depth is a parameter in the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"LM VALUE FUNCTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The LM value function is used in the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"YAO ET AL., 2023B\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Yao et al., 2023b is referenced for setting the maximum depth in LATS experiments<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"WIKIPEDIA WEB API\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Wikipedia web API is used for interactive information retrieval in the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"REACT\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">LATS is compared with ReAct in the HotPotQA experiments<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"LANGUAGE MODELS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Language models are used in the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"HYPERPARAMETERS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Hyperparameters are used in the value function for the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"FIG. 3\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Figure 3 shows the performance of LATS over time<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"FIG. 4\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Figure 4 illustrates how LATS works on an example task of HotPotQA<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"ALGORITHM 1\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Algorithm 1 describes the LATS process<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"SELECTION FORMULA\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Selection formula is used in the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"STATE SPACE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">State space refers to the complexity of the environment in which the LATS algorithm operates<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"ROLL-OUTS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Roll-outs refer to the number of iterations (K) in the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"CONTEXT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Context (c) is part of the state in the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"VISIT COUNTER\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Visit counter (N) is used in the LATS algorithm to track the number of visits to each state<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"ACTION SPACE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Action space (A) is the set of possible actions in the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"OBSERVATION SPACE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Observation space (O) is the set of possible observations in the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"INITIAL STATE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Initial state (s) is the starting point in the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"ACTION GENERATOR\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Action generator (p&#952;) is used to sample actions in the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"VALUE FUNCTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Value function (pV) is used to evaluate states in the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"REFLECTION GENERATOR\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Reflection generator (pref) is used to generate reflections in the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"ENVIRONMENT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Environment provides the context and rewards for the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"REWARD\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Reward (r) is the feedback from the environment in the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"TERMINAL STATE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Terminal state (st) is a state where the process ends in the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"SUCCESS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Success is a condition checked in the reflection phase of the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"EVALUATION OPERATION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Evaluation operation is used to score states in the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"TRAJECTORY\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Trajectory refers to the path taken through the state space in the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"ITERATIONS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Iterations refer to the number of times the LATS algorithm is run<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"LATS\" target=\"VALUE FUNCTION HYPERPARAMETERS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Value function hyperparameters include &#955;=0.5 for the LM score and self-consistency score in the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"WIKIPEDIA WEB API\" target=\"SEARCH [ENTITY]\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Search [entity] is an action type in the Wikipedia web API used in the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"WIKIPEDIA WEB API\" target=\"LOOKUP [STRING]\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Lookup [string] is an action type in the Wikipedia web API used in the LATS algorithm<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>    <edge source=\"REACT\" target=\"FIG. 4\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Figure 4 illustrates how ReAct works on an example task of HotPotQA<\/data>      <data key=\"d5\">48e423e2baf2ed485872756f5b4d87d8<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"fb2b4544aedd793e4d4ec3147320a51c","chunk":"interactive information retrieval:\n(1)search [entity ], which returns the first 5 sentences\nfrom the corresponding entity wiki page if it exists,\nor else suggests top-5 similar entities from the Wikipedia\nsearch engine,\n(2)lookup [string ], which returns the next sentence in\n15Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nPrompt Method HotpotQA (EM) \u2191\nLATS ( w= 0.5) 0.55\nLATS ( w= 2.0) 0.63\nLATS ( d= 4) 0.58\nLATS (CoT) 0.62\nLATS (No LM Heuristic) 0.37\nLATS ( w= 1.0,d= 7) 0.63\nTable 11. Ablation results on LATS and baseline variants in Hot-\nPotQA measured by Exact Match (EM). We test different depth d,\nexploration factor w, and versions of LATS using CoT and without\nthe LM value function. We sample n= 5andk= 50 trajectories.\nFigure 3. Performance over successive iterations on HumanEval\nwith GPT-3.5.\nthe page containing string ,\n(3)finish [answer ], which finishes the current task with\nanswer .\nThese API calls and free-form thoughts form the action\nspace for this environment.\nD.2. Programming\nThe HumanEval dataset (Chen et al., 2021) is a collection\nof 164 handwritten programming problems introduced to\nevaluate the functional correctness of models for synthe-\nsizing programs from natural language descriptions. Each\nproblem includes a function signature, docstring descrip-\ntion, reference implementation, and multiple unit tests, with\nan average of 7.7 tests per problem. The programming\ntasks assess comprehension of natural language, reasoning,\nalgorithms, and basic mathematics, at a difficulty level com-\nparable to simple software interview questions. Pass rates\nare evaluated with the pass@k metric, where k samples are\ngenerated per problem and a problem is considered solvedif any sample passes all tests. We use all 164 problems for\nour experiments and a maximum depth limit of 8. For the\nthree questions without sample test cases, we write our own.\nFor value function hyperparameters, we use \u03bb= 0.8for the\nLM score and self-consistency score. For GPT-3.5 we use\nsix internal tests, while for GPT-4 we use four internal tests.\nThe Mostly Basic Programming Problems (MBPP) (Austin\net al., 2022) benchmark contains 974 short Python functions\ndesigned to evaluate program synthesis techniques. The\ndataset was constructed by crowdsourcing from workers\nwith basic Python knowledge. Each data point consists of\na natural language description of a programming task, a\nreference solution implementation, and three test cases for\nfunctional correctness. The natural language prompts are\ntypically short, one-sentence descriptions. Solutions cover\ncommon programming constructs including mathematical\noperations, list processing, string manipulation, and usage\nof the Python standard library. On average, solutions are 6.8\nlines of code. The dataset is also supplemented with an ad-\nditional set of 426 problems that were manually verified for\nunambiguous specifications, standard function signatures,\nand accurate test cases. We use a randomly selected subset\nof 397 problems for our experiments. For value function\nhyperparameters, we use \u03bb= 0.8for the LM score and\nself-consistency score.\nD.3. WebShop\nWebShop (Yao et al., 2022) is an interactive web-based\nenvironment designed to evaluate agents on grounded\nlanguage understanding and decision-making. It simulates\nan e-commerce shopping task by providing agents with\nover 1 million real-world products scraped from Amazon,\nspanning 5 categories and 113 subcategories. These\nproducts contain rich linguistic information, with an\naverage text length of 262 words and a vocabulary size\nof 224k. In addition, there are over 800k unique product\noptions available for customization. The environment\nrenders webpages in two modes: HTML mode provides\npixel-level observations with interactive elements, while\nsimple mode converts the raw HTML into a structured text\nobservation more amenable for training agents. The action\nspace consists of query searches and button clicks, which\ntransition between 4-page types: search, results, item, and\nitem detail. Instructions are crowdsourced natural language\nspecifying product attributes and options, with a total of 12k\ncollected. Automatic rewards are computed by comparing\nthe product purchased by the agent against the attributes\nand options specified in the instruction, using both lexical\nmatching and semantic similarity metrics.\nThere are two evaluation metrics used in WebShop: (1) Task\nScore defined as (100\u00d7avg. reward ), which captures the\n16Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nFigure 4. Example trajectories on HotPotQA for ReAct ( left) and LATS ( right ). LATS can sample more actions and avoid failure from\nprevious mistakes by evaluating states with an LM to guide the search toward promising areas of the tree.\nType Argument State \u2192Next State\nsearch [Query ] Search \u2192Results\nchoose Back to search \u2217 \u2192 Search\nchoose Prev\/Next page Results \u2192Results\nchoose [Product title ] Results \u2192Item\nchoose [Option ] Item \u2192Item\nchoose Desc\/Overview Item \u2192Item-Detail\nchoose Previous Item-Detail \u2192Item\nchoose Buy Item \u2192Episode End\nTable 12. Action space of WebShop.\naverage reward obtained across episodes; and (2) Success\nRate (SR) defined as the portion","chunk_id":"fb2b4544aedd793e4d4ec3147320a51c","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"SEARCH","type":"ACTION\/COMMAND","description":"The search command returns the first 5 sentences from the corresponding entity wiki page if it exists, or suggests top-5 similar entities from the Wikipedia search engine.","source_id":"fb2b4544aedd793e4d4ec3147320a51c","entity_type":"ACTION\/COMMAND"},{"name":"LOOKUP","type":"ACTION\/COMMAND","description":"The lookup command returns the next sentence in the page containing the specified string.","source_id":"fb2b4544aedd793e4d4ec3147320a51c","entity_type":"ACTION\/COMMAND"},{"name":"FINISH","type":"ACTION\/COMMAND","description":"The finish command completes the current task with the provided answer.","source_id":"fb2b4544aedd793e4d4ec3147320a51c","entity_type":"ACTION\/COMMAND"},{"name":"LATS","type":"METHOD\/TECHNIQUE","description":"Language Agent Tree Search (LATS) is a method used in language models for reasoning, acting, and planning, with various configurations tested for performance.","source_id":"fb2b4544aedd793e4d4ec3147320a51c","entity_type":"METHOD\/TECHNIQUE"},{"name":"HOTPOTQA","type":"DATASET\/BENCHMARK","description":"HotPotQA is a dataset used to measure the performance of models in answering questions, with metrics such as Exact Match (EM) used for evaluation.","source_id":"fb2b4544aedd793e4d4ec3147320a51c","entity_type":"DATASET\/BENCHMARK"},{"name":"GPT-3.5","type":"MODEL","description":"GPT-3.5 is a version of OpenAI's language model used for evaluating performance on tasks such as HumanEval.","source_id":"fb2b4544aedd793e4d4ec3147320a51c","entity_type":"MODEL"},{"name":"GPT-4","type":"MODEL","description":"GPT-4 is a version of OpenAI's language model used for evaluating performance on tasks such as HumanEval.","source_id":"fb2b4544aedd793e4d4ec3147320a51c","entity_type":"MODEL"},{"name":"HUMANEVAL","type":"DATASET\/BENCHMARK","description":"HumanEval is a dataset of 164 handwritten programming problems used to evaluate the functional correctness of models for synthesizing programs from natural language descriptions.","source_id":"fb2b4544aedd793e4d4ec3147320a51c","entity_type":"DATASET\/BENCHMARK"},{"name":"MBPP","type":"DATASET\/BENCHMARK","description":"Mostly Basic Programming Problems (MBPP) is a benchmark containing 974 short Python functions designed to evaluate program synthesis techniques.","source_id":"fb2b4544aedd793e4d4ec3147320a51c","entity_type":"DATASET\/BENCHMARK"},{"name":"WEBSHOP","type":"ENVIRONMENT\/PLATFORM","description":"WebShop is an interactive web-based environment designed to evaluate agents on grounded language understanding and decision-making, simulating an e-commerce shopping task.","source_id":"fb2b4544aedd793e4d4ec3147320a51c","entity_type":"ENVIRONMENT\/PLATFORM"},{"name":"AMAZON","type":"COMPANY\/PLATFORM","description":"Amazon is an e-commerce platform from which over 1 million real-world products were scraped for the WebShop environment.","source_id":"fb2b4544aedd793e4d4ec3147320a51c","entity_type":"COMPANY\/PLATFORM"},{"name":"TASK SCORE","type":"METRIC","description":"Task Score is an evaluation metric in WebShop defined as 100 times the average reward obtained across episodes.","source_id":"fb2b4544aedd793e4d4ec3147320a51c","entity_type":"METRIC"},{"name":"SUCCESS RATE","type":"METRIC","description":"Success Rate (SR) is an evaluation metric in WebShop defined as the portion of successful episodes.","source_id":"fb2b4544aedd793e4d4ec3147320a51c","entity_type":"METRIC"},{"name":"INTERACTIVE INFORMATION RETRIEVAL","type":"","description":"","source_id":"fb2b4544aedd793e4d4ec3147320a51c"},{"name":"PROGRAMMING","type":"ACTIVITY","description":"Programming involves writing code to solve problems, often evaluated through datasets like HumanEval and MBPP.","source_id":"fb2b4544aedd793e4d4ec3147320a51c"},{"name":"FUNCTION SIGNATURE","type":"COMPONENT","description":"A function signature is part of a programming problem, including the function name and parameters.","source_id":"fb2b4544aedd793e4d4ec3147320a51c"},{"name":"DOCSTRING","type":"COMPONENT","description":"A docstring is a description of a function's purpose and behavior, included in programming problems.","source_id":"fb2b4544aedd793e4d4ec3147320a51c"},{"name":"REFERENCE IMPLEMENTATION","type":"COMPONENT","description":"A reference implementation is a sample solution provided for a programming problem.","source_id":"fb2b4544aedd793e4d4ec3147320a51c"},{"name":"UNIT TESTS","type":"COMPONENT","description":"Unit tests are tests provided to check the correctness of a function implementation in programming problems.","source_id":"fb2b4544aedd793e4d4ec3147320a51c"},{"name":"NATURAL LANGUAGE DESCRIPTION","type":"COMPONENT","description":"A natural language description explains a programming task in plain language, used in datasets like HumanEval and MBPP.","source_id":"fb2b4544aedd793e4d4ec3147320a51c"},{"name":"ALGORITHMS","type":"CONCEPT","description":"Algorithms are step-by-step procedures for solving problems, often evaluated in programming tasks.","source_id":"fb2b4544aedd793e4d4ec3147320a51c"},{"name":"BASIC MATHEMATICS","type":"CONCEPT","description":"Basic mathematics involves fundamental mathematical operations, often required in programming tasks.","source_id":"fb2b4544aedd793e4d4ec3147320a51c"},{"name":"CROWDSOURCING","type":"PROCESS","description":"Crowdsourcing involves gathering input or data from a large group of people, used to create datasets like MBPP.","source_id":"fb2b4544aedd793e4d4ec3147320a51c"},{"name":"PYTHON","type":"LANGUAGE","description":"Python is a programming language used in datasets like MBPP for writing short functions.","source_id":"fb2b4544aedd793e4d4ec3147320a51c"},{"name":"QUERY SEARCHES","type":"ACTION\/COMMAND","description":"Query searches are actions in WebShop that allow agents to search for products based on specified criteria.","source_id":"fb2b4544aedd793e4d4ec3147320a51c"},{"name":"BUTTON CLICKS","type":"ACTION\/COMMAND","description":"Button clicks are actions in WebShop that allow agents to interact with the web interface, such as selecting products or navigating pages.","source_id":"fb2b4544aedd793e4d4ec3147320a51c"},{"name":"HTML MODE","type":"MODE","description":"HTML mode in WebShop provides pixel-level observations with interactive elements for agents to interact with.","source_id":"fb2b4544aedd793e4d4ec3147320a51c"},{"name":"SIMPLE MODE","type":"MODE","description":"Simple mode in WebShop converts raw HTML into structured text observations for easier training of agents.","source_id":"fb2b4544aedd793e4d4ec3147320a51c"},{"name":"LEXICAL MATCHING","type":"TECHNIQUE","description":"Lexical matching is a technique used in WebShop to compare the product purchased by the agent against specified attributes and options.","source_id":"fb2b4544aedd793e4d4ec3147320a51c"},{"name":"SEMANTIC SIMILARITY","type":"TECHNIQUE","description":"Semantic similarity is a technique used in WebShop to compare the product purchased by the agent against specified attributes and options based on meaning.","source_id":"fb2b4544aedd793e4d4ec3147320a51c"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"SEARCH\">      <data key=\"d0\">ACTION\/COMMAND<\/data>      <data key=\"d1\">The search command returns the first 5 sentences from the corresponding entity wiki page if it exists, or suggests top-5 similar entities from the Wikipedia search engine.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>      <data key=\"d3\">ACTION\/COMMAND<\/data>    <\/node>    <node id=\"LOOKUP\">      <data key=\"d0\">ACTION\/COMMAND<\/data>      <data key=\"d1\">The lookup command returns the next sentence in the page containing the specified string.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>      <data key=\"d3\">ACTION\/COMMAND<\/data>    <\/node>    <node id=\"FINISH\">      <data key=\"d0\">ACTION\/COMMAND<\/data>      <data key=\"d1\">The finish command completes the current task with the provided answer.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>      <data key=\"d3\">ACTION\/COMMAND<\/data>    <\/node>    <node id=\"LATS\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Language Agent Tree Search (LATS) is a method used in language models for reasoning, acting, and planning, with various configurations tested for performance.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>      <data key=\"d3\">METHOD\/TECHNIQUE<\/data>    <\/node>    <node id=\"HOTPOTQA\">      <data key=\"d0\">DATASET\/BENCHMARK<\/data>      <data key=\"d1\">HotPotQA is a dataset used to measure the performance of models in answering questions, with metrics such as Exact Match (EM) used for evaluation.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>      <data key=\"d3\">DATASET\/BENCHMARK<\/data>    <\/node>    <node id=\"GPT-3.5\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-3.5 is a version of OpenAI's language model used for evaluating performance on tasks such as HumanEval.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4 is a version of OpenAI's language model used for evaluating performance on tasks such as HumanEval.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"HUMANEVAL\">      <data key=\"d0\">DATASET\/BENCHMARK<\/data>      <data key=\"d1\">HumanEval is a dataset of 164 handwritten programming problems used to evaluate the functional correctness of models for synthesizing programs from natural language descriptions.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>      <data key=\"d3\">DATASET\/BENCHMARK<\/data>    <\/node>    <node id=\"MBPP\">      <data key=\"d0\">DATASET\/BENCHMARK<\/data>      <data key=\"d1\">Mostly Basic Programming Problems (MBPP) is a benchmark containing 974 short Python functions designed to evaluate program synthesis techniques.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>      <data key=\"d3\">DATASET\/BENCHMARK<\/data>    <\/node>    <node id=\"WEBSHOP\">      <data key=\"d0\">ENVIRONMENT\/PLATFORM<\/data>      <data key=\"d1\">WebShop is an interactive web-based environment designed to evaluate agents on grounded language understanding and decision-making, simulating an e-commerce shopping task.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>      <data key=\"d3\">ENVIRONMENT\/PLATFORM<\/data>    <\/node>    <node id=\"AMAZON\">      <data key=\"d0\">COMPANY\/PLATFORM<\/data>      <data key=\"d1\">Amazon is an e-commerce platform from which over 1 million real-world products were scraped for the WebShop environment.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>      <data key=\"d3\">COMPANY\/PLATFORM<\/data>    <\/node>    <node id=\"TASK SCORE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Task Score is an evaluation metric in WebShop defined as 100 times the average reward obtained across episodes.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>      <data key=\"d3\">METRIC<\/data>    <\/node>    <node id=\"SUCCESS RATE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Success Rate (SR) is an evaluation metric in WebShop defined as the portion of successful episodes.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>      <data key=\"d3\">METRIC<\/data>    <\/node>    <node id=\"INTERACTIVE INFORMATION RETRIEVAL\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/node>    <node id=\"PROGRAMMING\">      <data key=\"d0\">ACTIVITY<\/data>      <data key=\"d1\">Programming involves writing code to solve problems, often evaluated through datasets like HumanEval and MBPP.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/node>    <node id=\"FUNCTION SIGNATURE\">      <data key=\"d0\">COMPONENT<\/data>      <data key=\"d1\">A function signature is part of a programming problem, including the function name and parameters.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/node>    <node id=\"DOCSTRING\">      <data key=\"d0\">COMPONENT<\/data>      <data key=\"d1\">A docstring is a description of a function's purpose and behavior, included in programming problems.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/node>    <node id=\"REFERENCE IMPLEMENTATION\">      <data key=\"d0\">COMPONENT<\/data>      <data key=\"d1\">A reference implementation is a sample solution provided for a programming problem.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/node>    <node id=\"UNIT TESTS\">      <data key=\"d0\">COMPONENT<\/data>      <data key=\"d1\">Unit tests are tests provided to check the correctness of a function implementation in programming problems.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/node>    <node id=\"NATURAL LANGUAGE DESCRIPTION\">      <data key=\"d0\">COMPONENT<\/data>      <data key=\"d1\">A natural language description explains a programming task in plain language, used in datasets like HumanEval and MBPP.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/node>    <node id=\"ALGORITHMS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Algorithms are step-by-step procedures for solving problems, often evaluated in programming tasks.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/node>    <node id=\"BASIC MATHEMATICS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Basic mathematics involves fundamental mathematical operations, often required in programming tasks.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/node>    <node id=\"CROWDSOURCING\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Crowdsourcing involves gathering input or data from a large group of people, used to create datasets like MBPP.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/node>    <node id=\"PYTHON\">      <data key=\"d0\">LANGUAGE<\/data>      <data key=\"d1\">Python is a programming language used in datasets like MBPP for writing short functions.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/node>    <node id=\"QUERY SEARCHES\">      <data key=\"d0\">ACTION\/COMMAND<\/data>      <data key=\"d1\">Query searches are actions in WebShop that allow agents to search for products based on specified criteria.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/node>    <node id=\"BUTTON CLICKS\">      <data key=\"d0\">ACTION\/COMMAND<\/data>      <data key=\"d1\">Button clicks are actions in WebShop that allow agents to interact with the web interface, such as selecting products or navigating pages.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/node>    <node id=\"HTML MODE\">      <data key=\"d0\">MODE<\/data>      <data key=\"d1\">HTML mode in WebShop provides pixel-level observations with interactive elements for agents to interact with.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/node>    <node id=\"SIMPLE MODE\">      <data key=\"d0\">MODE<\/data>      <data key=\"d1\">Simple mode in WebShop converts raw HTML into structured text observations for easier training of agents.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/node>    <node id=\"LEXICAL MATCHING\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Lexical matching is a technique used in WebShop to compare the product purchased by the agent against specified attributes and options.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/node>    <node id=\"SEMANTIC SIMILARITY\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Semantic similarity is a technique used in WebShop to compare the product purchased by the agent against specified attributes and options based on meaning.<\/data>      <data key=\"d2\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/node>    <edge source=\"LOOKUP\" target=\"INTERACTIVE INFORMATION RETRIEVAL\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Lookup is one of the commands used in interactive information retrieval to return the next sentence containing a specified string.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"FINISH\" target=\"INTERACTIVE INFORMATION RETRIEVAL\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Finish is one of the commands used in interactive information retrieval to complete the current task.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"LATS\" target=\"HOTPOTQA\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">LATS is evaluated on the HotPotQA dataset using metrics such as Exact Match (EM).<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"GPT-3.5\" target=\"HUMANEVAL\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">GPT-3.5 is used to evaluate performance on the HumanEval dataset.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"HUMANEVAL\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">GPT-4 is used to evaluate performance on the HumanEval dataset.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"HUMANEVAL\" target=\"PROGRAMMING\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Programming tasks are evaluated using the HumanEval dataset.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"HUMANEVAL\" target=\"FUNCTION SIGNATURE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Function signatures are part of the programming problems in the HumanEval dataset.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"HUMANEVAL\" target=\"DOCSTRING\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Docstrings are part of the programming problems in the HumanEval dataset.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"HUMANEVAL\" target=\"REFERENCE IMPLEMENTATION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Reference implementations are provided for programming problems in the HumanEval dataset.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"HUMANEVAL\" target=\"UNIT TESTS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Unit tests are provided to check the correctness of function implementations in the HumanEval dataset.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"HUMANEVAL\" target=\"NATURAL LANGUAGE DESCRIPTION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Natural language descriptions explain programming tasks in the HumanEval dataset.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"HUMANEVAL\" target=\"ALGORITHMS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Algorithms are evaluated through programming tasks in the HumanEval dataset.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"HUMANEVAL\" target=\"BASIC MATHEMATICS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Basic mathematics is evaluated through programming tasks in the HumanEval dataset.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"MBPP\" target=\"WEBSHOP\">      <data key=\"d4\">12.0<\/data>      <data key=\"d5\">MBPP is a benchmark used to evaluate program synthesis techniques, while WebShop evaluates agents on grounded language understanding and decision-making.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"MBPP\" target=\"PROGRAMMING\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Programming tasks are evaluated using the MBPP dataset.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"MBPP\" target=\"NATURAL LANGUAGE DESCRIPTION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Natural language descriptions explain programming tasks in the MBPP dataset.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"MBPP\" target=\"CROWDSOURCING\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Crowdsourcing was used to create the MBPP dataset.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"MBPP\" target=\"PYTHON\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Python is the programming language used in the MBPP dataset.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"AMAZON\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Amazon is the source of over 1 million real-world products used in the WebShop environment.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"TASK SCORE\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Task Score is one of the evaluation metrics used in the WebShop environment.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"SUCCESS RATE\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Success Rate is one of the evaluation metrics used in the WebShop environment.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"QUERY SEARCHES\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Query searches are actions in WebShop that allow agents to search for products.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"BUTTON CLICKS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Button clicks are actions in WebShop that allow agents to interact with the web interface.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"HTML MODE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">HTML mode in WebShop provides pixel-level observations for agents.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"SIMPLE MODE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Simple mode in WebShop converts raw HTML into structured text observations.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"LEXICAL MATCHING\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Lexical matching is used in WebShop to compare purchased products against specified attributes.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"SEMANTIC SIMILARITY\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Semantic similarity is used in WebShop to compare purchased products against specified attributes based on meaning.<\/data>      <data key=\"d6\">fb2b4544aedd793e4d4ec3147320a51c<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"b8dd0300033963bb4a3e1bad37f8e7b9","chunk":" State\nsearch [Query ] Search \u2192Results\nchoose Back to search \u2217 \u2192 Search\nchoose Prev\/Next page Results \u2192Results\nchoose [Product title ] Results \u2192Item\nchoose [Option ] Item \u2192Item\nchoose Desc\/Overview Item \u2192Item-Detail\nchoose Previous Item-Detail \u2192Item\nchoose Buy Item \u2192Episode End\nTable 12. Action space of WebShop.\naverage reward obtained across episodes; and (2) Success\nRate (SR) defined as the portion of instructions where r= 1.\nThe reward is calculated based on the number of attributes\nsatisfied by the selected item. We use 50 environments for\nour experiments and a maximum depth limit of 15. For\nvalue function hyperparameters, we use \u03bb= 0.8for the LM\nscore and self-consistency score.\nD.4. Game of 24\nGame of 24 is a mathematical reasoning challenge where\nthe goal is to use basic arithmetic operations to construct\n24 out of 4 numbers. We follow the setup from Yao et al.\n(2023a), where we measure success if the agent produces aPrompt Method Game of 24 (Success Rate) \u2191\nLATS (CoT, \u03bb= 1) 0.40\nLATS (CoT) 0.44\nTable 13. Ablations on \u03bbin Game of 24 with GPT-3.5. \u03bb= 0.5\nused in the main paper outperforms \u03bb= 1, equivalent to removing\nself-consistency, which indicates that the self-consistency score\nimproves the performance of LATS.\ncorrect equation that equals 24 and uses each input number\nonly once. We report success rate over 50 games. We use\nk= 30 iterations and a maximum depth limit of 5. For value\nfunction hyperparameters, we use \u03bb= 0.5for the LM score\nand self-consistency score. Tab. 13 shows the performance\ncomparison between \u03bb= 0.5and\u03bb= 1, which validates\nour design of self-consistency term.\nE. HotPotQA Prompts\nE.1. Base Acting Prompt\nSolve a question answering task with interleaving Thought,\nAction, Observation steps. Thought can reason about the\ncurrent situation, and Action can be three types:\n(1) Search[entity], which searches the exact entity on\nWikipedia and returns the first paragraph if it exists. If\nnot, it will return some similar entities to search.\n17Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\n(2) Lookup[keyword], which returns the next sentence con-\ntaining keyword in the current passage.\n(3) Finish[answer], which returns the answer and finishes\nthe task.\nAfter each observation, provide the next Thought and next\nAction.\nHere are some examples:\nQuestion: Which magazine was started first Arthur\u2019s Maga-\nzine or First for Women?\nThought 1: I need to search Arthur\u2019s Magazine and First for\nWomen, and find which was started first.\nAction 1: Search[Arthur\u2019s Magazine]\nObservation 1: Arthur\u2019s Magazine was an American literary\nperiodical published in Philadelphia in the 19th century.\nEdited by Timothy Shay Arthur, it featured work by Edgar\nA. Poe, J.H. Ingraham, Sarah Josepha Hale, Thomas G.\nSpear, and others.[1][2] In May 1846 it was merged into\nGodey\u2019s Lady\u2019s Book.[3]\nThought 2: Arthur\u2019s Magazine was started in 1844. I need\nto search First for Women next.\nAction 2: Search[First for Women]\nObservation 2: First for Women is a woman\u2019s magazine\npublished by Bauer Media Group in the USA.[1] The mag-\nazine was started in 1989. It is based in Englewood Cliffs,\nNew Jersey.[2] In 2011 the circulation of the magazine was\n1,310,696 copies.[3]\nThought 3: First for Women was started in 1989. 1844\n(Arthur\u2019s Magazine) <1989 (First for Women), so Arthur\u2019s\nMagazine was started first.\nAction 3: Finish[Arthur\u2019s Magazine]\n(examples)\nYou have attempted to answer the following question before\nand failed. The following reflection(s) give a plan to avoid\nfailing to answer the question in the same way you did\npreviously. Use them to improve your strategy of correctly\nanswering the given question.\n(trajectories)\n(input)\nE.2. Base Reasoning Prompt\nSolve a question answering task by having a Thought, then\nFinish with your answer. Thought can reason about the\ncurrent situation. Finish[answer] returns the answer and\nfinishes the task. You will be given context that you should\nuse to help you answer the question. Start your responsewith either Action or an indexed Thought\nHere are some examples:\nQuestion: What is the elevation range for the area that the\neastern sector of the Colorado orogeny extends into?\nLet\u2019s think step by step.\nThought 1: The eastern sector of Colorado orogeny extends\ninto the High Plains.\nThought 2: High Plains rise in elevation from around 1,800\nto 7,000 ft\nThought 3: The answer is 1,800 to 7,000 ft.\nAction: Finish[1,800 to 7,000 ft]\n(examples)\nPrevious trial: (trajectories)\n(input)\nE.3. Value Function Prompt\nAnalyze the trajectories of a solution to a question answering\ntask. The trajectories are labeled by environmental Obser-\nvations about the situation, Thoughts","chunk_id":"b8dd0300033963bb4a3e1bad37f8e7b9","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"WEBSHOP","type":"TOOL\/PLATFORM","description":"WebShop is a platform with an action space that includes various actions like searching, selecting products, and purchasing items","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"GAME OF 24","type":"GAME\/CHALLENGE","description":"Game of 24 is a mathematical reasoning challenge where the goal is to use basic arithmetic operations to construct the number 24 from four given numbers","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"GPT-3.5","type":"MODEL","description":"GPT-3.5 is a version of OpenAI's language model used in experiments for the Game of 24","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"LATS","type":"METHOD\/TECHNIQUE","description":"LATS (Language Agent Tree Search) is a method used in the Game of 24 to improve performance by incorporating self-consistency scores","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"HOTPOTQA","type":"DATASET\/TASK","description":"HotPotQA is a question answering task that involves interleaving Thought, Action, and Observation steps to solve questions","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"BAUER MEDIA GROUP","type":"ORGANIZATION","description":"Bauer Media Group is the publisher of the magazine First for Women","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"ARTHUR'S MAGAZINE","type":"PUBLICATION","description":"Arthur's Magazine was an American literary periodical published in Philadelphia in the 19th century","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"FIRST FOR WOMEN","type":"PUBLICATION","description":"First for Women is a woman's magazine published by Bauer Media Group in the USA, started in 1989","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"GODEY'S LADY'S BOOK","type":"PUBLICATION","description":"Godey's Lady's Book was a magazine that Arthur's Magazine was merged into in May 1846","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"QUERY","type":"ACTION","description":"Query is an action in WebShop where a search is performed","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"RESULTS","type":"STATE","description":"Results is a state in WebShop where search results are displayed","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"ITEM","type":"STATE","description":"Item is a state in WebShop where a specific product is selected","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"ITEM-DETAIL","type":"STATE","description":"Item-Detail is a state in WebShop where detailed information about a selected item is displayed","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"EPISODE END","type":"STATE","description":"Episode End is a state in WebShop where the buying process is completed","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"REWARD","type":"METRIC","description":"Reward is a metric in WebShop calculated based on the number of attributes satisfied by the selected item","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"SUCCESS RATE","type":"METRIC","description":"Success Rate (SR) is a metric in WebShop defined as the portion of instructions where the reward equals 1","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"VALUE FUNCTION","type":"METHOD\/TECHNIQUE","description":"Value Function is a method used in WebShop and Game of 24 to evaluate the performance of actions","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"SELF-CONSISTENCY SCORE","type":"METRIC","description":"Self-Consistency Score is a metric used in LATS to improve performance in the Game of 24","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"PROMPT","type":"METHOD\/TECHNIQUE","description":"Prompt is a method used in HotPotQA to guide the question answering process","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"THOUGHT","type":"ACTION","description":"Thought is an action in HotPotQA where reasoning about the current situation is performed","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"ACTION","type":"ACTION","description":"Action is an action in HotPotQA where a specific task is performed based on the Thought","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"OBSERVATION","type":"ACTION","description":"Observation is an action in HotPotQA where the result of an Action is analyzed","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"FINISH","type":"ACTION","description":"Finish is an action in HotPotQA where the final answer is provided and the task is completed","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"SEARCH","type":"ACTION","description":"Search is an action in HotPotQA where an entity is searched on Wikipedia","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"LOOKUP","type":"ACTION","description":"Lookup is an action in HotPotQA where the next sentence containing a keyword in the current passage is returned","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"COLORADO OROGENY","type":"ENTITY","description":"Colorado Orogeny is a geological event mentioned in a question in HotPotQA","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"},{"name":"HIGH PLAINS","type":"ENTITY","description":"High Plains is a region mentioned in a question in HotPotQA","source_id":"b8dd0300033963bb4a3e1bad37f8e7b9"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"WEBSHOP\">      <data key=\"d0\">TOOL\/PLATFORM<\/data>      <data key=\"d1\">WebShop is a platform with an action space that includes various actions like searching, selecting products, and purchasing items<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"GAME OF 24\">      <data key=\"d0\">GAME\/CHALLENGE<\/data>      <data key=\"d1\">Game of 24 is a mathematical reasoning challenge where the goal is to use basic arithmetic operations to construct the number 24 from four given numbers<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"GPT-3.5\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-3.5 is a version of OpenAI's language model used in experiments for the Game of 24<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"LATS\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">LATS (Language Agent Tree Search) is a method used in the Game of 24 to improve performance by incorporating self-consistency scores<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"HOTPOTQA\">      <data key=\"d0\">DATASET\/TASK<\/data>      <data key=\"d1\">HotPotQA is a question answering task that involves interleaving Thought, Action, and Observation steps to solve questions<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"BAUER MEDIA GROUP\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Bauer Media Group is the publisher of the magazine First for Women<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"ARTHUR'S MAGAZINE\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Arthur's Magazine was an American literary periodical published in Philadelphia in the 19th century<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"FIRST FOR WOMEN\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">First for Women is a woman's magazine published by Bauer Media Group in the USA, started in 1989<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"GODEY'S LADY'S BOOK\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Godey's Lady's Book was a magazine that Arthur's Magazine was merged into in May 1846<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"QUERY\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">Query is an action in WebShop where a search is performed<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"RESULTS\">      <data key=\"d0\">STATE<\/data>      <data key=\"d1\">Results is a state in WebShop where search results are displayed<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"ITEM\">      <data key=\"d0\">STATE<\/data>      <data key=\"d1\">Item is a state in WebShop where a specific product is selected<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"ITEM-DETAIL\">      <data key=\"d0\">STATE<\/data>      <data key=\"d1\">Item-Detail is a state in WebShop where detailed information about a selected item is displayed<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"EPISODE END\">      <data key=\"d0\">STATE<\/data>      <data key=\"d1\">Episode End is a state in WebShop where the buying process is completed<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"REWARD\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Reward is a metric in WebShop calculated based on the number of attributes satisfied by the selected item<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"SUCCESS RATE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Success Rate (SR) is a metric in WebShop defined as the portion of instructions where the reward equals 1<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"VALUE FUNCTION\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Value Function is a method used in WebShop and Game of 24 to evaluate the performance of actions<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"SELF-CONSISTENCY SCORE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Self-Consistency Score is a metric used in LATS to improve performance in the Game of 24<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"PROMPT\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Prompt is a method used in HotPotQA to guide the question answering process<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"THOUGHT\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">Thought is an action in HotPotQA where reasoning about the current situation is performed<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"ACTION\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">Action is an action in HotPotQA where a specific task is performed based on the Thought<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"OBSERVATION\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">Observation is an action in HotPotQA where the result of an Action is analyzed<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"FINISH\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">Finish is an action in HotPotQA where the final answer is provided and the task is completed<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"SEARCH\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">Search is an action in HotPotQA where an entity is searched on Wikipedia<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"LOOKUP\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">Lookup is an action in HotPotQA where the next sentence containing a keyword in the current passage is returned<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"COLORADO OROGENY\">      <data key=\"d0\">ENTITY<\/data>      <data key=\"d1\">Colorado Orogeny is a geological event mentioned in a question in HotPotQA<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <node id=\"HIGH PLAINS\">      <data key=\"d0\">ENTITY<\/data>      <data key=\"d1\">High Plains is a region mentioned in a question in HotPotQA<\/data>      <data key=\"d2\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/node>    <edge source=\"WEBSHOP\" target=\"GAME OF 24\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Both WebShop and Game of 24 are used as environments for experiments involving language models<\/data>      <data key=\"d5\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/edge>    <edge source=\"GAME OF 24\" target=\"GPT-3.5\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">GPT-3.5 is used to perform experiments in the Game of 24<\/data>      <data key=\"d5\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/edge>    <edge source=\"GAME OF 24\" target=\"LATS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LATS is a method used to improve performance in the Game of 24<\/data>      <data key=\"d5\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/edge>    <edge source=\"GPT-3.5\" target=\"HOTPOTQA\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">GPT-3.5 is used to solve question answering tasks in HotPotQA<\/data>      <data key=\"d5\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/edge>    <edge source=\"BAUER MEDIA GROUP\" target=\"FIRST FOR WOMEN\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">First for Women is published by Bauer Media Group<\/data>      <data key=\"d5\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/edge>    <edge source=\"ARTHUR'S MAGAZINE\" target=\"GODEY'S LADY'S BOOK\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Arthur's Magazine was merged into Godey's Lady's Book in May 1846<\/data>      <data key=\"d5\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/edge>    <edge source=\"ARTHUR'S MAGAZINE\" target=\"FIRST FOR WOMEN\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Arthur's Magazine and First for Women are compared in a question answering task<\/data>      <data key=\"d5\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/edge>    <edge source=\"QUERY\" target=\"RESULTS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Query leads to Results in WebShop<\/data>      <data key=\"d5\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/edge>    <edge source=\"RESULTS\" target=\"ITEM\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Results lead to Item in WebShop<\/data>      <data key=\"d5\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/edge>    <edge source=\"ITEM\" target=\"ITEM-DETAIL\">      <data key=\"d3\">15.0<\/data>      <data key=\"d4\">Item leads to Item-Detail in WebShopItem-Detail can lead back to Item in WebShop<\/data>      <data key=\"d5\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/edge>    <edge source=\"ITEM\" target=\"EPISODE END\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Item can lead to Episode End in WebShop<\/data>      <data key=\"d5\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/edge>    <edge source=\"REWARD\" target=\"SUCCESS RATE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Reward and Success Rate are metrics used to evaluate performance in WebShop<\/data>      <data key=\"d5\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/edge>    <edge source=\"VALUE FUNCTION\" target=\"SELF-CONSISTENCY SCORE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Value Function uses Self-Consistency Score to improve performance in the Game of 24<\/data>      <data key=\"d5\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/edge>    <edge source=\"PROMPT\" target=\"THOUGHT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Prompt guides the Thought process in HotPotQA<\/data>      <data key=\"d5\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/edge>    <edge source=\"THOUGHT\" target=\"ACTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Thought leads to Action in HotPotQA<\/data>      <data key=\"d5\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/edge>    <edge source=\"THOUGHT\" target=\"OBSERVATION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Observation leads to the next Thought in HotPotQA<\/data>      <data key=\"d5\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/edge>    <edge source=\"THOUGHT\" target=\"FINISH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Thought can lead to Finish in HotPotQA<\/data>      <data key=\"d5\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/edge>    <edge source=\"ACTION\" target=\"OBSERVATION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Action leads to Observation in HotPotQA<\/data>      <data key=\"d5\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/edge>    <edge source=\"SEARCH\" target=\"LOOKUP\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Search and Lookup are actions used in HotPotQA<\/data>      <data key=\"d5\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/edge>    <edge source=\"COLORADO OROGENY\" target=\"HIGH PLAINS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Colorado Orogeny extends into the High Plains<\/data>      <data key=\"d5\">b8dd0300033963bb4a3e1bad37f8e7b9<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"357f3442ba581c9d2bdf84d90509056f","chunk":" Plains rise in elevation from around 1,800\nto 7,000 ft\nThought 3: The answer is 1,800 to 7,000 ft.\nAction: Finish[1,800 to 7,000 ft]\n(examples)\nPrevious trial: (trajectories)\n(input)\nE.3. Value Function Prompt\nAnalyze the trajectories of a solution to a question answering\ntask. The trajectories are labeled by environmental Obser-\nvations about the situation, Thoughts that can reason about\nthe current situation, and Actions that can be three types:\n(1) Search[entity], which searches the exact entity on\nWikipedia and returns the first paragraph if it exists. If\nnot, it will return some similar entities to search.\n(2) Lookup[keyword], which returns the next sentence con-\ntaining keyword in the current passage.\n(3) Finish[answer], which returns the answer and finishes\nthe task.\nGiven a question and a trajectory, evaluate its correctness\nand provide your reasoning and analysis in detail. Focus\non the latest thought, action, and observation. Incomplete\ntrajectories can be correct if the thoughts and actions so\nfar are correct, even if the answer is not found yet. Do not\ngenerate additional thoughts or actions. Then at the last line\nconclude \u201cThus the correctness score is s\u201d, where s is an\ninteger from 1 to 10.\nQuestion: Which magazine was started first Arthur\u2019s Maga-\nzine or First for Women?\nThought 1: I need to search Arthur\u2019s Magazine and First for\nWomen, and find which was started first.\nAction 1: Search[Arthur\u2019s Magazine]\nObservation 1: Arthur\u2019s Magazine was an American literary\nperiodical published in Philadelphia in the 19th century.\nEdited by Timothy Shay Arthur, it featured work by Edgar\nA. Poe, J.H. Ingraham, Sarah Josepha Hale, Thomas G.\n18Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nSpear, and others.[1][2] In May 1846 it was merged into\nGodey\u2019s Lady\u2019s Book.[3]\nThis trajectory is correct as it is reasonable to search for\nthe first magazine provided in the question. It is also better\nto have simple searches corresponding to a single entity,\nmaking this the best action.\nThus the correctness score is 10\n(other examples)\n(failed trajectories)\n(context)\nE.4. Reflection Prompt\nAnalyze the trajectories of a solution to a question-\nanswering task. The trajectories are labeled by environ-\nmental Observations about the situation, Thoughts that can\nreason about the current situation, and Actions that can be\nthree types:\n(1) Search[entity], which searches the exact entity on\nWikipedia and returns the first paragraph if it exists. If\nnot, it will return some similar entities to search.\n(2) Lookup[keyword], which returns the next sentence con-\ntaining keyword in the current passage.\n(3) Finish[answer], which returns the answer and finishes\nthe task.\nGiven a question and a trajectory, evaluate its correctness\nand provide your reasoning and analysis in detail. Focus\non the latest thought, action, and observation. Incomplete\ntrajectories can be correct if the thoughts and actions so\nfar are correct, even if the answer is not found yet. Do not\ngenerate additional thoughts or actions. Then at the last line\nconclude \u201cThus the correctness score is s\u201d, where s is an\ninteger from 1 to 10.\nQuestion: Which magazine was started first Arthur\u2019s Maga-\nzine or First for Women?\nThought 1: I need to search Arthur\u2019s Magazine and First for\nWomen, and find which was started first.\nAction 1: Search[Arthur\u2019s Magazine]\nObservation 1: Arthur\u2019s Magazine was an American literary\nperiodical published in Philadelphia in the 19th century.\nEdited by Timothy Shay Arthur, it featured work by Edgar\nA. Poe, J.H. Ingraham, Sarah Josepha Hale, Thomas G.\nSpear, and others.[1][2] In May 1846 it was merged into\nGodey\u2019s Lady\u2019s Book.[3]\nThis trajectory is correct as it is reasonable to search for\nthe first magazine provided in the question. It is also better\nto have simple searches corresponding to a single entity,making this the best action.\nThus the correctness score is 10\n(other examples)\n(failed trajectories)\n(context)\nF. Programming Prompts\nF.1. HumanEval function implementation example\nSample function signature:\nd e f minSubArraySum ( nums ) :\nGiven an a r r a y of i n t e g e r s nums ,\nf i n d t h e minimum sum of any\nnon \u2212empty sub \u2212 a r r a y of nums .\nExample\nminSubArraySum ( [ \u2212 1 , \u22122 , \u22123]) == \u22126\nSample function body implementation:\nmin sum = f l o a t ( \u2019 i n f \u2019 )\nf o r i i n r a n g e ( l e n ( nums ) ) :\nc u r r e n t s u m = 0\nf o r j i n r a n g e ( i , l e n ( nums ) ) :\nc u r r e n t s u m += nums [ j ]\ni f c u r r e n t s u m <min sum :\nmin sum = c u r r e n t s u m\nr e t u r n min sum\nF.2. Base Acting\/Reasoning Prompt\nYou are an AI Python assistant. You will be given your\nprevious implementation of a function, a series of unit tests\nresults","chunk_id":"357f3442ba581c9d2bdf84d90509056f","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"VALUE FUNCTION PROMPT","type":"INSTRUCTION","description":"A prompt that asks to analyze the trajectories of a solution to a question answering task, focusing on thoughts, actions, and observations","source_id":"357f3442ba581c9d2bdf84d90509056f","entity_type":"INSTRUCTION"},{"name":"TRAJECTORIES","type":"CONCEPT","description":"Trajectories refer to the labeled sequences of environmental observations, thoughts, and actions in a question answering task","source_id":"357f3442ba581c9d2bdf84d90509056f","entity_type":"CONCEPT"},{"name":"SEARCH[ENTITY]","type":"ACTION","description":"An action type that searches for the exact entity on Wikipedia and returns the first paragraph if it exists","source_id":"357f3442ba581c9d2bdf84d90509056f","entity_type":"ACTION"},{"name":"LOOKUP[KEYWORD]","type":"ACTION","description":"An action type that returns the next sentence containing the specified keyword in the current passage","source_id":"357f3442ba581c9d2bdf84d90509056f","entity_type":"ACTION"},{"name":"FINISH[ANSWER]","type":"ACTION","description":"An action type that returns the answer and finishes the task","source_id":"357f3442ba581c9d2bdf84d90509056f","entity_type":"ACTION"},{"name":"QUESTION","type":"CONCEPT","description":"A query that needs to be answered, such as \"Which magazine was started first Arthur\u2019s Magazine or First for Women?\"","source_id":"357f3442ba581c9d2bdf84d90509056f","entity_type":"CONCEPT"},{"name":"THOUGHT","type":"CONCEPT","description":"A reasoning process about the current situation in a question answering task","source_id":"357f3442ba581c9d2bdf84d90509056f","entity_type":"CONCEPT"},{"name":"ACTION","type":"CONCEPT","description":"An operation performed to progress in a question answering task, such as searching or looking up information","source_id":"357f3442ba581c9d2bdf84d90509056f","entity_type":"CONCEPT"},{"name":"OBSERVATION","type":"CONCEPT","description":"Environmental feedback or information received after performing an action in a question answering task","source_id":"357f3442ba581c9d2bdf84d90509056f","entity_type":"CONCEPT"},{"name":"ARTHUR\u2019S MAGAZINE","type":"PUBLICATION","description":"An American literary periodical published in Philadelphia in the 19th century, edited by Timothy Shay Arthur","source_id":"357f3442ba581c9d2bdf84d90509056f","entity_type":"PUBLICATION"},{"name":"FIRST FOR WOMEN","type":"PUBLICATION","description":"A magazine that is part of the question \"Which magazine was started first Arthur\u2019s Magazine or First for Women?\"","source_id":"357f3442ba581c9d2bdf84d90509056f","entity_type":"PUBLICATION"},{"name":"REFLECTION PROMPT","type":"INSTRUCTION","description":"A prompt that asks to analyze the trajectories of a solution to a question-answering task, focusing on thoughts, actions, and observations","source_id":"357f3442ba581c9d2bdf84d90509056f","entity_type":"INSTRUCTION"},{"name":"PROGRAMMING PROMPTS","type":"INSTRUCTION","description":"Prompts related to programming tasks, such as implementing a function or analyzing code","source_id":"357f3442ba581c9d2bdf84d90509056f","entity_type":"INSTRUCTION"},{"name":"HUMANEVAL FUNCTION IMPLEMENTATION EXAMPLE","type":"EXAMPLE","description":"An example of a function implementation for evaluating human-like performance in programming tasks","source_id":"357f3442ba581c9d2bdf84d90509056f","entity_type":"EXAMPLE"},{"name":"MINIMUM SUBARRAY SUM","type":"FUNCTION","description":"A function that finds the minimum sum of any non-empty sub-array of integers","source_id":"357f3442ba581c9d2bdf84d90509056f","entity_type":"FUNCTION"},{"name":"UNIT TESTS","type":"CONCEPT","description":"Tests that are used to validate the correctness of a function implementation","source_id":"357f3442ba581c9d2bdf84d90509056f","entity_type":"CONCEPT"},{"name":"GODEY\u2019S LADY\u2019S BOOK","type":"PUBLICATION","description":"A magazine into which Arthur\u2019s Magazine was merged in May 1846","source_id":"357f3442ba581c9d2bdf84d90509056f"},{"name":"TIMOTHY SHAY ARTHUR","type":"PERSON","description":"The editor of Arthur\u2019s Magazine","source_id":"357f3442ba581c9d2bdf84d90509056f"},{"name":"EDGAR A. POE","type":"PERSON","description":"A contributor to Arthur\u2019s Magazine","source_id":"357f3442ba581c9d2bdf84d90509056f"},{"name":"J.H. INGRAHAM","type":"PERSON","description":"A contributor to Arthur\u2019s Magazine","source_id":"357f3442ba581c9d2bdf84d90509056f"},{"name":"SARAH JOSEPHA HALE","type":"PERSON","description":"A contributor to Arthur\u2019s Magazine","source_id":"357f3442ba581c9d2bdf84d90509056f"},{"name":"THOMAS G. SPEAR","type":"PERSON","description":"A contributor to Arthur\u2019s Magazine","source_id":"357f3442ba581c9d2bdf84d90509056f"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"VALUE FUNCTION PROMPT\">      <data key=\"d0\">INSTRUCTION<\/data>      <data key=\"d1\">A prompt that asks to analyze the trajectories of a solution to a question answering task, focusing on thoughts, actions, and observations<\/data>      <data key=\"d2\">357f3442ba581c9d2bdf84d90509056f<\/data>      <data key=\"d3\">INSTRUCTION<\/data>    <\/node>    <node id=\"TRAJECTORIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Trajectories refer to the labeled sequences of environmental observations, thoughts, and actions in a question answering task<\/data>      <data key=\"d2\">357f3442ba581c9d2bdf84d90509056f<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"SEARCH[ENTITY]\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">An action type that searches for the exact entity on Wikipedia and returns the first paragraph if it exists<\/data>      <data key=\"d2\">357f3442ba581c9d2bdf84d90509056f<\/data>      <data key=\"d3\">ACTION<\/data>    <\/node>    <node id=\"LOOKUP[KEYWORD]\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">An action type that returns the next sentence containing the specified keyword in the current passage<\/data>      <data key=\"d2\">357f3442ba581c9d2bdf84d90509056f<\/data>      <data key=\"d3\">ACTION<\/data>    <\/node>    <node id=\"FINISH[ANSWER]\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">An action type that returns the answer and finishes the task<\/data>      <data key=\"d2\">357f3442ba581c9d2bdf84d90509056f<\/data>      <data key=\"d3\">ACTION<\/data>    <\/node>    <node id=\"QUESTION\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A query that needs to be answered, such as \"Which magazine was started first Arthur&#8217;s Magazine or First for Women?\"<\/data>      <data key=\"d2\">357f3442ba581c9d2bdf84d90509056f<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"THOUGHT\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A reasoning process about the current situation in a question answering task<\/data>      <data key=\"d2\">357f3442ba581c9d2bdf84d90509056f<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"ACTION\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">An operation performed to progress in a question answering task, such as searching or looking up information<\/data>      <data key=\"d2\">357f3442ba581c9d2bdf84d90509056f<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"OBSERVATION\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Environmental feedback or information received after performing an action in a question answering task<\/data>      <data key=\"d2\">357f3442ba581c9d2bdf84d90509056f<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"ARTHUR&#8217;S MAGAZINE\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">An American literary periodical published in Philadelphia in the 19th century, edited by Timothy Shay Arthur<\/data>      <data key=\"d2\">357f3442ba581c9d2bdf84d90509056f<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"FIRST FOR WOMEN\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A magazine that is part of the question \"Which magazine was started first Arthur&#8217;s Magazine or First for Women?\"<\/data>      <data key=\"d2\">357f3442ba581c9d2bdf84d90509056f<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"REFLECTION PROMPT\">      <data key=\"d0\">INSTRUCTION<\/data>      <data key=\"d1\">A prompt that asks to analyze the trajectories of a solution to a question-answering task, focusing on thoughts, actions, and observations<\/data>      <data key=\"d2\">357f3442ba581c9d2bdf84d90509056f<\/data>      <data key=\"d3\">INSTRUCTION<\/data>    <\/node>    <node id=\"PROGRAMMING PROMPTS\">      <data key=\"d0\">INSTRUCTION<\/data>      <data key=\"d1\">Prompts related to programming tasks, such as implementing a function or analyzing code<\/data>      <data key=\"d2\">357f3442ba581c9d2bdf84d90509056f<\/data>      <data key=\"d3\">INSTRUCTION<\/data>    <\/node>    <node id=\"HUMANEVAL FUNCTION IMPLEMENTATION EXAMPLE\">      <data key=\"d0\">EXAMPLE<\/data>      <data key=\"d1\">An example of a function implementation for evaluating human-like performance in programming tasks<\/data>      <data key=\"d2\">357f3442ba581c9d2bdf84d90509056f<\/data>      <data key=\"d3\">EXAMPLE<\/data>    <\/node>    <node id=\"MINIMUM SUBARRAY SUM\">      <data key=\"d0\">FUNCTION<\/data>      <data key=\"d1\">A function that finds the minimum sum of any non-empty sub-array of integers<\/data>      <data key=\"d2\">357f3442ba581c9d2bdf84d90509056f<\/data>      <data key=\"d3\">FUNCTION<\/data>    <\/node>    <node id=\"UNIT TESTS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Tests that are used to validate the correctness of a function implementation<\/data>      <data key=\"d2\">357f3442ba581c9d2bdf84d90509056f<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"GODEY&#8217;S LADY&#8217;S BOOK\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A magazine into which Arthur&#8217;s Magazine was merged in May 1846<\/data>      <data key=\"d2\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/node>    <node id=\"TIMOTHY SHAY ARTHUR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">The editor of Arthur&#8217;s Magazine<\/data>      <data key=\"d2\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/node>    <node id=\"EDGAR A. POE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A contributor to Arthur&#8217;s Magazine<\/data>      <data key=\"d2\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/node>    <node id=\"J.H. INGRAHAM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A contributor to Arthur&#8217;s Magazine<\/data>      <data key=\"d2\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/node>    <node id=\"SARAH JOSEPHA HALE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A contributor to Arthur&#8217;s Magazine<\/data>      <data key=\"d2\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/node>    <node id=\"THOMAS G. SPEAR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A contributor to Arthur&#8217;s Magazine<\/data>      <data key=\"d2\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/node>    <edge source=\"TRAJECTORIES\" target=\"THOUGHT\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Trajectories include thoughts that reason about the current situation<\/data>      <data key=\"d6\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/edge>    <edge source=\"TRAJECTORIES\" target=\"ACTION\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Trajectories include actions that can be performed to progress in the task<\/data>      <data key=\"d6\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/edge>    <edge source=\"TRAJECTORIES\" target=\"OBSERVATION\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Trajectories include observations that provide feedback or information<\/data>      <data key=\"d6\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/edge>    <edge source=\"TRAJECTORIES\" target=\"REFLECTION PROMPT\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">The Reflection Prompt involves analyzing the trajectories of a solution to a question-answering task<\/data>      <data key=\"d6\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/edge>    <edge source=\"QUESTION\" target=\"THOUGHT\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">The thought process involves reasoning about how to answer the question<\/data>      <data key=\"d6\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/edge>    <edge source=\"QUESTION\" target=\"ARTHUR&#8217;S MAGAZINE\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">Arthur&#8217;s Magazine is part of the question \"Which magazine was started first Arthur&#8217;s Magazine or First for Women?\"<\/data>      <data key=\"d6\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/edge>    <edge source=\"QUESTION\" target=\"FIRST FOR WOMEN\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">First for Women is part of the question \"Which magazine was started first Arthur&#8217;s Magazine or First for Women?\"<\/data>      <data key=\"d6\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/edge>    <edge source=\"THOUGHT\" target=\"ACTION\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">The thought process determines the actions to be taken<\/data>      <data key=\"d6\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/edge>    <edge source=\"ACTION\" target=\"OBSERVATION\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Actions lead to observations that provide feedback or information<\/data>      <data key=\"d6\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/edge>    <edge source=\"ARTHUR&#8217;S MAGAZINE\" target=\"GODEY&#8217;S LADY&#8217;S BOOK\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Arthur&#8217;s Magazine was merged into Godey&#8217;s Lady&#8217;s Book in May 1846<\/data>      <data key=\"d6\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/edge>    <edge source=\"ARTHUR&#8217;S MAGAZINE\" target=\"TIMOTHY SHAY ARTHUR\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Timothy Shay Arthur was the editor of Arthur&#8217;s Magazine<\/data>      <data key=\"d6\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/edge>    <edge source=\"ARTHUR&#8217;S MAGAZINE\" target=\"EDGAR A. POE\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Edgar A. Poe was a contributor to Arthur&#8217;s Magazine<\/data>      <data key=\"d6\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/edge>    <edge source=\"ARTHUR&#8217;S MAGAZINE\" target=\"J.H. INGRAHAM\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">J.H. Ingraham was a contributor to Arthur&#8217;s Magazine<\/data>      <data key=\"d6\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/edge>    <edge source=\"ARTHUR&#8217;S MAGAZINE\" target=\"SARAH JOSEPHA HALE\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Sarah Josepha Hale was a contributor to Arthur&#8217;s Magazine<\/data>      <data key=\"d6\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/edge>    <edge source=\"ARTHUR&#8217;S MAGAZINE\" target=\"THOMAS G. SPEAR\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Thomas G. Spear was a contributor to Arthur&#8217;s Magazine<\/data>      <data key=\"d6\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/edge>    <edge source=\"PROGRAMMING PROMPTS\" target=\"HUMANEVAL FUNCTION IMPLEMENTATION EXAMPLE\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Programming Prompts include examples like the HumanEval function implementation<\/data>      <data key=\"d6\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/edge>    <edge source=\"HUMANEVAL FUNCTION IMPLEMENTATION EXAMPLE\" target=\"MINIMUM SUBARRAY SUM\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">The HumanEval function implementation example includes a sample implementation of the Minimum Subarray Sum function<\/data>      <data key=\"d6\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/edge>    <edge source=\"MINIMUM SUBARRAY SUM\" target=\"UNIT TESTS\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Unit tests are used to validate the correctness of the Minimum Subarray Sum function<\/data>      <data key=\"d6\">357f3442ba581c9d2bdf84d90509056f<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"785ad59c6a37896a4676ec5c1689735f","chunk":" , l e n ( nums ) ) :\nc u r r e n t s u m += nums [ j ]\ni f c u r r e n t s u m <min sum :\nmin sum = c u r r e n t s u m\nr e t u r n min sum\nF.2. Base Acting\/Reasoning Prompt\nYou are an AI Python assistant. You will be given your\nprevious implementation of a function, a series of unit tests\nresults, and your self-reflection on your previous implemen-\ntation. Write your full implementation (restate the function\nsignature).\nExample 1:\n[previous impl]:\nd e f add ( a : i n t , b : i n t ) \u2212 >i n t :\n\u2018 \u2018 Given i n t e g e r s a and b ,\nr e t u r n t h e t o t a l v a l u e of a and b . \u2019 \u2019\nr e t u r n a \u2212 b\n[unit test results from previous impl]:\nTested passed:\nTests failed:\nassert add(1, 2) == 3 # output: -1\n19Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nassert add(1, 2) == 4 # output: -1\n[reflection on previous impl]:\nThe implementation failed the test cases where the input\nintegers are 1 and 2. The issue arises because the code does\nnot add the two integers together, but instead subtracts the\nsecond integer from the first. To fix this issue, we should\nchange the operator from \u2018-\u2019 to \u2018+\u2019 in the return statement.\nThis will ensure that the function returns the correct output\nfor the given input.\n[improved impl]:\nd e f add ( a : i n t , b : i n t ) \u2212 >i n t :\n\u2018 \u2018\nGiven i n t e g e r s a and b ,\nr e t u r n t h e t o t a l v a l u e of a and b .\n\u2019 \u2019\nr e t u r n a + b\nF.3. Reflection Prompt\nYou are a Python programming assistant. You will be given\na function implementation and a series of unit test results.\nYour goal is to write a few sentences to explain why your\nimplementation is wrong, as indicated by the tests. You\nwill need this as guidance when you try again later. Only\nprovide the few sentence description in your answer, not the\nimplementation. You will be given a few examples by the\nuser.\nExample 1:\n[previous impl]:\nd e f add ( a : i n t , b : i n t ) \u2212 >i n t :\n\u2018 \u2018\nGiven i n t e g e r s a and b ,\nr e t u r n t h e t o t a l v a l u e of a and b .\n\u2019 \u2019\nr e t u r n a \u2212 b\n[unit test results from previous impl]:\nTested passed:\nTests failed:\nassert add(1, 2) == 3 # output: -1\nassert add(1, 2) == 4 # output: -1\n[reflection on previous impl]:\nThe implementation failed the test cases where the input\nintegers are 1 and 2. The issue arises because the code does\nnot add the two integers together, but instead subtracts the\nsecond integer from the first. To fix this issue, we should\nchange the operator from \u2018-\u2019 to \u2018+\u2019 in the return statement.This will ensure that the function returns the correct output\nfor the given input.\nF.4. Test Case Generation Prompt\nYou are an AI coding assistant that can write unique, diverse,\nand intuitive unit tests for functions given the signature and\ndocstring.\n(input)\nG. WebShop Prompts\nG.1. Acting Prompt\nWebshop\nInstruction:\ni would like a 3 ounce bottle of bright citrus deodorant for\nsensitive skin, and price lower than 50.00 dollars\n[Search]\nAction: search[3 ounce bright citrus deodorant sensitive\nskin]\nObservation:\n[Back to Search]\nPage 1 (Total results: 50)\n[Next ] [B078GWRC1J]\nBright Citrus Deodorant by Earth Mama \u2014 Natural and Safe\nfor Sensitive Skin, Pregnancy and Breastfeeding, Contains\nOrganic Calendula 3-Ounce\n$10.99\n[B078GTKVXY]\nGinger Fresh Deodorant by Earth Mama \u2014 Natural and Safe\nfor Sensitive Skin, Pregnancy and Breastfeeding, Contains\nOrganic Calendula 3-Ounce\n$10.99\n[B08KBVJ4XN]\nBarrel and Oak - Aluminum-Free Deodorant, Deodorant\nfor Men, Essential Oil-Based Scent, 24-Hour Odor Protec-\ntion, Cedar & Patchouli Blend, Gentle on Sensitive Skin\n(Mountain Sage, 2.7 oz, 2-Pack)\n$15.95\nAction: think[B078GWRC1J and B078GTKVXY are\nbright citrus deodorant less then 50 dollars. I can check\nB078GWRC1J first.]\n20Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nObservation: OK.\nAction: click[B078GWRC1J]\nObservation:\n[Back to Search]\n[Prev]\nscent [assorted scents][bright citrus][calming laven-\nder][ginger fresh][simply non-scents] size [travel set (4-\npack)][3 ounce (pack of 1)][3-ounce (2","chunk_id":"785ad59c6a37896a4676ec5c1689735f","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"AI PYTHON ASSISTANT","type":"TOOL\/ROLE","description":"An AI assistant designed to help with Python programming tasks, including implementing functions, running unit tests, and reflecting on code","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"FUNCTION IMPLEMENTATION","type":"CONCEPT\/PROCESS","description":"The process of writing and defining a function in Python, including its signature and body","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"UNIT TEST","type":"CONCEPT\/PROCESS","description":"A type of software testing where individual units or components of a software are tested to validate that each unit performs as expected","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"SELF-REFLECTION","type":"CONCEPT\/PROCESS","description":"The process of reviewing and analyzing one's own code to identify errors and areas for improvement","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"LANGUAGE AGENT TREE SEARCH","type":"CONCEPT\/TECHNIQUE","description":"A method that unifies reasoning, acting, and planning in language models","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"WEBSHOP","type":"TOOL\/PLATFORM","description":"An online platform where users can search for and purchase products","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"BRIGHT CITRUS DEODORANT","type":"PRODUCT","description":"A type of deodorant with a bright citrus scent, suitable for sensitive skin","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"EARTH MAMA","type":"BRAND","description":"A brand that produces natural and safe products for sensitive skin, pregnancy, and breastfeeding","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"GINGER FRESH DEODORANT","type":"PRODUCT","description":"A type of deodorant with a ginger fresh scent, suitable for sensitive skin","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"BARREL AND OAK","type":"BRAND","description":"A brand that produces aluminum-free deodorants and other personal care products","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"CEDAR & PATCHOULI DEODORANT","type":"PRODUCT","description":"A type of deodorant with a cedar and patchouli blend, suitable for sensitive skin","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"MIN SUM","type":"CONCEPT","description":"A variable used in a function to keep track of the minimum sum encountered during iteration","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"CURRENT SUM","type":"CONCEPT","description":"A variable used in a function to keep track of the current sum during iteration","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"NUMS","type":"CONCEPT","description":"A list of numbers that the function iterates over to calculate sums","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"BASE ACTING\/REASONING PROMPT","type":"TOOL\/PROCESS","description":"A prompt given to an AI Python assistant to guide the implementation of a function based on previous code, unit tests, and self-reflection","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"IMPROVED IMPLEMENTATION","type":"CONCEPT\/PROCESS","description":"The revised version of a function after identifying and fixing errors from the previous implementation","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"REFLECTION PROMPT","type":"TOOL\/PROCESS","description":"A prompt given to an AI Python assistant to guide the reflection on why a function implementation is wrong based on unit test results","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"TEST CASE GENERATION PROMPT","type":"TOOL\/PROCESS","description":"A prompt given to an AI coding assistant to write unique and diverse unit tests for functions","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"ACTING PROMPT","type":"TOOL\/PROCESS","description":"A prompt given to an AI assistant to guide actions in a specific scenario, such as searching for products in a webshop","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"SEARCH","type":"CONCEPT\/PROCESS","description":"The action of looking for specific items or information, such as products in a webshop","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"OBSERVATION","type":"CONCEPT\/PROCESS","description":"The result or feedback received after performing an action, such as a search in a webshop","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"THINK","type":"CONCEPT\/PROCESS","description":"The process of considering or reasoning about information before taking further action","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"CLICK","type":"CONCEPT\/PROCESS","description":"The action of selecting an item or link, such as a product in a webshop","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"PRICE","type":"CONCEPT","description":"The cost of a product, such as deodorant in a webshop","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"SIZE","type":"CONCEPT","description":"The dimensions or volume of a product, such as a 3-ounce bottle of deodorant","source_id":"785ad59c6a37896a4676ec5c1689735f"},{"name":"SCENT","type":"CONCEPT","description":"The fragrance or smell of a product, such as bright citrus or ginger fresh","source_id":"785ad59c6a37896a4676ec5c1689735f"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"AI PYTHON ASSISTANT\">      <data key=\"d0\">TOOL\/ROLE<\/data>      <data key=\"d1\">An AI assistant designed to help with Python programming tasks, including implementing functions, running unit tests, and reflecting on code<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"FUNCTION IMPLEMENTATION\">      <data key=\"d0\">CONCEPT\/PROCESS<\/data>      <data key=\"d1\">The process of writing and defining a function in Python, including its signature and body<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"UNIT TEST\">      <data key=\"d0\">CONCEPT\/PROCESS<\/data>      <data key=\"d1\">A type of software testing where individual units or components of a software are tested to validate that each unit performs as expected<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"SELF-REFLECTION\">      <data key=\"d0\">CONCEPT\/PROCESS<\/data>      <data key=\"d1\">The process of reviewing and analyzing one's own code to identify errors and areas for improvement<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"LANGUAGE AGENT TREE SEARCH\">      <data key=\"d0\">CONCEPT\/TECHNIQUE<\/data>      <data key=\"d1\">A method that unifies reasoning, acting, and planning in language models<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"WEBSHOP\">      <data key=\"d0\">TOOL\/PLATFORM<\/data>      <data key=\"d1\">An online platform where users can search for and purchase products<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"BRIGHT CITRUS DEODORANT\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A type of deodorant with a bright citrus scent, suitable for sensitive skin<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"EARTH MAMA\">      <data key=\"d0\">BRAND<\/data>      <data key=\"d1\">A brand that produces natural and safe products for sensitive skin, pregnancy, and breastfeeding<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"GINGER FRESH DEODORANT\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A type of deodorant with a ginger fresh scent, suitable for sensitive skin<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"BARREL AND OAK\">      <data key=\"d0\">BRAND<\/data>      <data key=\"d1\">A brand that produces aluminum-free deodorants and other personal care products<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"CEDAR &amp; PATCHOULI DEODORANT\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A type of deodorant with a cedar and patchouli blend, suitable for sensitive skin<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"MIN SUM\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A variable used in a function to keep track of the minimum sum encountered during iteration<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"CURRENT SUM\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A variable used in a function to keep track of the current sum during iteration<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"NUMS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A list of numbers that the function iterates over to calculate sums<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"BASE ACTING\/REASONING PROMPT\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">A prompt given to an AI Python assistant to guide the implementation of a function based on previous code, unit tests, and self-reflection<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"IMPROVED IMPLEMENTATION\">      <data key=\"d0\">CONCEPT\/PROCESS<\/data>      <data key=\"d1\">The revised version of a function after identifying and fixing errors from the previous implementation<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"REFLECTION PROMPT\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">A prompt given to an AI Python assistant to guide the reflection on why a function implementation is wrong based on unit test results<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"TEST CASE GENERATION PROMPT\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">A prompt given to an AI coding assistant to write unique and diverse unit tests for functions<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"ACTING PROMPT\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">A prompt given to an AI assistant to guide actions in a specific scenario, such as searching for products in a webshop<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"SEARCH\">      <data key=\"d0\">CONCEPT\/PROCESS<\/data>      <data key=\"d1\">The action of looking for specific items or information, such as products in a webshop<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"OBSERVATION\">      <data key=\"d0\">CONCEPT\/PROCESS<\/data>      <data key=\"d1\">The result or feedback received after performing an action, such as a search in a webshop<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"THINK\">      <data key=\"d0\">CONCEPT\/PROCESS<\/data>      <data key=\"d1\">The process of considering or reasoning about information before taking further action<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"CLICK\">      <data key=\"d0\">CONCEPT\/PROCESS<\/data>      <data key=\"d1\">The action of selecting an item or link, such as a product in a webshop<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"PRICE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">The cost of a product, such as deodorant in a webshop<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"SIZE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">The dimensions or volume of a product, such as a 3-ounce bottle of deodorant<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <node id=\"SCENT\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">The fragrance or smell of a product, such as bright citrus or ginger fresh<\/data>      <data key=\"d2\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/node>    <edge source=\"AI PYTHON ASSISTANT\" target=\"FUNCTION IMPLEMENTATION\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The AI Python assistant helps in writing and defining function implementations<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"AI PYTHON ASSISTANT\" target=\"UNIT TEST\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The AI Python assistant runs unit tests to validate the function implementations<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"AI PYTHON ASSISTANT\" target=\"SELF-REFLECTION\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The AI Python assistant performs self-reflection to identify errors and improve code<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"AI PYTHON ASSISTANT\" target=\"BASE ACTING\/REASONING PROMPT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The BASE ACTING\/REASONING PROMPT guides the AI Python assistant in implementing a function<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"FUNCTION IMPLEMENTATION\" target=\"UNIT TEST\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Unit tests are used to validate the correctness of function implementations<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"FUNCTION IMPLEMENTATION\" target=\"SELF-REFLECTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Self-reflection is used to review and improve function implementations<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"FUNCTION IMPLEMENTATION\" target=\"IMPROVED IMPLEMENTATION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">IMPROVED IMPLEMENTATION is the revised version of a FUNCTION IMPLEMENTATION<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"UNIT TEST\" target=\"TEST CASE GENERATION PROMPT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The TEST CASE GENERATION PROMPT guides the AI coding assistant in writing UNIT TESTS<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"SELF-REFLECTION\" target=\"REFLECTION PROMPT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The REFLECTION PROMPT guides the AI Python assistant in performing SELF-REFLECTION<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"BRIGHT CITRUS DEODORANT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Webshop is a platform where users can search for and purchase Bright Citrus Deodorant<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"GINGER FRESH DEODORANT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Webshop is a platform where users can search for and purchase Ginger Fresh Deodorant<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"CEDAR &amp; PATCHOULI DEODORANT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Webshop is a platform where users can search for and purchase Cedar &amp; Patchouli Deodorant<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"ACTING PROMPT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The ACTING PROMPT guides actions in the WEBSHOP<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"WEBSHOP\" target=\"SEARCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">SEARCH is an action performed in the WEBSHOP to find products<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"BRIGHT CITRUS DEODORANT\" target=\"EARTH MAMA\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Bright Citrus Deodorant is a product by the brand Earth Mama<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"BRIGHT CITRUS DEODORANT\" target=\"PRICE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">PRICE is an attribute of the BRIGHT CITRUS DEODORANT<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"BRIGHT CITRUS DEODORANT\" target=\"SIZE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">SIZE is an attribute of the BRIGHT CITRUS DEODORANT<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"BRIGHT CITRUS DEODORANT\" target=\"SCENT\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">SCENT is an attribute of the BRIGHT CITRUS DEODORANT<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"EARTH MAMA\" target=\"GINGER FRESH DEODORANT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Ginger Fresh Deodorant is a product by the brand Earth Mama<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"GINGER FRESH DEODORANT\" target=\"PRICE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">PRICE is an attribute of the GINGER FRESH DEODORANT<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"GINGER FRESH DEODORANT\" target=\"SIZE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">SIZE is an attribute of the GINGER FRESH DEODORANT<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"GINGER FRESH DEODORANT\" target=\"SCENT\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">SCENT is an attribute of the GINGER FRESH DEODORANT<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"BARREL AND OAK\" target=\"CEDAR &amp; PATCHOULI DEODORANT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Cedar &amp; Patchouli Deodorant is a product by the brand Barrel and Oak<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"CEDAR &amp; PATCHOULI DEODORANT\" target=\"PRICE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">PRICE is an attribute of the CEDAR &amp; PATCHOULI DEODORANT<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"CEDAR &amp; PATCHOULI DEODORANT\" target=\"SIZE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">SIZE is an attribute of the CEDAR &amp; PATCHOULI DEODORANT<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"CEDAR &amp; PATCHOULI DEODORANT\" target=\"SCENT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">SCENT is an attribute of the CEDAR &amp; PATCHOULI DEODORANT<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"MIN SUM\" target=\"CURRENT SUM\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">MIN SUM is updated based on the value of CURRENT SUM during iteration<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"CURRENT SUM\" target=\"NUMS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">CURRENT SUM is calculated by iterating over the elements in NUMS<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"SEARCH\" target=\"OBSERVATION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">OBSERVATION is the result received after performing a SEARCH<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"OBSERVATION\" target=\"THINK\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">THINK is the process of reasoning about the OBSERVATION before taking further action<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>    <edge source=\"THINK\" target=\"CLICK\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">CLICK is the action taken after the THINK process<\/data>      <data key=\"d5\">785ad59c6a37896a4676ec5c1689735f<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"6f486e20e3102c7a285e357d356417ad","chunk":"RC1J first.]\n20Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nObservation: OK.\nAction: click[B078GWRC1J]\nObservation:\n[Back to Search]\n[Prev]\nscent [assorted scents][bright citrus][calming laven-\nder][ginger fresh][simply non-scents] size [travel set (4-\npack)][3 ounce (pack of 1)][3-ounce (2-pack)] Bright Citrus\nDeodorant by Earth Mama \u2014 Natural and Safe for Sensi-\ntive Skin, Pregnancy and Breastfeeding, Contains Organic\nCalendula 3-Ounce\nPrice: $10.99\nRating: N.A.\n[Description]\n[Features]\n[Reviews]\n[Buy Now]\nAction: think[For 3 ounce bottle of bright citrus deodorant\nfor sensitive skin, the item has options \u2018bright citrus\u2019 and \u20183\nounce (pack of 1)\u2019 and seems good to buy.]\nObservation: OK.\nAction: click[bright citrus]\nObservation: You have clicked bright citrus.\nAction: click[3 ounce (pack of 1)]\nObservation: You have clicked 3 ounce (pack of 1).\nAction: click[Buy Now]\nG.2. Value Function Prompt\nGiven an item to purchase and a trajectory that aims to buy\nan item that exactly matches the specification, which cor-\nresponds to the ideal score of 1.0, analyze the following\ntrajectory, then at the last line conclude, \u201cThus the correct-\nness score is s\u201d, where s is an integer from 1 to 10.\nHere are some examples\nWebshop\nInstruction:i am looking for dairy free and apple variety pack of chips,\nand price lower than 30.00 dollars\n[Search]\nAction: search[dairy free and apple variety pack of chips]\nObservation:\n[Back to Search]\nPage 1 (Total results: 50)\n[Next]\n[B07HRFJWP8]\nEnjoy Life Foods Soft Baked Ovals, Breakfast Bars, Nut\nFree Bars, Soy Free, Dairy Free, Non GMO, Gluten Free,\nVegan, Variety Pack, 4 Boxes (20 Bars Total)\n$100.0\n[B01KMHY5PG]\nEnjoy Life Soft Baked Chewy Bars, Variety Pack, Nut Free\nBars, Soy Free, Dairy Free, Gluten Free, 6 Boxes (30 Total\nBars)\n$21.49\n[B008D2X8C4]\nEnjoy Life Lentil Chips Variety Pack, Dairy Free Chips, Soy\nFree, Nut Free, Non GMO, Vegan, Gluten Free, 24 Bags\n(0.8 oz)\n$100.0\nAction: think[The first two items are not what I want. The\nthird item is the dairy free and apple variety pack of chips I\nwant.]\nObservation: OK.\nAction: click[B008D2X8C4]\nObservation:\n[Back to Search]\n[Prev]\nflavor name [dill and sour cream][garlic & parmesan][light\nsea salt][margherita pizza][thai chili lime][variety pack] size\n[0.8 ounce (pack of 24)][4 ounce (pack of 12)]\nPrice: $100.0\nRating: N.A.\n[Description]\n[Features]\n21Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\n[Reviews]\n[Buy Now]\nAction: think[The item has options \u2018variety pack\u2019 and \u20180.8\nounce (pack of 24)\u2019 and seems good to buy.]\nObservation: OK.\nAction: click[variety pack]\nObservation: You have clicked variety pack.\nAction: click[0.8 ounce (pack of 24)]\nObservation: You have clicked 0.8 ounce (pack of 24).\nAction: click[Buy Now]\nReflection: In this attempt, I was unsuccessful. I acciden-\ntally bought a product that was $100, which is more than my\nbudget of $30. Either way, the initial search results were not\ngood. Next time, I will do search[\u201cvariety pack of chip\u201d;]\nand then check if the results meet the dairy free and the $30\nbudget constraints. I will continue to refine my searches so\nthat I can find more products.\nThus the correctness score is 5\n(input)\nG.3. Reflection Prompt\nYou are an advanced reasoning agent that can improve based\non self-reflection. You will be given a previous reasoning\ntrial in which you were given access to a shopping website\nand a specific type of item to buy. You were given access\nto relevant context and an item to purchase. You were un-\nsuccessful in buying the correct item either because you did\nnot find an item meeting all of the required specifications\nor because you did not select the correct item. The ideal\nscore is 1.0, and anything less is incorrect. In a few sen-\ntences, Diagnose a possible reason for failure and devise a\nnew, concise, high-level plan that aims to mitigate the same\nfailure. Use complete sentences. Here are some examples:\nPrevious Trial Instruction: i am looking for dairy free and\napple variety pack of chips, and price lower than 30.00\ndollars [Search]\nAction: search[dairy free and apple variety pack of chips]\nObservation: [Back to Search] Page 1 (Total results: 50)\n[Next >] [B07HRFJWP8] Enjoy Life Foods Soft Baked\nOvals, Breakfast Bars, Nut Free Bars, Soy Free, Dairy Free,\nNon GMO, Gluten Free","chunk_id":"6f486e20e3102c7a285e357d356417ad","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"LANGUAGE AGENT TREE SEARCH","type":"TECHNOLOGY\/PROCESS","description":"Language Agent Tree Search is a method that unifies reasoning, acting, and planning in language models","source_id":"6f486e20e3102c7a285e357d356417ad","entity_type":"TECHNOLOGY\/PROCESS"},{"name":"BRIGHT CITRUS DEODORANT","type":"PRODUCT","description":"Bright Citrus Deodorant by Earth Mama is a natural and safe deodorant for sensitive skin, pregnancy, and breastfeeding, containing organic calendula, available in a 3-ounce size","source_id":"6f486e20e3102c7a285e357d356417ad","entity_type":"PRODUCT"},{"name":"EARTH MAMA","type":"BRAND","description":"Earth Mama is the brand that produces the Bright Citrus Deodorant","source_id":"6f486e20e3102c7a285e357d356417ad","entity_type":"BRAND"},{"name":"ENJOY LIFE FOODS","type":"BRAND","description":"Enjoy Life Foods is a brand that produces various dairy-free, nut-free, soy-free, gluten-free, and vegan food products","source_id":"6f486e20e3102c7a285e357d356417ad","entity_type":"BRAND"},{"name":"DAIRY FREE AND APPLE VARIETY PACK OF CHIPS","type":"PRODUCT","description":"A variety pack of chips that is dairy-free and includes apple flavor, produced by Enjoy Life Foods","source_id":"6f486e20e3102c7a285e357d356417ad","entity_type":"PRODUCT"},{"name":"VALUE FUNCTION PROMPT","type":"INSTRUCTION","description":"A prompt that asks to analyze a purchasing trajectory and conclude a correctness score from 1 to 10","source_id":"6f486e20e3102c7a285e357d356417ad","entity_type":"INSTRUCTION"},{"name":"REFLECTION PROMPT","type":"INSTRUCTION","description":"A prompt that asks an advanced reasoning agent to diagnose a failure in a previous trial and devise a new plan to mitigate the failure","source_id":"6f486e20e3102c7a285e357d356417ad","entity_type":"INSTRUCTION"},{"name":"WEB SHOP","type":"PLATFORM","description":"An online shopping platform where users can search for and purchase items","source_id":"6f486e20e3102c7a285e357d356417ad","entity_type":"PLATFORM"},{"name":"GINGER FRESH DEODORANT","type":"PRODUCT","description":"Ginger Fresh Deodorant by Earth Mama is a natural and safe deodorant for sensitive skin, pregnancy, and breastfeeding, containing organic calendula, available in a 3-ounce size","source_id":"6f486e20e3102c7a285e357d356417ad"},{"name":"CALMING LAVENDER DEODORANT","type":"PRODUCT","description":"Calming Lavender Deodorant by Earth Mama is a natural and safe deodorant for sensitive skin, pregnancy, and breastfeeding, containing organic calendula, available in a 3-ounce size","source_id":"6f486e20e3102c7a285e357d356417ad"},{"name":"SIMPLY NON-SCENTS DEODORANT","type":"PRODUCT","description":"Simply Non-Scents Deodorant by Earth Mama is a natural and safe deodorant for sensitive skin, pregnancy, and breastfeeding, containing organic calendula, available in a 3-ounce size","source_id":"6f486e20e3102c7a285e357d356417ad"},{"name":"ENJOY LIFE FOODS SOFT BAKED OVALS","type":"PRODUCT","description":"Enjoy Life Foods Soft Baked Ovals are breakfast bars that are nut-free, soy-free, dairy-free, non-GMO, gluten-free, and vegan, available in a variety pack of 4 boxes","source_id":"6f486e20e3102c7a285e357d356417ad"},{"name":"ENJOY LIFE SOFT BAKED CHEWY BARS","type":"PRODUCT","description":"Enjoy Life Soft Baked Chewy Bars are nut-free, soy-free, dairy-free, gluten-free bars available in a variety pack of 6 boxes","source_id":"6f486e20e3102c7a285e357d356417ad"},{"name":"ENJOY LIFE LENTIL CHIPS VARIETY PACK","type":"PRODUCT","description":"Enjoy Life Lentil Chips Variety Pack are dairy-free, soy-free, nut-free, non-GMO, vegan, gluten-free chips available in a pack of 24 bags","source_id":"6f486e20e3102c7a285e357d356417ad"},{"name":"TRAVEL SET (4-PACK)","type":"PRODUCT","description":"A travel set of deodorants by Earth Mama, available in a pack of 4","source_id":"6f486e20e3102c7a285e357d356417ad"},{"name":"3 OUNCE (PACK OF 1)","type":"PRODUCT","description":"A 3-ounce bottle of deodorant by Earth Mama, available in a pack of 1","source_id":"6f486e20e3102c7a285e357d356417ad"},{"name":"3-OUNCE (2-PACK)","type":"PRODUCT","description":"A 3-ounce bottle of deodorant by Earth Mama, available in a pack of 2","source_id":"6f486e20e3102c7a285e357d356417ad"},{"name":"DAIRY FREE CHIPS","type":"PRODUCT","description":"Dairy-free chips produced by Enjoy Life Foods","source_id":"6f486e20e3102c7a285e357d356417ad","entity_type":"PRODUCT"},{"name":"NUT FREE BARS","type":"PRODUCT","description":"Nut-free bars produced by Enjoy Life Foods","source_id":"6f486e20e3102c7a285e357d356417ad"},{"name":"SOY FREE BARS","type":"PRODUCT","description":"Soy-free bars produced by Enjoy Life Foods","source_id":"6f486e20e3102c7a285e357d356417ad"},{"name":"GLUTEN FREE BARS","type":"PRODUCT","description":"Gluten-free bars produced by Enjoy Life Foods","source_id":"6f486e20e3102c7a285e357d356417ad"},{"name":"VEGAN BARS","type":"PRODUCT","description":"Vegan bars produced by Enjoy Life Foods","source_id":"6f486e20e3102c7a285e357d356417ad"},{"name":"NON GMO BARS","type":"PRODUCT","description":"Non-GMO bars produced by Enjoy Life Foods","source_id":"6f486e20e3102c7a285e357d356417ad"},{"name":"SOY FREE CHIPS","type":"PRODUCT","description":"Soy-free chips produced by Enjoy Life Foods","source_id":"6f486e20e3102c7a285e357d356417ad"},{"name":"NUT FREE CHIPS","type":"PRODUCT","description":"Nut-free chips produced by Enjoy Life Foods","source_id":"6f486e20e3102c7a285e357d356417ad"},{"name":"NON GMO CHIPS","type":"PRODUCT","description":"Non-GMO chips produced by Enjoy Life Foods","source_id":"6f486e20e3102c7a285e357d356417ad"},{"name":"VEGAN CHIPS","type":"PRODUCT","description":"Vegan chips produced by Enjoy Life Foods","source_id":"6f486e20e3102c7a285e357d356417ad"},{"name":"GLUTEN FREE CHIPS","type":"PRODUCT","description":"Gluten-free chips produced by Enjoy Life Foods","source_id":"6f486e20e3102c7a285e357d356417ad"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"LANGUAGE AGENT TREE SEARCH\">      <data key=\"d0\">TECHNOLOGY\/PROCESS<\/data>      <data key=\"d1\">Language Agent Tree Search is a method that unifies reasoning, acting, and planning in language models<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>      <data key=\"d3\">TECHNOLOGY\/PROCESS<\/data>    <\/node>    <node id=\"BRIGHT CITRUS DEODORANT\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">Bright Citrus Deodorant by Earth Mama is a natural and safe deodorant for sensitive skin, pregnancy, and breastfeeding, containing organic calendula, available in a 3-ounce size<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>      <data key=\"d3\">PRODUCT<\/data>    <\/node>    <node id=\"EARTH MAMA\">      <data key=\"d0\">BRAND<\/data>      <data key=\"d1\">Earth Mama is the brand that produces the Bright Citrus Deodorant<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>      <data key=\"d3\">BRAND<\/data>    <\/node>    <node id=\"ENJOY LIFE FOODS\">      <data key=\"d0\">BRAND<\/data>      <data key=\"d1\">Enjoy Life Foods is a brand that produces various dairy-free, nut-free, soy-free, gluten-free, and vegan food products<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>      <data key=\"d3\">BRAND<\/data>    <\/node>    <node id=\"DAIRY FREE AND APPLE VARIETY PACK OF CHIPS\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A variety pack of chips that is dairy-free and includes apple flavor, produced by Enjoy Life Foods<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>      <data key=\"d3\">PRODUCT<\/data>    <\/node>    <node id=\"VALUE FUNCTION PROMPT\">      <data key=\"d0\">INSTRUCTION<\/data>      <data key=\"d1\">A prompt that asks to analyze a purchasing trajectory and conclude a correctness score from 1 to 10<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>      <data key=\"d3\">INSTRUCTION<\/data>    <\/node>    <node id=\"REFLECTION PROMPT\">      <data key=\"d0\">INSTRUCTION<\/data>      <data key=\"d1\">A prompt that asks an advanced reasoning agent to diagnose a failure in a previous trial and devise a new plan to mitigate the failure<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>      <data key=\"d3\">INSTRUCTION<\/data>    <\/node>    <node id=\"WEB SHOP\">      <data key=\"d0\">PLATFORM<\/data>      <data key=\"d1\">An online shopping platform where users can search for and purchase items<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>      <data key=\"d3\">PLATFORM<\/data>    <\/node>    <node id=\"GINGER FRESH DEODORANT\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">Ginger Fresh Deodorant by Earth Mama is a natural and safe deodorant for sensitive skin, pregnancy, and breastfeeding, containing organic calendula, available in a 3-ounce size<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/node>    <node id=\"CALMING LAVENDER DEODORANT\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">Calming Lavender Deodorant by Earth Mama is a natural and safe deodorant for sensitive skin, pregnancy, and breastfeeding, containing organic calendula, available in a 3-ounce size<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/node>    <node id=\"SIMPLY NON-SCENTS DEODORANT\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">Simply Non-Scents Deodorant by Earth Mama is a natural and safe deodorant for sensitive skin, pregnancy, and breastfeeding, containing organic calendula, available in a 3-ounce size<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/node>    <node id=\"ENJOY LIFE FOODS SOFT BAKED OVALS\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">Enjoy Life Foods Soft Baked Ovals are breakfast bars that are nut-free, soy-free, dairy-free, non-GMO, gluten-free, and vegan, available in a variety pack of 4 boxes<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/node>    <node id=\"ENJOY LIFE SOFT BAKED CHEWY BARS\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">Enjoy Life Soft Baked Chewy Bars are nut-free, soy-free, dairy-free, gluten-free bars available in a variety pack of 6 boxes<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/node>    <node id=\"ENJOY LIFE LENTIL CHIPS VARIETY PACK\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">Enjoy Life Lentil Chips Variety Pack are dairy-free, soy-free, nut-free, non-GMO, vegan, gluten-free chips available in a pack of 24 bags<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/node>    <node id=\"TRAVEL SET (4-PACK)\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A travel set of deodorants by Earth Mama, available in a pack of 4<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/node>    <node id=\"3 OUNCE (PACK OF 1)\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A 3-ounce bottle of deodorant by Earth Mama, available in a pack of 1<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/node>    <node id=\"3-OUNCE (2-PACK)\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A 3-ounce bottle of deodorant by Earth Mama, available in a pack of 2<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/node>    <node id=\"DAIRY FREE CHIPS\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">Dairy-free chips produced by Enjoy Life Foods<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>      <data key=\"d3\">PRODUCT<\/data>    <\/node>    <node id=\"NUT FREE BARS\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">Nut-free bars produced by Enjoy Life Foods<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/node>    <node id=\"SOY FREE BARS\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">Soy-free bars produced by Enjoy Life Foods<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/node>    <node id=\"GLUTEN FREE BARS\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">Gluten-free bars produced by Enjoy Life Foods<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/node>    <node id=\"VEGAN BARS\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">Vegan bars produced by Enjoy Life Foods<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/node>    <node id=\"NON GMO BARS\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">Non-GMO bars produced by Enjoy Life Foods<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/node>    <node id=\"SOY FREE CHIPS\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">Soy-free chips produced by Enjoy Life Foods<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/node>    <node id=\"NUT FREE CHIPS\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">Nut-free chips produced by Enjoy Life Foods<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/node>    <node id=\"NON GMO CHIPS\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">Non-GMO chips produced by Enjoy Life Foods<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/node>    <node id=\"VEGAN CHIPS\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">Vegan chips produced by Enjoy Life Foods<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/node>    <node id=\"GLUTEN FREE CHIPS\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">Gluten-free chips produced by Enjoy Life Foods<\/data>      <data key=\"d2\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/node>    <edge source=\"BRIGHT CITRUS DEODORANT\" target=\"EARTH MAMA\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">Bright Citrus Deodorant is a product made by the brand Earth Mama<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"EARTH MAMA\" target=\"GINGER FRESH DEODORANT\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Ginger Fresh Deodorant is a product made by the brand Earth Mama<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"EARTH MAMA\" target=\"CALMING LAVENDER DEODORANT\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Calming Lavender Deodorant is a product made by the brand Earth Mama<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"EARTH MAMA\" target=\"SIMPLY NON-SCENTS DEODORANT\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Simply Non-Scents Deodorant is a product made by the brand Earth Mama<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"EARTH MAMA\" target=\"TRAVEL SET (4-PACK)\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Travel Set (4-Pack) is a product made by the brand Earth Mama<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"EARTH MAMA\" target=\"3 OUNCE (PACK OF 1)\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">3 Ounce (Pack of 1) is a product made by the brand Earth Mama<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"EARTH MAMA\" target=\"3-OUNCE (2-PACK)\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">3-Ounce (2-Pack) is a product made by the brand Earth Mama<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"ENJOY LIFE FOODS\" target=\"DAIRY FREE AND APPLE VARIETY PACK OF CHIPS\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">The dairy-free and apple variety pack of chips is a product made by Enjoy Life Foods<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"ENJOY LIFE FOODS\" target=\"ENJOY LIFE FOODS SOFT BAKED OVALS\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Enjoy Life Foods Soft Baked Ovals are a product made by Enjoy Life Foods<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"ENJOY LIFE FOODS\" target=\"ENJOY LIFE SOFT BAKED CHEWY BARS\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Enjoy Life Soft Baked Chewy Bars are a product made by Enjoy Life Foods<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"ENJOY LIFE FOODS\" target=\"ENJOY LIFE LENTIL CHIPS VARIETY PACK\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Enjoy Life Lentil Chips Variety Pack is a product made by Enjoy Life Foods<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"ENJOY LIFE FOODS\" target=\"DAIRY FREE CHIPS\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">Dairy-Free Chips are a product made by Enjoy Life Foods<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"ENJOY LIFE FOODS\" target=\"NUT FREE BARS\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Nut-Free Bars are a product made by Enjoy Life Foods<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"ENJOY LIFE FOODS\" target=\"SOY FREE BARS\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Soy-Free Bars are a product made by Enjoy Life Foods<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"ENJOY LIFE FOODS\" target=\"GLUTEN FREE BARS\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Gluten-Free Bars are a product made by Enjoy Life Foods<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"ENJOY LIFE FOODS\" target=\"VEGAN BARS\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Vegan Bars are a product made by Enjoy Life Foods<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"ENJOY LIFE FOODS\" target=\"NON GMO BARS\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Non-GMO Bars are a product made by Enjoy Life Foods<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"ENJOY LIFE FOODS\" target=\"SOY FREE CHIPS\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Soy-Free Chips are a product made by Enjoy Life Foods<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"ENJOY LIFE FOODS\" target=\"NUT FREE CHIPS\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Nut-Free Chips are a product made by Enjoy Life Foods<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"ENJOY LIFE FOODS\" target=\"NON GMO CHIPS\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Non-GMO Chips are a product made by Enjoy Life Foods<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"ENJOY LIFE FOODS\" target=\"VEGAN CHIPS\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Vegan Chips are a product made by Enjoy Life Foods<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"ENJOY LIFE FOODS\" target=\"GLUTEN FREE CHIPS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Gluten-Free Chips are a product made by Enjoy Life Foods<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"VALUE FUNCTION PROMPT\" target=\"WEB SHOP\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">The Value Function Prompt involves analyzing a purchasing trajectory on a web shop<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>    <edge source=\"REFLECTION PROMPT\" target=\"WEB SHOP\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">The Reflection Prompt involves diagnosing a failure in a purchasing trial on a web shop<\/data>      <data key=\"d6\">6f486e20e3102c7a285e357d356417ad<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"4ed5aa10872b585d02aa2daf4ff8f7fd","chunk":" i am looking for dairy free and\napple variety pack of chips, and price lower than 30.00\ndollars [Search]\nAction: search[dairy free and apple variety pack of chips]\nObservation: [Back to Search] Page 1 (Total results: 50)\n[Next >] [B07HRFJWP8] Enjoy Life Foods Soft Baked\nOvals, Breakfast Bars, Nut Free Bars, Soy Free, Dairy Free,\nNon GMO, Gluten Free, Vegan, Variety Pack, 4 Boxes(20 Bars Total) $100.0 [B01KMHY5PG] Enjoy Life Soft\nBaked Chewy Bars, Variety Pack, Nut Free Bars, Soy Free,\nDairy Free, Gluten Free, 6 Boxes (30 Total Bars) $21.49\n[B008D2X8C4] Enjoy Life Lentil Chips Variety Pack, Dairy\nFree Chips, Soy Free, Nut Free, Non GMO, Vegan, Gluten\nFree, 24 Bags (0.8 oz) $100.0\nAction: think[The first two items are not what I want. The\nthird item is the dairy free and apple variety pack of chips I\nwant.] Observation: OK.\nAction: click[B008D2X8C4] Observation: [Back to Search]\n[<Prev] flavor name [dill and sour cream][garlic & parme-\nsan][light sea salt][margherita pizza][thai chili lime][variety\npack] size [0.8 ounce (pack of 24)][4 ounce (pack of 12)]\nPrice: $100.0 Rating: N.A. [Description] [Features] [Re-\nviews] [Buy Now]\nAction: think[The item has options \u2018variety pack\u2019 and \u20180.8\nounce (pack of 24)\u2019 and seems good to buy.] Observation:\nOK.\nAction: click[variety pack] Observation: You have clicked\nvariety pack.\nAction: click[0.8 ounce (pack of 24)] Observation: You\nhave clicked 0.8 ounce (pack of 24).\nAction: click[Buy Now]\nSTATUS: FAIL\nReflection: In this attempt, I was unsuccessful. I acciden-\ntally bought a product that was $100, which is more than my\nbudget of $30. Either way, the initial search results were not\ngood. Next time, I will do search[\u201cvariety pack of chips\u201d]\nand then check if the results meet the dairy free and the $30\nbudget constraints. I will continue to refine my searches so\nthat I can find more products.\nPrevious Trial Instruction: i need gluten free vegetarian\nsmoked peppered bacon - 4 ounce (pack of 2), and price\nlower than 40.00 dollars [Search]\nAction: search[gluten free vegetarian smoked peppered ba-\ncon 4 ounce pack of 2] Observation: [Back to Search] Page\n1 (Total results: 50) [Next >] [B06Y96MXJV] Smoked\nBacon Sea Salt 3-Pack: Smoked Bacon Chipotle, Smoked\nBacon and Onion, Smoked Peppered Bacon - All-Natural\nSea Salts Slowly Smoked Over Alderwood - No Gluten, No\nMSG, Non-GMO (12 total oz.) $29.99 [B06Y96N1KG]\nSpicy Hot Pepper Sea Salt 3-Pack: Ghost Pepper, Jalapeno,\nHabanero - All Natural, Delicious Blends of Peppers & Sea\nSalt - Gluten-Free, Kosher, No MSG, Non-GMO (12 total\noz.) $29.99 [B07GJTKYJQ] Louisville Vegan Jerky - 5\nFlavor Variety Pack, Non-GMO Soy Protein, Gluten-Free\n(Black Pepper, Buffalo Dill, Pepperoni, Maple Bacon, and\nCarolina BBQ, 3 Ounces) $42.99\n22Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models\nAction: think[The first two items are not what I want. The\nthird item is not what I want, but it is the closest one.]\nObservation: OK.\nAction: click[B07GJTKYJQ] Observation: [Back to\nSearch] [ <Prev] Louisville Vegan Jerky - 5 Flavor Variety\nPack, Non-GMO Soy Protein, Gluten-Free (Black Pepper,\nBuffalo Dill, Pepperoni, Maple Bacon, and Carolina BBQ,\n3 Ounces) Price: $42.99 Rating: N.A. [Description] [Fea-\ntures] [Reviews] [Buy Now]\nAction: think[The price is too high and it is not what I want.]\nObservation: OK.\nAction: click[ <Prev] Observation: [Back to Search] Page\n1 (Total results: 50) [Next >] [B06Y96MXJV] Smoked\nBacon Sea Salt 3-Pack: Smoked Bacon Chipotle, Smoked\nBacon and Onion, Smoked Peppered Bacon - All-Natural\nSea Salts Slowly Smoked Over Alderwood - No Gluten,\nNo MSG, Non-GMO (12 total oz.) 29.99 [B06Y96N1KG]\nSpicy Hot Pepper Sea Salt 3-Pack: Ghost Pepper, Jalapeno,\nHabanero - All Natural, Delicious Blends of Peppers &\nSea Salt - Gluten-Free, Kosher, No MSG, Non-GMO (12\ntotal oz.) 29.99 [B07GJTKYJQ] Louisville Vegan Jerky - 5\nFlavor Variety Pack,","chunk_id":"4ed5aa10872b585d02aa2daf4ff8f7fd","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":1200,"entities":[{"name":"DAIRY FREE AND APPLE VARIETY PACK OF CHIPS","type":"PRODUCT","description":"A variety pack of chips that is dairy-free and includes apple flavor","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"ENJOY LIFE FOODS","type":"BRAND","description":"A brand that offers various allergen-free food products, including dairy-free, nut-free, soy-free, and gluten-free options","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"SOFT BAKED OVALS","type":"PRODUCT","description":"Breakfast bars from Enjoy Life Foods that are nut-free, soy-free, dairy-free, non-GMO, gluten-free, and vegan","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"SOFT BAKED CHEWY BARS","type":"PRODUCT","description":"Chewy bars from Enjoy Life Foods that are nut-free, soy-free, dairy-free, and gluten-free","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"LENTIL CHIPS","type":"PRODUCT","description":"Lentil chips from Enjoy Life Foods that are dairy-free, soy-free, nut-free, non-GMO, vegan, and gluten-free","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"VARIETY PACK","type":"OPTION","description":"An option for the Enjoy Life Lentil Chips that includes multiple flavors","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"0.8 OUNCE (PACK OF 24)","type":"SIZE","description":"A size option for the Enjoy Life Lentil Chips variety pack","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"BUY NOW","type":"ACTION","description":"An action to purchase a product immediately","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON","type":"PRODUCT","description":"A gluten-free, vegetarian product with smoked peppered bacon flavor","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"SMOKED BACON SEA SALT","type":"PRODUCT","description":"A 3-pack of smoked bacon sea salt flavors that are gluten-free, non-GMO, and contain no MSG","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"SPICY HOT PEPPER SEA SALT","type":"PRODUCT","description":"A 3-pack of spicy hot pepper sea salt flavors that are gluten-free, kosher, non-GMO, and contain no MSG","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"LOUISVILLE VEGAN JERKY","type":"PRODUCT","description":"A 5-flavor variety pack of vegan jerky that is non-GMO, soy protein-based, and gluten-free","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"SEARCH","type":"ACTION","description":"An action to look for specific products or information","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"THINK","type":"ACTION","description":"An action to reflect or consider information before making a decision","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"CLICK","type":"ACTION","description":"An action to select or interact with a specific item or option","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"REFLECTION","type":"ACTION","description":"An action to review and analyze past actions or decisions","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"PREVIOUS TRIAL INSTRUCTION","type":"ACTION","description":"An instruction given for a previous search or task","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"ENJOY LIFE FOODS SOFT BAKED OVALS","type":"PRODUCT","description":"A specific product from Enjoy Life Foods that includes breakfast bars which are nut-free, soy-free, dairy-free, non-GMO, gluten-free, and vegan","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"ENJOY LIFE SOFT BAKED CHEWY BARS","type":"PRODUCT","description":"A specific product from Enjoy Life Foods that includes chewy bars which are nut-free, soy-free, dairy-free, and gluten-free","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"ENJOY LIFE LENTIL CHIPS","type":"PRODUCT","description":"A specific product from Enjoy Life Foods that includes lentil chips which are dairy-free, soy-free, nut-free, non-GMO, vegan, and gluten-free","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"SMOKED BACON CHIPOTLE","type":"PRODUCT","description":"A flavor option in the Smoked Bacon Sea Salt 3-Pack that is gluten-free, non-GMO, and contains no MSG","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"SMOKED BACON AND ONION","type":"PRODUCT","description":"A flavor option in the Smoked Bacon Sea Salt 3-Pack that is gluten-free, non-GMO, and contains no MSG","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"GHOST PEPPER","type":"PRODUCT","description":"A flavor option in the Spicy Hot Pepper Sea Salt 3-Pack that is gluten-free, kosher, non-GMO, and contains no MSG","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"JALAPENO","type":"PRODUCT","description":"A flavor option in the Spicy Hot Pepper Sea Salt 3-Pack that is gluten-free, kosher, non-GMO, and contains no MSG","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"HABANERO","type":"PRODUCT","description":"A flavor option in the Spicy Hot Pepper Sea Salt 3-Pack that is gluten-free, kosher, non-GMO, and contains no MSG","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"BLACK PEPPER","type":"PRODUCT","description":"A flavor option in the Louisville Vegan Jerky 5-Flavor Variety Pack that is non-GMO, soy protein-based, and gluten-free","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"BUFFALO DILL","type":"PRODUCT","description":"A flavor option in the Louisville Vegan Jerky 5-Flavor Variety Pack that is non-GMO, soy protein-based, and gluten-free","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"PEPPERONI","type":"PRODUCT","description":"A flavor option in the Louisville Vegan Jerky 5-Flavor Variety Pack that is non-GMO, soy protein-based, and gluten-free","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"MAPLE BACON","type":"PRODUCT","description":"A flavor option in the Louisville Vegan Jerky 5-Flavor Variety Pack that is non-GMO, soy protein-based, and gluten-free","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"},{"name":"CAROLINA BBQ","type":"PRODUCT","description":"A flavor option in the Louisville Vegan Jerky 5-Flavor Variety Pack that is non-GMO, soy protein-based, and gluten-free","source_id":"4ed5aa10872b585d02aa2daf4ff8f7fd"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"DAIRY FREE AND APPLE VARIETY PACK OF CHIPS\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A variety pack of chips that is dairy-free and includes apple flavor<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"ENJOY LIFE FOODS\">      <data key=\"d0\">BRAND<\/data>      <data key=\"d1\">A brand that offers various allergen-free food products, including dairy-free, nut-free, soy-free, and gluten-free options<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"SOFT BAKED OVALS\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">Breakfast bars from Enjoy Life Foods that are nut-free, soy-free, dairy-free, non-GMO, gluten-free, and vegan<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"SOFT BAKED CHEWY BARS\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">Chewy bars from Enjoy Life Foods that are nut-free, soy-free, dairy-free, and gluten-free<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"LENTIL CHIPS\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">Lentil chips from Enjoy Life Foods that are dairy-free, soy-free, nut-free, non-GMO, vegan, and gluten-free<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"VARIETY PACK\">      <data key=\"d0\">OPTION<\/data>      <data key=\"d1\">An option for the Enjoy Life Lentil Chips that includes multiple flavors<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"0.8 OUNCE (PACK OF 24)\">      <data key=\"d0\">SIZE<\/data>      <data key=\"d1\">A size option for the Enjoy Life Lentil Chips variety pack<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"BUY NOW\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">An action to purchase a product immediately<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A gluten-free, vegetarian product with smoked peppered bacon flavor<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"SMOKED BACON SEA SALT\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A 3-pack of smoked bacon sea salt flavors that are gluten-free, non-GMO, and contain no MSG<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"SPICY HOT PEPPER SEA SALT\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A 3-pack of spicy hot pepper sea salt flavors that are gluten-free, kosher, non-GMO, and contain no MSG<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"LOUISVILLE VEGAN JERKY\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A 5-flavor variety pack of vegan jerky that is non-GMO, soy protein-based, and gluten-free<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"SEARCH\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">An action to look for specific products or information<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"THINK\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">An action to reflect or consider information before making a decision<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"CLICK\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">An action to select or interact with a specific item or option<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"REFLECTION\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">An action to review and analyze past actions or decisions<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"PREVIOUS TRIAL INSTRUCTION\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">An instruction given for a previous search or task<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"ENJOY LIFE FOODS SOFT BAKED OVALS\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A specific product from Enjoy Life Foods that includes breakfast bars which are nut-free, soy-free, dairy-free, non-GMO, gluten-free, and vegan<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"ENJOY LIFE SOFT BAKED CHEWY BARS\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A specific product from Enjoy Life Foods that includes chewy bars which are nut-free, soy-free, dairy-free, and gluten-free<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"ENJOY LIFE LENTIL CHIPS\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A specific product from Enjoy Life Foods that includes lentil chips which are dairy-free, soy-free, nut-free, non-GMO, vegan, and gluten-free<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"SMOKED BACON CHIPOTLE\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A flavor option in the Smoked Bacon Sea Salt 3-Pack that is gluten-free, non-GMO, and contains no MSG<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"SMOKED BACON AND ONION\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A flavor option in the Smoked Bacon Sea Salt 3-Pack that is gluten-free, non-GMO, and contains no MSG<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"GHOST PEPPER\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A flavor option in the Spicy Hot Pepper Sea Salt 3-Pack that is gluten-free, kosher, non-GMO, and contains no MSG<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"JALAPENO\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A flavor option in the Spicy Hot Pepper Sea Salt 3-Pack that is gluten-free, kosher, non-GMO, and contains no MSG<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"HABANERO\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A flavor option in the Spicy Hot Pepper Sea Salt 3-Pack that is gluten-free, kosher, non-GMO, and contains no MSG<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"BLACK PEPPER\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A flavor option in the Louisville Vegan Jerky 5-Flavor Variety Pack that is non-GMO, soy protein-based, and gluten-free<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"BUFFALO DILL\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A flavor option in the Louisville Vegan Jerky 5-Flavor Variety Pack that is non-GMO, soy protein-based, and gluten-free<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"PEPPERONI\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A flavor option in the Louisville Vegan Jerky 5-Flavor Variety Pack that is non-GMO, soy protein-based, and gluten-free<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"MAPLE BACON\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A flavor option in the Louisville Vegan Jerky 5-Flavor Variety Pack that is non-GMO, soy protein-based, and gluten-free<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <node id=\"CAROLINA BBQ\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A flavor option in the Louisville Vegan Jerky 5-Flavor Variety Pack that is non-GMO, soy protein-based, and gluten-free<\/data>      <data key=\"d2\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/node>    <edge source=\"DAIRY FREE AND APPLE VARIETY PACK OF CHIPS\" target=\"ENJOY LIFE FOODS\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The dairy-free and apple variety pack of chips is a product offered by Enjoy Life Foods<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"DAIRY FREE AND APPLE VARIETY PACK OF CHIPS\" target=\"SEARCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The search action is used to look for the dairy-free and apple variety pack of chips<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"DAIRY FREE AND APPLE VARIETY PACK OF CHIPS\" target=\"THINK\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The think action is used to reflect on whether the dairy-free and apple variety pack of chips meets the criteria<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"DAIRY FREE AND APPLE VARIETY PACK OF CHIPS\" target=\"CLICK\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The click action is used to select the dairy-free and apple variety pack of chips<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"DAIRY FREE AND APPLE VARIETY PACK OF CHIPS\" target=\"REFLECTION\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The reflection action is used to review the decision to buy the dairy-free and apple variety pack of chips<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"ENJOY LIFE FOODS\" target=\"SOFT BAKED OVALS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Soft Baked Ovals are a product offered by Enjoy Life Foods<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"ENJOY LIFE FOODS\" target=\"SOFT BAKED CHEWY BARS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Soft Baked Chewy Bars are a product offered by Enjoy Life Foods<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"ENJOY LIFE FOODS\" target=\"LENTIL CHIPS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Lentil Chips are a product offered by Enjoy Life Foods<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"SOFT BAKED OVALS\" target=\"ENJOY LIFE FOODS SOFT BAKED OVALS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Enjoy Life Foods Soft Baked Ovals is a specific product that includes breakfast bars<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"SOFT BAKED CHEWY BARS\" target=\"ENJOY LIFE SOFT BAKED CHEWY BARS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Enjoy Life Soft Baked Chewy Bars is a specific product that includes chewy bars<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"LENTIL CHIPS\" target=\"VARIETY PACK\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The variety pack is an option for the Enjoy Life Lentil Chips<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"LENTIL CHIPS\" target=\"0.8 OUNCE (PACK OF 24)\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The 0.8 ounce (pack of 24) is a size option for the Enjoy Life Lentil Chips<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"LENTIL CHIPS\" target=\"BUY NOW\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The Buy Now action is used to purchase the Enjoy Life Lentil Chips<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"LENTIL CHIPS\" target=\"ENJOY LIFE LENTIL CHIPS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Enjoy Life Lentil Chips is a specific product that includes lentil chips<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON\" target=\"SMOKED BACON SEA SALT\">      <data key=\"d3\">5.0<\/data>      <data key=\"d4\">Both products are gluten-free and have a smoked bacon flavor<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON\" target=\"SPICY HOT PEPPER SEA SALT\">      <data key=\"d3\">5.0<\/data>      <data key=\"d4\">Both products are gluten-free and contain pepper flavors<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON\" target=\"LOUISVILLE VEGAN JERKY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Both products are gluten-free and vegetarian<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON\" target=\"PREVIOUS TRIAL INSTRUCTION\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The previous trial instruction was to search for gluten-free vegetarian smoked peppered bacon<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON\" target=\"SEARCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The search action is used to look for gluten-free vegetarian smoked peppered bacon<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON\" target=\"THINK\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The think action is used to reflect on whether the gluten-free vegetarian smoked peppered bacon meets the criteria<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"GLUTEN FREE VEGETARIAN SMOKED PEPPERED BACON\" target=\"CLICK\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The click action is used to select the gluten-free vegetarian smoked peppered bacon<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"SMOKED BACON SEA SALT\" target=\"SMOKED BACON CHIPOTLE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Smoked Bacon Chipotle is a flavor option in the Smoked Bacon Sea Salt 3-Pack<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"SMOKED BACON SEA SALT\" target=\"SMOKED BACON AND ONION\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Smoked Bacon and Onion is a flavor option in the Smoked Bacon Sea Salt 3-Pack<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"SPICY HOT PEPPER SEA SALT\" target=\"GHOST PEPPER\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Ghost Pepper is a flavor option in the Spicy Hot Pepper Sea Salt 3-Pack<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"SPICY HOT PEPPER SEA SALT\" target=\"JALAPENO\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Jalapeno is a flavor option in the Spicy Hot Pepper Sea Salt 3-Pack<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"SPICY HOT PEPPER SEA SALT\" target=\"HABANERO\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Habanero is a flavor option in the Spicy Hot Pepper Sea Salt 3-Pack<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"LOUISVILLE VEGAN JERKY\" target=\"BLACK PEPPER\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Black Pepper is a flavor option in the Louisville Vegan Jerky 5-Flavor Variety Pack<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"LOUISVILLE VEGAN JERKY\" target=\"BUFFALO DILL\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Buffalo Dill is a flavor option in the Louisville Vegan Jerky 5-Flavor Variety Pack<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"LOUISVILLE VEGAN JERKY\" target=\"PEPPERONI\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Pepperoni is a flavor option in the Louisville Vegan Jerky 5-Flavor Variety Pack<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"LOUISVILLE VEGAN JERKY\" target=\"MAPLE BACON\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Maple Bacon is a flavor option in the Louisville Vegan Jerky 5-Flavor Variety Pack<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>    <edge source=\"LOUISVILLE VEGAN JERKY\" target=\"CAROLINA BBQ\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Carolina BBQ is a flavor option in the Louisville Vegan Jerky 5-Flavor Variety Pack<\/data>      <data key=\"d5\">4ed5aa10872b585d02aa2daf4ff8f7fd<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"5d356b8ff719763a38cecff22c4e17b7","chunk":" Non-GMO (12 total oz.) 29.99 [B06Y96N1KG]\nSpicy Hot Pepper Sea Salt 3-Pack: Ghost Pepper, Jalapeno,\nHabanero - All Natural, Delicious Blends of Peppers &\nSea Salt - Gluten-Free, Kosher, No MSG, Non-GMO (12\ntotal oz.) 29.99 [B07GJTKYJQ] Louisville Vegan Jerky - 5\nFlavor Variety Pack, Non-GMO Soy Protein, Gluten-Free\n(Black Pepper, Buffalo Dill, Pepperoni, Maple Bacon, and\nCarolina BBQ, 3 Ounces) 42.99\nAction: think[The first two items are not what I want.]\nObservation: OK.\nAction: click[Next >] Observation: Invalid action!\nAction: think[I need to refine my search.] Observation: OK.\nAction: click[ <Back to Search] Observation: Invalid ac-\ntion!\nAction: click[Back to Search]\nSTATUS: FAIL\nReflection: In this attempt, I was unsuccessful. The initial\nsearch results were not the products that I was looking for.\nNext time, I will do search[\u201cvegetarian bacon\u201d] for a broader\nsearch. I will check that the new results will fulfill the gluten\nfree and 4 ounce pack of 2 constraints. I will continue to\nrefine my searches so that I can find more products.\nPrevious trial: trajectory Reflection:\u201d\u2019\n23","chunk_id":"5d356b8ff719763a38cecff22c4e17b7","document_ids":["5597680041a0eb518b5a1bd4fee55c60"],"n_tokens":309,"entities":[{"name":"NON-GMO","type":"ATTRIBUTE","description":"Non-GMO refers to products that are not genetically modified","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"SPICY HOT PEPPER SEA SALT 3-PACK","type":"PRODUCT","description":"A 3-pack of spicy hot pepper sea salt including Ghost Pepper, Jalapeno, and Habanero flavors. It is all-natural, gluten-free, kosher, no MSG, and non-GMO","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"LOUISVILLE VEGAN JERKY","type":"PRODUCT","description":"A 5-flavor variety pack of vegan jerky made from non-GMO soy protein and gluten-free. Flavors include Black Pepper, Buffalo Dill, Pepperoni, Maple Bacon, and Carolina BBQ","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"GHOST PEPPER","type":"INGREDIENT","description":"A type of hot pepper used in the Spicy Hot Pepper Sea Salt 3-Pack","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"JALAPENO","type":"INGREDIENT","description":"A type of hot pepper used in the Spicy Hot Pepper Sea Salt 3-Pack","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"HABANERO","type":"INGREDIENT","description":"A type of hot pepper used in the Spicy Hot Pepper Sea Salt 3-Pack","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"GLUTEN-FREE","type":"ATTRIBUTE","description":"Indicates that the product does not contain gluten","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"KOSHER","type":"ATTRIBUTE","description":"Indicates that the product meets kosher dietary standards","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"NO MSG","type":"ATTRIBUTE","description":"Indicates that the product does not contain monosodium glutamate","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"SOY PROTEIN","type":"INGREDIENT","description":"A plant-based protein used in Louisville Vegan Jerky","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"BLACK PEPPER","type":"FLAVOR","description":"One of the flavors in the Louisville Vegan Jerky variety pack","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"BUFFALO DILL","type":"FLAVOR","description":"One of the flavors in the Louisville Vegan Jerky variety pack","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"PEPPERONI","type":"FLAVOR","description":"One of the flavors in the Louisville Vegan Jerky variety pack","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"MAPLE BACON","type":"FLAVOR","description":"One of the flavors in the Louisville Vegan Jerky variety pack","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"CAROLINA BBQ","type":"FLAVOR","description":"One of the flavors in the Louisville Vegan Jerky variety pack","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"SEARCH","type":"ACTION","description":"The action of looking for products using specific keywords","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"REFINE SEARCH","type":"ACTION","description":"The process of narrowing down search results to better match desired criteria","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"VEGETARIAN BACON","type":"PRODUCT","description":"A type of bacon alternative made from vegetarian ingredients","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"GLUTEN-FREE AND 4 OUNCE PACK OF 2","type":"CONSTRAINT","description":"Specific requirements for the product being searched for","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"ACTION","type":"ACTION","description":"An action taken by the user during the interaction with the system","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"THINK","type":"ACTION","description":"The action of considering or reflecting on the current situation or next steps","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"CLICK","type":"ACTION","description":"The action of selecting an option or button in the user interface","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"OBSERVATION","type":"ACTION","description":"The action of noting the system's response to a user's action","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"REFLECTION","type":"ACTION","description":"The action of reviewing and analyzing the outcome of the interaction","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"STATUS","type":"ATTRIBUTE","description":"The current state or condition of the system or process","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"FAIL","type":"ATTRIBUTE","description":"Indicates that the attempt or action was unsuccessful","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"PREVIOUS TRIAL","type":"ATTRIBUTE","description":"Refers to the earlier attempt or session in the process","source_id":"5d356b8ff719763a38cecff22c4e17b7"},{"name":"TRAJECTORY","type":"ATTRIBUTE","description":"The path or sequence of actions taken during the interaction","source_id":"5d356b8ff719763a38cecff22c4e17b7"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"NON-GMO\">      <data key=\"d0\">ATTRIBUTE<\/data>      <data key=\"d1\">Non-GMO refers to products that are not genetically modified<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"SPICY HOT PEPPER SEA SALT 3-PACK\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A 3-pack of spicy hot pepper sea salt including Ghost Pepper, Jalapeno, and Habanero flavors. It is all-natural, gluten-free, kosher, no MSG, and non-GMO<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"LOUISVILLE VEGAN JERKY\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A 5-flavor variety pack of vegan jerky made from non-GMO soy protein and gluten-free. Flavors include Black Pepper, Buffalo Dill, Pepperoni, Maple Bacon, and Carolina BBQ<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"GHOST PEPPER\">      <data key=\"d0\">INGREDIENT<\/data>      <data key=\"d1\">A type of hot pepper used in the Spicy Hot Pepper Sea Salt 3-Pack<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"JALAPENO\">      <data key=\"d0\">INGREDIENT<\/data>      <data key=\"d1\">A type of hot pepper used in the Spicy Hot Pepper Sea Salt 3-Pack<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"HABANERO\">      <data key=\"d0\">INGREDIENT<\/data>      <data key=\"d1\">A type of hot pepper used in the Spicy Hot Pepper Sea Salt 3-Pack<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"GLUTEN-FREE\">      <data key=\"d0\">ATTRIBUTE<\/data>      <data key=\"d1\">Indicates that the product does not contain gluten<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"KOSHER\">      <data key=\"d0\">ATTRIBUTE<\/data>      <data key=\"d1\">Indicates that the product meets kosher dietary standards<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"NO MSG\">      <data key=\"d0\">ATTRIBUTE<\/data>      <data key=\"d1\">Indicates that the product does not contain monosodium glutamate<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"SOY PROTEIN\">      <data key=\"d0\">INGREDIENT<\/data>      <data key=\"d1\">A plant-based protein used in Louisville Vegan Jerky<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"BLACK PEPPER\">      <data key=\"d0\">FLAVOR<\/data>      <data key=\"d1\">One of the flavors in the Louisville Vegan Jerky variety pack<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"BUFFALO DILL\">      <data key=\"d0\">FLAVOR<\/data>      <data key=\"d1\">One of the flavors in the Louisville Vegan Jerky variety pack<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"PEPPERONI\">      <data key=\"d0\">FLAVOR<\/data>      <data key=\"d1\">One of the flavors in the Louisville Vegan Jerky variety pack<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"MAPLE BACON\">      <data key=\"d0\">FLAVOR<\/data>      <data key=\"d1\">One of the flavors in the Louisville Vegan Jerky variety pack<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"CAROLINA BBQ\">      <data key=\"d0\">FLAVOR<\/data>      <data key=\"d1\">One of the flavors in the Louisville Vegan Jerky variety pack<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"SEARCH\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">The action of looking for products using specific keywords<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"REFINE SEARCH\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">The process of narrowing down search results to better match desired criteria<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"VEGETARIAN BACON\">      <data key=\"d0\">PRODUCT<\/data>      <data key=\"d1\">A type of bacon alternative made from vegetarian ingredients<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"GLUTEN-FREE AND 4 OUNCE PACK OF 2\">      <data key=\"d0\">CONSTRAINT<\/data>      <data key=\"d1\">Specific requirements for the product being searched for<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"ACTION\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">An action taken by the user during the interaction with the system<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"THINK\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">The action of considering or reflecting on the current situation or next steps<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"CLICK\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">The action of selecting an option or button in the user interface<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"OBSERVATION\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">The action of noting the system's response to a user's action<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"REFLECTION\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">The action of reviewing and analyzing the outcome of the interaction<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"STATUS\">      <data key=\"d0\">ATTRIBUTE<\/data>      <data key=\"d1\">The current state or condition of the system or process<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"FAIL\">      <data key=\"d0\">ATTRIBUTE<\/data>      <data key=\"d1\">Indicates that the attempt or action was unsuccessful<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"PREVIOUS TRIAL\">      <data key=\"d0\">ATTRIBUTE<\/data>      <data key=\"d1\">Refers to the earlier attempt or session in the process<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <node id=\"TRAJECTORY\">      <data key=\"d0\">ATTRIBUTE<\/data>      <data key=\"d1\">The path or sequence of actions taken during the interaction<\/data>      <data key=\"d2\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/node>    <edge source=\"SPICY HOT PEPPER SEA SALT 3-PACK\" target=\"GHOST PEPPER\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Ghost Pepper is one of the ingredients in the Spicy Hot Pepper Sea Salt 3-Pack<\/data>      <data key=\"d5\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/edge>    <edge source=\"SPICY HOT PEPPER SEA SALT 3-PACK\" target=\"JALAPENO\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Jalapeno is one of the ingredients in the Spicy Hot Pepper Sea Salt 3-Pack<\/data>      <data key=\"d5\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/edge>    <edge source=\"SPICY HOT PEPPER SEA SALT 3-PACK\" target=\"HABANERO\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Habanero is one of the ingredients in the Spicy Hot Pepper Sea Salt 3-Pack<\/data>      <data key=\"d5\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/edge>    <edge source=\"LOUISVILLE VEGAN JERKY\" target=\"SOY PROTEIN\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Soy Protein is the main ingredient in Louisville Vegan Jerky<\/data>      <data key=\"d5\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/edge>    <edge source=\"LOUISVILLE VEGAN JERKY\" target=\"BLACK PEPPER\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Black Pepper is one of the flavors in the Louisville Vegan Jerky variety pack<\/data>      <data key=\"d5\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/edge>    <edge source=\"LOUISVILLE VEGAN JERKY\" target=\"BUFFALO DILL\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Buffalo Dill is one of the flavors in the Louisville Vegan Jerky variety pack<\/data>      <data key=\"d5\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/edge>    <edge source=\"LOUISVILLE VEGAN JERKY\" target=\"PEPPERONI\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Pepperoni is one of the flavors in the Louisville Vegan Jerky variety pack<\/data>      <data key=\"d5\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/edge>    <edge source=\"LOUISVILLE VEGAN JERKY\" target=\"MAPLE BACON\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Maple Bacon is one of the flavors in the Louisville Vegan Jerky variety pack<\/data>      <data key=\"d5\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/edge>    <edge source=\"LOUISVILLE VEGAN JERKY\" target=\"CAROLINA BBQ\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Carolina BBQ is one of the flavors in the Louisville Vegan Jerky variety pack<\/data>      <data key=\"d5\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/edge>    <edge source=\"SEARCH\" target=\"REFINE SEARCH\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Refine Search is an action taken to improve the results of a Search<\/data>      <data key=\"d5\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/edge>    <edge source=\"SEARCH\" target=\"VEGETARIAN BACON\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Vegetarian Bacon is the product being searched for<\/data>      <data key=\"d5\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/edge>    <edge source=\"REFINE SEARCH\" target=\"GLUTEN-FREE AND 4 OUNCE PACK OF 2\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Refine Search is done to meet the constraints of Gluten-Free and 4 Ounce Pack of 2<\/data>      <data key=\"d5\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/edge>    <edge source=\"ACTION\" target=\"THINK\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Think is a type of action taken by the user<\/data>      <data key=\"d5\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/edge>    <edge source=\"ACTION\" target=\"CLICK\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Click is a type of action taken by the user<\/data>      <data key=\"d5\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/edge>    <edge source=\"ACTION\" target=\"OBSERVATION\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Observation is a type of action taken by the user<\/data>      <data key=\"d5\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/edge>    <edge source=\"ACTION\" target=\"REFLECTION\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Reflection is a type of action taken by the user<\/data>      <data key=\"d5\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/edge>    <edge source=\"STATUS\" target=\"FAIL\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Fail is a status indicating an unsuccessful attempt<\/data>      <data key=\"d5\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/edge>    <edge source=\"PREVIOUS TRIAL\" target=\"TRAJECTORY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Trajectory refers to the sequence of actions in the previous trial<\/data>      <data key=\"d5\">5d356b8ff719763a38cecff22c4e17b7<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"c3d0436082aada237ee4bee645f16059","chunk":"2024-8-19\nAutomated Design of Agentic Systems\nShengran Hu1,2, Cong Lu1,2and Jeff Clune1,2,3\n1University of British Columbia,2Vector Institute,3Canada CIFAR AI Chair\nResearchers are investing substantial effort in developing powerful general-purpose agents, wherein\nFoundation Models are used as modules within agentic systems (e.g. Chain-of-Thought, Self-Reflection,\nToolformer). However, the history of machine learning teaches us that hand-designed solutions are\neventually replaced by learned solutions. We formulate a new research area, Automated Design of\nAgentic Systems (ADAS), which aims to automatically create powerful agentic system designs, including\ninventing novel building blocks and\/or combining them in new ways. We further demonstrate that there\nis an unexplored yet promising approach within ADAS where agents can be defined in code and new\nagents can be automatically discovered by a meta agent programming ever better ones in code. Given\nthat programming languages are Turing Complete, this approach theoretically enables the learning\nofany possible agentic system: including novel prompts, tool use, control flows, and combinations\nthereof. We present a simple yet effective algorithm named Meta Agent Search to demonstrate this idea,\nwhere a meta agent iteratively programs interesting new agents based on an ever-growing archive of\nprevious discoveries. Through extensive experiments across multiple domains including coding, science,\nand math, we show that our algorithm can progressively invent agents with novel designs that greatly\noutperform state-of-the-art hand-designed agents. Importantly, we consistently observe the surprising\nresult that agents invented by Meta Agent Search maintain superior performance even when transferred\nacross domains and models, demonstrating their robustness and generality. Provided we develop it\nsafely, our work illustrates the potential of an exciting new research direction toward automatically\ndesigning ever-more powerful agentic systems to benefit humanity.\n\/githubhttps:\/\/github.com\/ShengranHu\/ADAS\n1. Introduction\nFoundation Models (FMs) such as GPT (OpenAI, 2022, 2024) and Claude (Anthropic, 2024b) are\nquicklybeingadoptedaspowerfulgeneral-purposeagentsforagentictasksthatneedflexiblereasoning\nand planning (Wang et al., 2024). Despite recent advancements in FMs, solving problems reliably\noften requires an agent to be a compound agentic system with multiple components instead of a\nmonolithic model query (Rockt\u00e4schel, 2024; Zaharia et al., 2024). Additionally, to enable agents to\nsolve complex real-world tasks, they often need access to external tools such as search engines, code\nexecution, and database queries. As a result, many effective building blocks of agentic systems have\nbeen proposed, such as chain-of-thought planning and reasoning (Hu & Clune, 2024; Wei et al., 2022;\nYao et al., 2023), memory structures (Lewis et al., 2020; Zhang et al., 2024c), tool use (Qu et al.,\n2024; Schick et al., 2023), and self-reflection (Madaan et al., 2024; Shinn et al., 2023). Although\nthese agents have already seen significant success across various applications (Wang et al., 2024),\ndeveloping these building blocks and combining them into complex agentic systems often requires\ndomain-specific manual tuning and substantial effort from both researchers and engineers.\nHowever, the history of machine learning reveals a recurring theme: manually created arti-\nfacts become replaced by learned, more efficient solutions over time as we get more compute and\ndata (Clune, 2019). An early example is from computer vision, where hand-designed features like\nHOG (Dalal & Triggs, 2005) were eventually replaced by learned features from Convolutional Neural\nCorresponding author(s): Shengran Hu (srhu@cs.ubc.ca)arXiv:2408.08435v1  [cs.AI]  15 Aug 2024Automated Design of Agentic Systems\nSummary and motivation : \u201cBased on \nthe insights from previous agents \u2026\u201d,\nName: \u201cDivide and Conquer Agent\u201d,\nCode: \u201cdef forward(Task):\n \u2026\u2026\n return Answer\u201d\nMeta AgentNext interesting agent\nAgent ArchiveTest performance on tasks InputRefine until novel \nand error -free\nExamples of Discovered Agents\nMulti -step Peer Review AgentExperts\nAnswers\nReviewersT ask\nVerified Multimodal AgentT ask\nVisual \nParadigm\nVerifier\nVerified \nParadigmVisual \nAnalyzer\nCOTAnswerT askSub -problem \nDivision subsubsub\nsubsub\nExpertsAnswersEnsembleAnswer\nDivide and Conquer AgentReviewsand add to archiveNew Agent\n\u2026\nFigure 1|Overview of the proposed algorithm Meta Agent Search and examples of discovered\nagents. In our algorithm, we instruct the \u201cmeta\u201d agent to iteratively program new agents, test their\nperformance on tasks, add them to an archive of discovered agents, and use this archive to inform the\nmeta agent in subsequent iterations. We show three example agents across our runs, with all names\ngenerated by the meta agent. The detailed code of example agents can be found in Appendix F.\nNetworks (CNNs, Krizhevsky et al. (2012)). More recently, AutoML methods (Hutter et al., 2019)\nand AI-Generating Algorithms (AI-GAs, Clune (2019)) have also demonstrated the superiority of\nlearned AI systems compared to hand-designed AI systems. For example, the current best-performing\nCNN models come from Neural Architecture Search (Elsken","chunk_id":"c3d0436082aada237ee4bee645f16059","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"SHENGRAN HU","type":"PERSON","description":"Shengran Hu is a researcher involved in the study of Automated Design of Agentic Systems and is affiliated with the University of British Columbia and the Vector Institute","source_id":"c3d0436082aada237ee4bee645f16059"},{"name":"CONG LU","type":"PERSON","description":"Cong Lu is a researcher involved in the study of Automated Design of Agentic Systems and is affiliated with the University of British Columbia and the Vector Institute","source_id":"c3d0436082aada237ee4bee645f16059"},{"name":"JEFF CLUNE","type":"PERSON","description":"Jeff Clune is a researcher involved in the study of Automated Design of Agentic Systems and is affiliated with the University of British Columbia, the Vector Institute, and holds a Canada CIFAR AI Chair","source_id":"c3d0436082aada237ee4bee645f16059"},{"name":"UNIVERSITY OF BRITISH COLUMBIA","type":"ORGANIZATION","description":"The University of British Columbia is an educational institution where some of the researchers involved in the study of Automated Design of Agentic Systems are affiliated","source_id":"c3d0436082aada237ee4bee645f16059"},{"name":"VECTOR INSTITUTE","type":"ORGANIZATION","description":"The Vector Institute is a research institution where some of the researchers involved in the study of Automated Design of Agentic Systems are affiliated","source_id":"c3d0436082aada237ee4bee645f16059"},{"name":"CANADA CIFAR AI CHAIR","type":"TITLE","description":"The Canada CIFAR AI Chair is a title held by Jeff Clune, one of the researchers involved in the study of Automated Design of Agentic Systems","source_id":"c3d0436082aada237ee4bee645f16059"},{"name":"AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)","type":"RESEARCH AREA","description":"Automated Design of Agentic Systems (ADAS) is a research area focused on automatically creating powerful agentic system designs, including inventing novel building blocks and\/or combining them in new ways","source_id":"c3d0436082aada237ee4bee645f16059"},{"name":"META AGENT SEARCH","type":"ALGORITHM","description":"Meta Agent Search is an algorithm that iteratively programs new agents, tests their performance on tasks, and adds them to an archive of discovered agents to inform subsequent iterations","source_id":"c3d0436082aada237ee4bee645f16059"},{"name":"FOUNDATION MODELS (FMS)","type":"TECHNOLOGY","description":"Foundation Models (FMs) are used as modules within agentic systems for tasks that need flexible reasoning and planning","source_id":"c3d0436082aada237ee4bee645f16059"},{"name":"GPT","type":"MODEL","description":"GPT is a Foundation Model developed by OpenAI, used for general-purpose agentic tasks","source_id":"c3d0436082aada237ee4bee645f16059"},{"name":"CLAUDE","type":"MODEL","description":"Claude is a Foundation Model developed by Anthropic, used for general-purpose agentic tasks","source_id":"c3d0436082aada237ee4bee645f16059"},{"name":"CHAIN-OF-THOUGHT","type":"TECHNIQUE","description":"Chain-of-Thought is a planning and reasoning technique used as a building block in agentic systems","source_id":"c3d0436082aada237ee4bee645f16059"},{"name":"SELF-REFLECTION","type":"TECHNIQUE","description":"Self-Reflection is a technique used in agentic systems to improve performance by reflecting on past actions","source_id":"c3d0436082aada237ee4bee645f16059"},{"name":"TOOLFORMER","type":"TECHNIQUE","description":"Toolformer is a technique used in agentic systems to enable the use of external tools","source_id":"c3d0436082aada237ee4bee645f16059"},{"name":"META AGENT","type":"AGENT","description":"A meta agent is an agent that programs other agents, tests their performance, and iteratively improves them","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"CONCEPT"},{"name":"AGENT ARCHIVE","type":"REPOSITORY","description":"Agent Archive is a repository where discovered agents are stored and used to inform the meta agent in subsequent iterations","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"CONCEPT"},{"name":"MULTI-STEP PEER REVIEW AGENT","type":"AGENT","description":"Multi-Step Peer Review Agent is an example of an agent discovered by the Meta Agent Search algorithm","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"CONCEPT"},{"name":"VERIFIED MULTIMODAL AGENT","type":"AGENT","description":"Verified Multimodal Agent is an example of an agent discovered by the Meta Agent Search algorithm","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"CONCEPT"},{"name":"DIVIDE AND CONQUER AGENT","type":"AGENT","description":"Divide and Conquer Agent is an example of an agent discovered by the Meta Agent Search algorithm","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"CONCEPT"},{"name":"HOG","type":"TECHNIQUE","description":"HOG (Histogram of Oriented Gradients) is a hand-designed feature used in computer vision that was eventually replaced by learned features from Convolutional Neural Networks","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"TECHNIQUE"},{"name":"CONVOLUTIONAL NEURAL NETWORKS (CNNS)","type":"TECHNOLOGY","description":"Convolutional Neural Networks (CNNs) are a type of neural network used in computer vision that replaced hand-designed features like HOG","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"TECHNOLOGY"},{"name":"NEURAL ARCHITECTURE SEARCH","type":"TECHNIQUE","description":"Neural Architecture Search is a method used to automatically design neural network architectures, leading to the best-performing CNN models","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"TECHNIQUE"},{"name":"AUTOML","type":"TECHNIQUE","description":"AutoML (Automated Machine Learning) is a method that automates the process of applying machine learning to real-world problems","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"TECHNIQUE"},{"name":"AI-GENERATING ALGORITHMS (AI-GAS)","type":"TECHNIQUE","description":"AI-Generating Algorithms (AI-GAs) are methods that automatically generate AI systems, demonstrating the superiority of learned AI systems over hand-designed ones","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"TECHNIQUE"},{"name":"SHENGRAN HU'S GITHUB","type":"RESOURCE","description":"Shengran Hu's GitHub is a resource where the code related to the Automated Design of Agentic Systems can be found","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"RESOURCE"},{"name":"ARXIV","type":"PUBLICATION","description":"arXiv is a repository where the paper on Automated Design of Agentic Systems is published","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"PUBLICATION"},{"name":"OPENAI","type":"ORGANIZATION","description":"OpenAI is the organization that developed the GPT Foundation Model","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"ORGANIZATION"},{"name":"ANTHROPIC","type":"ORGANIZATION","description":"Anthropic is the organization that developed the Claude Foundation Model","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"ORGANIZATION"},{"name":"WANG ET AL.","type":"AUTHOR","description":"Wang et al. are authors who have contributed to the research on Foundation Models and agentic systems","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"AUTHOR"},{"name":"ROCKT\u00c4SCHEL","type":"AUTHOR","description":"Rockt\u00e4schel is an author who has contributed to the research on compound agentic systems","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"AUTHOR"},{"name":"ZAHARIA ET AL.","type":"AUTHOR","description":"Zaharia et al. are authors who have contributed to the research on compound agentic systems","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"AUTHOR"},{"name":"HU & CLUNE","type":"AUTHOR","description":"Hu & Clune are authors who have contributed to the research on chain-of-thought planning and reasoning","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"AUTHOR"},{"name":"WEI ET AL.","type":"AUTHOR","description":"Wei et al. are authors who have contributed to the research on chain-of-thought planning and reasoning","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"AUTHOR"},{"name":"YAO ET AL.","type":"AUTHOR","description":"Yao et al. are authors who have contributed to the research on chain-of-thought planning and reasoning","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"AUTHOR"},{"name":"LEWIS ET AL.","type":"AUTHOR","description":"Lewis et al. are authors who have contributed to the research on memory structures in agentic systems","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"AUTHOR"},{"name":"ZHANG ET AL.","type":"AUTHOR","description":"Zhang et al. are authors who have contributed to the research on memory structures in agentic systems","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"AUTHOR"},{"name":"QU ET AL.","type":"AUTHOR","description":"Qu et al. are authors who have contributed to the research on tool use in agentic systems","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"AUTHOR"},{"name":"SCHICK ET AL.","type":"AUTHOR","description":"Schick et al. are authors who have contributed to the research on tool use in agentic systems","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"AUTHOR"},{"name":"MADAAN ET AL.","type":"AUTHOR","description":"Madaan et al. are authors who have contributed to the research on self-reflection in agentic systems","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"AUTHOR"},{"name":"SHINN ET AL.","type":"AUTHOR","description":"Shinn et al. are authors who have contributed to the research on self-reflection in agentic systems","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"AUTHOR"},{"name":"CLUNE (2019)","type":"AUTHOR","description":"Clune (2019) is an author who has contributed to the research on the history of machine learning and the replacement of hand-designed solutions with learned solutions","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"AUTHOR"},{"name":"DALAL & TRIGGS (2005)","type":"AUTHOR","description":"Dalal & Triggs (2005) are authors who have contributed to the research on hand-designed features in computer vision","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"AUTHOR"},{"name":"KRIZHEVSKY ET AL. (2012)","type":"AUTHOR","description":"Krizhevsky et al. (2012) are authors who have contributed to the research on Convolutional Neural Networks","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"AUTHOR"},{"name":"HUTTER ET AL. (2019)","type":"AUTHOR","description":"Hutter et al. (2019) are authors who have contributed to the research on AutoML methods","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"AUTHOR"},{"name":"ELSKEN","type":"AUTHOR","description":"Elsken is an author who has contributed to the research on Neural Architecture Search","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"AUTHOR"},{"name":"MEMORY STRUCTURES","type":"","description":"\nMemory structures are components in agentic systems that store information for future use, aiding in reasoning and planning","source_id":"c3d0436082aada237ee4bee645f16059","entity_type":"CONCEPT"},{"name":"TOOL USE","type":"","description":"","source_id":"c3d0436082aada237ee4bee645f16059"},{"name":"TASK","type":"CONCEPT","description":"A task is an activity or assignment that agents are designed to perform or solve","source_id":"c3d0436082aada237ee4bee645f16059"},{"name":"AGENT","type":"CONCEPT","description":"An agent is a system or entity designed to perform tasks, often using reasoning and planning","source_id":"c3d0436082aada237ee4bee645f16059"},{"name":"BUILDING BLOCKS","type":"CONCEPT","description":"Building blocks are fundamental components used to construct agentic systems, such as chain-of-thought, self-reflection, and tool use","source_id":"c3d0436082aada237ee4bee645f16059"},{"name":"COMPOUND AGENTIC SYSTEM","type":"CONCEPT","description":"A compound agentic system is an agentic system composed of multiple components or building blocks to solve complex tasks","source_id":"c3d0436082aada237ee4bee645f16059"},{"name":"MONOLITHIC MODEL QUERY","type":"CONCEPT","description":"A monolithic model query is a single, standalone model used to solve a task, as opposed to a compound agentic system","source_id":"c3d0436082aada237ee4bee645f16059"},{"name":"EXTERNAL TOOLS","type":"CONCEPT","description":"External tools are resources or utilities that agents can access to perform tasks, such as search engines, code execution, and database queries","source_id":"c3d0436082aada237ee4bee645f16059"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"SHENGRAN HU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shengran Hu is a researcher involved in the study of Automated Design of Agentic Systems and is affiliated with the University of British Columbia and the Vector Institute<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>    <\/node>    <node id=\"CONG LU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Cong Lu is a researcher involved in the study of Automated Design of Agentic Systems and is affiliated with the University of British Columbia and the Vector Institute<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>    <\/node>    <node id=\"JEFF CLUNE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jeff Clune is a researcher involved in the study of Automated Design of Agentic Systems and is affiliated with the University of British Columbia, the Vector Institute, and holds a Canada CIFAR AI Chair<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>    <\/node>    <node id=\"UNIVERSITY OF BRITISH COLUMBIA\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">The University of British Columbia is an educational institution where some of the researchers involved in the study of Automated Design of Agentic Systems are affiliated<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>    <\/node>    <node id=\"VECTOR INSTITUTE\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">The Vector Institute is a research institution where some of the researchers involved in the study of Automated Design of Agentic Systems are affiliated<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>    <\/node>    <node id=\"CANADA CIFAR AI CHAIR\">      <data key=\"d0\">TITLE<\/data>      <data key=\"d1\">The Canada CIFAR AI Chair is a title held by Jeff Clune, one of the researchers involved in the study of Automated Design of Agentic Systems<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>    <\/node>    <node id=\"AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)\">      <data key=\"d0\">RESEARCH AREA<\/data>      <data key=\"d1\">Automated Design of Agentic Systems (ADAS) is a research area focused on automatically creating powerful agentic system designs, including inventing novel building blocks and\/or combining them in new ways<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>    <\/node>    <node id=\"META AGENT SEARCH\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">Meta Agent Search is an algorithm that iteratively programs new agents, tests their performance on tasks, and adds them to an archive of discovered agents to inform subsequent iterations<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>    <\/node>    <node id=\"FOUNDATION MODELS (FMS)\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Foundation Models (FMs) are used as modules within agentic systems for tasks that need flexible reasoning and planning<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>    <\/node>    <node id=\"GPT\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT is a Foundation Model developed by OpenAI, used for general-purpose agentic tasks<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>    <\/node>    <node id=\"CLAUDE\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Claude is a Foundation Model developed by Anthropic, used for general-purpose agentic tasks<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>    <\/node>    <node id=\"CHAIN-OF-THOUGHT\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Chain-of-Thought is a planning and reasoning technique used as a building block in agentic systems<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>    <\/node>    <node id=\"SELF-REFLECTION\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Self-Reflection is a technique used in agentic systems to improve performance by reflecting on past actions<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>    <\/node>    <node id=\"TOOLFORMER\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Toolformer is a technique used in agentic systems to enable the use of external tools<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>    <\/node>    <node id=\"META AGENT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">A meta agent is an agent that programs other agents, tests their performance, and iteratively improves them<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"AGENT ARCHIVE\">      <data key=\"d0\">REPOSITORY<\/data>      <data key=\"d1\">Agent Archive is a repository where discovered agents are stored and used to inform the meta agent in subsequent iterations<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"MULTI-STEP PEER REVIEW AGENT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Multi-Step Peer Review Agent is an example of an agent discovered by the Meta Agent Search algorithm<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"VERIFIED MULTIMODAL AGENT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Verified Multimodal Agent is an example of an agent discovered by the Meta Agent Search algorithm<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"DIVIDE AND CONQUER AGENT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Divide and Conquer Agent is an example of an agent discovered by the Meta Agent Search algorithm<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"HOG\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">HOG (Histogram of Oriented Gradients) is a hand-designed feature used in computer vision that was eventually replaced by learned features from Convolutional Neural Networks<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">TECHNIQUE<\/data>    <\/node>    <node id=\"CONVOLUTIONAL NEURAL NETWORKS (CNNS)\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Convolutional Neural Networks (CNNs) are a type of neural network used in computer vision that replaced hand-designed features like HOG<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"NEURAL ARCHITECTURE SEARCH\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Neural Architecture Search is a method used to automatically design neural network architectures, leading to the best-performing CNN models<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">TECHNIQUE<\/data>    <\/node>    <node id=\"AUTOML\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">AutoML (Automated Machine Learning) is a method that automates the process of applying machine learning to real-world problems<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">TECHNIQUE<\/data>    <\/node>    <node id=\"AI-GENERATING ALGORITHMS (AI-GAS)\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">AI-Generating Algorithms (AI-GAs) are methods that automatically generate AI systems, demonstrating the superiority of learned AI systems over hand-designed ones<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">TECHNIQUE<\/data>    <\/node>    <node id=\"SHENGRAN HU'S GITHUB\">      <data key=\"d0\">RESOURCE<\/data>      <data key=\"d1\">Shengran Hu's GitHub is a resource where the code related to the Automated Design of Agentic Systems can be found<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">RESOURCE<\/data>    <\/node>    <node id=\"ARXIV\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">arXiv is a repository where the paper on Automated Design of Agentic Systems is published<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"OPENAI\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">OpenAI is the organization that developed the GPT Foundation Model<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"ANTHROPIC\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Anthropic is the organization that developed the Claude Foundation Model<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"WANG ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Wang et al. are authors who have contributed to the research on Foundation Models and agentic systems<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"ROCKT&#196;SCHEL\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Rockt&#228;schel is an author who has contributed to the research on compound agentic systems<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"ZAHARIA ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Zaharia et al. are authors who have contributed to the research on compound agentic systems<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"HU &amp; CLUNE\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Hu &amp; Clune are authors who have contributed to the research on chain-of-thought planning and reasoning<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"WEI ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Wei et al. are authors who have contributed to the research on chain-of-thought planning and reasoning<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"YAO ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Yao et al. are authors who have contributed to the research on chain-of-thought planning and reasoning<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"LEWIS ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Lewis et al. are authors who have contributed to the research on memory structures in agentic systems<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"ZHANG ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Zhang et al. are authors who have contributed to the research on memory structures in agentic systems<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"QU ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Qu et al. are authors who have contributed to the research on tool use in agentic systems<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"SCHICK ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Schick et al. are authors who have contributed to the research on tool use in agentic systems<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"MADAAN ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Madaan et al. are authors who have contributed to the research on self-reflection in agentic systems<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"SHINN ET AL.\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Shinn et al. are authors who have contributed to the research on self-reflection in agentic systems<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"CLUNE (2019)\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Clune (2019) is an author who has contributed to the research on the history of machine learning and the replacement of hand-designed solutions with learned solutions<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"DALAL &amp; TRIGGS (2005)\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Dalal &amp; Triggs (2005) are authors who have contributed to the research on hand-designed features in computer vision<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"KRIZHEVSKY ET AL. (2012)\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Krizhevsky et al. (2012) are authors who have contributed to the research on Convolutional Neural Networks<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"HUTTER ET AL. (2019)\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Hutter et al. (2019) are authors who have contributed to the research on AutoML methods<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"ELSKEN\">      <data key=\"d0\">AUTHOR<\/data>      <data key=\"d1\">Elsken is an author who has contributed to the research on Neural Architecture Search<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">AUTHOR<\/data>    <\/node>    <node id=\"MEMORY STRUCTURES\">      <data key=\"d0\" \/>      <data key=\"d1\">Memory structures are components in agentic systems that store information for future use, aiding in reasoning and planning<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"TOOL USE\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>    <\/node>    <node id=\"TASK\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A task is an activity or assignment that agents are designed to perform or solve<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>    <\/node>    <node id=\"AGENT\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">An agent is a system or entity designed to perform tasks, often using reasoning and planning<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>    <\/node>    <node id=\"BUILDING BLOCKS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Building blocks are fundamental components used to construct agentic systems, such as chain-of-thought, self-reflection, and tool use<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>    <\/node>    <node id=\"COMPOUND AGENTIC SYSTEM\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A compound agentic system is an agentic system composed of multiple components or building blocks to solve complex tasks<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>    <\/node>    <node id=\"MONOLITHIC MODEL QUERY\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A monolithic model query is a single, standalone model used to solve a task, as opposed to a compound agentic system<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>    <\/node>    <node id=\"EXTERNAL TOOLS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">External tools are resources or utilities that agents can access to perform tasks, such as search engines, code execution, and database queries<\/data>      <data key=\"d2\">c3d0436082aada237ee4bee645f16059<\/data>    <\/node>    <edge source=\"SHENGRAN HU\" target=\"CONG LU\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Shengran Hu and Cong Lu co-authored the study on Automated Design of Agentic Systems<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"SHENGRAN HU\" target=\"JEFF CLUNE\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Shengran Hu and Jeff Clune co-authored the study on Automated Design of Agentic Systems<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"SHENGRAN HU\" target=\"SHENGRAN HU'S GITHUB\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Shengran Hu's GitHub contains the code related to the research conducted by Shengran Hu<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"CONG LU\" target=\"JEFF CLUNE\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Cong Lu and Jeff Clune co-authored the study on Automated Design of Agentic Systems<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"UNIVERSITY OF BRITISH COLUMBIA\" target=\"VECTOR INSTITUTE\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Researchers from the University of British Columbia and the Vector Institute collaborated on the study of Automated Design of Agentic Systems<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"UNIVERSITY OF BRITISH COLUMBIA\" target=\"CANADA CIFAR AI CHAIR\">      <data key=\"d4\">12.0<\/data>      <data key=\"d5\">Jeff Clune, who holds a Canada CIFAR AI Chair, is affiliated with the University of British Columbia<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"VECTOR INSTITUTE\" target=\"CANADA CIFAR AI CHAIR\">      <data key=\"d4\">12.0<\/data>      <data key=\"d5\">Jeff Clune, who holds a Canada CIFAR AI Chair, is affiliated with the Vector Institute<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)\" target=\"META AGENT SEARCH\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">Meta Agent Search is an algorithm used within the research area of Automated Design of Agentic Systems<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)\" target=\"FOUNDATION MODELS (FMS)\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Foundation Models are used as modules within agentic systems in the research area of Automated Design of Agentic Systems<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)\" target=\"CHAIN-OF-THOUGHT\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Chain-of-Thought is a technique used as a building block in agentic systems within the research area of Automated Design of Agentic Systems<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)\" target=\"SELF-REFLECTION\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Self-Reflection is a technique used as a building block in agentic systems within the research area of Automated Design of Agentic Systems<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)\" target=\"TOOLFORMER\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Toolformer is a technique used as a building block in agentic systems within the research area of Automated Design of Agentic Systems<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)\" target=\"ARXIV\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">The paper on Automated Design of Agentic Systems is published on arXiv<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"AUTOMATED DESIGN OF AGENTIC SYSTEMS (ADAS)\" target=\"CLUNE (2019)\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Clune (2019) contributed to the research on the history of machine learning and the replacement of hand-designed solutions with learned solutions<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"META AGENT\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">Meta Agent is an agent that is programmed and iteratively improved by the Meta Agent Search algorithm<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"AGENT ARCHIVE\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Agent Archive is a repository used by the Meta Agent Search algorithm to store discovered agents<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"MULTI-STEP PEER REVIEW AGENT\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Multi-Step Peer Review Agent is an example of an agent discovered by the Meta Agent Search algorithm<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"VERIFIED MULTIMODAL AGENT\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Verified Multimodal Agent is an example of an agent discovered by the Meta Agent Search algorithm<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"DIVIDE AND CONQUER AGENT\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Divide and Conquer Agent is an example of an agent discovered by the Meta Agent Search algorithm<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"FOUNDATION MODELS (FMS)\" target=\"GPT\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">GPT is an example of a Foundation Model used in agentic systems<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"FOUNDATION MODELS (FMS)\" target=\"CLAUDE\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Claude is an example of a Foundation Model used in agentic systems<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"FOUNDATION MODELS (FMS)\" target=\"WANG ET AL.\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Wang et al. contributed to the research on Foundation Models<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"FOUNDATION MODELS (FMS)\" target=\"ROCKT&#196;SCHEL\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Rockt&#228;schel contributed to the research on compound agentic systems<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"FOUNDATION MODELS (FMS)\" target=\"ZAHARIA ET AL.\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Zaharia et al. contributed to the research on compound agentic systems<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"GPT\" target=\"OPENAI\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">OpenAI is the organization that developed the GPT Foundation Model<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"CLAUDE\" target=\"ANTHROPIC\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Anthropic is the organization that developed the Claude Foundation Model<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT\" target=\"HU &amp; CLUNE\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Hu &amp; Clune contributed to the research on chain-of-thought planning and reasoning<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT\" target=\"WEI ET AL.\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Wei et al. contributed to the research on chain-of-thought planning and reasoning<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT\" target=\"YAO ET AL.\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Yao et al. contributed to the research on chain-of-thought planning and reasoning<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"SELF-REFLECTION\" target=\"MADAAN ET AL.\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Madaan et al. contributed to the research on self-reflection in agentic systems<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"SELF-REFLECTION\" target=\"SHINN ET AL.\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Shinn et al. contributed to the research on self-reflection in agentic systems<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"HOG\" target=\"CONVOLUTIONAL NEURAL NETWORKS (CNNS)\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">HOG features were replaced by learned features from Convolutional Neural Networks<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"HOG\" target=\"DALAL &amp; TRIGGS (2005)\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Dalal &amp; Triggs (2005) contributed to the research on hand-designed features like HOG<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"CONVOLUTIONAL NEURAL NETWORKS (CNNS)\" target=\"NEURAL ARCHITECTURE SEARCH\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Neural Architecture Search is a method that led to the best-performing Convolutional Neural Networks<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"CONVOLUTIONAL NEURAL NETWORKS (CNNS)\" target=\"KRIZHEVSKY ET AL. (2012)\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Krizhevsky et al. (2012) contributed to the research on Convolutional Neural Networks<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"NEURAL ARCHITECTURE SEARCH\" target=\"ELSKEN\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Elsken contributed to the research on Neural Architecture Search<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"AUTOML\" target=\"AI-GENERATING ALGORITHMS (AI-GAS)\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">AutoML and AI-Generating Algorithms are methods that demonstrate the superiority of learned AI systems over hand-designed ones<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"AUTOML\" target=\"HUTTER ET AL. (2019)\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Hutter et al. (2019) contributed to the research on AutoML methods<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"LEWIS ET AL.\" target=\"MEMORY STRUCTURES\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Lewis et al. contributed to the research on memory structures in agentic systems<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"ZHANG ET AL.\" target=\"MEMORY STRUCTURES\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Zhang et al. contributed to the research on memory structures in agentic systems<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"QU ET AL.\" target=\"TOOL USE\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Qu et al. contributed to the research on tool use in agentic systems<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>    <edge source=\"SCHICK ET AL.\" target=\"TOOL USE\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Schick et al. contributed to the research on tool use in agentic systems<\/data>      <data key=\"d6\">c3d0436082aada237ee4bee645f16059<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"81c504ffbcc5ed882e234802135295ba","chunk":" The detailed code of example agents can be found in Appendix F.\nNetworks (CNNs, Krizhevsky et al. (2012)). More recently, AutoML methods (Hutter et al., 2019)\nand AI-Generating Algorithms (AI-GAs, Clune (2019)) have also demonstrated the superiority of\nlearned AI systems compared to hand-designed AI systems. For example, the current best-performing\nCNN models come from Neural Architecture Search (Elsken et al., 2019; Shen et al., 2023) instead\nof manual design; in LLM alignment, learned loss functions (Lu et al., 2024a) outperform most\nhand-designed ones such as DPO (Rafailov et al., 2024); The AI Scientist (Lu et al., 2024b) demon-\nstrates an automated research pipeline, including the development of novel ML algorithms; and\nan endless number of robotics learning environments can be automatically generated in works like\nOMNI-EPIC (Faldor et al., 2024), which demonstrate surprising creativity in generated environments\nand allow more efficient environment creation than the manual approach (see more examples in\nSection 5). Therefore, in this paper, we propose a new research question: Can we automate the design\nof agentic systems rather than relying on manual efforts?\nTo explore the above research question, we formulate a new research area we call Automated\nDesign of AgenticSystems (ADAS), which aims to automatically invent novel building blocks and\ndesign powerful agentic systems (Section 2). We argue that ADAS may prove to be the fastest path to\ndeveloping powerful agents, and show initial evidence that learned agents can greatly outperform\nhand-designed agents. Considering the tremendous number of building blocks yet to be discovered in\nagentic systems (Section 5), it would take a long time for our research community to discover them\nall. Even if we successfully discover most of the useful building blocks, combining them into effective\nagentic systems for massive real-world applications would still be challenging and time-consuming,\ngiven the many different ways the building blocks can combine and interact with each other. In\ncontrast, with ADAS, the building blocks and agents can be learned in an automated fashion. ADAS\n2Automated Design of Agentic Systems\nmay not only potentially save human effort in developing powerful agents but also could be a faster\npath to more effective solutions than manual design.\nAlthough a few existing works can be considered as ADAS methods, most of them focus only on\ndesigning prompts (Fernando et al., 2024; Yang et al., 2024), greatly limiting their ability to invent\nflexible design patterns in agents (Section 5). In this paper, we show that there is an unexplored\nyet promising approach to ADAS where we can define the entire agentic system in code and new\nagents can be automatically discovered by a \u201cmeta\u201d agent programming even better ones in code.\nGiven that most programming languages, such as Python, which we use in this paper, are Turing\nComplete (Boyer & Moore, 1983; Ladha, 2024), searching within a code space theoretically enables a\nADAS algorithm to discover anypossible agentic systems, including all components such as prompts,\ntool use, control flows, and more. Furthermore, with recent FMs being increasingly proficient in\ncoding, we can use FMs as a meta agent to create new agents in code for ADAS, enabling novel agents\nto be programmed in an automated manner.\nFollowing the aforementioned ideas, we present Meta Agent Search in this paper as one of the first\nalgorithms in ADAS that enables complete design in code space (Figure 1). The core concept of Meta\nAgent Search is to instruct a meta agent to iteratively create interestingly new agents, evaluate them,\nadd them to an archive that stores discovered agents, and use this archive to help the meta agent in\nsubsequent iterations create yet more interestingly new agents. Similar to existing open-endedness\nalgorithms that leverage human notions of interestingness (Lu et al., 2024c; Zhang et al., 2024a),\nwe encourage the meta agent to explore interesting (e.g., novel or worthwhile) agents. To validate\nthe proposed approach, we evaluate the proposed Meta Agent Search on: (1) the challenging ARC\nlogic puzzle task (Chollet, 2019) that aims to test the general intelligence of an AI system, (2) four\npopular benchmarks on reading comprehension, math, science questions, and multi-task problem\nsolving, and (3) the transferability of discovered agents to held-out domains and models (Section 4).\nOur experiments show that the discovered agents substantially outperform state-of-the-art hand-\ndesigned baselines. For instance, our agents improve F1 scores on reading comprehension tasks in\nDROP (Dua et al., 2019) by 13.6\/100 and accuracy rates on math tasks in MGSM (Shi et al., 2023) by\n14.4%. Additionally, they improve accuracy over baselines by 25.9%and13.2%on GSM8K (Cobbe\net al., 2021) and GSM-Hard (Gao et al., 2023) math tasks, respectively, after transferring across\ndomains. The promising performance of our algorithm over hand-designed solutions illustrates\nthe potential of ADAS in automating the design of agentic systems. Furthermore, the experiments\ndemonstrate that the discovered agents not only perform well when transferring across similar\ndomains but also exhibit strong performance when transferring across dissimilar domains, such as\nfrom mathematics to reading comprehension. This highlights the robustness and transferability of the\nag","chunk_id":"81c504ffbcc5ed882e234802135295ba","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"APPENDIX F","type":"DOCUMENT SECTION","description":"Appendix F contains the detailed code of example agents","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"CNN","type":"TECHNOLOGY","description":"Convolutional Neural Networks (CNNs) are a type of deep learning model used in various AI applications","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"KRIZHEVSKY ET AL. (2012)","type":"PUBLICATION","description":"A publication by Krizhevsky et al. in 2012 that discusses Convolutional Neural Networks","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"AUTOML","type":"TECHNOLOGY","description":"AutoML methods are automated machine learning techniques that optimize the process of applying machine learning to real-world problems","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"HUTTER ET AL. (2019)","type":"PUBLICATION","description":"A publication by Hutter et al. in 2019 that discusses AutoML methods","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"AI-GENERATING ALGORITHMS (AI-GAS)","type":"TECHNOLOGY","description":"AI-Generating Algorithms are methods that automatically generate AI systems","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"CLUNE (2019)","type":"PUBLICATION","description":"A publication by Clune in 2019 that discusses AI-Generating Algorithms","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"NEURAL ARCHITECTURE SEARCH","type":"TECHNOLOGY","description":"Neural Architecture Search is a method for automating the design of neural network architectures","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"ELSKEN ET AL. (2019)","type":"PUBLICATION","description":"A publication by Elsken et al. in 2019 that discusses Neural Architecture Search","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"SHEN ET AL. (2023)","type":"PUBLICATION","description":"A publication by Shen et al. in 2023 that discusses Neural Architecture Search","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"LLM ALIGNMENT","type":"TECHNOLOGY","description":"LLM alignment refers to aligning large language models to specific tasks or goals","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"LEARNED LOSS FUNCTIONS","type":"TECHNOLOGY","description":"Learned loss functions are loss functions that are optimized through learning rather than manually designed","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"LU ET AL. (2024A)","type":"PUBLICATION","description":"A publication by Lu et al. in 2024 that discusses learned loss functions in LLM alignment","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"DPO","type":"TECHNOLOGY","description":"DPO is a hand-designed loss function used in LLM alignment","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"RAFAILOV ET AL. (2024)","type":"PUBLICATION","description":"A publication by Rafailov et al. in 2024 that discusses DPO","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"AI SCIENTIST","type":"TECHNOLOGY","description":"AI Scientist is an automated research pipeline for developing novel machine learning algorithms","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"LU ET AL. (2024B)","type":"PUBLICATION","description":"A publication by Lu et al. in 2024 that discusses the AI Scientist","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"OMNI-EPIC","type":"TECHNOLOGY","description":"OMNI-EPIC is a system for automatically generating robotics learning environments","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"FALDOR ET AL. (2024)","type":"PUBLICATION","description":"A publication by Faldor et al. in 2024 that discusses OMNI-EPIC","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"ADAS","type":"RESEARCH AREA","description":"Automated Design of Agentic Systems (ADAS) is a research area focused on automating the invention of novel building blocks and designing powerful agentic systems","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"META AGENT SEARCH","type":"ALGORITHM","description":"Meta Agent Search is an algorithm in ADAS that enables the complete design of agentic systems in code space","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"ARC LOGIC PUZZLE TASK","type":"BENCHMARK","description":"The ARC logic puzzle task is a benchmark that tests the general intelligence of an AI system","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"CHOLLET (2019)","type":"PUBLICATION","description":"A publication by Chollet in 2019 that discusses the ARC logic puzzle task","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"DROP","type":"BENCHMARK","description":"DROP is a benchmark for reading comprehension tasks","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"DUA ET AL. (2019)","type":"PUBLICATION","description":"A publication by Dua et al. in 2019 that discusses the DROP benchmark","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"MGSM","type":"BENCHMARK","description":"MGSM is a benchmark for math tasks","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"SHI ET AL. (2023)","type":"PUBLICATION","description":"A publication by Shi et al. in 2023 that discusses the MGSM benchmark","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"GSM8K","type":"BENCHMARK","description":"GSM8K is a benchmark for math tasks","source_id":"81c504ffbcc5ed882e234802135295ba","entity_type":"BENCHMARK"},{"name":"COBBE ET AL. (2021)","type":"PUBLICATION","description":"A publication by Cobbe et al. in 2021 that discusses the GSM8K benchmark","source_id":"81c504ffbcc5ed882e234802135295ba","entity_type":"PUBLICATION"},{"name":"GSM-HARD","type":"BENCHMARK","description":"GSM-Hard is a benchmark for math tasks","source_id":"81c504ffbcc5ed882e234802135295ba","entity_type":"BENCHMARK"},{"name":"GAO ET AL. (2023)","type":"PUBLICATION","description":"A publication by Gao et al. in 2023 that discusses the GSM-Hard benchmark","source_id":"81c504ffbcc5ed882e234802135295ba","entity_type":"PUBLICATION"},{"name":"FERNANDO ET AL. (2024)","type":"PUBLICATION","description":"A publication by Fernando et al. in 2024 that discusses ADAS methods focusing on designing prompts","source_id":"81c504ffbcc5ed882e234802135295ba","entity_type":"PUBLICATION"},{"name":"YANG ET AL. (2024)","type":"PUBLICATION","description":"A publication by Yang et al. in 2024 that discusses ADAS methods focusing on designing prompts","source_id":"81c504ffbcc5ed882e234802135295ba","entity_type":"PUBLICATION"},{"name":"PYTHON","type":"PROGRAMMING LANGUAGE","description":"Python is a Turing Complete programming language used in ADAS research","source_id":"81c504ffbcc5ed882e234802135295ba","entity_type":"PROGRAMMING LANGUAGE"},{"name":"BOYER & MOORE (1983)","type":"PUBLICATION","description":"A publication by Boyer & Moore in 1983 that discusses Turing Completeness","source_id":"81c504ffbcc5ed882e234802135295ba","entity_type":"PUBLICATION"},{"name":"LADHA (2024)","type":"PUBLICATION","description":"A publication by Ladha in 2024 that discusses Turing Completeness","source_id":"81c504ffbcc5ed882e234802135295ba","entity_type":"PUBLICATION"},{"name":"FMS","type":"TECHNOLOGY","description":"Foundation Models (FMs) are large-scale models proficient in coding, used as meta agents in ADAS","source_id":"81c504ffbcc5ed882e234802135295ba","entity_type":"TECHNOLOGY"},{"name":"LU ET AL. (2024C)","type":"PUBLICATION","description":"A publication by Lu et al. in 2024 that discusses open-endedness algorithms leveraging human notions of interestingness","source_id":"81c504ffbcc5ed882e234802135295ba","entity_type":"PUBLICATION"},{"name":"ZHANG ET AL. (2024A)","type":"PUBLICATION","description":"A publication by Zhang et al. in 2024 that discusses open-endedness algorithms leveraging human notions of interestingness","source_id":"81c504ffbcc5ed882e234802135295ba","entity_type":"PUBLICATION"},{"name":"AGENTIC SYSTEMS","type":"TECHNOLOGY","description":"Agentic systems are systems designed to perform tasks autonomously","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"BUILDING BLOCKS","type":"TECHNOLOGY","description":"Building blocks refer to the fundamental components used to construct agentic systems","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"META AGENT","type":"TECHNOLOGY","description":"A meta agent is an agent that creates other agents, often used in the context of ADAS","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"ARC","type":"BENCHMARK","description":"ARC is a benchmark for logic puzzle tasks aimed at testing the general intelligence of AI systems","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"READING COMPREHENSION","type":"BENCHMARK","description":"Reading comprehension benchmarks test the ability of AI systems to understand and interpret text","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"MATH","type":"BENCHMARK","description":"Math benchmarks test the ability of AI systems to solve mathematical problems","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"SCIENCE QUESTIONS","type":"BENCHMARK","description":"Science questions benchmarks test the ability of AI systems to answer questions related to science","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"MULTI-TASK PROBLEM SOLVING","type":"BENCHMARK","description":"Multi-task problem solving benchmarks test the ability of AI systems to solve a variety of tasks","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"TRANSFERABILITY","type":"TECHNOLOGY","description":"Transferability refers to the ability of AI systems to apply learned knowledge to different domains","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"OPEN-ENDEDNESS ALGORITHMS","type":"TECHNOLOGY","description":"Open-endedness algorithms encourage the exploration of novel and interesting solutions","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"INTERESTINGNESS","type":"TECHNOLOGY","description":"Interestingness refers to the quality of being novel or worthwhile, often used in the context of open-endedness algorithms","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"F1 SCORES","type":"METRIC","description":"F1 scores are a measure of a model's accuracy, considering both precision and recall","source_id":"81c504ffbcc5ed882e234802135295ba"},{"name":"ACCURACY RATES","type":"METRIC","description":"Accuracy rates measure the proportion of correct predictions made by a model","source_id":"81c504ffbcc5ed882e234802135295ba"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"APPENDIX F\">      <data key=\"d0\">DOCUMENT SECTION<\/data>      <data key=\"d1\">Appendix F contains the detailed code of example agents<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"CNN\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Convolutional Neural Networks (CNNs) are a type of deep learning model used in various AI applications<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"KRIZHEVSKY ET AL. (2012)\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Krizhevsky et al. in 2012 that discusses Convolutional Neural Networks<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"AUTOML\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">AutoML methods are automated machine learning techniques that optimize the process of applying machine learning to real-world problems<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"HUTTER ET AL. (2019)\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Hutter et al. in 2019 that discusses AutoML methods<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"AI-GENERATING ALGORITHMS (AI-GAS)\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">AI-Generating Algorithms are methods that automatically generate AI systems<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"CLUNE (2019)\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Clune in 2019 that discusses AI-Generating Algorithms<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"NEURAL ARCHITECTURE SEARCH\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Neural Architecture Search is a method for automating the design of neural network architectures<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"ELSKEN ET AL. (2019)\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Elsken et al. in 2019 that discusses Neural Architecture Search<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"SHEN ET AL. (2023)\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Shen et al. in 2023 that discusses Neural Architecture Search<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"LLM ALIGNMENT\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">LLM alignment refers to aligning large language models to specific tasks or goals<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"LEARNED LOSS FUNCTIONS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Learned loss functions are loss functions that are optimized through learning rather than manually designed<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"LU ET AL. (2024A)\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Lu et al. in 2024 that discusses learned loss functions in LLM alignment<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"DPO\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">DPO is a hand-designed loss function used in LLM alignment<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"RAFAILOV ET AL. (2024)\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Rafailov et al. in 2024 that discusses DPO<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"AI SCIENTIST\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">AI Scientist is an automated research pipeline for developing novel machine learning algorithms<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"LU ET AL. (2024B)\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Lu et al. in 2024 that discusses the AI Scientist<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"OMNI-EPIC\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">OMNI-EPIC is a system for automatically generating robotics learning environments<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"FALDOR ET AL. (2024)\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Faldor et al. in 2024 that discusses OMNI-EPIC<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"ADAS\">      <data key=\"d0\">RESEARCH AREA<\/data>      <data key=\"d1\">Automated Design of Agentic Systems (ADAS) is a research area focused on automating the invention of novel building blocks and designing powerful agentic systems<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"META AGENT SEARCH\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">Meta Agent Search is an algorithm in ADAS that enables the complete design of agentic systems in code space<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"ARC LOGIC PUZZLE TASK\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">The ARC logic puzzle task is a benchmark that tests the general intelligence of an AI system<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"CHOLLET (2019)\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Chollet in 2019 that discusses the ARC logic puzzle task<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"DROP\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">DROP is a benchmark for reading comprehension tasks<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"DUA ET AL. (2019)\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Dua et al. in 2019 that discusses the DROP benchmark<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"MGSM\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">MGSM is a benchmark for math tasks<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"SHI ET AL. (2023)\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Shi et al. in 2023 that discusses the MGSM benchmark<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"GSM8K\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">GSM8K is a benchmark for math tasks<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>      <data key=\"d3\">BENCHMARK<\/data>    <\/node>    <node id=\"COBBE ET AL. (2021)\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Cobbe et al. in 2021 that discusses the GSM8K benchmark<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"GSM-HARD\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">GSM-Hard is a benchmark for math tasks<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>      <data key=\"d3\">BENCHMARK<\/data>    <\/node>    <node id=\"GAO ET AL. (2023)\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Gao et al. in 2023 that discusses the GSM-Hard benchmark<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"FERNANDO ET AL. (2024)\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Fernando et al. in 2024 that discusses ADAS methods focusing on designing prompts<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"YANG ET AL. (2024)\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Yang et al. in 2024 that discusses ADAS methods focusing on designing prompts<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"PYTHON\">      <data key=\"d0\">PROGRAMMING LANGUAGE<\/data>      <data key=\"d1\">Python is a Turing Complete programming language used in ADAS research<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>      <data key=\"d3\">PROGRAMMING LANGUAGE<\/data>    <\/node>    <node id=\"BOYER &amp; MOORE (1983)\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Boyer &amp; Moore in 1983 that discusses Turing Completeness<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"LADHA (2024)\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Ladha in 2024 that discusses Turing Completeness<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"FMS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Foundation Models (FMs) are large-scale models proficient in coding, used as meta agents in ADAS<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"LU ET AL. (2024C)\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Lu et al. in 2024 that discusses open-endedness algorithms leveraging human notions of interestingness<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"ZHANG ET AL. (2024A)\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Zhang et al. in 2024 that discusses open-endedness algorithms leveraging human notions of interestingness<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"AGENTIC SYSTEMS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Agentic systems are systems designed to perform tasks autonomously<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"BUILDING BLOCKS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Building blocks refer to the fundamental components used to construct agentic systems<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"META AGENT\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">A meta agent is an agent that creates other agents, often used in the context of ADAS<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"ARC\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">ARC is a benchmark for logic puzzle tasks aimed at testing the general intelligence of AI systems<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"READING COMPREHENSION\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">Reading comprehension benchmarks test the ability of AI systems to understand and interpret text<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"MATH\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">Math benchmarks test the ability of AI systems to solve mathematical problems<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"SCIENCE QUESTIONS\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">Science questions benchmarks test the ability of AI systems to answer questions related to science<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"MULTI-TASK PROBLEM SOLVING\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">Multi-task problem solving benchmarks test the ability of AI systems to solve a variety of tasks<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"TRANSFERABILITY\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Transferability refers to the ability of AI systems to apply learned knowledge to different domains<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"OPEN-ENDEDNESS ALGORITHMS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Open-endedness algorithms encourage the exploration of novel and interesting solutions<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"INTERESTINGNESS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Interestingness refers to the quality of being novel or worthwhile, often used in the context of open-endedness algorithms<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"F1 SCORES\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">F1 scores are a measure of a model's accuracy, considering both precision and recall<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <node id=\"ACCURACY RATES\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Accuracy rates measure the proportion of correct predictions made by a model<\/data>      <data key=\"d2\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/node>    <edge source=\"CNN\" target=\"KRIZHEVSKY ET AL. (2012)\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Krizhevsky et al. (2012) discusses Convolutional Neural Networks<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"AUTOML\" target=\"HUTTER ET AL. (2019)\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Hutter et al. (2019) discusses AutoML methods<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"AI-GENERATING ALGORITHMS (AI-GAS)\" target=\"CLUNE (2019)\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Clune (2019) discusses AI-Generating Algorithms<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"NEURAL ARCHITECTURE SEARCH\" target=\"ELSKEN ET AL. (2019)\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Elsken et al. (2019) discusses Neural Architecture Search<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"NEURAL ARCHITECTURE SEARCH\" target=\"SHEN ET AL. (2023)\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Shen et al. (2023) discusses Neural Architecture Search<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"LEARNED LOSS FUNCTIONS\" target=\"LU ET AL. (2024A)\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Lu et al. (2024a) discusses learned loss functions in LLM alignment<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"DPO\" target=\"RAFAILOV ET AL. (2024)\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Rafailov et al. (2024) discusses DPO<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"AI SCIENTIST\" target=\"LU ET AL. (2024B)\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Lu et al. (2024b) discusses the AI Scientist<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"OMNI-EPIC\" target=\"FALDOR ET AL. (2024)\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Faldor et al. (2024) discusses OMNI-EPIC<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"FERNANDO ET AL. (2024)\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Fernando et al. (2024) discusses ADAS methods focusing on designing prompts<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"YANG ET AL. (2024)\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Yang et al. (2024) discusses ADAS methods focusing on designing prompts<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"ARC LOGIC PUZZLE TASK\" target=\"CHOLLET (2019)\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Chollet (2019) discusses the ARC logic puzzle task<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"CHOLLET (2019)\" target=\"ARC\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Chollet (2019) discusses the ARC logic puzzle task<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"DROP\" target=\"DUA ET AL. (2019)\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Dua et al. (2019) discusses the DROP benchmark<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"DROP\" target=\"READING COMPREHENSION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">DROP is a benchmark for reading comprehension tasks<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"MGSM\" target=\"SHI ET AL. (2023)\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Shi et al. (2023) discusses the MGSM benchmark<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"MGSM\" target=\"MATH\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">MGSM is a benchmark for math tasks<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"GSM8K\" target=\"COBBE ET AL. (2021)\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Cobbe et al. (2021) discusses the GSM8K benchmark<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"GSM8K\" target=\"MATH\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">GSM8K is a benchmark for math tasks<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"GSM-HARD\" target=\"GAO ET AL. (2023)\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Gao et al. (2023) discusses the GSM-Hard benchmark<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"GSM-HARD\" target=\"MATH\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">GSM-Hard is a benchmark for math tasks<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"PYTHON\" target=\"BOYER &amp; MOORE (1983)\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Boyer &amp; Moore (1983) discusses Turing Completeness<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"PYTHON\" target=\"LADHA (2024)\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Ladha (2024) discusses Turing Completeness<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"FMS\" target=\"LU ET AL. (2024C)\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Lu et al. (2024c) discusses open-endedness algorithms leveraging human notions of interestingness<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"FMS\" target=\"ZHANG ET AL. (2024A)\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Zhang et al. (2024a) discusses open-endedness algorithms leveraging human notions of interestingness<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"AGENTIC SYSTEMS\" target=\"BUILDING BLOCKS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Building blocks are fundamental components used to construct agentic systems<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>    <edge source=\"AGENTIC SYSTEMS\" target=\"META AGENT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">A meta agent creates other agents within agentic systems<\/data>      <data key=\"d6\">81c504ffbcc5ed882e234802135295ba<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"4884e8429ca1e567dadf5e22b4b68274","chunk":" et al., 2023) math tasks, respectively, after transferring across\ndomains. The promising performance of our algorithm over hand-designed solutions illustrates\nthe potential of ADAS in automating the design of agentic systems. Furthermore, the experiments\ndemonstrate that the discovered agents not only perform well when transferring across similar\ndomains but also exhibit strong performance when transferring across dissimilar domains, such as\nfrom mathematics to reading comprehension. This highlights the robustness and transferability of the\nagentic systems discovered by Meta Agent Search. In conclusion, our work opens up many exciting\nresearch directions and encourages further studies (Section 6).\n2. New Research Area: Automated Design of Agentic Systems (ADAS)\nAt the time of writing, the community has not reached a consensus on the definitions or terminologies\nof agents. Here, by agents we refer to agentic systems that involve Foundation Models (FMs) as\nmodules in the control flow to solve tasks by planning, using tools, and carrying out multiple, iterative\nsteps of processing (Chase, 2024; Ng, 2024).\nIn this paper, we propose a new research area Automated Design of Agentic Systems (ADAS).\nSimilar to research areas in AI-GAs (Clune, 2019) and AutoML (Hutter et al., 2019), such as Neural\nArchitecture Search (Elsken et al., 2019), we formulate ADAS as an optimization process and identify\nthree key components of ADAS algorithms (Figure 2).\n3Automated Design of Agentic Systems\nSearch Space\nE.g. Agents defined by code\nSearch Algorithm\nE.g. LLM defines agents using code\nEvaluation Function\nE.g. Accuracy on the taskWhere is the capital of CanadaOttawa\n\u2705SampleNew AgentEvaluate the ObjectivesAgent\u2026\u20261 + 1 = ?\nFigure 2|The three key components of Automated Design of Agentic Systems (ADAS). The search\nspace determines which agentic systems can be represented in ADAS. The search algorithm specifies\nhow the ADAS method explores the search space. The evaluation function defines how to evaluate a\ncandidate agent on target objectives such as performance.\nFormulation\nAutomated Design of Agentic Systems (ADAS) involves using a search algorithm to discover\nagentic systems across a search space thatoptimize anevaluation function .\n\u2022Search Space : The search space defines which agentic systems can be represented and thus\ndiscovered in ADAS. For example, works like PromptBreeder (Fernando et al., 2024) mutate only\nthe text prompts of an agent, but their other components, such as control flow, remain the same.\nThus, in these search spaces, agents that have a different control flow than the predefined one can\nnot be represented. Existing works also explore search spaces such as graph structures (Zhuge\net al., 2024) and feed-forward networks (Liu et al., 2023).\n\u2022Search Algorithm : The search algorithm defines how ADAS algorithms explore the search space.\nSince the search space is often very large or even unbounded, the exploration-exploitation trade-\noff (Sutton & Barto, 2018) should be considered. Ideally, the algorithm can both quickly discover\nhigh-performance agentic systems and avoid remaining stuck in a local optimum. Existing ap-\nproachesincludeusingReinforcementLearning(Zhugeetal.,2024)oranFMiterativelygenerating\nnew solutions (Fernando et al., 2024) as search algorithms.\n\u2022Evaluation Function : Depending on the application of the ADAS algorithm, we may consider\ndifferentobjectivestooptimize,suchasperformance,cost,latency,orsafetyofagents. Anevaluation\nfunction defines how to evaluate a candidate agent on those objectives. For example, to assess\nthe agent\u2019s performance on unseen future data, a simple method is to calculate the accuracy rate\non the validation data for a task, which is commonly adopted in existing works (Fernando et al.,\n2024; Zhuge et al., 2024).\nAlthoughmanysearchspacedesignsarepossibleandsomehavealreadybeenexplored(Section5),\nthere is an unexplored yet promising approach where we can define the entire agentic system in\ncode and new agents can be automatically discovered by a meta agent programming even better\nones in code. Searching within a code space theoretically enables the ADAS algorithm to discover\nanypossible building blocks (e.g., prompts, tool use, control flow) and agentic systems that combine\nany of these building blocks in any way. This approach also offers better interpretability for agent\ndesign patterns since the program code is often readable, making debugging easier and enhancing AI\nsafety. Additionally, compared to search spaces using networks (Liu et al., 2023) or graphs (Zhuge\net al., 2024), searching in a code space allows us to more easily build on existing human efforts. For\nexample, it is possible to search within open-source agent frameworks like LangChain (LangChainAI,\n2022) and build upon all existing building blocks (e.g., RAG, search engine tools). Finally, since FMs\n4Automated Design of Agentic Systems\nare proficient in coding, utilizing a code search space allows us to leverage existing expertise from\nFMs during the search process. In contrast, search algorithms in custom search spaces, such as graphs,\nmay be much less efficient due to the absence of these priors. Therefore, we argue that the approach\nof using programming languages as the search space should be studied more in ADAS.\n3. Our Algorithm: Meta Agent Search\nIn this section, we present Meta Agent Search, a simple yet effective algorithm to demonstrate the\napproach of defining and searching for agents","chunk_id":"4884e8429ca1e567dadf5e22b4b68274","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"ADAS","type":"RESEARCH AREA\/ALGORITHM","description":"Automated Design of Agentic Systems (ADAS) is a research area that involves using a search algorithm to discover agentic systems across a search space that optimize an evaluation function","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"META AGENT SEARCH","type":"ALGORITHM","description":"Meta Agent Search is an algorithm that demonstrates the approach of defining and searching for agents in the context of ADAS","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"ALGORITHM"},{"name":"FOUNDATION MODELS (FMS)","type":"TECHNOLOGY","description":"Foundation Models (FMs) are modules used in the control flow of agentic systems to solve tasks by planning, using tools, and carrying out multiple, iterative steps of processing","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"TECHNOLOGY"},{"name":"SEARCH SPACE","type":"COMPONENT","description":"The search space defines which agentic systems can be represented and thus discovered in ADAS","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"COMPONENT"},{"name":"SEARCH ALGORITHM","type":"COMPONENT","description":"The search algorithm defines how ADAS algorithms explore the search space","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"COMPONENT"},{"name":"EVALUATION FUNCTION","type":"COMPONENT","description":"The evaluation function defines how to evaluate a candidate agent on target objectives such as performance","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"COMPONENT"},{"name":"PROMPTBREEDER","type":"TOOL\/ALGORITHM","description":"PromptBreeder is a tool that mutates only the text prompts of an agent, but their other components, such as control flow, remain the same","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"TOOL\/ALGORITHM"},{"name":"LANGCHAIN","type":"FRAMEWORK","description":"LangChain is an open-source agent framework that can be used to build upon existing building blocks like RAG and search engine tools","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"FRAMEWORK"},{"name":"RAG","type":"TOOL\/COMPONENT","description":"RAG is a building block used in agent frameworks like LangChain","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"TOOL\/COMPONENT"},{"name":"CHASE","type":"PERSON","description":"Chase is an author referenced in the context of defining agentic systems involving Foundation Models","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"PERSON"},{"name":"NG","type":"PERSON","description":"Ng is an author referenced in the context of defining agentic systems involving Foundation Models","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"PERSON"},{"name":"CLUNE","type":"PERSON","description":"Clune is an author referenced in the context of research areas in AI-GAs","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"PERSON"},{"name":"HUTTER","type":"PERSON","description":"Hutter is an author referenced in the context of research areas in AutoML","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"PERSON"},{"name":"ELSKEN","type":"PERSON","description":"Elsken is an author referenced in the context of Neural Architecture Search","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"PERSON"},{"name":"FERNANDO","type":"PERSON","description":"Fernando is an author referenced in the context of PromptBreeder and other ADAS-related works","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"PERSON"},{"name":"ZHUGE","type":"PERSON","description":"Zhuge is an author referenced in the context of search spaces such as graph structures and reinforcement learning in ADAS","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"PERSON"},{"name":"LIU","type":"PERSON","description":"Liu is an author referenced in the context of search spaces such as feed-forward networks in ADAS","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"PERSON"},{"name":"SUTTON","type":"PERSON","description":"Sutton is an author referenced in the context of the exploration-exploitation trade-off in search algorithms","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"PERSON"},{"name":"BARTO","type":"PERSON","description":"Barto is an author referenced in the context of the exploration-exploitation trade-off in search algorithms","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"PERSON"},{"name":"META AGENT","type":"TECHNOLOGY","description":"Meta Agent is a concept where a meta agent programs better agents in code, enhancing the ADAS algorithm's ability to discover new agentic systems","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"AI-GAS","type":"RESEARCH AREA","description":"AI-GAs (Artificial Intelligence-Generative Algorithms) is a research area related to ADAS","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"AUTOML","type":"RESEARCH AREA","description":"AutoML (Automated Machine Learning) is a research area related to ADAS","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"NEURAL ARCHITECTURE SEARCH","type":"RESEARCH AREA","description":"Neural Architecture Search is a research area related to ADAS, focusing on optimizing neural network architectures","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"REINFORCEMENT LEARNING","type":"TECHNOLOGY","description":"Reinforcement Learning is a method used in search algorithms to explore the search space in ADAS","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"FEED-FORWARD NETWORKS","type":"TECHNOLOGY","description":"Feed-forward networks are a type of search space explored in ADAS","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"GRAPH STRUCTURES","type":"TECHNOLOGY","description":"Graph structures are a type of search space explored in ADAS","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"EXPLORATION-EXPLOITATION TRADE-OFF","type":"CONCEPT","description":"The exploration-exploitation trade-off is a concept in search algorithms that balances discovering high-performance agentic systems and avoiding local optima","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"ACCURACY RATE","type":"METRIC","description":"Accuracy rate is a metric used in the evaluation function to assess an agent's performance on validation data","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"PERFORMANCE","type":"METRIC","description":"Performance is a metric used in the evaluation function to assess an agent's effectiveness","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"COST","type":"METRIC","description":"Cost is a metric used in the evaluation function to assess the expense of running an agent","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"LATENCY","type":"METRIC","description":"Latency is a metric used in the evaluation function to assess the response time of an agent","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"SAFETY","type":"METRIC","description":"Safety is a metric used in the evaluation function to assess the risk associated with an agent","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"MATHEMATICS","type":"DOMAIN","description":"Mathematics is a domain where agentic systems can be applied and evaluated","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"READING COMPREHENSION","type":"DOMAIN","description":"Reading comprehension is a domain where agentic systems can be applied and evaluated","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"AGENTIC SYSTEMS","type":"TECHNOLOGY","description":"Agentic systems are systems that involve Foundation Models as modules to solve tasks by planning, using tools, and carrying out multiple, iterative steps of processing","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"VALIDATION DATA","type":"DATA","description":"Validation data is used to assess the performance of an agent on unseen future data","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"CONTROL FLOW","type":"COMPONENT","description":"Control flow is a component of agentic systems that dictates the sequence of operations or steps an agent follows","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"TOOL USE","type":"COMPONENT","description":"Tool use is a component of agentic systems that involves using external tools to accomplish tasks","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"TEXT PROMPTS","type":"COMPONENT","description":"Text prompts are components of agentic systems that can be mutated to create new agents","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"PROGRAMMING LANGUAGES","type":"TECHNOLOGY","description":"Programming languages are used as a search space in ADAS to define and discover new agentic systems","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"OPEN-SOURCE AGENT FRAMEWORKS","type":"TECHNOLOGY","description":"Open-source agent frameworks like LangChain are used to build upon existing building blocks in ADAS","source_id":"4884e8429ca1e567dadf5e22b4b68274"},{"name":"AI SAFETY","type":"CONCEPT","description":"AI safety is a concept that involves ensuring the safe operation of AI systems, which can be enhanced by using readable program code in ADAS","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"CONCEPT"},{"name":"DEBUGGING","type":"PROCESS","description":"Debugging is a process that involves identifying and fixing issues in program code, which is made easier by using readable code in ADAS","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"PROCESS"},{"name":"UNSEEN FUTURE DATA","type":"DATA","description":"Unseen future data is data that an agent has not encountered before, used to evaluate its performance","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"DATA"},{"name":"EXISTING HUMAN EFFORTS","type":"CONCEPT","description":"Existing human efforts refer to the prior work and knowledge that can be built upon in ADAS, especially when using programming languages as the search space","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"CONCEPT"},{"name":"EXISTING BUILDING BLOCKS","type":"COMPONENT","description":"Existing building blocks are components like RAG and search engine tools that can be used in open-source agent frameworks in ADAS","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"COMPONENT"},{"name":"SEARCH ENGINE TOOLS","type":"TOOL\/COMPONENT","description":"Search engine tools are components that can be used in open-source agent frameworks like LangChain in ADAS","source_id":"4884e8429ca1e567dadf5e22b4b68274","entity_type":"TOOL\/COMPONENT"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"ADAS\">      <data key=\"d0\">RESEARCH AREA\/ALGORITHM<\/data>      <data key=\"d1\">Automated Design of Agentic Systems (ADAS) is a research area that involves using a search algorithm to discover agentic systems across a search space that optimize an evaluation function<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"META AGENT SEARCH\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">Meta Agent Search is an algorithm that demonstrates the approach of defining and searching for agents in the context of ADAS<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">ALGORITHM<\/data>    <\/node>    <node id=\"FOUNDATION MODELS (FMS)\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Foundation Models (FMs) are modules used in the control flow of agentic systems to solve tasks by planning, using tools, and carrying out multiple, iterative steps of processing<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"SEARCH SPACE\">      <data key=\"d0\">COMPONENT<\/data>      <data key=\"d1\">The search space defines which agentic systems can be represented and thus discovered in ADAS<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">COMPONENT<\/data>    <\/node>    <node id=\"SEARCH ALGORITHM\">      <data key=\"d0\">COMPONENT<\/data>      <data key=\"d1\">The search algorithm defines how ADAS algorithms explore the search space<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">COMPONENT<\/data>    <\/node>    <node id=\"EVALUATION FUNCTION\">      <data key=\"d0\">COMPONENT<\/data>      <data key=\"d1\">The evaluation function defines how to evaluate a candidate agent on target objectives such as performance<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">COMPONENT<\/data>    <\/node>    <node id=\"PROMPTBREEDER\">      <data key=\"d0\">TOOL\/ALGORITHM<\/data>      <data key=\"d1\">PromptBreeder is a tool that mutates only the text prompts of an agent, but their other components, such as control flow, remain the same<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">TOOL\/ALGORITHM<\/data>    <\/node>    <node id=\"LANGCHAIN\">      <data key=\"d0\">FRAMEWORK<\/data>      <data key=\"d1\">LangChain is an open-source agent framework that can be used to build upon existing building blocks like RAG and search engine tools<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">FRAMEWORK<\/data>    <\/node>    <node id=\"RAG\">      <data key=\"d0\">TOOL\/COMPONENT<\/data>      <data key=\"d1\">RAG is a building block used in agent frameworks like LangChain<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">TOOL\/COMPONENT<\/data>    <\/node>    <node id=\"CHASE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chase is an author referenced in the context of defining agentic systems involving Foundation Models<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ng is an author referenced in the context of defining agentic systems involving Foundation Models<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CLUNE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Clune is an author referenced in the context of research areas in AI-GAs<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HUTTER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hutter is an author referenced in the context of research areas in AutoML<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ELSKEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Elsken is an author referenced in the context of Neural Architecture Search<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"FERNANDO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Fernando is an author referenced in the context of PromptBreeder and other ADAS-related works<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHUGE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhuge is an author referenced in the context of search spaces such as graph structures and reinforcement learning in ADAS<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liu is an author referenced in the context of search spaces such as feed-forward networks in ADAS<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SUTTON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sutton is an author referenced in the context of the exploration-exploitation trade-off in search algorithms<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BARTO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Barto is an author referenced in the context of the exploration-exploitation trade-off in search algorithms<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"META AGENT\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Meta Agent is a concept where a meta agent programs better agents in code, enhancing the ADAS algorithm's ability to discover new agentic systems<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"AI-GAS\">      <data key=\"d0\">RESEARCH AREA<\/data>      <data key=\"d1\">AI-GAs (Artificial Intelligence-Generative Algorithms) is a research area related to ADAS<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"AUTOML\">      <data key=\"d0\">RESEARCH AREA<\/data>      <data key=\"d1\">AutoML (Automated Machine Learning) is a research area related to ADAS<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"NEURAL ARCHITECTURE SEARCH\">      <data key=\"d0\">RESEARCH AREA<\/data>      <data key=\"d1\">Neural Architecture Search is a research area related to ADAS, focusing on optimizing neural network architectures<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"REINFORCEMENT LEARNING\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Reinforcement Learning is a method used in search algorithms to explore the search space in ADAS<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"FEED-FORWARD NETWORKS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Feed-forward networks are a type of search space explored in ADAS<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"GRAPH STRUCTURES\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Graph structures are a type of search space explored in ADAS<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"EXPLORATION-EXPLOITATION TRADE-OFF\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">The exploration-exploitation trade-off is a concept in search algorithms that balances discovering high-performance agentic systems and avoiding local optima<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"ACCURACY RATE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Accuracy rate is a metric used in the evaluation function to assess an agent's performance on validation data<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"PERFORMANCE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Performance is a metric used in the evaluation function to assess an agent's effectiveness<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"COST\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Cost is a metric used in the evaluation function to assess the expense of running an agent<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"LATENCY\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Latency is a metric used in the evaluation function to assess the response time of an agent<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"SAFETY\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Safety is a metric used in the evaluation function to assess the risk associated with an agent<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"MATHEMATICS\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">Mathematics is a domain where agentic systems can be applied and evaluated<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"READING COMPREHENSION\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">Reading comprehension is a domain where agentic systems can be applied and evaluated<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"AGENTIC SYSTEMS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Agentic systems are systems that involve Foundation Models as modules to solve tasks by planning, using tools, and carrying out multiple, iterative steps of processing<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"VALIDATION DATA\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Validation data is used to assess the performance of an agent on unseen future data<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"CONTROL FLOW\">      <data key=\"d0\">COMPONENT<\/data>      <data key=\"d1\">Control flow is a component of agentic systems that dictates the sequence of operations or steps an agent follows<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"TOOL USE\">      <data key=\"d0\">COMPONENT<\/data>      <data key=\"d1\">Tool use is a component of agentic systems that involves using external tools to accomplish tasks<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"TEXT PROMPTS\">      <data key=\"d0\">COMPONENT<\/data>      <data key=\"d1\">Text prompts are components of agentic systems that can be mutated to create new agents<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"PROGRAMMING LANGUAGES\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Programming languages are used as a search space in ADAS to define and discover new agentic systems<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"OPEN-SOURCE AGENT FRAMEWORKS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Open-source agent frameworks like LangChain are used to build upon existing building blocks in ADAS<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/node>    <node id=\"AI SAFETY\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">AI safety is a concept that involves ensuring the safe operation of AI systems, which can be enhanced by using readable program code in ADAS<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"DEBUGGING\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Debugging is a process that involves identifying and fixing issues in program code, which is made easier by using readable code in ADAS<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">PROCESS<\/data>    <\/node>    <node id=\"UNSEEN FUTURE DATA\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Unseen future data is data that an agent has not encountered before, used to evaluate its performance<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">DATA<\/data>    <\/node>    <node id=\"EXISTING HUMAN EFFORTS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Existing human efforts refer to the prior work and knowledge that can be built upon in ADAS, especially when using programming languages as the search space<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"EXISTING BUILDING BLOCKS\">      <data key=\"d0\">COMPONENT<\/data>      <data key=\"d1\">Existing building blocks are components like RAG and search engine tools that can be used in open-source agent frameworks in ADAS<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">COMPONENT<\/data>    <\/node>    <node id=\"SEARCH ENGINE TOOLS\">      <data key=\"d0\">TOOL\/COMPONENT<\/data>      <data key=\"d1\">Search engine tools are components that can be used in open-source agent frameworks like LangChain in ADAS<\/data>      <data key=\"d2\">4884e8429ca1e567dadf5e22b4b68274<\/data>      <data key=\"d3\">TOOL\/COMPONENT<\/data>    <\/node>    <edge source=\"ADAS\" target=\"META AGENT SEARCH\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">Meta Agent Search is an algorithm used to demonstrate the approach of defining and searching for agents in ADAS<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"FOUNDATION MODELS (FMS)\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Foundation Models (FMs) are used as modules in the control flow of agentic systems in ADAS<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"SEARCH SPACE\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">The search space is a key component of ADAS that defines which agentic systems can be represented<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"SEARCH ALGORITHM\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">The search algorithm is a key component of ADAS that defines how the search space is explored<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"EVALUATION FUNCTION\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">The evaluation function is a key component of ADAS that defines how to evaluate a candidate agent<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"CLUNE\">      <data key=\"d4\">10.0<\/data>      <data key=\"d5\">Clune is referenced in the context of research areas related to ADAS<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"HUTTER\">      <data key=\"d4\">10.0<\/data>      <data key=\"d5\">Hutter is referenced in the context of research areas related to ADAS<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"ELSKEN\">      <data key=\"d4\">10.0<\/data>      <data key=\"d5\">Elsken is referenced in the context of Neural Architecture Search related to ADAS<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"FERNANDO\">      <data key=\"d4\">10.0<\/data>      <data key=\"d5\">Fernando is referenced in the context of ADAS-related works<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"ZHUGE\">      <data key=\"d4\">10.0<\/data>      <data key=\"d5\">Zhuge is referenced in the context of search spaces and reinforcement learning in ADAS<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"LIU\">      <data key=\"d4\">10.0<\/data>      <data key=\"d5\">Liu is referenced in the context of search spaces such as feed-forward networks in ADAS<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"META AGENT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Meta Agent is a concept where a meta agent programs better agents in code, enhancing the ADAS algorithm's ability to discover new agentic systems<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"AI-GAS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AI-GAs is a research area related to ADAS<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"AUTOML\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AutoML is a research area related to ADAS<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"NEURAL ARCHITECTURE SEARCH\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Neural Architecture Search is a research area related to ADAS<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"MATHEMATICS\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">Mathematics is a domain where agentic systems can be applied and evaluated in ADAS<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"READING COMPREHENSION\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">Reading comprehension is a domain where agentic systems can be applied and evaluated in ADAS<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"AI SAFETY\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AI safety is a concept that involves ensuring the safe operation of AI systems, which can be enhanced by using readable program code in ADAS<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"DEBUGGING\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Debugging is a process that involves identifying and fixing issues in program code, which is made easier by using readable code in ADAS<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"EXISTING HUMAN EFFORTS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Existing human efforts refer to the prior work and knowledge that can be built upon in ADAS, especially when using programming languages as the search space<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"FOUNDATION MODELS (FMS)\" target=\"CHASE\">      <data key=\"d4\">10.0<\/data>      <data key=\"d5\">Chase is referenced in the context of defining agentic systems involving Foundation Models<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"FOUNDATION MODELS (FMS)\" target=\"NG\">      <data key=\"d4\">10.0<\/data>      <data key=\"d5\">Ng is referenced in the context of defining agentic systems involving Foundation Models<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"FOUNDATION MODELS (FMS)\" target=\"AGENTIC SYSTEMS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Agentic systems involve Foundation Models as modules to solve tasks<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"SEARCH SPACE\" target=\"PROMPTBREEDER\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">PromptBreeder mutates only the text prompts of an agent within the search space<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"SEARCH SPACE\" target=\"LANGCHAIN\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">LangChain is an open-source agent framework that can be used within the search space<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"SEARCH SPACE\" target=\"FEED-FORWARD NETWORKS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Feed-forward networks are a type of search space explored in ADAS<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"SEARCH SPACE\" target=\"GRAPH STRUCTURES\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Graph structures are a type of search space explored in ADAS<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"SEARCH SPACE\" target=\"PROGRAMMING LANGUAGES\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Programming languages are used as a search space in ADAS to define and discover new agentic systems<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"SEARCH SPACE\" target=\"OPEN-SOURCE AGENT FRAMEWORKS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Open-source agent frameworks like LangChain are used to build upon existing building blocks in ADAS<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"SEARCH SPACE\" target=\"EXISTING BUILDING BLOCKS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Existing building blocks are components like RAG and search engine tools that can be used in open-source agent frameworks in ADAS<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"SEARCH ALGORITHM\" target=\"SUTTON\">      <data key=\"d4\">10.0<\/data>      <data key=\"d5\">Sutton is referenced in the context of the exploration-exploitation trade-off in search algorithms<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"SEARCH ALGORITHM\" target=\"BARTO\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">Barto is referenced in the context of the exploration-exploitation trade-off in search algorithms<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"SEARCH ALGORITHM\" target=\"REINFORCEMENT LEARNING\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Reinforcement Learning is a method used in search algorithms to explore the search space in ADAS<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"SEARCH ALGORITHM\" target=\"EXPLORATION-EXPLOITATION TRADE-OFF\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">The exploration-exploitation trade-off is a concept in search algorithms that balances discovering high-performance agentic systems and avoiding local optima<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"EVALUATION FUNCTION\" target=\"ACCURACY RATE\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Accuracy rate is a metric used in the evaluation function to assess an agent's performance on validation data<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"EVALUATION FUNCTION\" target=\"PERFORMANCE\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Performance is a metric used in the evaluation function to assess an agent's effectiveness<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"EVALUATION FUNCTION\" target=\"COST\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Cost is a metric used in the evaluation function to assess the expense of running an agent<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"EVALUATION FUNCTION\" target=\"LATENCY\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Latency is a metric used in the evaluation function to assess the response time of an agent<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"EVALUATION FUNCTION\" target=\"SAFETY\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Safety is a metric used in the evaluation function to assess the risk associated with an agent<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"EVALUATION FUNCTION\" target=\"VALIDATION DATA\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Validation data is used to assess the performance of an agent on unseen future data in the evaluation function<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"EVALUATION FUNCTION\" target=\"UNSEEN FUTURE DATA\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Unseen future data is data that an agent has not encountered before, used to evaluate its performance in the evaluation function<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"PROMPTBREEDER\" target=\"FERNANDO\">      <data key=\"d4\">10.0<\/data>      <data key=\"d5\">Fernando is referenced in the context of PromptBreeder<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"LANGCHAIN\" target=\"RAG\">      <data key=\"d4\">12.0<\/data>      <data key=\"d5\">RAG is a building block used in the LangChain framework<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"LANGCHAIN\" target=\"SEARCH ENGINE TOOLS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Search engine tools are components that can be used in open-source agent frameworks like LangChain in ADAS<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"AGENTIC SYSTEMS\" target=\"CONTROL FLOW\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Control flow is a component of agentic systems that dictates the sequence of operations or steps an agent follows<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"AGENTIC SYSTEMS\" target=\"TOOL USE\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Tool use is a component of agentic systems that involves using external tools to accomplish tasks<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>    <edge source=\"AGENTIC SYSTEMS\" target=\"TEXT PROMPTS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Text prompts are components of agentic systems that can be mutated to create new agents<\/data>      <data key=\"d6\">4884e8429ca1e567dadf5e22b4b68274<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"24d7b89ae9522ae60d2317984951355b","chunk":" leverage existing expertise from\nFMs during the search process. In contrast, search algorithms in custom search spaces, such as graphs,\nmay be much less efficient due to the absence of these priors. Therefore, we argue that the approach\nof using programming languages as the search space should be studied more in ADAS.\n3. Our Algorithm: Meta Agent Search\nIn this section, we present Meta Agent Search, a simple yet effective algorithm to demonstrate the\napproach of defining and searching for agents in code. The core idea of Meta Agent Search is to adopt\nFMs as meta agents to iteratively program interestingly new agents based on an ever-growing archive\nof previous discoveries. Although any possible building blocks and agentic systems can theoretically\nbe programmed by the meta agent from scratch, it is inefficient in practice to avoid providing the\nmeta agent any basic functions such as FM query APIs or existing tools. Therefore, in this paper, we\ndefine a simple framework (within 100 lines of code) for the meta agent, providing it with a basic\nset of essential functions like querying FMs or formatting prompts. As a result, the meta agent only\nneeds to program a \u201cforward\u201d function to define a new agentic system, similar to the practice in\nFunSearch (Romera-Paredes et al., 2024). This function takes in the information of the task and\noutputs the agent\u2019s response to the task. Details of the framework codes and examples of the agents\ndefined with this framework can be found in Appendix B.\nAs shown in Figure 1, the core idea of Meta Agent Search is to have a meta agent iteratively\nprogram new agents in code. We show the main prompt for the meta agent to program new agents\nbelow, where variables in the prompts are highlighted. Similar to existing open-endedness algorithms\nthat leverage human notions of interestingness (Lu et al., 2024c; Zhang et al., 2024a), we encourage\nthe meta agent to explore interestingly new (e.g., novel or worthwhile) agents based on an ever-\ngrowing archive of previous discoveries. We also adopt self-reflection (Madaan et al., 2024; Shinn\net al., 2023) iterations in our meta agent, where it performs two iterations of refinement on the\nnovelty and correctness of the proposal and performs up to three refinements when errors occur\nwhile running the code. Full details of the prompt are presented in Appendix A.\nAfter a new agent is generated, we evaluate it using the validation data from the target domain.\nHere, we calculate the performance (e.g., success rate or F1 score) and 95% bootstrap confidence\ninterval as the metrics for the meta agent to maximize. The generated agent is then added to the\narchive with the evaluation metrics, and the iteration continues with the updated archive until the\nmaximum number of iterations is reached.\nMain prompt for the meta agent.\nYou are an expert machine learning researcher testing different agentic systems.\n[BriefDescriptionoftheDomain]\n[FrameworkCode]\n[OutputInstructionsandExamples]\n[DiscoveredAgentArchive] (initializedwithbaselines,updatedateveryiteration)\n# Your task\nYou are deeply familiar with prompting techniques and the agent works from the literature. Your goal is\nto maximize the performance by proposing interestingly new agents ......\nUse the knowledge from the archive and inspiration from academic literature to propose the next\ninteresting agentic system design.\n5Automated Design of Agentic Systems\n4. Experiments\nWe conduct extensive experiments on: (1) the challenging ARC logic puzzle task (Chollet, 2019)\n(Section 4.1), (2) four popular benchmarks assessing the agent\u2019s abilities on reading comprehension,\nmath, science questions, and multi-task problem solving (Section 4.2), (3) the transferability of\nthe discovered agents on ARC to three held-out models, and (4) the transferability of discovered\nagents on Math to four held-out math tasks and three tasks that are beyond math (Section 4.3).\nAcross all experiments, we find that the discovered agents substantially outperform baseline state-\nof-the-art hand-designed agents. Notably, our discovered agents improve over baselines on reading\ncomprehension tasks in DROP (Dua et al., 2019) by 13.6\/100 (F1 score) and on math tasks in\nMGSM (Shi et al., 2023) by 14.4%(accuracy rate). Additionally, our discovered agents improve over\nthe baseline on ARC tasks by 14%(accuracy rate) after transferring from GPT-3.5 to GPT-4, and by\n25.9%and13.2%(accuracy rate) after transferring from MGSM math tasks to held-out math tasks in\nGSM8K (Cobbe et al., 2021) and GSM-Hard (Gao et al., 2023) respectively. All code, prompts, and\nexperiment results are available at https:\/\/github.com\/ShengranHu\/ADAS .\n0 5 10 15 20 25\nIteration468101214Held-out T est Accuracy (%)\nInitially tested generating high-level strategies\nbefore implementing low-level details.An important strategy emerged: using multiple COT s\nto generate possible answers, refining them, and\nfinally ensembling the best answers.Introduced dynamic memory for doing more refinements.Scaled up the previous idea.Best agent: introduced multiple\ncritics for enhanced refinement.Meta-Agent Search on ARC\nChain-of-Thought\nSelf-Refine\nLLM DebateCOT-SC\nQuality-Diversity\nMeta-Agent Search\n(a)\nTask5 COTs\n5 Answers\nHuman -like \nCritic\nFeedbackEfficiency Expert\nReadability Expert\nSimplicity","chunk_id":"24d7b89ae9522ae60d2317984951355b","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"META AGENT SEARCH","type":"ALGORITHM","description":"Meta Agent Search is an algorithm that defines and searches for agents in code by adopting FMs as meta agents to iteratively program new agents based on an ever-growing archive of previous discoveries","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"FM","type":"TECHNOLOGY","description":"FMs (Foundation Models) are used as meta agents in the Meta Agent Search algorithm to program new agents","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"ADAS","type":"FIELD","description":"ADAS (Automated Design of Agentic Systems) is a field of study that involves using programming languages as the search space for designing agentic systems","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"FUNSEARCH","type":"ALGORITHM","description":"FunSearch is an algorithm mentioned as a practice similar to Meta Agent Search, where a \"forward\" function is programmed to define a new agentic system","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"ARC","type":"TASK","description":"ARC (Abstraction and Reasoning Corpus) is a challenging logic puzzle task used in experiments to evaluate the performance of discovered agents","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"DROP","type":"DATASET","description":"DROP (Discrete Reasoning Over Paragraphs) is a dataset used to assess the reading comprehension abilities of agents","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"MGSM","type":"DATASET","description":"MGSM (Math Generalization and Symbolic Manipulation) is a dataset used to evaluate the math abilities of agents","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"GSM8K","type":"DATASET","description":"GSM8K is a dataset used to evaluate the transferability of discovered agents on math tasks","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"GSM-HARD","type":"DATASET","description":"GSM-Hard is a dataset used to evaluate the transferability of discovered agents on more challenging math tasks","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"GPT-3.5","type":"MODEL","description":"GPT-3.5 is a version of OpenAI's language model used as a baseline for transferring discovered agents to GPT-4","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"GPT-4","type":"MODEL","description":"GPT-4 is a version of OpenAI's language model used to evaluate the transferability of discovered agents from GPT-3.5","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"CHAIN-OF-THOUGHT","type":"TECHNIQUE","description":"Chain-of-Thought (COT) is a technique used to generate possible answers, refine them, and ensemble the best answers in the Meta Agent Search algorithm","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"SELF-REFINE","type":"TECHNIQUE","description":"Self-Refine is a technique where the meta agent performs iterations of refinement on the novelty and correctness of the proposal","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"LLM DEBATE","type":"TECHNIQUE","description":"LLM Debate is a technique used in the Meta Agent Search algorithm to enhance refinement through multiple critics","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"QUALITY-DIVERSITY","type":"TECHNIQUE","description":"Quality-Diversity is a technique used in the Meta Agent Search algorithm to explore interestingly new agents based on an ever-growing archive of previous discoveries","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"SHENGRAN HU","type":"PERSON","description":"Shengran Hu is the author of the paper on Automated Design of Agentic Systems and the creator of the Meta Agent Search algorithm","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"GITHUB","type":"PLATFORM","description":"GitHub is the platform where all code, prompts, and experiment results related to the Meta Agent Search algorithm are available","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"ROMERA-PAREDES","type":"PERSON","description":"Romera-Paredes is an author mentioned in relation to the FunSearch algorithm","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"LU","type":"PERSON","description":"Lu is an author mentioned in relation to open-endedness algorithms that leverage human notions of interestingness","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"ZHANG","type":"PERSON","description":"Zhang is an author mentioned in relation to open-endedness algorithms that leverage human notions of interestingness","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"MADAAN","type":"PERSON","description":"Madaan is an author mentioned in relation to self-reflection iterations in the meta agent","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"SHINN","type":"PERSON","description":"Shinn is an author mentioned in relation to self-reflection iterations in the meta agent","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"CHOLLET","type":"PERSON","description":"Chollet is an author mentioned in relation to the ARC logic puzzle task","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"DUA","type":"PERSON","description":"Dua is an author mentioned in relation to the DROP dataset","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"SHI","type":"PERSON","description":"Shi is an author mentioned in relation to the MGSM dataset","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"COBBE","type":"PERSON","description":"Cobbe is an author mentioned in relation to the GSM8K dataset","source_id":"24d7b89ae9522ae60d2317984951355b"},{"name":"GAO","type":"PERSON","description":"Gao is an author mentioned in relation to the GSM-Hard dataset","source_id":"24d7b89ae9522ae60d2317984951355b"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"META AGENT SEARCH\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">Meta Agent Search is an algorithm that defines and searches for agents in code by adopting FMs as meta agents to iteratively program new agents based on an ever-growing archive of previous discoveries<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"FM\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">FMs (Foundation Models) are used as meta agents in the Meta Agent Search algorithm to program new agents<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"ADAS\">      <data key=\"d0\">FIELD<\/data>      <data key=\"d1\">ADAS (Automated Design of Agentic Systems) is a field of study that involves using programming languages as the search space for designing agentic systems<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"FUNSEARCH\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">FunSearch is an algorithm mentioned as a practice similar to Meta Agent Search, where a \"forward\" function is programmed to define a new agentic system<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"ARC\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">ARC (Abstraction and Reasoning Corpus) is a challenging logic puzzle task used in experiments to evaluate the performance of discovered agents<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"DROP\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">DROP (Discrete Reasoning Over Paragraphs) is a dataset used to assess the reading comprehension abilities of agents<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"MGSM\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">MGSM (Math Generalization and Symbolic Manipulation) is a dataset used to evaluate the math abilities of agents<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"GSM8K\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">GSM8K is a dataset used to evaluate the transferability of discovered agents on math tasks<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"GSM-HARD\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">GSM-Hard is a dataset used to evaluate the transferability of discovered agents on more challenging math tasks<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"GPT-3.5\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-3.5 is a version of OpenAI's language model used as a baseline for transferring discovered agents to GPT-4<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4 is a version of OpenAI's language model used to evaluate the transferability of discovered agents from GPT-3.5<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"CHAIN-OF-THOUGHT\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Chain-of-Thought (COT) is a technique used to generate possible answers, refine them, and ensemble the best answers in the Meta Agent Search algorithm<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"SELF-REFINE\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Self-Refine is a technique where the meta agent performs iterations of refinement on the novelty and correctness of the proposal<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"LLM DEBATE\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">LLM Debate is a technique used in the Meta Agent Search algorithm to enhance refinement through multiple critics<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"QUALITY-DIVERSITY\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Quality-Diversity is a technique used in the Meta Agent Search algorithm to explore interestingly new agents based on an ever-growing archive of previous discoveries<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"SHENGRAN HU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shengran Hu is the author of the paper on Automated Design of Agentic Systems and the creator of the Meta Agent Search algorithm<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"GITHUB\">      <data key=\"d0\">PLATFORM<\/data>      <data key=\"d1\">GitHub is the platform where all code, prompts, and experiment results related to the Meta Agent Search algorithm are available<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"ROMERA-PAREDES\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Romera-Paredes is an author mentioned in relation to the FunSearch algorithm<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"LU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lu is an author mentioned in relation to open-endedness algorithms that leverage human notions of interestingness<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhang is an author mentioned in relation to open-endedness algorithms that leverage human notions of interestingness<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"MADAAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Madaan is an author mentioned in relation to self-reflection iterations in the meta agent<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"SHINN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shinn is an author mentioned in relation to self-reflection iterations in the meta agent<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"CHOLLET\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chollet is an author mentioned in relation to the ARC logic puzzle task<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"DUA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dua is an author mentioned in relation to the DROP dataset<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"SHI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shi is an author mentioned in relation to the MGSM dataset<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"COBBE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Cobbe is an author mentioned in relation to the GSM8K dataset<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <node id=\"GAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gao is an author mentioned in relation to the GSM-Hard dataset<\/data>      <data key=\"d2\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/node>    <edge source=\"META AGENT SEARCH\" target=\"FM\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Meta Agent Search uses FMs as meta agents to iteratively program new agents<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"ADAS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Meta Agent Search is an approach studied within the field of ADAS<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"FUNSEARCH\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search uses a similar practice to FunSearch by programming a \"forward\" function to define a new agentic system<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"ARC\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Meta Agent Search is evaluated on the ARC logic puzzle task<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"DROP\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search improves performance on reading comprehension tasks in the DROP dataset<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"MGSM\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search improves performance on math tasks in the MGSM dataset<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"GSM8K\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search improves performance on math tasks in the GSM8K dataset<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"GSM-HARD\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search improves performance on math tasks in the GSM-Hard dataset<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"GPT-3.5\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Meta Agent Search transfers discovered agents from GPT-3.5 to GPT-4<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"GPT-4\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Meta Agent Search transfers discovered agents from GPT-3.5 to GPT-4<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"CHAIN-OF-THOUGHT\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search uses the Chain-of-Thought technique to generate, refine, and ensemble answers<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"SELF-REFINE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search uses the Self-Refine technique to perform iterations of refinement on proposals<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"LLM DEBATE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search uses the LLM Debate technique to enhance refinement through multiple critics<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"QUALITY-DIVERSITY\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search uses the Quality-Diversity technique to explore new agents based on an archive of previous discoveries<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"SHENGRAN HU\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Shengran Hu is the author of the paper on Automated Design of Agentic Systems and the creator of the Meta Agent Search algorithm<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"GITHUB\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">All code, prompts, and experiment results related to Meta Agent Search are available on GitHub<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"LU\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Lu is an author mentioned in relation to open-endedness algorithms that leverage human notions of interestingness, similar to Meta Agent Search<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"ZHANG\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Zhang is an author mentioned in relation to open-endedness algorithms that leverage human notions of interestingness, similar to Meta Agent Search<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"MADAAN\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Madaan is an author mentioned in relation to self-reflection iterations in the meta agent<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"SHINN\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Shinn is an author mentioned in relation to self-reflection iterations in the meta agent<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"FUNSEARCH\" target=\"ROMERA-PAREDES\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Romera-Paredes is an author mentioned in relation to the FunSearch algorithm<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"ARC\" target=\"CHOLLET\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Chollet is an author mentioned in relation to the ARC logic puzzle task<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"DROP\" target=\"DUA\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Dua is an author mentioned in relation to the DROP dataset<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"MGSM\" target=\"SHI\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Shi is an author mentioned in relation to the MGSM dataset<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"GSM8K\" target=\"COBBE\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Cobbe is an author mentioned in relation to the GSM8K dataset<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>    <edge source=\"GSM-HARD\" target=\"GAO\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Gao is an author mentioned in relation to the GSM-Hard dataset<\/data>      <data key=\"d5\">24d7b89ae9522ae60d2317984951355b<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"1a6353c9d196dc2debad7c27c902bcd7","chunk":" refining them, and\nfinally ensembling the best answers.Introduced dynamic memory for doing more refinements.Scaled up the previous idea.Best agent: introduced multiple\ncritics for enhanced refinement.Meta-Agent Search on ARC\nChain-of-Thought\nSelf-Refine\nLLM DebateCOT-SC\nQuality-Diversity\nMeta-Agent Search\n(a)\nTask5 COTs\n5 Answers\nHuman -like \nCritic\nFeedbackEfficiency Expert\nReadability Expert\nSimplicity ExpertExperts\nFeedback\nRefinement\n3 timesAll \nAnswers\nEvaluateTop-3 \nAnswersEnsembleFinal \nAnswer\nStructured Feedback and Ensemble AgentThe Best Discovered Agent on ARC (b)\nFigure 3|The results of Meta Agent Search on the ARC challenge. (a) Meta Agent Search progres-\nsively discovers high-performance agents based on an ever-growing archive of previous discoveries.\nWe report the median accuracy and the 95% bootstrap confidence interval on a held-out test set by\nevaluating agents five times. (b) The visualization of the best agent discovered by Meta Agent Search\non the ARC challenge. Detailed implementation of this agent is available in Appendix C.\n4.1. Case Study: ARC Challenge\nWefirstdemonstratehowMetaAgentSearchdiscoversnovelagenticsystemsandoutperformsexisting\nstate-of-the-art hand-designed agents in the Abstraction and Reasoning Corpus (ARC) challenge (Chol-\nlet, 2019). This challenge aims to evaluate the general intelligence of AI systems through their ability\nto efficiently acquire new skills. Questions in ARC include (1) showing multiple examples of visual\ninput-output grid patterns, (2) the AI system learning the transformation rule of grid patterns from\nexamples, and (3) predicting the output grid pattern given a test input grid pattern. Since each\nquestion in ARC has a unique transformation rule, it requires the AI system to learn efficiently with\n6Automated Design of Agentic Systems\nfew-shot examples, leveraging capabilities in number counting, geometry, and topology.\nSetup. Following common practice (Greenblatt, 2024), we require the agent to write code for the\ntransformation rule instead of answering directly. We provide tool functions in the framework that\nevaluate the generated transformation code. Given the significant challenge that ARC poses to current\nAI systems, we sample our data from questions with grid dimensions \u22645\u00d75in the \u201cPublic Training\nSet (Easy)\u201d. We sample a validation set and a test set with 20 and 60 questions, respectively, for\nsearching and testing. We calculate the validation and test accuracy of an agent by assessing it over\nthe validation and test sets five times to reduce the variance from the stochastic sampling of FMs. We\nevaluate all discovered agents on the held-out test set and report the test accuracy in Figure 3. Meta\nAgent Search runs for 25 iterations and the meta agent uses GPT-4 (OpenAI, 2024), while discovered\nagents and baselines are evaluated using GPT-3.5 (OpenAI, 2022) to reduce compute cost. More\nalgorithmic details and examples of ARC questions can be found in Appendix C.\nBaselines. We compared against five state-of-the-art hand-designed agents: (1) Chain-of-Thought\n(COT) (Wei et al., 2022), which instructs the agent to output the reasoning before answering to\nimprove complex problem-solving through intermediate steps; (2) Self-Consistency with Chain-of-\nThought (COT-SC) (Wang et al., 2023b), which ensembles multiple parallel answers from COT to\nproduce a more accurate answer; (3) Self-Refine (Madaan et al., 2024; Shinn et al., 2023), which\nallows iterative self-reflection to correct mistakes made in previous attempts; (4) LLM-Debate (Du\net al., 2023), which enables different LLMs to debate with each other, leveraging diverse perspectives\nto find better answers; (5) Quality-Diversity, a simplified version of Intelligent Go-Explore (Lu et al.,\n2024c), which produces and ensembles diverse answers to better explore potential solutions. We also\nuse all baselines as initial seeds in the archive for Meta Agent Search. More details about baselines\ncan be found in Appendix E.\nResults and Analysis. As shown in Figure 3a, Meta Agent Search effectively and progressively\ndiscovers agents that perform better than state-of-the-art hand-designed baselines. Important break-\nthroughs are highlighted in the text boxes. As is critical in prior works on open-endedness and AI-GAs\n(Faldor et al., 2024; Lehman & Stanley, 2011; Wang et al., 2019, 2020; Zhang et al., 2024a), Meta\nAgent Search innovates based on a growing archive of previous stepping stones. For example, an\nimportant design pattern emerged in iteration 3 where it uses multiple COTs to generate possible\nanswers, refines them, and finally ensembles the best answers. This became a crucial stepping\nstone that subsequent designs tended to utilize. Additionally, the best-discovered agent is shown\nin Figure 3b, where a complex feedback mechanism is adopted to refine answers more effectively.\nCareful observation of the search progress reveals that this sophisticated feedback mechanism did\nnot appear suddenly. Instead, the ideas of incorporating diverse feedback, evaluating for various\nspecific traits (via experts) such as efficiency and simplicity, and simulating human-like feedback\nemerged in iterations 5, 11, and 12, respectively. The final mechanism is an innovation based on\nthese three stepping stones. This illustrates that even though these stepping stones did not achieve","chunk_id":"1a6353c9d196dc2debad7c27c902bcd7","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"META AGENT SEARCH","type":"PROCESS\/TECHNIQUE","description":"Meta Agent Search is a process that progressively discovers high-performance agents based on an ever-growing archive of previous discoveries","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"ARC CHALLENGE","type":"TASK\/CHALLENGE","description":"The Abstraction and Reasoning Corpus (ARC) challenge aims to evaluate the general intelligence of AI systems through their ability to efficiently acquire new skills","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"GPT-4","type":"MODEL","description":"GPT-4 is a version of OpenAI's language model used by the meta agent in Meta Agent Search","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"GPT-3.5","type":"MODEL","description":"GPT-3.5 is a version of OpenAI's language model used to evaluate discovered agents and baselines in Meta Agent Search","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"CHAIN-OF-THOUGHT (COT)","type":"TECHNIQUE","description":"Chain-of-Thought (COT) instructs the agent to output the reasoning before answering to improve complex problem-solving through intermediate steps","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"SELF-CONSISTENCY WITH CHAIN-OF-THOUGHT (COT-SC)","type":"TECHNIQUE","description":"Self-Consistency with Chain-of-Thought (COT-SC) ensembles multiple parallel answers from COT to produce a more accurate answer","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"SELF-REFINE","type":"TECHNIQUE","description":"Self-Refine allows iterative self-reflection to correct mistakes made in previous attempts","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"LLM-DEBATE","type":"TECHNIQUE","description":"LLM-Debate enables different LLMs to debate with each other, leveraging diverse perspectives to find better answers","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"QUALITY-DIVERSITY","type":"TECHNIQUE","description":"Quality-Diversity is a simplified version of Intelligent Go-Explore, which produces and ensembles diverse answers to better explore potential solutions","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"ABSTRACTION AND REASONING CORPUS (ARC)","type":"DATASET","description":"The dataset used in the ARC challenge, consisting of visual input-output grid patterns","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"GREENBLATT, 2024","type":"REFERENCE","description":"A reference to a common practice in the field, requiring the agent to write code for the transformation rule instead of answering directly","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"WEI ET AL., 2022","type":"REFERENCE","description":"A reference to the authors who introduced the Chain-of-Thought (COT) technique","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"WANG ET AL., 2023B","type":"REFERENCE","description":"A reference to the authors who introduced the Self-Consistency with Chain-of-Thought (COT-SC) technique","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"MADAAN ET AL., 2024","type":"REFERENCE","description":"A reference to the authors who introduced the Self-Refine technique","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"SHINN ET AL., 2023","type":"REFERENCE","description":"A reference to the authors who contributed to the Self-Refine technique","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"DU ET AL., 2023","type":"REFERENCE","description":"A reference to the authors who introduced the LLM-Debate technique","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"LU ET AL., 2024C","type":"REFERENCE","description":"A reference to the authors who introduced the Quality-Diversity technique","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"FALDOR ET AL., 2024","type":"REFERENCE","description":"A reference to prior works on open-endedness and AI-GAs","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"LEHMAN & STANLEY, 2011","type":"REFERENCE","description":"A reference to prior works on open-endedness and AI-GAs","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"WANG ET AL., 2019","type":"REFERENCE","description":"A reference to prior works on open-endedness and AI-GAs","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"WANG ET AL., 2020","type":"REFERENCE","description":"A reference to prior works on open-endedness and AI-GAs","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"ZHANG ET AL., 2024A","type":"REFERENCE","description":"A reference to prior works on open-endedness and AI-GAs","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"APPENDIX C","type":"DOCUMENT SECTION","description":"A section in the document providing detailed implementation of the best agent discovered by Meta Agent Search","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"APPENDIX E","type":"DOCUMENT SECTION","description":"A section in the document providing more details about the baselines used in the study","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"FIGURE 3","type":"VISUALIZATION","description":"A figure in the document showing the results of Meta Agent Search on the ARC challenge","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"PUBLIC TRAINING SET (EASY)","type":"DATASET","description":"A subset of the ARC dataset with grid dimensions \u22645\u00d75 used for training agents","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"VALIDATION SET","type":"DATASET","description":"A set of 20 questions sampled from the ARC dataset used for validating agents","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"TEST SET","type":"DATASET","description":"A set of 60 questions sampled from the ARC dataset used for testing agents","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"DYNAMIC MEMORY","type":"TECHNIQUE","description":"Dynamic memory is introduced for doing more refinements in the Meta Agent Search process","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"MULTIPLE CRITICS","type":"TECHNIQUE","description":"Multiple critics are introduced for enhanced refinement in the best agent discovered by Meta Agent Search","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"META-AGENT","type":"AGENT","description":"The meta-agent in Meta Agent Search uses GPT-4 to discover novel agentic systems","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"CRITIC","type":"AGENT","description":"Critics are used to provide feedback for refining answers in the Meta Agent Search process","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"EFFICIENCY EXPERT","type":"AGENT","description":"An expert that evaluates the efficiency of answers in the Meta Agent Search process","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"READABILITY EXPERT","type":"AGENT","description":"An expert that evaluates the readability of answers in the Meta Agent Search process","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"SIMPLICITY EXPERT","type":"AGENT","description":"An expert that evaluates the simplicity of answers in the Meta Agent Search process","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"FEEDBACK","type":"PROCESS","description":"Feedback is provided by critics and experts to refine answers in the Meta Agent Search process","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"ENSEMBLE","type":"PROCESS","description":"Ensembling is used to combine the best answers in the Meta Agent Search process","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"HUMAN-LIKE FEEDBACK","type":"PROCESS","description":"Human-like feedback is simulated to refine answers in the Meta Agent Search process","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"TRANSFORMATION RULE","type":"CONCEPT","description":"The rule that the AI system learns to transform input grid patterns to output grid patterns in the ARC challenge","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"NUMBER COUNTING","type":"SKILL","description":"A capability required by AI systems to efficiently learn from few-shot examples in the ARC challenge","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"GEOMETRY","type":"SKILL","description":"A capability required by AI systems to efficiently learn from few-shot examples in the ARC challenge","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"TOPOLOGY","type":"SKILL","description":"A capability required by AI systems to efficiently learn from few-shot examples in the ARC challenge","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"TOOL FUNCTIONS","type":"TOOL","description":"Functions provided in the framework to evaluate the generated transformation code in the ARC challenge","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"STOCHASTIC SAMPLING OF FMS","type":"PROCESS","description":"A process used to reduce variance in the validation and test accuracy of agents in the ARC challenge","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"ITERATION 3","type":"EVENT","description":"An iteration in Meta Agent Search where multiple COTs are used to generate possible answers, refine them, and ensemble the best answers","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"ITERATION 5","type":"EVENT","description":"An iteration in Meta Agent Search where the idea of incorporating diverse feedback emerged","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"ITERATION 11","type":"EVENT","description":"An iteration in Meta Agent Search where the idea of evaluating for various specific traits via experts emerged","source_id":"1a6353c9d196dc2debad7c27c902bcd7"},{"name":"ITERATION 12","type":"EVENT","description":"An iteration in Meta Agent Search where the idea of simulating human-like feedback emerged","source_id":"1a6353c9d196dc2debad7c27c902bcd7"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"META AGENT SEARCH\">      <data key=\"d0\">PROCESS\/TECHNIQUE<\/data>      <data key=\"d1\">Meta Agent Search is a process that progressively discovers high-performance agents based on an ever-growing archive of previous discoveries<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"ARC CHALLENGE\">      <data key=\"d0\">TASK\/CHALLENGE<\/data>      <data key=\"d1\">The Abstraction and Reasoning Corpus (ARC) challenge aims to evaluate the general intelligence of AI systems through their ability to efficiently acquire new skills<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4 is a version of OpenAI's language model used by the meta agent in Meta Agent Search<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"GPT-3.5\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-3.5 is a version of OpenAI's language model used to evaluate discovered agents and baselines in Meta Agent Search<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"CHAIN-OF-THOUGHT (COT)\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Chain-of-Thought (COT) instructs the agent to output the reasoning before answering to improve complex problem-solving through intermediate steps<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"SELF-CONSISTENCY WITH CHAIN-OF-THOUGHT (COT-SC)\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Self-Consistency with Chain-of-Thought (COT-SC) ensembles multiple parallel answers from COT to produce a more accurate answer<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"SELF-REFINE\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Self-Refine allows iterative self-reflection to correct mistakes made in previous attempts<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"LLM-DEBATE\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">LLM-Debate enables different LLMs to debate with each other, leveraging diverse perspectives to find better answers<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"QUALITY-DIVERSITY\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Quality-Diversity is a simplified version of Intelligent Go-Explore, which produces and ensembles diverse answers to better explore potential solutions<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"ABSTRACTION AND REASONING CORPUS (ARC)\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">The dataset used in the ARC challenge, consisting of visual input-output grid patterns<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"GREENBLATT, 2024\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to a common practice in the field, requiring the agent to write code for the transformation rule instead of answering directly<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"WEI ET AL., 2022\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to the authors who introduced the Chain-of-Thought (COT) technique<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"WANG ET AL., 2023B\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to the authors who introduced the Self-Consistency with Chain-of-Thought (COT-SC) technique<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"MADAAN ET AL., 2024\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to the authors who introduced the Self-Refine technique<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"SHINN ET AL., 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to the authors who contributed to the Self-Refine technique<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"DU ET AL., 2023\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to the authors who introduced the LLM-Debate technique<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"LU ET AL., 2024C\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to the authors who introduced the Quality-Diversity technique<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"FALDOR ET AL., 2024\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to prior works on open-endedness and AI-GAs<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"LEHMAN &amp; STANLEY, 2011\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to prior works on open-endedness and AI-GAs<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"WANG ET AL., 2019\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to prior works on open-endedness and AI-GAs<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"WANG ET AL., 2020\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to prior works on open-endedness and AI-GAs<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"ZHANG ET AL., 2024A\">      <data key=\"d0\">REFERENCE<\/data>      <data key=\"d1\">A reference to prior works on open-endedness and AI-GAs<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"APPENDIX C\">      <data key=\"d0\">DOCUMENT SECTION<\/data>      <data key=\"d1\">A section in the document providing detailed implementation of the best agent discovered by Meta Agent Search<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"APPENDIX E\">      <data key=\"d0\">DOCUMENT SECTION<\/data>      <data key=\"d1\">A section in the document providing more details about the baselines used in the study<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"FIGURE 3\">      <data key=\"d0\">VISUALIZATION<\/data>      <data key=\"d1\">A figure in the document showing the results of Meta Agent Search on the ARC challenge<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"PUBLIC TRAINING SET (EASY)\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A subset of the ARC dataset with grid dimensions &#8804;5&#215;5 used for training agents<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"VALIDATION SET\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A set of 20 questions sampled from the ARC dataset used for validating agents<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"TEST SET\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A set of 60 questions sampled from the ARC dataset used for testing agents<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"DYNAMIC MEMORY\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Dynamic memory is introduced for doing more refinements in the Meta Agent Search process<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"MULTIPLE CRITICS\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Multiple critics are introduced for enhanced refinement in the best agent discovered by Meta Agent Search<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"META-AGENT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">The meta-agent in Meta Agent Search uses GPT-4 to discover novel agentic systems<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"CRITIC\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Critics are used to provide feedback for refining answers in the Meta Agent Search process<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"EFFICIENCY EXPERT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">An expert that evaluates the efficiency of answers in the Meta Agent Search process<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"READABILITY EXPERT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">An expert that evaluates the readability of answers in the Meta Agent Search process<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"SIMPLICITY EXPERT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">An expert that evaluates the simplicity of answers in the Meta Agent Search process<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"FEEDBACK\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Feedback is provided by critics and experts to refine answers in the Meta Agent Search process<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"ENSEMBLE\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Ensembling is used to combine the best answers in the Meta Agent Search process<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"HUMAN-LIKE FEEDBACK\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Human-like feedback is simulated to refine answers in the Meta Agent Search process<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"TRANSFORMATION RULE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">The rule that the AI system learns to transform input grid patterns to output grid patterns in the ARC challenge<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"NUMBER COUNTING\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">A capability required by AI systems to efficiently learn from few-shot examples in the ARC challenge<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"GEOMETRY\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">A capability required by AI systems to efficiently learn from few-shot examples in the ARC challenge<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"TOPOLOGY\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">A capability required by AI systems to efficiently learn from few-shot examples in the ARC challenge<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"TOOL FUNCTIONS\">      <data key=\"d0\">TOOL<\/data>      <data key=\"d1\">Functions provided in the framework to evaluate the generated transformation code in the ARC challenge<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"STOCHASTIC SAMPLING OF FMS\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">A process used to reduce variance in the validation and test accuracy of agents in the ARC challenge<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"ITERATION 3\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">An iteration in Meta Agent Search where multiple COTs are used to generate possible answers, refine them, and ensemble the best answers<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"ITERATION 5\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">An iteration in Meta Agent Search where the idea of incorporating diverse feedback emerged<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"ITERATION 11\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">An iteration in Meta Agent Search where the idea of evaluating for various specific traits via experts emerged<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <node id=\"ITERATION 12\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">An iteration in Meta Agent Search where the idea of simulating human-like feedback emerged<\/data>      <data key=\"d2\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/node>    <edge source=\"META AGENT SEARCH\" target=\"ARC CHALLENGE\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Meta Agent Search is used to discover novel agentic systems that outperform existing state-of-the-art agents in the ARC challenge<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"GPT-4\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Meta Agent Search uses GPT-4 as the meta agent<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"GPT-3.5\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Discovered agents and baselines in Meta Agent Search are evaluated using GPT-3.5<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"CHAIN-OF-THOUGHT (COT)\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search uses Chain-of-Thought (COT) as one of the state-of-the-art hand-designed agents<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"SELF-CONSISTENCY WITH CHAIN-OF-THOUGHT (COT-SC)\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search uses Self-Consistency with Chain-of-Thought (COT-SC) as one of the state-of-the-art hand-designed agents<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"SELF-REFINE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search uses Self-Refine as one of the state-of-the-art hand-designed agents<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"LLM-DEBATE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search uses LLM-Debate as one of the state-of-the-art hand-designed agents<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"QUALITY-DIVERSITY\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search uses Quality-Diversity as one of the state-of-the-art hand-designed agents<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"ABSTRACTION AND REASONING CORPUS (ARC)\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Meta Agent Search is applied to the Abstraction and Reasoning Corpus (ARC) dataset<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"FALDOR ET AL., 2024\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search builds on prior works on open-endedness and AI-GAs by Faldor et al., 2024<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"LEHMAN &amp; STANLEY, 2011\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search builds on prior works on open-endedness and AI-GAs by Lehman &amp; Stanley, 2011<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"WANG ET AL., 2019\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search builds on prior works on open-endedness and AI-GAs by Wang et al., 2019<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"WANG ET AL., 2020\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search builds on prior works on open-endedness and AI-GAs by Wang et al., 2020<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"ZHANG ET AL., 2024A\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search builds on prior works on open-endedness and AI-GAs by Zhang et al., 2024a<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"APPENDIX C\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Appendix C provides detailed implementation of the best agent discovered by Meta Agent Search<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"APPENDIX E\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Appendix E provides more details about the baselines used in Meta Agent Search<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"FIGURE 3\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Figure 3 shows the results of Meta Agent Search on the ARC challenge<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"PUBLIC TRAINING SET (EASY)\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Meta Agent Search uses the Public Training Set (Easy) for training agents<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"VALIDATION SET\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Meta Agent Search uses a validation set of 20 questions for validating agents<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"TEST SET\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Meta Agent Search uses a test set of 60 questions for testing agents<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"DYNAMIC MEMORY\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Dynamic memory is introduced in Meta Agent Search for doing more refinements<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"MULTIPLE CRITICS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Multiple critics are introduced in Meta Agent Search for enhanced refinement<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"META-AGENT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The meta-agent in Meta Agent Search uses GPT-4<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"CRITIC\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Critics provide feedback for refining answers in Meta Agent Search<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"EFFICIENCY EXPERT\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Efficiency experts evaluate the efficiency of answers in Meta Agent Search<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"READABILITY EXPERT\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Readability experts evaluate the readability of answers in Meta Agent Search<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"SIMPLICITY EXPERT\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Simplicity experts evaluate the simplicity of answers in Meta Agent Search<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"FEEDBACK\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Feedback is provided by critics and experts to refine answers in Meta Agent Search<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"ENSEMBLE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Ensembling is used to combine the best answers in Meta Agent Search<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"HUMAN-LIKE FEEDBACK\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Human-like feedback is simulated to refine answers in Meta Agent Search<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"ITERATION 3\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Iteration 3 in Meta Agent Search uses multiple COTs to generate possible answers, refine them, and ensemble the best answers<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"ITERATION 5\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Iteration 5 in Meta Agent Search incorporates diverse feedback<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"ITERATION 11\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Iteration 11 in Meta Agent Search evaluates for various specific traits via experts<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"ITERATION 12\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Iteration 12 in Meta Agent Search simulates human-like feedback<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"ARC CHALLENGE\" target=\"TRANSFORMATION RULE\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The ARC challenge requires AI systems to learn the transformation rule of grid patterns<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"ARC CHALLENGE\" target=\"NUMBER COUNTING\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Number counting is a capability required by AI systems in the ARC challenge<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"ARC CHALLENGE\" target=\"GEOMETRY\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Geometry is a capability required by AI systems in the ARC challenge<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"ARC CHALLENGE\" target=\"TOPOLOGY\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Topology is a capability required by AI systems in the ARC challenge<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"ARC CHALLENGE\" target=\"TOOL FUNCTIONS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Tool functions are provided in the framework to evaluate the generated transformation code in the ARC challenge<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"ARC CHALLENGE\" target=\"STOCHASTIC SAMPLING OF FMS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Stochastic sampling of FMs is used to reduce variance in the validation and test accuracy of agents in the ARC challenge<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT (COT)\" target=\"WEI ET AL., 2022\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Chain-of-Thought (COT) was introduced by Wei et al., 2022<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"SELF-CONSISTENCY WITH CHAIN-OF-THOUGHT (COT-SC)\" target=\"WANG ET AL., 2023B\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Self-Consistency with Chain-of-Thought (COT-SC) was introduced by Wang et al., 2023b<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"SELF-REFINE\" target=\"MADAAN ET AL., 2024\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Self-Refine was introduced by Madaan et al., 2024<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"SELF-REFINE\" target=\"SHINN ET AL., 2023\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Self-Refine was contributed to by Shinn et al., 2023<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"LLM-DEBATE\" target=\"DU ET AL., 2023\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">LLM-Debate was introduced by Du et al., 2023<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>    <edge source=\"QUALITY-DIVERSITY\" target=\"LU ET AL., 2024C\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Quality-Diversity was introduced by Lu et al., 2024c<\/data>      <data key=\"d5\">1a6353c9d196dc2debad7c27c902bcd7<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"bc26e68b0b2783ba912b9e5606d9eb0b","chunk":" is adopted to refine answers more effectively.\nCareful observation of the search progress reveals that this sophisticated feedback mechanism did\nnot appear suddenly. Instead, the ideas of incorporating diverse feedback, evaluating for various\nspecific traits (via experts) such as efficiency and simplicity, and simulating human-like feedback\nemerged in iterations 5, 11, and 12, respectively. The final mechanism is an innovation based on\nthese three stepping stones. This illustrates that even though these stepping stones did not achieve\nhigh performance immediately upon emergence, later discoveries benefited from these innovations\nby combining different stepping stones, resembling crossover in evolution via LLMs (Meyerson et al.,\n2023). Overall, the results showcase the potential of ADAS and the effectiveness of Meta Agent Search\nto progressively discover agents that outperform state-of-the-art hand-designed baselines and invent\nnovel design patterns through the innovation and combination of various stepping stones.\n4.2. Reasoning and Problem-Solving Domains\nSetup. Next,weinvestigatethepotentialofouralgorithmtoimprovethecapabilitiesofagentsacross\nmath, reading, and reasoning domains. We test Meta Agent Search on four popular benchmarks: (1)\nDROP (Dua et al., 2019) for evaluating Reading Comprehension ; (2) MGSM (Shi et al., 2023) for\n7Automated Design of Agentic Systems\nAgent NameF1 Score Accuracy (%)\nReading Comprehension Math Multi-task Science\nState-of-the-art Hand-designed Agents\nChain-of-Thought (Wei et al., 2022) 64.2\u00b10.9 28 .0\u00b13.1 65 .4\u00b13.3 29 .2\u00b13.1\nCOT-SC (Wang et al., 2023b) 64.4\u00b10.8 28 .2\u00b13.165.9\u00b13.230.5\u00b13.2\nSelf-Refine (Madaan et al., 2024) 59.2\u00b10.9 27 .5\u00b13.1 63 .5\u00b13.431.6\u00b13.2\nLLM Debate (Du et al., 2023) 60.6\u00b10.9 39.0\u00b13.465.6\u00b13.3 31 .4\u00b13.2\nStep-back Abstraction (Zheng et al., 2023) 60.4\u00b11.0 31 .1\u00b13.2 65 .1\u00b13.3 26 .9\u00b13.0\nQuality-Diversity (Lu et al., 2024c) 61.8\u00b10.9 23 .8\u00b13.0 65 .1\u00b13.3 30 .2\u00b13.1\nRole Assignment (Xu et al., 2023) 65.8\u00b10.9 30.1\u00b13.2 64 .5\u00b13.3 31 .1\u00b13.1\nAutomated Design of Agentic Systems on Different Domains\nBest Agents from Meta Agent Search 79.4\u00b10.8 53 .4\u00b13.5 69 .6\u00b13.2 34 .6\u00b13.2\nTable 1|Performance comparison between Meta Agent Search and state-of-the-art hand-\ndesigned agents across multiple domains. Meta Agent Search discovers superior agents compared\nto the baselines in every domain. We report the test accuracy and the 95% bootstrap confidence\ninterval on held-out test sets. The search is conducted independently for each domain.\nevaluating Mathcapability under a multi-lingual setting; (3) MMLU (Hendrycks et al., 2021) for\nevaluating Multi-task Problem Solving; and (4) GPQA (Rein et al., 2023) for evaluating the capability\nof solving hard (graduate-level) questions in Science. The search is conducted independently within\neach domain. Meta Agent Search runs for 30 iterations. The meta agent uses GPT-4 (OpenAI, 2024),\nwhile the discovered agents and baselines are evaluated using GPT-3.5 (OpenAI, 2022). More details\nabout datasets and experiment settings can be found in Appendix D.\nBaselines. We adopt all baselines introduced in Section 4.1. Additionally, since the above domains\nrequirestrongreasoningskills,weincludetwoadditionalbaselinesthatspecificallyfocusonenhancing\nthereasoningcapabilitiesofagentsforamorethoroughcomparison: (1)Step-backAbstraction(Zheng\net al., 2023), which instructs agents to first consider the principles involved in solving the task for\nbetter reasoning; (2) Role Assignment, which assigns different roles to FMs similar to Xu et al. (2023)\nto obtain better answers. More details about the baselines can be found in Appendix E.\nResults and Analysis. The results across multiple domains demonstrate that Meta Agent Search\ncan discover agents that outperform state-of-the-art hand-designed agents (Table 1). We want to\nhighlight the substantial gap between the learned agents and hand-designed agents in the Reading\nComprehension and Math domains, with improvements in F1 scores by 13.6\/100 and accuracy rates\nby14.4%, respectively. While Meta Agent Search also outperforms baselines in the Multi-task and\nScience domains, the gap is smaller. We hypothesize that for challenging questions in the Science\nand Multi-task domains, the knowledge in FMs is not sufficient to solve the questions, limiting the\nimprovement through optimizing agentic systems, which is a problem that will diminish as FMs\nimprove. In","chunk_id":"bc26e68b0b2783ba912b9e5606d9eb0b","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"ADAS","type":"TOOL\/PROCESS","description":"ADAS (Automated Design of Agentic Systems) is a process that progressively discovers agents that outperform state-of-the-art hand-designed baselines and invent novel design patterns through the innovation and combination of various stepping stones","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"META AGENT SEARCH","type":"TOOL\/PROCESS","description":"Meta Agent Search is a method used to discover agents that outperform state-of-the-art hand-designed baselines across multiple domains such as reading comprehension, math, multi-task problem solving, and science","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"DROP","type":"BENCHMARK","description":"DROP (Dua et al., 2019) is a benchmark for evaluating reading comprehension","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"MGSM","type":"BENCHMARK","description":"MGSM (Shi et al., 2023) is a benchmark for evaluating math capability under a multi-lingual setting","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"MMLU","type":"BENCHMARK","description":"MMLU (Hendrycks et al., 2021) is a benchmark for evaluating multi-task problem solving","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"GPQA","type":"BENCHMARK","description":"GPQA (Rein et al., 2023) is a benchmark for evaluating the capability of solving hard (graduate-level) questions in science","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"GPT-4","type":"MODEL","description":"GPT-4 (OpenAI, 2024) is a language model used by the meta agent in Meta Agent Search","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"GPT-3.5","type":"MODEL","description":"GPT-3.5 (OpenAI, 2022) is a language model used to evaluate the discovered agents and baselines in Meta Agent Search","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"CHAIN-OF-THOUGHT","type":"AGENT","description":"Chain-of-Thought (Wei et al., 2022) is a state-of-the-art hand-designed agent used as a baseline in Meta Agent Search","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"COT-SC","type":"AGENT","description":"COT-SC (Wang et al., 2023b) is a state-of-the-art hand-designed agent used as a baseline in Meta Agent Search","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"SELF-REFINE","type":"AGENT","description":"Self-Refine (Madaan et al., 2024) is a state-of-the-art hand-designed agent used as a baseline in Meta Agent Search","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"LLM DEBATE","type":"AGENT","description":"LLM Debate (Du et al., 2023) is a state-of-the-art hand-designed agent used as a baseline in Meta Agent Search","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"STEP-BACK ABSTRACTION","type":"AGENT","description":"Step-back Abstraction (Zheng et al., 2023) is a state-of-the-art hand-designed agent used as a baseline in Meta Agent Search","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"QUALITY-DIVERSITY","type":"AGENT","description":"Quality-Diversity (Lu et al., 2024c) is a state-of-the-art hand-designed agent used as a baseline in Meta Agent Search","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"ROLE ASSIGNMENT","type":"AGENT","description":"Role Assignment (Xu et al., 2023) is a state-of-the-art hand-designed agent used as a baseline in Meta Agent Search","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"DUA ET AL.","type":"PERSON","description":"Dua et al. are the authors of the DROP benchmark for evaluating reading comprehension","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"SHI ET AL.","type":"PERSON","description":"Shi et al. are the authors of the MGSM benchmark for evaluating math capability under a multi-lingual setting","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"HENDRYCKS ET AL.","type":"PERSON","description":"Hendrycks et al. are the authors of the MMLU benchmark for evaluating multi-task problem solving","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"REIN ET AL.","type":"PERSON","description":"Rein et al. are the authors of the GPQA benchmark for evaluating the capability of solving hard (graduate-level) questions in science","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"WEI ET AL.","type":"PERSON","description":"Wei et al. are the authors of the Chain-of-Thought agent","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"WANG ET AL.","type":"PERSON","description":"Wang et al. are the authors of the COT-SC agent","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"MADAAN ET AL.","type":"PERSON","description":"Madaan et al. are the authors of the Self-Refine agent","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"DU ET AL.","type":"PERSON","description":"Du et al. are the authors of the LLM Debate agent","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"ZHENG ET AL.","type":"PERSON","description":"Zheng et al. are the authors of the Step-back Abstraction agent","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"LU ET AL.","type":"PERSON","description":"Lu et al. are the authors of the Quality-Diversity agent","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"XU ET AL.","type":"PERSON","description":"Xu et al. are the authors of the Role Assignment agent","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"MECHANISM","type":"TOOL\/PROCESS","description":"A sophisticated feedback mechanism that refines answers more effectively by incorporating diverse feedback, evaluating for various specific traits, and simulating human-like feedback","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"ITERATION 5","type":"EVENT","description":"The iteration where the idea of incorporating diverse feedback emerged","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"ITERATION 11","type":"EVENT","description":"The iteration where the idea of evaluating for various specific traits such as efficiency and simplicity emerged","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"ITERATION 12","type":"EVENT","description":"The iteration where the idea of simulating human-like feedback emerged","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"MEYERSON ET AL.","type":"PERSON","description":"Meyerson et al. are the authors who discussed the concept of crossover in evolution via LLMs","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"AGENT","type":"AGENT","description":"An entity discovered by Meta Agent Search that outperforms state-of-the-art hand-designed baselines","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"EXPERTS","type":"PERSON","description":"Individuals who evaluate various specific traits such as efficiency and simplicity","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"READING COMPREHENSION","type":"DOMAIN","description":"A domain tested by Meta Agent Search using the DROP benchmark","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"MATH","type":"DOMAIN","description":"A domain tested by Meta Agent Search using the MGSM benchmark","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"MULTI-TASK PROBLEM SOLVING","type":"DOMAIN","description":"A domain tested by Meta Agent Search using the MMLU benchmark","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"SCIENCE","type":"DOMAIN","description":"A domain tested by Meta Agent Search using the GPQA benchmark","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"F1 SCORE","type":"METRIC","description":"A performance metric used to evaluate agents in the Reading Comprehension and Math domains","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"ACCURACY","type":"METRIC","description":"A performance metric used to evaluate agents in the Reading Comprehension and Math domains","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"BOOTSTRAP CONFIDENCE INTERVAL","type":"METRIC","description":"A statistical measure reported in the performance comparison of Meta Agent Search and state-of-the-art hand-designed agents","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"EXPERIMENT SETTINGS","type":"TOOL\/PROCESS","description":"Details about the datasets and experiment settings used in Meta Agent Search, found in Appendix D","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"BASELINES","type":"TOOL\/PROCESS","description":"The state-of-the-art hand-designed agents used for comparison in Meta Agent Search","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"APPENDIX D","type":"DOCUMENT","description":"The section of the document where more details about datasets and experiment settings can be found","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"APPENDIX E","type":"DOCUMENT","description":"The section of the document where more details about the baselines can be found","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"},{"name":"FMS","type":"MODEL","description":"Foundation Models used in the Meta Agent Search process","source_id":"bc26e68b0b2783ba912b9e5606d9eb0b"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"ADAS\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">ADAS (Automated Design of Agentic Systems) is a process that progressively discovers agents that outperform state-of-the-art hand-designed baselines and invent novel design patterns through the innovation and combination of various stepping stones<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"META AGENT SEARCH\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">Meta Agent Search is a method used to discover agents that outperform state-of-the-art hand-designed baselines across multiple domains such as reading comprehension, math, multi-task problem solving, and science<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"DROP\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">DROP (Dua et al., 2019) is a benchmark for evaluating reading comprehension<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"MGSM\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">MGSM (Shi et al., 2023) is a benchmark for evaluating math capability under a multi-lingual setting<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"MMLU\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">MMLU (Hendrycks et al., 2021) is a benchmark for evaluating multi-task problem solving<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"GPQA\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">GPQA (Rein et al., 2023) is a benchmark for evaluating the capability of solving hard (graduate-level) questions in science<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4 (OpenAI, 2024) is a language model used by the meta agent in Meta Agent Search<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"GPT-3.5\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-3.5 (OpenAI, 2022) is a language model used to evaluate the discovered agents and baselines in Meta Agent Search<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"CHAIN-OF-THOUGHT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Chain-of-Thought (Wei et al., 2022) is a state-of-the-art hand-designed agent used as a baseline in Meta Agent Search<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"COT-SC\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">COT-SC (Wang et al., 2023b) is a state-of-the-art hand-designed agent used as a baseline in Meta Agent Search<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"SELF-REFINE\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Self-Refine (Madaan et al., 2024) is a state-of-the-art hand-designed agent used as a baseline in Meta Agent Search<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"LLM DEBATE\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">LLM Debate (Du et al., 2023) is a state-of-the-art hand-designed agent used as a baseline in Meta Agent Search<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"STEP-BACK ABSTRACTION\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Step-back Abstraction (Zheng et al., 2023) is a state-of-the-art hand-designed agent used as a baseline in Meta Agent Search<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"QUALITY-DIVERSITY\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Quality-Diversity (Lu et al., 2024c) is a state-of-the-art hand-designed agent used as a baseline in Meta Agent Search<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"ROLE ASSIGNMENT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Role Assignment (Xu et al., 2023) is a state-of-the-art hand-designed agent used as a baseline in Meta Agent Search<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"DUA ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dua et al. are the authors of the DROP benchmark for evaluating reading comprehension<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"SHI ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shi et al. are the authors of the MGSM benchmark for evaluating math capability under a multi-lingual setting<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"HENDRYCKS ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hendrycks et al. are the authors of the MMLU benchmark for evaluating multi-task problem solving<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"REIN ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Rein et al. are the authors of the GPQA benchmark for evaluating the capability of solving hard (graduate-level) questions in science<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"WEI ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wei et al. are the authors of the Chain-of-Thought agent<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"WANG ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wang et al. are the authors of the COT-SC agent<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"MADAAN ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Madaan et al. are the authors of the Self-Refine agent<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"DU ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Du et al. are the authors of the LLM Debate agent<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"ZHENG ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zheng et al. are the authors of the Step-back Abstraction agent<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"LU ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lu et al. are the authors of the Quality-Diversity agent<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"XU ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xu et al. are the authors of the Role Assignment agent<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"MECHANISM\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">A sophisticated feedback mechanism that refines answers more effectively by incorporating diverse feedback, evaluating for various specific traits, and simulating human-like feedback<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"ITERATION 5\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">The iteration where the idea of incorporating diverse feedback emerged<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"ITERATION 11\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">The iteration where the idea of evaluating for various specific traits such as efficiency and simplicity emerged<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"ITERATION 12\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">The iteration where the idea of simulating human-like feedback emerged<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"MEYERSON ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Meyerson et al. are the authors who discussed the concept of crossover in evolution via LLMs<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"AGENT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">An entity discovered by Meta Agent Search that outperforms state-of-the-art hand-designed baselines<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"EXPERTS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Individuals who evaluate various specific traits such as efficiency and simplicity<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"READING COMPREHENSION\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">A domain tested by Meta Agent Search using the DROP benchmark<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"MATH\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">A domain tested by Meta Agent Search using the MGSM benchmark<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"MULTI-TASK PROBLEM SOLVING\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">A domain tested by Meta Agent Search using the MMLU benchmark<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"SCIENCE\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">A domain tested by Meta Agent Search using the GPQA benchmark<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"F1 SCORE\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A performance metric used to evaluate agents in the Reading Comprehension and Math domains<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"ACCURACY\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A performance metric used to evaluate agents in the Reading Comprehension and Math domains<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"BOOTSTRAP CONFIDENCE INTERVAL\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A statistical measure reported in the performance comparison of Meta Agent Search and state-of-the-art hand-designed agents<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"EXPERIMENT SETTINGS\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">Details about the datasets and experiment settings used in Meta Agent Search, found in Appendix D<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"BASELINES\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">The state-of-the-art hand-designed agents used for comparison in Meta Agent Search<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"APPENDIX D\">      <data key=\"d0\">DOCUMENT<\/data>      <data key=\"d1\">The section of the document where more details about datasets and experiment settings can be found<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"APPENDIX E\">      <data key=\"d0\">DOCUMENT<\/data>      <data key=\"d1\">The section of the document where more details about the baselines can be found<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <node id=\"FMS\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Foundation Models used in the Meta Agent Search process<\/data>      <data key=\"d2\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/node>    <edge source=\"ADAS\" target=\"META AGENT SEARCH\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Meta Agent Search is a method used within the ADAS process to discover superior agents<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"MECHANISM\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The sophisticated feedback mechanism is part of the ADAS process<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"MEYERSON ET AL.\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Meyerson et al. discussed the concept of crossover in evolution via LLMs, which is related to ADAS<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"DROP\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Meta Agent Search uses the DROP benchmark to evaluate reading comprehension<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"MGSM\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Meta Agent Search uses the MGSM benchmark to evaluate math capability<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"MMLU\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Meta Agent Search uses the MMLU benchmark to evaluate multi-task problem solving<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"GPQA\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Meta Agent Search uses the GPQA benchmark to evaluate the capability of solving hard science questions<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"GPT-4\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Meta Agent Search uses GPT-4 as the language model for the meta agent<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"GPT-3.5\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Meta Agent Search uses GPT-3.5 to evaluate discovered agents and baselines<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"CHAIN-OF-THOUGHT\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search compares its discovered agents against the Chain-of-Thought baseline<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"COT-SC\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search compares its discovered agents against the COT-SC baseline<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"SELF-REFINE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search compares its discovered agents against the Self-Refine baseline<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"LLM DEBATE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search compares its discovered agents against the LLM Debate baseline<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"STEP-BACK ABSTRACTION\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search compares its discovered agents against the Step-back Abstraction baseline<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"QUALITY-DIVERSITY\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search compares its discovered agents against the Quality-Diversity baseline<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"ROLE ASSIGNMENT\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search compares its discovered agents against the Role Assignment baseline<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"AGENT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Meta Agent Search discovers agents that outperform state-of-the-art hand-designed baselines<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"READING COMPREHENSION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Meta Agent Search tests agents in the Reading Comprehension domain<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"MATH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Meta Agent Search tests agents in the Math domain<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"MULTI-TASK PROBLEM SOLVING\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Meta Agent Search tests agents in the Multi-task Problem Solving domain<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"SCIENCE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Meta Agent Search tests agents in the Science domain<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"F1 SCORE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search reports F1 scores for agents in the Reading Comprehension and Math domains<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"ACCURACY\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search reports accuracy rates for agents in the Reading Comprehension and Math domains<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"BOOTSTRAP CONFIDENCE INTERVAL\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta Agent Search reports the 95% bootstrap confidence interval for performance comparison<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"EXPERIMENT SETTINGS\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Meta Agent Search details about datasets and experiment settings can be found in Appendix D<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"BASELINES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Meta Agent Search compares discovered agents against state-of-the-art hand-designed baselines<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"APPENDIX D\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Appendix D contains more details about datasets and experiment settings used in Meta Agent Search<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"APPENDIX E\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Appendix E contains more details about the baselines used in Meta Agent Search<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"FMS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Meta Agent Search uses Foundation Models in the process<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"DROP\" target=\"DUA ET AL.\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Dua et al. are the authors of the DROP benchmark<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"MGSM\" target=\"SHI ET AL.\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Shi et al. are the authors of the MGSM benchmark<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"MMLU\" target=\"HENDRYCKS ET AL.\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Hendrycks et al. are the authors of the MMLU benchmark<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"GPQA\" target=\"REIN ET AL.\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Rein et al. are the authors of the GPQA benchmark<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT\" target=\"WEI ET AL.\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Wei et al. are the authors of the Chain-of-Thought agent<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"COT-SC\" target=\"WANG ET AL.\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Wang et al. are the authors of the COT-SC agent<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"SELF-REFINE\" target=\"MADAAN ET AL.\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Madaan et al. are the authors of the Self-Refine agent<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"LLM DEBATE\" target=\"DU ET AL.\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Du et al. are the authors of the LLM Debate agent<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"STEP-BACK ABSTRACTION\" target=\"ZHENG ET AL.\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Zheng et al. are the authors of the Step-back Abstraction agent<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"QUALITY-DIVERSITY\" target=\"LU ET AL.\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Lu et al. are the authors of the Quality-Diversity agent<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"ROLE ASSIGNMENT\" target=\"XU ET AL.\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Xu et al. are the authors of the Role Assignment agent<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"MECHANISM\" target=\"ITERATION 5\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The idea of incorporating diverse feedback emerged in Iteration 5<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"MECHANISM\" target=\"ITERATION 11\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The idea of evaluating for various specific traits emerged in Iteration 11<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"MECHANISM\" target=\"ITERATION 12\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The idea of simulating human-like feedback emerged in Iteration 12<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"MECHANISM\" target=\"EXPERTS\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Experts evaluate various specific traits such as efficiency and simplicity<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"READING COMPREHENSION\" target=\"F1 SCORE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">F1 scores are used to evaluate agents in the Reading Comprehension domain<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"READING COMPREHENSION\" target=\"ACCURACY\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Accuracy rates are used to evaluate agents in the Reading Comprehension domain<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"MATH\" target=\"F1 SCORE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">F1 scores are used to evaluate agents in the Math domain<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>    <edge source=\"MATH\" target=\"ACCURACY\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Accuracy rates are used to evaluate agents in the Math domain<\/data>      <data key=\"d5\">bc26e68b0b2783ba912b9e5606d9eb0b<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"2901d5e2711fa4f32d39cd8eea36cd71","chunk":"1 scores by 13.6\/100 and accuracy rates\nby14.4%, respectively. While Meta Agent Search also outperforms baselines in the Multi-task and\nScience domains, the gap is smaller. We hypothesize that for challenging questions in the Science\nand Multi-task domains, the knowledge in FMs is not sufficient to solve the questions, limiting the\nimprovement through optimizing agentic systems, which is a problem that will diminish as FMs\nimprove. In contrast, in the Reading Comprehension and Math domains, FMs possess adequate\nknowledge to solve the questions, and errors could mainly be hallucinations or calculation mistakes,\nwhich can be mitigated through well-designed agentic systems, like the ones discovered by Meta\nAgent Search. Overall, the results across various domains showcase the effectiveness of Meta Agent\nSearch in searching for agents tailored to specific domains. This could be increasingly useful for\nsaving human efforts and developing better task-specific agents as we continue to create agents for a\ndiverse set of applications (Wang et al., 2024).\n8Automated Design of Agentic Systems\n4.3. Generalization and transferability\nAgent NameAccuracy on ARC (%)\nGPT-3.5 Claude-Haiku GPT-4 Claude-Sonnet\nManually Designed Agents\nChain-of-Thought (Wei et al., 2022) 6.0\u00b12.7 4.3\u00b12.2 17 .7\u00b14.4 25 .3\u00b15.0\nCOT-SC (Wang et al., 2023b) 8.0\u00b13.2 5.3\u00b12.5 19 .7\u00b14.5 26 .3\u00b14.9\nLLM Debate (Du et al., 2023) 4.0\u00b12.2 1.7\u00b11.5 19 .0\u00b14.5 24 .7\u00b14.8\nSelf-Refine (Madaan et al., 2024) 6.7\u00b12.7 6.3\u00b12.8 23 .0\u00b15.2 39 .3\u00b15.5\nQuality-Diversity (Lu et al., 2024c) 7.0\u00b12.9 3.3\u00b12.2 23.0\u00b14.7 31.7\u00b15.3\nTop Agents Searched with GPT-3.5 Transferred to Other FMs\nStructured Feedback and Ensemble Agent 13.7\u00b13.9 5.0\u00b12.5 30 .0\u00b15.2 38 .7\u00b15.5\nHierarchical Committee Reinforcement Agent 13.3\u00b13.8 8.3\u00b13.2 32 .3\u00b18.9 39 .7\u00b15.5\nDynamic Memory and Refinement Agent\u202012.7\u00b13.9 9.7\u00b13.3 37 .0\u00b15.3 48 .3\u00b15.7\nTable 2|Performance on ARC when transferring top agents from GPT-3.5 to other FMs. Agents\ndiscovered by Meta Agent Search consistently outperform the baselines across different models. We\nreport the test accuracy and the 95% bootstrap confidence interval. The names of top agents are\ngenerated by Meta Agent Search.\u2020We manually changed this name because the original generated\nname was confusing.\nIn the previous sections, we illustrated that Meta Agent Search can find effective agents for\nindividual tasks. In this section, we further demonstrate the transferability and generalizability of the\ndiscovered agents. To show that the invented building blocks and design patterns are generalizable,\nwe conduct experiments on the transferability of the discovered agents.\nTransferability Across Foundation Models. We first transfer discovered agents from GPT-3.5 (Ope-\nnAI, 2022) to other FMs on ARC to test whether agents found when performing Meta Agent Search\nwith one FM generalize to others. We test the top 3 agents with the best test accuracy evaluated with\nGPT-3.5 on ARC and then transfer them to three popular models: Claude-Haiku (Anthropic, 2024a),\nGPT-4 (OpenAI, 2024), and Claude-Sonnet (Anthropic, 2024b). We adopt the same baselines as\nthose used in ARC (Section 4.1) and MGSM (Section 4.2). As shown in Table 2, we observe that the\nsearched agents consistently outperform the hand-designed agents with a substantial gap. Notably,\nwe found that Claude-Sonnet, the most powerful model from Anthropic, performs the best among all\ntested models, enabling our best agent to achieve nearly 50% accuracy on ARC.\nTransferability Across Domains. Next, we transfer the discovered agent from the MGSM (Math)\ndomain to other math domains to test whether the invented agents can generalize across different\ndomains. Similarly, we test the top 3 agents from MGSM and transfer them to (1) four popular math\ndomains: GSM8K (Cobbe et al., 2021), GSM-Hard (Gao et al., 2023), SVAMP (Patel et al., 2021),\nand ASDiv (Miao et al., 2020) and (2) three domains beyond math adopted in Section 4.2. As shown\nin Table 3, we observe a similar superiority in the performance of Meta Agent Search compared to\nbaselines. Notably, our agents improve accuracy by 25.9%and13.2%on GSM8K (Cobbe et al., 202","chunk_id":"2901d5e2711fa4f32d39cd8eea36cd71","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"META AGENT SEARCH","type":"TOOL\/PROCESS","description":"Meta Agent Search is a process used to discover effective agents tailored to specific domains, showcasing its effectiveness across various domains","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"TOOL\/PROCESS"},{"name":"FMS","type":"TECHNOLOGY","description":"Foundation Models (FMs) are large-scale models that possess knowledge to solve questions in various domains","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"TECHNOLOGY"},{"name":"READING COMPREHENSION","type":"DOMAIN","description":"Reading Comprehension is a domain where FMs possess adequate knowledge to solve questions","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"DOMAIN"},{"name":"MATH","type":"DOMAIN","description":"Math is a domain where FMs possess adequate knowledge to solve questions, and errors could mainly be hallucinations or calculation mistakes","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"DOMAIN"},{"name":"SCIENCE","type":"DOMAIN","description":"Science is a domain where the knowledge in FMs is not sufficient to solve challenging questions","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"DOMAIN"},{"name":"MULTI-TASK","type":"DOMAIN","description":"Multi-task is a domain where the knowledge in FMs is not sufficient to solve challenging questions","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"DOMAIN"},{"name":"WANG ET AL., 2024","type":"PUBLICATION","description":"A publication that discusses the effectiveness of Meta Agent Search in various domains","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"PUBLICATION"},{"name":"GPT-3.5","type":"MODEL","description":"GPT-3.5 is a version of OpenAI's language model used to evaluate the performance of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"MODEL"},{"name":"CLAUDE-HAIKU","type":"MODEL","description":"Claude-Haiku is a model from Anthropic used to evaluate the performance of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"MODEL"},{"name":"GPT-4","type":"MODEL","description":"GPT-4 is a version of OpenAI's language model used to evaluate the performance of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"MODEL"},{"name":"CLAUDE-SONNET","type":"MODEL","description":"Claude-Sonnet is a model from Anthropic used to evaluate the performance of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"MODEL"},{"name":"CHAIN-OF-THOUGHT","type":"METHOD","description":"Chain-of-Thought is a manually designed agent method used for comparison in the evaluation of Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"METHOD"},{"name":"COT-SC","type":"METHOD","description":"COT-SC is a manually designed agent method used for comparison in the evaluation of Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"METHOD"},{"name":"LLM DEBATE","type":"METHOD","description":"LLM Debate is a manually designed agent method used for comparison in the evaluation of Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"METHOD"},{"name":"SELF-REFINE","type":"METHOD","description":"Self-Refine is a manually designed agent method used for comparison in the evaluation of Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"METHOD"},{"name":"QUALITY-DIVERSITY","type":"METHOD","description":"Quality-Diversity is a manually designed agent method used for comparison in the evaluation of Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"METHOD"},{"name":"STRUCTURED FEEDBACK AND ENSEMBLE AGENT","type":"AGENT","description":"Structured Feedback and Ensemble Agent is one of the top agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"AGENT"},{"name":"HIERARCHICAL COMMITTEE REINFORCEMENT AGENT","type":"AGENT","description":"Hierarchical Committee Reinforcement Agent is one of the top agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"AGENT"},{"name":"DYNAMIC MEMORY AND REFINEMENT AGENT","type":"AGENT","description":"Dynamic Memory and Refinement Agent is one of the top agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"AGENT"},{"name":"ARC","type":"DATASET","description":"ARC is a dataset used to evaluate the performance of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"DATASET"},{"name":"MGSM","type":"DATASET","description":"MGSM is a math dataset used to evaluate the performance of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"DATASET"},{"name":"GSM8K","type":"DATASET","description":"GSM8K is a math dataset used to evaluate the performance of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"DATASET"},{"name":"GSM-HARD","type":"DATASET","description":"GSM-Hard is a math dataset used to evaluate the performance of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"DATASET"},{"name":"SVAMP","type":"DATASET","description":"SVAMP is a math dataset used to evaluate the performance of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"DATASET"},{"name":"ASDIV","type":"DATASET","description":"ASDiv is a math dataset used to evaluate the performance of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"DATASET"},{"name":"COBBE ET AL., 2021","type":"PUBLICATION","description":"A publication that discusses the GSM8K dataset","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"PUBLICATION"},{"name":"GAO ET AL., 2023","type":"PUBLICATION","description":"A publication that discusses the GSM-Hard dataset","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"PUBLICATION"},{"name":"PATEL ET AL., 2021","type":"PUBLICATION","description":"A publication that discusses the SVAMP dataset","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"PUBLICATION"},{"name":"MIAO ET AL., 2020","type":"PUBLICATION","description":"A publication that discusses the ASDiv dataset","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"PUBLICATION"},{"name":"WEI ET AL., 2022","type":"PUBLICATION","description":"A publication that discusses the Chain-of-Thought method","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"PUBLICATION"},{"name":"WANG ET AL., 2023B","type":"PUBLICATION","description":"A publication that discusses the COT-SC method","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"PUBLICATION"},{"name":"DU ET AL., 2023","type":"PUBLICATION","description":"A publication that discusses the LLM Debate method","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"PUBLICATION"},{"name":"MADAAN ET AL., 2024","type":"PUBLICATION","description":"A publication that discusses the Self-Refine method","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"PUBLICATION"},{"name":"LU ET AL., 2024C","type":"PUBLICATION","description":"A publication that discusses the Quality-Diversity method","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"PUBLICATION"},{"name":"ANTHROPIC","type":"ORGANIZATION","description":"Anthropic is the organization behind the Claude-Haiku and Claude-Sonnet models","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"ORGANIZATION"},{"name":"OPENAI","type":"ORGANIZATION","description":"OpenAI is the organization behind the GPT-3.5 and GPT-4 models","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"ORGANIZATION"},{"name":"MULTI-TASK AND SCIENCE DOMAINS","type":"DOMAIN","description":"Multi-task and Science domains are areas where Meta Agent Search outperforms baselines, but the gap is smaller due to the challenging nature of the questions","source_id":"2901d5e2711fa4f32d39cd8eea36cd71"},{"name":"AGENTIC SYSTEMS","type":"TECHNOLOGY","description":"Agentic systems are systems optimized to improve performance in various domains, particularly effective in mitigating errors like hallucinations or calculation mistakes","source_id":"2901d5e2711fa4f32d39cd8eea36cd71"},{"name":"HUMAN EFFORTS","type":"CONCEPT","description":"Human efforts refer to the manual work that can be saved by using Meta Agent Search to develop better task-specific agents","source_id":"2901d5e2711fa4f32d39cd8eea36cd71"},{"name":"TASK-SPECIFIC AGENTS","type":"AGENT","description":"Task-specific agents are agents tailored to perform specific tasks effectively, discovered through Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71"},{"name":"TRANSFERABILITY","type":"CONCEPT","description":"Transferability refers to the ability of agents discovered by Meta Agent Search to perform well across different models and domains","source_id":"2901d5e2711fa4f32d39cd8eea36cd71"},{"name":"GENERALIZATION","type":"CONCEPT","description":"Generalization refers to the ability of agents discovered by Meta Agent Search to apply learned knowledge to new, unseen tasks or domains","source_id":"2901d5e2711fa4f32d39cd8eea36cd71"},{"name":"BOOTSTRAP CONFIDENCE INTERVAL","type":"METHOD","description":"Bootstrap confidence interval is a statistical method used to report the test accuracy of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71"},{"name":"MGSM (MATH)","type":"DOMAIN","description":"MGSM (Math) is a domain used to test the transferability and generalizability of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71"},{"name":"GSM8K (COBBE ET AL., 2021)","type":"DOMAIN","description":"GSM8K (Cobbe et al., 2021) is a math domain used to test the transferability and generalizability of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71"},{"name":"GSM-HARD (GAO ET AL., 2023)","type":"DOMAIN","description":"GSM-Hard (Gao et al., 2023) is a math domain used to test the transferability and generalizability of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71"},{"name":"SVAMP (PATEL ET AL., 2021)","type":"DOMAIN","description":"SVAMP (Patel et al., 2021) is a math domain used to test the transferability and generalizability of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71"},{"name":"ASDIV (MIAO ET AL., 2020)","type":"DOMAIN","description":"ASDiv (Miao et al., 2020) is a math domain used to test the transferability and generalizability of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71"},{"name":"MGSM (MATH) DOMAIN","type":"DOMAIN","description":"MGSM (Math) domain is used to test the transferability and generalizability of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"DOMAIN"},{"name":"FOUR POPULAR MATH DOMAINS","type":"DOMAIN","description":"Four popular math domains are used to test the transferability and generalizability of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"DOMAIN"},{"name":"DOMAINS BEYOND MATH","type":"DOMAIN","description":"Domains beyond math are used to test the transferability and generalizability of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"DOMAIN"},{"name":"TOP 3 AGENTS","type":"AGENT","description":"Top 3 agents are the best-performing agents discovered by Meta Agent Search, evaluated with GPT-3.5 on ARC and transferred to other models","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"AGENT"},{"name":"INVENTED BUILDING BLOCKS AND DESIGN PATTERNS","type":"CONCEPT","description":"Invented building blocks and design patterns are the components and strategies discovered by Meta Agent Search that contribute to the effectiveness of the agents","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"CONCEPT"},{"name":"PERFORMANCE ON ARC","type":"CONCEPT","description":"Performance on ARC refers to the evaluation results of agents discovered by Meta Agent Search on the ARC dataset","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"CONCEPT"},{"name":"TEST ACCURACY","type":"CONCEPT","description":"Test accuracy is a measure of how well agents discovered by Meta Agent Search perform on specific datasets","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"CONCEPT"},{"name":"95% BOOTSTRAP CONFIDENCE INTERVAL","type":"METHOD","description":"95% bootstrap confidence interval is a statistical method used to report the test accuracy of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"METHOD"},{"name":"CLAUDE-SONNET (ANTHROPIC, 2024B)","type":"MODEL","description":"Claude-Sonnet (Anthropic, 2024b) is a model from Anthropic used to evaluate the performance of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"MODEL"},{"name":"CLAUDE-HAIKU (ANTHROPIC, 2024A)","type":"MODEL","description":"Claude-Haiku (Anthropic, 2024a) is a model from Anthropic used to evaluate the performance of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"MODEL"},{"name":"GPT-4 (OPENAI, 2024)","type":"MODEL","description":"GPT-4 (OpenAI, 2024) is a version of OpenAI's language model used to evaluate the performance of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"MODEL"},{"name":"GPT-3.5 (OPENAI, 2022)","type":"MODEL","description":"GPT-3.5 (OpenAI, 2022) is a version of OpenAI's language model used to evaluate the performance of agents discovered by Meta Agent Search","source_id":"2901d5e2711fa4f32d39cd8eea36cd71","entity_type":"MODEL"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"META AGENT SEARCH\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">Meta Agent Search is a process used to discover effective agents tailored to specific domains, showcasing its effectiveness across various domains<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">TOOL\/PROCESS<\/data>    <\/node>    <node id=\"FMS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Foundation Models (FMs) are large-scale models that possess knowledge to solve questions in various domains<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"READING COMPREHENSION\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">Reading Comprehension is a domain where FMs possess adequate knowledge to solve questions<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">DOMAIN<\/data>    <\/node>    <node id=\"MATH\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">Math is a domain where FMs possess adequate knowledge to solve questions, and errors could mainly be hallucinations or calculation mistakes<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">DOMAIN<\/data>    <\/node>    <node id=\"SCIENCE\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">Science is a domain where the knowledge in FMs is not sufficient to solve challenging questions<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">DOMAIN<\/data>    <\/node>    <node id=\"MULTI-TASK\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">Multi-task is a domain where the knowledge in FMs is not sufficient to solve challenging questions<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">DOMAIN<\/data>    <\/node>    <node id=\"WANG ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication that discusses the effectiveness of Meta Agent Search in various domains<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"GPT-3.5\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-3.5 is a version of OpenAI's language model used to evaluate the performance of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"CLAUDE-HAIKU\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Claude-Haiku is a model from Anthropic used to evaluate the performance of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4 is a version of OpenAI's language model used to evaluate the performance of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"CLAUDE-SONNET\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Claude-Sonnet is a model from Anthropic used to evaluate the performance of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"CHAIN-OF-THOUGHT\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Chain-of-Thought is a manually designed agent method used for comparison in the evaluation of Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">METHOD<\/data>    <\/node>    <node id=\"COT-SC\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">COT-SC is a manually designed agent method used for comparison in the evaluation of Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">METHOD<\/data>    <\/node>    <node id=\"LLM DEBATE\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">LLM Debate is a manually designed agent method used for comparison in the evaluation of Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">METHOD<\/data>    <\/node>    <node id=\"SELF-REFINE\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Self-Refine is a manually designed agent method used for comparison in the evaluation of Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">METHOD<\/data>    <\/node>    <node id=\"QUALITY-DIVERSITY\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Quality-Diversity is a manually designed agent method used for comparison in the evaluation of Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">METHOD<\/data>    <\/node>    <node id=\"STRUCTURED FEEDBACK AND ENSEMBLE AGENT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Structured Feedback and Ensemble Agent is one of the top agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">AGENT<\/data>    <\/node>    <node id=\"HIERARCHICAL COMMITTEE REINFORCEMENT AGENT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Hierarchical Committee Reinforcement Agent is one of the top agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">AGENT<\/data>    <\/node>    <node id=\"DYNAMIC MEMORY AND REFINEMENT AGENT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Dynamic Memory and Refinement Agent is one of the top agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">AGENT<\/data>    <\/node>    <node id=\"ARC\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">ARC is a dataset used to evaluate the performance of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">DATASET<\/data>    <\/node>    <node id=\"MGSM\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">MGSM is a math dataset used to evaluate the performance of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">DATASET<\/data>    <\/node>    <node id=\"GSM8K\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">GSM8K is a math dataset used to evaluate the performance of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">DATASET<\/data>    <\/node>    <node id=\"GSM-HARD\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">GSM-Hard is a math dataset used to evaluate the performance of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">DATASET<\/data>    <\/node>    <node id=\"SVAMP\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">SVAMP is a math dataset used to evaluate the performance of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">DATASET<\/data>    <\/node>    <node id=\"ASDIV\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">ASDiv is a math dataset used to evaluate the performance of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">DATASET<\/data>    <\/node>    <node id=\"COBBE ET AL., 2021\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication that discusses the GSM8K dataset<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"GAO ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication that discusses the GSM-Hard dataset<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"PATEL ET AL., 2021\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication that discusses the SVAMP dataset<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"MIAO ET AL., 2020\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication that discusses the ASDiv dataset<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"WEI ET AL., 2022\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication that discusses the Chain-of-Thought method<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"WANG ET AL., 2023B\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication that discusses the COT-SC method<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"DU ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication that discusses the LLM Debate method<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"MADAAN ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication that discusses the Self-Refine method<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"LU ET AL., 2024C\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication that discusses the Quality-Diversity method<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"ANTHROPIC\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Anthropic is the organization behind the Claude-Haiku and Claude-Sonnet models<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"OPENAI\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">OpenAI is the organization behind the GPT-3.5 and GPT-4 models<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"MULTI-TASK AND SCIENCE DOMAINS\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">Multi-task and Science domains are areas where Meta Agent Search outperforms baselines, but the gap is smaller due to the challenging nature of the questions<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/node>    <node id=\"AGENTIC SYSTEMS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Agentic systems are systems optimized to improve performance in various domains, particularly effective in mitigating errors like hallucinations or calculation mistakes<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/node>    <node id=\"HUMAN EFFORTS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Human efforts refer to the manual work that can be saved by using Meta Agent Search to develop better task-specific agents<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/node>    <node id=\"TASK-SPECIFIC AGENTS\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Task-specific agents are agents tailored to perform specific tasks effectively, discovered through Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/node>    <node id=\"TRANSFERABILITY\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Transferability refers to the ability of agents discovered by Meta Agent Search to perform well across different models and domains<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/node>    <node id=\"GENERALIZATION\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Generalization refers to the ability of agents discovered by Meta Agent Search to apply learned knowledge to new, unseen tasks or domains<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/node>    <node id=\"BOOTSTRAP CONFIDENCE INTERVAL\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Bootstrap confidence interval is a statistical method used to report the test accuracy of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/node>    <node id=\"MGSM (MATH)\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">MGSM (Math) is a domain used to test the transferability and generalizability of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/node>    <node id=\"GSM8K (COBBE ET AL., 2021)\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">GSM8K (Cobbe et al., 2021) is a math domain used to test the transferability and generalizability of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/node>    <node id=\"GSM-HARD (GAO ET AL., 2023)\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">GSM-Hard (Gao et al., 2023) is a math domain used to test the transferability and generalizability of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/node>    <node id=\"SVAMP (PATEL ET AL., 2021)\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">SVAMP (Patel et al., 2021) is a math domain used to test the transferability and generalizability of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/node>    <node id=\"ASDIV (MIAO ET AL., 2020)\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">ASDiv (Miao et al., 2020) is a math domain used to test the transferability and generalizability of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/node>    <node id=\"MGSM (MATH) DOMAIN\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">MGSM (Math) domain is used to test the transferability and generalizability of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">DOMAIN<\/data>    <\/node>    <node id=\"FOUR POPULAR MATH DOMAINS\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">Four popular math domains are used to test the transferability and generalizability of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">DOMAIN<\/data>    <\/node>    <node id=\"DOMAINS BEYOND MATH\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">Domains beyond math are used to test the transferability and generalizability of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">DOMAIN<\/data>    <\/node>    <node id=\"TOP 3 AGENTS\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Top 3 agents are the best-performing agents discovered by Meta Agent Search, evaluated with GPT-3.5 on ARC and transferred to other models<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">AGENT<\/data>    <\/node>    <node id=\"INVENTED BUILDING BLOCKS AND DESIGN PATTERNS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Invented building blocks and design patterns are the components and strategies discovered by Meta Agent Search that contribute to the effectiveness of the agents<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"PERFORMANCE ON ARC\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Performance on ARC refers to the evaluation results of agents discovered by Meta Agent Search on the ARC dataset<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"TEST ACCURACY\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Test accuracy is a measure of how well agents discovered by Meta Agent Search perform on specific datasets<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"95% BOOTSTRAP CONFIDENCE INTERVAL\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">95% bootstrap confidence interval is a statistical method used to report the test accuracy of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">METHOD<\/data>    <\/node>    <node id=\"CLAUDE-SONNET (ANTHROPIC, 2024B)\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Claude-Sonnet (Anthropic, 2024b) is a model from Anthropic used to evaluate the performance of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"CLAUDE-HAIKU (ANTHROPIC, 2024A)\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Claude-Haiku (Anthropic, 2024a) is a model from Anthropic used to evaluate the performance of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"GPT-4 (OPENAI, 2024)\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4 (OpenAI, 2024) is a version of OpenAI's language model used to evaluate the performance of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"GPT-3.5 (OPENAI, 2022)\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-3.5 (OpenAI, 2022) is a version of OpenAI's language model used to evaluate the performance of agents discovered by Meta Agent Search<\/data>      <data key=\"d2\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <edge source=\"META AGENT SEARCH\" target=\"FMS\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Meta Agent Search is used to discover agents that can leverage the knowledge in FMs<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"READING COMPREHENSION\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Meta Agent Search is effective in the Reading Comprehension domain<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"MATH\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Meta Agent Search is effective in the Math domain<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"SCIENCE\">      <data key=\"d4\">12.0<\/data>      <data key=\"d5\">Meta Agent Search is used in the Science domain<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"MULTI-TASK\">      <data key=\"d4\">12.0<\/data>      <data key=\"d5\">Meta Agent Search is used in the Multi-task domain<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"WANG ET AL., 2024\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Wang et al., 2024 discusses the effectiveness of Meta Agent Search<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"GPT-3.5\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Meta Agent Search uses GPT-3.5 to evaluate the performance of discovered agents<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"CLAUDE-HAIKU\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Meta Agent Search uses Claude-Haiku to evaluate the performance of discovered agents<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"GPT-4\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Meta Agent Search uses GPT-4 to evaluate the performance of discovered agents<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"CLAUDE-SONNET\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Meta Agent Search uses Claude-Sonnet to evaluate the performance of discovered agents<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"CHAIN-OF-THOUGHT\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Meta Agent Search outperforms the Chain-of-Thought method<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"COT-SC\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Meta Agent Search outperforms the COT-SC method<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"LLM DEBATE\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Meta Agent Search outperforms the LLM Debate method<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"SELF-REFINE\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Meta Agent Search outperforms the Self-Refine method<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"QUALITY-DIVERSITY\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Meta Agent Search outperforms the Quality-Diversity method<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"STRUCTURED FEEDBACK AND ENSEMBLE AGENT\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Structured Feedback and Ensemble Agent is one of the top agents discovered by Meta Agent Search<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"HIERARCHICAL COMMITTEE REINFORCEMENT AGENT\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Hierarchical Committee Reinforcement Agent is one of the top agents discovered by Meta Agent Search<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"DYNAMIC MEMORY AND REFINEMENT AGENT\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Dynamic Memory and Refinement Agent is one of the top agents discovered by Meta Agent Search<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"ARC\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Meta Agent Search evaluates the performance of discovered agents on the ARC dataset<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"MGSM\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Meta Agent Search evaluates the performance of discovered agents on the MGSM dataset<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"GSM8K\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Meta Agent Search evaluates the performance of discovered agents on the GSM8K dataset<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"GSM-HARD\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Meta Agent Search evaluates the performance of discovered agents on the GSM-Hard dataset<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"SVAMP\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Meta Agent Search evaluates the performance of discovered agents on the SVAMP dataset<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"ASDIV\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Meta Agent Search evaluates the performance of discovered agents on the ASDiv dataset<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"GPT-3.5\" target=\"OPENAI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">OpenAI is the organization behind the GPT-3.5 model<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"CLAUDE-HAIKU\" target=\"ANTHROPIC\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Anthropic is the organization behind the Claude-Haiku model<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"OPENAI\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">OpenAI is the organization behind the GPT-4 model<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"CLAUDE-SONNET\" target=\"ANTHROPIC\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Anthropic is the organization behind the Claude-Sonnet model<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT\" target=\"WEI ET AL., 2022\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wei et al., 2022 discusses the Chain-of-Thought method<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"COT-SC\" target=\"WANG ET AL., 2023B\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang et al., 2023b discusses the COT-SC method<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"LLM DEBATE\" target=\"DU ET AL., 2023\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Du et al., 2023 discusses the LLM Debate method<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"SELF-REFINE\" target=\"MADAAN ET AL., 2024\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Madaan et al., 2024 discusses the Self-Refine method<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"QUALITY-DIVERSITY\" target=\"LU ET AL., 2024C\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Lu et al., 2024c discusses the Quality-Diversity method<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"GSM8K\" target=\"COBBE ET AL., 2021\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Cobbe et al., 2021 discusses the GSM8K dataset<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"GSM-HARD\" target=\"GAO ET AL., 2023\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Gao et al., 2023 discusses the GSM-Hard dataset<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"SVAMP\" target=\"PATEL ET AL., 2021\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Patel et al., 2021 discusses the SVAMP dataset<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>    <edge source=\"ASDIV\" target=\"MIAO ET AL., 2020\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Miao et al., 2020 discusses the ASDiv dataset<\/data>      <data key=\"d6\">2901d5e2711fa4f32d39cd8eea36cd71<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"0b6b4880e77d40e284702da16be4ef64","chunk":"3), SVAMP (Patel et al., 2021),\nand ASDiv (Miao et al., 2020) and (2) three domains beyond math adopted in Section 4.2. As shown\nin Table 3, we observe a similar superiority in the performance of Meta Agent Search compared to\nbaselines. Notably, our agents improve accuracy by 25.9%and13.2%on GSM8K (Cobbe et al., 2021)\nand GSM-Hard (Gao et al., 2023), respectively, compared to the baselines. More surprisingly, we\nobserve that agents discovered in the math domain can be transferred to non-math domains (Table 4).\nWhile the performance of agents originally searched in the math domain does not fully match that of\nagents specifically designed for the target domains, they still outperform (in Reading Comprehension\nand Multi-task) or match (in Science) the state-of-the-art hand-designed agent baselines. These\nresults illustrate that Meta Agent Search can discover generalizable design patterns and agentic\nsystems.\n9Automated Design of Agentic Systems\nAgent NameAccuracy (%)\nMGSM GSM8K GSM-Hard SVAMP ASDiv\nManually Designed Agents\nChain-of-Thought (Wei et al., 2022) 28.0\u00b13.134.9\u00b13.2 15 .0\u00b12.5 77 .8\u00b12.8 88 .9\u00b12.2\nCOT-SC (Wang et al., 2023b) 28.2\u00b13.137.8\u00b13.4 15 .5\u00b12.5 78 .2\u00b12.8 89 .0\u00b12.1\nSelf-Refine (Madaan et al., 2024) 27.5\u00b13.138.9\u00b13.4 15 .1\u00b12.478.5\u00b12.8 89 .2\u00b12.2\nLLM Debate (Du et al., 2023) 39.0\u00b13.443.6\u00b13.417.4\u00b12.6 76 .0\u00b13.0 88 .9\u00b12.2\nStep-back Abstraction (Zheng et al., 2023) 31.1\u00b13.231.5\u00b13.3 12 .2\u00b12.3 76 .1\u00b13.0 87 .8\u00b12.3\nQuality-Diversity (Lu et al., 2024c) 23.8\u00b13.028.0\u00b13.1 14 .1\u00b12.4 69 .8\u00b13.2 80 .1\u00b12.8\nRole Assignment (Xu et al., 2023) 30.1\u00b13.237.0\u00b13.418.0\u00b12.773.0\u00b13.0 83 .1\u00b12.6\nTop Agents Searched on MGSM (Math) Transferred to Other Math Domains\nDynamic Role-Playing Architecture 53.4\u00b13.569.5\u00b13.2 31 .2\u00b13.281.5\u00b12.691.8\u00b11.8\nStructured Multimodal Feedback Loop 50.2\u00b13.564.5\u00b13.4 30 .1\u00b13.282.6\u00b12.689.9\u00b12.1\nInteractive Multimodal Feedback Loop 47.4\u00b13.564.9\u00b13.3 27 .6\u00b13.2 80 .6\u00b12.8 89 .8\u00b12.1\nTable 3|Performance on different math domains when transferring top agents from MGSM to\nother math domains. Agents discovered by Meta Agent Search consistently outperform the baselines\nacross different math domains. We report the test accuracy and the 95% bootstrap confidence interval.\nThe names of top agents are generated by Meta Agent Search.\n5. Related Work\nAgentic Systems. Researchers develop various building blocks and design patterns for different\napplications. Important building blocks for agentic systems includes: prompting techniques (Chen\net al., 2023a; Schulhoff et al., 2024), chain-of-thought-based planning and reasoning methods (Hu\n& Clune, 2024; Wei et al., 2022; Yao et al., 2023), reflection (Madaan et al., 2024; Shinn et al.,\n2023), developing new skills for embodied agents in code (Vemprala et al., 2023; Wang et al., 2023a),\nexternal memory and RAG (Lewis et al., 2020; Zhang et al., 2024c), tool use (Nakano et al., 2021;\nQu et al., 2024; Schick et al., 2023), assigning FM modules in the agentic system with different\nroles and enabling them to collaborate (Hong et al., 2023; Qian et al., 2023, 2024; Wu et al., 2023;\nXu et al., 2023), and enabling the agent to instruct itself for the next action (Richards, 2023), etc.\nWhile the community has invested substantial effort in developing all the above important techniques,\nthis is only a partial list of the discovered building blocks, and many more remain to be uncovered.\nTherefore, in this paper, we propose a new research area, ADAS, which aims to invent novel building\nblocks and design powerful agentic systems in an automated manner.\nAI-Generating Algorithms and AutoML. Following the lessons learned from the history of machine\nlearning, research in AI-Generating Algorithms (AI-GAs","chunk_id":"0b6b4880e77d40e284702da16be4ef64","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"SVAMP","type":"DATASET","description":"SVAMP is a dataset used for evaluating the performance of models in mathematical problem-solving tasks","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"ASDIV","type":"DATASET","description":"ASDiv is a dataset used for evaluating the performance of models in mathematical problem-solving tasks","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"META AGENT SEARCH","type":"METHOD\/TECHNIQUE","description":"Meta Agent Search is a method used to discover generalizable design patterns and agentic systems that can be transferred across different domains","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"GSM8K","type":"DATASET","description":"GSM8K is a dataset used for evaluating the performance of models in mathematical problem-solving tasks","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"GSM-HARD","type":"DATASET","description":"GSM-Hard is a dataset used for evaluating the performance of models in more challenging mathematical problem-solving tasks","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"READING COMPREHENSION","type":"TASK","description":"Reading Comprehension is a task where models are evaluated on their ability to understand and interpret written text","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"MULTI-TASK","type":"TASK","description":"Multi-task is a task where models are evaluated on their ability to perform multiple different tasks simultaneously","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"SCIENCE","type":"DOMAIN","description":"Science is a domain where models are evaluated on their ability to understand and interpret scientific information","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"CHAIN-OF-THOUGHT","type":"METHOD\/TECHNIQUE","description":"Chain-of-Thought is a method used for planning and reasoning in agentic systems","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"COT-SC","type":"METHOD\/TECHNIQUE","description":"COT-SC is a method used for planning and reasoning in agentic systems","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"SELF-REFINE","type":"METHOD\/TECHNIQUE","description":"Self-Refine is a method used for improving the performance of models through self-reflection and refinement","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"LLM DEBATE","type":"METHOD\/TECHNIQUE","description":"LLM Debate is a method used for improving the performance of models through debate and discussion","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"STEP-BACK ABSTRACTION","type":"METHOD\/TECHNIQUE","description":"Step-back Abstraction is a method used for improving the performance of models through abstraction and simplification","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"QUALITY-DIVERSITY","type":"METHOD\/TECHNIQUE","description":"Quality-Diversity is a method used for improving the performance of models through diversity and quality control","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"ROLE ASSIGNMENT","type":"METHOD\/TECHNIQUE","description":"Role Assignment is a method used for assigning different roles to modules in an agentic system and enabling them to collaborate","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"DYNAMIC ROLE-PLAYING ARCHITECTURE","type":"METHOD\/TECHNIQUE","description":"Dynamic Role-Playing Architecture is a method used for improving the performance of models through dynamic role-playing and interaction","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"STRUCTURED MULTIMODAL FEEDBACK LOOP","type":"METHOD\/TECHNIQUE","description":"Structured Multimodal Feedback Loop is a method used for improving the performance of models through structured feedback and interaction","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"INTERACTIVE MULTIMODAL FEEDBACK LOOP","type":"METHOD\/TECHNIQUE","description":"Interactive Multimodal Feedback Loop is a method used for improving the performance of models through interactive feedback and interaction","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"PROMPTING TECHNIQUES","type":"METHOD\/TECHNIQUE","description":"Prompting Techniques are methods used for improving the performance of models through effective prompting","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"REFLECTION","type":"METHOD\/TECHNIQUE","description":"Reflection is a method used for improving the performance of models through self-reflection and refinement","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"EXTERNAL MEMORY","type":"METHOD\/TECHNIQUE","description":"External Memory is a method used for improving the performance of models through the use of external memory resources","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"RAG","type":"METHOD\/TECHNIQUE","description":"RAG (Retrieval-Augmented Generation) is a method used for improving the performance of models through retrieval and generation","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"TOOL USE","type":"METHOD\/TECHNIQUE","description":"Tool Use is a method used for improving the performance of models through the use of external tools","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"FM MODULES","type":"COMPONENT","description":"FM Modules are components in an agentic system that are assigned different roles and enabled to collaborate","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"ADAS","type":"RESEARCH AREA","description":"ADAS (Automated Design of Agentic Systems) is a research area focused on inventing novel building blocks and designing powerful agentic systems in an automated manner","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"AI-GENERATING ALGORITHMS","type":"METHOD\/TECHNIQUE","description":"AI-Generating Algorithms are methods used for generating AI models and systems automatically","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"AUTOML","type":"METHOD\/TECHNIQUE","description":"AutoML (Automated Machine Learning) is a method used for automating the process of machine learning model development","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"PATEL ET AL.","type":"PERSON","description":"Patel et al. are the authors of the SVAMP dataset","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"MIAO ET AL.","type":"PERSON","description":"Miao et al. are the authors of the ASDiv dataset","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"COBBE ET AL.","type":"PERSON","description":"Cobbe et al. are the authors of the GSM8K dataset","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"GAO ET AL.","type":"PERSON","description":"Gao et al. are the authors of the GSM-Hard dataset","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"WEI ET AL.","type":"PERSON","description":"Wei et al. are the authors of the Chain-of-Thought method","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"WANG ET AL.","type":"PERSON","description":"Wang et al. are the authors of the method for developing new skills for embodied agents in code\nWang et al. are the authors of the COT-SC method","source_id":"0b6b4880e77d40e284702da16be4ef64","entity_type":"PERSON"},{"name":"MADAAN ET AL.","type":"PERSON","description":"Madaan et al. are the authors of the Self-Refine method","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"DU ET AL.","type":"PERSON","description":"Du et al. are the authors of the LLM Debate method","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"ZHENG ET AL.","type":"PERSON","description":"Zheng et al. are the authors of the Step-back Abstraction method","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"LU ET AL.","type":"PERSON","description":"Lu et al. are the authors of the Quality-Diversity method","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"XU ET AL.","type":"PERSON","description":"Xu et al. are the authors of the Role Assignment method","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"CHEN ET AL.","type":"PERSON","description":"Chen et al. are the authors of the Prompting Techniques method","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"SCHULHOFF ET AL.","type":"PERSON","description":"Schulhoff et al. are the authors of the Prompting Techniques method","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"HU & CLUNE","type":"PERSON","description":"Hu & Clune are the authors of the Chain-of-Thought-based planning and reasoning methods","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"YAO ET AL.","type":"PERSON","description":"Yao et al. are the authors of the Chain-of-Thought-based planning and reasoning methods","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"SHINN ET AL.","type":"PERSON","description":"Shinn et al. are the authors of the Reflection method","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"VEMPRALA ET AL.","type":"PERSON","description":"Vemprala et al. are the authors of the method for developing new skills for embodied agents in code","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"LEWIS ET AL.","type":"PERSON","description":"Lewis et al. are the authors of the External Memory and RAG methods","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"ZHANG ET AL.","type":"PERSON","description":"Zhang et al. are the authors of the External Memory and RAG methods","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"NAKANO ET AL.","type":"PERSON","description":"Nakano et al. are the authors of the Tool Use method","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"QU ET AL.","type":"PERSON","description":"Qu et al. are the authors of the Tool Use method","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"SCHICK ET AL.","type":"PERSON","description":"Schick et al. are the authors of the Tool Use method","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"HONG ET AL.","type":"PERSON","description":"Hong et al. are the authors of the method for assigning FM modules in the agentic system with different roles and enabling them to collaborate","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"QIAN ET AL.","type":"PERSON","description":"Qian et al. are the authors of the method for assigning FM modules in the agentic system with different roles and enabling them to collaborate","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"WU ET AL.","type":"PERSON","description":"Wu et al. are the authors of the method for assigning FM modules in the agentic system with different roles and enabling them to collaborate","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"RICHARDS","type":"PERSON","description":"Richards is the author of the method for enabling the agent to instruct itself for the next action","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"CHAIN-OF-THOUGHT-BASED PLANNING AND REASONING METHODS","type":"","description":"","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"DEVELOPING NEW SKILLS FOR EMBODIED AGENTS IN CODE","type":"","description":"","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"EXTERNAL MEMORY AND RAG","type":"","description":"","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"ASSIGNING FM MODULES IN THE AGENTIC SYSTEM WITH DIFFERENT ROLES AND ENABLING THEM TO COLLABORATE","type":"","description":"","source_id":"0b6b4880e77d40e284702da16be4ef64"},{"name":"ENABLING THE AGENT TO INSTRUCT ITSELF FOR THE NEXT ACTION","type":"","description":"","source_id":"0b6b4880e77d40e284702da16be4ef64"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"SVAMP\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">SVAMP is a dataset used for evaluating the performance of models in mathematical problem-solving tasks<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"ASDIV\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">ASDiv is a dataset used for evaluating the performance of models in mathematical problem-solving tasks<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"META AGENT SEARCH\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Meta Agent Search is a method used to discover generalizable design patterns and agentic systems that can be transferred across different domains<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"GSM8K\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">GSM8K is a dataset used for evaluating the performance of models in mathematical problem-solving tasks<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"GSM-HARD\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">GSM-Hard is a dataset used for evaluating the performance of models in more challenging mathematical problem-solving tasks<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"READING COMPREHENSION\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">Reading Comprehension is a task where models are evaluated on their ability to understand and interpret written text<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"MULTI-TASK\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">Multi-task is a task where models are evaluated on their ability to perform multiple different tasks simultaneously<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"SCIENCE\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">Science is a domain where models are evaluated on their ability to understand and interpret scientific information<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"CHAIN-OF-THOUGHT\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Chain-of-Thought is a method used for planning and reasoning in agentic systems<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"COT-SC\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">COT-SC is a method used for planning and reasoning in agentic systems<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"SELF-REFINE\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Self-Refine is a method used for improving the performance of models through self-reflection and refinement<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"LLM DEBATE\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">LLM Debate is a method used for improving the performance of models through debate and discussion<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"STEP-BACK ABSTRACTION\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Step-back Abstraction is a method used for improving the performance of models through abstraction and simplification<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"QUALITY-DIVERSITY\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Quality-Diversity is a method used for improving the performance of models through diversity and quality control<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"ROLE ASSIGNMENT\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Role Assignment is a method used for assigning different roles to modules in an agentic system and enabling them to collaborate<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"DYNAMIC ROLE-PLAYING ARCHITECTURE\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Dynamic Role-Playing Architecture is a method used for improving the performance of models through dynamic role-playing and interaction<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"STRUCTURED MULTIMODAL FEEDBACK LOOP\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Structured Multimodal Feedback Loop is a method used for improving the performance of models through structured feedback and interaction<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"INTERACTIVE MULTIMODAL FEEDBACK LOOP\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Interactive Multimodal Feedback Loop is a method used for improving the performance of models through interactive feedback and interaction<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"PROMPTING TECHNIQUES\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Prompting Techniques are methods used for improving the performance of models through effective prompting<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"REFLECTION\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Reflection is a method used for improving the performance of models through self-reflection and refinement<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"EXTERNAL MEMORY\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">External Memory is a method used for improving the performance of models through the use of external memory resources<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"RAG\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">RAG (Retrieval-Augmented Generation) is a method used for improving the performance of models through retrieval and generation<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"TOOL USE\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Tool Use is a method used for improving the performance of models through the use of external tools<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"FM MODULES\">      <data key=\"d0\">COMPONENT<\/data>      <data key=\"d1\">FM Modules are components in an agentic system that are assigned different roles and enabled to collaborate<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"ADAS\">      <data key=\"d0\">RESEARCH AREA<\/data>      <data key=\"d1\">ADAS (Automated Design of Agentic Systems) is a research area focused on inventing novel building blocks and designing powerful agentic systems in an automated manner<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"AI-GENERATING ALGORITHMS\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">AI-Generating Algorithms are methods used for generating AI models and systems automatically<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"AUTOML\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">AutoML (Automated Machine Learning) is a method used for automating the process of machine learning model development<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"PATEL ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Patel et al. are the authors of the SVAMP dataset<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"MIAO ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Miao et al. are the authors of the ASDiv dataset<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"COBBE ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Cobbe et al. are the authors of the GSM8K dataset<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"GAO ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gao et al. are the authors of the GSM-Hard dataset<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"WEI ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wei et al. are the authors of the Chain-of-Thought method<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"WANG ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wang et al. are the authors of the method for developing new skills for embodied agents in codeWang et al. are the authors of the COT-SC method<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MADAAN ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Madaan et al. are the authors of the Self-Refine method<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"DU ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Du et al. are the authors of the LLM Debate method<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"ZHENG ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zheng et al. are the authors of the Step-back Abstraction method<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"LU ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lu et al. are the authors of the Quality-Diversity method<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"XU ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xu et al. are the authors of the Role Assignment method<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"CHEN ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chen et al. are the authors of the Prompting Techniques method<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"SCHULHOFF ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Schulhoff et al. are the authors of the Prompting Techniques method<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"HU &amp; CLUNE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hu &amp; Clune are the authors of the Chain-of-Thought-based planning and reasoning methods<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"YAO ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yao et al. are the authors of the Chain-of-Thought-based planning and reasoning methods<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"SHINN ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shinn et al. are the authors of the Reflection method<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"VEMPRALA ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Vemprala et al. are the authors of the method for developing new skills for embodied agents in code<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"LEWIS ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lewis et al. are the authors of the External Memory and RAG methods<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"ZHANG ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhang et al. are the authors of the External Memory and RAG methods<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"NAKANO ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nakano et al. are the authors of the Tool Use method<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"QU ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Qu et al. are the authors of the Tool Use method<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"SCHICK ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Schick et al. are the authors of the Tool Use method<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"HONG ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hong et al. are the authors of the method for assigning FM modules in the agentic system with different roles and enabling them to collaborate<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"QIAN ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Qian et al. are the authors of the method for assigning FM modules in the agentic system with different roles and enabling them to collaborate<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"WU ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wu et al. are the authors of the method for assigning FM modules in the agentic system with different roles and enabling them to collaborate<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"RICHARDS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Richards is the author of the method for enabling the agent to instruct itself for the next action<\/data>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"CHAIN-OF-THOUGHT-BASED PLANNING AND REASONING METHODS\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"DEVELOPING NEW SKILLS FOR EMBODIED AGENTS IN CODE\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"EXTERNAL MEMORY AND RAG\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"ASSIGNING FM MODULES IN THE AGENTIC SYSTEM WITH DIFFERENT ROLES AND ENABLING THEM TO COLLABORATE\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <node id=\"ENABLING THE AGENT TO INSTRUCT ITSELF FOR THE NEXT ACTION\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/node>    <edge source=\"SVAMP\" target=\"PATEL ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Patel et al. are the authors of the SVAMP dataset<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"ASDIV\" target=\"MIAO ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Miao et al. are the authors of the ASDiv dataset<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"GSM8K\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Meta Agent Search improves accuracy on the GSM8K dataset<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"GSM-HARD\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Meta Agent Search improves accuracy on the GSM-Hard dataset<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"READING COMPREHENSION\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Meta Agent Search outperforms state-of-the-art baselines in Reading Comprehension<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"MULTI-TASK\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Meta Agent Search outperforms state-of-the-art baselines in Multi-task<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"SCIENCE\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Meta Agent Search matches state-of-the-art baselines in Science<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"CHAIN-OF-THOUGHT\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">Chain-of-Thought is a method used in Meta Agent Search<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"COT-SC\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">COT-SC is a method used in Meta Agent Search<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"SELF-REFINE\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">Self-Refine is a method used in Meta Agent Search<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"LLM DEBATE\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">LLM Debate is a method used in Meta Agent Search<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"STEP-BACK ABSTRACTION\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">Step-back Abstraction is a method used in Meta Agent Search<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"QUALITY-DIVERSITY\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">Quality-Diversity is a method used in Meta Agent Search<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"ROLE ASSIGNMENT\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">Role Assignment is a method used in Meta Agent Search<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"DYNAMIC ROLE-PLAYING ARCHITECTURE\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Dynamic Role-Playing Architecture is a top agent discovered by Meta Agent Search<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"STRUCTURED MULTIMODAL FEEDBACK LOOP\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Structured Multimodal Feedback Loop is a top agent discovered by Meta Agent Search<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"INTERACTIVE MULTIMODAL FEEDBACK LOOP\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Interactive Multimodal Feedback Loop is a top agent discovered by Meta Agent Search<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"PROMPTING TECHNIQUES\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">Prompting Techniques are used in Meta Agent Search<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"REFLECTION\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">Reflection is used in Meta Agent Search<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"EXTERNAL MEMORY\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">External Memory is used in Meta Agent Search<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"RAG\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">RAG is used in Meta Agent Search<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"TOOL USE\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">Tool Use is used in Meta Agent Search<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"FM MODULES\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">FM Modules are used in Meta Agent Search<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"ADAS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">ADAS is the research area that proposes Meta Agent Search<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"AI-GENERATING ALGORITHMS\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">AI-Generating Algorithms are related to Meta Agent Search<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"AUTOML\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">AutoML is related to Meta Agent Search<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"GSM8K\" target=\"COBBE ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Cobbe et al. are the authors of the GSM8K dataset<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"GSM-HARD\" target=\"GAO ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Gao et al. are the authors of the GSM-Hard dataset<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT\" target=\"WEI ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wei et al. are the authors of the Chain-of-Thought method<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"COT-SC\" target=\"WANG ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang et al. are the authors of the COT-SC method<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"SELF-REFINE\" target=\"MADAAN ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Madaan et al. are the authors of the Self-Refine method<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"LLM DEBATE\" target=\"DU ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Du et al. are the authors of the LLM Debate method<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"STEP-BACK ABSTRACTION\" target=\"ZHENG ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Zheng et al. are the authors of the Step-back Abstraction method<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"QUALITY-DIVERSITY\" target=\"LU ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Lu et al. are the authors of the Quality-Diversity method<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"ROLE ASSIGNMENT\" target=\"XU ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Xu et al. are the authors of the Role Assignment method<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"PROMPTING TECHNIQUES\" target=\"CHEN ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Chen et al. are the authors of the Prompting Techniques method<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"PROMPTING TECHNIQUES\" target=\"SCHULHOFF ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Schulhoff et al. are the authors of the Prompting Techniques method<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"REFLECTION\" target=\"SHINN ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Shinn et al. are the authors of the Reflection method<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"TOOL USE\" target=\"NAKANO ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Nakano et al. are the authors of the Tool Use method<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"TOOL USE\" target=\"QU ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Qu et al. are the authors of the Tool Use method<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"TOOL USE\" target=\"SCHICK ET AL.\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Schick et al. are the authors of the Tool Use method<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"WANG ET AL.\" target=\"DEVELOPING NEW SKILLS FOR EMBODIED AGENTS IN CODE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang et al. are the authors of the method for developing new skills for embodied agents in code<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"HU &amp; CLUNE\" target=\"CHAIN-OF-THOUGHT-BASED PLANNING AND REASONING METHODS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Hu &amp; Clune are the authors of the Chain-of-Thought-based planning and reasoning methods<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"YAO ET AL.\" target=\"CHAIN-OF-THOUGHT-BASED PLANNING AND REASONING METHODS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yao et al. are the authors of the Chain-of-Thought-based planning and reasoning methods<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"VEMPRALA ET AL.\" target=\"DEVELOPING NEW SKILLS FOR EMBODIED AGENTS IN CODE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Vemprala et al. are the authors of the method for developing new skills for embodied agents in code<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"LEWIS ET AL.\" target=\"EXTERNAL MEMORY AND RAG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Lewis et al. are the authors of the External Memory and RAG methods<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"ZHANG ET AL.\" target=\"EXTERNAL MEMORY AND RAG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Zhang et al. are the authors of the External Memory and RAG methods<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"HONG ET AL.\" target=\"ASSIGNING FM MODULES IN THE AGENTIC SYSTEM WITH DIFFERENT ROLES AND ENABLING THEM TO COLLABORATE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Hong et al. are the authors of the method for assigning FM modules in the agentic system with different roles and enabling them to collaborate<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"QIAN ET AL.\" target=\"ASSIGNING FM MODULES IN THE AGENTIC SYSTEM WITH DIFFERENT ROLES AND ENABLING THEM TO COLLABORATE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Qian et al. are the authors of the method for assigning FM modules in the agentic system with different roles and enabling them to collaborate<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"WU ET AL.\" target=\"ASSIGNING FM MODULES IN THE AGENTIC SYSTEM WITH DIFFERENT ROLES AND ENABLING THEM TO COLLABORATE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wu et al. are the authors of the method for assigning FM modules in the agentic system with different roles and enabling them to collaborate<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>    <edge source=\"RICHARDS\" target=\"ENABLING THE AGENT TO INSTRUCT ITSELF FOR THE NEXT ACTION\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Richards is the author of the method for enabling the agent to instruct itself for the next action<\/data>      <data key=\"d6\">0b6b4880e77d40e284702da16be4ef64<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"7c08d98f503d722d7de13be55375c8cb","chunk":"While the community has invested substantial effort in developing all the above important techniques,\nthis is only a partial list of the discovered building blocks, and many more remain to be uncovered.\nTherefore, in this paper, we propose a new research area, ADAS, which aims to invent novel building\nblocks and design powerful agentic systems in an automated manner.\nAI-Generating Algorithms and AutoML. Following the lessons learned from the history of machine\nlearning, research in AI-Generating Algorithms (AI-GAs) (Clune, 2019) and AutoML (Hutter et al.,\n2019) continually strives to learn more components in AI systems to replace handcrafted ones. There\nare mainly three pillars in this field: (1) meta-learning architectures, (2) meta-learning the learning\nalgorithms, and (3) generating effective learning environments and training data (Clune, 2019). For\nexample, Neural Architecture Search (Elsken et al., 2019; Hu et al., 2021; Lu et al., 2019) aims to\nautomate the design of neural network architectures like convolution, which falls under the first pillar.\nThe second pillar includes works like MAML (Finn et al., 2017) and Meta-RL (Duan et al., 2017;\nNorman & Clune, 2023; Wang et al., 2016; Zintgraf et al., 2021a,b), which allow \u201clearning to learn\u201d\nfor better sample efficiency, generalizability, and continuous learning of multiple tasks. Additionally,\nworks like POET (Dharna et al., 2020; Wang et al., 2019, 2020) and OMNI-EPIC (Faldor et al., 2024)\nunder the third pillar aim to generate learning environments in an open-ended manner. We believe\n10Automated Design of Agentic Systems\nAgent NameAccuracy (%) F1 Score Accuracy (%)\nMath Reading Comprehension Multi-task Science\nManually Designed Agents\nChain-of-Thought (Wei et al., 2022) 28.0\u00b13.1 64.2\u00b10.9 65 .4\u00b13.3 29 .2\u00b13.1\nCOT-SC (Wang et al., 2023b) 28.2\u00b13.1 64.4\u00b10.8 65.9\u00b13.230.5\u00b13.2\nSelf-Refine (Madaan et al., 2024) 27.5\u00b13.1 59.2\u00b10.9 63 .5\u00b13.431.6\u00b13.2\nLLM Debate (Du et al., 2023) 39.0\u00b13.4 60.6\u00b10.9 65 .6\u00b13.3 31 .4\u00b13.2\nStep-back Abstraction (Zheng et al., 2023) 31.1\u00b13.2 60.4\u00b11.0 65 .1\u00b13.3 26 .9\u00b13.0\nQuality-Diversity (Lu et al., 2024c) 23.8\u00b13.0 61.8\u00b10.9 65 .1\u00b13.1 30 .2\u00b13.1\nRole Assignment (Xu et al., 2023) 30.1\u00b13.2 65.8\u00b10.9 64.5\u00b13.3 31 .1\u00b13.1\nTop Agents Searched on Math (MGSM) Transferred beyond Math Domains\nDynamic Role-Playing Architecture 53.4\u00b13.5 70.4\u00b10.9 62 .4\u00b13.4 28 .6\u00b13.1\nStructured Multimodal Feedback Loop 50.2\u00b13.5 70.4\u00b10.9 67.0\u00b13.228.7\u00b13.1\nInteractive Multimodal Feedback Loop 47.4\u00b13.5 71.9\u00b10.8 64.8\u00b13.329.9\u00b13.2\nTable 4|Performance across multiple domains when transferring top agents from the Math\n(MGSM) domain to non-math domains. Agents discovered by Meta Agent Search in the math\ndomain can outperform or match the performance of baselines after being transferred to domains\nbeyond math. We report the test accuracy and the 95% bootstrap confidence interval.\nthat the proposed Automated Design of Agentic Systems belongs to both the first and second pillars:\nPillar one because ADAS meta-learns the architecture of agentic systems, but also Pillar two because\nagents are proficient in in-context learning, thus ADAS can also be considered as learning to learn, as\ndemonstrated in the ARC challenge (Section 4.1).\nAdditionally, recent AI-GA and AutoML works have incorporated Foundation Models (FMs) to\nwrite code. For example, in FunSearch (Romera-Paredes et al., 2024) and EoH (Liu et al., 2024),\nFMs write code to discover better optimization algorithms. In DiscoPOP (Lu et al., 2024a), FMs\nprogram the loss function for preference learning in FM alignment training (Rafailov et al., 2024).\nAdditionally, Eureka (Ma et al., 2023) and language-to-reward (Yu et al., 2023) enable FMs to write\nreward functions for reinforcement learning in robotics. Finally, OMNI-EPIC (Faldor et al., 2024)\nenables FMs to create robotics learning environments by programming in code","chunk_id":"7c08d98f503d722d7de13be55375c8cb","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"ADAS","type":"RESEARCH AREA","description":"ADAS (Automated Design of Agentic Systems) is a proposed research area aimed at inventing novel building blocks and designing powerful agentic systems in an automated manner","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"AI-GENERATING ALGORITHMS","type":"TECHNOLOGY","description":"AI-Generating Algorithms (AI-GAs) are a field of research focused on learning components in AI systems to replace handcrafted ones","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"AUTOML","type":"TECHNOLOGY","description":"AutoML is a field of research that aims to automate the process of machine learning model development","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"NEURAL ARCHITECTURE SEARCH","type":"TECHNIQUE","description":"Neural Architecture Search is a technique aimed at automating the design of neural network architectures","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"MAML","type":"TECHNIQUE","description":"MAML (Model-Agnostic Meta-Learning) is a technique that allows \"learning to learn\" for better sample efficiency and generalizability","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"META-RL","type":"TECHNIQUE","description":"Meta-RL (Meta-Reinforcement Learning) is a technique that allows \"learning to learn\" for continuous learning of multiple tasks","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"POET","type":"TECHNIQUE","description":"POET (Paired Open-Ended Trailblazer) is a technique aimed at generating learning environments in an open-ended manner","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"OMNI-EPIC","type":"TECHNIQUE","description":"OMNI-EPIC is a technique that enables the generation of learning environments in an open-ended manner","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"FOUNDATION MODELS","type":"TECHNOLOGY","description":"Foundation Models (FMs) are large-scale models used to write code for various applications, including optimization algorithms and reinforcement learning","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"FUNSEARCH","type":"TOOL","description":"FunSearch is a tool where Foundation Models write code to discover better optimization algorithms","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"EOH","type":"TOOL","description":"EoH is a tool where Foundation Models write code to discover better optimization algorithms","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"DISCOPOP","type":"TOOL","description":"DiscoPOP is a tool where Foundation Models program the loss function for preference learning in FM alignment training","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"EUREKA","type":"TOOL","description":"Eureka is a tool that enables Foundation Models to write reward functions for reinforcement learning in robotics","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"LANGUAGE-TO-REWARD","type":"TOOL","description":"Language-to-Reward is a tool that enables Foundation Models to write reward functions for reinforcement learning in robotics","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"CHAIN-OF-THOUGHT","type":"AGENT","description":"Chain-of-Thought is a manually designed agent used for various tasks such as Math, Reading Comprehension, Multi-task, and Science","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"COT-SC","type":"AGENT","description":"COT-SC is a manually designed agent used for various tasks such as Math, Reading Comprehension, Multi-task, and Science","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"SELF-REFINE","type":"AGENT","description":"Self-Refine is a manually designed agent used for various tasks such as Math, Reading Comprehension, Multi-task, and Science","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"LLM DEBATE","type":"AGENT","description":"LLM Debate is a manually designed agent used for various tasks such as Math, Reading Comprehension, Multi-task, and Science","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"STEP-BACK ABSTRACTION","type":"AGENT","description":"Step-back Abstraction is a manually designed agent used for various tasks such as Math, Reading Comprehension, Multi-task, and Science","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"QUALITY-DIVERSITY","type":"AGENT","description":"Quality-Diversity is a manually designed agent used for various tasks such as Math, Reading Comprehension, Multi-task, and Science","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"ROLE ASSIGNMENT","type":"AGENT","description":"Role Assignment is a manually designed agent used for various tasks such as Math, Reading Comprehension, Multi-task, and Science","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"DYNAMIC ROLE-PLAYING ARCHITECTURE","type":"AGENT","description":"Dynamic Role-Playing Architecture is a top agent discovered in the Math domain and transferred to non-math domains","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"STRUCTURED MULTIMODAL FEEDBACK LOOP","type":"AGENT","description":"Structured Multimodal Feedback Loop is a top agent discovered in the Math domain and transferred to non-math domains","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"INTERACTIVE MULTIMODAL FEEDBACK LOOP","type":"AGENT","description":"Interactive Multimodal Feedback Loop is a top agent discovered in the Math domain and transferred to non-math domains","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"CLUNE, 2019","type":"PUBLICATION","description":"A publication by Clune in 2019 related to AI-Generating Algorithms","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"HUTTER ET AL., 2019","type":"PUBLICATION","description":"A publication by Hutter et al. in 2019 related to AutoML","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"ELSKEN ET AL., 2019","type":"PUBLICATION","description":"A publication by Elsken et al. in 2019 related to Neural Architecture Search","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"HU ET AL., 2021","type":"PUBLICATION","description":"A publication by Hu et al. in 2021 related to Neural Architecture Search","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"LU ET AL., 2019","type":"PUBLICATION","description":"A publication by Lu et al. in 2019 related to Neural Architecture Search","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"FINN ET AL., 2017","type":"PUBLICATION","description":"A publication by Finn et al. in 2017 related to MAML","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"DUAN ET AL., 2017","type":"PUBLICATION","description":"A publication by Duan et al. in 2017 related to Meta-RL","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"NORMAN & CLUNE, 2023","type":"PUBLICATION","description":"A publication by Norman & Clune in 2023 related to Meta-RL","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"WANG ET AL., 2016","type":"PUBLICATION","description":"A publication by Wang et al. in 2016 related to Meta-RL","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"ZINTGRAF ET AL., 2021A","type":"PUBLICATION","description":"A publication by Zintgraf et al. in 2021 related to Meta-RL","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"ZINTGRAF ET AL., 2021B","type":"PUBLICATION","description":"A publication by Zintgraf et al. in 2021 related to Meta-RL","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"DHARNA ET AL., 2020","type":"PUBLICATION","description":"A publication by Dharna et al. in 2020 related to POET","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"WANG ET AL., 2019","type":"PUBLICATION","description":"A publication by Wang et al. in 2019 related to POET","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"WANG ET AL., 2020","type":"PUBLICATION","description":"A publication by Wang et al. in 2020 related to POET","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"FALDOR ET AL., 2024","type":"PUBLICATION","description":"A publication by Faldor et al. in 2024 related to OMNI-EPIC","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"ROMERA-PAREDES ET AL., 2024","type":"PUBLICATION","description":"A publication by Romera-Paredes et al. in 2024 related to FunSearch","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"LIU ET AL., 2024","type":"PUBLICATION","description":"A publication by Liu et al. in 2024 related to EoH","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"LU ET AL., 2024A","type":"PUBLICATION","description":"A publication by Lu et al. in 2024 related to DiscoPOP","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"RAFAILOV ET AL., 2024","type":"PUBLICATION","description":"A publication by Rafailov et al. in 2024 related to FM alignment training","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"MA ET AL., 2023","type":"PUBLICATION","description":"A publication by Ma et al. in 2023 related to Eureka","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"YU ET AL., 2023","type":"PUBLICATION","description":"A publication by Yu et al. in 2023 related to language-to-reward","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"WEI ET AL., 2022","type":"PUBLICATION","description":"A publication by Wei et al. in 2022 related to Chain-of-Thought","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"WANG ET AL., 2023B","type":"PUBLICATION","description":"A publication by Wang et al. in 2023 related to COT-SC","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"MADAAN ET AL., 2024","type":"PUBLICATION","description":"A publication by Madaan et al. in 2024 related to Self-Refine","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"DU ET AL., 2023","type":"PUBLICATION","description":"A publication by Du et al. in 2023 related to LLM Debate","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"ZHENG ET AL., 2023","type":"PUBLICATION","description":"A publication by Zheng et al. in 2023 related to Step-back Abstraction","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"LU ET AL., 2024C","type":"PUBLICATION","description":"A publication by Lu et al. in 2024 related to Quality-Diversity","source_id":"7c08d98f503d722d7de13be55375c8cb"},{"name":"XU ET AL., 2023","type":"PUBLICATION","description":"A publication by Xu et al. in 2023 related to Role Assignment","source_id":"7c08d98f503d722d7de13be55375c8cb"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"ADAS\">      <data key=\"d0\">RESEARCH AREA<\/data>      <data key=\"d1\">ADAS (Automated Design of Agentic Systems) is a proposed research area aimed at inventing novel building blocks and designing powerful agentic systems in an automated manner<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"AI-GENERATING ALGORITHMS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">AI-Generating Algorithms (AI-GAs) are a field of research focused on learning components in AI systems to replace handcrafted ones<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"AUTOML\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">AutoML is a field of research that aims to automate the process of machine learning model development<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"NEURAL ARCHITECTURE SEARCH\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Neural Architecture Search is a technique aimed at automating the design of neural network architectures<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"MAML\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">MAML (Model-Agnostic Meta-Learning) is a technique that allows \"learning to learn\" for better sample efficiency and generalizability<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"META-RL\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Meta-RL (Meta-Reinforcement Learning) is a technique that allows \"learning to learn\" for continuous learning of multiple tasks<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"POET\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">POET (Paired Open-Ended Trailblazer) is a technique aimed at generating learning environments in an open-ended manner<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"OMNI-EPIC\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">OMNI-EPIC is a technique that enables the generation of learning environments in an open-ended manner<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"FOUNDATION MODELS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Foundation Models (FMs) are large-scale models used to write code for various applications, including optimization algorithms and reinforcement learning<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"FUNSEARCH\">      <data key=\"d0\">TOOL<\/data>      <data key=\"d1\">FunSearch is a tool where Foundation Models write code to discover better optimization algorithms<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"EOH\">      <data key=\"d0\">TOOL<\/data>      <data key=\"d1\">EoH is a tool where Foundation Models write code to discover better optimization algorithms<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"DISCOPOP\">      <data key=\"d0\">TOOL<\/data>      <data key=\"d1\">DiscoPOP is a tool where Foundation Models program the loss function for preference learning in FM alignment training<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"EUREKA\">      <data key=\"d0\">TOOL<\/data>      <data key=\"d1\">Eureka is a tool that enables Foundation Models to write reward functions for reinforcement learning in robotics<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"LANGUAGE-TO-REWARD\">      <data key=\"d0\">TOOL<\/data>      <data key=\"d1\">Language-to-Reward is a tool that enables Foundation Models to write reward functions for reinforcement learning in robotics<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"CHAIN-OF-THOUGHT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Chain-of-Thought is a manually designed agent used for various tasks such as Math, Reading Comprehension, Multi-task, and Science<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"COT-SC\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">COT-SC is a manually designed agent used for various tasks such as Math, Reading Comprehension, Multi-task, and Science<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"SELF-REFINE\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Self-Refine is a manually designed agent used for various tasks such as Math, Reading Comprehension, Multi-task, and Science<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"LLM DEBATE\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">LLM Debate is a manually designed agent used for various tasks such as Math, Reading Comprehension, Multi-task, and Science<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"STEP-BACK ABSTRACTION\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Step-back Abstraction is a manually designed agent used for various tasks such as Math, Reading Comprehension, Multi-task, and Science<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"QUALITY-DIVERSITY\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Quality-Diversity is a manually designed agent used for various tasks such as Math, Reading Comprehension, Multi-task, and Science<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"ROLE ASSIGNMENT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Role Assignment is a manually designed agent used for various tasks such as Math, Reading Comprehension, Multi-task, and Science<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"DYNAMIC ROLE-PLAYING ARCHITECTURE\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Dynamic Role-Playing Architecture is a top agent discovered in the Math domain and transferred to non-math domains<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"STRUCTURED MULTIMODAL FEEDBACK LOOP\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Structured Multimodal Feedback Loop is a top agent discovered in the Math domain and transferred to non-math domains<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"INTERACTIVE MULTIMODAL FEEDBACK LOOP\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Interactive Multimodal Feedback Loop is a top agent discovered in the Math domain and transferred to non-math domains<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"CLUNE, 2019\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Clune in 2019 related to AI-Generating Algorithms<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"HUTTER ET AL., 2019\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Hutter et al. in 2019 related to AutoML<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"ELSKEN ET AL., 2019\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Elsken et al. in 2019 related to Neural Architecture Search<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"HU ET AL., 2021\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Hu et al. in 2021 related to Neural Architecture Search<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"LU ET AL., 2019\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Lu et al. in 2019 related to Neural Architecture Search<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"FINN ET AL., 2017\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Finn et al. in 2017 related to MAML<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"DUAN ET AL., 2017\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Duan et al. in 2017 related to Meta-RL<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"NORMAN &amp; CLUNE, 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Norman &amp; Clune in 2023 related to Meta-RL<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"WANG ET AL., 2016\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Wang et al. in 2016 related to Meta-RL<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"ZINTGRAF ET AL., 2021A\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Zintgraf et al. in 2021 related to Meta-RL<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"ZINTGRAF ET AL., 2021B\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Zintgraf et al. in 2021 related to Meta-RL<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"DHARNA ET AL., 2020\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Dharna et al. in 2020 related to POET<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"WANG ET AL., 2019\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Wang et al. in 2019 related to POET<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"WANG ET AL., 2020\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Wang et al. in 2020 related to POET<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"FALDOR ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Faldor et al. in 2024 related to OMNI-EPIC<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"ROMERA-PAREDES ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Romera-Paredes et al. in 2024 related to FunSearch<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"LIU ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Liu et al. in 2024 related to EoH<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"LU ET AL., 2024A\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Lu et al. in 2024 related to DiscoPOP<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"RAFAILOV ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Rafailov et al. in 2024 related to FM alignment training<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"MA ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Ma et al. in 2023 related to Eureka<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"YU ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Yu et al. in 2023 related to language-to-reward<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"WEI ET AL., 2022\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Wei et al. in 2022 related to Chain-of-Thought<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"WANG ET AL., 2023B\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Wang et al. in 2023 related to COT-SC<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"MADAAN ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Madaan et al. in 2024 related to Self-Refine<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"DU ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Du et al. in 2023 related to LLM Debate<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"ZHENG ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Zheng et al. in 2023 related to Step-back Abstraction<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"LU ET AL., 2024C\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Lu et al. in 2024 related to Quality-Diversity<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <node id=\"XU ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Xu et al. in 2023 related to Role Assignment<\/data>      <data key=\"d2\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/node>    <edge source=\"ADAS\" target=\"AI-GENERATING ALGORITHMS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">ADAS aims to invent novel building blocks and design powerful agentic systems, which aligns with the goals of AI-Generating Algorithms<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"AUTOML\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">ADAS aims to invent novel building blocks and design powerful agentic systems, which aligns with the goals of AutoML<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"AI-GENERATING ALGORITHMS\" target=\"NEURAL ARCHITECTURE SEARCH\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Neural Architecture Search is a technique under the first pillar of AI-Generating Algorithms<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"AI-GENERATING ALGORITHMS\" target=\"MAML\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">MAML is a technique under the second pillar of AI-Generating Algorithms<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"AI-GENERATING ALGORITHMS\" target=\"META-RL\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Meta-RL is a technique under the second pillar of AI-Generating Algorithms<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"AI-GENERATING ALGORITHMS\" target=\"POET\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">POET is a technique under the third pillar of AI-Generating Algorithms<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"AI-GENERATING ALGORITHMS\" target=\"OMNI-EPIC\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">OMNI-EPIC is a technique under the third pillar of AI-Generating Algorithms<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"AI-GENERATING ALGORITHMS\" target=\"CLUNE, 2019\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Clune in 2019 is related to AI-Generating Algorithms<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"AUTOML\" target=\"HUTTER ET AL., 2019\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Hutter et al. in 2019 is related to AutoML<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"NEURAL ARCHITECTURE SEARCH\" target=\"ELSKEN ET AL., 2019\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Elsken et al. in 2019 is related to Neural Architecture Search<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"NEURAL ARCHITECTURE SEARCH\" target=\"HU ET AL., 2021\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Hu et al. in 2021 is related to Neural Architecture Search<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"NEURAL ARCHITECTURE SEARCH\" target=\"LU ET AL., 2019\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Lu et al. in 2019 is related to Neural Architecture Search<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"MAML\" target=\"FINN ET AL., 2017\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Finn et al. in 2017 is related to MAML<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"META-RL\" target=\"DUAN ET AL., 2017\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Duan et al. in 2017 is related to Meta-RL<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"META-RL\" target=\"NORMAN &amp; CLUNE, 2023\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Norman &amp; Clune in 2023 is related to Meta-RL<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"META-RL\" target=\"WANG ET AL., 2016\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Wang et al. in 2016 is related to Meta-RL<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"META-RL\" target=\"ZINTGRAF ET AL., 2021A\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Zintgraf et al. in 2021 is related to Meta-RL<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"META-RL\" target=\"ZINTGRAF ET AL., 2021B\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Zintgraf et al. in 2021 is related to Meta-RL<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"POET\" target=\"DHARNA ET AL., 2020\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Dharna et al. in 2020 is related to POET<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"POET\" target=\"WANG ET AL., 2019\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Wang et al. in 2019 is related to POET<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"POET\" target=\"WANG ET AL., 2020\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Wang et al. in 2020 is related to POET<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"OMNI-EPIC\" target=\"FOUNDATION MODELS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">OMNI-EPIC enables Foundation Models to create robotics learning environments<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"OMNI-EPIC\" target=\"FALDOR ET AL., 2024\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Faldor et al. in 2024 is related to OMNI-EPIC<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"FOUNDATION MODELS\" target=\"FUNSEARCH\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">FunSearch uses Foundation Models to write code for discovering better optimization algorithms<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"FOUNDATION MODELS\" target=\"EOH\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">EoH uses Foundation Models to write code for discovering better optimization algorithms<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"FOUNDATION MODELS\" target=\"DISCOPOP\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">DiscoPOP uses Foundation Models to program the loss function for preference learning<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"FOUNDATION MODELS\" target=\"EUREKA\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Eureka uses Foundation Models to write reward functions for reinforcement learning in robotics<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"FOUNDATION MODELS\" target=\"LANGUAGE-TO-REWARD\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Language-to-Reward uses Foundation Models to write reward functions for reinforcement learning in robotics<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"FUNSEARCH\" target=\"ROMERA-PAREDES ET AL., 2024\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Romera-Paredes et al. in 2024 is related to FunSearch<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"EOH\" target=\"LIU ET AL., 2024\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Liu et al. in 2024 is related to EoH<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"DISCOPOP\" target=\"LU ET AL., 2024A\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Lu et al. in 2024 is related to DiscoPOP<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"DISCOPOP\" target=\"RAFAILOV ET AL., 2024\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Rafailov et al. in 2024 is related to FM alignment training, which is part of DiscoPOP<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"EUREKA\" target=\"MA ET AL., 2023\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Ma et al. in 2023 is related to Eureka<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"LANGUAGE-TO-REWARD\" target=\"YU ET AL., 2023\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Yu et al. in 2023 is related to language-to-reward<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT\" target=\"WEI ET AL., 2022\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Wei et al. in 2022 is related to Chain-of-Thought<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"COT-SC\" target=\"WANG ET AL., 2023B\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Wang et al. in 2023 is related to COT-SC<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"SELF-REFINE\" target=\"MADAAN ET AL., 2024\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Madaan et al. in 2024 is related to Self-Refine<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"LLM DEBATE\" target=\"DU ET AL., 2023\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Du et al. in 2023 is related to LLM Debate<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"STEP-BACK ABSTRACTION\" target=\"ZHENG ET AL., 2023\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Zheng et al. in 2023 is related to Step-back Abstraction<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"QUALITY-DIVERSITY\" target=\"LU ET AL., 2024C\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">The publication by Lu et al. in 2024 is related to Quality-Diversity<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>    <edge source=\"ROLE ASSIGNMENT\" target=\"XU ET AL., 2023\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The publication by Xu et al. in 2023 is related to Role Assignment<\/data>      <data key=\"d5\">7c08d98f503d722d7de13be55375c8cb<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"dc55f071b95dec721a9820d39cdb3ccd","chunk":"a), FMs\nprogram the loss function for preference learning in FM alignment training (Rafailov et al., 2024).\nAdditionally, Eureka (Ma et al., 2023) and language-to-reward (Yu et al., 2023) enable FMs to write\nreward functions for reinforcement learning in robotics. Finally, OMNI-EPIC (Faldor et al., 2024)\nenables FMs to create robotics learning environments by programming in code. Here, we adopt a\nsimilar idea that enables FMs to program new agents in code.\nExisting Attempts to ADAS. There are two categories of works that can be considered attempts at\nADAS in the literature: those that learn better prompts only, and those that learn more components\nin agents than just prompts. Most works fall into the first category: learning prompts only. Works like\nOPRO (Yang et al., 2024), PromptBreeder (Fernando et al., 2024), and Self-Discover (Zhou et al.,\n2024a) adopt FMs to automate prompt engineering for agents, primarily focusing on the phrasing of\ninstructions in the prompt to enhance the reasoning capability of agents. Thus, the learned prompts\nare domain-specific and difficult to generalize. Beyond instructions, works like EvoAgent (Yuan\net al., 2024) and AgentVerse (Chen et al., 2023b) optimize role definition in the prompt, as assigning\npersonas or roles to agents has been shown to be beneficial (Xu et al., 2023). Although tuning prompts\neffectively improves performance, other important components in agentic systems remain fixed and\nhand-designed, vastly limiting the space of agents that can be discovered.\nThere are far fewer attempts in the second category, which involves learning more components\nthan just prompts in agentic systems. Most represent agents as networks or graphs in the search\nspace. In these formulations, the FM with a certain prompt is considered a transformation function\nfor text on nodes, and the information flow of the text is considered as edges. DyLAN (Liu et al.,\n11Automated Design of Agentic Systems\n2023) starts with a fully connected feed-forward network and uses FMs to score the response quality\nof nodes in each layer to prune the connections. DSPy (Khattab et al., 2024) first generates a set\nof possible nodes and then optimizes across the Cartesian product of these nodes while optimizing\nthe few-shot examples for nodes. GPT-Swarm (Zhuge et al., 2024) represents an agentic system in\na graph with a predefined set of nodes and uses a Reinforcement Learning algorithm to optimize\nthe possible connections between nodes while optimizing the prompt for each node in a separate\nstage. Although these works allow the learning of control flow (optimizing edges in networks or\ngraphs), many other components, such as whether and which tools to learn or even how many nodes\nto have, are still not learned, greatly limiting the space of agents that can be discovered. Besides\nlearning prompts and control flow, AgentOptimizer (Zhang et al., 2024b) learns the tools used in\nagents, and Agent Symbolic Learning (Zhou et al., 2024b) learns prompts, tools, and control flow\ntogether. While Agent Symbolic Learning shares similar motivations to learn more components in\nagents, it manually designs the search space for each component separately, which may make it a\nharder search space for search algorithms. In addition, it mainly improves agents based on an existing\ncomplex agent, without showing the emergence of new design patterns or building blocks. In contrast,\nour work represents all possible components in code, allowing the search to be easier by leveraging\nhuman efforts in the existing codebase of agents and FMs\u2019 expertise in coding. We also demonstrate\nhow novel and diverse building blocks and design patterns emerge from a set of basic agent designs,\nillustrating the potential creativity that can emerge from ADAS.\n6. Discussion and Conclusion\nSafety Considerations. We strongly advise researchers to be aware of the safety concerns\nwhen executing untrusted model-generated code in Meta Agent Search and other research\ninvolvingcodegeneration. While it is highly unlikely that model-generated code will perform overtly\nmaliciousactionsinourcurrentsettingsandwiththeFoundationModels(FMs)weuse, suchcodemay\nstill act destructively due to limitations in model capability or alignment (Chen et al., 2021; Rokon\net al., 2020). Ideally, sandbox environments can be used to safely run untrusted model-generated\ncode (Chen et al., 2021; Yee et al., 2010).\nMore broadly, research on more powerful AI systems raises the question of whether we should\nbe conducting research to advance AI capabilities at all. That topic clearly includes the proposed\nAutomatedDesignofAgenticSystems(ADAS)asanewareainAI-GAresearch, whichcouldpotentially\ncontribute to an even faster way to create Artificial General Intelligence (AGI) than the current manual\napproach (Clune, 2019). The question of whether and why we should pursue AGI and AI-GA has\nbeen discussed in many papers (Bengio et al., 2024; Bostrom, 2002; Clune, 2019; Ecoffet et al., 2020;\nYudkowsky et al., 2008), and is beyond the scope of this paper. Specifically as regards ADAS, we\nbelieve it is net beneficial to publish this work. First, this work demonstrates that with the available\nAPI access to powerful FMs, it is easy to program powerful ADAS algorithms, and do so without any\nexp","chunk_id":"dc55f071b95dec721a9820d39cdb3ccd","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"EUREKA","type":"TOOL\/TECHNOLOGY","description":"Eureka is a tool that enables FMs to write reward functions for reinforcement learning in robotics","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"LANGUAGE-TO-REWARD","type":"TOOL\/TECHNOLOGY","description":"Language-to-reward is a tool that enables FMs to write reward functions for reinforcement learning in robotics","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"OMNI-EPIC","type":"TOOL\/TECHNOLOGY","description":"OMNI-EPIC enables FMs to create robotics learning environments by programming in code","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"ADAS","type":"CONCEPT","description":"Automated Design of Agentic Systems (ADAS) involves learning more components in agents than just prompts","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"OPRO","type":"TOOL\/TECHNOLOGY","description":"OPRO adopts FMs to automate prompt engineering for agents, focusing on the phrasing of instructions in the prompt to enhance reasoning capability","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"PROMPTBREEDER","type":"TOOL\/TECHNOLOGY","description":"PromptBreeder adopts FMs to automate prompt engineering for agents, focusing on the phrasing of instructions in the prompt to enhance reasoning capability","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"SELF-DISCOVER","type":"TOOL\/TECHNOLOGY","description":"Self-Discover adopts FMs to automate prompt engineering for agents, focusing on the phrasing of instructions in the prompt to enhance reasoning capability","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"EVOAGENT","type":"TOOL\/TECHNOLOGY","description":"EvoAgent optimizes role definition in the prompt, assigning personas or roles to agents","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"AGENTVERSE","type":"TOOL\/TECHNOLOGY","description":"AgentVerse optimizes role definition in the prompt, assigning personas or roles to agents","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"DYLAN","type":"TOOL\/TECHNOLOGY","description":"DyLAN uses FMs to score the response quality of nodes in each layer to prune the connections in a fully connected feed-forward network","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"DSPY","type":"TOOL\/TECHNOLOGY","description":"DSPy generates a set of possible nodes and optimizes across the Cartesian product of these nodes while optimizing the few-shot examples for nodes","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"GPT-SWARM","type":"TOOL\/TECHNOLOGY","description":"GPT-Swarm represents an agentic system in a graph with a predefined set of nodes and uses a Reinforcement Learning algorithm to optimize the possible connections between nodes","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"AGENTOPTIMIZER","type":"TOOL\/TECHNOLOGY","description":"AgentOptimizer learns the tools used in agents","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"AGENT SYMBOLIC LEARNING","type":"TOOL\/TECHNOLOGY","description":"Agent Symbolic Learning learns prompts, tools, and control flow together in agents","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"META AGENT SEARCH","type":"TOOL\/TECHNOLOGY","description":"Meta Agent Search involves executing untrusted model-generated code and raises safety concerns","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"AGI","type":"CONCEPT","description":"Artificial General Intelligence (AGI) is a concept in AI research that involves creating highly autonomous systems with general intelligence","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"AI-GA","type":"CONCEPT","description":"AI-GA refers to AI Generative Algorithms, which could potentially contribute to creating AGI faster than the current manual approach","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"BENGIO ET AL., 2024","type":"PUBLICATION","description":"A paper discussing the pursuit of AGI and AI-GA","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"BOSTROM, 2002","type":"PUBLICATION","description":"A paper discussing the pursuit of AGI and AI-GA","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"CLUNE, 2019","type":"PUBLICATION","description":"A paper discussing the pursuit of AGI and AI-GA","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"ECOFFET ET AL., 2020","type":"PUBLICATION","description":"A paper discussing the pursuit of AGI and AI-GA","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"YUDKOWSKY ET AL., 2008","type":"PUBLICATION","description":"A paper discussing the pursuit of AGI and AI-GA","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"CHEN ET AL., 2021","type":"PUBLICATION","description":"A paper discussing safety concerns when executing untrusted model-generated code","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"ROKON ET AL., 2020","type":"PUBLICATION","description":"A paper discussing safety concerns when executing untrusted model-generated code","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"YEE ET AL., 2010","type":"PUBLICATION","description":"A paper discussing the use of sandbox environments to safely run untrusted model-generated code","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"FMS","type":"","description":"","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"MA ET AL., 2023","type":"PUBLICATION","description":"A paper discussing Eureka and its application in enabling FMs to write reward functions for reinforcement learning in robotics","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"YU ET AL., 2023","type":"PUBLICATION","description":"A paper discussing language-to-reward and its application in enabling FMs to write reward functions for reinforcement learning in robotics","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"FALDOR ET AL., 2024","type":"PUBLICATION","description":"A paper discussing OMNI-EPIC and its application in enabling FMs to create robotics learning environments by programming in code","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"YANG ET AL., 2024","type":"PUBLICATION","description":"A paper discussing OPRO and its application in automating prompt engineering for agents","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"FERNANDO ET AL., 2024","type":"PUBLICATION","description":"A paper discussing PromptBreeder and its application in automating prompt engineering for agents","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"ZHOU ET AL., 2024A","type":"PUBLICATION","description":"A paper discussing Self-Discover and its application in automating prompt engineering for agents","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"YUAN ET AL., 2024","type":"PUBLICATION","description":"A paper discussing EvoAgent and its application in optimizing role definition in the prompt","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"CHEN ET AL., 2023B","type":"PUBLICATION","description":"A paper discussing AgentVerse and its application in optimizing role definition in the prompt","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"XU ET AL., 2023","type":"PUBLICATION","description":"A paper discussing the benefits of assigning personas or roles to agents","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"LIU ET AL., 2023","type":"PUBLICATION","description":"A paper discussing DyLAN and its application in using FMs to score the response quality of nodes in each layer to prune the connections","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"KHATTAB ET AL., 2024","type":"PUBLICATION","description":"A paper discussing DSPy and its application in generating a set of possible nodes and optimizing across the Cartesian product of these nodes","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"ZHUGE ET AL., 2024","type":"PUBLICATION","description":"A paper discussing GPT-Swarm and its application in representing an agentic system in a graph with a predefined set of nodes","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"ZHANG ET AL., 2024B","type":"PUBLICATION","description":"A paper discussing AgentOptimizer and its application in learning the tools used in agents","source_id":"dc55f071b95dec721a9820d39cdb3ccd"},{"name":"ZHOU ET AL., 2024B","type":"PUBLICATION","description":"A paper discussing Agent Symbolic Learning and its application in learning prompts, tools, and control flow together in agents","source_id":"dc55f071b95dec721a9820d39cdb3ccd"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"EUREKA\">      <data key=\"d0\">TOOL\/TECHNOLOGY<\/data>      <data key=\"d1\">Eureka is a tool that enables FMs to write reward functions for reinforcement learning in robotics<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"LANGUAGE-TO-REWARD\">      <data key=\"d0\">TOOL\/TECHNOLOGY<\/data>      <data key=\"d1\">Language-to-reward is a tool that enables FMs to write reward functions for reinforcement learning in robotics<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"OMNI-EPIC\">      <data key=\"d0\">TOOL\/TECHNOLOGY<\/data>      <data key=\"d1\">OMNI-EPIC enables FMs to create robotics learning environments by programming in code<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"ADAS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Automated Design of Agentic Systems (ADAS) involves learning more components in agents than just prompts<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"OPRO\">      <data key=\"d0\">TOOL\/TECHNOLOGY<\/data>      <data key=\"d1\">OPRO adopts FMs to automate prompt engineering for agents, focusing on the phrasing of instructions in the prompt to enhance reasoning capability<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"PROMPTBREEDER\">      <data key=\"d0\">TOOL\/TECHNOLOGY<\/data>      <data key=\"d1\">PromptBreeder adopts FMs to automate prompt engineering for agents, focusing on the phrasing of instructions in the prompt to enhance reasoning capability<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"SELF-DISCOVER\">      <data key=\"d0\">TOOL\/TECHNOLOGY<\/data>      <data key=\"d1\">Self-Discover adopts FMs to automate prompt engineering for agents, focusing on the phrasing of instructions in the prompt to enhance reasoning capability<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"EVOAGENT\">      <data key=\"d0\">TOOL\/TECHNOLOGY<\/data>      <data key=\"d1\">EvoAgent optimizes role definition in the prompt, assigning personas or roles to agents<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"AGENTVERSE\">      <data key=\"d0\">TOOL\/TECHNOLOGY<\/data>      <data key=\"d1\">AgentVerse optimizes role definition in the prompt, assigning personas or roles to agents<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"DYLAN\">      <data key=\"d0\">TOOL\/TECHNOLOGY<\/data>      <data key=\"d1\">DyLAN uses FMs to score the response quality of nodes in each layer to prune the connections in a fully connected feed-forward network<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"DSPY\">      <data key=\"d0\">TOOL\/TECHNOLOGY<\/data>      <data key=\"d1\">DSPy generates a set of possible nodes and optimizes across the Cartesian product of these nodes while optimizing the few-shot examples for nodes<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"GPT-SWARM\">      <data key=\"d0\">TOOL\/TECHNOLOGY<\/data>      <data key=\"d1\">GPT-Swarm represents an agentic system in a graph with a predefined set of nodes and uses a Reinforcement Learning algorithm to optimize the possible connections between nodes<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"AGENTOPTIMIZER\">      <data key=\"d0\">TOOL\/TECHNOLOGY<\/data>      <data key=\"d1\">AgentOptimizer learns the tools used in agents<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"AGENT SYMBOLIC LEARNING\">      <data key=\"d0\">TOOL\/TECHNOLOGY<\/data>      <data key=\"d1\">Agent Symbolic Learning learns prompts, tools, and control flow together in agents<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"META AGENT SEARCH\">      <data key=\"d0\">TOOL\/TECHNOLOGY<\/data>      <data key=\"d1\">Meta Agent Search involves executing untrusted model-generated code and raises safety concerns<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"AGI\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Artificial General Intelligence (AGI) is a concept in AI research that involves creating highly autonomous systems with general intelligence<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"AI-GA\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">AI-GA refers to AI Generative Algorithms, which could potentially contribute to creating AGI faster than the current manual approach<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"BENGIO ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper discussing the pursuit of AGI and AI-GA<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"BOSTROM, 2002\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper discussing the pursuit of AGI and AI-GA<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"CLUNE, 2019\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper discussing the pursuit of AGI and AI-GA<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"ECOFFET ET AL., 2020\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper discussing the pursuit of AGI and AI-GA<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"YUDKOWSKY ET AL., 2008\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper discussing the pursuit of AGI and AI-GA<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"CHEN ET AL., 2021\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper discussing safety concerns when executing untrusted model-generated code<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"ROKON ET AL., 2020\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper discussing safety concerns when executing untrusted model-generated code<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"YEE ET AL., 2010\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper discussing the use of sandbox environments to safely run untrusted model-generated code<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"FMS\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"MA ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper discussing Eureka and its application in enabling FMs to write reward functions for reinforcement learning in robotics<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"YU ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper discussing language-to-reward and its application in enabling FMs to write reward functions for reinforcement learning in robotics<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"FALDOR ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper discussing OMNI-EPIC and its application in enabling FMs to create robotics learning environments by programming in code<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"YANG ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper discussing OPRO and its application in automating prompt engineering for agents<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"FERNANDO ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper discussing PromptBreeder and its application in automating prompt engineering for agents<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"ZHOU ET AL., 2024A\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper discussing Self-Discover and its application in automating prompt engineering for agents<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"YUAN ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper discussing EvoAgent and its application in optimizing role definition in the prompt<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"CHEN ET AL., 2023B\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper discussing AgentVerse and its application in optimizing role definition in the prompt<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"XU ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper discussing the benefits of assigning personas or roles to agents<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"LIU ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper discussing DyLAN and its application in using FMs to score the response quality of nodes in each layer to prune the connections<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"KHATTAB ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper discussing DSPy and its application in generating a set of possible nodes and optimizing across the Cartesian product of these nodes<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"ZHUGE ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper discussing GPT-Swarm and its application in representing an agentic system in a graph with a predefined set of nodes<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"ZHANG ET AL., 2024B\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper discussing AgentOptimizer and its application in learning the tools used in agents<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <node id=\"ZHOU ET AL., 2024B\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A paper discussing Agent Symbolic Learning and its application in learning prompts, tools, and control flow together in agents<\/data>      <data key=\"d2\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/node>    <edge source=\"EUREKA\" target=\"MA ET AL., 2023\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Ma et al., 2023 discusses Eureka and its application in enabling FMs to write reward functions for reinforcement learning in robotics<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"LANGUAGE-TO-REWARD\" target=\"FMS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Language-to-reward enables FMs to write reward functions for reinforcement learning in robotics<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"LANGUAGE-TO-REWARD\" target=\"YU ET AL., 2023\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Yu et al., 2023 discusses language-to-reward and its application in enabling FMs to write reward functions for reinforcement learning in robotics<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"OMNI-EPIC\" target=\"FMS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">OMNI-EPIC enables FMs to create robotics learning environments by programming in code<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"OMNI-EPIC\" target=\"FALDOR ET AL., 2024\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Faldor et al., 2024 discusses OMNI-EPIC and its application in enabling FMs to create robotics learning environments by programming in code<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"OPRO\" target=\"PROMPTBREEDER\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Both OPRO and PromptBreeder adopt FMs to automate prompt engineering for agents<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"OPRO\" target=\"SELF-DISCOVER\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Both OPRO and Self-Discover adopt FMs to automate prompt engineering for agents<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"OPRO\" target=\"YANG ET AL., 2024\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Yang et al., 2024 discusses OPRO and its application in automating prompt engineering for agents<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"PROMPTBREEDER\" target=\"SELF-DISCOVER\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Both PromptBreeder and Self-Discover adopt FMs to automate prompt engineering for agents<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"PROMPTBREEDER\" target=\"FERNANDO ET AL., 2024\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Fernando et al., 2024 discusses PromptBreeder and its application in automating prompt engineering for agents<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"SELF-DISCOVER\" target=\"ZHOU ET AL., 2024A\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Zhou et al., 2024a discusses Self-Discover and its application in automating prompt engineering for agents<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"EVOAGENT\" target=\"AGENTVERSE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Both EvoAgent and AgentVerse optimize role definition in the prompt<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"EVOAGENT\" target=\"YUAN ET AL., 2024\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Yuan et al., 2024 discusses EvoAgent and its application in optimizing role definition in the prompt<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"AGENTVERSE\" target=\"CHEN ET AL., 2023B\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Chen et al., 2023b discusses AgentVerse and its application in optimizing role definition in the prompt<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"AGENTVERSE\" target=\"XU ET AL., 2023\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Xu et al., 2023 discusses the benefits of assigning personas or roles to agents, which is a concept used in AgentVerse<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"DYLAN\" target=\"DSPY\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Both DyLAN and DSPy involve learning more components than just prompts in agentic systems<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"DYLAN\" target=\"GPT-SWARM\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Both DyLAN and GPT-Swarm involve learning more components than just prompts in agentic systems<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"DYLAN\" target=\"LIU ET AL., 2023\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Liu et al., 2023 discusses DyLAN and its application in using FMs to score the response quality of nodes in each layer to prune the connections<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"DSPY\" target=\"GPT-SWARM\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Both DSPy and GPT-Swarm involve learning more components than just prompts in agentic systems<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"DSPY\" target=\"KHATTAB ET AL., 2024\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Khattab et al., 2024 discusses DSPy and its application in generating a set of possible nodes and optimizing across the Cartesian product of these nodes<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"GPT-SWARM\" target=\"ZHUGE ET AL., 2024\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Zhuge et al., 2024 discusses GPT-Swarm and its application in representing an agentic system in a graph with a predefined set of nodes<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"AGENTOPTIMIZER\" target=\"AGENT SYMBOLIC LEARNING\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Both AgentOptimizer and Agent Symbolic Learning learn tools used in agents<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"AGENTOPTIMIZER\" target=\"ZHANG ET AL., 2024B\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Zhang et al., 2024b discusses AgentOptimizer and its application in learning the tools used in agents<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"AGENT SYMBOLIC LEARNING\" target=\"ZHOU ET AL., 2024B\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Zhou et al., 2024b discusses Agent Symbolic Learning and its application in learning prompts, tools, and control flow together in agents<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"CHEN ET AL., 2021\">      <data key=\"d3\">16.0<\/data>      <data key=\"d4\">Chen et al., 2021 discusses safety concerns when executing untrusted model-generated code in Meta Agent Search<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"ROKON ET AL., 2020\">      <data key=\"d3\">16.0<\/data>      <data key=\"d4\">Rokon et al., 2020 discusses safety concerns when executing untrusted model-generated code in Meta Agent Search<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"YEE ET AL., 2010\">      <data key=\"d3\">16.0<\/data>      <data key=\"d4\">Yee et al., 2010 discusses the use of sandbox environments to safely run untrusted model-generated code in Meta Agent Search<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"AGI\" target=\"AI-GA\">      <data key=\"d3\">16.0<\/data>      <data key=\"d4\">AI-GA could potentially contribute to creating AGI faster than the current manual approach<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"AGI\" target=\"BENGIO ET AL., 2024\">      <data key=\"d3\">14.0<\/data>      <data key=\"d4\">Bengio et al., 2024 discusses the pursuit of AGI<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"AGI\" target=\"BOSTROM, 2002\">      <data key=\"d3\">14.0<\/data>      <data key=\"d4\">Bostrom, 2002 discusses the pursuit of AGI<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"AGI\" target=\"CLUNE, 2019\">      <data key=\"d3\">14.0<\/data>      <data key=\"d4\">Clune, 2019 discusses the pursuit of AGI<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"AGI\" target=\"ECOFFET ET AL., 2020\">      <data key=\"d3\">14.0<\/data>      <data key=\"d4\">Ecoffet et al., 2020 discusses the pursuit of AGI<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>    <edge source=\"AGI\" target=\"YUDKOWSKY ET AL., 2008\">      <data key=\"d3\">2.0<\/data>      <data key=\"d4\">Yudkowsky et al., 2008 discusses the pursuit of AGI<\/data>      <data key=\"d5\">dc55f071b95dec721a9820d39cdb3ccd<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"6bdf681c0bd9e401ac72344a6a0ae479","chunk":"; Bostrom, 2002; Clune, 2019; Ecoffet et al., 2020;\nYudkowsky et al., 2008), and is beyond the scope of this paper. Specifically as regards ADAS, we\nbelieve it is net beneficial to publish this work. First, this work demonstrates that with the available\nAPI access to powerful FMs, it is easy to program powerful ADAS algorithms, and do so without any\nexpensive hardware like GPUs. We feel it is beneficial to let the community know such algorithms are\npowerful and easy to create, so they can be informed and account for them. Moreover, by sharing this\ninformation, we hope to motivate follow-up work into safe-ADAS, such as algorithms that conduct\nADAS safely during both search itself (e.g. not risking running any harmful code) and that refuse\nto create dishonest, unhelpful, and\/or harmful agents. Such an open-source research approach to\ncreate safe-ADAS could be a better way to create safer AI systems (Caldwell, 2011; Meta, 2024). One\ndirection we find particularly promising is to simply ask the Meta Agent Search algorithm to be safe\nduring training and only create helpful, harmless, honest agents, potentially incorporating ideas such\nas Constitutional AI (Bai et al., 2022).\n12Automated Design of Agentic Systems\nFuture Work. Our work also opens up many future research directions. For example:\n\u2022Higher-order ADAS. Since the meta agent used in ADAS to program new agents in code is also\nan agent, ADAS can become self-referential where the meta agent can be improved through ADAS\nas well. It would be an exciting direction to have a higher order of meta-learning to allow the\nlearning of the meta agent and even the meta-meta agent, etc. (Lu et al., 2023)\n\u2022Seeding ADAS with more existing building blocks. Although we can theoretically allow any\ncomponents in agentic systems to be programmed from scratch in the code space, it is not efficient\nin practice. Therefore, it would be interesting to explore ADAS by standing on the shoulders of\nexisting human efforts, such as search engine tools, RAG (Lewis et al., 2020), or functions from\nexisting agent frameworks like LangChain (LangChainAI, 2022). Additionally, it is interesting\nto support multi-modal capabilities (e.g. vision) in FMs or allow different FMs to be available in\nagentic systems. This will enable the meta agent to choose from different FMs flexibly according to\nthe difficulty of the instruction and whether data privacy is a priority.\n\u2022Multi-objective ADAS. We only consider one objective (i.e., performance) to optimize in this\npaper, but in practice, multiple objectives are often considered, such as cost, latency, and robustness\nof agentic systems (Hu et al., 2021; Huang et al., 2023). Thus, integrating multi-objective search\nalgorithms (Deb et al., 2002) in ADAS could be promising.\n\u2022Novelty search algorithms. In Meta Agent Search, the design of the search algorithm is rel-\natively simple, focusing solely on exploring interesting new designs. A more careful design of\nthe search algorithm can be a promising future direction. For example, one could incorporate\nmore sophisticated ideas from Quality-Diversity (Cully & Demiris, 2017; Mouret & Clune, 2015),\nAI-generating (Clune, 2019), and Open-ended Algorithms (Faldor et al., 2024; Stanley & Lehman,\n2015; Stanley et al., 2019; Zhang et al., 2024a). One could also include more classic approaches\nto balance exploration and exploitation (Liu et al., 2024; Sutton & Barto, 2018).\n\u2022More intelligent evaluation functions. In this work, we simply evaluate discovered agents on the\nevaluation set and use the numerical performance results. However, this approach is both expensive\nand misses a lot of information. A promising future direction is to enable the meta agent to analyze\ndetailed running logs during the evaluation, which contain rich information on the failure and\nsuccess modes for better debugging and improving agentic systems (Zhou et al., 2024b). Also,\nmany tasks involve subjective answer evaluations (Chiang et al., 2024; Lu et al., 2024b) that do\nnot have ground-truth answers. It is also important to design novel evaluation functions in ADAS\nto address these tasks. Finally, in this work, we targeted only one domain during the search. It\nwould be interesting to explore whether ADAS algorithms can design even better generalist agents\nwhen specifically searching for agents capable of performing well across multiple domains.\n\u2022More complex domains. Additionally, we only evaluate Meta Agent Search on single-step QA\ntasks in this paper. It would be interesting to extend the method to more complex domians, such\nas real-world applications involving multi-step interaction with complex environments.\n\u2022Understanding the emergence of complexity from human organizations. Beyond potentially\nsaving researchers\u2019 efforts and improving upon the manual design of agentic systems, the research\nin ADAS is also scientifically intriguing as it sheds light on the origins of complexity emerging from\nhuman organization and society. The agentic system is a machine learning system that operates\nprimarily over natural language\u2014a representation that is interpretable to humans and used by\nhumans in constructing our organization and society. Thus, there is a close connection between\nagentic systems and human organizations, as shown in works incorporating the organizational\nstructure for human companies in agents (Hong et al., 2023) or","chunk_id":"6bdf681c0bd9e401ac72344a6a0ae479","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"BOSTROM","type":"PERSON","description":"Bostrom is an author referenced in the context of discussions beyond the scope of the paper","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PERSON"},{"name":"CLUNE","type":"PERSON","description":"Clune is an author referenced in the context of discussions beyond the scope of the paper","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PERSON"},{"name":"ECOFFET ET AL.","type":"PERSON","description":"Ecoffet et al. are authors referenced in the context of discussions beyond the scope of the paper","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PERSON"},{"name":"YUDKOWSKY ET AL.","type":"PERSON","description":"Yudkowsky et al. are authors referenced in the context of discussions beyond the scope of the paper","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PERSON"},{"name":"ADAS","type":"TECHNOLOGY","description":"ADAS stands for Automated Design of Agentic Systems, which are algorithms that can be programmed using powerful FMs without expensive hardware","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"API","type":"TECHNOLOGY","description":"API access to powerful FMs is used to program ADAS algorithms","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"SAFE-ADAS","type":"TECHNOLOGY","description":"Safe-ADAS refers to algorithms that conduct ADAS safely, avoiding harmful code and creating honest, helpful agents","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"META AGENT SEARCH","type":"TECHNOLOGY","description":"Meta Agent Search is an algorithm that can be asked to be safe during training and create helpful, harmless, honest agents","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"CONSTITUTIONAL AI","type":"TECHNOLOGY","description":"Constitutional AI is an idea that can be incorporated into Meta Agent Search to ensure the creation of safe agents","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"HIGHER-ORDER ADAS","type":"TECHNOLOGY","description":"Higher-order ADAS refers to the concept of improving the meta agent through ADAS, allowing for meta-learning of the meta agent and beyond","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"RAG","type":"TECHNOLOGY","description":"RAG stands for Retrieval-Augmented Generation, a tool that can be used as a building block in ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"LANGCHAIN","type":"TECHNOLOGY","description":"LangChain is an existing agent framework that can provide functions for ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"MULTI-OBJECTIVE ADAS","type":"TECHNOLOGY","description":"Multi-objective ADAS refers to integrating multiple objectives like cost, latency, and robustness into ADAS algorithms","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"NOVELTY SEARCH ALGORITHMS","type":"TECHNOLOGY","description":"Novelty search algorithms focus on exploring new designs and can be incorporated into Meta Agent Search","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"QUALITY-DIVERSITY","type":"TECHNOLOGY","description":"Quality-Diversity is a concept that can be incorporated into the design of search algorithms for ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"AI-GENERATING","type":"TECHNOLOGY","description":"AI-generating refers to algorithms that can generate AI, a concept that can be incorporated into ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"OPEN-ENDED ALGORITHMS","type":"TECHNOLOGY","description":"Open-ended algorithms are designed to explore a wide range of possibilities and can be incorporated into ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"EVALUATION FUNCTIONS","type":"TECHNOLOGY","description":"Evaluation functions are used to assess the performance of discovered agents in ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"META AGENT","type":"TECHNOLOGY","description":"Meta agent is an agent used in ADAS to program new agents in code","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"MULTI-MODAL CAPABILITIES","type":"TECHNOLOGY","description":"Multi-modal capabilities refer to the ability to handle different types of data, such as vision, in FMs","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"META","type":"ORGANIZATION","description":"Meta is an organization mentioned in the context of open-source research for safe-ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"ORGANIZATION"},{"name":"CALDWELL","type":"PERSON","description":"Caldwell is an author referenced in the context of open-source research for safe-ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PERSON"},{"name":"BAI ET AL.","type":"PERSON","description":"Bai et al. are authors referenced in the context of Constitutional AI","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PERSON"},{"name":"LU ET AL.","type":"PERSON","description":"Lu et al. are authors referenced in the context of higher-order ADAS and subjective answer evaluations","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PERSON"},{"name":"LEWIS ET AL.","type":"PERSON","description":"Lewis et al. are authors referenced in the context of RAG","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PERSON"},{"name":"LANGCHAINAI","type":"ORGANIZATION","description":"LangChainAI is the organization behind the LangChain framework","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"ORGANIZATION"},{"name":"HU ET AL.","type":"PERSON","description":"Hu et al. are authors referenced in the context of multi-objective ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PERSON"},{"name":"HUANG ET AL.","type":"PERSON","description":"Huang et al. are authors referenced in the context of multi-objective ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PERSON"},{"name":"DEB ET AL.","type":"PERSON","description":"Deb et al. are authors referenced in the context of multi-objective search algorithms","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PERSON"},{"name":"CULLY & DEMIRIS","type":"PERSON","description":"Cully & Demiris are authors referenced in the context of Quality-Diversity","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PERSON"},{"name":"MOURET & CLUNE","type":"PERSON","description":"Mouret & Clune are authors referenced in the context of Quality-Diversity","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PERSON"},{"name":"FALDOR ET AL.","type":"PERSON","description":"Faldor et al. are authors referenced in the context of Open-ended Algorithms","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PERSON"},{"name":"STANLEY & LEHMAN","type":"PERSON","description":"Stanley & Lehman are authors referenced in the context of Open-ended Algorithms","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PERSON"},{"name":"STANLEY ET AL.","type":"PERSON","description":"Stanley et al. are authors referenced in the context of Open-ended Algorithms","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PERSON"},{"name":"ZHANG ET AL.","type":"PERSON","description":"Zhang et al. are authors referenced in the context of Open-ended Algorithms","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PERSON"},{"name":"LIU ET AL.","type":"PERSON","description":"Liu et al. are authors referenced in the context of balancing exploration and exploitation","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PERSON"},{"name":"SUTTON & BARTO","type":"PERSON","description":"Sutton & Barto are authors referenced in the context of balancing exploration and exploitation","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PERSON"},{"name":"ZHOU ET AL.","type":"PERSON","description":"Zhou et al. are authors referenced in the context of intelligent evaluation functions","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PERSON"},{"name":"CHIANG ET AL.","type":"PERSON","description":"Chiang et al. are authors referenced in the context of subjective answer evaluations","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PERSON"},{"name":"HONG ET AL.","type":"PERSON","description":"Hong et al. are authors referenced in the context of incorporating organizational structure in agents","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PERSON"},{"name":"AGENTIC SYSTEMS","type":"TECHNOLOGY","description":"Agentic systems are machine learning systems that operate primarily over natural language and are interpretable to humans","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"NATURAL LANGUAGE","type":"TECHNOLOGY","description":"Natural language is the representation used by agentic systems and humans in constructing organizations and society","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"HUMAN ORGANIZATIONS","type":"CONCEPT","description":"Human organizations are structures that can be incorporated into agentic systems to improve their design","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"CONCEPT"},{"name":"SOCIETY","type":"CONCEPT","description":"Society is the broader context in which human organizations and agentic systems operate","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"CONCEPT"},{"name":"COMPLEX DOMAINS","type":"CONCEPT","description":"Complex domains refer to real-world applications involving multi-step interaction with complex environments","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"CONCEPT"},{"name":"SINGLE-STEP QA TASKS","type":"CONCEPT","description":"Single-step QA tasks are the type of tasks on which Meta Agent Search is evaluated in the paper","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"CONCEPT"},{"name":"MULTIPLE DOMAINS","type":"CONCEPT","description":"Multiple domains refer to the capability of ADAS algorithms to design agents that perform well across various fields","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"CONCEPT"},{"name":"META-META AGENT","type":"TECHNOLOGY","description":"Meta-meta agent is a higher-order agent that can be learned through meta-learning in ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"BUILDING BLOCKS","type":"CONCEPT","description":"Building blocks refer to existing components that can be used to seed ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"CONCEPT"},{"name":"SEARCH ENGINE TOOLS","type":"TECHNOLOGY","description":"Search engine tools are existing human efforts that can be used as building blocks in ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"FM","type":"TECHNOLOGY","description":"FM stands for Foundation Models, which are used in ADAS to program agents","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"DATA PRIVACY","type":"CONCEPT","description":"Data privacy is a priority that can influence the choice of FMs in agentic systems","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"CONCEPT"},{"name":"PERFORMANCE","type":"CONCEPT","description":"Performance is the primary objective considered in the optimization of ADAS in the paper","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"CONCEPT"},{"name":"COST","type":"CONCEPT","description":"Cost is an objective that can be considered in multi-objective ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"CONCEPT"},{"name":"LATENCY","type":"CONCEPT","description":"Latency is an objective that can be considered in multi-objective ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"CONCEPT"},{"name":"ROBUSTNESS","type":"CONCEPT","description":"Robustness is an objective that can be considered in multi-objective ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"CONCEPT"},{"name":"EXPLORATION","type":"CONCEPT","description":"Exploration is a strategy in search algorithms to discover new designs","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"CONCEPT"},{"name":"EXPLOITATION","type":"CONCEPT","description":"Exploitation is a strategy in search algorithms to utilize known good designs","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"CONCEPT"},{"name":"DEBUGGING","type":"PROCESS","description":"Debugging is the process of analyzing running logs to improve agentic systems","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PROCESS"},{"name":"SUBJECTIVE ANSWER EVALUATIONS","type":"PROCESS","description":"Subjective answer evaluations are tasks that do not have ground-truth answers and require novel evaluation functions in ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PROCESS"},{"name":"GENERALIST AGENTS","type":"TECHNOLOGY","description":"Generalist agents are agents capable of performing well across multiple domains","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"INTERPRETABLE","type":"ATTRIBUTE","description":"Interpretable refers to the quality of being understandable to humans, as in the case of natural language used in agentic systems","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"ATTRIBUTE"},{"name":"ORGANIZATIONAL STRUCTURE","type":"CONCEPT","description":"Organizational structure refers to the arrangement of roles and responsibilities within human companies, which can be incorporated into agents","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"CONCEPT"},{"name":"HUMAN COMPANIES","type":"CONCEPT","description":"Human companies are organizations that can provide a model for the design of agentic systems","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"CONCEPT"},{"name":"COMPLEXITY","type":"CONCEPT","description":"Complexity refers to the intricate and interconnected nature of systems, which can emerge from human organizations and agentic systems","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"CONCEPT"},{"name":"META-LEARNING","type":"PROCESS","description":"Meta-learning is the process of learning how to learn, applied to the meta agent and beyond in ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PROCESS"},{"name":"TRAINING","type":"PROCESS","description":"Training is the process of teaching the meta agent to be safe and create helpful, harmless, honest agents","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PROCESS"},{"name":"HONEST AGENTS","type":"TECHNOLOGY","description":"Honest agents are agents that are designed to be truthful and reliable","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"HELPFUL AGENTS","type":"TECHNOLOGY","description":"Helpful agents are agents that are designed to assist and provide value","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"HARMLESS AGENTS","type":"TECHNOLOGY","description":"Harmless agents are agents that are designed to avoid causing harm","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"NUMERICAL PERFORMANCE RESULTS","type":"DATA","description":"Numerical performance results are used to evaluate discovered agents in ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"DATA"},{"name":"RUNNING LOGS","type":"DATA","description":"Running logs contain detailed information on the performance of agents during evaluation","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"DATA"},{"name":"FAILURE MODES","type":"DATA","description":"Failure modes are patterns of errors or issues that occur during the operation of agentic systems","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"DATA"},{"name":"SUCCESS MODES","type":"DATA","description":"Success modes are patterns of correct or optimal performance during the operation of agentic systems","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"DATA"},{"name":"QA TASKS","type":"TASK","description":"QA tasks refer to question-answering tasks used to evaluate Meta Agent Search","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TASK"},{"name":"REAL-WORLD APPLICATIONS","type":"TASK","description":"Real-world applications involve multi-step interactions with complex environments","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TASK"},{"name":"INTERACTION","type":"PROCESS","description":"Interaction refers to the engagement between agents and their environments in real-world applications","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PROCESS"},{"name":"ENVIRONMENTS","type":"CONCEPT","description":"Environments are the settings or contexts in which agents operate and interact","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"CONCEPT"},{"name":"HUMAN EFFORTS","type":"CONCEPT","description":"Human efforts refer to existing work and tools that can be leveraged in ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"CONCEPT"},{"name":"SEARCH","type":"PROCESS","description":"Search is the process of exploring and discovering new designs in ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PROCESS"},{"name":"SEARCH ALGORITHM","type":"TECHNOLOGY","description":"Search algorithm is the method used to explore and discover new designs in Meta Agent Search","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"INSTRUCTION","type":"DATA","description":"Instruction refers to the commands or tasks given to the meta agent in ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"DATA"},{"name":"DOMAIN","type":"CONCEPT","description":"Domain refers to the specific area or field in which ADAS algorithms operate","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"CONCEPT"},{"name":"META AGENT SEARCH ALGORITHM","type":"TECHNOLOGY","description":"Meta Agent Search Algorithm is the specific algorithm used in Meta Agent Search to\nMeta Agent Search Algorithm is the specific algorithm used in Meta Agent Search to explore new designs","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"QUALITY-DIVERSITY ALGORITHMS","type":"TECHNOLOGY","description":"Quality-Diversity algorithms are used to explore a wide range of possibilities in ADAS","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"TECHNOLOGY"},{"name":"BALANCING EXPLORATION AND EXPLOITATION","type":"PROCESS","description":"Balancing exploration and exploitation is a strategy in search algorithms to discover new designs while utilizing known good designs","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"PROCESS"},{"name":"DETAILED RUNNING LOGS","type":"DATA","description":"Detailed running logs contain rich information on the performance of agents during evaluation","source_id":"6bdf681c0bd9e401ac72344a6a0ae479","entity_type":"DATA"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"BOSTROM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bostrom is an author referenced in the context of discussions beyond the scope of the paper<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CLUNE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Clune is an author referenced in the context of discussions beyond the scope of the paper<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ECOFFET ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ecoffet et al. are authors referenced in the context of discussions beyond the scope of the paper<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YUDKOWSKY ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yudkowsky et al. are authors referenced in the context of discussions beyond the scope of the paper<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ADAS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">ADAS stands for Automated Design of Agentic Systems, which are algorithms that can be programmed using powerful FMs without expensive hardware<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"API\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">API access to powerful FMs is used to program ADAS algorithms<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"SAFE-ADAS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Safe-ADAS refers to algorithms that conduct ADAS safely, avoiding harmful code and creating honest, helpful agents<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"META AGENT SEARCH\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Meta Agent Search is an algorithm that can be asked to be safe during training and create helpful, harmless, honest agents<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"CONSTITUTIONAL AI\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Constitutional AI is an idea that can be incorporated into Meta Agent Search to ensure the creation of safe agents<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"HIGHER-ORDER ADAS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Higher-order ADAS refers to the concept of improving the meta agent through ADAS, allowing for meta-learning of the meta agent and beyond<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"RAG\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">RAG stands for Retrieval-Augmented Generation, a tool that can be used as a building block in ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"LANGCHAIN\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">LangChain is an existing agent framework that can provide functions for ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"MULTI-OBJECTIVE ADAS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Multi-objective ADAS refers to integrating multiple objectives like cost, latency, and robustness into ADAS algorithms<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"NOVELTY SEARCH ALGORITHMS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Novelty search algorithms focus on exploring new designs and can be incorporated into Meta Agent Search<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"QUALITY-DIVERSITY\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Quality-Diversity is a concept that can be incorporated into the design of search algorithms for ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"AI-GENERATING\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">AI-generating refers to algorithms that can generate AI, a concept that can be incorporated into ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"OPEN-ENDED ALGORITHMS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Open-ended algorithms are designed to explore a wide range of possibilities and can be incorporated into ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"EVALUATION FUNCTIONS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Evaluation functions are used to assess the performance of discovered agents in ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"META AGENT\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Meta agent is an agent used in ADAS to program new agents in code<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"MULTI-MODAL CAPABILITIES\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Multi-modal capabilities refer to the ability to handle different types of data, such as vision, in FMs<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"META\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Meta is an organization mentioned in the context of open-source research for safe-ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"CALDWELL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Caldwell is an author referenced in the context of open-source research for safe-ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BAI ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bai et al. are authors referenced in the context of Constitutional AI<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LU ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lu et al. are authors referenced in the context of higher-order ADAS and subjective answer evaluations<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LEWIS ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lewis et al. are authors referenced in the context of RAG<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LANGCHAINAI\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">LangChainAI is the organization behind the LangChain framework<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"HU ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hu et al. are authors referenced in the context of multi-objective ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HUANG ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Huang et al. are authors referenced in the context of multi-objective ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DEB ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Deb et al. are authors referenced in the context of multi-objective search algorithms<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CULLY &amp; DEMIRIS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Cully &amp; Demiris are authors referenced in the context of Quality-Diversity<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MOURET &amp; CLUNE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mouret &amp; Clune are authors referenced in the context of Quality-Diversity<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"FALDOR ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Faldor et al. are authors referenced in the context of Open-ended Algorithms<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"STANLEY &amp; LEHMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Stanley &amp; Lehman are authors referenced in the context of Open-ended Algorithms<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"STANLEY ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Stanley et al. are authors referenced in the context of Open-ended Algorithms<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHANG ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhang et al. are authors referenced in the context of Open-ended Algorithms<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LIU ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liu et al. are authors referenced in the context of balancing exploration and exploitation<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SUTTON &amp; BARTO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sutton &amp; Barto are authors referenced in the context of balancing exploration and exploitation<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHOU ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhou et al. are authors referenced in the context of intelligent evaluation functions<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHIANG ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chiang et al. are authors referenced in the context of subjective answer evaluations<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HONG ET AL.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hong et al. are authors referenced in the context of incorporating organizational structure in agents<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"AGENTIC SYSTEMS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Agentic systems are machine learning systems that operate primarily over natural language and are interpretable to humans<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"NATURAL LANGUAGE\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Natural language is the representation used by agentic systems and humans in constructing organizations and society<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"HUMAN ORGANIZATIONS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Human organizations are structures that can be incorporated into agentic systems to improve their design<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"SOCIETY\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Society is the broader context in which human organizations and agentic systems operate<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"COMPLEX DOMAINS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Complex domains refer to real-world applications involving multi-step interaction with complex environments<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"SINGLE-STEP QA TASKS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Single-step QA tasks are the type of tasks on which Meta Agent Search is evaluated in the paper<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"MULTIPLE DOMAINS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Multiple domains refer to the capability of ADAS algorithms to design agents that perform well across various fields<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"META-META AGENT\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Meta-meta agent is a higher-order agent that can be learned through meta-learning in ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"BUILDING BLOCKS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Building blocks refer to existing components that can be used to seed ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"SEARCH ENGINE TOOLS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Search engine tools are existing human efforts that can be used as building blocks in ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"FM\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">FM stands for Foundation Models, which are used in ADAS to program agents<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"DATA PRIVACY\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Data privacy is a priority that can influence the choice of FMs in agentic systems<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"PERFORMANCE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Performance is the primary objective considered in the optimization of ADAS in the paper<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"COST\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Cost is an objective that can be considered in multi-objective ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"LATENCY\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Latency is an objective that can be considered in multi-objective ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"ROBUSTNESS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Robustness is an objective that can be considered in multi-objective ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"EXPLORATION\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Exploration is a strategy in search algorithms to discover new designs<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"EXPLOITATION\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Exploitation is a strategy in search algorithms to utilize known good designs<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"DEBUGGING\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Debugging is the process of analyzing running logs to improve agentic systems<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PROCESS<\/data>    <\/node>    <node id=\"SUBJECTIVE ANSWER EVALUATIONS\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Subjective answer evaluations are tasks that do not have ground-truth answers and require novel evaluation functions in ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PROCESS<\/data>    <\/node>    <node id=\"GENERALIST AGENTS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Generalist agents are agents capable of performing well across multiple domains<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"INTERPRETABLE\">      <data key=\"d0\">ATTRIBUTE<\/data>      <data key=\"d1\">Interpretable refers to the quality of being understandable to humans, as in the case of natural language used in agentic systems<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">ATTRIBUTE<\/data>    <\/node>    <node id=\"ORGANIZATIONAL STRUCTURE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Organizational structure refers to the arrangement of roles and responsibilities within human companies, which can be incorporated into agents<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"HUMAN COMPANIES\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Human companies are organizations that can provide a model for the design of agentic systems<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"COMPLEXITY\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Complexity refers to the intricate and interconnected nature of systems, which can emerge from human organizations and agentic systems<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"META-LEARNING\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Meta-learning is the process of learning how to learn, applied to the meta agent and beyond in ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PROCESS<\/data>    <\/node>    <node id=\"TRAINING\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Training is the process of teaching the meta agent to be safe and create helpful, harmless, honest agents<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PROCESS<\/data>    <\/node>    <node id=\"HONEST AGENTS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Honest agents are agents that are designed to be truthful and reliable<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"HELPFUL AGENTS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Helpful agents are agents that are designed to assist and provide value<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"HARMLESS AGENTS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Harmless agents are agents that are designed to avoid causing harm<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"NUMERICAL PERFORMANCE RESULTS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Numerical performance results are used to evaluate discovered agents in ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">DATA<\/data>    <\/node>    <node id=\"RUNNING LOGS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Running logs contain detailed information on the performance of agents during evaluation<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">DATA<\/data>    <\/node>    <node id=\"FAILURE MODES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Failure modes are patterns of errors or issues that occur during the operation of agentic systems<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">DATA<\/data>    <\/node>    <node id=\"SUCCESS MODES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Success modes are patterns of correct or optimal performance during the operation of agentic systems<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">DATA<\/data>    <\/node>    <node id=\"QA TASKS\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">QA tasks refer to question-answering tasks used to evaluate Meta Agent Search<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TASK<\/data>    <\/node>    <node id=\"REAL-WORLD APPLICATIONS\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">Real-world applications involve multi-step interactions with complex environments<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TASK<\/data>    <\/node>    <node id=\"INTERACTION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Interaction refers to the engagement between agents and their environments in real-world applications<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PROCESS<\/data>    <\/node>    <node id=\"ENVIRONMENTS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Environments are the settings or contexts in which agents operate and interact<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"HUMAN EFFORTS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Human efforts refer to existing work and tools that can be leveraged in ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"SEARCH\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Search is the process of exploring and discovering new designs in ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PROCESS<\/data>    <\/node>    <node id=\"SEARCH ALGORITHM\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Search algorithm is the method used to explore and discover new designs in Meta Agent Search<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"INSTRUCTION\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Instruction refers to the commands or tasks given to the meta agent in ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">DATA<\/data>    <\/node>    <node id=\"DOMAIN\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Domain refers to the specific area or field in which ADAS algorithms operate<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"META AGENT SEARCH ALGORITHM\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Meta Agent Search Algorithm is the specific algorithm used in Meta Agent Search toMeta Agent Search Algorithm is the specific algorithm used in Meta Agent Search to explore new designs<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"QUALITY-DIVERSITY ALGORITHMS\">      <data key=\"d0\">TECHNOLOGY<\/data>      <data key=\"d1\">Quality-Diversity algorithms are used to explore a wide range of possibilities in ADAS<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">TECHNOLOGY<\/data>    <\/node>    <node id=\"BALANCING EXPLORATION AND EXPLOITATION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Balancing exploration and exploitation is a strategy in search algorithms to discover new designs while utilizing known good designs<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">PROCESS<\/data>    <\/node>    <node id=\"DETAILED RUNNING LOGS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Detailed running logs contain rich information on the performance of agents during evaluation<\/data>      <data key=\"d2\">6bdf681c0bd9e401ac72344a6a0ae479<\/data>      <data key=\"d3\">DATA<\/data>    <\/node>  <\/graph><\/graphml>"}
{"id":"7de66b94cf868b37b1df51dc545c415f","chunk":"AS is also scientifically intriguing as it sheds light on the origins of complexity emerging from\nhuman organization and society. The agentic system is a machine learning system that operates\nprimarily over natural language\u2014a representation that is interpretable to humans and used by\nhumans in constructing our organization and society. Thus, there is a close connection between\nagentic systems and human organizations, as shown in works incorporating the organizational\nstructure for human companies in agents (Hong et al., 2023) or simulating a human town with\nagents (Park et al., 2023). Therefore, the study in ADAS may enable us to observe how to create\na simple set of conditions and have an algorithm to bootstrap itself from simplicity to produce\ncomplexity in a system akin to human society.\n13Automated Design of Agentic Systems\n\u2022Towards a Better Understanding of FMs. Works from Neural Architecture Search (Huang et al.,\n2023) show that by observing the emerged architecture, we could gain more insights into Neural\nNetworks. In this paper, we also gained insights about FMs from the results. For example, the\nbest agent with GPT-3.5 involves a complex feedback mechanism, but when we transfer to other\nadvanced models, the agent with a simpler feedback mechanism but more refinement becomes a\nbetter agent (Section 4.3). This shows that GPT-3.5 may have a worse capability in evaluating and\nrefining the answers, so it needs a complex feedback mechanism for better refinement, while other\nadvanced models benefit more from a simpler feedback mechanism.\nConclusion. Inthispaper, weproposeanewresearchproblem, AutomatedDesignofAgenticSystems\n(ADAS), which aims to automatically invent novel building blocks and design powerful agentic systems .\nWe demonstrated that a promising approach to ADAS is to define agents in code, allowing new agents\nto be automatically discovered by a \u201cmeta\u201d agent programming them in code. Following this idea,\nwe propose Meta Agent Search, where the meta agent iteratively builds on previous discoveries\nto program interesting new agents. The experiments show that Meta Agent Search consistently\noutperforms state-of-the-art hand-designed agents across an extensive number of domains, and the\ndiscovered agents transfer well across models and domains. Overall, our work illustrates the potential\nof an exciting new research direction toward full automation in developing powerful agentic systems\nfrom the bottom up.\nAcknowledgments\nThis work was supported by the Vector Institute, the Canada CIFAR AI Chairs program, grants from\nSchmidt Futures and Open Philanthropy, an NSERC Discovery Grant, and a generous donation from\nRafael Cosman. We thank Jenny Zhang, Rach Pradhan, Ruiyu Gou, Nicholas Ioannidis, and Eunjeong\nHwang for insightful discussions and feedback.\n14Automated Design of Agentic Systems\nReferences\nAnthropic. Introducing the next generation of claude. https:\/\/www.anthropic.com\/news\/\nclaude-3-family , March 2024a. Blog post.\nAnthropic. Introducing claude 3.5 sonnet. https:\/\/www.anthropic.com\/news\/\nclaude-3-5-sonnet , June 2024b. Blog post.\nYuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna\nChen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, et al. Constitutional ai: Harmlessness\nfrom ai feedback. arXiv preprint arXiv:2212.08073 , 2022.\nYoshua Bengio, Geoffrey Hinton, Andrew Yao, Dawn Song, Pieter Abbeel, Trevor Darrell, Yuval Noah\nHarari, Ya-Qin Zhang, Lan Xue, Shai Shalev-Shwartz, et al. Managing extreme ai risks amid rapid\nprogress. Science, 384(6698):842\u2013845, 2024.\nN Bostrom. Existential Risks: analyzing human extinction scenarios and related hazards. Journal of\nEvolution and Technology , 9, 2002.\nRobert S Boyer and J Strother Moore. A mechanical proof of the Turing completeness of pure LISP .\nCiteseer, 1983.\nTracey Caldwell. Ethical hackers: putting on the white hat. Network Security , 2011(7):10\u201313, 2011.\nHarrison Chase. What is an agent? https:\/\/blog.langchain.dev\/what-is-an-agent\/ , June\n2024. Blog post.\nBanghao Chen, Zhaofeng Zhang, Nicolas Langren\u00e9, and Shengxin Zhu. Unleashing the poten-\ntial of prompt engineering in large language models: a comprehensive review. arXiv preprint\narXiv:2310.14735 , 2023a.\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared\nKaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large\nlanguage models trained on code. arXiv preprint arXiv:2107.03374 , 2021.\nWeize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi Lu,\nYi-Hsin Hung, Chen Qian, et al. Agentverse: Facilitating multi-agent collaboration and exploring\nemergent behaviors. In The Twelfth International Conference on Learning Representations , 2023b.\nWei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nikolas Angel","chunk_id":"7de66b94cf868b37b1df51dc545c415f","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"AS","type":"CONCEPT","description":"AS refers to the agentic system, a machine learning system that operates primarily over natural language and is interpretable to humans","source_id":"7de66b94cf868b37b1df51dc545c415f"},{"name":"HUMAN ORGANIZATION","type":"CONCEPT","description":"Human organization refers to the structured arrangement of individuals and groups in society","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"CONCEPT"},{"name":"HUMAN SOCIETY","type":"CONCEPT","description":"Human society refers to the collective of human beings and their social structures and institutions","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"CONCEPT"},{"name":"AGENTIC SYSTEM","type":"SYSTEM","description":"A machine learning system that operates primarily over natural language and is interpretable to humans","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"SYSTEM"},{"name":"HONG ET AL., 2023","type":"PUBLICATION","description":"A work that incorporates the organizational structure for human companies in agents","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PUBLICATION"},{"name":"PARK ET AL., 2023","type":"PUBLICATION","description":"A work that simulates a human town with agents","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PUBLICATION"},{"name":"ADAS","type":"CONCEPT","description":"Automated Design of Agentic Systems, a research problem aiming to automatically invent novel building blocks and design powerful agentic systems","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"CONCEPT"},{"name":"NEURAL ARCHITECTURE SEARCH","type":"CONCEPT","description":"A method that shows insights into Neural Networks by observing the emerged architecture","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"CONCEPT"},{"name":"GPT-3.5","type":"MODEL","description":"A version of OpenAI's language model used in the study to evaluate agentic systems","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"MODEL"},{"name":"META AGENT SEARCH","type":"PROCESS","description":"A process where a meta agent iteratively builds on previous discoveries to program new agents","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PROCESS"},{"name":"VECTOR INSTITUTE","type":"ORGANIZATION","description":"An organization that supported the work on Automated Design of Agentic Systems","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"ORGANIZATION"},{"name":"CANADA CIFAR AI CHAIRS PROGRAM","type":"PROGRAM","description":"A program that supported the work on Automated Design of Agentic Systems","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PROGRAM"},{"name":"SCHMIDT FUTURES","type":"ORGANIZATION","description":"An organization that provided grants for the work on Automated Design of Agentic Systems","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"ORGANIZATION"},{"name":"OPEN PHILANTHROPY","type":"ORGANIZATION","description":"An organization that provided grants for the work on Automated Design of Agentic Systems","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"ORGANIZATION"},{"name":"NSERC DISCOVERY GRANT","type":"GRANT","description":"A grant that supported the work on Automated Design of Agentic Systems","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"GRANT"},{"name":"RAFAEL COSMAN","type":"PERSON","description":"A person who made a generous donation to support the work on Automated Design of Agentic Systems","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"JENNY ZHANG","type":"PERSON","description":"A person acknowledged for insightful discussions and feedback on the work","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"RACH PRADHAN","type":"PERSON","description":"A person acknowledged for insightful discussions and feedback on the work","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"RUIYU GOU","type":"PERSON","description":"A person acknowledged for insightful discussions and feedback on the work","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"NICHOLAS IOANNIDIS","type":"PERSON","description":"A person acknowledged for insightful discussions and feedback on the work","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"EUNJEONG HWANG","type":"PERSON","description":"A person acknowledged for insightful discussions and feedback on the work","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"ANTHROPIC","type":"ORGANIZATION","description":"An organization that introduced the next generation of Claude and Claude 3.5 Sonnet","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"ORGANIZATION"},{"name":"YUNTAO BAI","type":"PERSON","description":"An author of the paper \"Constitutional AI: Harmlessness from AI Feedback\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"SAURAV KADAVATH","type":"PERSON","description":"An author of the paper \"Constitutional AI: Harmlessness from AI Feedback\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"SANDIPAN KUNDU","type":"PERSON","description":"An author of the paper \"Constitutional AI: Harmlessness from AI Feedback\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"AMANDA ASKELL","type":"PERSON","description":"An author of the paper \"Constitutional AI: Harmlessness from AI Feedback\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"JACKSON KERNION","type":"PERSON","description":"An author of the paper \"Constitutional AI: Harmlessness from AI Feedback\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"ANDY JONES","type":"PERSON","description":"An author of the paper \"Constitutional AI: Harmlessness from AI Feedback\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"ANNA CHEN","type":"PERSON","description":"An author of the paper \"Constitutional AI: Harmlessness from AI Feedback\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"ANNA GOLDIE","type":"PERSON","description":"An author of the paper \"Constitutional AI: Harmlessness from AI Feedback\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"AZALIA MIRHOSEINI","type":"PERSON","description":"An author of the paper \"Constitutional AI: Harmlessness from AI Feedback\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"CAMERON MCKINNON","type":"PERSON","description":"An author of the paper \"Constitutional AI: Harmlessness from AI Feedback\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"YOSHUA BENGIO","type":"PERSON","description":"An author of the paper \"Managing Extreme AI Risks Amid Rapid Progress\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"GEOFFREY HINTON","type":"PERSON","description":"An author of the paper \"Managing Extreme AI Risks Amid Rapid Progress\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"ANDREW YAO","type":"PERSON","description":"An author of the paper \"Managing Extreme AI Risks Amid Rapid Progress\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"DAWN SONG","type":"PERSON","description":"An author of the paper \"Managing Extreme AI Risks Amid Rapid Progress\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"PIETER ABBEEL","type":"PERSON","description":"An author of the paper \"Managing Extreme AI Risks Amid Rapid Progress\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"TREVOR DARRELL","type":"PERSON","description":"An author of the paper \"Managing Extreme AI Risks Amid Rapid Progress\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"YUVAL NOAH HARARI","type":"PERSON","description":"An author of the paper \"Managing Extreme AI Risks Amid Rapid Progress\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"YA-QIN ZHANG","type":"PERSON","description":"An author of the paper \"Managing Extreme AI Risks Amid Rapid Progress\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"LAN XUE","type":"PERSON","description":"An author of the paper \"Managing Extreme AI Risks Amid Rapid Progress\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"SHAI SHALEV-SHWARTZ","type":"PERSON","description":"An author of the paper \"Managing Extreme AI Risks Amid Rapid Progress\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"N BOSTROM","type":"PERSON","description":"An author of the paper \"Existential Risks: Analyzing Human Extinction Scenarios and Related Hazards\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"ROBERT S BOYER","type":"PERSON","description":"An author of the paper \"A Mechanical Proof of the Turing Completeness of Pure LISP\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"J STROTHER MOORE","type":"PERSON","description":"An author of the paper \"A Mechanical Proof of the Turing Completeness of Pure LISP\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"TRACEY CALDWELL","type":"PERSON","description":"An author of the paper \"Ethical Hackers: Putting on the White Hat\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"HARRISON CHASE","type":"PERSON","description":"An author of the blog post \"What is an Agent?\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"BANGHAO CHEN","type":"PERSON","description":"An author of the paper \"Unleashing the Potential of Prompt Engineering in Large Language Models: A Comprehensive Review\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"ZHAOFENG ZHANG","type":"PERSON","description":"An author of the paper \"Unleashing the Potential of Prompt Engineering in Large Language Models: A Comprehensive Review\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"NICOLAS LANGREN\u00c9","type":"PERSON","description":"An author of the paper \"Unleashing the Potential of Prompt Engineering in Large Language Models: A Comprehensive Review\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"SHENGXIN ZHU","type":"PERSON","description":"An author of the paper \"Unleashing the Potential of Prompt Engineering in Large Language Models: A Comprehensive Review\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"MARK CHEN","type":"PERSON","description":"An author of the paper \"Evaluating Large Language Models Trained on Code\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"JERRY TWOREK","type":"PERSON","description":"An author of the paper \"Evaluating Large Language Models Trained on Code\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"HEEWOO JUN","type":"PERSON","description":"An author of the paper \"Evaluating Large Language Models Trained on Code\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"QIMING YUAN","type":"PERSON","description":"An author of the paper \"Evaluating Large Language Models Trained on Code\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"HENRIQUE PONDE DE OLIVEIRA PINTO","type":"PERSON","description":"An author of the paper \"Evaluating Large Language Models Trained on Code\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"JARED KAPLAN","type":"PERSON","description":"An author of the paper \"Evaluating Large Language Models Trained on Code\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"HARRI EDWARDS","type":"PERSON","description":"An author of the paper \"Evaluating Large Language Models Trained on Code\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"YURI BURDA","type":"PERSON","description":"An author of the paper \"Evaluating Large Language Models Trained on Code\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"NICHOLAS JOSEPH","type":"PERSON","description":"An author of the paper \"Evaluating Large Language Models Trained on Code\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"GREG BROCKMAN","type":"PERSON","description":"An author of the paper \"Evaluating Large Language Models Trained on Code\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"WEIZE CHEN","type":"PERSON","description":"An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"YUSHENG SU","type":"PERSON","description":"An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"JINGWEI ZUO","type":"PERSON","description":"An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"CHENG YANG","type":"PERSON","description":"An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"CHENFEI YUAN","type":"PERSON","description":"An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"CHI-MIN CHAN","type":"PERSON","description":"An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"HEYANG YU","type":"PERSON","description":"An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"YAXI LU","type":"PERSON","description":"An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"YI-HSIN HUNG","type":"PERSON","description":"An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"CHEN QIAN","type":"PERSON","description":"An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"WEI-LIN CHIANG","type":"PERSON","description":"An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"LIANMIN ZHENG","type":"PERSON","description":"An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"YING SHENG","type":"PERSON","description":"An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"},{"name":"ANASTASIOS NIKOLAS ANGEL","type":"PERSON","description":"An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"","source_id":"7de66b94cf868b37b1df51dc545c415f","entity_type":"PERSON"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"AS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">AS refers to the agentic system, a machine learning system that operates primarily over natural language and is interpretable to humans<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/node>    <node id=\"HUMAN ORGANIZATION\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Human organization refers to the structured arrangement of individuals and groups in society<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"HUMAN SOCIETY\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Human society refers to the collective of human beings and their social structures and institutions<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"AGENTIC SYSTEM\">      <data key=\"d0\">SYSTEM<\/data>      <data key=\"d1\">A machine learning system that operates primarily over natural language and is interpretable to humans<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">SYSTEM<\/data>    <\/node>    <node id=\"HONG ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A work that incorporates the organizational structure for human companies in agents<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"PARK ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A work that simulates a human town with agents<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"ADAS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Automated Design of Agentic Systems, a research problem aiming to automatically invent novel building blocks and design powerful agentic systems<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"NEURAL ARCHITECTURE SEARCH\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A method that shows insights into Neural Networks by observing the emerged architecture<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">CONCEPT<\/data>    <\/node>    <node id=\"GPT-3.5\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">A version of OpenAI's language model used in the study to evaluate agentic systems<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"META AGENT SEARCH\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">A process where a meta agent iteratively builds on previous discoveries to program new agents<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PROCESS<\/data>    <\/node>    <node id=\"VECTOR INSTITUTE\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">An organization that supported the work on Automated Design of Agentic Systems<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"CANADA CIFAR AI CHAIRS PROGRAM\">      <data key=\"d0\">PROGRAM<\/data>      <data key=\"d1\">A program that supported the work on Automated Design of Agentic Systems<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PROGRAM<\/data>    <\/node>    <node id=\"SCHMIDT FUTURES\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">An organization that provided grants for the work on Automated Design of Agentic Systems<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"OPEN PHILANTHROPY\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">An organization that provided grants for the work on Automated Design of Agentic Systems<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"NSERC DISCOVERY GRANT\">      <data key=\"d0\">GRANT<\/data>      <data key=\"d1\">A grant that supported the work on Automated Design of Agentic Systems<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">GRANT<\/data>    <\/node>    <node id=\"RAFAEL COSMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A person who made a generous donation to support the work on Automated Design of Agentic Systems<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JENNY ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A person acknowledged for insightful discussions and feedback on the work<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"RACH PRADHAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A person acknowledged for insightful discussions and feedback on the work<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"RUIYU GOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A person acknowledged for insightful discussions and feedback on the work<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NICHOLAS IOANNIDIS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A person acknowledged for insightful discussions and feedback on the work<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"EUNJEONG HWANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">A person acknowledged for insightful discussions and feedback on the work<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ANTHROPIC\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">An organization that introduced the next generation of Claude and Claude 3.5 Sonnet<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"YUNTAO BAI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Constitutional AI: Harmlessness from AI Feedback\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SAURAV KADAVATH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Constitutional AI: Harmlessness from AI Feedback\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SANDIPAN KUNDU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Constitutional AI: Harmlessness from AI Feedback\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"AMANDA ASKELL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Constitutional AI: Harmlessness from AI Feedback\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JACKSON KERNION\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Constitutional AI: Harmlessness from AI Feedback\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ANDY JONES\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Constitutional AI: Harmlessness from AI Feedback\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ANNA CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Constitutional AI: Harmlessness from AI Feedback\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ANNA GOLDIE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Constitutional AI: Harmlessness from AI Feedback\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"AZALIA MIRHOSEINI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Constitutional AI: Harmlessness from AI Feedback\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CAMERON MCKINNON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Constitutional AI: Harmlessness from AI Feedback\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YOSHUA BENGIO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Managing Extreme AI Risks Amid Rapid Progress\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GEOFFREY HINTON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Managing Extreme AI Risks Amid Rapid Progress\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ANDREW YAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Managing Extreme AI Risks Amid Rapid Progress\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DAWN SONG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Managing Extreme AI Risks Amid Rapid Progress\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PIETER ABBEEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Managing Extreme AI Risks Amid Rapid Progress\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TREVOR DARRELL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Managing Extreme AI Risks Amid Rapid Progress\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YUVAL NOAH HARARI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Managing Extreme AI Risks Amid Rapid Progress\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YA-QIN ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Managing Extreme AI Risks Amid Rapid Progress\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LAN XUE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Managing Extreme AI Risks Amid Rapid Progress\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHAI SHALEV-SHWARTZ\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Managing Extreme AI Risks Amid Rapid Progress\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"N BOSTROM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Existential Risks: Analyzing Human Extinction Scenarios and Related Hazards\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ROBERT S BOYER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"A Mechanical Proof of the Turing Completeness of Pure LISP\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"J STROTHER MOORE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"A Mechanical Proof of the Turing Completeness of Pure LISP\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TRACEY CALDWELL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Ethical Hackers: Putting on the White Hat\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HARRISON CHASE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the blog post \"What is an Agent?\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BANGHAO CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Unleashing the Potential of Prompt Engineering in Large Language Models: A Comprehensive Review\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHAOFENG ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Unleashing the Potential of Prompt Engineering in Large Language Models: A Comprehensive Review\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NICOLAS LANGREN&#201;\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Unleashing the Potential of Prompt Engineering in Large Language Models: A Comprehensive Review\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHENGXIN ZHU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Unleashing the Potential of Prompt Engineering in Large Language Models: A Comprehensive Review\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MARK CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Evaluating Large Language Models Trained on Code\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JERRY TWOREK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Evaluating Large Language Models Trained on Code\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HEEWOO JUN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Evaluating Large Language Models Trained on Code\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"QIMING YUAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Evaluating Large Language Models Trained on Code\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HENRIQUE PONDE DE OLIVEIRA PINTO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Evaluating Large Language Models Trained on Code\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JARED KAPLAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Evaluating Large Language Models Trained on Code\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HARRI EDWARDS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Evaluating Large Language Models Trained on Code\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YURI BURDA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Evaluating Large Language Models Trained on Code\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NICHOLAS JOSEPH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Evaluating Large Language Models Trained on Code\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GREG BROCKMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Evaluating Large Language Models Trained on Code\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WEIZE CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YUSHENG SU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JINGWEI ZUO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHENG YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHENFEI YUAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHI-MIN CHAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HEYANG YU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YAXI LU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YI-HSIN HUNG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHEN QIAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WEI-LIN CHIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LIANMIN ZHENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YING SHENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ANASTASIOS NIKOLAS ANGEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the paper \"Agentverse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors\"<\/data>      <data key=\"d2\">7de66b94cf868b37b1df51dc545c415f<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <edge source=\"AS\" target=\"HUMAN ORGANIZATION\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">AS sheds light on the origins of complexity emerging from human organization<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"AS\" target=\"HUMAN SOCIETY\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">AS sheds light on the origins of complexity emerging from human society<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"HUMAN ORGANIZATION\" target=\"AGENTIC SYSTEM\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Agentic systems operate over natural language, which is used by humans in constructing our organization<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"HUMAN SOCIETY\" target=\"AGENTIC SYSTEM\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Agentic systems operate over natural language, which is used by humans in constructing our society<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"AGENTIC SYSTEM\" target=\"HONG ET AL., 2023\">      <data key=\"d4\">12.0<\/data>      <data key=\"d5\">Hong et al. (2023) incorporated the organizational structure for human companies in agents<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"AGENTIC SYSTEM\" target=\"PARK ET AL., 2023\">      <data key=\"d4\">12.0<\/data>      <data key=\"d5\">Park et al. (2023) simulated a human town with agents<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"AGENTIC SYSTEM\" target=\"ADAS\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">ADAS aims to design powerful agentic systems<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"META AGENT SEARCH\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">Meta Agent Search is a proposed approach to ADAS<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"VECTOR INSTITUTE\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Vector Institute supported the work on ADAS<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"CANADA CIFAR AI CHAIRS PROGRAM\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Canada CIFAR AI Chairs program supported the work on ADAS<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"SCHMIDT FUTURES\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Schmidt Futures provided grants for the work on ADAS<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"OPEN PHILANTHROPY\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Open Philanthropy provided grants for the work on ADAS<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"NSERC DISCOVERY GRANT\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">NSERC Discovery Grant supported the work on ADAS<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"RAFAEL COSMAN\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Rafael Cosman made a generous donation to support the work on ADAS<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"JENNY ZHANG\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Jenny Zhang provided insightful discussions and feedback on the work<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"RACH PRADHAN\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Rach Pradhan provided insightful discussions and feedback on the work<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"RUIYU GOU\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Ruiyu Gou provided insightful discussions and feedback on the work<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"NICHOLAS IOANNIDIS\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Nicholas Ioannidis provided insightful discussions and feedback on the work<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"ADAS\" target=\"EUNJEONG HWANG\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Eunjeong Hwang provided insightful discussions and feedback on the work<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"NEURAL ARCHITECTURE SEARCH\" target=\"GPT-3.5\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Neural Architecture Search shows insights into Neural Networks, and GPT-3.5 was used to evaluate agentic systems<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"ANTHROPIC\" target=\"YUNTAO BAI\">      <data key=\"d4\">12.0<\/data>      <data key=\"d5\">Yuntao Bai is associated with Anthropic<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"ANTHROPIC\" target=\"SAURAV KADAVATH\">      <data key=\"d4\">12.0<\/data>      <data key=\"d5\">Saurav Kadavath is associated with Anthropic<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"ANTHROPIC\" target=\"SANDIPAN KUNDU\">      <data key=\"d4\">12.0<\/data>      <data key=\"d5\">Sandipan Kundu is associated with Anthropic<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"ANTHROPIC\" target=\"AMANDA ASKELL\">      <data key=\"d4\">12.0<\/data>      <data key=\"d5\">Amanda Askell is associated with Anthropic<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"ANTHROPIC\" target=\"JACKSON KERNION\">      <data key=\"d4\">12.0<\/data>      <data key=\"d5\">Jackson Kernion is associated with Anthropic<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"ANTHROPIC\" target=\"ANDY JONES\">      <data key=\"d4\">12.0<\/data>      <data key=\"d5\">Andy Jones is associated with Anthropic<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"ANTHROPIC\" target=\"ANNA CHEN\">      <data key=\"d4\">12.0<\/data>      <data key=\"d5\">Anna Chen is associated with Anthropic<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"ANTHROPIC\" target=\"ANNA GOLDIE\">      <data key=\"d4\">12.0<\/data>      <data key=\"d5\">Anna Goldie is associated with Anthropic<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"ANTHROPIC\" target=\"AZALIA MIRHOSEINI\">      <data key=\"d4\">12.0<\/data>      <data key=\"d5\">Azalia Mirhoseini is associated with Anthropic<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"ANTHROPIC\" target=\"CAMERON MCKINNON\">      <data key=\"d4\">12.0<\/data>      <data key=\"d5\">Cameron McKinnon is associated with Anthropic<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"YOSHUA BENGIO\" target=\"GEOFFREY HINTON\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Yoshua Bengio and Geoffrey Hinton co-authored the paper \"Managing Extreme AI Risks Amid Rapid Progress\"<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"YOSHUA BENGIO\" target=\"ANDREW YAO\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Yoshua Bengio and Andrew Yao co-authored the paper \"Managing Extreme AI Risks Amid Rapid Progress\"<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"YOSHUA BENGIO\" target=\"DAWN SONG\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Yoshua Bengio and Dawn Song co-authored the paper \"Managing Extreme AI Risks Amid Rapid Progress\"<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>    <edge source=\"YOSHUA BENGIO\" target=\"PIETER ABBEEL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yoshua Bengio and Pieter Abbeel co-authored the paper \"Managing Extreme AI Risks Amid Rapid Progress\"<\/data>      <data key=\"d6\">7de66b94cf868b37b1df51dc545c415f<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"022e7927d281e80e188f29ea343cc115","chunk":" Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi Lu,\nYi-Hsin Hung, Chen Qian, et al. Agentverse: Facilitating multi-agent collaboration and exploring\nemergent behaviors. In The Twelfth International Conference on Learning Representations , 2023b.\nWei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nikolas Angelopoulos, Tianle Li, Dacheng Li,\nHao Zhang, Banghua Zhu, Michael Jordan, Joseph E. Gonzalez, and Ion Stoica. Chatbot arena: An\nopen platform for evaluating llms by human preference, 2024.\nFran\u00e7ois Chollet. On the measure of intelligence. arXiv preprint arXiv:1911.01547 , 2019.\nJeff Clune. Ai-gas: Ai-generating algorithms, an alternate paradigm for producing general artificial\nintelligence. arXiv preprint arXiv:1905.10985 , 2019.\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias\nPlappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word\nproblems. arXiv preprint arXiv:2110.14168 , 2021.\nAntoineCullyandYiannisDemiris. Qualityanddiversityoptimization: Aunifyingmodularframework.\nIEEE Transactions on Evolutionary Computation , 22(2):245\u2013259, 2017.\n15Automated Design of Agentic Systems\nN. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In 2005 IEEE Computer\nSociety Conference on Computer Vision and Pattern Recognition (CVPR\u201905) , volume 1, pp. 886\u2013893\nvol. 1, 2005. doi: 10.1109\/CVPR.2005.177.\nKalyanmoyDeb, AmritPratap, SameerAgarwal, andTAMTMeyarivan. Afastandelitistmultiobjective\ngenetic algorithm: Nsga-ii. IEEE transactions on evolutionary computation , 6(2):182\u2013197, 2002.\nAaron Dharna, Julian Togelius, and Lisa B Soros. Co-generation of game levels and game-playing\nagents. In Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Enter-\ntainment , volume 16, pp. 203\u2013209, 2020.\nYilun Du, Shuang Li, Antonio Torralba, Joshua BTenenbaum, and Igor Mordatch. Improving factuality\nand reasoning in language models through multiagent debate. arXiv preprint arXiv:2305.14325 ,\n2023.\nDheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt Gardner.\nDROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs. In Jill\nBurstein, Christy Doran, and Thamar Solorio (eds.), Proceedings of the 2019 Conference of the North\nAmerican Chapter of the Association for Computational Linguistics: Human Language Technologies,\nVolume 1 (Long and Short Papers) , pp. 2368\u20132378, Minneapolis, Minnesota, June 2019. Association\nfor Computational Linguistics. doi: 10.18653\/v1\/N19-1246.\nYan Duan, John Schulman, Xi Chen, Peter L. Bartlett, Ilya Sutskever, and Pieter Abbeel. RL^2: Fast\nreinforcement learning via slow reinforcement learning. In International Conference on Learning\nRepresentations , 2017.\nAdrien Ecoffet, Jeff Clune, and Joel Lehman. Open questions in creating safe open-ended AI: Tensions\nbetween control and creativity. In Conference on Artificial Life , pp. 27\u201335. MIT Press, 2020.\nThomas Elsken, Jan Hendrik Metzen, and Frank Hutter. Neural architecture search: A survey. Journal\nof Machine Learning Research , 20(55):1\u201321, 2019.\nMaxence Faldor, Jenny Zhang, Antoine Cully, and Jeff Clune. Omni-epic: Open-endedness via\nmodels of human notions of interestingness with environments programmed in code. arXiv preprint\narXiv:2405.15568 , 2024.\nChrisantha Fernando, Dylan Sunil Banarse, Henryk Michalewski, Simon Osindero, and Tim Rock-\nt\u00e4schel. Promptbreeder: Self-referential self-improvement via prompt evolution, 2024.\nChelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of\ndeep networks. In International conference on machine learning , pp. 1126\u20131135. PMLR, 2017.\nLuyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and\nGraham Neubig. Pal: Program-aided language models. In International Conference on Machine\nLearning , pp. 10764\u201310799. PMLR, 2023.\nRyan Greenblatt. Getting 50% sota on arc-agi with gpt-4. https:\/\/redwoodresearch.substack.\ncom\/p\/getting-50-sota-on-arc-agi-with-gpt , July 202","chunk_id":"022e7927d281e80e188f29ea343cc115","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"CHEN, YUSHENG","type":"PERSON","description":"Chen, Yusheng is an author of the paper \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"SU, JINGWEI","type":"PERSON","description":"Su, Jingwei is an author of the paper \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"ZUO, CHENG","type":"PERSON","description":"Zuo, Cheng is an author of the paper \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"YANG, CHENFEI","type":"PERSON","description":"Yang, Chenfei is an author of the paper \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"YUAN, CHI-MIN","type":"PERSON","description":"Yuan, Chi-Min is an author of the paper \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"CHAN, HEYANG","type":"PERSON","description":"Chan, Heyang is an author of the paper \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"YU, YAXI","type":"PERSON","description":"Yu, Yaxi is an author of the paper \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"HUNG, YI-HSIN","type":"PERSON","description":"Hung, Yi-Hsin is an author of the paper \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"QIAN, CHEN","type":"PERSON","description":"Qian, Chen is an author of the paper \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"AGENTVERSE","type":"PAPER","description":"Agentverse is a paper titled \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors\" presented at The Twelfth International Conference on Learning Representations, 2023","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PAPER"},{"name":"THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS","type":"CONFERENCE","description":"The conference where the paper \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors\" was presented in 2023","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"CONFERENCE"},{"name":"WEI-LIN CHIANG","type":"PERSON","description":"Wei-Lin Chiang is an author of the paper \"Chatbot arena: An open platform for evaluating llms by human preference\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"LIANMIN ZHENG","type":"PERSON","description":"Lianmin Zheng is an author of the paper \"Chatbot arena: An open platform for evaluating llms by human preference\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"YING SHENG","type":"PERSON","description":"Ying Sheng is an author of the paper \"Chatbot arena: An open platform for evaluating llms by human preference\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"ANASTASIOS NIKOLAS ANGELOPOULOS","type":"PERSON","description":"Anastasios Nikolas Angelopoulos is an author of the paper \"Chatbot arena: An open platform for evaluating llms by human preference\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"TIANLE LI","type":"PERSON","description":"Tianle Li is an author of the paper \"Chatbot arena: An open platform for evaluating llms by human preference\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"DACHENG LI","type":"PERSON","description":"Dacheng Li is an author of the paper \"Chatbot arena: An open platform for evaluating llms by human preference\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"HAO ZHANG","type":"PERSON","description":"Hao Zhang is an author of the paper \"Chatbot arena: An open platform for evaluating llms by human preference\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"BANGHUA ZHU","type":"PERSON","description":"Banghua Zhu is an author of the paper \"Chatbot arena: An open platform for evaluating llms by human preference\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"MICHAEL JORDAN","type":"PERSON","description":"Michael Jordan is an author of the paper \"Chatbot arena: An open platform for evaluating llms by human preference\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"JOSEPH E. GONZALEZ","type":"PERSON","description":"Joseph E. Gonzalez is an author of the paper \"Chatbot arena: An open platform for evaluating llms by human preference\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"ION STOICA","type":"PERSON","description":"Ion Stoica is an author of the paper \"Chatbot arena: An open platform for evaluating llms by human preference\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"CHATBOT ARENA","type":"PAPER","description":"Chatbot arena is a paper titled \"Chatbot arena: An open platform for evaluating llms by human preference\" published in 2024","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PAPER"},{"name":"FRAN\u00c7OIS CHOLLET","type":"PERSON","description":"Fran\u00e7ois Chollet is the author of the paper \"On the measure of intelligence\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"ON THE MEASURE OF INTELLIGENCE","type":"PAPER","description":"On the measure of intelligence is a paper authored by Fran\u00e7ois Chollet, published as an arXiv preprint in 2019","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PAPER"},{"name":"JEFF CLUNE","type":"PERSON","description":"Jeff Clune is the author of the paper \"Ai-gas: Ai-generating algorithms, an alternate paradigm for producing general artificial intelligence\"\nJeff Clune is an author of the paper \"Open questions in creating safe open-ended AI: Tensions between control and creativity\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"AI-GAS: AI-GENERATING ALGORITHMS","type":"PAPER","description":"Ai-gas: Ai-generating algorithms is a paper authored by Jeff Clune, published as an arXiv preprint in 2019","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PAPER"},{"name":"KARL COBBE","type":"PERSON","description":"Karl Cobbe is an author of the paper \"Training verifiers to solve math word problems\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"VINEET KOSARAJU","type":"PERSON","description":"Vineet Kosaraju is an author of the paper \"Training verifiers to solve math word problems\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"MOHAMMAD BAVARIAN","type":"PERSON","description":"Mohammad Bavarian is an author of the paper \"Training verifiers to solve math word problems\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"MARK CHEN","type":"PERSON","description":"Mark Chen is an author of the paper \"Training verifiers to solve math word problems\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"HEEWOO JUN","type":"PERSON","description":"Heewoo Jun is an author of the paper \"Training verifiers to solve math word problems\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"LUKASZ KAISER","type":"PERSON","description":"Lukasz Kaiser is an author of the paper \"Training verifiers to solve math word problems\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"MATTHIAS PLAPPERT","type":"PERSON","description":"Matthias Plappert is an author of the paper \"Training verifiers to solve math word problems\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"JERRY TWOREK","type":"PERSON","description":"Jerry Tworek is an author of the paper \"Training verifiers to solve math word problems\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"JACOB HILTON","type":"PERSON","description":"Jacob Hilton is an author of the paper \"Training verifiers to solve math word problems\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"REIICHIRO NAKANO","type":"PERSON","description":"Reiichiro Nakano is an author of the paper \"Training verifiers to solve math word problems\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"TRAINING VERIFIERS TO SOLVE MATH WORD PROBLEMS","type":"PAPER","description":"Training verifiers to solve math word problems is a paper authored by Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, and Reiichiro Nakano, published as an arXiv preprint in 2021","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PAPER"},{"name":"ANTOINE CULLY","type":"PERSON","description":"Antoine Cully is an author of the paper \"Quality and diversity optimization: A unifying modular framework\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"YIANNIS DEMIRIS","type":"PERSON","description":"Yiannis Demiris is an author of the paper \"Quality and diversity optimization: A unifying modular framework\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"QUALITY AND DIVERSITY OPTIMIZATION","type":"PAPER","description":"Quality and diversity optimization is a paper authored by Antoine Cully and Yiannis Demiris, published in IEEE Transactions on Evolutionary Computation in 2017","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PAPER"},{"name":"N. DALAL","type":"PERSON","description":"N. Dalal is an author of the paper \"Histograms of oriented gradients for human detection\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"B. TRIGGS","type":"PERSON","description":"B. Triggs is an author of the paper \"Histograms of oriented gradients for human detection\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"HISTOGRAMS OF ORIENTED GRADIENTS FOR HUMAN DETECTION","type":"PAPER","description":"Histograms of oriented gradients for human detection is a paper authored by N. Dalal and B. Triggs, presented at the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR\u201905)","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PAPER"},{"name":"KALYANMOY DEB","type":"PERSON","description":"Kalyanmoy Deb is an author of the paper \"A fast and elitist multiobjective genetic algorithm: Nsga-ii\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"AMRIT PRATAP","type":"PERSON","description":"Amrit Pratap is an author of the paper \"A fast and elitist multiobjective genetic algorithm: Nsga-ii\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"SAMEER AGARWAL","type":"PERSON","description":"Sameer Agarwal is an author of the paper \"A fast and elitist multiobjective genetic algorithm: Nsga-ii\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"TAMT MEYARIVAN","type":"PERSON","description":"TAMT Meyarivan is an author of the paper \"A fast and elitist multiobjective genetic algorithm: Nsga-ii\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"A FAST AND ELITIST MULTIOBJECTIVE GENETIC ALGORITHM: NSGA-II","type":"PAPER","description":"A fast and elitist multiobjective genetic algorithm: Nsga-ii is a paper authored by Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, and TAMT Meyarivan, published in IEEE Transactions on Evolutionary Computation in 2002","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PAPER"},{"name":"AARON DHARNA","type":"PERSON","description":"Aaron Dharna is an author of the paper \"Co-generation of game levels and game-playing agents\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"JULIAN TOGELIUS","type":"PERSON","description":"Julian Togelius is an author of the paper \"Co-generation of game levels and game-playing agents\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"LISA B SOROS","type":"PERSON","description":"Lisa B Soros is an author of the paper \"Co-generation of game levels and game-playing agents\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"CO-GENERATION OF GAME LEVELS AND GAME-PLAYING AGENTS","type":"PAPER","description":"Co-generation of game levels and game-playing agents is a paper authored by Aaron Dharna, Julian Togelius, and Lisa B Soros, presented at the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment in 2020","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PAPER"},{"name":"YILUN DU","type":"PERSON","description":"Yilun Du is an author of the paper \"Improving factuality and reasoning in language models through multiagent debate\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"SHUANG LI","type":"PERSON","description":"Shuang Li is an author of the paper \"Improving factuality and reasoning in language models through multiagent debate\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"ANTONIO TORRALBA","type":"PERSON","description":"Antonio Torralba is an author of the paper \"Improving factuality and reasoning in language models through multiagent debate\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"JOSHUA B. TENENBAUM","type":"PERSON","description":"Joshua B. Tenenbaum is an author of the paper \"Improving factuality and reasoning in language models through multiagent debate\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"IGOR MORDATCH","type":"PERSON","description":"Igor Mordatch is an author of the paper \"Improving factuality and reasoning in language models through multiagent debate\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"IMPROVING FACTUALITY AND REASONING IN LANGUAGE MODELS THROUGH MULTIAGENT DEBATE","type":"PAPER","description":"Improving factuality and reasoning in language models through multiagent debate is a paper authored by Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, and Igor Mordatch, published as an arXiv preprint in 2023","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PAPER"},{"name":"DHEERU DUA","type":"PERSON","description":"Dheeru Dua is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"YIZHONG WANG","type":"PERSON","description":"Yizhong Wang is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"PRADEEP DASIGI","type":"PERSON","description":"Pradeep Dasigi is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"GABRIEL STANOVSKY","type":"PERSON","description":"Gabriel Stanovsky is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"SAMEER SINGH","type":"PERSON","description":"Sameer Singh is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"MATT GARDNER","type":"PERSON","description":"Matt Gardner is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"DROP: A READING COMPREHENSION BENCHMARK REQUIRING DISCRETE REASONING OVER PARAGRAPHS","type":"PAPER","description":"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs is a paper authored by Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt Gardner, presented at the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PAPER"},{"name":"YAN DUAN","type":"PERSON","description":"Yan Duan is an author of the paper \"RL^2: Fast reinforcement learning via slow reinforcement learning\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"JOHN SCHULMAN","type":"PERSON","description":"John Schulman is an author of the paper \"RL^2: Fast reinforcement learning via slow reinforcement learning\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"XI CHEN","type":"PERSON","description":"Xi Chen is an author of the paper \"RL^2: Fast reinforcement learning via slow reinforcement learning\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"PETER L. BARTLETT","type":"PERSON","description":"Peter L. Bartlett is an author of the paper \"RL^2: Fast reinforcement learning via slow reinforcement learning\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"ILYA SUTSKEVER","type":"PERSON","description":"Ilya Sutskever is an author of the paper \"RL^2: Fast reinforcement learning via slow reinforcement learning\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"PIETER ABBEEL","type":"PERSON","description":"Pieter Abbeel is an author of the paper \"RL^2: Fast reinforcement learning via slow reinforcement learning\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"RL^2: FAST REINFORCEMENT LEARNING VIA SLOW REINFORCEMENT LEARNING","type":"PAPER","description":"RL^2: Fast reinforcement learning via slow reinforcement learning is a paper authored by Yan Duan, John Schulman, Xi Chen, Peter L. Bartlett, Ilya Sutskever, and Pieter Abbeel, presented at the International Conference on Learning Representations in 2017","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PAPER"},{"name":"ADRIEN ECOFFET","type":"PERSON","description":"Adrien Ecoffet is an author of the paper \"Open questions in creating safe open-ended AI: Tensions between control and creativity\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"JOEL LEHMAN","type":"PERSON","description":"Joel Lehman is an author of the paper \"Open questions in creating safe open-ended AI: Tensions between control and creativity\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"OPEN QUESTIONS IN CREATING SAFE OPEN-ENDED AI: TENSIONS BETWEEN CONTROL AND CREATIVITY","type":"PAPER","description":"Open questions in creating safe open-ended AI: Tensions between control and creativity is a paper authored by Adrien Ecoffet, Jeff Clune, and Joel Lehman, presented at the Conference on Artificial Life in 2020","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PAPER"},{"name":"THOMAS ELSKEN","type":"PERSON","description":"Thomas Elsken is an author of the paper \"Neural architecture search: A survey\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"JAN HENDRIK METZEN","type":"PERSON","description":"Jan Hendrik Metzen is an author of the paper \"Neural architecture search: A survey\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"FRANK HUTTER","type":"PERSON","description":"Frank Hutter is an author of the paper \"Neural architecture search: A survey\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"NEURAL ARCHITECTURE SEARCH: A SURVEY","type":"PAPER","description":"Neural architecture search: A survey is a paper authored by Thomas Elsken, Jan Hendrik Metzen, and Frank Hutter, published in the Journal of Machine Learning Research in 2019","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PAPER"},{"name":"MAXENCE FALDOR","type":"PERSON","description":"Maxence Faldor is an author of the paper \"Omni-epic: Open-endedness via models of human notions of interestingness with environments programmed in code\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"},{"name":"JENNY ZHANG","type":"PERSON","description":"Jenny Zhang is an author of the paper \"Omni-epic: Open-endedness via models of human notions of interestingness with environments programmed in code\"","source_id":"022e7927d281e80e188f29ea343cc115","entity_type":"PERSON"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"CHEN, YUSHENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chen, Yusheng is an author of the paper \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SU, JINGWEI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Su, Jingwei is an author of the paper \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZUO, CHENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zuo, Cheng is an author of the paper \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YANG, CHENFEI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yang, Chenfei is an author of the paper \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YUAN, CHI-MIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yuan, Chi-Min is an author of the paper \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHAN, HEYANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chan, Heyang is an author of the paper \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YU, YAXI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yu, Yaxi is an author of the paper \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HUNG, YI-HSIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hung, Yi-Hsin is an author of the paper \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"QIAN, CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Qian, Chen is an author of the paper \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"AGENTVERSE\">      <data key=\"d0\">PAPER<\/data>      <data key=\"d1\">Agentverse is a paper titled \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors\" presented at The Twelfth International Conference on Learning Representations, 2023<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PAPER<\/data>    <\/node>    <node id=\"THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">The conference where the paper \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors\" was presented in 2023<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">CONFERENCE<\/data>    <\/node>    <node id=\"WEI-LIN CHIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wei-Lin Chiang is an author of the paper \"Chatbot arena: An open platform for evaluating llms by human preference\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LIANMIN ZHENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lianmin Zheng is an author of the paper \"Chatbot arena: An open platform for evaluating llms by human preference\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YING SHENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ying Sheng is an author of the paper \"Chatbot arena: An open platform for evaluating llms by human preference\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ANASTASIOS NIKOLAS ANGELOPOULOS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Anastasios Nikolas Angelopoulos is an author of the paper \"Chatbot arena: An open platform for evaluating llms by human preference\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TIANLE LI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tianle Li is an author of the paper \"Chatbot arena: An open platform for evaluating llms by human preference\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DACHENG LI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dacheng Li is an author of the paper \"Chatbot arena: An open platform for evaluating llms by human preference\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HAO ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hao Zhang is an author of the paper \"Chatbot arena: An open platform for evaluating llms by human preference\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BANGHUA ZHU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Banghua Zhu is an author of the paper \"Chatbot arena: An open platform for evaluating llms by human preference\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MICHAEL JORDAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Michael Jordan is an author of the paper \"Chatbot arena: An open platform for evaluating llms by human preference\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JOSEPH E. GONZALEZ\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joseph E. Gonzalez is an author of the paper \"Chatbot arena: An open platform for evaluating llms by human preference\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ION STOICA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ion Stoica is an author of the paper \"Chatbot arena: An open platform for evaluating llms by human preference\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHATBOT ARENA\">      <data key=\"d0\">PAPER<\/data>      <data key=\"d1\">Chatbot arena is a paper titled \"Chatbot arena: An open platform for evaluating llms by human preference\" published in 2024<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PAPER<\/data>    <\/node>    <node id=\"FRAN&#199;OIS CHOLLET\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Fran&#231;ois Chollet is the author of the paper \"On the measure of intelligence\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ON THE MEASURE OF INTELLIGENCE\">      <data key=\"d0\">PAPER<\/data>      <data key=\"d1\">On the measure of intelligence is a paper authored by Fran&#231;ois Chollet, published as an arXiv preprint in 2019<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PAPER<\/data>    <\/node>    <node id=\"JEFF CLUNE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jeff Clune is the author of the paper \"Ai-gas: Ai-generating algorithms, an alternate paradigm for producing general artificial intelligence\"Jeff Clune is an author of the paper \"Open questions in creating safe open-ended AI: Tensions between control and creativity\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"AI-GAS: AI-GENERATING ALGORITHMS\">      <data key=\"d0\">PAPER<\/data>      <data key=\"d1\">Ai-gas: Ai-generating algorithms is a paper authored by Jeff Clune, published as an arXiv preprint in 2019<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PAPER<\/data>    <\/node>    <node id=\"KARL COBBE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Karl Cobbe is an author of the paper \"Training verifiers to solve math word problems\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"VINEET KOSARAJU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Vineet Kosaraju is an author of the paper \"Training verifiers to solve math word problems\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MOHAMMAD BAVARIAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mohammad Bavarian is an author of the paper \"Training verifiers to solve math word problems\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MARK CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mark Chen is an author of the paper \"Training verifiers to solve math word problems\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HEEWOO JUN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Heewoo Jun is an author of the paper \"Training verifiers to solve math word problems\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LUKASZ KAISER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lukasz Kaiser is an author of the paper \"Training verifiers to solve math word problems\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MATTHIAS PLAPPERT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Matthias Plappert is an author of the paper \"Training verifiers to solve math word problems\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JERRY TWOREK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jerry Tworek is an author of the paper \"Training verifiers to solve math word problems\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JACOB HILTON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jacob Hilton is an author of the paper \"Training verifiers to solve math word problems\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"REIICHIRO NAKANO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Reiichiro Nakano is an author of the paper \"Training verifiers to solve math word problems\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TRAINING VERIFIERS TO SOLVE MATH WORD PROBLEMS\">      <data key=\"d0\">PAPER<\/data>      <data key=\"d1\">Training verifiers to solve math word problems is a paper authored by Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, and Reiichiro Nakano, published as an arXiv preprint in 2021<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PAPER<\/data>    <\/node>    <node id=\"ANTOINE CULLY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Antoine Cully is an author of the paper \"Quality and diversity optimization: A unifying modular framework\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YIANNIS DEMIRIS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yiannis Demiris is an author of the paper \"Quality and diversity optimization: A unifying modular framework\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"QUALITY AND DIVERSITY OPTIMIZATION\">      <data key=\"d0\">PAPER<\/data>      <data key=\"d1\">Quality and diversity optimization is a paper authored by Antoine Cully and Yiannis Demiris, published in IEEE Transactions on Evolutionary Computation in 2017<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PAPER<\/data>    <\/node>    <node id=\"N. DALAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">N. Dalal is an author of the paper \"Histograms of oriented gradients for human detection\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"B. TRIGGS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">B. Triggs is an author of the paper \"Histograms of oriented gradients for human detection\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HISTOGRAMS OF ORIENTED GRADIENTS FOR HUMAN DETECTION\">      <data key=\"d0\">PAPER<\/data>      <data key=\"d1\">Histograms of oriented gradients for human detection is a paper authored by N. Dalal and B. Triggs, presented at the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&#8217;05)<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PAPER<\/data>    <\/node>    <node id=\"KALYANMOY DEB\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kalyanmoy Deb is an author of the paper \"A fast and elitist multiobjective genetic algorithm: Nsga-ii\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"AMRIT PRATAP\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Amrit Pratap is an author of the paper \"A fast and elitist multiobjective genetic algorithm: Nsga-ii\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SAMEER AGARWAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sameer Agarwal is an author of the paper \"A fast and elitist multiobjective genetic algorithm: Nsga-ii\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TAMT MEYARIVAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">TAMT Meyarivan is an author of the paper \"A fast and elitist multiobjective genetic algorithm: Nsga-ii\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"A FAST AND ELITIST MULTIOBJECTIVE GENETIC ALGORITHM: NSGA-II\">      <data key=\"d0\">PAPER<\/data>      <data key=\"d1\">A fast and elitist multiobjective genetic algorithm: Nsga-ii is a paper authored by Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, and TAMT Meyarivan, published in IEEE Transactions on Evolutionary Computation in 2002<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PAPER<\/data>    <\/node>    <node id=\"AARON DHARNA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Aaron Dharna is an author of the paper \"Co-generation of game levels and game-playing agents\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JULIAN TOGELIUS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Julian Togelius is an author of the paper \"Co-generation of game levels and game-playing agents\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LISA B SOROS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lisa B Soros is an author of the paper \"Co-generation of game levels and game-playing agents\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CO-GENERATION OF GAME LEVELS AND GAME-PLAYING AGENTS\">      <data key=\"d0\">PAPER<\/data>      <data key=\"d1\">Co-generation of game levels and game-playing agents is a paper authored by Aaron Dharna, Julian Togelius, and Lisa B Soros, presented at the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment in 2020<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PAPER<\/data>    <\/node>    <node id=\"YILUN DU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yilun Du is an author of the paper \"Improving factuality and reasoning in language models through multiagent debate\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHUANG LI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shuang Li is an author of the paper \"Improving factuality and reasoning in language models through multiagent debate\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ANTONIO TORRALBA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Antonio Torralba is an author of the paper \"Improving factuality and reasoning in language models through multiagent debate\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JOSHUA B. TENENBAUM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joshua B. Tenenbaum is an author of the paper \"Improving factuality and reasoning in language models through multiagent debate\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"IGOR MORDATCH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Igor Mordatch is an author of the paper \"Improving factuality and reasoning in language models through multiagent debate\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"IMPROVING FACTUALITY AND REASONING IN LANGUAGE MODELS THROUGH MULTIAGENT DEBATE\">      <data key=\"d0\">PAPER<\/data>      <data key=\"d1\">Improving factuality and reasoning in language models through multiagent debate is a paper authored by Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, and Igor Mordatch, published as an arXiv preprint in 2023<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PAPER<\/data>    <\/node>    <node id=\"DHEERU DUA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dheeru Dua is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YIZHONG WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yizhong Wang is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PRADEEP DASIGI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pradeep Dasigi is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GABRIEL STANOVSKY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gabriel Stanovsky is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SAMEER SINGH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sameer Singh is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MATT GARDNER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Matt Gardner is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DROP: A READING COMPREHENSION BENCHMARK REQUIRING DISCRETE REASONING OVER PARAGRAPHS\">      <data key=\"d0\">PAPER<\/data>      <data key=\"d1\">DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs is a paper authored by Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt Gardner, presented at the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PAPER<\/data>    <\/node>    <node id=\"YAN DUAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yan Duan is an author of the paper \"RL^2: Fast reinforcement learning via slow reinforcement learning\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JOHN SCHULMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">John Schulman is an author of the paper \"RL^2: Fast reinforcement learning via slow reinforcement learning\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XI CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xi Chen is an author of the paper \"RL^2: Fast reinforcement learning via slow reinforcement learning\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PETER L. BARTLETT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Peter L. Bartlett is an author of the paper \"RL^2: Fast reinforcement learning via slow reinforcement learning\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ILYA SUTSKEVER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ilya Sutskever is an author of the paper \"RL^2: Fast reinforcement learning via slow reinforcement learning\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PIETER ABBEEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pieter Abbeel is an author of the paper \"RL^2: Fast reinforcement learning via slow reinforcement learning\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"RL^2: FAST REINFORCEMENT LEARNING VIA SLOW REINFORCEMENT LEARNING\">      <data key=\"d0\">PAPER<\/data>      <data key=\"d1\">RL^2: Fast reinforcement learning via slow reinforcement learning is a paper authored by Yan Duan, John Schulman, Xi Chen, Peter L. Bartlett, Ilya Sutskever, and Pieter Abbeel, presented at the International Conference on Learning Representations in 2017<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PAPER<\/data>    <\/node>    <node id=\"ADRIEN ECOFFET\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Adrien Ecoffet is an author of the paper \"Open questions in creating safe open-ended AI: Tensions between control and creativity\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JOEL LEHMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joel Lehman is an author of the paper \"Open questions in creating safe open-ended AI: Tensions between control and creativity\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"OPEN QUESTIONS IN CREATING SAFE OPEN-ENDED AI: TENSIONS BETWEEN CONTROL AND CREATIVITY\">      <data key=\"d0\">PAPER<\/data>      <data key=\"d1\">Open questions in creating safe open-ended AI: Tensions between control and creativity is a paper authored by Adrien Ecoffet, Jeff Clune, and Joel Lehman, presented at the Conference on Artificial Life in 2020<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PAPER<\/data>    <\/node>    <node id=\"THOMAS ELSKEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Thomas Elsken is an author of the paper \"Neural architecture search: A survey\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JAN HENDRIK METZEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jan Hendrik Metzen is an author of the paper \"Neural architecture search: A survey\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"FRANK HUTTER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Frank Hutter is an author of the paper \"Neural architecture search: A survey\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NEURAL ARCHITECTURE SEARCH: A SURVEY\">      <data key=\"d0\">PAPER<\/data>      <data key=\"d1\">Neural architecture search: A survey is a paper authored by Thomas Elsken, Jan Hendrik Metzen, and Frank Hutter, published in the Journal of Machine Learning Research in 2019<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PAPER<\/data>    <\/node>    <node id=\"MAXENCE FALDOR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Maxence Faldor is an author of the paper \"Omni-epic: Open-endedness via models of human notions of interestingness with environments programmed in code\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JENNY ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jenny Zhang is an author of the paper \"Omni-epic: Open-endedness via models of human notions of interestingness with environments programmed in code\"<\/data>      <data key=\"d2\">022e7927d281e80e188f29ea343cc115<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>  <\/graph><\/graphml>"}
{"id":"6109537356a2ce2339f77c827aa3668e","chunk":", Yiming Yang, Jamie Callan, and\nGraham Neubig. Pal: Program-aided language models. In International Conference on Machine\nLearning , pp. 10764\u201310799. PMLR, 2023.\nRyan Greenblatt. Getting 50% sota on arc-agi with gpt-4. https:\/\/redwoodresearch.substack.\ncom\/p\/getting-50-sota-on-arc-agi-with-gpt , July 2024. Technical Report.\nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob\nSteinhardt. Measuring massive multitask language understanding. In International Conference on\nLearning Representations , 2021.\n16Automated Design of Agentic Systems\nSirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang,\nSteven Ka Shing Yau, Zijuan Lin, Liyang Zhou, et al. Metagpt: Meta programming for multi-agent\ncollaborative framework. arXiv preprint arXiv:2308.00352 , 2023.\nShengran Hu and Jeff Clune. Thought Cloning: Learning to think while acting by imitating human\nthinking. Advances in Neural Information Processing Systems , 36, 2024.\nShengran Hu, Ran Cheng, Cheng He, Zhichao Lu, Jing Wang, and Miao Zhang. Accelerating multi-\nobjective neural architecture search by random-weight evaluation. Complex & Intelligent Systems ,\npp. 1\u201310, 2021.\nShihua Huang, Zhichao Lu, Kalyanmoy Deb, and Vishnu Naresh Boddeti. Revisiting residual networks\nfor adversarial robustness. In Proceedings of the IEEE\/CVF Conference on Computer Vision and Pattern\nRecognition , pp. 8202\u20138211, 2023.\nFrank Hutter, Lars Kotthoff, and Joaquin Vanschoren. Automated machine learning: methods, systems,\nchallenges . Springer Nature, 2019.\nOmar Khattab, Arnav Singhvi, Paridhi Maheshwari, Zhiyuan Zhang, Keshav Santhanam, Saiful\nHaq, Ashutosh Sharma, Thomas T Joshi, Hanna Moazam, Heather Miller, et al. Dspy: Compiling\ndeclarative language model calls into state-of-the-art pipelines. In The Twelfth International\nConference on Learning Representations , 2024.\nAlexKrizhevsky,IlyaSutskever,andGeoffreyEHinton. Imagenetclassificationwithdeepconvolutional\nneural networks. Advances in neural information processing systems , 25, 2012.\nAbrahim Ladha. Lecture 11: Turing-completeness. https:\/\/faculty.cc.gatech.edu\/~ladha\/\nS24\/4510\/L11.pdf , 2024. CS 4510 Automata and Complexity, February 21st, 2024, Scribed by\nRishabh Singhal.\nLangChainAI. Langchain: Build context-aware reasoning applications. https:\/\/github.com\/\nlangchain-ai\/langchain , 2022.\nJoel Lehman and Kenneth O Stanley. Abandoning objectives: Evolution through the search for novelty\nalone.Evolutionary computation , 19(2):189\u2013223, 2011.\nPatrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal,\nHeinrich K\u00fcttler, Mike Lewis, Wen-tau Yih, Tim Rockt\u00e4schel, et al. Retrieval-augmented generation\nforknowledge-intensivenlptasks. AdvancesinNeuralInformationProcessingSystems ,33:9459\u20139474,\n2020.\nFei Liu, Tong Xialiang, Mingxuan Yuan, Xi Lin, Fu Luo, Zhenkun Wang, Zhichao Lu, and Qingfu\nZhang. Evolution of heuristics: Towards efficient automatic algorithm design using large language\nmodel. In Forty-first International Conference on Machine Learning , 2024.\nZijun Liu, Yanzhe Zhang, Peng Li, Yang Liu, and Diyi Yang. Dynamic llm-agent network: An llm-agent\ncollaboration framework with agent team optimization. arXiv preprint arXiv:2310.02170 , 2023.\nChris Lu, Sebastian Towers, and Jakob Foerster. Arbitrary order meta-learning with simple population-\nbased evolution. In ALIFE 2023: Ghost in the Machine: Proceedings of the 2023 Artificial Life\nConference . MIT Press, 2023.\nChris Lu, Samuel Holt, Claudio Fanconi, Alex J Chan, Jakob Foerster, Mihaela van der Schaar, and\nRobert Tjarko Lange. Discovering preference optimization algorithms with and for large language\nmodels. arXiv preprint arXiv:2406.08414 , 2024a.\n17Automated Design of Agentic Systems\nChris Lu, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff Clune, and David Ha. The AI Scientist:\nTowards fully automated open-ended scientific discovery. arXiv preprint arXiv:2408.06292 , 2024b.\nCong Lu, Shengran Hu, and Jeff Clune. Intelligent go-explore: Standing on the shoulders of giant\nfoundation models. arXiv preprint arXiv:2405.15143 , 2024c.\nZhichao Lu, Ian Whalen, Vishnu Boddeti, Yashesh Dhe","chunk_id":"6109537356a2ce2339f77c827aa3668e","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"YIMING YANG","type":"PERSON","description":"Yiming Yang is an author of the paper \"Pal: Program-aided language models\"","source_id":"6109537356a2ce2339f77c827aa3668e"},{"name":"JAMIE CALLAN","type":"PERSON","description":"Jamie Callan is an author of the paper \"Pal: Program-aided language models\"","source_id":"6109537356a2ce2339f77c827aa3668e"},{"name":"GRAHAM NEUBIG","type":"PERSON","description":"Graham Neubig is an author of the paper \"Pal: Program-aided language models\"","source_id":"6109537356a2ce2339f77c827aa3668e"},{"name":"PAL","type":"TOOL\/FRAMEWORK","description":"Pal is a program-aided language model discussed in the paper by Yiming Yang, Jamie Callan, and Graham Neubig","source_id":"6109537356a2ce2339f77c827aa3668e"},{"name":"INTERNATIONAL CONFERENCE ON MACHINE LEARNING","type":"CONFERENCE","description":"The conference where the paper \"Pal: Program-aided language models\" was presented","source_id":"6109537356a2ce2339f77c827aa3668e"},{"name":"RYAN GREENBLATT","type":"PERSON","description":"Ryan Greenblatt is the author of the technical report \"Getting 50% sota on arc-agi with gpt-4\"","source_id":"6109537356a2ce2339f77c827aa3668e"},{"name":"GPT-4","type":"MODEL","description":"GPT-4 is a language model mentioned in the technical report by Ryan Greenblatt","source_id":"6109537356a2ce2339f77c827aa3668e"},{"name":"DAN HENDRYCKS","type":"PERSON","description":"Dan Hendrycks is an author of the paper \"Measuring massive multitask language understanding\"","source_id":"6109537356a2ce2339f77c827aa3668e"},{"name":"COLLIN BURNS","type":"PERSON","description":"Collin Burns is an author of the paper \"Measuring massive multitask language understanding\"","source_id":"6109537356a2ce2339f77c827aa3668e"},{"name":"STEVEN BASART","type":"PERSON","description":"Steven Basart is an author of the paper \"Measuring massive multitask language understanding\"","source_id":"6109537356a2ce2339f77c827aa3668e"},{"name":"ANDY ZOU","type":"PERSON","description":"Andy Zou is an author of the paper \"Measuring massive multitask language understanding\"","source_id":"6109537356a2ce2339f77c827aa3668e"},{"name":"MANTAS MAZEIKA","type":"PERSON","description":"Mantas Mazeika is an author of the paper \"Measuring massive multitask language understanding\"","source_id":"6109537356a2ce2339f77c827aa3668e"},{"name":"DAWN SONG","type":"PERSON","description":"Dawn Song is an author of the paper \"Measuring massive multitask language understanding\"","source_id":"6109537356a2ce2339f77c827aa3668e"},{"name":"JACOB STEINHARDT","type":"PERSON","description":"Jacob Steinhardt is an author of the paper \"Measuring massive multitask language understanding\"","source_id":"6109537356a2ce2339f77c827aa3668e"},{"name":"INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS","type":"CONFERENCE","description":"The conference where the paper \"Measuring massive multitask language understanding\" was presented","source_id":"6109537356a2ce2339f77c827aa3668e"},{"name":"SIRUI HONG","type":"PERSON","description":"Sirui Hong is an author of the paper \"Metagpt: Meta programming for multi-agent collaborative framework\"","source_id":"6109537356a2ce2339f77c827aa3668e"},{"name":"XIAWU ZHENG","type":"PERSON","description":"Xiawu Zheng is an author of the paper \"Metagpt: Meta programming for multi-agent collaborative framework\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"JONATHAN CHEN","type":"PERSON","description":"Jonathan Chen is an author of the paper \"Metagpt: Meta programming for multi-agent collaborative framework\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"YUHENG CHENG","type":"PERSON","description":"Yuheng Cheng is an author of the paper \"Metagpt: Meta programming for multi-agent collaborative framework\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"JINLIN WANG","type":"PERSON","description":"Jinlin Wang is an author of the paper \"Metagpt: Meta programming for multi-agent collaborative framework\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"CEYAO ZHANG","type":"PERSON","description":"Ceyao Zhang is an author of the paper \"Metagpt: Meta programming for multi-agent collaborative framework\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"ZILI WANG","type":"PERSON","description":"Zili Wang is an author of the paper \"Metagpt: Meta programming for multi-agent collaborative framework\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"STEVEN KA SHING YAU","type":"PERSON","description":"Steven Ka Shing Yau is an author of the paper \"Metagpt: Meta programming for multi-agent collaborative framework\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"ZIJUAN LIN","type":"PERSON","description":"Zijuan Lin is an author of the paper \"Metagpt: Meta programming for multi-agent collaborative framework\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"LIYANG ZHOU","type":"PERSON","description":"Liyang Zhou is an author of the paper \"Metagpt: Meta programming for multi-agent collaborative framework\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"METAGPT","type":"TOOL\/FRAMEWORK","description":"Metagpt is a meta programming framework for multi-agent collaboration discussed in the paper by Sirui Hong et al.","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"TOOL\/FRAMEWORK"},{"name":"ARXIV","type":"PUBLICATION","description":"The platform where the paper \"Metagpt: Meta programming for multi-agent collaborative framework\" was published\nThe platform where the paper \"Discovering preference optimization algorithms with and for large language models\" was published\nThe platform where the paper \"Dynamic llm-agent network: An llm-agent collaboration framework with agent team optimization\" was published","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PUBLICATION"},{"name":"SHENGRAN HU","type":"PERSON","description":"Shengran Hu is an author of the paper \"Thought Cloning: Learning to think while acting by imitating human thinking\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"JEFF CLUNE","type":"PERSON","description":"Jeff Clune is an author of the paper \"Thought Cloning: Learning to think while acting by imitating human thinking\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS","type":"CONFERENCE","description":"The conference where the paper \"Imagenet classification with deep convolutional neural networks\" was presented\nThe conference where the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\" was presented\nThe conference where the paper \"Thought Cloning: Learning to think while acting by imitating human thinking\" was presented","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"CONFERENCE"},{"name":"RAN CHENG","type":"PERSON","description":"Ran Cheng is an author of the paper \"Accelerating multi-objective neural architecture search by random-weight evaluation\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"CHENG HE","type":"PERSON","description":"Cheng He is an author of the paper \"Accelerating multi-objective neural architecture search by random-weight evaluation\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"ZHICHAO LU","type":"PERSON","description":"Zhichao Lu is an author of the paper \"Accelerating multi-objective neural architecture search by random-weight evaluation\"\nZhichao Lu is an author of the paper \"Evolution of heuristics: Towards efficient automatic algorithm design using large language model\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"JING WANG","type":"PERSON","description":"Jing Wang is an author of the paper \"Accelerating multi-objective neural architecture search by random-weight evaluation\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"MIAO ZHANG","type":"PERSON","description":"Miao Zhang is an author of the paper \"Accelerating multi-objective neural architecture search by random-weight evaluation\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"COMPLEX & INTELLIGENT SYSTEMS","type":"PUBLICATION","description":"The journal where the paper \"Accelerating multi-objective neural architecture search by random-weight evaluation\" was published","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PUBLICATION"},{"name":"SHIHUA HUANG","type":"PERSON","description":"Shihua Huang is an author of the paper \"Revisiting residual networks for adversarial robustness\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"KALYANMOY DEB","type":"PERSON","description":"Kalyanmoy Deb is an author of the paper \"Revisiting residual networks for adversarial robustness\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"VISHNU NARESH BODDETI","type":"PERSON","description":"Vishnu Naresh Boddeti is an author of the paper \"Revisiting residual networks for adversarial robustness\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"IEEE\/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION","type":"CONFERENCE","description":"The conference where the paper \"Revisiting residual networks for adversarial robustness\" was presented","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"CONFERENCE"},{"name":"FRANK HUTTER","type":"PERSON","description":"Frank Hutter is an author of the book \"Automated machine learning: methods, systems, challenges\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"LARS KOTTHOFF","type":"PERSON","description":"Lars Kotthoff is an author of the book \"Automated machine learning: methods, systems, challenges\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"JOAQUIN VANSCHOREN","type":"PERSON","description":"Joaquin Vanschoren is an author of the book \"Automated machine learning: methods, systems, challenges\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"SPRINGER NATURE","type":"PUBLISHER","description":"The publisher of the book \"Automated machine learning: methods, systems, challenges\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PUBLISHER"},{"name":"OMAR KHATTAB","type":"PERSON","description":"Omar Khattab is an author of the paper \"Dspy: Compiling declarative language model calls into state-of-the-art pipelines\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"ARNAV SINGHVI","type":"PERSON","description":"Arnav Singhvi is an author of the paper \"Dspy: Compiling declarative language model calls into state-of-the-art pipelines\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"PARIDHI MAHESHWARI","type":"PERSON","description":"Paridhi Maheshwari is an author of the paper \"Dspy: Compiling declarative language model calls into state-of-the-art pipelines\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"ZHIYUAN ZHANG","type":"PERSON","description":"Zhiyuan Zhang is an author of the paper \"Dspy: Compiling declarative language model calls into state-of-the-art pipelines\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"KESHAV SANTHANAM","type":"PERSON","description":"Keshav Santhanam is an author of the paper \"Dspy: Compiling declarative language model calls into state-of-the-art pipelines\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"SAIFUL HAQ","type":"PERSON","description":"Saiful Haq is an author of the paper \"Dspy: Compiling declarative language model calls into state-of-the-art pipelines\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"ASHUTOSH SHARMA","type":"PERSON","description":"Ashutosh Sharma is an author of the paper \"Dspy: Compiling declarative language model calls into state-of-the-art pipelines\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"THOMAS T JOSHI","type":"PERSON","description":"Thomas T Joshi is an author of the paper \"Dspy: Compiling declarative language model calls into state-of-the-art pipelines\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"HANNA MOAZAM","type":"PERSON","description":"Hanna Moazam is an author of the paper \"Dspy: Compiling declarative language model calls into state-of-the-art pipelines\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"HEATHER MILLER","type":"PERSON","description":"Heather Miller is an author of the paper \"Dspy: Compiling declarative language model calls into state-of-the-art pipelines\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS","type":"CONFERENCE","description":"The conference where the paper \"Dspy: Compiling declarative language model calls into state-of-the-art pipelines\" was presented","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"CONFERENCE"},{"name":"ALEX KRIZHEVSKY","type":"PERSON","description":"Alex Krizhevsky is an author of the paper \"Imagenet classification with deep convolutional neural networks\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"ILYA SUTSKEVER","type":"PERSON","description":"Ilya Sutskever is an author of the paper \"Imagenet classification with deep convolutional neural networks\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"GEOFFREY E HINTON","type":"PERSON","description":"Geoffrey E Hinton is an author of the paper \"Imagenet classification with deep convolutional neural networks\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"ABRAHIM LADHA","type":"PERSON","description":"Abrahim Ladha is the author of the lecture \"Lecture 11: Turing-completeness\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"CS 4510 AUTOMATA AND COMPLEXITY","type":"COURSE","description":"The course for which the lecture \"Lecture 11: Turing-completeness\" was given","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"COURSE"},{"name":"RISHABH SINGHAL","type":"PERSON","description":"Rishabh Singhal is the scribe for the lecture \"Lecture 11: Turing-completeness\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"LANGCHAINAI","type":"ORGANIZATION","description":"LangChainAI is the organization behind the Langchain project","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"ORGANIZATION"},{"name":"LANGCHAIN","type":"TOOL\/FRAMEWORK","description":"Langchain is a tool for building context-aware reasoning applications developed by LangChainAI","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"TOOL\/FRAMEWORK"},{"name":"JOEL LEHMAN","type":"PERSON","description":"Joel Lehman is an author of the paper \"Abandoning objectives: Evolution through the search for novelty alone\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"KENNETH O STANLEY","type":"PERSON","description":"Kenneth O Stanley is an author of the paper \"Abandoning objectives: Evolution through the search for novelty alone\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"EVOLUTIONARY COMPUTATION","type":"PUBLICATION","description":"The journal where the paper \"Abandoning objectives: Evolution through the search for novelty alone\" was published","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PUBLICATION"},{"name":"PATRICK LEWIS","type":"PERSON","description":"Patrick Lewis is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"ETHAN PEREZ","type":"PERSON","description":"Ethan Perez is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"ALEKSANDRA PIKTUS","type":"PERSON","description":"Aleksandra Piktus is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"FABIO PETRONI","type":"PERSON","description":"Fabio Petroni is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"VLADIMIR KARPUKHIN","type":"PERSON","description":"Vladimir Karpukhin is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"NAMAN GOYAL","type":"PERSON","description":"Naman Goyal is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"HEINRICH K\u00dcTTLER","type":"PERSON","description":"Heinrich K\u00fcttler is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"MIKE LEWIS","type":"PERSON","description":"Mike Lewis is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"WEN-TAU YIH","type":"PERSON","description":"Wen-tau Yih is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"TIM ROCKT\u00c4SCHEL","type":"PERSON","description":"Tim Rockt\u00e4schel is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"FEI LIU","type":"PERSON","description":"Fei Liu is an author of the paper \"Evolution of heuristics: Towards efficient automatic algorithm design using large language model\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"TONG XIALIANG","type":"PERSON","description":"Tong Xialiang is an author of the paper \"Evolution of heuristics: Towards efficient automatic algorithm design using large language model\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"MINGXUAN YUAN","type":"PERSON","description":"Mingxuan Yuan is an author of the paper \"Evolution of heuristics: Towards efficient automatic algorithm design using large language model\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"XI LIN","type":"PERSON","description":"Xi Lin is an author of the paper \"Evolution of heuristics: Towards efficient automatic algorithm design using large language model\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"FU LUO","type":"PERSON","description":"Fu Luo is an author of the paper \"Evolution of heuristics: Towards efficient automatic algorithm design using large language model\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"ZHENKUN WANG","type":"PERSON","description":"Zhenkun Wang is an author of the paper \"Evolution of heuristics: Towards efficient automatic algorithm design using large language model\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"QINGFU ZHANG","type":"PERSON","description":"Qingfu Zhang is an author of the paper \"Evolution of heuristics: Towards efficient automatic algorithm design using large language model\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"FORTY-FIRST INTERNATIONAL CONFERENCE ON MACHINE LEARNING","type":"CONFERENCE","description":"The conference where the paper \"Evolution of heuristics: Towards efficient automatic algorithm design using large language model\" was presented","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"CONFERENCE"},{"name":"ZIJUN LIU","type":"PERSON","description":"Zijun Liu is an author of the paper \"Dynamic llm-agent network: An llm-agent collaboration framework with agent team optimization\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"YANZHE ZHANG","type":"PERSON","description":"Yanzhe Zhang is an author of the paper \"Dynamic llm-agent network: An llm-agent collaboration framework with agent team optimization\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"PENG LI","type":"PERSON","description":"Peng Li is an author of the paper \"Dynamic llm-agent network: An llm-agent collaboration framework with agent team optimization\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"YANG LIU","type":"PERSON","description":"Yang Liu is an author of the paper \"Dynamic llm-agent network: An llm-agent collaboration framework with agent team optimization\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"DIYI YANG","type":"PERSON","description":"Diyi Yang is an author of the paper \"Dynamic llm-agent network: An llm-agent collaboration framework with agent team optimization\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"CHRIS LU","type":"PERSON","description":"Chris Lu is an author of the paper \"The AI Scientist: Towards fully automated open-ended scientific discovery\"\nChris Lu is an author of the paper \"Arbitrary order meta-learning with simple population-based evolution\"\nChris Lu is an author of the paper \"Discovering preference optimization algorithms with and for large language models\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"SEBASTIAN TOWERS","type":"PERSON","description":"Sebastian Towers is an author of the paper \"Arbitrary order meta-learning with simple population-based evolution\"\nSebastian Towers is an author","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"JAKOB FOERSTER","type":"PERSON","description":"Jakob Foerster is an author of the paper \"Arbitrary order meta-learning with simple population-based evolution\"\nJakob Foerster is an author of the paper \"Discovering preference optimization algorithms with and for large language models\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"ALIFE 2023: GHOST IN THE MACHINE: PROCEEDINGS OF THE 2023 ARTIFICIAL LIFE CONFERENCE","type":"CONFERENCE","description":"The conference where the paper \"Arbitrary order meta-learning with simple population-based evolution\" was presented","source_id":"6109537356a2ce2339f77c827aa3668e"},{"name":"MIT PRESS","type":"PUBLISHER","description":"The publisher of the proceedings \"ALIFE 2023: Ghost in the Machine: Proceedings of the 2023 Artificial Life Conference\"","source_id":"6109537356a2ce2339f77c827aa3668e"},{"name":"SAMUEL HOLT","type":"PERSON","description":"Samuel Holt is an author of the paper \"Discovering preference optimization algorithms with and for large language models\"","source_id":"6109537356a2ce2339f77c827aa3668e"},{"name":"CLAUDIO FANCONI","type":"PERSON","description":"Claudio Fanconi is an author of the paper \"Discovering preference optimization algorithms with and for large language models\"","source_id":"6109537356a2ce2339f77c827aa3668e"},{"name":"ALEX J CHAN","type":"PERSON","description":"Alex J Chan is an author of the paper \"Discovering preference optimization algorithms with and for large language models\"","source_id":"6109537356a2ce2339f77c827aa3668e"},{"name":"MIHAELA VAN DER SCHAAR","type":"PERSON","description":"Mihaela van der Schaar is an author of the paper \"Discovering preference optimization algorithms with and for large language models\"","source_id":"6109537356a2ce2339f77c827aa3668e"},{"name":"ROBERT TJARKO LANGE","type":"PERSON","description":"Robert Tjarko Lange is an author of the paper \"Discovering preference optimization algorithms with and for large language models\"\nRobert Tjarko Lange is an author of the paper \"The AI Scientist: Towards fully automated open-ended scientific discovery\"","source_id":"6109537356a2ce2339f77c827aa3668e","entity_type":"PERSON"},{"name":"CONG LU","type":"PERSON","description":"Cong Lu is an author of the paper \"The AI Scientist: Towards fully automated open-ended scientific discovery\"","source_id":"6109537356a2ce2339f77c827aa3668e"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"YIMING YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yiming Yang is an author of the paper \"Pal: Program-aided language models\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>    <node id=\"JAMIE CALLAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jamie Callan is an author of the paper \"Pal: Program-aided language models\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>    <node id=\"GRAHAM NEUBIG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Graham Neubig is an author of the paper \"Pal: Program-aided language models\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>    <node id=\"PAL\">      <data key=\"d0\">TOOL\/FRAMEWORK<\/data>      <data key=\"d1\">Pal is a program-aided language model discussed in the paper by Yiming Yang, Jamie Callan, and Graham Neubig<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>    <node id=\"INTERNATIONAL CONFERENCE ON MACHINE LEARNING\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">The conference where the paper \"Pal: Program-aided language models\" was presented<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>    <node id=\"RYAN GREENBLATT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ryan Greenblatt is the author of the technical report \"Getting 50% sota on arc-agi with gpt-4\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4 is a language model mentioned in the technical report by Ryan Greenblatt<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>    <node id=\"DAN HENDRYCKS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dan Hendrycks is an author of the paper \"Measuring massive multitask language understanding\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>    <node id=\"COLLIN BURNS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Collin Burns is an author of the paper \"Measuring massive multitask language understanding\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>    <node id=\"STEVEN BASART\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Steven Basart is an author of the paper \"Measuring massive multitask language understanding\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>    <node id=\"ANDY ZOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Andy Zou is an author of the paper \"Measuring massive multitask language understanding\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>    <node id=\"MANTAS MAZEIKA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mantas Mazeika is an author of the paper \"Measuring massive multitask language understanding\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>    <node id=\"DAWN SONG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dawn Song is an author of the paper \"Measuring massive multitask language understanding\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>    <node id=\"JACOB STEINHARDT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jacob Steinhardt is an author of the paper \"Measuring massive multitask language understanding\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>    <node id=\"INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">The conference where the paper \"Measuring massive multitask language understanding\" was presented<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>    <node id=\"SIRUI HONG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sirui Hong is an author of the paper \"Metagpt: Meta programming for multi-agent collaborative framework\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>    <node id=\"XIAWU ZHENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xiawu Zheng is an author of the paper \"Metagpt: Meta programming for multi-agent collaborative framework\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JONATHAN CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jonathan Chen is an author of the paper \"Metagpt: Meta programming for multi-agent collaborative framework\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YUHENG CHENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yuheng Cheng is an author of the paper \"Metagpt: Meta programming for multi-agent collaborative framework\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JINLIN WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jinlin Wang is an author of the paper \"Metagpt: Meta programming for multi-agent collaborative framework\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CEYAO ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ceyao Zhang is an author of the paper \"Metagpt: Meta programming for multi-agent collaborative framework\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZILI WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zili Wang is an author of the paper \"Metagpt: Meta programming for multi-agent collaborative framework\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"STEVEN KA SHING YAU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Steven Ka Shing Yau is an author of the paper \"Metagpt: Meta programming for multi-agent collaborative framework\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZIJUAN LIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zijuan Lin is an author of the paper \"Metagpt: Meta programming for multi-agent collaborative framework\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LIYANG ZHOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Liyang Zhou is an author of the paper \"Metagpt: Meta programming for multi-agent collaborative framework\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"METAGPT\">      <data key=\"d0\">TOOL\/FRAMEWORK<\/data>      <data key=\"d1\">Metagpt is a meta programming framework for multi-agent collaboration discussed in the paper by Sirui Hong et al.<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">TOOL\/FRAMEWORK<\/data>    <\/node>    <node id=\"ARXIV\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The platform where the paper \"Metagpt: Meta programming for multi-agent collaborative framework\" was publishedThe platform where the paper \"Discovering preference optimization algorithms with and for large language models\" was publishedThe platform where the paper \"Dynamic llm-agent network: An llm-agent collaboration framework with agent team optimization\" was published<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"SHENGRAN HU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shengran Hu is an author of the paper \"Thought Cloning: Learning to think while acting by imitating human thinking\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JEFF CLUNE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jeff Clune is an author of the paper \"Thought Cloning: Learning to think while acting by imitating human thinking\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">The conference where the paper \"Imagenet classification with deep convolutional neural networks\" was presentedThe conference where the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\" was presentedThe conference where the paper \"Thought Cloning: Learning to think while acting by imitating human thinking\" was presented<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">CONFERENCE<\/data>    <\/node>    <node id=\"RAN CHENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ran Cheng is an author of the paper \"Accelerating multi-objective neural architecture search by random-weight evaluation\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHENG HE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Cheng He is an author of the paper \"Accelerating multi-objective neural architecture search by random-weight evaluation\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHICHAO LU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhichao Lu is an author of the paper \"Accelerating multi-objective neural architecture search by random-weight evaluation\"Zhichao Lu is an author of the paper \"Evolution of heuristics: Towards efficient automatic algorithm design using large language model\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JING WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jing Wang is an author of the paper \"Accelerating multi-objective neural architecture search by random-weight evaluation\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MIAO ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Miao Zhang is an author of the paper \"Accelerating multi-objective neural architecture search by random-weight evaluation\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"COMPLEX &amp; INTELLIGENT SYSTEMS\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The journal where the paper \"Accelerating multi-objective neural architecture search by random-weight evaluation\" was published<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"SHIHUA HUANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shihua Huang is an author of the paper \"Revisiting residual networks for adversarial robustness\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KALYANMOY DEB\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kalyanmoy Deb is an author of the paper \"Revisiting residual networks for adversarial robustness\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"VISHNU NARESH BODDETI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Vishnu Naresh Boddeti is an author of the paper \"Revisiting residual networks for adversarial robustness\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"IEEE\/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">The conference where the paper \"Revisiting residual networks for adversarial robustness\" was presented<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">CONFERENCE<\/data>    <\/node>    <node id=\"FRANK HUTTER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Frank Hutter is an author of the book \"Automated machine learning: methods, systems, challenges\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LARS KOTTHOFF\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lars Kotthoff is an author of the book \"Automated machine learning: methods, systems, challenges\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JOAQUIN VANSCHOREN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joaquin Vanschoren is an author of the book \"Automated machine learning: methods, systems, challenges\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SPRINGER NATURE\">      <data key=\"d0\">PUBLISHER<\/data>      <data key=\"d1\">The publisher of the book \"Automated machine learning: methods, systems, challenges\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PUBLISHER<\/data>    <\/node>    <node id=\"OMAR KHATTAB\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Omar Khattab is an author of the paper \"Dspy: Compiling declarative language model calls into state-of-the-art pipelines\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ARNAV SINGHVI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Arnav Singhvi is an author of the paper \"Dspy: Compiling declarative language model calls into state-of-the-art pipelines\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PARIDHI MAHESHWARI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Paridhi Maheshwari is an author of the paper \"Dspy: Compiling declarative language model calls into state-of-the-art pipelines\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHIYUAN ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhiyuan Zhang is an author of the paper \"Dspy: Compiling declarative language model calls into state-of-the-art pipelines\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KESHAV SANTHANAM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Keshav Santhanam is an author of the paper \"Dspy: Compiling declarative language model calls into state-of-the-art pipelines\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SAIFUL HAQ\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Saiful Haq is an author of the paper \"Dspy: Compiling declarative language model calls into state-of-the-art pipelines\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ASHUTOSH SHARMA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ashutosh Sharma is an author of the paper \"Dspy: Compiling declarative language model calls into state-of-the-art pipelines\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"THOMAS T JOSHI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Thomas T Joshi is an author of the paper \"Dspy: Compiling declarative language model calls into state-of-the-art pipelines\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HANNA MOAZAM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hanna Moazam is an author of the paper \"Dspy: Compiling declarative language model calls into state-of-the-art pipelines\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HEATHER MILLER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Heather Miller is an author of the paper \"Dspy: Compiling declarative language model calls into state-of-the-art pipelines\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">The conference where the paper \"Dspy: Compiling declarative language model calls into state-of-the-art pipelines\" was presented<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">CONFERENCE<\/data>    <\/node>    <node id=\"ALEX KRIZHEVSKY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Alex Krizhevsky is an author of the paper \"Imagenet classification with deep convolutional neural networks\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ILYA SUTSKEVER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ilya Sutskever is an author of the paper \"Imagenet classification with deep convolutional neural networks\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GEOFFREY E HINTON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Geoffrey E Hinton is an author of the paper \"Imagenet classification with deep convolutional neural networks\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ABRAHIM LADHA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Abrahim Ladha is the author of the lecture \"Lecture 11: Turing-completeness\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CS 4510 AUTOMATA AND COMPLEXITY\">      <data key=\"d0\">COURSE<\/data>      <data key=\"d1\">The course for which the lecture \"Lecture 11: Turing-completeness\" was given<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">COURSE<\/data>    <\/node>    <node id=\"RISHABH SINGHAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Rishabh Singhal is the scribe for the lecture \"Lecture 11: Turing-completeness\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LANGCHAINAI\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">LangChainAI is the organization behind the Langchain project<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"LANGCHAIN\">      <data key=\"d0\">TOOL\/FRAMEWORK<\/data>      <data key=\"d1\">Langchain is a tool for building context-aware reasoning applications developed by LangChainAI<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">TOOL\/FRAMEWORK<\/data>    <\/node>    <node id=\"JOEL LEHMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joel Lehman is an author of the paper \"Abandoning objectives: Evolution through the search for novelty alone\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KENNETH O STANLEY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kenneth O Stanley is an author of the paper \"Abandoning objectives: Evolution through the search for novelty alone\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"EVOLUTIONARY COMPUTATION\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The journal where the paper \"Abandoning objectives: Evolution through the search for novelty alone\" was published<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"PATRICK LEWIS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Patrick Lewis is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ETHAN PEREZ\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ethan Perez is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ALEKSANDRA PIKTUS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Aleksandra Piktus is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"FABIO PETRONI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Fabio Petroni is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"VLADIMIR KARPUKHIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Vladimir Karpukhin is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NAMAN GOYAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Naman Goyal is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HEINRICH K&#220;TTLER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Heinrich K&#252;ttler is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MIKE LEWIS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mike Lewis is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WEN-TAU YIH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wen-tau Yih is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TIM ROCKT&#196;SCHEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tim Rockt&#228;schel is an author of the paper \"Retrieval-augmented generation for knowledge-intensive NLP tasks\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"FEI LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Fei Liu is an author of the paper \"Evolution of heuristics: Towards efficient automatic algorithm design using large language model\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TONG XIALIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tong Xialiang is an author of the paper \"Evolution of heuristics: Towards efficient automatic algorithm design using large language model\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MINGXUAN YUAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mingxuan Yuan is an author of the paper \"Evolution of heuristics: Towards efficient automatic algorithm design using large language model\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XI LIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xi Lin is an author of the paper \"Evolution of heuristics: Towards efficient automatic algorithm design using large language model\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"FU LUO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Fu Luo is an author of the paper \"Evolution of heuristics: Towards efficient automatic algorithm design using large language model\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHENKUN WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhenkun Wang is an author of the paper \"Evolution of heuristics: Towards efficient automatic algorithm design using large language model\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"QINGFU ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Qingfu Zhang is an author of the paper \"Evolution of heuristics: Towards efficient automatic algorithm design using large language model\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"FORTY-FIRST INTERNATIONAL CONFERENCE ON MACHINE LEARNING\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">The conference where the paper \"Evolution of heuristics: Towards efficient automatic algorithm design using large language model\" was presented<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">CONFERENCE<\/data>    <\/node>    <node id=\"ZIJUN LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zijun Liu is an author of the paper \"Dynamic llm-agent network: An llm-agent collaboration framework with agent team optimization\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YANZHE ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yanzhe Zhang is an author of the paper \"Dynamic llm-agent network: An llm-agent collaboration framework with agent team optimization\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PENG LI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Peng Li is an author of the paper \"Dynamic llm-agent network: An llm-agent collaboration framework with agent team optimization\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YANG LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yang Liu is an author of the paper \"Dynamic llm-agent network: An llm-agent collaboration framework with agent team optimization\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DIYI YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Diyi Yang is an author of the paper \"Dynamic llm-agent network: An llm-agent collaboration framework with agent team optimization\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHRIS LU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chris Lu is an author of the paper \"The AI Scientist: Towards fully automated open-ended scientific discovery\"Chris Lu is an author of the paper \"Arbitrary order meta-learning with simple population-based evolution\"Chris Lu is an author of the paper \"Discovering preference optimization algorithms with and for large language models\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SEBASTIAN TOWERS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sebastian Towers is an author of the paper \"Arbitrary order meta-learning with simple population-based evolution\"Sebastian Towers is an author<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JAKOB FOERSTER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jakob Foerster is an author of the paper \"Arbitrary order meta-learning with simple population-based evolution\"Jakob Foerster is an author of the paper \"Discovering preference optimization algorithms with and for large language models\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ALIFE 2023: GHOST IN THE MACHINE: PROCEEDINGS OF THE 2023 ARTIFICIAL LIFE CONFERENCE\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">The conference where the paper \"Arbitrary order meta-learning with simple population-based evolution\" was presented<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>    <node id=\"MIT PRESS\">      <data key=\"d0\">PUBLISHER<\/data>      <data key=\"d1\">The publisher of the proceedings \"ALIFE 2023: Ghost in the Machine: Proceedings of the 2023 Artificial Life Conference\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>    <node id=\"SAMUEL HOLT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Samuel Holt is an author of the paper \"Discovering preference optimization algorithms with and for large language models\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>    <node id=\"CLAUDIO FANCONI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Claudio Fanconi is an author of the paper \"Discovering preference optimization algorithms with and for large language models\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>    <node id=\"ALEX J CHAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Alex J Chan is an author of the paper \"Discovering preference optimization algorithms with and for large language models\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>    <node id=\"MIHAELA VAN DER SCHAAR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mihaela van der Schaar is an author of the paper \"Discovering preference optimization algorithms with and for large language models\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>    <node id=\"ROBERT TJARKO LANGE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Robert Tjarko Lange is an author of the paper \"Discovering preference optimization algorithms with and for large language models\"Robert Tjarko Lange is an author of the paper \"The AI Scientist: Towards fully automated open-ended scientific discovery\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CONG LU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Cong Lu is an author of the paper \"The AI Scientist: Towards fully automated open-ended scientific discovery\"<\/data>      <data key=\"d2\">6109537356a2ce2339f77c827aa3668e<\/data>    <\/node>  <\/graph><\/graphml>"}
{"id":"1b1399c76420a477c0c97893d258ae69","chunk":" The AI Scientist:\nTowards fully automated open-ended scientific discovery. arXiv preprint arXiv:2408.06292 , 2024b.\nCong Lu, Shengran Hu, and Jeff Clune. Intelligent go-explore: Standing on the shoulders of giant\nfoundation models. arXiv preprint arXiv:2405.15143 , 2024c.\nZhichao Lu, Ian Whalen, Vishnu Boddeti, Yashesh Dhebar, Kalyanmoy Deb, Erik Goodman, and\nWolfgang Banzhaf. Nsga-net: neural architecture search using multi-objective genetic algorithm.\nInProceedings of the genetic and evolutionary computation conference , pp. 419\u2013427, 2019.\nYecheng Jason Ma, William Liang, Guanzhi Wang, De-An Huang, Osbert Bastani, Dinesh Jayaraman,\nYuke Zhu, Linxi Fan, and Anima Anandkumar. Eureka: Human-level reward design via coding\nlarge language models. In The Twelfth International Conference on Learning Representations , 2023.\nAman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri\nAlon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et al. Self-refine: Iterative refinement with\nself-feedback. Advances in Neural Information Processing Systems , 36, 2024.\nMeta. Open source ai is the path forward. https:\/\/about.fb.com\/news\/2024\/07\/\nopen-source-ai-is-the-path-forward\/ , July 2024. News article.\nElliot Meyerson, Mark J Nelson, Herbie Bradley, Adam Gaier, Arash Moradi, Amy K Hoover, and\nJoel Lehman. Language model crossover: Variation through few-shot prompting. arXiv preprint\narXiv:2302.12170 , 2023.\nShen-yun Miao, Chao-Chun Liang, and Keh-Yih Su. A diverse corpus for evaluating and developing\nenglish math word problem solvers. In Proceedings of the 58th Annual Meeting of the Association for\nComputational Linguistics , pp. 975\u2013984, 2020.\nJean-Baptiste Mouret and Jeff Clune. Illuminating search spaces by mapping elites. arXiv preprint\narXiv:1504.04909 , 2015.\nReiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher\nHesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al. Webgpt: Browser-assisted question-\nanswering with human feedback. arXiv preprint arXiv:2112.09332 , 2021.\nAndrew Ng. Issue 253. https:\/\/www.deeplearning.ai\/the-batch\/issue-253\/ , June 2024.\nNewsletter issue.\nBen Norman and Jeff Clune. First-explore, then exploit: Meta-learning intelligent exploration. arXiv\npreprint arXiv:2307.02276 , 2023.\nOpenAI. Introducing chatgpt. https:\/\/openai.com\/index\/chatgpt\/ , November 2022. Blog\npost.\nOpenAI. Simple evals, 2023. URL https:\/\/github.com\/openai\/simple-evals . Accessed:\n2024-08-10.\nOpenAI. Gpt-4 technical report, 2024.\nJoon Sung Park, Joseph O\u2019Brien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, and Michael S\nBernstein. Generative agents: Interactive simulacra of human behavior. In Proceedings of the 36th\nannual acm symposium on user interface software and technology , pp. 1\u201322, 2023.\n18Automated Design of Agentic Systems\nArkil Patel, Satwik Bhattamishra, and Navin Goyal. Are NLP models really able to solve simple\nmath word problems? In Proceedings of the 2021 Conference of the North American Chapter of the\nAssociation for Computational Linguistics: Human Language Technologies , pp. 2080\u20132094, Online,\nJune 2021. Association for Computational Linguistics. doi: 10.18653\/v1\/2021.naacl-main.168.\nChen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, and Maosong\nSun. Communicative agents for software development. arXiv preprint arXiv:2307.07924 , 2023.\nChen Qian, Zihao Xie, Yifei Wang, Wei Liu, Yufan Dang, Zhuoyun Du, Weize Chen, Cheng Yang,\nZhiyuan Liu, and Maosong Sun. Scaling large-language-model-based multi-agent collaboration.\narXiv preprint arXiv:2406.07155 , 2024.\nChangle Qu, Sunhao Dai, Xiaochi Wei, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Jun Xu, and Ji-Rong\nWen. Tool learning with large language models: A survey. arXiv preprint arXiv:2405.17935 , 2024.\nRafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D Manning, Stefano Ermon, and Chelsea\nFinn. Direct preference optimization: Your language model is secretly a reward model. Advances in\nNeural Information Processing Systems , ","chunk_id":"1b1399c76420a477c0c97893d258ae69","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"THE AI SCIENTIST","type":"PAPER","description":"The AI Scientist: Towards fully automated open-ended scientific discovery is a paper published as an arXiv preprint in 2024","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PAPER"},{"name":"CONG LU","type":"PERSON","description":"Cong Lu is an author of the paper \"Intelligent go-explore: Standing on the shoulders of giant foundation models\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"SHENGRAN HU","type":"PERSON","description":"Shengran Hu is an author of the paper \"Intelligent go-explore: Standing on the shoulders of giant foundation models\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"JEFF CLUNE","type":"PERSON","description":"Jeff Clune is an author of the paper \"Intelligent go-explore: Standing on the shoulders of giant foundation models\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"ZHICHAO LU","type":"PERSON","description":"Zhichao Lu is an author of the paper \"Nsga-net: neural architecture search using multi-objective genetic algorithm\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"IAN WHALEN","type":"PERSON","description":"Ian Whalen is an author of the paper \"Nsga-net: neural architecture search using multi-objective genetic algorithm\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"VISHNU BODDETI","type":"PERSON","description":"Vishnu Boddeti is an author of the paper \"Nsga-net: neural architecture search using multi-objective genetic algorithm\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"YASHESH DHEBAR","type":"PERSON","description":"Yashesh Dhebar is an author of the paper \"Nsga-net: neural architecture search using multi-objective genetic algorithm\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"KALYANMOY DEB","type":"PERSON","description":"Kalyanmoy Deb is an author of the paper \"Nsga-net: neural architecture search using multi-objective genetic algorithm\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"ERIK GOODMAN","type":"PERSON","description":"Erik Goodman is an author of the paper \"Nsga-net: neural architecture search using multi-objective genetic algorithm\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"WOLFGANG BANZHAF","type":"PERSON","description":"Wolfgang Banzhaf is an author of the paper \"Nsga-net: neural architecture search using multi-objective genetic algorithm\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"NSGA-NET","type":"TOOL\/ALGORITHM","description":"Nsga-net is a neural architecture search tool using a multi-objective genetic algorithm","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"TOOL\/ALGORITHM"},{"name":"GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE","type":"EVENT","description":"The conference where the paper \"Nsga-net: neural architecture search using multi-objective genetic algorithm\" was presented","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"EVENT"},{"name":"YECHENG JASON MA","type":"PERSON","description":"Yecheng Jason Ma is an author of the paper \"Eureka: Human-level reward design via coding large language models\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"WILLIAM LIANG","type":"PERSON","description":"William Liang is an author of the paper \"Eureka: Human-level reward design via coding large language models\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"GUANZHI WANG","type":"PERSON","description":"Guanzhi Wang is an author of the paper \"Eureka: Human-level reward design via coding large language models\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"DE-AN HUANG","type":"PERSON","description":"De-An Huang is an author of the paper \"Eureka: Human-level reward design via coding large language models\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"OSBERT BASTANI","type":"PERSON","description":"Osbert Bastani is an author of the paper \"Eureka: Human-level reward design via coding large language models\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"DINESH JAYARAMAN","type":"PERSON","description":"Dinesh Jayaraman is an author of the paper \"Eureka: Human-level reward design via coding large language models\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"YUKE ZHU","type":"PERSON","description":"Yuke Zhu is an author of the paper \"Eureka: Human-level reward design via coding large language models\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"LINXI FAN","type":"PERSON","description":"Linxi Fan is an author of the paper \"Eureka: Human-level reward design via coding large language models\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"ANIMA ANANDKUMAR","type":"PERSON","description":"Anima Anandkumar is an author of the paper \"Eureka: Human-level reward design via coding large language models\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"EUREKA","type":"TOOL\/ALGORITHM","description":"Eureka is a tool for human-level reward design via coding large language models","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"TOOL\/ALGORITHM"},{"name":"THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS","type":"EVENT","description":"The conference where the paper \"Eureka: Human-level reward design via coding large language models\" was presented","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"EVENT"},{"name":"AMAN MADAAN","type":"PERSON","description":"Aman Madaan is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"NIKET TANDON","type":"PERSON","description":"Niket Tandon is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"PRAKHAR GUPTA","type":"PERSON","description":"Prakhar Gupta is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"SKYLER HALLINAN","type":"PERSON","description":"Skyler Hallinan is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"LUYU GAO","type":"PERSON","description":"Luyu Gao is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"SARAH WIEGREFFE","type":"PERSON","description":"Sarah Wiegreffe is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"URI ALON","type":"PERSON","description":"Uri Alon is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"NOUHA DZIRI","type":"PERSON","description":"Nouha Dziri is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"SHRIMAI PRABHUMOYE","type":"PERSON","description":"Shrimai Prabhumoye is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"YIMING YANG","type":"PERSON","description":"Yiming Yang is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"SELF-REFINE","type":"TOOL\/ALGORITHM","description":"Self-refine is a tool for iterative refinement with self-feedback","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"TOOL\/ALGORITHM"},{"name":"ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS","type":"EVENT","description":"The conference where the paper \"Self-refine: Iterative refinement with self-feedback\" was presented","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"EVENT"},{"name":"META","type":"ORGANIZATION","description":"Meta is the organization that published the news article \"Open source ai is the path forward\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"ORGANIZATION"},{"name":"ELLIOT MEYERSON","type":"PERSON","description":"Elliot Meyerson is an author of the paper \"Language model crossover: Variation through few-shot prompting\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"MARK J NELSON","type":"PERSON","description":"Mark J Nelson is an author of the paper \"Language model crossover: Variation through few-shot prompting\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"HERBIE BRADLEY","type":"PERSON","description":"Herbie Bradley is an author of the paper \"Language model crossover: Variation through few-shot prompting\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"ADAM GAIER","type":"PERSON","description":"Adam Gaier is an author of the paper \"Language model crossover: Variation through few-shot prompting\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"ARASH MORADI","type":"PERSON","description":"Arash Moradi is an author of the paper \"Language model crossover: Variation through few-shot prompting\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"AMY K HOOVER","type":"PERSON","description":"Amy K Hoover is an author of the paper \"Language model crossover: Variation through few-shot prompting\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"JOEL LEHMAN","type":"PERSON","description":"Joel Lehman is an author of the paper \"Language model crossover: Variation through few-shot prompting\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"LANGUAGE MODEL CROSSOVER","type":"TOOL\/ALGORITHM","description":"Language model crossover is a tool for variation through few-shot prompting","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"TOOL\/ALGORITHM"},{"name":"SHEN-YUN MIAO","type":"PERSON","description":"Shen-yun Miao is an author of the paper \"A diverse corpus for evaluating and developing english math word problem solvers\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"CHAO-CHUN LIANG","type":"PERSON","description":"Chao-Chun Liang is an author of the paper \"A diverse corpus for evaluating and developing english math word problem solvers\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"KEH-YIH SU","type":"PERSON","description":"Keh-Yih Su is an author of the paper \"A diverse corpus for evaluating and developing english math word problem solvers\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"A DIVERSE CORPUS FOR EVALUATING AND DEVELOPING ENGLISH MATH WORD PROBLEM SOLVERS","type":"TOOL\/DATASET","description":"A diverse corpus for evaluating and developing english math word problem solvers is a dataset for evaluating and developing English math word problem solvers","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"TOOL\/DATASET"},{"name":"THE 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS","type":"EVENT","description":"The conference where the paper \"A diverse corpus for evaluating and developing english math word problem solvers\" was presented","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"EVENT"},{"name":"JEAN-BAPTISTE MOURET","type":"PERSON","description":"Jean-Baptiste Mouret is an author of the paper \"Illuminating search spaces by mapping elites\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"ILLUMINATING SEARCH SPACES BY MAPPING ELITES","type":"TOOL\/ALGORITHM","description":"Illuminating search spaces by mapping elites is a tool for illuminating search spaces","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"TOOL\/ALGORITHM"},{"name":"REIICHIRO NAKANO","type":"PERSON","description":"Reiichiro Nakano is an author of the paper \"Webgpt: Browser-assisted question-answering with human feedback\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"JACOB HILTON","type":"PERSON","description":"Jacob Hilton is an author of the paper \"Webgpt: Browser-assisted question-answering with human feedback\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"SUCHIR BALAJI","type":"PERSON","description":"Suchir Balaji is an author of the paper \"Webgpt: Browser-assisted question-answering with human feedback\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"JEFF WU","type":"PERSON","description":"Jeff Wu is an author of the paper \"Webgpt: Browser-assisted question-answering with human feedback\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"LONG OUYANG","type":"PERSON","description":"Long Ouyang is an author of the paper \"Webgpt: Browser-assisted question-answering with human feedback\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"CHRISTINA KIM","type":"PERSON","description":"Christina Kim is an author of the paper \"Webgpt: Browser-assisted question-answering with human feedback\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"CHRISTOPHER HESSE","type":"PERSON","description":"Christopher Hesse is an author of the paper \"Webgpt: Browser-assisted question-answering with human feedback\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"SHANTANU JAIN","type":"PERSON","description":"Shantanu Jain is an author of the paper \"Webgpt: Browser-assisted question-answering with human feedback\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"VINEET KOSARAJU","type":"PERSON","description":"Vineet Kosaraju is an author of the paper \"Webgpt: Browser-assisted question-answering with human feedback\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"WILLIAM SAUNDERS","type":"PERSON","description":"William Saunders is an author of the paper \"Webgpt: Browser-assisted question-answering with human feedback\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"WEBGPT","type":"TOOL\/ALGORITHM","description":"Webgpt is a tool for browser-assisted question-answering with human feedback","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"TOOL\/ALGORITHM"},{"name":"ANDREW NG","type":"PERSON","description":"Andrew Ng is the author of the newsletter issue \"Issue 253\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"BEN NORMAN","type":"PERSON","description":"Ben Norman is an author of the paper \"First-explore, then exploit: Meta-learning intelligent exploration\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"FIRST-EXPLORE, THEN EXPLOIT","type":"TOOL\/ALGORITHM","description":"First-explore, then exploit is a tool for meta-learning intelligent exploration","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"TOOL\/ALGORITHM"},{"name":"OPENAI","type":"ORGANIZATION","description":"OpenAI is the organization behind ChatGPT and Simple Evals","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"ORGANIZATION"},{"name":"CHATGPT","type":"TOOL\/ALGORITHM","description":"ChatGPT is a conversational AI model introduced by OpenAI","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"TOOL\/ALGORITHM"},{"name":"SIMPLE EVALS","type":"TOOL\/ALGORITHM","description":"Simple Evals is a tool by OpenAI for evaluating AI models","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"TOOL\/ALGORITHM"},{"name":"GPT-4 TECHNICAL REPORT","type":"DOCUMENT","description":"GPT-4 Technical Report is a document published by OpenAI in 2024","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"DOCUMENT"},{"name":"JOON SUNG PARK","type":"PERSON","description":"Joon Sung Park is an author of the paper \"Generative agents: Interactive simulacra of human behavior\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"JOSEPH O\u2019BRIEN","type":"PERSON","description":"Joseph O\u2019Brien is an author of the paper \"Generative agents: Interactive simulacra of human behavior\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"CARRIE JUN CAI","type":"PERSON","description":"Carrie Jun Cai is an author of the paper \"Generative agents: Interactive simulacra of human behavior\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"MEREDITH RINGEL MORRIS","type":"PERSON","description":"Meredith Ringel Morris is an author of the paper \"Generative agents: Interactive simulacra of human behavior\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"PERCY LIANG","type":"PERSON","description":"Percy Liang is an author of the paper \"Generative agents: Interactive simulacra of human behavior\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"MICHAEL S BERNSTEIN","type":"PERSON","description":"Michael S Bernstein is an author of the paper \"Generative agents: Interactive simulacra of human behavior\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"GENERATIVE AGENTS","type":"TOOL\/ALGORITHM","description":"Generative agents are interactive simulacra of human behavior","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"TOOL\/ALGORITHM"},{"name":"THE 36TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY","type":"EVENT","description":"The conference where the paper \"Generative agents: Interactive simulacra of human behavior\" was presented","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"EVENT"},{"name":"ARKIL PATEL","type":"PERSON","description":"Arkil Patel is an author of the paper \"Are NLP models really able to solve simple math word problems?\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"SATWIK BHATTAMISHRA","type":"PERSON","description":"Satwik Bhattamishra is an author of the paper \"Are NLP models really able to solve simple math word problems?\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"NAVIN GOYAL","type":"PERSON","description":"Navin Goyal is an author of the paper \"Are NLP models really able to solve simple math word problems?\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"THE 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES","type":"EVENT","description":"The conference where the paper \"Are NLP models really able to solve simple math word problems?\" was presented","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"EVENT"},{"name":"CHEN QIAN","type":"PERSON","description":"Chen Qian is an author of the paper \"Communicative agents for software development\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"XIN CONG","type":"PERSON","description":"Xin Cong is an author of the paper \"Communicative agents for software development\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"CHENG YANG","type":"PERSON","description":"Cheng Yang is an author of the paper \"Communicative agents for software development\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"WEIZE CHEN","type":"PERSON","description":"Weize Chen is an author of the paper \"Communicative agents for software development\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"YUSHENG SU","type":"PERSON","description":"Yusheng Su is an author of the paper \"Communicative agents for software development\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"JUYUAN XU","type":"PERSON","description":"Juyuan Xu is an author of the paper \"Communicative agents for software development\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"ZHIYUAN LIU","type":"PERSON","description":"Zhiyuan Liu is an author of the paper \"Communicative agents for software development\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"MAOSONG SUN","type":"PERSON","description":"Maosong Sun is an author of the paper \"Communicative agents for software development\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"COMMUNICATIVE AGENTS","type":"TOOL\/ALGORITHM","description":"Communicative agents are tools for software development","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"TOOL\/ALGORITHM"},{"name":"ZIHAO XIE","type":"PERSON","description":"Zihao Xie is an author of the paper \"Scaling large-language-model-based multi-agent collaboration\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"YIFEI WANG","type":"PERSON","description":"Yifei Wang is an author of the paper \"Scaling large-language-model-based multi-agent collaboration\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"WEI LIU","type":"PERSON","description":"Wei Liu is an author of the paper \"Scaling large-language-model-based multi-agent collaboration\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"YUFAN DANG","type":"PERSON","description":"Yufan Dang is an author of the paper \"Scaling large-language-model-based multi-agent collaboration\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"ZHUOYUN DU","type":"PERSON","description":"Zhuoyun Du is an author of the paper \"Scaling large-language-model-based multi-agent collaboration\"","source_id":"1b1399c76420a477c0c97893d258ae69","entity_type":"PERSON"},{"name":"SCALING LARGE-LANGUAGE-MODEL-BASED MULTI-AGENT COLLABORATION","type":"TOOL\/ALGORITHM","description":"Scaling large-language-model-based multi-agent collaboration is a tool for multi-agent collaboration","source_id":"1b1399c76420a477c0c97893d258ae69"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"THE AI SCIENTIST\">      <data key=\"d0\">PAPER<\/data>      <data key=\"d1\">The AI Scientist: Towards fully automated open-ended scientific discovery is a paper published as an arXiv preprint in 2024<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PAPER<\/data>    <\/node>    <node id=\"CONG LU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Cong Lu is an author of the paper \"Intelligent go-explore: Standing on the shoulders of giant foundation models\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHENGRAN HU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shengran Hu is an author of the paper \"Intelligent go-explore: Standing on the shoulders of giant foundation models\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JEFF CLUNE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jeff Clune is an author of the paper \"Intelligent go-explore: Standing on the shoulders of giant foundation models\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHICHAO LU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhichao Lu is an author of the paper \"Nsga-net: neural architecture search using multi-objective genetic algorithm\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"IAN WHALEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ian Whalen is an author of the paper \"Nsga-net: neural architecture search using multi-objective genetic algorithm\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"VISHNU BODDETI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Vishnu Boddeti is an author of the paper \"Nsga-net: neural architecture search using multi-objective genetic algorithm\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YASHESH DHEBAR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yashesh Dhebar is an author of the paper \"Nsga-net: neural architecture search using multi-objective genetic algorithm\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KALYANMOY DEB\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kalyanmoy Deb is an author of the paper \"Nsga-net: neural architecture search using multi-objective genetic algorithm\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ERIK GOODMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Erik Goodman is an author of the paper \"Nsga-net: neural architecture search using multi-objective genetic algorithm\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WOLFGANG BANZHAF\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wolfgang Banzhaf is an author of the paper \"Nsga-net: neural architecture search using multi-objective genetic algorithm\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NSGA-NET\">      <data key=\"d0\">TOOL\/ALGORITHM<\/data>      <data key=\"d1\">Nsga-net is a neural architecture search tool using a multi-objective genetic algorithm<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">TOOL\/ALGORITHM<\/data>    <\/node>    <node id=\"GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">The conference where the paper \"Nsga-net: neural architecture search using multi-objective genetic algorithm\" was presented<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">EVENT<\/data>    <\/node>    <node id=\"YECHENG JASON MA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yecheng Jason Ma is an author of the paper \"Eureka: Human-level reward design via coding large language models\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WILLIAM LIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">William Liang is an author of the paper \"Eureka: Human-level reward design via coding large language models\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GUANZHI WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Guanzhi Wang is an author of the paper \"Eureka: Human-level reward design via coding large language models\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DE-AN HUANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">De-An Huang is an author of the paper \"Eureka: Human-level reward design via coding large language models\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"OSBERT BASTANI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Osbert Bastani is an author of the paper \"Eureka: Human-level reward design via coding large language models\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DINESH JAYARAMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dinesh Jayaraman is an author of the paper \"Eureka: Human-level reward design via coding large language models\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YUKE ZHU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yuke Zhu is an author of the paper \"Eureka: Human-level reward design via coding large language models\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LINXI FAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Linxi Fan is an author of the paper \"Eureka: Human-level reward design via coding large language models\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ANIMA ANANDKUMAR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Anima Anandkumar is an author of the paper \"Eureka: Human-level reward design via coding large language models\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"EUREKA\">      <data key=\"d0\">TOOL\/ALGORITHM<\/data>      <data key=\"d1\">Eureka is a tool for human-level reward design via coding large language models<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">TOOL\/ALGORITHM<\/data>    <\/node>    <node id=\"THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">The conference where the paper \"Eureka: Human-level reward design via coding large language models\" was presented<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">EVENT<\/data>    <\/node>    <node id=\"AMAN MADAAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Aman Madaan is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NIKET TANDON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Niket Tandon is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PRAKHAR GUPTA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Prakhar Gupta is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SKYLER HALLINAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Skyler Hallinan is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LUYU GAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Luyu Gao is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SARAH WIEGREFFE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sarah Wiegreffe is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"URI ALON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Uri Alon is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NOUHA DZIRI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nouha Dziri is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHRIMAI PRABHUMOYE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shrimai Prabhumoye is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YIMING YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yiming Yang is an author of the paper \"Self-refine: Iterative refinement with self-feedback\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SELF-REFINE\">      <data key=\"d0\">TOOL\/ALGORITHM<\/data>      <data key=\"d1\">Self-refine is a tool for iterative refinement with self-feedback<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">TOOL\/ALGORITHM<\/data>    <\/node>    <node id=\"ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">The conference where the paper \"Self-refine: Iterative refinement with self-feedback\" was presented<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">EVENT<\/data>    <\/node>    <node id=\"META\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Meta is the organization that published the news article \"Open source ai is the path forward\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"ELLIOT MEYERSON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Elliot Meyerson is an author of the paper \"Language model crossover: Variation through few-shot prompting\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MARK J NELSON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mark J Nelson is an author of the paper \"Language model crossover: Variation through few-shot prompting\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HERBIE BRADLEY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Herbie Bradley is an author of the paper \"Language model crossover: Variation through few-shot prompting\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ADAM GAIER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Adam Gaier is an author of the paper \"Language model crossover: Variation through few-shot prompting\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ARASH MORADI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Arash Moradi is an author of the paper \"Language model crossover: Variation through few-shot prompting\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"AMY K HOOVER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Amy K Hoover is an author of the paper \"Language model crossover: Variation through few-shot prompting\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JOEL LEHMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joel Lehman is an author of the paper \"Language model crossover: Variation through few-shot prompting\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LANGUAGE MODEL CROSSOVER\">      <data key=\"d0\">TOOL\/ALGORITHM<\/data>      <data key=\"d1\">Language model crossover is a tool for variation through few-shot prompting<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">TOOL\/ALGORITHM<\/data>    <\/node>    <node id=\"SHEN-YUN MIAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shen-yun Miao is an author of the paper \"A diverse corpus for evaluating and developing english math word problem solvers\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHAO-CHUN LIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chao-Chun Liang is an author of the paper \"A diverse corpus for evaluating and developing english math word problem solvers\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KEH-YIH SU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Keh-Yih Su is an author of the paper \"A diverse corpus for evaluating and developing english math word problem solvers\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"A DIVERSE CORPUS FOR EVALUATING AND DEVELOPING ENGLISH MATH WORD PROBLEM SOLVERS\">      <data key=\"d0\">TOOL\/DATASET<\/data>      <data key=\"d1\">A diverse corpus for evaluating and developing english math word problem solvers is a dataset for evaluating and developing English math word problem solvers<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">TOOL\/DATASET<\/data>    <\/node>    <node id=\"THE 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">The conference where the paper \"A diverse corpus for evaluating and developing english math word problem solvers\" was presented<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">EVENT<\/data>    <\/node>    <node id=\"JEAN-BAPTISTE MOURET\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jean-Baptiste Mouret is an author of the paper \"Illuminating search spaces by mapping elites\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ILLUMINATING SEARCH SPACES BY MAPPING ELITES\">      <data key=\"d0\">TOOL\/ALGORITHM<\/data>      <data key=\"d1\">Illuminating search spaces by mapping elites is a tool for illuminating search spaces<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">TOOL\/ALGORITHM<\/data>    <\/node>    <node id=\"REIICHIRO NAKANO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Reiichiro Nakano is an author of the paper \"Webgpt: Browser-assisted question-answering with human feedback\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JACOB HILTON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jacob Hilton is an author of the paper \"Webgpt: Browser-assisted question-answering with human feedback\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SUCHIR BALAJI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Suchir Balaji is an author of the paper \"Webgpt: Browser-assisted question-answering with human feedback\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JEFF WU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jeff Wu is an author of the paper \"Webgpt: Browser-assisted question-answering with human feedback\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LONG OUYANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Long Ouyang is an author of the paper \"Webgpt: Browser-assisted question-answering with human feedback\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHRISTINA KIM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Christina Kim is an author of the paper \"Webgpt: Browser-assisted question-answering with human feedback\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHRISTOPHER HESSE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Christopher Hesse is an author of the paper \"Webgpt: Browser-assisted question-answering with human feedback\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHANTANU JAIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shantanu Jain is an author of the paper \"Webgpt: Browser-assisted question-answering with human feedback\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"VINEET KOSARAJU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Vineet Kosaraju is an author of the paper \"Webgpt: Browser-assisted question-answering with human feedback\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WILLIAM SAUNDERS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">William Saunders is an author of the paper \"Webgpt: Browser-assisted question-answering with human feedback\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WEBGPT\">      <data key=\"d0\">TOOL\/ALGORITHM<\/data>      <data key=\"d1\">Webgpt is a tool for browser-assisted question-answering with human feedback<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">TOOL\/ALGORITHM<\/data>    <\/node>    <node id=\"ANDREW NG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Andrew Ng is the author of the newsletter issue \"Issue 253\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BEN NORMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ben Norman is an author of the paper \"First-explore, then exploit: Meta-learning intelligent exploration\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"FIRST-EXPLORE, THEN EXPLOIT\">      <data key=\"d0\">TOOL\/ALGORITHM<\/data>      <data key=\"d1\">First-explore, then exploit is a tool for meta-learning intelligent exploration<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">TOOL\/ALGORITHM<\/data>    <\/node>    <node id=\"OPENAI\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">OpenAI is the organization behind ChatGPT and Simple Evals<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"CHATGPT\">      <data key=\"d0\">TOOL\/ALGORITHM<\/data>      <data key=\"d1\">ChatGPT is a conversational AI model introduced by OpenAI<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">TOOL\/ALGORITHM<\/data>    <\/node>    <node id=\"SIMPLE EVALS\">      <data key=\"d0\">TOOL\/ALGORITHM<\/data>      <data key=\"d1\">Simple Evals is a tool by OpenAI for evaluating AI models<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">TOOL\/ALGORITHM<\/data>    <\/node>    <node id=\"GPT-4 TECHNICAL REPORT\">      <data key=\"d0\">DOCUMENT<\/data>      <data key=\"d1\">GPT-4 Technical Report is a document published by OpenAI in 2024<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">DOCUMENT<\/data>    <\/node>    <node id=\"JOON SUNG PARK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joon Sung Park is an author of the paper \"Generative agents: Interactive simulacra of human behavior\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JOSEPH O&#8217;BRIEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joseph O&#8217;Brien is an author of the paper \"Generative agents: Interactive simulacra of human behavior\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CARRIE JUN CAI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Carrie Jun Cai is an author of the paper \"Generative agents: Interactive simulacra of human behavior\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MEREDITH RINGEL MORRIS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Meredith Ringel Morris is an author of the paper \"Generative agents: Interactive simulacra of human behavior\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PERCY LIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Percy Liang is an author of the paper \"Generative agents: Interactive simulacra of human behavior\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MICHAEL S BERNSTEIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Michael S Bernstein is an author of the paper \"Generative agents: Interactive simulacra of human behavior\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GENERATIVE AGENTS\">      <data key=\"d0\">TOOL\/ALGORITHM<\/data>      <data key=\"d1\">Generative agents are interactive simulacra of human behavior<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">TOOL\/ALGORITHM<\/data>    <\/node>    <node id=\"THE 36TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">The conference where the paper \"Generative agents: Interactive simulacra of human behavior\" was presented<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">EVENT<\/data>    <\/node>    <node id=\"ARKIL PATEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Arkil Patel is an author of the paper \"Are NLP models really able to solve simple math word problems?\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SATWIK BHATTAMISHRA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Satwik Bhattamishra is an author of the paper \"Are NLP models really able to solve simple math word problems?\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NAVIN GOYAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Navin Goyal is an author of the paper \"Are NLP models really able to solve simple math word problems?\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"THE 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">The conference where the paper \"Are NLP models really able to solve simple math word problems?\" was presented<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">EVENT<\/data>    <\/node>    <node id=\"CHEN QIAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chen Qian is an author of the paper \"Communicative agents for software development\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XIN CONG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xin Cong is an author of the paper \"Communicative agents for software development\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHENG YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Cheng Yang is an author of the paper \"Communicative agents for software development\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WEIZE CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Weize Chen is an author of the paper \"Communicative agents for software development\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YUSHENG SU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yusheng Su is an author of the paper \"Communicative agents for software development\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JUYUAN XU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Juyuan Xu is an author of the paper \"Communicative agents for software development\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHIYUAN LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhiyuan Liu is an author of the paper \"Communicative agents for software development\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MAOSONG SUN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Maosong Sun is an author of the paper \"Communicative agents for software development\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"COMMUNICATIVE AGENTS\">      <data key=\"d0\">TOOL\/ALGORITHM<\/data>      <data key=\"d1\">Communicative agents are tools for software development<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">TOOL\/ALGORITHM<\/data>    <\/node>    <node id=\"ZIHAO XIE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zihao Xie is an author of the paper \"Scaling large-language-model-based multi-agent collaboration\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YIFEI WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yifei Wang is an author of the paper \"Scaling large-language-model-based multi-agent collaboration\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WEI LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wei Liu is an author of the paper \"Scaling large-language-model-based multi-agent collaboration\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YUFAN DANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yufan Dang is an author of the paper \"Scaling large-language-model-based multi-agent collaboration\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHUOYUN DU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhuoyun Du is an author of the paper \"Scaling large-language-model-based multi-agent collaboration\"<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SCALING LARGE-LANGUAGE-MODEL-BASED MULTI-AGENT COLLABORATION\">      <data key=\"d0\">TOOL\/ALGORITHM<\/data>      <data key=\"d1\">Scaling large-language-model-based multi-agent collaboration is a tool for multi-agent collaboration<\/data>      <data key=\"d2\">1b1399c76420a477c0c97893d258ae69<\/data>    <\/node>  <\/graph><\/graphml>"}
{"id":"34d0bb2211fc795fe1096442e086a2b3","chunk":"qiang Wang, Dawei Yin, Jun Xu, and Ji-Rong\nWen. Tool learning with large language models: A survey. arXiv preprint arXiv:2405.17935 , 2024.\nRafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D Manning, Stefano Ermon, and Chelsea\nFinn. Direct preference optimization: Your language model is secretly a reward model. Advances in\nNeural Information Processing Systems , 36, 2024.\nDavid Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani,\nJulian Michael, and Samuel R. Bowman. Gpqa: A graduate-level google-proof q&a benchmark,\n2023.\nToran Bruce Richards. Autogpt. https:\/\/github.com\/Significant-Gravitas\/AutoGPT ,\n2023. GitHub repository.\nTim Rockt\u00e4schel. Artificial Intelligence: 10 Things You Should Know . Seven Dials, September 2024.\nISBN 978-1399626521.\nMd Omar Faruk Rokon, Risul Islam, Ahmad Darki, Evangelos E Papalexakis, and Michalis Faloutsos.\n{SourceFinder}: Finding malware {Source-Code}from publicly available repositories in {GitHub}.\nIn23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020) , pp.\n149\u2013163, 2020.\nBernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, M Pawan\nKumar, Emilien Dupont, Francisco JR Ruiz, Jordan S Ellenberg, Pengming Wang, Omar Fawzi, et al.\nMathematical discoveries from program search with large language models. Nature, 625(7995):\n468\u2013475, 2024.\nTimo Schick, Jane Dwivedi-Yu, Roberto Dessi, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke\nZettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach\nthemselves to use tools. In Thirty-seventh Conference on Neural Information Processing Systems ,\n2023. URL https:\/\/openreview.net\/forum?id=Yacmpz84TH .\nSander Schulhoff, Michael Ilie, Nishant Balepur, Konstantine Kahadze, Amanda Liu, Chenglei Si,\nYinheng Li, Aayush Gupta, HyoJung Han, Sevien Schulhoff, et al. The prompt report: A systematic\nsurvey of prompting techniques. arXiv preprint arXiv:2406.06608 , 2024.\nXuan Shen, Yaohua Wang, Ming Lin, Yilun Huang, Hao Tang, Xiuyu Sun, and Yanzhi Wang. Deepmad:\nMathematical architecture design for deep convolutional neural network. In Proceedings of the\nIEEE\/CVF Conference on Computer Vision and Pattern Recognition , pp. 6163\u20136173, 2023.\nFreda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi, Hyung Won\nChung, Yi Tay, Sebastian Ruder, Denny Zhou, Dipanjan Das, and Jason Wei. Language models\n19Automated Design of Agentic Systems\nare multilingual chain-of-thought reasoners. In The Eleventh International Conference on Learning\nRepresentations , 2023.\nNoah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. Reflexion:\nLanguage agents with verbal reinforcement learning. Advances in Neural Information Processing\nSystems, 36, 2023.\nKenneth O Stanley and Joel Lehman. Why greatness cannot be planned: The myth of the objective .\nSpringer, 2015.\nKenneth O Stanley, Jeff Clune, Joel Lehman, and Risto Miikkulainen. Designing neural networks\nthrough neuroevolution. Nature Machine Intelligence , 1(1):24\u201335, 2019.\nRichard S Sutton and Andrew G Barto. Reinforcement learning: An introduction . MIT press, 2018.\nSai Vemprala, Rogerio Bonatti, Arthur Bucker, and Ashish Kapoor. Chatgpt for robotics:\nDesign principles and model abilities. Technical Report MSR-TR-2023-8, Microsoft,\nFebruary 2023. URL https:\/\/www.microsoft.com\/en-us\/research\/publication\/\nchatgpt-for-robotics-design-principles-and-model-abilities\/ .\nGuanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and\nAnima Anandkumar. Voyager: An open-ended embodied agent with large language models. arXiv\npreprint arXiv: Arxiv-2305.16291 , 2023a.\nJane X Wang, Zeb Kurth-Nelson, Dhruva Tirumala, Hubert Soyer, Joel Z Leibo, Remi Munos, Charles\nBlundell, Dharshan Kumaran, and Matt Botvinick. Learning to reinforcement learn. arXiv preprint\narXiv:1611.05763 , 2016.\nLei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai\nTang, Xu Chen, Yankai Lin, et al. A survey on large language model based autonomous agents.\nFrontiers of Computer Science ,","chunk_id":"34d0bb2211fc795fe1096442e086a2b3","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"QIANG WANG","type":"PERSON","description":"Qiang Wang is an author of the paper \"Tool learning with large language models: A survey\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"DAWEI YIN","type":"PERSON","description":"Dawei Yin is an author of the paper \"Tool learning with large language models: A survey\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"JUN XU","type":"PERSON","description":"Jun Xu is an author of the paper \"Tool learning with large language models: A survey\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"JI-RONG WEN","type":"PERSON","description":"Ji-Rong Wen is an author of the paper \"Tool learning with large language models: A survey\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"ARXIV","type":"PUBLICATION","description":"arXiv is the platform where the paper \"Learning to reinforcement learn\" was published\narXiv is the platform where the paper \"Tool learning with large language models: A survey\" was published\narXiv is the platform where the paper \"Voyager: An open-ended embodied agent with large language models\" was published\narXiv is the platform where the paper \"The prompt report: A systematic survey of prompting techniques\" was published","source_id":"34d0bb2211fc795fe1096442e086a2b3","entity_type":"PUBLICATION"},{"name":"RAFAEL RAFAILOV","type":"PERSON","description":"Rafael Rafailov is an author of the paper \"Direct preference optimization: Your language model is secretly a reward model\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"ARCHIT SHARMA","type":"PERSON","description":"Archit Sharma is an author of the paper \"Direct preference optimization: Your language model is secretly a reward model\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"ERIC MITCHELL","type":"PERSON","description":"Eric Mitchell is an author of the paper \"Direct preference optimization: Your language model is secretly a reward model\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"CHRISTOPHER D MANNING","type":"PERSON","description":"Christopher D Manning is an author of the paper \"Direct preference optimization: Your language model is secretly a reward model\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"STEFANO ERMON","type":"PERSON","description":"Stefano Ermon is an author of the paper \"Direct preference optimization: Your language model is secretly a reward model\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"CHELSEA FINN","type":"PERSON","description":"Chelsea Finn is an author of the paper \"Direct preference optimization: Your language model is secretly a reward model\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS","type":"PUBLICATION","description":"The conference where the paper \"Reflexion: Language agents with verbal reinforcement learning\" was presented\nThe conference where the paper \"Direct preference optimization: Your language model is secretly a reward model\" was presented","source_id":"34d0bb2211fc795fe1096442e086a2b3","entity_type":"PUBLICATION"},{"name":"DAVID REIN","type":"PERSON","description":"David Rein is an author of the paper \"Gpqa: A graduate-level google-proof q&a benchmark\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"BETTY LI HOU","type":"PERSON","description":"Betty Li Hou is an author of the paper \"Gpqa: A graduate-level google-proof q&a benchmark\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"ASA COOPER STICKLAND","type":"PERSON","description":"Asa Cooper Stickland is an author of the paper \"Gpqa: A graduate-level google-proof q&a benchmark\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"JACKSON PETTY","type":"PERSON","description":"Jackson Petty is an author of the paper \"Gpqa: A graduate-level google-proof q&a benchmark\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"RICHARD YUANZHE PANG","type":"PERSON","description":"Richard Yuanzhe Pang is an author of the paper \"Gpqa: A graduate-level google-proof q&a benchmark\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"JULIEN DIRANI","type":"PERSON","description":"Julien Dirani is an author of the paper \"Gpqa: A graduate-level google-proof q&a benchmark\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"JULIAN MICHAEL","type":"PERSON","description":"Julian Michael is an author of the paper \"Gpqa: A graduate-level google-proof q&a benchmark\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"SAMUEL R. BOWMAN","type":"PERSON","description":"Samuel R. Bowman is an author of the paper \"Gpqa: A graduate-level google-proof q&a benchmark\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"TORAN BRUCE RICHARDS","type":"PERSON","description":"Toran Bruce Richards is the creator of the AutoGPT project on GitHub","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"AUTOGPT","type":"TOOL\/PROJECT","description":"AutoGPT is a project hosted on GitHub by Toran Bruce Richards","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"GITHUB","type":"PLATFORM","description":"GitHub is the platform where the AutoGPT project is hosted","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"TIM ROCKT\u00c4SCHEL","type":"PERSON","description":"Tim Rockt\u00e4schel is the author of the book \"Artificial Intelligence: 10 Things You Should Know\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"SEVEN DIALS","type":"PUBLISHER","description":"Seven Dials is the publisher of the book \"Artificial Intelligence: 10 Things You Should Know\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"MD OMAR FARUK ROKON","type":"PERSON","description":"Md Omar Faruk Rokon is an author of the paper \"SourceFinder: Finding malware Source-Code from publicly available repositories in GitHub\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"RISUL ISLAM","type":"PERSON","description":"Risul Islam is an author of the paper \"SourceFinder: Finding malware Source-Code from publicly available repositories in GitHub\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"AHMAD DARKI","type":"PERSON","description":"Ahmad Darki is an author of the paper \"SourceFinder: Finding malware Source-Code from publicly available repositories in GitHub\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"EVANGELOS E PAPALEXAKIS","type":"PERSON","description":"Evangelos E Papalexakis is an author of the paper \"SourceFinder: Finding malware Source-Code from publicly available repositories in GitHub\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"MICHALIS FALOUTSOS","type":"PERSON","description":"Michalis Faloutsos is an author of the paper \"SourceFinder: Finding malware Source-Code from publicly available repositories in GitHub\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"INTERNATIONAL SYMPOSIUM ON RESEARCH IN ATTACKS, INTRUSIONS AND DEFENSES","type":"CONFERENCE","description":"The conference where the paper \"SourceFinder: Finding malware Source-Code from publicly available repositories in GitHub\" was presented","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"BERNARDINO ROMERA-PAREDES","type":"PERSON","description":"Bernardino Romera-Paredes is an author of the paper \"Mathematical discoveries from program search with large language models\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"MOHAMMADAMIN BAREKATAIN","type":"PERSON","description":"Mohammadamin Barekatain is an author of the paper \"Mathematical discoveries from program search with large language models\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"ALEXANDER NOVIKOV","type":"PERSON","description":"Alexander Novikov is an author of the paper \"Mathematical discoveries from program search with large language models\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"MATEJ BALOG","type":"PERSON","description":"Matej Balog is an author of the paper \"Mathematical discoveries from program search with large language models\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"M PAWAN KUMAR","type":"PERSON","description":"M Pawan Kumar is an author of the paper \"Mathematical discoveries from program search with large language models\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"EMILIEN DUPONT","type":"PERSON","description":"Emilien Dupont is an author of the paper \"Mathematical discoveries from program search with large language models\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"FRANCISCO JR RUIZ","type":"PERSON","description":"Francisco JR Ruiz is an author of the paper \"Mathematical discoveries from program search with large language models\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"JORDAN S ELLENBERG","type":"PERSON","description":"Jordan S Ellenberg is an author of the paper \"Mathematical discoveries from program search with large language models\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"PENGMING WANG","type":"PERSON","description":"Pengming Wang is an author of the paper \"Mathematical discoveries from program search with large language models\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"OMAR FAWZI","type":"PERSON","description":"Omar Fawzi is an author of the paper \"Mathematical discoveries from program search with large language models\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"NATURE","type":"PUBLICATION","description":"Nature is the journal where the paper \"Mathematical discoveries from program search with large language models\" was published","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"TIMO SCHICK","type":"PERSON","description":"Timo Schick is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"JANE DWIVEDI-YU","type":"PERSON","description":"Jane Dwivedi-Yu is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"ROBERTO DESSI","type":"PERSON","description":"Roberto Dessi is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"ROBERTA RAILEANU","type":"PERSON","description":"Roberta Raileanu is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"MARIA LOMELI","type":"PERSON","description":"Maria Lomeli is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"ERIC HAMBRO","type":"PERSON","description":"Eric Hambro is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"LUKE ZETTLEMOYER","type":"PERSON","description":"Luke Zettlemoyer is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"NICOLA CANCEDDA","type":"PERSON","description":"Nicola Cancedda is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"THOMAS SCIALOM","type":"PERSON","description":"Thomas Scialom is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"NEURAL INFORMATION PROCESSING SYSTEMS","type":"CONFERENCE","description":"The conference where the paper \"Toolformer: Language models can teach themselves to use tools\" was presented","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"SANDER SCHULHOFF","type":"PERSON","description":"Sander Schulhoff is an author of the paper \"The prompt report: A systematic survey of prompting techniques\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"MICHAEL ILIE","type":"PERSON","description":"Michael Ilie is an author of the paper \"The prompt report: A systematic survey of prompting techniques\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"NISHANT BALEPUR","type":"PERSON","description":"Nishant Balepur is an author of the paper \"The prompt report: A systematic survey of prompting techniques\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"KONSTANTINE KAHADZE","type":"PERSON","description":"Konstantine Kahadze is an author of the paper \"The prompt report: A systematic survey of prompting techniques\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"AMANDA LIU","type":"PERSON","description":"Amanda Liu is an author of the paper \"The prompt report: A systematic survey of prompting techniques\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"CHENGLEI SI","type":"PERSON","description":"Chenglei Si is an author of the paper \"The prompt report: A systematic survey of prompting techniques\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"YINHENG LI","type":"PERSON","description":"Yinheng Li is an author of the paper \"The prompt report: A systematic survey of prompting techniques\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"AAYUSH GUPTA","type":"PERSON","description":"Aayush Gupta is an author of the paper \"The prompt report: A systematic survey of prompting techniques\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"HYOJUNG HAN","type":"PERSON","description":"HyoJung Han is an author of the paper \"The prompt report: A systematic survey of prompting techniques\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"SEVIEN SCHULHOFF","type":"PERSON","description":"Sevien Schulhoff is an author of the paper \"The prompt report: A systematic survey of prompting techniques\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"XUAN SHEN","type":"PERSON","description":"Xuan Shen is an author of the paper \"Deepmad: Mathematical architecture design for deep convolutional neural network\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"YAOHUA WANG","type":"PERSON","description":"Yaohua Wang is an author of the paper \"Deepmad: Mathematical architecture design for deep convolutional neural network\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"MING LIN","type":"PERSON","description":"Ming Lin is an author of the paper \"Deepmad: Mathematical architecture design for deep convolutional neural network\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"YILUN HUANG","type":"PERSON","description":"Yilun Huang is an author of the paper \"Deepmad: Mathematical architecture design for deep convolutional neural network\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"HAO TANG","type":"PERSON","description":"Hao Tang is an author of the paper \"Deepmad: Mathematical architecture design for deep convolutional neural network\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"XIUYU SUN","type":"PERSON","description":"Xiuyu Sun is an author of the paper \"Deepmad: Mathematical architecture design for deep convolutional neural network\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"YANZHI WANG","type":"PERSON","description":"Yanzhi Wang is an author of the paper \"Deepmad: Mathematical architecture design for deep convolutional neural network\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"IEEE\/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION","type":"CONFERENCE","description":"The conference where the paper \"Deepmad: Mathematical architecture design for deep convolutional neural network\" was presented","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"FREDA SHI","type":"PERSON","description":"Freda Shi is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"MIRAC SUZGUN","type":"PERSON","description":"Mirac Suzgun is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"MARKUS FREITAG","type":"PERSON","description":"Markus Freitag is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"XUEZHI WANG","type":"PERSON","description":"Xuezhi Wang is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"SURAJ SRIVATS","type":"PERSON","description":"Suraj Srivats is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"SOROUSH VOSOUGHI","type":"PERSON","description":"Soroush Vosoughi is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"HYUNG WON CHUNG","type":"PERSON","description":"Hyung Won Chung is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"YI TAY","type":"PERSON","description":"Yi Tay is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"SEBASTIAN RUDER","type":"PERSON","description":"Sebastian Ruder is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"DENNY ZHOU","type":"PERSON","description":"Denny Zhou is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"DIPANJAN DAS","type":"PERSON","description":"Dipanjan Das is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"JASON WEI","type":"PERSON","description":"Jason Wei is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS","type":"CONFERENCE","description":"The conference where the paper \"Language models are multilingual chain-of-thought reasoners\" was presented","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"NOAH SHINN","type":"PERSON","description":"Noah Shinn is an author of the paper \"Reflexion: Language agents with verbal reinforcement learning\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"FEDERICO CASSANO","type":"PERSON","description":"Federico Cassano is an author of the paper \"Reflexion: Language agents with verbal reinforcement learning\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"ASHWIN GOPINATH","type":"PERSON","description":"Ashwin Gopinath is an author of the paper \"Reflexion: Language agents with verbal reinforcement learning\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"KARTHIK NARASIMHAN","type":"PERSON","description":"Karthik Narasimhan is an author of the paper \"Reflexion: Language agents with verbal reinforcement learning\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"SHUNYU YAO","type":"PERSON","description":"Shunyu Yao is an author of the paper \"Reflexion: Language agents with verbal reinforcement learning\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"KENNETH O STANLEY","type":"PERSON","description":"Kenneth O Stanley is an author of the paper \"Designing neural networks through neuroevolution\"\nKenneth O Stanley is an author of the book \"Why greatness cannot be planned: The myth of the objective\"","source_id":"34d0bb2211fc795fe1096442e086a2b3","entity_type":"PERSON"},{"name":"JOEL LEHMAN","type":"PERSON","description":"Joel Lehman is an author of the paper \"Designing neural networks through neuroevolution\"\nJoel Lehman is an author of the book \"Why greatness cannot be planned: The myth of the objective\"","source_id":"34d0bb2211fc795fe1096442e086a2b3","entity_type":"PERSON"},{"name":"SPRINGER","type":"PUBLISHER","description":"Springer is the publisher of the book \"Why greatness cannot be planned: The myth of the objective\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"JEFF CLUNE","type":"PERSON","description":"Jeff Clune is an author of the paper \"Designing neural networks through neuroevolution\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"RISTO MIIKKULAINEN","type":"PERSON","description":"Risto Miikkulainen is an author of the paper \"Designing neural networks through neuroevolution\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"NATURE MACHINE INTELLIGENCE","type":"PUBLICATION","description":"Nature Machine Intelligence is the journal where the paper \"Designing neural networks through neuroevolution\" was published","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"RICHARD S SUTTON","type":"PERSON","description":"Richard S Sutton is an author of the book \"Reinforcement learning: An introduction\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"ANDREW G BARTO","type":"PERSON","description":"Andrew G Barto is an author of the book \"Reinforcement learning: An introduction\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"MIT PRESS","type":"PUBLISHER","description":"MIT Press is the publisher of the book \"Reinforcement learning: An introduction\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"SAI VEMPRALA","type":"PERSON","description":"Sai Vemprala is an author of the paper \"ChatGPT for robotics: Design principles and model abilities\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"ROGERIO BONATTI","type":"PERSON","description":"Rogerio Bonatti is an author of the paper \"ChatGPT for robotics: Design principles and model abilities\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"ARTHUR BUCKER","type":"PERSON","description":"Arthur Bucker is an author of the paper \"ChatGPT for robotics: Design principles and model abilities\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"ASHISH KAPOOR","type":"PERSON","description":"Ashish Kapoor is an author of the paper \"ChatGPT for robotics: Design principles and model abilities\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"MICROSOFT","type":"ORGANIZATION","description":"Microsoft is the organization behind the technical report \"ChatGPT for robotics: Design principles and model abilities\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"GUANZHI WANG","type":"PERSON","description":"Guanzhi Wang is an author of the paper \"Voyager: An open-ended embodied agent with large language models\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"YUQI XIE","type":"PERSON","description":"Yuqi Xie is an author of the paper \"Voyager: An open-ended embodied agent with large language models\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"YUNFAN JIANG","type":"PERSON","description":"Yunfan Jiang is an author of the paper \"Voyager: An open-ended embodied agent with large language models\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"AJAY MANDLEKAR","type":"PERSON","description":"Ajay Mandlekar is an author of the paper \"Voyager: An open-ended embodied agent with large language models\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"CHAOWEI XIAO","type":"PERSON","description":"Chaowei Xiao is an author of the paper \"Voyager: An open-ended embodied agent with large language models\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"YUKE ZHU","type":"PERSON","description":"Yuke Zhu is an author of the paper \"Voyager: An open-ended embodied agent with large language models\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"LINXI FAN","type":"PERSON","description":"Linxi Fan is an author of the paper \"Voyager: An open-ended embodied agent with large language models\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"ANIMA ANANDKUMAR","type":"PERSON","description":"Anima Anandkumar is an author of the paper \"Voyager: An open-ended embodied agent with large language models\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"JANE X WANG","type":"PERSON","description":"Jane X Wang is an author of the paper \"Learning to reinforcement learn\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"ZEB KURTH-NELSON","type":"PERSON","description":"Zeb Kurth-Nelson is an author of the paper \"Learning to reinforcement learn\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"DHRUVA TIRUMALA","type":"PERSON","description":"Dhruva Tirumala is an author of the paper \"Learning to reinforcement learn\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"HUBERT SOYER","type":"PERSON","description":"Hubert Soyer is an author of the paper \"Learning to reinforcement learn\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"JOEL Z LEIBO","type":"PERSON","description":"Joel Z Leibo is an author of the paper \"Learning to reinforcement learn\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"REMI MUNOS","type":"PERSON","description":"Remi Munos is an author of the paper \"Learning to reinforcement learn\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"CHARLES BLUNDELL","type":"PERSON","description":"Charles Blundell is an author of the paper \"Learning to reinforcement learn\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"DHARSHAN KUMARAN","type":"PERSON","description":"Dharshan Kumaran is an author of the paper \"Learning to reinforcement learn\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"MATT BOTVINICK","type":"PERSON","description":"Matt Botvinick is an author of the paper \"Learning to reinforcement learn\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"LEI WANG","type":"PERSON","description":"Lei Wang is an author of the paper \"A survey on large language model based autonomous agents\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"CHEN MA","type":"PERSON","description":"Chen Ma is an author of the paper \"A survey on large language model based autonomous agents\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"XUEYANG FENG","type":"PERSON","description":"Xueyang Feng is an author of the paper \"A survey on large language model based autonomous agents\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"ZEYU ZHANG","type":"PERSON","description":"Zeyu Zhang is an author of the paper \"A survey on large language model based autonomous agents\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"HAO YANG","type":"PERSON","description":"Hao Yang is an author of the paper \"A survey on large language model based autonomous agents\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"JINGSEN ZHANG","type":"PERSON","description":"Jingsen Zhang is an author of the paper \"A survey on large language model based autonomous agents\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"ZHIYUAN CHEN","type":"PERSON","description":"Zhiyuan Chen is an author of the paper \"A survey on large language model based autonomous agents\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"JIAKAI TANG","type":"PERSON","description":"Jiakai Tang is an author of the paper \"A survey on large language model based autonomous agents\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"XU CHEN","type":"PERSON","description":"Xu Chen is an author of the paper \"A survey on large language model based autonomous agents\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"YANKAI LIN","type":"PERSON","description":"Yankai Lin is an author of the paper \"A survey on large language model based autonomous agents\"","source_id":"34d0bb2211fc795fe1096442e086a2b3"},{"name":"FRONTIERS OF COMPUTER SCIENCE","type":"PUBLICATION","description":"Frontiers of Computer Science is the journal where the paper \"A survey on large language model based autonomous agents\" was published","source_id":"34d0bb2211fc795fe1096442e086a2b3"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"QIANG WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Qiang Wang is an author of the paper \"Tool learning with large language models: A survey\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"DAWEI YIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dawei Yin is an author of the paper \"Tool learning with large language models: A survey\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"JUN XU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jun Xu is an author of the paper \"Tool learning with large language models: A survey\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"JI-RONG WEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ji-Rong Wen is an author of the paper \"Tool learning with large language models: A survey\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"ARXIV\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">arXiv is the platform where the paper \"Learning to reinforcement learn\" was publishedarXiv is the platform where the paper \"Tool learning with large language models: A survey\" was publishedarXiv is the platform where the paper \"Voyager: An open-ended embodied agent with large language models\" was publishedarXiv is the platform where the paper \"The prompt report: A systematic survey of prompting techniques\" was published<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"RAFAEL RAFAILOV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Rafael Rafailov is an author of the paper \"Direct preference optimization: Your language model is secretly a reward model\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"ARCHIT SHARMA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Archit Sharma is an author of the paper \"Direct preference optimization: Your language model is secretly a reward model\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"ERIC MITCHELL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Eric Mitchell is an author of the paper \"Direct preference optimization: Your language model is secretly a reward model\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"CHRISTOPHER D MANNING\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Christopher D Manning is an author of the paper \"Direct preference optimization: Your language model is secretly a reward model\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"STEFANO ERMON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Stefano Ermon is an author of the paper \"Direct preference optimization: Your language model is secretly a reward model\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"CHELSEA FINN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chelsea Finn is an author of the paper \"Direct preference optimization: Your language model is secretly a reward model\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">The conference where the paper \"Reflexion: Language agents with verbal reinforcement learning\" was presentedThe conference where the paper \"Direct preference optimization: Your language model is secretly a reward model\" was presented<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"DAVID REIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">David Rein is an author of the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"BETTY LI HOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Betty Li Hou is an author of the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"ASA COOPER STICKLAND\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Asa Cooper Stickland is an author of the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"JACKSON PETTY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jackson Petty is an author of the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"RICHARD YUANZHE PANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Richard Yuanzhe Pang is an author of the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"JULIEN DIRANI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Julien Dirani is an author of the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"JULIAN MICHAEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Julian Michael is an author of the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"SAMUEL R. BOWMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Samuel R. Bowman is an author of the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"TORAN BRUCE RICHARDS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Toran Bruce Richards is the creator of the AutoGPT project on GitHub<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"AUTOGPT\">      <data key=\"d0\">TOOL\/PROJECT<\/data>      <data key=\"d1\">AutoGPT is a project hosted on GitHub by Toran Bruce Richards<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"GITHUB\">      <data key=\"d0\">PLATFORM<\/data>      <data key=\"d1\">GitHub is the platform where the AutoGPT project is hosted<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"TIM ROCKT&#196;SCHEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tim Rockt&#228;schel is the author of the book \"Artificial Intelligence: 10 Things You Should Know\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"SEVEN DIALS\">      <data key=\"d0\">PUBLISHER<\/data>      <data key=\"d1\">Seven Dials is the publisher of the book \"Artificial Intelligence: 10 Things You Should Know\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"MD OMAR FARUK ROKON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Md Omar Faruk Rokon is an author of the paper \"SourceFinder: Finding malware Source-Code from publicly available repositories in GitHub\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"RISUL ISLAM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Risul Islam is an author of the paper \"SourceFinder: Finding malware Source-Code from publicly available repositories in GitHub\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"AHMAD DARKI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ahmad Darki is an author of the paper \"SourceFinder: Finding malware Source-Code from publicly available repositories in GitHub\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"EVANGELOS E PAPALEXAKIS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Evangelos E Papalexakis is an author of the paper \"SourceFinder: Finding malware Source-Code from publicly available repositories in GitHub\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"MICHALIS FALOUTSOS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Michalis Faloutsos is an author of the paper \"SourceFinder: Finding malware Source-Code from publicly available repositories in GitHub\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"INTERNATIONAL SYMPOSIUM ON RESEARCH IN ATTACKS, INTRUSIONS AND DEFENSES\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">The conference where the paper \"SourceFinder: Finding malware Source-Code from publicly available repositories in GitHub\" was presented<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"BERNARDINO ROMERA-PAREDES\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bernardino Romera-Paredes is an author of the paper \"Mathematical discoveries from program search with large language models\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"MOHAMMADAMIN BAREKATAIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mohammadamin Barekatain is an author of the paper \"Mathematical discoveries from program search with large language models\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"ALEXANDER NOVIKOV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Alexander Novikov is an author of the paper \"Mathematical discoveries from program search with large language models\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"MATEJ BALOG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Matej Balog is an author of the paper \"Mathematical discoveries from program search with large language models\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"M PAWAN KUMAR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">M Pawan Kumar is an author of the paper \"Mathematical discoveries from program search with large language models\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"EMILIEN DUPONT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Emilien Dupont is an author of the paper \"Mathematical discoveries from program search with large language models\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"FRANCISCO JR RUIZ\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Francisco JR Ruiz is an author of the paper \"Mathematical discoveries from program search with large language models\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"JORDAN S ELLENBERG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jordan S Ellenberg is an author of the paper \"Mathematical discoveries from program search with large language models\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"PENGMING WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pengming Wang is an author of the paper \"Mathematical discoveries from program search with large language models\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"OMAR FAWZI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Omar Fawzi is an author of the paper \"Mathematical discoveries from program search with large language models\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"NATURE\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Nature is the journal where the paper \"Mathematical discoveries from program search with large language models\" was published<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"TIMO SCHICK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Timo Schick is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"JANE DWIVEDI-YU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jane Dwivedi-Yu is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"ROBERTO DESSI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Roberto Dessi is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"ROBERTA RAILEANU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Roberta Raileanu is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"MARIA LOMELI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Maria Lomeli is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"ERIC HAMBRO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Eric Hambro is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"LUKE ZETTLEMOYER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Luke Zettlemoyer is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"NICOLA CANCEDDA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nicola Cancedda is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"THOMAS SCIALOM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Thomas Scialom is an author of the paper \"Toolformer: Language models can teach themselves to use tools\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"NEURAL INFORMATION PROCESSING SYSTEMS\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">The conference where the paper \"Toolformer: Language models can teach themselves to use tools\" was presented<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"SANDER SCHULHOFF\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sander Schulhoff is an author of the paper \"The prompt report: A systematic survey of prompting techniques\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"MICHAEL ILIE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Michael Ilie is an author of the paper \"The prompt report: A systematic survey of prompting techniques\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"NISHANT BALEPUR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nishant Balepur is an author of the paper \"The prompt report: A systematic survey of prompting techniques\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"KONSTANTINE KAHADZE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Konstantine Kahadze is an author of the paper \"The prompt report: A systematic survey of prompting techniques\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"AMANDA LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Amanda Liu is an author of the paper \"The prompt report: A systematic survey of prompting techniques\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"CHENGLEI SI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chenglei Si is an author of the paper \"The prompt report: A systematic survey of prompting techniques\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"YINHENG LI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yinheng Li is an author of the paper \"The prompt report: A systematic survey of prompting techniques\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"AAYUSH GUPTA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Aayush Gupta is an author of the paper \"The prompt report: A systematic survey of prompting techniques\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"HYOJUNG HAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">HyoJung Han is an author of the paper \"The prompt report: A systematic survey of prompting techniques\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"SEVIEN SCHULHOFF\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sevien Schulhoff is an author of the paper \"The prompt report: A systematic survey of prompting techniques\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"XUAN SHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xuan Shen is an author of the paper \"Deepmad: Mathematical architecture design for deep convolutional neural network\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"YAOHUA WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yaohua Wang is an author of the paper \"Deepmad: Mathematical architecture design for deep convolutional neural network\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"MING LIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ming Lin is an author of the paper \"Deepmad: Mathematical architecture design for deep convolutional neural network\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"YILUN HUANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yilun Huang is an author of the paper \"Deepmad: Mathematical architecture design for deep convolutional neural network\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"HAO TANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hao Tang is an author of the paper \"Deepmad: Mathematical architecture design for deep convolutional neural network\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"XIUYU SUN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xiuyu Sun is an author of the paper \"Deepmad: Mathematical architecture design for deep convolutional neural network\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"YANZHI WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yanzhi Wang is an author of the paper \"Deepmad: Mathematical architecture design for deep convolutional neural network\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"IEEE\/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">The conference where the paper \"Deepmad: Mathematical architecture design for deep convolutional neural network\" was presented<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"FREDA SHI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Freda Shi is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"MIRAC SUZGUN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mirac Suzgun is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"MARKUS FREITAG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Markus Freitag is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"XUEZHI WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xuezhi Wang is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"SURAJ SRIVATS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Suraj Srivats is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"SOROUSH VOSOUGHI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Soroush Vosoughi is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"HYUNG WON CHUNG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hyung Won Chung is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"YI TAY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yi Tay is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"SEBASTIAN RUDER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sebastian Ruder is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"DENNY ZHOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Denny Zhou is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"DIPANJAN DAS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dipanjan Das is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"JASON WEI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jason Wei is an author of the paper \"Language models are multilingual chain-of-thought reasoners\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">The conference where the paper \"Language models are multilingual chain-of-thought reasoners\" was presented<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"NOAH SHINN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Noah Shinn is an author of the paper \"Reflexion: Language agents with verbal reinforcement learning\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"FEDERICO CASSANO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Federico Cassano is an author of the paper \"Reflexion: Language agents with verbal reinforcement learning\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"ASHWIN GOPINATH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ashwin Gopinath is an author of the paper \"Reflexion: Language agents with verbal reinforcement learning\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"KARTHIK NARASIMHAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Karthik Narasimhan is an author of the paper \"Reflexion: Language agents with verbal reinforcement learning\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"SHUNYU YAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shunyu Yao is an author of the paper \"Reflexion: Language agents with verbal reinforcement learning\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"KENNETH O STANLEY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kenneth O Stanley is an author of the paper \"Designing neural networks through neuroevolution\"Kenneth O Stanley is an author of the book \"Why greatness cannot be planned: The myth of the objective\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JOEL LEHMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joel Lehman is an author of the paper \"Designing neural networks through neuroevolution\"Joel Lehman is an author of the book \"Why greatness cannot be planned: The myth of the objective\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SPRINGER\">      <data key=\"d0\">PUBLISHER<\/data>      <data key=\"d1\">Springer is the publisher of the book \"Why greatness cannot be planned: The myth of the objective\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"JEFF CLUNE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jeff Clune is an author of the paper \"Designing neural networks through neuroevolution\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"RISTO MIIKKULAINEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Risto Miikkulainen is an author of the paper \"Designing neural networks through neuroevolution\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"NATURE MACHINE INTELLIGENCE\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Nature Machine Intelligence is the journal where the paper \"Designing neural networks through neuroevolution\" was published<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"RICHARD S SUTTON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Richard S Sutton is an author of the book \"Reinforcement learning: An introduction\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"ANDREW G BARTO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Andrew G Barto is an author of the book \"Reinforcement learning: An introduction\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"MIT PRESS\">      <data key=\"d0\">PUBLISHER<\/data>      <data key=\"d1\">MIT Press is the publisher of the book \"Reinforcement learning: An introduction\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"SAI VEMPRALA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sai Vemprala is an author of the paper \"ChatGPT for robotics: Design principles and model abilities\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"ROGERIO BONATTI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Rogerio Bonatti is an author of the paper \"ChatGPT for robotics: Design principles and model abilities\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"ARTHUR BUCKER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Arthur Bucker is an author of the paper \"ChatGPT for robotics: Design principles and model abilities\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"ASHISH KAPOOR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ashish Kapoor is an author of the paper \"ChatGPT for robotics: Design principles and model abilities\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"MICROSOFT\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Microsoft is the organization behind the technical report \"ChatGPT for robotics: Design principles and model abilities\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"GUANZHI WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Guanzhi Wang is an author of the paper \"Voyager: An open-ended embodied agent with large language models\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"YUQI XIE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yuqi Xie is an author of the paper \"Voyager: An open-ended embodied agent with large language models\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"YUNFAN JIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yunfan Jiang is an author of the paper \"Voyager: An open-ended embodied agent with large language models\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"AJAY MANDLEKAR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ajay Mandlekar is an author of the paper \"Voyager: An open-ended embodied agent with large language models\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"CHAOWEI XIAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chaowei Xiao is an author of the paper \"Voyager: An open-ended embodied agent with large language models\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"YUKE ZHU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yuke Zhu is an author of the paper \"Voyager: An open-ended embodied agent with large language models\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"LINXI FAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Linxi Fan is an author of the paper \"Voyager: An open-ended embodied agent with large language models\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"ANIMA ANANDKUMAR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Anima Anandkumar is an author of the paper \"Voyager: An open-ended embodied agent with large language models\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"JANE X WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jane X Wang is an author of the paper \"Learning to reinforcement learn\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"ZEB KURTH-NELSON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zeb Kurth-Nelson is an author of the paper \"Learning to reinforcement learn\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"DHRUVA TIRUMALA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dhruva Tirumala is an author of the paper \"Learning to reinforcement learn\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"HUBERT SOYER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hubert Soyer is an author of the paper \"Learning to reinforcement learn\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"JOEL Z LEIBO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joel Z Leibo is an author of the paper \"Learning to reinforcement learn\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"REMI MUNOS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Remi Munos is an author of the paper \"Learning to reinforcement learn\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"CHARLES BLUNDELL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Charles Blundell is an author of the paper \"Learning to reinforcement learn\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"DHARSHAN KUMARAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dharshan Kumaran is an author of the paper \"Learning to reinforcement learn\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"MATT BOTVINICK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Matt Botvinick is an author of the paper \"Learning to reinforcement learn\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"LEI WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lei Wang is an author of the paper \"A survey on large language model based autonomous agents\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"CHEN MA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chen Ma is an author of the paper \"A survey on large language model based autonomous agents\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"XUEYANG FENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xueyang Feng is an author of the paper \"A survey on large language model based autonomous agents\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"ZEYU ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zeyu Zhang is an author of the paper \"A survey on large language model based autonomous agents\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"HAO YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hao Yang is an author of the paper \"A survey on large language model based autonomous agents\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"JINGSEN ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jingsen Zhang is an author of the paper \"A survey on large language model based autonomous agents\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"ZHIYUAN CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhiyuan Chen is an author of the paper \"A survey on large language model based autonomous agents\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"JIAKAI TANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jiakai Tang is an author of the paper \"A survey on large language model based autonomous agents\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"XU CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xu Chen is an author of the paper \"A survey on large language model based autonomous agents\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"YANKAI LIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yankai Lin is an author of the paper \"A survey on large language model based autonomous agents\"<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <node id=\"FRONTIERS OF COMPUTER SCIENCE\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Frontiers of Computer Science is the journal where the paper \"A survey on large language model based autonomous agents\" was published<\/data>      <data key=\"d2\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/node>    <edge source=\"QIANG WANG\" target=\"DAWEI YIN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Qiang Wang and Dawei Yin co-authored the paper \"Tool learning with large language models: A survey\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"QIANG WANG\" target=\"JUN XU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Qiang Wang and Jun Xu co-authored the paper \"Tool learning with large language models: A survey\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"QIANG WANG\" target=\"JI-RONG WEN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Qiang Wang and Ji-Rong Wen co-authored the paper \"Tool learning with large language models: A survey\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"DAWEI YIN\" target=\"JUN XU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Dawei Yin and Jun Xu co-authored the paper \"Tool learning with large language models: A survey\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"DAWEI YIN\" target=\"JI-RONG WEN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Dawei Yin and Ji-Rong Wen co-authored the paper \"Tool learning with large language models: A survey\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"JUN XU\" target=\"JI-RONG WEN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Jun Xu and Ji-Rong Wen co-authored the paper \"Tool learning with large language models: A survey\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"RAFAEL RAFAILOV\" target=\"ARCHIT SHARMA\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Rafael Rafailov and Archit Sharma co-authored the paper \"Direct preference optimization: Your language model is secretly a reward model\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"RAFAEL RAFAILOV\" target=\"ERIC MITCHELL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Rafael Rafailov and Eric Mitchell co-authored the paper \"Direct preference optimization: Your language model is secretly a reward model\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"RAFAEL RAFAILOV\" target=\"CHRISTOPHER D MANNING\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Rafael Rafailov and Christopher D Manning co-authored the paper \"Direct preference optimization: Your language model is secretly a reward model\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"RAFAEL RAFAILOV\" target=\"STEFANO ERMON\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Rafael Rafailov and Stefano Ermon co-authored the paper \"Direct preference optimization: Your language model is secretly a reward model\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"RAFAEL RAFAILOV\" target=\"CHELSEA FINN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Rafael Rafailov and Chelsea Finn co-authored the paper \"Direct preference optimization: Your language model is secretly a reward model\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"ARCHIT SHARMA\" target=\"ERIC MITCHELL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Archit Sharma and Eric Mitchell co-authored the paper \"Direct preference optimization: Your language model is secretly a reward model\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"ARCHIT SHARMA\" target=\"CHRISTOPHER D MANNING\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Archit Sharma and Christopher D Manning co-authored the paper \"Direct preference optimization: Your language model is secretly a reward model\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"ARCHIT SHARMA\" target=\"STEFANO ERMON\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Archit Sharma and Stefano Ermon co-authored the paper \"Direct preference optimization: Your language model is secretly a reward model\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"ARCHIT SHARMA\" target=\"CHELSEA FINN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Archit Sharma and Chelsea Finn co-authored the paper \"Direct preference optimization: Your language model is secretly a reward model\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"ERIC MITCHELL\" target=\"CHRISTOPHER D MANNING\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Eric Mitchell and Christopher D Manning co-authored the paper \"Direct preference optimization: Your language model is secretly a reward model\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"ERIC MITCHELL\" target=\"STEFANO ERMON\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Eric Mitchell and Stefano Ermon co-authored the paper \"Direct preference optimization: Your language model is secretly a reward model\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"ERIC MITCHELL\" target=\"CHELSEA FINN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Eric Mitchell and Chelsea Finn co-authored the paper \"Direct preference optimization: Your language model is secretly a reward model\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"CHRISTOPHER D MANNING\" target=\"STEFANO ERMON\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Christopher D Manning and Stefano Ermon co-authored the paper \"Direct preference optimization: Your language model is secretly a reward model\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"CHRISTOPHER D MANNING\" target=\"CHELSEA FINN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Christopher D Manning and Chelsea Finn co-authored the paper \"Direct preference optimization: Your language model is secretly a reward model\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"STEFANO ERMON\" target=\"CHELSEA FINN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Stefano Ermon and Chelsea Finn co-authored the paper \"Direct preference optimization: Your language model is secretly a reward model\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"DAVID REIN\" target=\"BETTY LI HOU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">David Rein and Betty Li Hou co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"DAVID REIN\" target=\"ASA COOPER STICKLAND\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">David Rein and Asa Cooper Stickland co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"DAVID REIN\" target=\"JACKSON PETTY\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">David Rein and Jackson Petty co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"DAVID REIN\" target=\"RICHARD YUANZHE PANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">David Rein and Richard Yuanzhe Pang co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"DAVID REIN\" target=\"JULIEN DIRANI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">David Rein and Julien Dirani co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"DAVID REIN\" target=\"JULIAN MICHAEL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">David Rein and Julian Michael co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"DAVID REIN\" target=\"SAMUEL R. BOWMAN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">David Rein and Samuel R. Bowman co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"BETTY LI HOU\" target=\"ASA COOPER STICKLAND\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Betty Li Hou and Asa Cooper Stickland co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"BETTY LI HOU\" target=\"JACKSON PETTY\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Betty Li Hou and Jackson Petty co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"BETTY LI HOU\" target=\"RICHARD YUANZHE PANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Betty Li Hou and Richard Yuanzhe Pang co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"BETTY LI HOU\" target=\"JULIEN DIRANI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Betty Li Hou and Julien Dirani co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"BETTY LI HOU\" target=\"JULIAN MICHAEL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Betty Li Hou and Julian Michael co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"BETTY LI HOU\" target=\"SAMUEL R. BOWMAN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Betty Li Hou and Samuel R. Bowman co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"ASA COOPER STICKLAND\" target=\"JACKSON PETTY\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Asa Cooper Stickland and Jackson Petty co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"ASA COOPER STICKLAND\" target=\"RICHARD YUANZHE PANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Asa Cooper Stickland and Richard Yuanzhe Pang co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"ASA COOPER STICKLAND\" target=\"JULIEN DIRANI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Asa Cooper Stickland and Julien Dirani co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"ASA COOPER STICKLAND\" target=\"JULIAN MICHAEL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Asa Cooper Stickland and Julian Michael co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"ASA COOPER STICKLAND\" target=\"SAMUEL R. BOWMAN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Asa Cooper Stickland and Samuel R. Bowman co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"JACKSON PETTY\" target=\"RICHARD YUANZHE PANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Jackson Petty and Richard Yuanzhe Pang co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"JACKSON PETTY\" target=\"JULIEN DIRANI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Jackson Petty and Julien Dirani co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"JACKSON PETTY\" target=\"JULIAN MICHAEL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Jackson Petty and Julian Michael co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"JACKSON PETTY\" target=\"SAMUEL R. BOWMAN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Jackson Petty and Samuel R. Bowman co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"RICHARD YUANZHE PANG\" target=\"JULIEN DIRANI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Richard Yuanzhe Pang and Julien Dirani co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"RICHARD YUANZHE PANG\" target=\"JULIAN MICHAEL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Richard Yuanzhe Pang and Julian Michael co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>    <edge source=\"RICHARD YUANZHE PANG\" target=\"SAMUEL R. BOWMAN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Richard Yuanzhe Pang and Samuel R. Bowman co-authored the paper \"Gpqa: A graduate-level google-proof q&amp;a benchmark\"<\/data>      <data key=\"d6\">34d0bb2211fc795fe1096442e086a2b3<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"2600a1ed94ad2d3675ea80575c39cbd1","chunk":"shan Kumaran, and Matt Botvinick. Learning to reinforcement learn. arXiv preprint\narXiv:1611.05763 , 2016.\nLei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai\nTang, Xu Chen, Yankai Lin, et al. A survey on large language model based autonomous agents.\nFrontiers of Computer Science , 18(6):186345, 2024.\nRui Wang, Joel Lehman, Jeff Clune, and Kenneth O. Stanley. Poet: open-ended coevolution of\nenvironments and their optimized solutions. In Proceedings of the Genetic and Evolutionary Compu-\ntation Conference , GECCO \u201919, pp. 142\u2013151, New York, NY, USA, 2019. Association for Computing\nMachinery. ISBN 9781450361118. doi: 10.1145\/3321707.3321799.\nRui Wang, Joel Lehman, Aditya Rawal, Jiale Zhi, Yulun Li, Jeffrey Clune, and Kenneth Stanley.\nEnhanced poet: Open-ended reinforcement learning through unbounded invention of learning\nchallenges and their solutions. In International conference on machine learning , pp. 9940\u20139951.\nPMLR, 2020.\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi, Sharan Narang, Aakanksha\nChowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language\nmodels. In The Eleventh International Conference on Learning Representations , 2023b.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,\net al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural\ninformation processing systems , 35:24824\u201324837, 2022.\nQingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang,\nXiaoyun Zhang, and Chi Wang. Autogen: Enabling next-gen llm applications via multi-agent\nconversation framework. arXiv preprint arXiv:2308.08155 , 2023.\n20Automated Design of Agentic Systems\nBenfeng Xu, An Yang, Junyang Lin, Quan Wang, Chang Zhou, Yongdong Zhang, and Zhendong Mao.\nExpertprompting: Instructing large language models to be distinguished experts. arXiv preprint\narXiv:2305.14688 , 2023.\nChengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V Le, Denny Zhou, and Xinyun Chen.\nLarge language models as optimizers. In The Twelfth International Conference on Learning Represen-\ntations, 2024. URL https:\/\/openreview.net\/forum?id=Bb4VGOWELI .\nShunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R Narasimhan, and Yuan\nCao. React: Synergizing reasoning and acting in language models. In The Eleventh International\nConference on Learning Representations , 2023. URL https:\/\/openreview.net\/forum?id=WE_\nvluYUL-X .\nBennet Yee, David Sehr, Gregory Dardyk, J Bradley Chen, Robert Muth, Tavis Ormandy, Shiki Okasaka,\nNeha Narula, and Nicholas Fullagar. Native client: A sandbox for portable, untrusted x86 native\ncode.Communications of the ACM , 53(1):91\u201399, 2010.\nWenhao Yu, Nimrod Gileadi, Chuyuan Fu, Sean Kirmani, Kuang-Huei Lee, Montserrat Gonzalez\nArenas, Hao-Tien Lewis Chiang, Tom Erez, Leonard Hasenclever, Jan Humplik, et al. Language to\nrewards for robotic skill synthesis. In Conference on Robot Learning , pp. 374\u2013404. PMLR, 2023.\nSiyu Yuan, Kaitao Song, Jiangjie Chen, Xu Tan, Dongsheng Li, and Deqing Yang. Evoagent: Towards\nautomatic multi-agent generation via evolutionary algorithms. arXiv preprint arXiv:2406.14228 ,\n2024.\nEliezer Yudkowsky et al. Artificial Intelligence as a positive and negative factor in global risk. Global\ncatastrophic risks , 1(303):184, 2008.\nMatei Zaharia, Omar Khattab, Lingjiao Chen, Jared Quincy Davis, Heather Miller, Chris Potts,\nJames Zou, Michael Carbin, Jonathan Frankle, Naveen Rao, and Ali Ghodsi. The shift\nfrom models to compound ai systems. https:\/\/bair.berkeley.edu\/blog\/2024\/02\/18\/\ncompound-ai-systems\/ , 2024.\nJennyZhang, JoelLehman, KennethStanley, andJeffClune. OMNI:Open-endednessviamodelsofhu-\nman notions of interestingness. In The Twelfth International Conference on Learning Representations ,\n2024a. URL https:\/\/openreview.net\/forum?id=AgM3MzT99c .\nShaokun Zhang, Jieyu Zhang, Jiale Liu, Linxin Song, Chi Wang","chunk_id":"2600a1ed94ad2d3675ea80575c39cbd1","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"MATT BOTVINICK","type":"PERSON","description":"Matt Botvinick is an author of the paper \"Learning to reinforcement learn\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"ARXIV","type":"PUBLICATION","description":"arXiv is the platform where the paper \"Learning to reinforcement learn\" was published","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"LEI WANG","type":"PERSON","description":"Lei Wang is an author of the paper \"A survey on large language model based autonomous agents\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"CHEN MA","type":"PERSON","description":"Chen Ma is an author of the paper \"A survey on large language model based autonomous agents\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"XUEYANG FENG","type":"PERSON","description":"Xueyang Feng is an author of the paper \"A survey on large language model based autonomous agents\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"ZEYU ZHANG","type":"PERSON","description":"Zeyu Zhang is an author of the paper \"A survey on large language model based autonomous agents\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"HAO YANG","type":"PERSON","description":"Hao Yang is an author of the paper \"A survey on large language model based autonomous agents\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"JINGSEN ZHANG","type":"PERSON","description":"Jingsen Zhang is an author of the paper \"A survey on large language model based autonomous agents\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"ZHIYUAN CHEN","type":"PERSON","description":"Zhiyuan Chen is an author of the paper \"A survey on large language model based autonomous agents\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"JIAKAI TANG","type":"PERSON","description":"Jiakai Tang is an author of the paper \"A survey on large language model based autonomous agents\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"XU CHEN","type":"PERSON","description":"Xu Chen is an author of the paper \"A survey on large language model based autonomous agents\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"YANKAI LIN","type":"PERSON","description":"Yankai Lin is an author of the paper \"A survey on large language model based autonomous agents\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"FRONTIERS OF COMPUTER SCIENCE","type":"PUBLICATION","description":"Frontiers of Computer Science is the journal where the paper \"A survey on large language model based autonomous agents\" was published","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"RUI WANG","type":"PERSON","description":"Rui Wang is an author of the papers \"Poet: open-ended coevolution of environments and their optimized solutions\" and \"Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"JOEL LEHMAN","type":"PERSON","description":"Joel Lehman is an author of the papers \"Poet: open-ended coevolution of environments and their optimized solutions\" and \"Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"JEFF CLUNE","type":"PERSON","description":"Jeff Clune is an author of the papers \"Poet: open-ended coevolution of environments and their optimized solutions\" and \"Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions\"\nJeff Clune is an author of the paper \"OMNI: Open-endedness via models of human notions of interestingness\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"KENNETH O. STANLEY","type":"PERSON","description":"Kenneth O. Stanley is an author of the papers \"Poet: open-ended coevolution of environments and their optimized solutions\" and \"Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE","type":"EVENT","description":"The Genetic and Evolutionary Computation Conference is where the paper \"Poet: open-ended coevolution of environments and their optimized solutions\" was presented","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"ASSOCIATION FOR COMPUTING MACHINERY","type":"ORGANIZATION","description":"The Association for Computing Machinery is the organization that hosted the Genetic and Evolutionary Computation Conference","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"ADITYA RAWAL","type":"PERSON","description":"Aditya Rawal is an author of the paper \"Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"JIALE ZHI","type":"PERSON","description":"Jiale Zhi is an author of the paper \"Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"YULUN LI","type":"PERSON","description":"Yulun Li is an author of the paper \"Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"INTERNATIONAL CONFERENCE ON MACHINE LEARNING","type":"EVENT","description":"The International Conference on Machine Learning is where the paper \"Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions\" was presented","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"PMLR","type":"ORGANIZATION","description":"PMLR is the organization that hosted the International Conference on Machine Learning\nPMLR is the organization that hosted the Conference on Robot Learning","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"ORGANIZATION"},{"name":"XUEZHI WANG","type":"PERSON","description":"Xuezhi Wang is an author of the papers \"Self-consistency improves chain of thought reasoning in language models\" and \"Chain-of-thought prompting elicits reasoning in large language models\"\nXuezhi Wang is an author of the paper \"Self-consistency improves chain of thought reasoning in language models\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"JASON WEI","type":"PERSON","description":"Jason Wei is an author of the paper \"Self-consistency improves chain of thought reasoning in language models\"\nJason Wei is an author of the papers \"Self-consistency improves chain of thought reasoning in language models\" and \"Chain-of-thought prompting elicits reasoning in large language models\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"DALE SCHUURMANS","type":"PERSON","description":"Dale Schuurmans is an author of the papers \"Self-consistency improves chain of thought reasoning in language models\" and \"Chain-of-thought prompting elicits reasoning in large language models\"\nDale Schuurmans is an author of the paper \"Self-consistency improves chain of thought reasoning in language models\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"QUOC V LE","type":"PERSON","description":"Quoc V Le is an author of the papers \"Self-consistency improves chain of thought reasoning in language models\" and \"Chain-of-thought prompting elicits reasoning in large language models\"\nQuoc V Le is an author of the paper \"Self-consistency improves chain of thought reasoning in language models\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"ED H. CHI","type":"PERSON","description":"Ed H. Chi is an author of the paper \"Self-consistency improves chain of thought reasoning in language models\"\nEd H. Chi is an author of the papers \"Self-consistency improves chain of thought reasoning in language models\" and \"Chain-of-thought prompting elicits reasoning in large language models\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"SHARAN NARANG","type":"PERSON","description":"Sharan Narang is an author of the paper \"Self-consistency improves chain of thought reasoning in language models\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"AAKANKSHA CHOWDHERY","type":"PERSON","description":"Aakanksha Chowdhery is an author of the paper \"Self-consistency improves chain of thought reasoning in language models\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"DENNY ZHOU","type":"PERSON","description":"Denny Zhou is an author of the papers \"Self-consistency improves chain of thought reasoning in language models\" and \"Chain-of-thought prompting elicits reasoning in large language models\"\nDenny Zhou is an author of the paper \"Self-consistency improves chain of thought reasoning in language models\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"THE ELEVENTH INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS","type":"EVENT","description":"The Eleventh International Conference on Learning Representations is where the paper \"Self-consistency improves chain of thought reasoning in language models\" was presented\nThe Eleventh International Conference on Learning Representations is where the papers \"Self-consistency improves chain of thought reasoning in language models\" and \"React: Synergizing reasoning and acting in language models\" were presented","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"EVENT"},{"name":"MAARTEN BOSMA","type":"PERSON","description":"Maarten Bosma is an author of the paper \"Chain-of-thought prompting elicits reasoning in large language models\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"FEI XIA","type":"PERSON","description":"Fei Xia is an author of the paper \"Chain-of-thought prompting elicits reasoning in large language models\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS","type":"PUBLICATION","description":"Advances in Neural Information Processing Systems is the journal where the paper \"Chain-of-thought prompting elicits reasoning in large language models\" was published","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PUBLICATION"},{"name":"QINGYUN WU","type":"PERSON","description":"Qingyun Wu is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"GAGAN BANSAL","type":"PERSON","description":"Gagan Bansal is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"JIEYU ZHANG","type":"PERSON","description":"Jieyu Zhang is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"YIRAN WU","type":"PERSON","description":"Yiran Wu is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"SHAOKUN ZHANG","type":"PERSON","description":"Shaokun Zhang is an author of the paper \"Evoagent: Towards automatic multi-agent generation via evolutionary algorithms\"\nShaokun Zhang is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\"\nShaokun Zhang is an author of the papers \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\" and \"Evoagent: Towards automatic multi-agent generation via evolutionary algorithms\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"ERKANG ZHU","type":"PERSON","description":"Erkang Zhu is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"BEIBIN LI","type":"PERSON","description":"Beibin Li is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"LI JIANG","type":"PERSON","description":"Li Jiang is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"XIAOYUN ZHANG","type":"PERSON","description":"Xiaoyun Zhang is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"CHI WANG","type":"PERSON","description":"Chi Wang is an author of the papers \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\" and \"Evoagent: Towards automatic multi-agent generation via evolutionary algorithms\"\nChi Wang is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"BENFENG XU","type":"PERSON","description":"Benfeng Xu is an author of the paper \"Expertprompting: Instructing large language models to be distinguished experts\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"AN YANG","type":"PERSON","description":"An Yang is an author of the paper \"Expertprompting: Instructing large language models to be distinguished experts\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"JUNYANG LIN","type":"PERSON","description":"Junyang Lin is an author of the paper \"Expertprompting: Instructing large language models to be distinguished experts\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"QUAN WANG","type":"PERSON","description":"Quan Wang is an author of the paper \"Expertprompting: Instructing large language models to be distinguished experts\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"CHANG ZHOU","type":"PERSON","description":"Chang Zhou is an author of the paper \"Expertprompting: Instructing large language models to be distinguished experts\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"YONGDONG ZHANG","type":"PERSON","description":"Yongdong Zhang is an author of the paper \"Expertprompting: Instructing large language models to be distinguished experts\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"ZHENDONG MAO","type":"PERSON","description":"Zhendong Mao is an author of the paper \"Expertprompting: Instructing large language models to be distinguished experts\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"CHENGRUN YANG","type":"PERSON","description":"Chengrun Yang is an author of the paper \"Large language models as optimizers\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"YIFENG LU","type":"PERSON","description":"Yifeng Lu is an author of the paper \"Large language models as optimizers\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"HANXIAO LIU","type":"PERSON","description":"Hanxiao Liu is an author of the paper \"Large language models as optimizers\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"XINYUN CHEN","type":"PERSON","description":"Xinyun Chen is an author of the paper \"Large language models as optimizers\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS","type":"EVENT","description":"The Twelfth International Conference on Learning Representations is where the papers \"Large language models as optimizers\" and \"OMNI: Open-endedness via models of human notions of interestingness\" were presented","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"SHUNYU YAO","type":"PERSON","description":"Shunyu Yao is an author of the paper \"React: Synergizing reasoning and acting in language models\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"JEFFREY ZHAO","type":"PERSON","description":"Jeffrey Zhao is an author of the paper \"React: Synergizing reasoning and acting in language models\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"DIAN YU","type":"PERSON","description":"Dian Yu is an author of the paper \"React: Synergizing reasoning and acting in language models\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"NAN DU","type":"PERSON","description":"Nan Du is an author of the paper \"React: Synergizing reasoning and acting in language models\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"IZHAK SHAFRAN","type":"PERSON","description":"Izhak Shafran is an author of the paper \"React: Synergizing reasoning and acting in language models\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"KARTHIK R NARASIMHAN","type":"PERSON","description":"Karthik R Narasimhan is an author of the paper \"React: Synergizing reasoning and acting in language models\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"YUAN CAO","type":"PERSON","description":"Yuan Cao is an author of the paper \"React: Synergizing reasoning and acting in language models\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"BENNET YEE","type":"PERSON","description":"Bennet Yee is an author of the paper \"Native client: A sandbox for portable, untrusted x86 native code\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"DAVID SEHR","type":"PERSON","description":"David Sehr is an author of the paper \"Native client: A sandbox for portable, untrusted x86 native code\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"GREGORY DARDYK","type":"PERSON","description":"Gregory Dardyk is an author of the paper \"Native client: A sandbox for portable, untrusted x86 native code\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"J BRADLEY CHEN","type":"PERSON","description":"J Bradley Chen is an author of the paper \"Native client: A sandbox for portable, untrusted x86 native code\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"ROBERT MUTH","type":"PERSON","description":"Robert Muth is an author of the paper \"Native client: A sandbox for portable, untrusted x86 native code\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"TAVIS ORMANDY","type":"PERSON","description":"Tavis Ormandy is an author of the paper \"Native client: A sandbox for portable, untrusted x86 native code\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"SHIKI OKASAKA","type":"PERSON","description":"Shiki Okasaka is an author of the paper \"Native client: A sandbox for portable, untrusted x86 native code\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"NEHA NARULA","type":"PERSON","description":"Neha Narula is an author of the paper \"Native client: A sandbox for portable, untrusted x86 native code\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"NICHOLAS FULLAGAR","type":"PERSON","description":"Nicholas Fullagar is an author of the paper \"Native client: A sandbox for portable, untrusted x86 native code\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"COMMUNICATIONS OF THE ACM","type":"PUBLICATION","description":"Communications of the ACM is the journal where the paper \"Native client: A sandbox for portable, untrusted x86 native code\" was published","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"WENHAO YU","type":"PERSON","description":"Wenhao Yu is an author of the paper \"Language to rewards for robotic skill synthesis\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"NIMROD GILEADI","type":"PERSON","description":"Nimrod Gileadi is an author of the paper \"Language to rewards for robotic skill synthesis\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"CHUYUAN FU","type":"PERSON","description":"Chuyuan Fu is an author of the paper \"Language to rewards for robotic skill synthesis\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"SEAN KIRMANI","type":"PERSON","description":"Sean Kirmani is an author of the paper \"Language to rewards for robotic skill synthesis\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"KUANG-HUEI LEE","type":"PERSON","description":"Kuang-Huei Lee is an author of the paper \"Language to rewards for robotic skill synthesis\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"MONTSERRAT GONZALEZ ARENAS","type":"PERSON","description":"Montserrat Gonzalez Arenas is an author of the paper \"Language to rewards for robotic skill synthesis\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"HAO-TIEN LEWIS CHIANG","type":"PERSON","description":"Hao-Tien Lewis Chiang is an author of the paper \"Language to rewards for robotic skill synthesis\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"TOM EREZ","type":"PERSON","description":"Tom Erez is an author of the paper \"Language to rewards for robotic skill synthesis\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"LEONARD HASENCLEVER","type":"PERSON","description":"Leonard Hasenclever is an author of the paper \"Language to rewards for robotic skill synthesis\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"JAN HUMPLIK","type":"PERSON","description":"Jan Humplik is an author of the paper \"Language to rewards for robotic skill synthesis\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"CONFERENCE ON ROBOT LEARNING","type":"EVENT","description":"The Conference on Robot Learning is where the paper \"Language to rewards for robotic skill synthesis\" was presented","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"SIYU YUAN","type":"PERSON","description":"Siyu Yuan is an author of the paper \"Evoagent: Towards automatic multi-agent generation via evolutionary algorithms\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"KAITAO SONG","type":"PERSON","description":"Kaitao Song is an author of the\nKaitao Song is an author of the paper \"Evoagent: Towards automatic multi-agent generation via evolutionary algorithms\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1","entity_type":"PERSON"},{"name":"JIANGJIE CHEN","type":"PERSON","description":"Jiangjie Chen is an author of the paper \"Evoagent: Towards automatic multi-agent generation via evolutionary algorithms\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"XU TAN","type":"PERSON","description":"Xu Tan is an author of the paper \"Evoagent: Towards automatic multi-agent generation via evolutionary algorithms\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"DONGSHENG LI","type":"PERSON","description":"Dongsheng Li is an author of the paper \"Evoagent: Towards automatic multi-agent generation via evolutionary algorithms\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"DEQING YANG","type":"PERSON","description":"Deqing Yang is an author of the paper \"Evoagent: Towards automatic multi-agent generation via evolutionary algorithms\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"ELIEZER YUDKOWSKY","type":"PERSON","description":"Eliezer Yudkowsky is an author of the paper \"Artificial Intelligence as a positive and negative factor in global risk\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"GLOBAL CATASTROPHIC RISKS","type":"PUBLICATION","description":"Global Catastrophic Risks is the journal where the paper \"Artificial Intelligence as a positive and negative factor in global risk\" was published","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"MATEI ZAHARIA","type":"PERSON","description":"Matei Zaharia is an author of the paper \"The shift from models to compound ai systems\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"OMAR KHATTAB","type":"PERSON","description":"Omar Khattab is an author of the paper \"The shift from models to compound ai systems\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"LINGJIAO CHEN","type":"PERSON","description":"Lingjiao Chen is an author of the paper \"The shift from models to compound ai systems\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"JARED QUINCY DAVIS","type":"PERSON","description":"Jared Quincy Davis is an author of the paper \"The shift from models to compound ai systems\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"HEATHER MILLER","type":"PERSON","description":"Heather Miller is an author of the paper \"The shift from models to compound ai systems\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"CHRIS POTTS","type":"PERSON","description":"Chris Potts is an author of the paper \"The shift from models to compound ai systems\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"JAMES ZOU","type":"PERSON","description":"James Zou is an author of the paper \"The shift from models to compound ai systems\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"MICHAEL CARBIN","type":"PERSON","description":"Michael Carbin is an author of the paper \"The shift from models to compound ai systems\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"JONATHAN FRANKLE","type":"PERSON","description":"Jonathan Frankle is an author of the paper \"The shift from models to compound ai systems\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"NAVEEN RAO","type":"PERSON","description":"Naveen Rao is an author of the paper \"The shift from models to compound ai systems\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"ALI GHODSI","type":"PERSON","description":"Ali Ghodsi is an author of the paper \"The shift from models to compound ai systems\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"BAIR","type":"ORGANIZATION","description":"BAIR is the organization that published the blog post \"The shift from models to compound ai systems\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"JENNY ZHANG","type":"PERSON","description":"Jenny Zhang is an author of the paper \"OMNI: Open-endedness via models of human notions of interestingness\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"},{"name":"KENNETH STANLEY","type":"PERSON","description":"Kenneth Stanley is an author of the paper \"OMNI: Open-endedness via models of human notions of interestingness\"","source_id":"2600a1ed94ad2d3675ea80575c39cbd1"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"MATT BOTVINICK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Matt Botvinick is an author of the paper \"Learning to reinforcement learn\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"ARXIV\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">arXiv is the platform where the paper \"Learning to reinforcement learn\" was published<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"LEI WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lei Wang is an author of the paper \"A survey on large language model based autonomous agents\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"CHEN MA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chen Ma is an author of the paper \"A survey on large language model based autonomous agents\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"XUEYANG FENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xueyang Feng is an author of the paper \"A survey on large language model based autonomous agents\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"ZEYU ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zeyu Zhang is an author of the paper \"A survey on large language model based autonomous agents\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"HAO YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hao Yang is an author of the paper \"A survey on large language model based autonomous agents\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"JINGSEN ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jingsen Zhang is an author of the paper \"A survey on large language model based autonomous agents\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"ZHIYUAN CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhiyuan Chen is an author of the paper \"A survey on large language model based autonomous agents\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"JIAKAI TANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jiakai Tang is an author of the paper \"A survey on large language model based autonomous agents\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"XU CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xu Chen is an author of the paper \"A survey on large language model based autonomous agents\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"YANKAI LIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yankai Lin is an author of the paper \"A survey on large language model based autonomous agents\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"FRONTIERS OF COMPUTER SCIENCE\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Frontiers of Computer Science is the journal where the paper \"A survey on large language model based autonomous agents\" was published<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"RUI WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Rui Wang is an author of the papers \"Poet: open-ended coevolution of environments and their optimized solutions\" and \"Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"JOEL LEHMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joel Lehman is an author of the papers \"Poet: open-ended coevolution of environments and their optimized solutions\" and \"Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"JEFF CLUNE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jeff Clune is an author of the papers \"Poet: open-ended coevolution of environments and their optimized solutions\" and \"Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions\"Jeff Clune is an author of the paper \"OMNI: Open-endedness via models of human notions of interestingness\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KENNETH O. STANLEY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kenneth O. Stanley is an author of the papers \"Poet: open-ended coevolution of environments and their optimized solutions\" and \"Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">The Genetic and Evolutionary Computation Conference is where the paper \"Poet: open-ended coevolution of environments and their optimized solutions\" was presented<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"ASSOCIATION FOR COMPUTING MACHINERY\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">The Association for Computing Machinery is the organization that hosted the Genetic and Evolutionary Computation Conference<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"ADITYA RAWAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Aditya Rawal is an author of the paper \"Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"JIALE ZHI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jiale Zhi is an author of the paper \"Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"YULUN LI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yulun Li is an author of the paper \"Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"INTERNATIONAL CONFERENCE ON MACHINE LEARNING\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">The International Conference on Machine Learning is where the paper \"Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions\" was presented<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"PMLR\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">PMLR is the organization that hosted the International Conference on Machine LearningPMLR is the organization that hosted the Conference on Robot Learning<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"XUEZHI WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xuezhi Wang is an author of the papers \"Self-consistency improves chain of thought reasoning in language models\" and \"Chain-of-thought prompting elicits reasoning in large language models\"Xuezhi Wang is an author of the paper \"Self-consistency improves chain of thought reasoning in language models\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JASON WEI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jason Wei is an author of the paper \"Self-consistency improves chain of thought reasoning in language models\"Jason Wei is an author of the papers \"Self-consistency improves chain of thought reasoning in language models\" and \"Chain-of-thought prompting elicits reasoning in large language models\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DALE SCHUURMANS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dale Schuurmans is an author of the papers \"Self-consistency improves chain of thought reasoning in language models\" and \"Chain-of-thought prompting elicits reasoning in large language models\"Dale Schuurmans is an author of the paper \"Self-consistency improves chain of thought reasoning in language models\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"QUOC V LE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Quoc V Le is an author of the papers \"Self-consistency improves chain of thought reasoning in language models\" and \"Chain-of-thought prompting elicits reasoning in large language models\"Quoc V Le is an author of the paper \"Self-consistency improves chain of thought reasoning in language models\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ED H. CHI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ed H. Chi is an author of the paper \"Self-consistency improves chain of thought reasoning in language models\"Ed H. Chi is an author of the papers \"Self-consistency improves chain of thought reasoning in language models\" and \"Chain-of-thought prompting elicits reasoning in large language models\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHARAN NARANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sharan Narang is an author of the paper \"Self-consistency improves chain of thought reasoning in language models\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"AAKANKSHA CHOWDHERY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Aakanksha Chowdhery is an author of the paper \"Self-consistency improves chain of thought reasoning in language models\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DENNY ZHOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Denny Zhou is an author of the papers \"Self-consistency improves chain of thought reasoning in language models\" and \"Chain-of-thought prompting elicits reasoning in large language models\"Denny Zhou is an author of the paper \"Self-consistency improves chain of thought reasoning in language models\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"THE ELEVENTH INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">The Eleventh International Conference on Learning Representations is where the paper \"Self-consistency improves chain of thought reasoning in language models\" was presentedThe Eleventh International Conference on Learning Representations is where the papers \"Self-consistency improves chain of thought reasoning in language models\" and \"React: Synergizing reasoning and acting in language models\" were presented<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">EVENT<\/data>    <\/node>    <node id=\"MAARTEN BOSMA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Maarten Bosma is an author of the paper \"Chain-of-thought prompting elicits reasoning in large language models\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"FEI XIA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Fei Xia is an author of the paper \"Chain-of-thought prompting elicits reasoning in large language models\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Advances in Neural Information Processing Systems is the journal where the paper \"Chain-of-thought prompting elicits reasoning in large language models\" was published<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"QINGYUN WU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Qingyun Wu is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GAGAN BANSAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gagan Bansal is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JIEYU ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jieyu Zhang is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YIRAN WU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yiran Wu is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHAOKUN ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shaokun Zhang is an author of the paper \"Evoagent: Towards automatic multi-agent generation via evolutionary algorithms\"Shaokun Zhang is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\"Shaokun Zhang is an author of the papers \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\" and \"Evoagent: Towards automatic multi-agent generation via evolutionary algorithms\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ERKANG ZHU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Erkang Zhu is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BEIBIN LI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Beibin Li is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LI JIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Li Jiang is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XIAOYUN ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xiaoyun Zhang is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHI WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chi Wang is an author of the papers \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\" and \"Evoagent: Towards automatic multi-agent generation via evolutionary algorithms\"Chi Wang is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation framework\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BENFENG XU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Benfeng Xu is an author of the paper \"Expertprompting: Instructing large language models to be distinguished experts\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"AN YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An Yang is an author of the paper \"Expertprompting: Instructing large language models to be distinguished experts\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JUNYANG LIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Junyang Lin is an author of the paper \"Expertprompting: Instructing large language models to be distinguished experts\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"QUAN WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Quan Wang is an author of the paper \"Expertprompting: Instructing large language models to be distinguished experts\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHANG ZHOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chang Zhou is an author of the paper \"Expertprompting: Instructing large language models to be distinguished experts\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YONGDONG ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yongdong Zhang is an author of the paper \"Expertprompting: Instructing large language models to be distinguished experts\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHENDONG MAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhendong Mao is an author of the paper \"Expertprompting: Instructing large language models to be distinguished experts\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHENGRUN YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chengrun Yang is an author of the paper \"Large language models as optimizers\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YIFENG LU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yifeng Lu is an author of the paper \"Large language models as optimizers\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HANXIAO LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hanxiao Liu is an author of the paper \"Large language models as optimizers\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XINYUN CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xinyun Chen is an author of the paper \"Large language models as optimizers\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">The Twelfth International Conference on Learning Representations is where the papers \"Large language models as optimizers\" and \"OMNI: Open-endedness via models of human notions of interestingness\" were presented<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"SHUNYU YAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shunyu Yao is an author of the paper \"React: Synergizing reasoning and acting in language models\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JEFFREY ZHAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jeffrey Zhao is an author of the paper \"React: Synergizing reasoning and acting in language models\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DIAN YU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dian Yu is an author of the paper \"React: Synergizing reasoning and acting in language models\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NAN DU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nan Du is an author of the paper \"React: Synergizing reasoning and acting in language models\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"IZHAK SHAFRAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Izhak Shafran is an author of the paper \"React: Synergizing reasoning and acting in language models\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KARTHIK R NARASIMHAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Karthik R Narasimhan is an author of the paper \"React: Synergizing reasoning and acting in language models\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YUAN CAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yuan Cao is an author of the paper \"React: Synergizing reasoning and acting in language models\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BENNET YEE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bennet Yee is an author of the paper \"Native client: A sandbox for portable, untrusted x86 native code\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DAVID SEHR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">David Sehr is an author of the paper \"Native client: A sandbox for portable, untrusted x86 native code\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GREGORY DARDYK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gregory Dardyk is an author of the paper \"Native client: A sandbox for portable, untrusted x86 native code\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"J BRADLEY CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">J Bradley Chen is an author of the paper \"Native client: A sandbox for portable, untrusted x86 native code\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ROBERT MUTH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Robert Muth is an author of the paper \"Native client: A sandbox for portable, untrusted x86 native code\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TAVIS ORMANDY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tavis Ormandy is an author of the paper \"Native client: A sandbox for portable, untrusted x86 native code\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHIKI OKASAKA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shiki Okasaka is an author of the paper \"Native client: A sandbox for portable, untrusted x86 native code\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NEHA NARULA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Neha Narula is an author of the paper \"Native client: A sandbox for portable, untrusted x86 native code\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NICHOLAS FULLAGAR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nicholas Fullagar is an author of the paper \"Native client: A sandbox for portable, untrusted x86 native code\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"COMMUNICATIONS OF THE ACM\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Communications of the ACM is the journal where the paper \"Native client: A sandbox for portable, untrusted x86 native code\" was published<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"WENHAO YU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wenhao Yu is an author of the paper \"Language to rewards for robotic skill synthesis\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NIMROD GILEADI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nimrod Gileadi is an author of the paper \"Language to rewards for robotic skill synthesis\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHUYUAN FU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chuyuan Fu is an author of the paper \"Language to rewards for robotic skill synthesis\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SEAN KIRMANI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sean Kirmani is an author of the paper \"Language to rewards for robotic skill synthesis\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KUANG-HUEI LEE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kuang-Huei Lee is an author of the paper \"Language to rewards for robotic skill synthesis\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MONTSERRAT GONZALEZ ARENAS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Montserrat Gonzalez Arenas is an author of the paper \"Language to rewards for robotic skill synthesis\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HAO-TIEN LEWIS CHIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hao-Tien Lewis Chiang is an author of the paper \"Language to rewards for robotic skill synthesis\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TOM EREZ\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tom Erez is an author of the paper \"Language to rewards for robotic skill synthesis\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LEONARD HASENCLEVER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Leonard Hasenclever is an author of the paper \"Language to rewards for robotic skill synthesis\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JAN HUMPLIK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jan Humplik is an author of the paper \"Language to rewards for robotic skill synthesis\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CONFERENCE ON ROBOT LEARNING\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">The Conference on Robot Learning is where the paper \"Language to rewards for robotic skill synthesis\" was presented<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"SIYU YUAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Siyu Yuan is an author of the paper \"Evoagent: Towards automatic multi-agent generation via evolutionary algorithms\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KAITAO SONG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kaitao Song is an author of theKaitao Song is an author of the paper \"Evoagent: Towards automatic multi-agent generation via evolutionary algorithms\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JIANGJIE CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jiangjie Chen is an author of the paper \"Evoagent: Towards automatic multi-agent generation via evolutionary algorithms\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"XU TAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xu Tan is an author of the paper \"Evoagent: Towards automatic multi-agent generation via evolutionary algorithms\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"DONGSHENG LI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dongsheng Li is an author of the paper \"Evoagent: Towards automatic multi-agent generation via evolutionary algorithms\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"DEQING YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Deqing Yang is an author of the paper \"Evoagent: Towards automatic multi-agent generation via evolutionary algorithms\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"ELIEZER YUDKOWSKY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Eliezer Yudkowsky is an author of the paper \"Artificial Intelligence as a positive and negative factor in global risk\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"GLOBAL CATASTROPHIC RISKS\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Global Catastrophic Risks is the journal where the paper \"Artificial Intelligence as a positive and negative factor in global risk\" was published<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"MATEI ZAHARIA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Matei Zaharia is an author of the paper \"The shift from models to compound ai systems\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"OMAR KHATTAB\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Omar Khattab is an author of the paper \"The shift from models to compound ai systems\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"LINGJIAO CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lingjiao Chen is an author of the paper \"The shift from models to compound ai systems\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"JARED QUINCY DAVIS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jared Quincy Davis is an author of the paper \"The shift from models to compound ai systems\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"HEATHER MILLER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Heather Miller is an author of the paper \"The shift from models to compound ai systems\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"CHRIS POTTS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chris Potts is an author of the paper \"The shift from models to compound ai systems\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"JAMES ZOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">James Zou is an author of the paper \"The shift from models to compound ai systems\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"MICHAEL CARBIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Michael Carbin is an author of the paper \"The shift from models to compound ai systems\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"JONATHAN FRANKLE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jonathan Frankle is an author of the paper \"The shift from models to compound ai systems\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"NAVEEN RAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Naveen Rao is an author of the paper \"The shift from models to compound ai systems\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"ALI GHODSI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ali Ghodsi is an author of the paper \"The shift from models to compound ai systems\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"BAIR\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">BAIR is the organization that published the blog post \"The shift from models to compound ai systems\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"JENNY ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jenny Zhang is an author of the paper \"OMNI: Open-endedness via models of human notions of interestingness\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>    <node id=\"KENNETH STANLEY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kenneth Stanley is an author of the paper \"OMNI: Open-endedness via models of human notions of interestingness\"<\/data>      <data key=\"d2\">2600a1ed94ad2d3675ea80575c39cbd1<\/data>    <\/node>  <\/graph><\/graphml>"}
{"id":"cc802d9b841fde55e9c0c2ba0ef7869d","chunk":"ai-systems\/ , 2024.\nJennyZhang, JoelLehman, KennethStanley, andJeffClune. OMNI:Open-endednessviamodelsofhu-\nman notions of interestingness. In The Twelfth International Conference on Learning Representations ,\n2024a. URL https:\/\/openreview.net\/forum?id=AgM3MzT99c .\nShaokun Zhang, Jieyu Zhang, Jiale Liu, Linxin Song, Chi Wang, Ranjay Krishna, and Qingyun\nWu. Offline training of language model agents with functions as learnable weights. In Forty-first\nInternational Conference on Machine Learning , 2024b.\nZeyu Zhang, Xiaohe Bo, Chen Ma, Rui Li, Xu Chen, Quanyu Dai, Jieming Zhu, Zhenhua Dong, and\nJi-Rong Wen. A survey on the memory mechanism of large language model based agents. arXiv\npreprint arXiv:2404.13501 , 2024c.\nHuaixiu Steven Zheng, Swaroop Mishra, Xinyun Chen, Heng-Tze Cheng, Ed H Chi, Quoc V Le, and\nDenny Zhou. Take a step back: Evoking reasoning via abstraction in large language models. arXiv\npreprint arXiv:2310.06117 , 2023.\nPei Zhou, Jay Pujara, Xiang Ren, Xinyun Chen, Heng-Tze Cheng, Quoc V Le, Ed H Chi, Denny Zhou,\nSwaroop Mishra, and Huaixiu Steven Zheng. Self-discover: Large language models self-compose\nreasoning structures. arXiv preprint arXiv:2402.03620 , 2024a.\n21Automated Design of Agentic Systems\nWangchunshu Zhou, Yixin Ou, Shengwei Ding, Long Li, Jialong Wu, Tiannan Wang, Jiamin Chen,\nShuai Wang, Xiaohua Xu, Ningyu Zhang, et al. Symbolic learning enables self-evolving agents.\narXiv preprint arXiv:2406.18532 , 2024b.\nMingchen Zhuge, Wenyi Wang, Louis Kirsch, Francesco Faccio, Dmitrii Khizbullin, and J\u00fcrgen\nSchmidhuber. Gptswarm: Language agents as optimizable graphs. In Forty-first International\nConference on Machine Learning , 2024.\nLuisaZintgraf,SebastianSchulze,CongLu,LeoFeng,MaximilianIgl,KyriacosShiarlis,YarinGal,Katja\nHofmann, and Shimon Whiteson. Varibad: Variational bayes-adaptive deep rl via meta-learning.\nJournal of Machine Learning Research , 22(289):1\u201339, 2021a.\nLuisa M Zintgraf, Leo Feng, Cong Lu, Maximilian Igl, Kristian Hartikainen, Katja Hofmann, and\nShimon Whiteson. Exploration in approximate hyper-state space for meta reinforcement learning.\nInInternational Conference on Machine Learning , pp. 12991\u201313001. PMLR, 2021b.\n22Automated Design of Agentic Systems\nSupplementary Material\nTable of Contents\nA Prompts 24\nB Framework Code 26\nC Experiment Details for ARC Challenge 30\nD Experiment Details for Reasoning and Problem-Solving Domains 33\nE Baselines 35\nF Example Agents 36\nG Cost of Experiments 39\n23Automated Design of Agentic Systems\nA. Prompts\nWe use the following prompts for the meta agent in Meta Agent Search. Variables in the prompts\nthat vary depending on domains and iterations are highlighted. All detailed prompts are available at\nhttps:\/\/github.com\/ShengranHu\/ADAS .\nWe use the following system prompt for every query in the meta agent.\nSystem prompt for the meta agent.\nYou are a helpful assistant. Make sure to return in a WELL-FORMED JSON object.\nWe use the following prompt for the meta agent to design the new agent based on the archive of\npreviously discovered agents.\nMain prompt for the meta agent.\nYou are an expert machine learning researcher testing various agentic systems. Your objective is to design\nbuilding blocks such as prompts and control flows within these systems to solve complex tasks. Your aim\nis to design an optimal agent performing well on [BriefDescriptionoftheDomain].\n[FrameworkCode]\n[OutputInstructionsandExamples]\n[DiscoveredAgentArchive] (initializedwithbaselines,updatedateveryiteration)\n# Your task\nYou are deeply familiar with prompting techniques and the agent works from the literature. Your goal is\nto maximize the specified performance metrics by proposing interestingly new agents.\nObserve the discovered agents carefully and think about what insights, lessons, or stepping stones can be\nlearned from them.\nBe creative when thinking about the next interesting agent to try. You are encouraged to draw inspiration\nfrom related agent papers or academic papers from other research areas.\nUse the knowledge from the archive and inspiration from academic literature to propose the next\ninteresting agentic system design.\nTHINK OUTSIDE THE BOX.\nThe domain descriptions are available in Appendices C and D and the framework code is available\nin Appendix B. We use the following prompt to instruct and format the output of the meta agent.\nHere, we collect and present some common mistakes that the meta agent may make in the prompt.\nWe found it effective in improving the quality of the generated code.\nOutput Instruction and Example.\n# Output Instruction and Example:\nThe first key should be (\u201cthought\u201d), and it should capture your thought process for designing the\nnext function. In","chunk_id":"cc802d9b841fde55e9c0c2ba0ef7869d","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"JENNY ZHANG","type":"PERSON","description":"Jenny Zhang is an author of the paper \"OMNI: Open-endedness via models of human notions of interestingness\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d"},{"name":"JOEL LEHMAN","type":"PERSON","description":"Joel Lehman is an author of the paper \"OMNI: Open-endedness via models of human notions of interestingness\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d"},{"name":"KENNETH STANLEY","type":"PERSON","description":"Kenneth Stanley is an author of the paper \"OMNI: Open-endedness via models of human notions of interestingness\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d"},{"name":"JEFF CLUNE","type":"PERSON","description":"Jeff Clune is an author of the paper \"OMNI: Open-endedness via models of human notions of interestingness\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d"},{"name":"SHAOKUN ZHANG","type":"PERSON","description":"Shaokun Zhang is an author of the paper \"Offline training of language model agents with functions as learnable weights\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"JIEYU ZHANG","type":"PERSON","description":"Jieyu Zhang is an author of the paper \"Offline training of language model agents with functions as learnable weights\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"JIALE LIU","type":"PERSON","description":"Jiale Liu is an author of the paper \"Offline training of language model agents with functions as learnable weights\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"LINXIN SONG","type":"PERSON","description":"Linxin Song is an author of the paper \"Offline training of language model agents with functions as learnable weights\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"CHI WANG","type":"PERSON","description":"Chi Wang is an author of the paper \"Offline training of language model agents with functions as learnable weights\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"RANJAY KRISHNA","type":"PERSON","description":"Ranjay Krishna is an author of the paper \"Offline training of language model agents with functions as learnable weights\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"QINGYUN WU","type":"PERSON","description":"Qingyun Wu is an author of the paper \"Offline training of language model agents with functions as learnable weights\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"ZEYU ZHANG","type":"PERSON","description":"Zeyu Zhang is an author of the paper \"A survey on the memory mechanism of large language model based agents\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"XIAOHE BO","type":"PERSON","description":"Xiaohe Bo is an author of the paper \"A survey on the memory mechanism of large language model based agents\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"CHEN MA","type":"PERSON","description":"Chen Ma is an author of the paper \"A survey on the memory mechanism of large language model based agents\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"RUI LI","type":"PERSON","description":"Rui Li is an author of the paper \"A survey on the memory mechanism of large language model based agents\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"XU CHEN","type":"PERSON","description":"Xu Chen is an author of the paper \"A survey on the memory mechanism of large language model based agents\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"QUANYU DAI","type":"PERSON","description":"Quanyu Dai is an author of the paper \"A survey on the memory mechanism of large language model based agents\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"JIEMING ZHU","type":"PERSON","description":"Jieming Zhu is an author of the paper \"A survey on the memory mechanism of large language model based agents\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"ZHENHUA DONG","type":"PERSON","description":"Zhenhua Dong is an author of the paper \"A survey on the memory mechanism of large language model based agents\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"JI-RONG WEN","type":"PERSON","description":"Ji-Rong Wen is an author of the paper \"A survey on the memory mechanism of large language model based agents\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"HUAIXIU STEVEN ZHENG","type":"PERSON","description":"Huaixiu Steven Zheng is an author of the paper \"Take a step back: Evoking reasoning via abstraction in large language models\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"SWAROOP MISHRA","type":"PERSON","description":"Swaroop Mishra is an author of the paper \"Take a step back: Evoking reasoning via abstraction in large language models\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"XINYUN CHEN","type":"PERSON","description":"Xinyun Chen is an author of the paper \"Take a step back: Evoking reasoning via abstraction in large language models\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"HENG-TZE CHENG","type":"PERSON","description":"Heng-Tze Cheng is an author of the paper \"Take a step back: Evoking reasoning via abstraction in large language models\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"ED H CHI","type":"PERSON","description":"Ed H Chi is an author of the paper \"Take a step back: Evoking reasoning via abstraction in large language models\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"QUOC V LE","type":"PERSON","description":"Quoc V Le is an author of the paper \"Take a step back: Evoking reasoning via abstraction in large language models\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"DENNY ZHOU","type":"PERSON","description":"Denny Zhou is an author of the paper \"Take a step back: Evoking reasoning via abstraction in large language models\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"PEI ZHOU","type":"PERSON","description":"Pei Zhou is an author of the paper \"Self-discover: Large language models self-compose reasoning structures\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"JAY PUJARA","type":"PERSON","description":"Jay Pujara is an author of the paper \"Self-discover: Large language models self-compose reasoning structures\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"XIANG REN","type":"PERSON","description":"Xiang Ren is an author of the paper \"Self-discover: Large language models self-compose reasoning structures\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"WANGCHUNSHU ZHOU","type":"PERSON","description":"Wangchunshu Zhou is an author of the paper \"Symbolic learning enables self-evolving agents\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"YIXIN OU","type":"PERSON","description":"Yixin Ou is an author of the paper \"Symbolic learning enables self-evolving agents\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"SHENGWEI DING","type":"PERSON","description":"Shengwei Ding is an author of the paper \"Symbolic learning enables self-evolving agents\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"LONG LI","type":"PERSON","description":"Long Li is an author of the paper \"Symbolic learning enables self-evolving agents\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"JIALONG WU","type":"PERSON","description":"Jialong Wu is an author of the paper \"Symbolic learning enables self-evolving agents\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"TIANNAN WANG","type":"PERSON","description":"Tiannan Wang is an author of the paper \"Symbolic learning enables self-evolving agents\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"JIAMIN CHEN","type":"PERSON","description":"Jiamin Chen is an author of the paper \"Symbolic learning enables self-evolving agents\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"SHUAI WANG","type":"PERSON","description":"Shuai Wang is an author of the paper \"Symbolic learning enables self-evolving agents\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"XIAOHUA XU","type":"PERSON","description":"Xiaohua Xu is an author of the paper \"Symbolic learning enables self-evolving agents\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"NINGYU ZHANG","type":"PERSON","description":"Ningyu Zhang is an author of the paper \"Symbolic learning enables self-evolving agents\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"MINGCHEN ZHUGE","type":"PERSON","description":"Mingchen Zhuge is an author of the paper \"GPTSwarm: Language agents as optimizable graphs\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"WENYI WANG","type":"PERSON","description":"Wenyi Wang is an author of the paper \"GPTSwarm: Language agents as optimizable graphs\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"LOUIS KIRSCH","type":"PERSON","description":"Louis Kirsch is an author of the paper \"GPTSwarm: Language agents as optimizable graphs\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"FRANCESCO FACCIO","type":"PERSON","description":"Francesco Faccio is an author of the paper \"GPTSwarm: Language agents as optimizable graphs\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"DMITRII KHIZBULLIN","type":"PERSON","description":"Dmitrii Khizbullin is an author of the paper \"GPTSwarm: Language agents as optimizable graphs\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"J\u00dcRGEN SCHMIDHUBER","type":"PERSON","description":"J\u00fcrgen Schmidhuber is an author of the paper \"GPTSwarm: Language agents as optimizable graphs\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"LUISA ZINTGRAF","type":"PERSON","description":"Luisa Zintgraf is an author of the paper \"Varibad: Variational bayes-adaptive deep RL via meta-learning\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"SEBASTIAN SCHULZE","type":"PERSON","description":"Sebastian Schulze is an author of the paper \"Varibad: Variational bayes-adaptive deep RL via meta-learning\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"CONG LU","type":"PERSON","description":"Cong Lu is an author of the paper \"Varibad: Variational bayes-adaptive deep RL via meta-learning\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"LEO FENG","type":"PERSON","description":"Leo Feng is an author of the paper \"Varibad: Variational bayes-adaptive deep RL via meta-learning\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"MAXIMILIAN IGL","type":"PERSON","description":"Maximilian Igl is an author of the paper \"Varibad: Variational bayes-adaptive deep RL via meta-learning\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"KYRIACOS SHIARLIS","type":"PERSON","description":"Kyriacos Shiarlis is an author of the paper \"Varibad: Variational bayes-adaptive deep RL via meta-learning\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"YARIN GAL","type":"PERSON","description":"Yarin Gal is an author of the paper \"Varibad: Variational bayes-adaptive deep RL via meta-learning\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"KATJA HOFMANN","type":"PERSON","description":"Katja Hofmann is an author of the paper \"Varibad: Variational bayes-adaptive deep RL via meta-learning\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"SHIMON WHITESON","type":"PERSON","description":"Shimon Whiteson is an author of the paper \"Varibad: Variational bayes-adaptive deep RL via meta-learning\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"LUISA M ZINTGRAF","type":"PERSON","description":"Luisa M Zintgraf is an author of the paper \"Exploration in approximate hyper-state space for meta reinforcement learning\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"KRISTIAN HARTIKAINEN","type":"PERSON","description":"Kristian Hartikainen is an author of the paper \"Exploration in approximate hyper-state space for meta reinforcement learning\"","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PERSON"},{"name":"INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS","type":"CONFERENCE","description":"The conference where the paper \"OMNI: Open-endedness via models of human notions of interestingness\" was presented","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"CONFERENCE"},{"name":"FORTY-FIRST INTERNATIONAL CONFERENCE ON MACHINE LEARNING","type":"CONFERENCE","description":"The conference where the paper \"Offline training of language model agents with functions as learnable weights\" was presented","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"CONFERENCE"},{"name":"ARXIV","type":"PUBLICATION PLATFORM","description":"The platform where the paper \"A survey on the memory mechanism of large language model based agents\" was published","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"PUBLICATION PLATFORM"},{"name":"JOURNAL OF MACHINE LEARNING RESEARCH","type":"JOURNAL","description":"The journal where the paper \"Varibad: Variational bayes-adaptive deep RL via meta-learning\" was published","source_id":"cc802d9b841fde55e9c0c2ba0ef7869d","entity_type":"JOURNAL"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"JENNY ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jenny Zhang is an author of the paper \"OMNI: Open-endedness via models of human notions of interestingness\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/node>    <node id=\"JOEL LEHMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joel Lehman is an author of the paper \"OMNI: Open-endedness via models of human notions of interestingness\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/node>    <node id=\"KENNETH STANLEY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kenneth Stanley is an author of the paper \"OMNI: Open-endedness via models of human notions of interestingness\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/node>    <node id=\"JEFF CLUNE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jeff Clune is an author of the paper \"OMNI: Open-endedness via models of human notions of interestingness\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/node>    <node id=\"SHAOKUN ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shaokun Zhang is an author of the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JIEYU ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jieyu Zhang is an author of the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JIALE LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jiale Liu is an author of the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LINXIN SONG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Linxin Song is an author of the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHI WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chi Wang is an author of the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"RANJAY KRISHNA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ranjay Krishna is an author of the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"QINGYUN WU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Qingyun Wu is an author of the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZEYU ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zeyu Zhang is an author of the paper \"A survey on the memory mechanism of large language model based agents\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XIAOHE BO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xiaohe Bo is an author of the paper \"A survey on the memory mechanism of large language model based agents\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHEN MA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chen Ma is an author of the paper \"A survey on the memory mechanism of large language model based agents\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"RUI LI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Rui Li is an author of the paper \"A survey on the memory mechanism of large language model based agents\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XU CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xu Chen is an author of the paper \"A survey on the memory mechanism of large language model based agents\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"QUANYU DAI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Quanyu Dai is an author of the paper \"A survey on the memory mechanism of large language model based agents\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JIEMING ZHU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jieming Zhu is an author of the paper \"A survey on the memory mechanism of large language model based agents\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZHENHUA DONG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhenhua Dong is an author of the paper \"A survey on the memory mechanism of large language model based agents\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JI-RONG WEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ji-Rong Wen is an author of the paper \"A survey on the memory mechanism of large language model based agents\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HUAIXIU STEVEN ZHENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Huaixiu Steven Zheng is an author of the paper \"Take a step back: Evoking reasoning via abstraction in large language models\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SWAROOP MISHRA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Swaroop Mishra is an author of the paper \"Take a step back: Evoking reasoning via abstraction in large language models\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XINYUN CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xinyun Chen is an author of the paper \"Take a step back: Evoking reasoning via abstraction in large language models\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HENG-TZE CHENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Heng-Tze Cheng is an author of the paper \"Take a step back: Evoking reasoning via abstraction in large language models\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ED H CHI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ed H Chi is an author of the paper \"Take a step back: Evoking reasoning via abstraction in large language models\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"QUOC V LE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Quoc V Le is an author of the paper \"Take a step back: Evoking reasoning via abstraction in large language models\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DENNY ZHOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Denny Zhou is an author of the paper \"Take a step back: Evoking reasoning via abstraction in large language models\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PEI ZHOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pei Zhou is an author of the paper \"Self-discover: Large language models self-compose reasoning structures\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JAY PUJARA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jay Pujara is an author of the paper \"Self-discover: Large language models self-compose reasoning structures\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XIANG REN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xiang Ren is an author of the paper \"Self-discover: Large language models self-compose reasoning structures\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WANGCHUNSHU ZHOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wangchunshu Zhou is an author of the paper \"Symbolic learning enables self-evolving agents\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YIXIN OU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yixin Ou is an author of the paper \"Symbolic learning enables self-evolving agents\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHENGWEI DING\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shengwei Ding is an author of the paper \"Symbolic learning enables self-evolving agents\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LONG LI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Long Li is an author of the paper \"Symbolic learning enables self-evolving agents\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JIALONG WU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jialong Wu is an author of the paper \"Symbolic learning enables self-evolving agents\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"TIANNAN WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tiannan Wang is an author of the paper \"Symbolic learning enables self-evolving agents\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JIAMIN CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jiamin Chen is an author of the paper \"Symbolic learning enables self-evolving agents\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHUAI WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shuai Wang is an author of the paper \"Symbolic learning enables self-evolving agents\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XIAOHUA XU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xiaohua Xu is an author of the paper \"Symbolic learning enables self-evolving agents\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NINGYU ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ningyu Zhang is an author of the paper \"Symbolic learning enables self-evolving agents\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MINGCHEN ZHUGE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mingchen Zhuge is an author of the paper \"GPTSwarm: Language agents as optimizable graphs\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WENYI WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wenyi Wang is an author of the paper \"GPTSwarm: Language agents as optimizable graphs\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LOUIS KIRSCH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Louis Kirsch is an author of the paper \"GPTSwarm: Language agents as optimizable graphs\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"FRANCESCO FACCIO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Francesco Faccio is an author of the paper \"GPTSwarm: Language agents as optimizable graphs\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DMITRII KHIZBULLIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dmitrii Khizbullin is an author of the paper \"GPTSwarm: Language agents as optimizable graphs\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"J&#220;RGEN SCHMIDHUBER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">J&#252;rgen Schmidhuber is an author of the paper \"GPTSwarm: Language agents as optimizable graphs\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LUISA ZINTGRAF\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Luisa Zintgraf is an author of the paper \"Varibad: Variational bayes-adaptive deep RL via meta-learning\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SEBASTIAN SCHULZE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sebastian Schulze is an author of the paper \"Varibad: Variational bayes-adaptive deep RL via meta-learning\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CONG LU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Cong Lu is an author of the paper \"Varibad: Variational bayes-adaptive deep RL via meta-learning\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LEO FENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Leo Feng is an author of the paper \"Varibad: Variational bayes-adaptive deep RL via meta-learning\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MAXIMILIAN IGL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Maximilian Igl is an author of the paper \"Varibad: Variational bayes-adaptive deep RL via meta-learning\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KYRIACOS SHIARLIS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kyriacos Shiarlis is an author of the paper \"Varibad: Variational bayes-adaptive deep RL via meta-learning\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YARIN GAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yarin Gal is an author of the paper \"Varibad: Variational bayes-adaptive deep RL via meta-learning\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KATJA HOFMANN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Katja Hofmann is an author of the paper \"Varibad: Variational bayes-adaptive deep RL via meta-learning\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHIMON WHITESON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shimon Whiteson is an author of the paper \"Varibad: Variational bayes-adaptive deep RL via meta-learning\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LUISA M ZINTGRAF\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Luisa M Zintgraf is an author of the paper \"Exploration in approximate hyper-state space for meta reinforcement learning\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"KRISTIAN HARTIKAINEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kristian Hartikainen is an author of the paper \"Exploration in approximate hyper-state space for meta reinforcement learning\"<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"INTERNATIONAL CONFERENCE ON LEARNING REPRESENTATIONS\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">The conference where the paper \"OMNI: Open-endedness via models of human notions of interestingness\" was presented<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">CONFERENCE<\/data>    <\/node>    <node id=\"FORTY-FIRST INTERNATIONAL CONFERENCE ON MACHINE LEARNING\">      <data key=\"d0\">CONFERENCE<\/data>      <data key=\"d1\">The conference where the paper \"Offline training of language model agents with functions as learnable weights\" was presented<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">CONFERENCE<\/data>    <\/node>    <node id=\"ARXIV\">      <data key=\"d0\">PUBLICATION PLATFORM<\/data>      <data key=\"d1\">The platform where the paper \"A survey on the memory mechanism of large language model based agents\" was published<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">PUBLICATION PLATFORM<\/data>    <\/node>    <node id=\"JOURNAL OF MACHINE LEARNING RESEARCH\">      <data key=\"d0\">JOURNAL<\/data>      <data key=\"d1\">The journal where the paper \"Varibad: Variational bayes-adaptive deep RL via meta-learning\" was published<\/data>      <data key=\"d2\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>      <data key=\"d3\">JOURNAL<\/data>    <\/node>    <edge source=\"JENNY ZHANG\" target=\"JOEL LEHMAN\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Jenny Zhang and Joel Lehman co-authored the paper \"OMNI: Open-endedness via models of human notions of interestingness\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"JENNY ZHANG\" target=\"KENNETH STANLEY\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Jenny Zhang and Kenneth Stanley co-authored the paper \"OMNI: Open-endedness via models of human notions of interestingness\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"JENNY ZHANG\" target=\"JEFF CLUNE\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Jenny Zhang and Jeff Clune co-authored the paper \"OMNI: Open-endedness via models of human notions of interestingness\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"JOEL LEHMAN\" target=\"KENNETH STANLEY\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Joel Lehman and Kenneth Stanley co-authored the paper \"OMNI: Open-endedness via models of human notions of interestingness\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"JOEL LEHMAN\" target=\"JEFF CLUNE\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Joel Lehman and Jeff Clune co-authored the paper \"OMNI: Open-endedness via models of human notions of interestingness\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"KENNETH STANLEY\" target=\"JEFF CLUNE\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Kenneth Stanley and Jeff Clune co-authored the paper \"OMNI: Open-endedness via models of human notions of interestingness\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"SHAOKUN ZHANG\" target=\"JIEYU ZHANG\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Shaokun Zhang and Jieyu Zhang co-authored the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"SHAOKUN ZHANG\" target=\"JIALE LIU\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Shaokun Zhang and Jiale Liu co-authored the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"SHAOKUN ZHANG\" target=\"LINXIN SONG\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Shaokun Zhang and Linxin Song co-authored the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"SHAOKUN ZHANG\" target=\"CHI WANG\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Shaokun Zhang and Chi Wang co-authored the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"SHAOKUN ZHANG\" target=\"RANJAY KRISHNA\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Shaokun Zhang and Ranjay Krishna co-authored the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"SHAOKUN ZHANG\" target=\"QINGYUN WU\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Shaokun Zhang and Qingyun Wu co-authored the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"JIEYU ZHANG\" target=\"JIALE LIU\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Jieyu Zhang and Jiale Liu co-authored the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"JIEYU ZHANG\" target=\"LINXIN SONG\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Jieyu Zhang and Linxin Song co-authored the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"JIEYU ZHANG\" target=\"CHI WANG\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Jieyu Zhang and Chi Wang co-authored the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"JIEYU ZHANG\" target=\"RANJAY KRISHNA\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Jieyu Zhang and Ranjay Krishna co-authored the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"JIEYU ZHANG\" target=\"QINGYUN WU\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Jieyu Zhang and Qingyun Wu co-authored the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"JIALE LIU\" target=\"LINXIN SONG\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Jiale Liu and Linxin Song co-authored the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"JIALE LIU\" target=\"CHI WANG\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Jiale Liu and Chi Wang co-authored the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"JIALE LIU\" target=\"RANJAY KRISHNA\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Jiale Liu and Ranjay Krishna co-authored the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"JIALE LIU\" target=\"QINGYUN WU\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Jiale Liu and Qingyun Wu co-authored the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"LINXIN SONG\" target=\"CHI WANG\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Linxin Song and Chi Wang co-authored the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"LINXIN SONG\" target=\"RANJAY KRISHNA\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Linxin Song and Ranjay Krishna co-authored the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"LINXIN SONG\" target=\"QINGYUN WU\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Linxin Song and Qingyun Wu co-authored the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"CHI WANG\" target=\"RANJAY KRISHNA\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Chi Wang and Ranjay Krishna co-authored the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"CHI WANG\" target=\"QINGYUN WU\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Chi Wang and Qingyun Wu co-authored the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>    <edge source=\"RANJAY KRISHNA\" target=\"QINGYUN WU\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Ranjay Krishna and Qingyun Wu co-authored the paper \"Offline training of language model agents with functions as learnable weights\"<\/data>      <data key=\"d6\">cc802d9b841fde55e9c0c2ba0ef7869d<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"282313a8340c6792e8c35f53ed157cd0","chunk":" available in Appendices C and D and the framework code is available\nin Appendix B. We use the following prompt to instruct and format the output of the meta agent.\nHere, we collect and present some common mistakes that the meta agent may make in the prompt.\nWe found it effective in improving the quality of the generated code.\nOutput Instruction and Example.\n# Output Instruction and Example:\nThe first key should be (\u201cthought\u201d), and it should capture your thought process for designing the\nnext function. In the \u201cthought\u201d section, first reason about what the next interesting agent to try\nshould be, then describe your reasoning and the overall concept behind the agent design, and\nfinally detail the implementation steps. The second key (\u201cname\u201d) corresponds to the name of\nyour next agent architecture. Finally, the last key (\u201ccode\u201d) corresponds to the exact \u201cforward()\u201d\nfunction in Python code that you would like to try. You must write COMPLETE CODE in \u201ccode\u201d:\nYourcodewillbepartoftheentireproject, sopleaseimplementcomplete, reliable, reusablecodesnippets.\n24Automated Design of Agentic Systems\nHere is an example of the output format for the next agent:\n{\u201cthought\u201d: \u201c**Insights:** Your insights on what should be the next interesting agent. **Overall Idea:**\nyour reasoning and the overall concept behind the agent design. **Implementation:** describe the\nimplementation step by step.\u201d,\n\u201cname\u201d: \u201cName of your proposed agent\u201d,\n\u201ccode\u201d: \u201cdef forward(self, taskInfo): # Your code here\u201d}\n## WRONG Implementation examples:\n[Examplesofpotentialmistakesthemetaagentmaymakeinimplementation]\nAfter the first response from the meta agent, we perform two rounds of self-reflection to make the\ngenerated agent novel and error-free (Madaan et al., 2024; Shinn et al., 2023).\nPrompt for self-reflection round 1.\n[GeneratedAgentfromPreviousIteration]\nCarefully review the proposed new architecture and reflect on the following points:\n1. **Interestingness**: Assess whether your proposed architecture is interesting or innovative compared\nto existing methods in the archive. If you determine that the proposed architecture is not interesting,\nsuggest a new architecture that addresses these shortcomings.\n- Make sure to check the difference between the proposed architecture and previous attempts.\n- Compare the proposal and the architectures in the archive CAREFULLY, including their actual differences\nin the implementation.\n- Decide whether the current architecture is innovative.\n- USE CRITICAL THINKING!\n2. **Implementation Mistakes**: Identify any mistakes you may have made in the implementation.\nReview the code carefully, debug any issues you find, and provide a corrected version. REMEMBER\nchecking \"## WRONG Implementation examples\" in the prompt.\n3. **Improvement**: Based on the proposed architecture, suggest improvements in the detailed\nimplementation that could increase its performance or effectiveness. In this step, focus on refining and\noptimizing the existing implementation without altering the overall design framework, except if you\nwant to propose a different architecture if the current is not interesting.\n- Observe carefully about whether the implementation is actually doing what it is supposed to do.\n- Check if there is redundant code or unnecessary steps in the implementation. Replace them with\neffective implementation.\n- Try to avoid the implementation being too similar to the previous agent.\nAnd then, you need to improve or revise the implementation, or implement the new proposed architecture\nbased on the reflection.\nYour response should be organized as follows:\n\"reflection\": Provide your thoughts on the interestingness of the architecture, identify any mistakes in the\nimplementation, and suggest improvements.\n\"thought\": Revise your previous proposal or propose a new architecture if necessary, using the same\nformat as the example response.\n\"name\": Provide a name for the revised or new architecture. (Don\u2019t put words like \"new\" or \"improved\"\nin the name.)\n\"code\": Provide the corrected code or an improved implementation. Make sure you actually implement\nyour fix and improvement in this code.\n25Automated Design of Agentic Systems\nPrompt for self-reflection round 2.\nUsing the tips in \u201c## WRONG Implementation examples\u201d section, further revise the code.\nYour response should be organized as follows:\nInclude your updated reflections in the \u201creflection\u201d. Repeat the previous \u201cthought\u201d and \u201cname\u201d. Update\nthe corrected version of the code in the \u201ccode\u201d section.\nWhen an error is encountered during the execution of the generated code, we conduct a reflection\nand re-run the code. This process is repeated up to five times if errors persist. Here is the prompt we\nuse to self-reflect any runtime error:\nPrompt for self-reflection when a runtime error occurs.\nError during evaluation:\n[Runtimeerrors]\nCarefully consider where you went wrong in your latest implementation. Using insights from previous\nattempts, try to debug the current code to implement the same thought. Repeat your previous thought in\n\u201cthought\u201d, and put your thinking for debugging in \u201cdebug_thought\u201d.\nB. Framework Code\nIn this paper, we provide the meta agent with a simple framework to implement basic functions,\nsuch as querying Foundation Models (FMs) and formatting prompts. The framework consists of\nfewer than 100 lines of code (excluding comments). In this framework, we encapsulate every\npiece of information into a namedtuple Info object, making it easy to combine different types of\ninformation (e.g., FM responses, results from tool function calls, task descriptions) and facilitate\ncommunicationbetweendifferentmodules. Additionally,intheFMmodule,weautomaticallyconstruct\nthe prompt by concatenating all input Info objects into a structured format, with each Info titled by\nits metadata (e.g., name, author). Throughout the appendix, we renamed some variables in the\ncode to match the terminologies used in the main text. The full framework code is available at","chunk_id":"282313a8340c6792e8c35f53ed157cd0","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"META AGENT","type":"AGENT\/TOOL","description":"The meta agent is a system designed to generate and improve agent architectures through iterative self-reflection and debugging processes.","source_id":"282313a8340c6792e8c35f53ed157cd0"},{"name":"PROMPT","type":"INSTRUCTION\/FORMAT","description":"The prompt is used to instruct the meta agent on how to format its output, including sections for thought process, agent name, and code implementation.","source_id":"282313a8340c6792e8c35f53ed157cd0"},{"name":"THOUGHT","type":"SECTION\/KEY","description":"The \"thought\" section captures the meta agent's reasoning, overall concept, and implementation steps for designing the next function or agent.","source_id":"282313a8340c6792e8c35f53ed157cd0"},{"name":"NAME","type":"SECTION\/KEY","description":"The \"name\" section corresponds to the name of the next agent architecture proposed by the meta agent.","source_id":"282313a8340c6792e8c35f53ed157cd0"},{"name":"CODE","type":"SECTION\/KEY","description":"The \"code\" section contains the exact Python code for the \"forward()\" function that the meta agent proposes to implement.","source_id":"282313a8340c6792e8c35f53ed157cd0"},{"name":"SELF-REFLECTION","type":"PROCESS","description":"Self-reflection is a process where the meta agent reviews and improves its proposed architecture and implementation through critical thinking and debugging.","source_id":"282313a8340c6792e8c35f53ed157cd0"},{"name":"IMPLEMENTATION MISTAKES","type":"ISSUE\/ERROR","description":"Implementation mistakes are errors or issues in the code that the meta agent needs to identify and correct during the self-reflection process.","source_id":"282313a8340c6792e8c35f53ed157cd0"},{"name":"IMPROVEMENT","type":"PROCESS","description":"Improvement involves refining and optimizing the existing implementation to increase performance or effectiveness without altering the overall design framework.","source_id":"282313a8340c6792e8c35f53ed157cd0"},{"name":"RUNTIME ERROR","type":"ISSUE\/ERROR","description":"A runtime error is an error encountered during the execution of the generated code, prompting the meta agent to debug and correct the code.","source_id":"282313a8340c6792e8c35f53ed157cd0"},{"name":"FRAMEWORK","type":"SYSTEM\/TOOL","description":"The framework is a simple system provided to the meta agent to implement basic functions, such as querying Foundation Models and formatting prompts.","source_id":"282313a8340c6792e8c35f53ed157cd0"},{"name":"FOUNDATION MODELS (FMS)","type":"MODEL\/TOOL","description":"Foundation Models are models queried by the meta agent within the framework to assist in generating and improving agent architectures.","source_id":"282313a8340c6792e8c35f53ed157cd0"},{"name":"NAMEDTUPLE INFO OBJECT","type":"DATA STRUCTURE","description":"The namedtuple Info object is used in the framework to encapsulate and combine different types of information, facilitating communication between modules.","source_id":"282313a8340c6792e8c35f53ed157cd0"},{"name":"INFO OBJECT","type":"DATA STRUCTURE","description":"The Info object is a namedtuple used to encapsulate various pieces of information, such as FM responses and task descriptions, within the framework.","source_id":"282313a8340c6792e8c35f53ed157cd0","entity_type":"DATA STRUCTURE"},{"name":"APPENDIX B","type":"SECTION\/DOCUMENT","description":"Appendix B contains the framework code used by the meta agent.","source_id":"282313a8340c6792e8c35f53ed157cd0"},{"name":"APPENDICES C AND D","type":"SECTION\/DOCUMENT","description":"Appendices C and D contain additional information relevant to the meta agent's operation and evaluation.","source_id":"282313a8340c6792e8c35f53ed157cd0"},{"name":"OUTPUT INSTRUCTION AND EXAMPLE","type":"SECTION\/DOCUMENT","description":"This section provides instructions and examples for the meta agent's output format, including the \"thought,\" \"name,\" and \"code\" keys.","source_id":"282313a8340c6792e8c35f53ed157cd0"},{"name":"MADAAN ET AL., 2024","type":"REFERENCE\/AUTHOR","description":"Madaan et al. (2024) is a reference cited in the context of self-reflection and improving the generated agent.","source_id":"282313a8340c6792e8c35f53ed157cd0"},{"name":"SHINN ET AL., 2023","type":"REFERENCE\/AUTHOR","description":"Shinn et al. (2023) is a reference cited in the context of self-reflection and improving the generated agent.","source_id":"282313a8340c6792e8c35f53ed157cd0"},{"name":"ARCHIVE","type":"DATASET\/REPOSITORY","description":"The archive contains existing methods and architectures that the meta agent compares its proposed architecture against during self-reflection.","source_id":"282313a8340c6792e8c35f53ed157cd0"},{"name":"WRONG IMPLEMENTATION EXAMPLES","type":"SECTION\/DOCUMENT","description":"This section provides examples of potential mistakes the meta agent may make in implementation, used for self-reflection and debugging.","source_id":"282313a8340c6792e8c35f53ed157cd0"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"META AGENT\">      <data key=\"d0\">AGENT\/TOOL<\/data>      <data key=\"d1\">The meta agent is a system designed to generate and improve agent architectures through iterative self-reflection and debugging processes.<\/data>      <data key=\"d2\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/node>    <node id=\"PROMPT\">      <data key=\"d0\">INSTRUCTION\/FORMAT<\/data>      <data key=\"d1\">The prompt is used to instruct the meta agent on how to format its output, including sections for thought process, agent name, and code implementation.<\/data>      <data key=\"d2\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/node>    <node id=\"THOUGHT\">      <data key=\"d0\">SECTION\/KEY<\/data>      <data key=\"d1\">The \"thought\" section captures the meta agent's reasoning, overall concept, and implementation steps for designing the next function or agent.<\/data>      <data key=\"d2\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/node>    <node id=\"NAME\">      <data key=\"d0\">SECTION\/KEY<\/data>      <data key=\"d1\">The \"name\" section corresponds to the name of the next agent architecture proposed by the meta agent.<\/data>      <data key=\"d2\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/node>    <node id=\"CODE\">      <data key=\"d0\">SECTION\/KEY<\/data>      <data key=\"d1\">The \"code\" section contains the exact Python code for the \"forward()\" function that the meta agent proposes to implement.<\/data>      <data key=\"d2\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/node>    <node id=\"SELF-REFLECTION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Self-reflection is a process where the meta agent reviews and improves its proposed architecture and implementation through critical thinking and debugging.<\/data>      <data key=\"d2\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/node>    <node id=\"IMPLEMENTATION MISTAKES\">      <data key=\"d0\">ISSUE\/ERROR<\/data>      <data key=\"d1\">Implementation mistakes are errors or issues in the code that the meta agent needs to identify and correct during the self-reflection process.<\/data>      <data key=\"d2\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/node>    <node id=\"IMPROVEMENT\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Improvement involves refining and optimizing the existing implementation to increase performance or effectiveness without altering the overall design framework.<\/data>      <data key=\"d2\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/node>    <node id=\"RUNTIME ERROR\">      <data key=\"d0\">ISSUE\/ERROR<\/data>      <data key=\"d1\">A runtime error is an error encountered during the execution of the generated code, prompting the meta agent to debug and correct the code.<\/data>      <data key=\"d2\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/node>    <node id=\"FRAMEWORK\">      <data key=\"d0\">SYSTEM\/TOOL<\/data>      <data key=\"d1\">The framework is a simple system provided to the meta agent to implement basic functions, such as querying Foundation Models and formatting prompts.<\/data>      <data key=\"d2\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/node>    <node id=\"FOUNDATION MODELS (FMS)\">      <data key=\"d0\">MODEL\/TOOL<\/data>      <data key=\"d1\">Foundation Models are models queried by the meta agent within the framework to assist in generating and improving agent architectures.<\/data>      <data key=\"d2\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/node>    <node id=\"NAMEDTUPLE INFO OBJECT\">      <data key=\"d0\">DATA STRUCTURE<\/data>      <data key=\"d1\">The namedtuple Info object is used in the framework to encapsulate and combine different types of information, facilitating communication between modules.<\/data>      <data key=\"d2\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/node>    <node id=\"INFO OBJECT\">      <data key=\"d0\">DATA STRUCTURE<\/data>      <data key=\"d1\">The Info object is a namedtuple used to encapsulate various pieces of information, such as FM responses and task descriptions, within the framework.<\/data>      <data key=\"d2\">282313a8340c6792e8c35f53ed157cd0<\/data>      <data key=\"d3\">DATA STRUCTURE<\/data>    <\/node>    <node id=\"APPENDIX B\">      <data key=\"d0\">SECTION\/DOCUMENT<\/data>      <data key=\"d1\">Appendix B contains the framework code used by the meta agent.<\/data>      <data key=\"d2\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/node>    <node id=\"APPENDICES C AND D\">      <data key=\"d0\">SECTION\/DOCUMENT<\/data>      <data key=\"d1\">Appendices C and D contain additional information relevant to the meta agent's operation and evaluation.<\/data>      <data key=\"d2\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/node>    <node id=\"OUTPUT INSTRUCTION AND EXAMPLE\">      <data key=\"d0\">SECTION\/DOCUMENT<\/data>      <data key=\"d1\">This section provides instructions and examples for the meta agent's output format, including the \"thought,\" \"name,\" and \"code\" keys.<\/data>      <data key=\"d2\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/node>    <node id=\"MADAAN ET AL., 2024\">      <data key=\"d0\">REFERENCE\/AUTHOR<\/data>      <data key=\"d1\">Madaan et al. (2024) is a reference cited in the context of self-reflection and improving the generated agent.<\/data>      <data key=\"d2\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/node>    <node id=\"SHINN ET AL., 2023\">      <data key=\"d0\">REFERENCE\/AUTHOR<\/data>      <data key=\"d1\">Shinn et al. (2023) is a reference cited in the context of self-reflection and improving the generated agent.<\/data>      <data key=\"d2\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/node>    <node id=\"ARCHIVE\">      <data key=\"d0\">DATASET\/REPOSITORY<\/data>      <data key=\"d1\">The archive contains existing methods and architectures that the meta agent compares its proposed architecture against during self-reflection.<\/data>      <data key=\"d2\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/node>    <node id=\"WRONG IMPLEMENTATION EXAMPLES\">      <data key=\"d0\">SECTION\/DOCUMENT<\/data>      <data key=\"d1\">This section provides examples of potential mistakes the meta agent may make in implementation, used for self-reflection and debugging.<\/data>      <data key=\"d2\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/node>    <edge source=\"META AGENT\" target=\"PROMPT\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">The meta agent uses the prompt to format its output, including sections for thought process, agent name, and code implementation.<\/data>      <data key=\"d6\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/edge>    <edge source=\"META AGENT\" target=\"SELF-REFLECTION\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">The meta agent performs self-reflection to review and improve its proposed architecture and implementation.<\/data>      <data key=\"d6\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/edge>    <edge source=\"META AGENT\" target=\"FRAMEWORK\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">The meta agent uses the framework to implement basic functions and format prompts.<\/data>      <data key=\"d6\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/edge>    <edge source=\"META AGENT\" target=\"IMPLEMENTATION MISTAKES\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">The meta agent identifies and corrects implementation mistakes during the self-reflection process.<\/data>      <data key=\"d6\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/edge>    <edge source=\"META AGENT\" target=\"IMPROVEMENT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">The meta agent suggests and implements improvements to increase the performance or effectiveness of the proposed architecture.<\/data>      <data key=\"d6\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/edge>    <edge source=\"META AGENT\" target=\"RUNTIME ERROR\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">The meta agent debugs and corrects the code when a runtime error is encountered during execution.<\/data>      <data key=\"d6\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/edge>    <edge source=\"META AGENT\" target=\"APPENDIX B\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">The meta agent uses the framework code provided in Appendix B.<\/data>      <data key=\"d6\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/edge>    <edge source=\"META AGENT\" target=\"APPENDICES C AND D\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">The meta agent references information available in Appendices C and D.<\/data>      <data key=\"d6\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/edge>    <edge source=\"META AGENT\" target=\"OUTPUT INSTRUCTION AND EXAMPLE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">The meta agent follows the output instructions and examples provided in this section.<\/data>      <data key=\"d6\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/edge>    <edge source=\"META AGENT\" target=\"MADAAN ET AL., 2024\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">The meta agent's self-reflection process is influenced by the work of Madaan et al. (2024).<\/data>      <data key=\"d6\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/edge>    <edge source=\"META AGENT\" target=\"SHINN ET AL., 2023\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">The meta agent's self-reflection process is influenced by the work of Shinn et al. (2023).<\/data>      <data key=\"d6\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/edge>    <edge source=\"META AGENT\" target=\"ARCHIVE\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">The meta agent compares its proposed architecture against existing methods in the archive during self-reflection.<\/data>      <data key=\"d6\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/edge>    <edge source=\"META AGENT\" target=\"WRONG IMPLEMENTATION EXAMPLES\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">The meta agent uses the \"WRONG Implementation examples\" section to identify and correct mistakes during self-reflection.<\/data>      <data key=\"d6\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/edge>    <edge source=\"META AGENT\" target=\"INFO OBJECT\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">The meta agent uses Info objects to encapsulate and combine different types of information within the framework.<\/data>      <data key=\"d6\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/edge>    <edge source=\"FRAMEWORK\" target=\"FOUNDATION MODELS (FMS)\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">The framework includes querying Foundation Models to assist the meta agent in generating and improving agent architectures.<\/data>      <data key=\"d6\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/edge>    <edge source=\"FRAMEWORK\" target=\"NAMEDTUPLE INFO OBJECT\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">The framework uses the namedtuple Info object to encapsulate and combine different types of information.<\/data>      <data key=\"d6\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/edge>    <edge source=\"FOUNDATION MODELS (FMS)\" target=\"INFO OBJECT\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">Foundation Models' responses are encapsulated in Info objects within the framework.<\/data>      <data key=\"d6\">282313a8340c6792e8c35f53ed157cd0<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"d66dc9ce4a9545b44f7486ea057b5937","chunk":"\ninformation (e.g., FM responses, results from tool function calls, task descriptions) and facilitate\ncommunicationbetweendifferentmodules. Additionally,intheFMmodule,weautomaticallyconstruct\nthe prompt by concatenating all input Info objects into a structured format, with each Info titled by\nits metadata (e.g., name, author). Throughout the appendix, we renamed some variables in the\ncode to match the terminologies used in the main text. The full framework code is available at\nhttps:\/\/github.com\/ShengranHu\/ADAS .\nCode 1|The simple framework used in Meta-Agent Search.\n1# Named tuple for holding task information\n2Info = namedtuple (\u2019Info \u2019, [\u2019name \u2019, \u2019author \u2019, \u2019content \u2019, \u2019\niteration_idx \u2019])\n3\n4# Format instructions for FM response\n5FORMAT_INST = lambda request_keys : f\" Reply EXACTLY with the\nfollowing JSON format .\\n{str( request_keys )}\\ nDO NOT MISS ANY\nFIELDS AND MAKE SURE THE JSON FORMAT IS CORRECT !\\n\"\n6\n7# Description of the role of the FM Module\n8ROLE_DESC = lambda role : f\"You are a { role }.\"\n9\n10@backoff . on_exception ( backoff .expo , openai . RateLimitError )\n11def get_json_response_from_gpt (msg , model , system_message ,\ntemperature ):\n12 \\\"\"\"\n13 Function to get JSON response from GPT model .\n14\n15 Args :\n16 - msg (str ): The user message .\n26Automated Design of Agentic Systems\n17 - model (str ): The model to use .\n18 - system_message (str ): The system message .\n19 - temperature ( float ): Sampling temperature .\n20\n21 Returns :\n22 - dict : The JSON response .\n23 \\\"\"\"\n24 ...\n25 return json_dict\n26\n27class FM_Module :\n28 \\\"\"\"\n29 Base class for an FM module .\n30\n31 Attributes :\n32 - output_fields ( list ): Fields expected in the output .\n33 - name (str ): Name of the FM module .\n34 - role (str ): Role description for the FM module .\n35 - model (str ): Model to be used .\n36 - temperature ( float ): Sampling temperature .\n37 - id (str ): Unique identifier for the FM module instance .\n38 \\\"\"\"\n39\n40 def __init__ (self , output_fields : list , name : str , role =\u2019helpful\nassistant \u2019, model =\u2019gpt -3.5 - turbo -0125 \u2019, temperature =0.5) ->\nNone :\n41 ...\n42\n43 def generate_prompt (self , input_infos , instruction ) -> str:\n44 \\\"\"\"\n45 Generates a prompt for the FM.\n46\n47 Args :\n48 - input_infos ( list ): List of input information .\n49 - instruction (str ): Instruction for the task .\n50\n51 Returns :\n52 - tuple : System prompt and user prompt .\n53\n54 An example of generated prompt :\n55 \"\"\n56 You are a helpful assistant .\n57\n58 # Output Format :\n59 Reply EXACTLY with the following JSON format .\n60 ...\n61\n62 # Your Task :\n63 You will given some number of paired example inputs and\noutputs . The outputs ...\n64\n65 ### thinking #1 by Chain -of - Thought hkFo ( yourself ):\n66 ...\n67\n68 # Instruction :\n69 Please think step by step and then solve the task by writing\n27Automated Design of Agentic Systems\nthe code .\n70 \"\"\n71 \\\"\"\"\n72 ...\n73 return system_prompt , prompt\n74\n75 def query (self , input_infos : list , instruction , iteration_idx\n= -1) -> list [ Info ]:\n76 \\\"\"\"\n77 Queries the FM with provided input information and\ninstruction .\n78\n79 Args :\n80 - input_infos ( list ): List of input information .\n81 - instruction (str ): Instruction for the task .\n82 - iteration_idx (int ): Iteration index for the task .\n83\n84 Returns :\n85 - output_infos ( list [ Info ]): Output information .\n86 \\\"\"\"\n87 ...\n88 return output_infos\n89\n90 def __repr__ ( self ):\n91 return f\"{ self . agent_name } { self .id}\"\n92\n93 def __call__ (self , input_infos : list , instruction , iteration_idx\n= -1):\n94 return self . query ( input_infos , instruction , iteration_idx =\niteration_idx )\n95\n96class AgentSystem :\n97 def forward (self , taskInfo ) -> Union [Info , str ]:\n98 \\\"\"\"\n99 Placeholder method for processing task information .\n100\n101 Args :\n102 - taskInfo ( Info ): Task information .\n103\n104 Returns :\n105 - Answer ( Union [Info , str ]): Your FINAL Answer . Return\neither a namedtuple Info or a string for the answer .\n106 \\\"\"\"\n107 pass\nWith the provided framework, an agent can be easily defined with a \u201cforward\u201d function. Here we\nshow an example of implementing self-reflection using the framework.\nCode 2|Self-Reflection implementation example\n1def forward (self , taskInfo ):\n2 # Instruction for initial reasoning\n3 cot_initial_instruction = \" Please think step by step and then\nsolve the task .\"\n4\n5 # Instruction for reflecting on previous attempts and feedback\n28Automated Design of Agentic Systems\nto improve\n6 cot_reflect_instruction = \" Given previous attempts and feedback ,\ncarefully consider where you could go wrong in your latest\nattempt . Using insights from previous attempts , try to solve\nthe task better .\"\n7 cot_module = FM_Module ([ \u2019thinking \u2019, \u2019answer \u2019], \u2019Chain -of - Thought\n\u2019)\n8\n9 # Instruction for providing feedback and correcting the answer\n10 critic_instruction = \" Please review the answer above and\ncriticize","chunk_id":"d66dc9ce4a9545b44f7486ea057b5937","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"FM MODULE","type":"TOOL\/COMPONENT","description":"A module that constructs prompts by concatenating input Info objects into a structured format and generates responses using a specified model","source_id":"d66dc9ce4a9545b44f7486ea057b5937"},{"name":"INFO","type":"DATA STRUCTURE","description":"A named tuple used for holding task information, including name, author, content, and iteration index","source_id":"d66dc9ce4a9545b44f7486ea057b5937"},{"name":"FORMAT_INST","type":"FUNCTION","description":"A lambda function that formats instructions for FM responses in a specific JSON format","source_id":"d66dc9ce4a9545b44f7486ea057b5937"},{"name":"ROLE_DESC","type":"FUNCTION","description":"A lambda function that describes the role of the FM Module","source_id":"d66dc9ce4a9545b44f7486ea057b5937"},{"name":"GET_JSON_RESPONSE_FROM_GPT","type":"FUNCTION","description":"A function to get JSON responses from a GPT model, handling rate limit errors using backoff","source_id":"d66dc9ce4a9545b44f7486ea057b5937"},{"name":"FM_MODULE","type":"CLASS","description":"A base class for an FM module, containing attributes like output fields, name, role, model, temperature, and ID","source_id":"d66dc9ce4a9545b44f7486ea057b5937"},{"name":"AGENT SYSTEM","type":"SYSTEM","description":"A system that processes task information and returns either a namedtuple Info or a string as the final answer","source_id":"d66dc9ce4a9545b44f7486ea057b5937"},{"name":"SELF-REFLECTION","type":"PROCESS","description":"A process implemented using the framework to improve task-solving by reflecting on previous attempts and feedback","source_id":"d66dc9ce4a9545b44f7486ea057b5937"},{"name":"SHENGRAN HU","type":"PERSON","description":"The author or maintainer of the framework code available on GitHub","source_id":"d66dc9ce4a9545b44f7486ea057b5937"},{"name":"GITHUB","type":"PLATFORM","description":"The platform where the full framework code is available","source_id":"d66dc9ce4a9545b44f7486ea057b5937"},{"name":"META-AGENT SEARCH","type":"SYSTEM","description":"A system that uses a simple framework for agentic tasks, including modules like FM_Module","source_id":"d66dc9ce4a9545b44f7486ea057b5937"},{"name":"CODE 1","type":"CODE SNIPPET","description":"A code snippet showing the simple framework used in Meta-Agent Search","source_id":"d66dc9ce4a9545b44f7486ea057b5937"},{"name":"CODE 2","type":"CODE SNIPPET","description":"A code snippet showing an example of implementing self-reflection using the framework","source_id":"d66dc9ce4a9545b44f7486ea057b5937"},{"name":"TASK DESCRIPTIONS","type":"DATA STRUCTURE","description":"Descriptions of tasks that are used to facilitate communication between different modules","source_id":"d66dc9ce4a9545b44f7486ea057b5937"},{"name":"FM RESPONSES","type":"DATA STRUCTURE","description":"Responses generated by the FM Module based on the constructed prompts","source_id":"d66dc9ce4a9545b44f7486ea057b5937"},{"name":"RESULTS FROM TOOL FUNCTION CALLS","type":"DATA STRUCTURE","description":"Results obtained from calling functions within the tool","source_id":"d66dc9ce4a9545b44f7486ea057b5937"},{"name":"PROMPT","type":"DATA STRUCTURE","description":"A structured format generated by the FM Module by concatenating input Info objects","source_id":"d66dc9ce4a9545b44f7486ea057b5937"},{"name":"SYSTEM PROMPT","type":"DATA STRUCTURE","description":"Part of the prompt generated by the FM Module, providing system-level instructions","source_id":"d66dc9ce4a9545b44f7486ea057b5937"},{"name":"USER PROMPT","type":"DATA STRUCTURE","description":"Part of the prompt generated by the FM Module, providing user-level instructions","source_id":"d66dc9ce4a9545b44f7486ea057b5937"},{"name":"COT_INITIAL_INSTRUCTION","type":"DATA STRUCTURE","description":"Instruction for initial reasoning in the self-reflection process","source_id":"d66dc9ce4a9545b44f7486ea057b5937"},{"name":"COT_REFLECT_INSTRUCTION","type":"DATA STRUCTURE","description":"Instruction for reflecting on previous attempts and feedback to improve task-solving","source_id":"d66dc9ce4a9545b44f7486ea057b5937"},{"name":"CRITIC_INSTRUCTION","type":"DATA STRUCTURE","description":"Instruction for providing feedback and correcting the answer","source_id":"d66dc9ce4a9545b44f7486ea057b5937"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"FM MODULE\">      <data key=\"d0\">TOOL\/COMPONENT<\/data>      <data key=\"d1\">A module that constructs prompts by concatenating input Info objects into a structured format and generates responses using a specified model<\/data>      <data key=\"d2\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/node>    <node id=\"INFO\">      <data key=\"d0\">DATA STRUCTURE<\/data>      <data key=\"d1\">A named tuple used for holding task information, including name, author, content, and iteration index<\/data>      <data key=\"d2\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/node>    <node id=\"FORMAT_INST\">      <data key=\"d0\">FUNCTION<\/data>      <data key=\"d1\">A lambda function that formats instructions for FM responses in a specific JSON format<\/data>      <data key=\"d2\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/node>    <node id=\"ROLE_DESC\">      <data key=\"d0\">FUNCTION<\/data>      <data key=\"d1\">A lambda function that describes the role of the FM Module<\/data>      <data key=\"d2\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/node>    <node id=\"GET_JSON_RESPONSE_FROM_GPT\">      <data key=\"d0\">FUNCTION<\/data>      <data key=\"d1\">A function to get JSON responses from a GPT model, handling rate limit errors using backoff<\/data>      <data key=\"d2\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/node>    <node id=\"FM_MODULE\">      <data key=\"d0\">CLASS<\/data>      <data key=\"d1\">A base class for an FM module, containing attributes like output fields, name, role, model, temperature, and ID<\/data>      <data key=\"d2\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/node>    <node id=\"AGENT SYSTEM\">      <data key=\"d0\">SYSTEM<\/data>      <data key=\"d1\">A system that processes task information and returns either a namedtuple Info or a string as the final answer<\/data>      <data key=\"d2\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/node>    <node id=\"SELF-REFLECTION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">A process implemented using the framework to improve task-solving by reflecting on previous attempts and feedback<\/data>      <data key=\"d2\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/node>    <node id=\"SHENGRAN HU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">The author or maintainer of the framework code available on GitHub<\/data>      <data key=\"d2\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/node>    <node id=\"GITHUB\">      <data key=\"d0\">PLATFORM<\/data>      <data key=\"d1\">The platform where the full framework code is available<\/data>      <data key=\"d2\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/node>    <node id=\"META-AGENT SEARCH\">      <data key=\"d0\">SYSTEM<\/data>      <data key=\"d1\">A system that uses a simple framework for agentic tasks, including modules like FM_Module<\/data>      <data key=\"d2\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/node>    <node id=\"CODE 1\">      <data key=\"d0\">CODE SNIPPET<\/data>      <data key=\"d1\">A code snippet showing the simple framework used in Meta-Agent Search<\/data>      <data key=\"d2\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/node>    <node id=\"CODE 2\">      <data key=\"d0\">CODE SNIPPET<\/data>      <data key=\"d1\">A code snippet showing an example of implementing self-reflection using the framework<\/data>      <data key=\"d2\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/node>    <node id=\"TASK DESCRIPTIONS\">      <data key=\"d0\">DATA STRUCTURE<\/data>      <data key=\"d1\">Descriptions of tasks that are used to facilitate communication between different modules<\/data>      <data key=\"d2\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/node>    <node id=\"FM RESPONSES\">      <data key=\"d0\">DATA STRUCTURE<\/data>      <data key=\"d1\">Responses generated by the FM Module based on the constructed prompts<\/data>      <data key=\"d2\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/node>    <node id=\"RESULTS FROM TOOL FUNCTION CALLS\">      <data key=\"d0\">DATA STRUCTURE<\/data>      <data key=\"d1\">Results obtained from calling functions within the tool<\/data>      <data key=\"d2\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/node>    <node id=\"PROMPT\">      <data key=\"d0\">DATA STRUCTURE<\/data>      <data key=\"d1\">A structured format generated by the FM Module by concatenating input Info objects<\/data>      <data key=\"d2\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/node>    <node id=\"SYSTEM PROMPT\">      <data key=\"d0\">DATA STRUCTURE<\/data>      <data key=\"d1\">Part of the prompt generated by the FM Module, providing system-level instructions<\/data>      <data key=\"d2\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/node>    <node id=\"USER PROMPT\">      <data key=\"d0\">DATA STRUCTURE<\/data>      <data key=\"d1\">Part of the prompt generated by the FM Module, providing user-level instructions<\/data>      <data key=\"d2\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/node>    <node id=\"COT_INITIAL_INSTRUCTION\">      <data key=\"d0\">DATA STRUCTURE<\/data>      <data key=\"d1\">Instruction for initial reasoning in the self-reflection process<\/data>      <data key=\"d2\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/node>    <node id=\"COT_REFLECT_INSTRUCTION\">      <data key=\"d0\">DATA STRUCTURE<\/data>      <data key=\"d1\">Instruction for reflecting on previous attempts and feedback to improve task-solving<\/data>      <data key=\"d2\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/node>    <node id=\"CRITIC_INSTRUCTION\">      <data key=\"d0\">DATA STRUCTURE<\/data>      <data key=\"d1\">Instruction for providing feedback and correcting the answer<\/data>      <data key=\"d2\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/node>    <edge source=\"FM MODULE\" target=\"INFO\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The FM Module constructs prompts by concatenating input Info objects<\/data>      <data key=\"d5\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/edge>    <edge source=\"FM MODULE\" target=\"FORMAT_INST\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The FM Module uses FORMAT_INST to format instructions for FM responses<\/data>      <data key=\"d5\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/edge>    <edge source=\"FM MODULE\" target=\"ROLE_DESC\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The FM Module uses ROLE_DESC to describe its role<\/data>      <data key=\"d5\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/edge>    <edge source=\"FM MODULE\" target=\"GET_JSON_RESPONSE_FROM_GPT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The FM Module uses the function GET_JSON_RESPONSE_FROM_GPT to get JSON responses from a GPT model<\/data>      <data key=\"d5\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/edge>    <edge source=\"FM MODULE\" target=\"SELF-REFLECTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The FM Module is used in the self-reflection process to improve task-solving<\/data>      <data key=\"d5\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/edge>    <edge source=\"FM MODULE\" target=\"AGENT SYSTEM\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The Agent System can use the FM Module to process task information<\/data>      <data key=\"d5\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/edge>    <edge source=\"FM MODULE\" target=\"META-AGENT SEARCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The FM Module is part of the Meta-Agent Search system<\/data>      <data key=\"d5\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/edge>    <edge source=\"FM MODULE\" target=\"PROMPT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The FM Module generates a prompt by concatenating input Info objects<\/data>      <data key=\"d5\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/edge>    <edge source=\"FM MODULE\" target=\"FM RESPONSES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The FM Module generates FM responses based on the constructed prompts<\/data>      <data key=\"d5\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/edge>    <edge source=\"FM MODULE\" target=\"RESULTS FROM TOOL FUNCTION CALLS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The FM Module may use results from tool function calls in its operations<\/data>      <data key=\"d5\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/edge>    <edge source=\"FM MODULE\" target=\"TASK DESCRIPTIONS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The FM Module uses task descriptions to facilitate communication between different modules<\/data>      <data key=\"d5\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/edge>    <edge source=\"SELF-REFLECTION\" target=\"COT_INITIAL_INSTRUCTION\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Self-reflection uses the COT_INITIAL_INSTRUCTION for initial reasoning<\/data>      <data key=\"d5\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/edge>    <edge source=\"SELF-REFLECTION\" target=\"COT_REFLECT_INSTRUCTION\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Self-reflection uses the COT_REFLECT_INSTRUCTION for reflecting on previous attempts and feedback<\/data>      <data key=\"d5\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/edge>    <edge source=\"SELF-REFLECTION\" target=\"CRITIC_INSTRUCTION\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Self-reflection uses the CRITIC_INSTRUCTION for providing feedback and correcting the answer<\/data>      <data key=\"d5\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/edge>    <edge source=\"SHENGRAN HU\" target=\"GITHUB\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Shengran Hu has made the framework code available on GitHub<\/data>      <data key=\"d5\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/edge>    <edge source=\"META-AGENT SEARCH\" target=\"CODE 1\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Code 1 shows the simple framework used in Meta-Agent Search<\/data>      <data key=\"d5\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/edge>    <edge source=\"META-AGENT SEARCH\" target=\"CODE 2\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Code 2 shows an example of implementing self-reflection using the framework<\/data>      <data key=\"d5\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/edge>    <edge source=\"PROMPT\" target=\"SYSTEM PROMPT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The prompt generated by the FM Module includes a system prompt<\/data>      <data key=\"d5\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/edge>    <edge source=\"PROMPT\" target=\"USER PROMPT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The prompt generated by the FM Module includes a user prompt<\/data>      <data key=\"d5\">d66dc9ce4a9545b44f7486ea057b5937<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"4b43decac6833d1515992f8869ecada7","chunk":"entic Systems\nto improve\n6 cot_reflect_instruction = \" Given previous attempts and feedback ,\ncarefully consider where you could go wrong in your latest\nattempt . Using insights from previous attempts , try to solve\nthe task better .\"\n7 cot_module = FM_Module ([ \u2019thinking \u2019, \u2019answer \u2019], \u2019Chain -of - Thought\n\u2019)\n8\n9 # Instruction for providing feedback and correcting the answer\n10 critic_instruction = \" Please review the answer above and\ncriticize on where might be wrong . If you are absolutely sure\nit is correct , output \u2019True \u2019 in \u2019correct \u2019.\"\n11 critic_module = FM_Module ([ \u2019feedback \u2019, \u2019correct \u2019], \u2019Critic \u2019)\n12\n13 N_max = 5 # Maximum number of attempts\n14\n15 # Initial attempt\n16 cot_inputs = [ taskInfo ]\n17 thinking , answer = cot_module ( cot_inputs ,\ncot_initial_instruction , 0)\n18\n19 for i in range ( N_max ):\n20 # Get feedback and correct status from the critic\n21 feedback , correct = critic_module ([ taskInfo , thinking ,\nanswer ], critic_instruction , i)\n22 if correct . content == \u2019True \u2019:\n23 break\n24\n25 # Add feedback to the inputs for the next iteration\n26 cot_inputs . extend ([ thinking , answer , feedback ])\n27\n28 # Reflect on previous attemps and refine the answer\n29 thinking , answer = cot_module ( cot_inputs ,\ncot_reflect_instruction , i + 1)\n30 return answer\n29Automated Design of Agentic Systems\nExample Input -output grid #1\nExample Input -output grid #2\nTest grid\nAnswer\nFigure 4|An example task from the ARC challenge (Chollet, 2019). Given the input-output grid\nexamples, the AI system is asked to learn the transformation rules and then apply these learned rules\nto the test grid to predict the final answer.\nC. Experiment Details for ARC Challenge\nAn example task from the ARC challenge is shown in Figure 4. In the ARC challenge experiments\n(Section 4.1), we represent the grids as strings of 2-D arrays, where each color is represented by an\ninteger. Weinstructthemetaagenttodesignagentsthatgeneratecodeassolutionsratherthandirectly\noutputting answers. Additionally, we provide two tool functions within the framework: (1) to test\nwhetherthegeneratedcodecansolvetheexamplegridsand(2)toobtainthetask\u2019sanswerbyapplying\nthe generated code to the test grid. The accuracy rate is calculated by the Exact Match between the\nreference solution and the predicted answer. The meta agent uses \u201cgpt-4o-2024-05-13\u201d (OpenAI,\n2024), while discovered agents and baselines are evaluated using \u201cgpt-3.5-turbo-0125\u201d (OpenAI,\n2022) to reduce compute cost.\nThe domain description of ARC for the meta agent is shown below:\nDescription of ARC for the meta agent.\nYour aim is to find an optimal agent performing well on the ARC (Abstraction and Reasoning Corpus)\nchallenge.\nIn this challenge, each task consists of three demonstration examples, and one test example. Each\nExample consists of an \u201cinput grid\u201d and an \u201coutput grid\u201d. Test-takers need to use the transformation rule\nlearned from the examples to predict the output grid for the test example.\n30Automated Design of Agentic Systems\n# An example task from ARC challenge:\n## Task Overview:\nYou will be given some number of paired example inputs and outputs grids. The outputs were produced\nby applying a transformation rule to the input grids. In addition to the paired example inputs and\noutputs, there is also one test input without a known output.\nThe inputs and outputs are each \u201cgrids\u201d. A grid is a rectangular matrix of integers between 0 and 9\n(inclusive). Each number corresponds to a color. 0 is black.\nYour task is to determine the transformation rule from examples and find out the answer, involving\ndetermining the size of the output grid for the test and correctly filling each cell of the grid with the\nappropriate color or number.\nThe transformation only needs to be unambiguous and applicable to the example inputs and the test\ninput. It doesn\u2019t need to work for all possible inputs. Observe the examples carefully, imagine the grid\nvisually, and try to find the pattern.\n## Examples:\n### Example 0:\ninput = [[0,0,0,0,5,0,0,0,0], [0,0,0,0,5,0,0,0,0], [0,0,0,4,5,0,0,0,0], [0,0,0,4,5,4,4,0,0],\n[0,0,3,3,5,0,0,0,0], [0,0,0,3,5,0,0,0,0], [0,0,0,3,5,3,3,3,0], [0,0,0,3,5,0,0,0,0], [0,0,0,0,5,0,0,0,0],\n[0,0,0,0,5,0,0,0,0]]\noutput = [[0,0,0,0], [0,0,0,0], [0,0,0,4], [0,0,4,4], [0,0,3,3], [0,0,0,3], [0,3,3,3], [0,0,0,3], [0,0","chunk_id":"4b43decac6833d1515992f8869ecada7","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"COT_REFLECT_INSTRUCTION","type":"INSTRUCTION","description":"An instruction to reflect on previous attempts and feedback to improve the task solution","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"COT_MODULE","type":"TOOL\/MODULE","description":"A module named FM_Module used for 'Chain-of-Thought' processing, involving thinking and answering","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"CRITIC_INSTRUCTION","type":"INSTRUCTION","description":"An instruction to review and criticize the answer, or confirm its correctness","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"CRITIC_MODULE","type":"TOOL\/MODULE","description":"A module named FM_Module used for providing feedback and correcting answers","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"N_MAX","type":"PARAMETER","description":"The maximum number of attempts allowed, set to 5","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"TASKINFO","type":"DATA","description":"The initial input data for the task","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"THINKING","type":"PROCESS","description":"The process of thinking involved in solving the task","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"ANSWER","type":"RESULT","description":"The answer generated by the cot_module","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"FEEDBACK","type":"DATA","description":"The feedback provided by the critic_module","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"ARC CHALLENGE","type":"CHALLENGE","description":"A challenge involving learning transformation rules from input-output grid examples to predict the output grid for a test example","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"META AGENT","type":"AGENT","description":"An agent designed to generate code solutions for the ARC challenge tasks","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"GPT-4O-2024-05-13","type":"MODEL","description":"A version of OpenAI's language model used by the meta agent","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"GPT-3.5-TURBO-0125","type":"MODEL","description":"A version of OpenAI's language model used to evaluate discovered agents and baselines","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"EXACT MATCH","type":"METRIC","description":"A metric used to calculate the accuracy rate by comparing the reference solution and the predicted answer","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"INPUT GRID","type":"DATA","description":"A rectangular matrix of integers representing colors, used as input in the ARC challenge","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"OUTPUT GRID","type":"DATA","description":"A rectangular matrix of integers representing colors, used as output in the ARC challenge","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"COT_INITIAL_INSTRUCTION","type":"INSTRUCTION","description":"An initial instruction used by the cot_module to start the task-solving process","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"EXPERIMENT DETAILS","type":"SECTION","description":"Details about the experiments conducted for the ARC challenge","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"TRANSFORMATION RULE","type":"CONCEPT","description":"A rule learned from input-output grid examples to predict the output grid for a test example","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"DEMONSTRATION EXAMPLES","type":"DATA","description":"Examples provided in the ARC challenge to demonstrate the transformation rule","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"TEST EXAMPLE","type":"DATA","description":"An example in the ARC challenge where the output grid needs to be predicted","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"EXAMPLE 0","type":"DATA","description":"An example task from the ARC challenge involving specific input and output grids","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"ARC","type":"CHALLENGE","description":"Abstraction and Reasoning Corpus, a challenge involving learning transformation rules from input-output grid examples","source_id":"4b43decac6833d1515992f8869ecada7"},{"name":"OPENAI","type":"ORGANIZATION","description":"The organization behind the GPT-4o-2024-05-13 and GPT-3.5-turbo-0125 models","source_id":"4b43decac6833d1515992f8869ecada7"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"COT_REFLECT_INSTRUCTION\">      <data key=\"d0\">INSTRUCTION<\/data>      <data key=\"d1\">An instruction to reflect on previous attempts and feedback to improve the task solution<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"COT_MODULE\">      <data key=\"d0\">TOOL\/MODULE<\/data>      <data key=\"d1\">A module named FM_Module used for 'Chain-of-Thought' processing, involving thinking and answering<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"CRITIC_INSTRUCTION\">      <data key=\"d0\">INSTRUCTION<\/data>      <data key=\"d1\">An instruction to review and criticize the answer, or confirm its correctness<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"CRITIC_MODULE\">      <data key=\"d0\">TOOL\/MODULE<\/data>      <data key=\"d1\">A module named FM_Module used for providing feedback and correcting answers<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"N_MAX\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">The maximum number of attempts allowed, set to 5<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"TASKINFO\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">The initial input data for the task<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"THINKING\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The process of thinking involved in solving the task<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"ANSWER\">      <data key=\"d0\">RESULT<\/data>      <data key=\"d1\">The answer generated by the cot_module<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"FEEDBACK\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">The feedback provided by the critic_module<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"ARC CHALLENGE\">      <data key=\"d0\">CHALLENGE<\/data>      <data key=\"d1\">A challenge involving learning transformation rules from input-output grid examples to predict the output grid for a test example<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"META AGENT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">An agent designed to generate code solutions for the ARC challenge tasks<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"GPT-4O-2024-05-13\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">A version of OpenAI's language model used by the meta agent<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"GPT-3.5-TURBO-0125\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">A version of OpenAI's language model used to evaluate discovered agents and baselines<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"EXACT MATCH\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">A metric used to calculate the accuracy rate by comparing the reference solution and the predicted answer<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"INPUT GRID\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">A rectangular matrix of integers representing colors, used as input in the ARC challenge<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"OUTPUT GRID\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">A rectangular matrix of integers representing colors, used as output in the ARC challenge<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"COT_INITIAL_INSTRUCTION\">      <data key=\"d0\">INSTRUCTION<\/data>      <data key=\"d1\">An initial instruction used by the cot_module to start the task-solving process<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"EXPERIMENT DETAILS\">      <data key=\"d0\">SECTION<\/data>      <data key=\"d1\">Details about the experiments conducted for the ARC challenge<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"TRANSFORMATION RULE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A rule learned from input-output grid examples to predict the output grid for a test example<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"DEMONSTRATION EXAMPLES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Examples provided in the ARC challenge to demonstrate the transformation rule<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"TEST EXAMPLE\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">An example in the ARC challenge where the output grid needs to be predicted<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"EXAMPLE 0\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">An example task from the ARC challenge involving specific input and output grids<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"ARC\">      <data key=\"d0\">CHALLENGE<\/data>      <data key=\"d1\">Abstraction and Reasoning Corpus, a challenge involving learning transformation rules from input-output grid examples<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <node id=\"OPENAI\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">The organization behind the GPT-4o-2024-05-13 and GPT-3.5-turbo-0125 models<\/data>      <data key=\"d2\">4b43decac6833d1515992f8869ecada7<\/data>    <\/node>    <edge source=\"COT_REFLECT_INSTRUCTION\" target=\"COT_MODULE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The cot_module uses the cot_reflect_instruction to refine the answer<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"COT_MODULE\" target=\"TASKINFO\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The cot_module uses taskInfo as initial input<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"COT_MODULE\" target=\"THINKING\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The cot_module generates the thinking process<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"COT_MODULE\" target=\"ANSWER\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The cot_module generates the answer<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"COT_MODULE\" target=\"COT_INITIAL_INSTRUCTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The cot_module uses the cot_initial_instruction to start the task-solving process<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"CRITIC_INSTRUCTION\" target=\"CRITIC_MODULE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The critic_module uses the critic_instruction to review and correct the answer<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"CRITIC_MODULE\" target=\"TASKINFO\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The critic_module uses taskInfo as input<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"CRITIC_MODULE\" target=\"THINKING\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The critic_module reviews the thinking process<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"CRITIC_MODULE\" target=\"ANSWER\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The critic_module reviews the answer<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"CRITIC_MODULE\" target=\"FEEDBACK\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The critic_module provides feedback<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"ARC CHALLENGE\" target=\"META AGENT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The meta agent is designed to perform well on the ARC challenge<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"ARC CHALLENGE\" target=\"INPUT GRID\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The ARC challenge involves input grids<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"ARC CHALLENGE\" target=\"OUTPUT GRID\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The ARC challenge involves output grids<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"ARC CHALLENGE\" target=\"EXACT MATCH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The accuracy rate in the ARC challenge is calculated using the Exact Match metric<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"ARC CHALLENGE\" target=\"EXPERIMENT DETAILS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The experiment details section provides information about the ARC challenge<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"ARC CHALLENGE\" target=\"TRANSFORMATION RULE\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The ARC challenge involves learning a transformation rule from examples<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"ARC CHALLENGE\" target=\"DEMONSTRATION EXAMPLES\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The ARC challenge provides demonstration examples to illustrate the transformation rule<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"ARC CHALLENGE\" target=\"TEST EXAMPLE\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The ARC challenge includes a test example where the output grid needs to be predicted<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"ARC CHALLENGE\" target=\"EXAMPLE 0\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Example 0 is a specific task from the ARC challenge<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"META AGENT\" target=\"GPT-4O-2024-05-13\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The meta agent uses GPT-4o-2024-05-13<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"META AGENT\" target=\"GPT-3.5-TURBO-0125\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Discovered agents and baselines are evaluated using GPT-3.5-turbo-0125<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"META AGENT\" target=\"ARC\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The meta agent is designed to perform well on the ARC challenge<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"GPT-4O-2024-05-13\" target=\"OPENAI\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">GPT-4o-2024-05-13 is a model developed by OpenAI<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>    <edge source=\"GPT-3.5-TURBO-0125\" target=\"OPENAI\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">GPT-3.5-turbo-0125 is a model developed by OpenAI<\/data>      <data key=\"d5\">4b43decac6833d1515992f8869ecada7<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"449db721e37968e073e3579b59e023b2","chunk":",0],\n[0,0,0,0,5,0,0,0,0]]\noutput = [[0,0,0,0], [0,0,0,0], [0,0,0,4], [0,0,4,4], [0,0,3,3], [0,0,0,3], [0,3,3,3], [0,0,0,3], [0,0,0,0],\n[0,0,0,0]]\n### Example 1:\ninput = [[0,0,0,0,5,0,0,0,0], [0,0,0,2,5,0,0,0,0], [0,0,0,2,5,2,6,0,0], [0,0,0,2,5,0,0,0,0],\n[0,0,0,2,5,2,2,2,0], [0,0,6,6,5,6,0,0,0], [0,0,0,2,5,0,0,0,0], [0,2,2,0,5,2,0,0,0], [0,0,0,2,5,0,0,0,0],\n[0,0,0,0,5,0,0,0,0]]\noutput = [[0,0,0,0], [0,0,0,2], [0,0,6,2], [0,0,0,2], [0,2,2,2], [0,0,6,6], [0,0,0,2], [0,2,2,2], [0,0,0,2],\n[0,0,0,0]]\n### Example 2:\ninput = [[0,0,0,0,5,0,0,0,0], [0,0,0,0,5,7,0,0,0], [0,0,0,8,5,0,0,0,0], [0,0,0,8,5,0,0,0,0],\n[0,7,8,8,5,0,0,0,0], [0,0,0,0,5,8,8,0,0], [0,0,0,8,5,0,0,0,0], [0,0,0,8,5,0,0,0,0], [0,0,0,0,5,8,7,0,0],\n[0,0,0,0,5,0,0,0,0]]\noutput= [[0,0,0,0], [0,0,0,7], [0,0,0,8], [0,0,0,8], [0,7,8,8], [0,0,8,8], [0,0,0,8], [0,0,0,8], [0,0,7,8],\n[0,0,0,0]]\n### Test Problem:\ninput = [[0,0,0,0,5,0,0,0,0], [0,0,0,1,5,0,0,0,0], [0,0,0,1,5,1,0,0,0], [0,1,1,1,5,1,1,1,6],\n[0,0,0,6,5,6,6,0,0], [0,0,0,0,5,1,1,1,0], [0,0,0,1,5,0,0,0,0], [0,0,0,1,5,1,6,0,0], [0,0,0,0,5,6,0,0,0],\n[0,0,0,0,5,0,0,0,0]]\nAnalyze the transformation rules based on the provided Examples and determine what the output should\nbe for the Test Problem.\nHere we present the best agent on ARC discovered by Meta Agent Search. All agents from the\nexperiment can be found at https:\/\/github.com\/ShengranHu\/ADAS .\nCode 3|The best agent on ARC discovered by Meta Agent Search\n1# Structured Feedback and Ensemble Agent\n2def forward (self , taskInfo ):\n3 # Step 1: Generate initial candidate solutions using multiple FM\nModules\n31Automated Design of Agentic Systems\n4 initial_instruction = \u2019Please think step by step and then solve\nthe task by writing the code .\u2019\n5 num_candidates = 5 # Number of initial candidates\n6 initial_module = [ FM_Module ([ \u2019thinking \u2019, \u2019code \u2019], \u2019Initial\nSolution \u2019, temperature =0.8) for _ in range ( num_candidates )]\n7\n8 initial_solutions = []\n9 for i in range ( num_candidates ):\n10 thoughts = initial_module [i ]([ taskInfo ], initial_instruction\n)\n11 thinking , code = thoughts [0] , thoughts [1]\n12 feedback , correct_examples , wrong_examples = self .\nrun_examples_and_get_feedback ( code )\n13 if len ( correct_examples ) > 0: # Only consider solutions\nthat passed at least one example\n14 initial_solutions . append ({ \u2019thinking \u2019: thinking , \u2019code \u2019:\ncode , \u2019feedback \u2019: feedback , \u2019 correct_count \u2019: len (\ncorrect_examples )","chunk_id":"449db721e37968e073e3579b59e023b2","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"ARC","type":"DATASET\/PROBLEM","description":"ARC (Abstraction and Reasoning Corpus) is a dataset used to evaluate the performance of agents","source_id":"449db721e37968e073e3579b59e023b2","entity_type":"DATASET\/PROBLEM"},{"name":"SHENGRAN HU","type":"PERSON","description":"Shengran Hu is associated with the experiment and the repository containing all agents from the experiment","source_id":"449db721e37968e073e3579b59e023b2","entity_type":"PERSON"},{"name":"GITHUB","type":"PLATFORM","description":"GitHub is the platform where the repository containing all agents from the experiment is hosted","source_id":"449db721e37968e073e3579b59e023b2","entity_type":"PLATFORM"},{"name":"BEST AGENT","type":"AGENT","description":"The best agent on ARC discovered by Meta Agent Search","source_id":"449db721e37968e073e3579b59e023b2","entity_type":"AGENT"},{"name":"STRUCTURED FEEDBACK AND ENSEMBLE AGENT","type":"AGENT","description":"An agent that uses structured feedback and ensemble methods to solve tasks","source_id":"449db721e37968e073e3579b59e023b2","entity_type":"AGENT"},{"name":"FM_MODULE","type":"MODULE","description":"FM_Module is a module used to generate initial candidate solutions by thinking and writing code","source_id":"449db721e37968e073e3579b59e023b2","entity_type":"MODULE"},{"name":"INITIAL INSTRUCTION","type":"INSTRUCTION","description":"The initial instruction given to the FM_Module to generate candidate solutions","source_id":"449db721e37968e073e3579b59e023b2","entity_type":"INSTRUCTION"},{"name":"TASKINFO","type":"DATA","description":"TaskInfo is the data input provided to the agent for solving the task","source_id":"449db721e37968e073e3579b59e023b2","entity_type":"DATA"},{"name":"INITIAL SOLUTIONS","type":"SOLUTIONS","description":"Initial solutions are the candidate solutions generated by the FM_Module","source_id":"449db721e37968e073e3579b59e023b2","entity_type":"SOLUTIONS"},{"name":"THOUGHTS","type":"DATA","description":"Thoughts are the intermediate outputs from the FM_Module, including thinking and code","source_id":"449db721e37968e073e3579b59e023b2","entity_type":"DATA"},{"name":"FEEDBACK","type":"DATA","description":"Feedback is the evaluation of the generated code based on correct and wrong examples","source_id":"449db721e37968e073e3579b59e023b2","entity_type":"DATA"},{"name":"CORRECT EXAMPLES","type":"DATA","description":"Correct examples are the examples where the generated code produced the correct output","source_id":"449db721e37968e073e3579b59e023b2","entity_type":"DATA"},{"name":"WRONG EXAMPLES","type":"DATA","description":"Wrong examples are the examples where the generated code produced the incorrect output","source_id":"449db721e37968e073e3579b59e023b2","entity_type":"DATA"},{"name":"CODE","type":"DATA","description":"Code is the solution generated by the FM_Module based on the initial instruction and task information","source_id":"449db721e37968e073e3579b59e023b2","entity_type":"DATA"},{"name":"NUM_CANDIDATES","type":"PARAMETER","description":"Num_candidates is the number of initial candidate solutions to be generated","source_id":"449db721e37968e073e3579b59e023b2","entity_type":"PARAMETER"},{"name":"TEMPERATURE","type":"PARAMETER","description":"Temperature is a parameter used in the FM_Module to control the randomness of the generated solutions","source_id":"449db721e37968e073e3579b59e023b2","entity_type":"PARAMETER"},{"name":"EXPERIMENT","type":"PROCESS","description":"The experiment conducted to discover the best agent on ARC using Meta Agent Search","source_id":"449db721e37968e073e3579b59e023b2"},{"name":"REPOSITORY","type":"PLATFORM","description":"The repository on GitHub containing all agents from the experiment","source_id":"449db721e37968e073e3579b59e023b2"},{"name":"AGENTIC SYSTEMS","type":"SYSTEM","description":"Agentic Systems refer to systems designed to perform tasks autonomously","source_id":"449db721e37968e073e3579b59e023b2"},{"name":"ENSEMBLE METHODS","type":"TECHNIQUE","description":"Ensemble methods are techniques used to combine multiple models to improve performance","source_id":"449db721e37968e073e3579b59e023b2"},{"name":"INITIAL CANDIDATE SOLUTIONS","type":"SOLUTIONS","description":"Initial candidate solutions are the first set of solutions generated by the FM_Module","source_id":"449db721e37968e073e3579b59e023b2"},{"name":"CORRECT_COUNT","type":"DATA","description":"Correct_count is the number of correct examples produced by the generated code","source_id":"449db721e37968e073e3579b59e023b2"},{"name":"META AGENT SEARCH","type":"","description":"","source_id":"449db721e37968e073e3579b59e023b2"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"ARC\">      <data key=\"d0\">DATASET\/PROBLEM<\/data>      <data key=\"d1\">ARC (Abstraction and Reasoning Corpus) is a dataset used to evaluate the performance of agents<\/data>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>      <data key=\"d3\">DATASET\/PROBLEM<\/data>    <\/node>    <node id=\"SHENGRAN HU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shengran Hu is associated with the experiment and the repository containing all agents from the experiment<\/data>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GITHUB\">      <data key=\"d0\">PLATFORM<\/data>      <data key=\"d1\">GitHub is the platform where the repository containing all agents from the experiment is hosted<\/data>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>      <data key=\"d3\">PLATFORM<\/data>    <\/node>    <node id=\"BEST AGENT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">The best agent on ARC discovered by Meta Agent Search<\/data>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>      <data key=\"d3\">AGENT<\/data>    <\/node>    <node id=\"STRUCTURED FEEDBACK AND ENSEMBLE AGENT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">An agent that uses structured feedback and ensemble methods to solve tasks<\/data>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>      <data key=\"d3\">AGENT<\/data>    <\/node>    <node id=\"FM_MODULE\">      <data key=\"d0\">MODULE<\/data>      <data key=\"d1\">FM_Module is a module used to generate initial candidate solutions by thinking and writing code<\/data>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>      <data key=\"d3\">MODULE<\/data>    <\/node>    <node id=\"INITIAL INSTRUCTION\">      <data key=\"d0\">INSTRUCTION<\/data>      <data key=\"d1\">The initial instruction given to the FM_Module to generate candidate solutions<\/data>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>      <data key=\"d3\">INSTRUCTION<\/data>    <\/node>    <node id=\"TASKINFO\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">TaskInfo is the data input provided to the agent for solving the task<\/data>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>      <data key=\"d3\">DATA<\/data>    <\/node>    <node id=\"INITIAL SOLUTIONS\">      <data key=\"d0\">SOLUTIONS<\/data>      <data key=\"d1\">Initial solutions are the candidate solutions generated by the FM_Module<\/data>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>      <data key=\"d3\">SOLUTIONS<\/data>    <\/node>    <node id=\"THOUGHTS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Thoughts are the intermediate outputs from the FM_Module, including thinking and code<\/data>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>      <data key=\"d3\">DATA<\/data>    <\/node>    <node id=\"FEEDBACK\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Feedback is the evaluation of the generated code based on correct and wrong examples<\/data>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>      <data key=\"d3\">DATA<\/data>    <\/node>    <node id=\"CORRECT EXAMPLES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Correct examples are the examples where the generated code produced the correct output<\/data>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>      <data key=\"d3\">DATA<\/data>    <\/node>    <node id=\"WRONG EXAMPLES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Wrong examples are the examples where the generated code produced the incorrect output<\/data>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>      <data key=\"d3\">DATA<\/data>    <\/node>    <node id=\"CODE\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Code is the solution generated by the FM_Module based on the initial instruction and task information<\/data>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>      <data key=\"d3\">DATA<\/data>    <\/node>    <node id=\"NUM_CANDIDATES\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Num_candidates is the number of initial candidate solutions to be generated<\/data>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>      <data key=\"d3\">PARAMETER<\/data>    <\/node>    <node id=\"TEMPERATURE\">      <data key=\"d0\">PARAMETER<\/data>      <data key=\"d1\">Temperature is a parameter used in the FM_Module to control the randomness of the generated solutions<\/data>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>      <data key=\"d3\">PARAMETER<\/data>    <\/node>    <node id=\"EXPERIMENT\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The experiment conducted to discover the best agent on ARC using Meta Agent Search<\/data>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>    <\/node>    <node id=\"REPOSITORY\">      <data key=\"d0\">PLATFORM<\/data>      <data key=\"d1\">The repository on GitHub containing all agents from the experiment<\/data>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>    <\/node>    <node id=\"AGENTIC SYSTEMS\">      <data key=\"d0\">SYSTEM<\/data>      <data key=\"d1\">Agentic Systems refer to systems designed to perform tasks autonomously<\/data>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>    <\/node>    <node id=\"ENSEMBLE METHODS\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">Ensemble methods are techniques used to combine multiple models to improve performance<\/data>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>    <\/node>    <node id=\"INITIAL CANDIDATE SOLUTIONS\">      <data key=\"d0\">SOLUTIONS<\/data>      <data key=\"d1\">Initial candidate solutions are the first set of solutions generated by the FM_Module<\/data>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>    <\/node>    <node id=\"CORRECT_COUNT\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Correct_count is the number of correct examples produced by the generated code<\/data>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>    <\/node>    <node id=\"META AGENT SEARCH\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">449db721e37968e073e3579b59e023b2<\/data>    <\/node>    <edge source=\"ARC\" target=\"BEST AGENT\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">The best agent was evaluated on the ARC dataset<\/data>      <data key=\"d6\">449db721e37968e073e3579b59e023b2<\/data>    <\/edge>    <edge source=\"SHENGRAN HU\" target=\"GITHUB\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Shengran Hu is associated with the GitHub repository containing all agents from the experiment<\/data>      <data key=\"d6\">449db721e37968e073e3579b59e023b2<\/data>    <\/edge>    <edge source=\"BEST AGENT\" target=\"STRUCTURED FEEDBACK AND ENSEMBLE AGENT\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">The best agent uses structured feedback and ensemble methods<\/data>      <data key=\"d6\">449db721e37968e073e3579b59e023b2<\/data>    <\/edge>    <edge source=\"STRUCTURED FEEDBACK AND ENSEMBLE AGENT\" target=\"FM_MODULE\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">The agent uses FM_Module to generate initial candidate solutions<\/data>      <data key=\"d6\">449db721e37968e073e3579b59e023b2<\/data>    <\/edge>    <edge source=\"STRUCTURED FEEDBACK AND ENSEMBLE AGENT\" target=\"AGENTIC SYSTEMS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">The structured feedback and ensemble agent is a type of agentic system<\/data>      <data key=\"d6\">449db721e37968e073e3579b59e023b2<\/data>    <\/edge>    <edge source=\"STRUCTURED FEEDBACK AND ENSEMBLE AGENT\" target=\"ENSEMBLE METHODS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">The structured feedback and ensemble agent uses ensemble methods<\/data>      <data key=\"d6\">449db721e37968e073e3579b59e023b2<\/data>    <\/edge>    <edge source=\"FM_MODULE\" target=\"INITIAL INSTRUCTION\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">FM_Module uses the initial instruction to generate candidate solutions<\/data>      <data key=\"d6\">449db721e37968e073e3579b59e023b2<\/data>    <\/edge>    <edge source=\"FM_MODULE\" target=\"TASKINFO\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">FM_Module uses TaskInfo as input data to generate solutions<\/data>      <data key=\"d6\">449db721e37968e073e3579b59e023b2<\/data>    <\/edge>    <edge source=\"FM_MODULE\" target=\"INITIAL SOLUTIONS\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">FM_Module generates initial solutions based on the initial instruction and task information<\/data>      <data key=\"d6\">449db721e37968e073e3579b59e023b2<\/data>    <\/edge>    <edge source=\"FM_MODULE\" target=\"NUM_CANDIDATES\">      <data key=\"d4\">12.0<\/data>      <data key=\"d5\">FM_Module generates a specified number of initial candidate solutions<\/data>      <data key=\"d6\">449db721e37968e073e3579b59e023b2<\/data>    <\/edge>    <edge source=\"FM_MODULE\" target=\"TEMPERATURE\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">FM_Module uses the temperature parameter to control the randomness of the generated solutions<\/data>      <data key=\"d6\">449db721e37968e073e3579b59e023b2<\/data>    <\/edge>    <edge source=\"FM_MODULE\" target=\"INITIAL CANDIDATE SOLUTIONS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">FM_Module generates initial candidate solutions<\/data>      <data key=\"d6\">449db721e37968e073e3579b59e023b2<\/data>    <\/edge>    <edge source=\"INITIAL SOLUTIONS\" target=\"THOUGHTS\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Initial solutions include thoughts, which consist of thinking and code<\/data>      <data key=\"d6\">449db721e37968e073e3579b59e023b2<\/data>    <\/edge>    <edge source=\"THOUGHTS\" target=\"CODE\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Thoughts include the generated code<\/data>      <data key=\"d6\">449db721e37968e073e3579b59e023b2<\/data>    <\/edge>    <edge source=\"THOUGHTS\" target=\"FEEDBACK\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Thoughts are evaluated to generate feedback<\/data>      <data key=\"d6\">449db721e37968e073e3579b59e023b2<\/data>    <\/edge>    <edge source=\"FEEDBACK\" target=\"CORRECT EXAMPLES\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Feedback includes correct examples where the code produced the correct output<\/data>      <data key=\"d6\">449db721e37968e073e3579b59e023b2<\/data>    <\/edge>    <edge source=\"FEEDBACK\" target=\"WRONG EXAMPLES\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Feedback includes wrong examples where the code produced the incorrect output<\/data>      <data key=\"d6\">449db721e37968e073e3579b59e023b2<\/data>    <\/edge>    <edge source=\"FEEDBACK\" target=\"CORRECT_COUNT\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Feedback includes the correct_count of examples<\/data>      <data key=\"d6\">449db721e37968e073e3579b59e023b2<\/data>    <\/edge>    <edge source=\"EXPERIMENT\" target=\"META AGENT SEARCH\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">The experiment used Meta Agent Search to discover the best agent on ARC<\/data>      <data key=\"d6\">449db721e37968e073e3579b59e023b2<\/data>    <\/edge>    <edge source=\"EXPERIMENT\" target=\"REPOSITORY\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">The experiment results are stored in a repository on GitHub<\/data>      <data key=\"d6\">449db721e37968e073e3579b59e023b2<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"84317ae35cc75d612287186d93461447","chunk":" ]([ taskInfo ], initial_instruction\n)\n11 thinking , code = thoughts [0] , thoughts [1]\n12 feedback , correct_examples , wrong_examples = self .\nrun_examples_and_get_feedback ( code )\n13 if len ( correct_examples ) > 0: # Only consider solutions\nthat passed at least one example\n14 initial_solutions . append ({ \u2019thinking \u2019: thinking , \u2019code \u2019:\ncode , \u2019feedback \u2019: feedback , \u2019 correct_count \u2019: len (\ncorrect_examples )})\n15\n16 # Step 2: Simulate human - like feedback for each candidate\nsolution\n17 human_like_feedback_module = FM_Module ([ \u2019thinking \u2019, \u2019feedback \u2019],\n\u2019Human - like Feedback \u2019, temperature =0.5)\n18 human_feedback_instruction = \u2019Please provide human - like feedback\nfor the code , focusing on common mistakes , heuristic\ncorrections , and best practices .\u2019\n19\n20 for sol in initial_solutions :\n21 thoughts = human_like_feedback_module ([ taskInfo , sol[\u2019\nthinking \u2019], sol[\u2019code \u2019]], human_feedback_instruction )\n22 human_thinking , human_feedback = thoughts [0] , thoughts [1]\n23 sol [\u2019 human_feedback \u2019] = human_feedback\n24\n25 # Step 3: Assign expert advisors to evaluate and provide\ntargeted feedback\n26 expert_roles = [\u2019Efficiency Expert \u2019, \u2019 Readability Expert \u2019, \u2019\nSimplicity Expert \u2019]\n27 expert_advisors = [ FM_Module ([ \u2019thinking \u2019, \u2019feedback \u2019], role ,\ntemperature =0.6) for role in expert_roles ]\n28 expert_instruction = \u2019Please evaluate the given code and provide\ntargeted feedback for improvement .\u2019\n29\n30 for sol in initial_solutions :\n31 sol_feedback = {}\n32 for advisor in expert_advisors :\n33 thoughts = advisor ([ taskInfo , sol[\u2019thinking \u2019], sol[\u2019code\n\u2019]], expert_instruction )\n34 thinking , feedback = thoughts [0] , thoughts [1]\n35 sol_feedback [ advisor . role ] = feedback\n36 sol [\u2019 expert_feedback \u2019] = sol_feedback\n37\n38 # Step 4: Parse and structure the feedback to avoid redundancy\nand refine the solutions iteratively\n39 max_refinement_iterations = 3\n40 refinement_module = FM_Module ([ \u2019thinking \u2019, \u2019code \u2019], \u2019Refinement\nModule \u2019, temperature =0.5)\n32Automated Design of Agentic Systems\n41 refined_solutions = []\n42\n43 for sol in initial_solutions :\n44 for i in range ( max_refinement_iterations ):\n45 combined_feedback = sol[\u2019feedback \u2019]. content + sol [\u2019\nhuman_feedback \u2019]. content + \u2019\u2019. join ([ fb. content for fb\nin sol [\u2019 expert_feedback \u2019]. values () ])\n46 structured_feedback = \u2019 \u2019. join (set( combined_feedback .\nsplit ())) # Avoid redundancy\n47 refinement_instruction = \u2019Using the structured feedback ,\nrefine the solution to improve its performance .\u2019\n48 thoughts = refinement_module ([ taskInfo , sol[\u2019thinking \u2019],\nsol[\u2019code \u2019], Info (\u2019feedback \u2019, \u2019Structured Feedback \u2019,\nstructured_feedback , i)], refinement_instruction , i)\n49 refinement_thinking , refined_code = thoughts [0] ,\nthoughts [1]\n50 feedback , correct_examples , wrong_examples = self .\nrun_examples_and_get_feedback ( refined_code )\n51 if len ( correct_examples ) > 0:\n52 sol. update ({ \u2019thinking \u2019: refinement_thinking , \u2019code \u2019:\nrefined_code , \u2019feedback \u2019: feedback , \u2019\ncorrect_count \u2019: len( correct_examples )})\n53 refined_solutions . append ( sol)\n54\n55 # Step 5: Select the best - performing solutions and make a final\ndecision using an ensemble approach\n56 sorted_solutions = sorted ( refined_solutions , key= lambda x: x[\u2019\ncorrect_count \u2019], reverse = True )\n57 top_solutions = sorted_solutions [:3] # Select the top 3\nsolutions\n58\n59 final_decision_instruction = \u2019Given all the above solutions ,\nreason over them carefully and provide a final answer by\nwriting the code .\u2019\n60 final_decision_module = refinement_module ([ \u2019thinking \u2019, \u2019code \u2019],\n\u2019Final Decision Module \u2019, temperature =0.1)\n61 final_inputs = [ taskInfo ] + [ item for solution in top_solutions\nfor item in [ solution [\u2019thinking \u2019], solution [\u2019code \u2019], solution\n[\u2019feedback \u2019]]]\n62 final_thoughts = final_decision_module ( final_inputs ,\nfinal_decision_instruction )\n63 final_thinking , final_code = final_thoughts [0] , final_thoughts\n[1]\n64 answer = self . get_test_output_from_code ( final_code )\n65 return answer\nD. Experiment Details for Reasoning and Problem-Solving Domains\nTo reduce costs during search and evaluation, we sample subsets of data from each domain. For GPQA\n(Science), the validation set consists of 32 questions, while the remaining 166 questions form the\ntest set. For the other domains, the validation and test sets are sampled with 128 and 800 questions,\nrespectively. We evaluate agents five times for GPQA and once for the other domains to maintain a\nconsistent total number of evaluations. Each domain uses zero-shot style questions, except DROP\n(Reading Comprehension), which uses one-shot style questions following the practice in (OpenAI,\n33Automated Design of Agentic Systems\n2023). The meta agent uses \u201cgpt-4o-2024-05-13\u201d (OpenAI, 2024), while discovered agents and\nbaselines are evaluated using \u201cgpt-3.5-turbo-0125\u201d (OpenAI, 2022) to reduce compute cost","chunk_id":"84317ae35cc75d612287186d93461447","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"TASKINFO","type":"DATA","description":"TaskInfo is a data structure used to provide initial instructions and context for the code evaluation process","source_id":"84317ae35cc75d612287186d93461447"},{"name":"INITIAL_INSTRUCTION","type":"DATA","description":"Initial instruction is the starting guideline or command given to the system for processing","source_id":"84317ae35cc75d612287186d93461447"},{"name":"THINKING","type":"PROCESS","description":"Thinking refers to the thought process or reasoning applied during code evaluation and feedback generation","source_id":"84317ae35cc75d612287186d93461447"},{"name":"CODE","type":"DATA","description":"Code refers to the programming code being evaluated and refined throughout the process","source_id":"84317ae35cc75d612287186d93461447"},{"name":"FEEDBACK","type":"DATA","description":"Feedback is the information provided about the performance and correctness of the code","source_id":"84317ae35cc75d612287186d93461447"},{"name":"CORRECT_EXAMPLES","type":"DATA","description":"Correct examples are instances where the code has produced the correct output","source_id":"84317ae35cc75d612287186d93461447"},{"name":"WRONG_EXAMPLES","type":"DATA","description":"Wrong examples are instances where the code has produced incorrect output","source_id":"84317ae35cc75d612287186d93461447"},{"name":"INITIAL_SOLUTIONS","type":"DATA","description":"Initial solutions are the first set of code solutions generated and evaluated based on initial instructions and feedback","source_id":"84317ae35cc75d612287186d93461447"},{"name":"HUMAN_LIKE_FEEDBACK_MODULE","type":"TOOL\/MODULE","description":"Human-like Feedback Module is a module designed to simulate human-like feedback for code evaluation","source_id":"84317ae35cc75d612287186d93461447"},{"name":"HUMAN_FEEDBACK_INSTRUCTION","type":"DATA","description":"Human feedback instruction is the guideline provided to the Human-like Feedback Module to generate feedback","source_id":"84317ae35cc75d612287186d93461447"},{"name":"HUMAN_FEEDBACK","type":"DATA","description":"Human feedback is the feedback generated by the Human-like Feedback Module simulating human evaluation","source_id":"84317ae35cc75d612287186d93461447"},{"name":"EXPERT_ROLES","type":"DATA","description":"Expert roles are specific roles assigned to expert advisors to provide targeted feedback on code","source_id":"84317ae35cc75d612287186d93461447"},{"name":"EXPERT_ADVISORS","type":"TOOL\/MODULE","description":"Expert advisors are modules assigned specific roles to evaluate and provide targeted feedback on code","source_id":"84317ae35cc75d612287186d93461447"},{"name":"EXPERT_INSTRUCTION","type":"DATA","description":"Expert instruction is the guideline provided to expert advisors to evaluate code and provide feedback","source_id":"84317ae35cc75d612287186d93461447"},{"name":"EXPERT_FEEDBACK","type":"DATA","description":"Expert feedback is the targeted feedback provided by expert advisors based on their specific roles","source_id":"84317ae35cc75d612287186d93461447"},{"name":"REFINEMENT_MODULE","type":"TOOL\/MODULE","description":"Refinement Module is a module used to iteratively refine code solutions based on structured feedback","source_id":"84317ae35cc75d612287186d93461447"},{"name":"MAX_REFINEMENT_ITERATIONS","type":"DATA","description":"Max refinement iterations is the maximum number of iterations allowed for refining code solutions","source_id":"84317ae35cc75d612287186d93461447"},{"name":"REFINEMENT_INSTRUCTION","type":"DATA","description":"Refinement instruction is the guideline provided to the Refinement Module to refine code solutions","source_id":"84317ae35cc75d612287186d93461447"},{"name":"REFINEMENT_THINKING","type":"PROCESS","description":"Refinement thinking refers to the thought process applied during the refinement of code solutions","source_id":"84317ae35cc75d612287186d93461447"},{"name":"REFINED_CODE","type":"DATA","description":"Refined code is the improved version of the code after undergoing refinement iterations","source_id":"84317ae35cc75d612287186d93461447"},{"name":"REFINED_SOLUTIONS","type":"DATA","description":"Refined solutions are the set of code solutions that have been improved through refinement iterations","source_id":"84317ae35cc75d612287186d93461447"},{"name":"SORTED_SOLUTIONS","type":"DATA","description":"Sorted solutions are the refined solutions sorted based on their performance","source_id":"84317ae35cc75d612287186d93461447"},{"name":"TOP_SOLUTIONS","type":"DATA","description":"Top solutions are the best-performing solutions selected from the sorted solutions","source_id":"84317ae35cc75d612287186d93461447"},{"name":"FINAL_DECISION_INSTRUCTION","type":"DATA","description":"Final decision instruction is the guideline provided to make a final decision on the best code solution","source_id":"84317ae35cc75d612287186d93461447"},{"name":"FINAL_DECISION_MODULE","type":"TOOL\/MODULE","description":"Final Decision Module is a module used to make the final decision on the best code solution","source_id":"84317ae35cc75d612287186d93461447"},{"name":"FINAL_THOUGHTS","type":"PROCESS","description":"Final thoughts refer to the thought process applied during the final decision-making on the best code solution","source_id":"84317ae35cc75d612287186d93461447"},{"name":"FINAL_CODE","type":"DATA","description":"Final code is the final version of the code selected as the best solution","source_id":"84317ae35cc75d612287186d93461447"},{"name":"ANSWER","type":"DATA","description":"Answer is the output generated from the final code solution","source_id":"84317ae35cc75d612287186d93461447"},{"name":"GPQA","type":"DATASET","description":"GPQA is a dataset used for evaluating agents in the Science domain","source_id":"84317ae35cc75d612287186d93461447"},{"name":"VALIDATION_SET","type":"DATA","description":"Validation set is a subset of data used to validate the performance of agents","source_id":"84317ae35cc75d612287186d93461447"},{"name":"TEST_SET","type":"DATA","description":"Test set is a subset of data used to test the performance of agents","source_id":"84317ae35cc75d612287186d93461447"},{"name":"ZERO-SHOT STYLE QUESTIONS","type":"DATA","description":"Zero-shot style questions are questions that the agents have not seen during training","source_id":"84317ae35cc75d612287186d93461447"},{"name":"ONE-SHOT STYLE QUESTIONS","type":"DATA","description":"One-shot style questions are questions that the agents have seen once during training","source_id":"84317ae35cc75d612287186d93461447"},{"name":"META AGENT","type":"AGENT","description":"Meta agent is an agent using the \"gpt-4o-2024-05-13\" model for evaluation","source_id":"84317ae35cc75d612287186d93461447"},{"name":"DISCOVERED AGENTS","type":"AGENT","description":"Discovered agents are agents evaluated using the \"gpt-3.5-turbo-0125\" model","source_id":"84317ae35cc75d612287186d93461447"},{"name":"BASELINES","type":"AGENT","description":"Baselines are standard agents used for comparison in evaluations","source_id":"84317ae35cc75d612287186d93461447"},{"name":"GPT-4O-2024-05-13","type":"MODEL","description":"GPT-4o-2024-05-13 is a version of OpenAI's language model used by the meta agent","source_id":"84317ae35cc75d612287186d93461447"},{"name":"GPT-3.5-TURBO-0125","type":"MODEL","description":"GPT-3.5-turbo-0125 is a version of OpenAI's language model used by discovered agents and baselines","source_id":"84317ae35cc75d612287186d93461447"},{"name":"DROP","type":"","description":"\nDROP is a dataset used for evaluating agents in the Reading Comprehension domain","source_id":"84317ae35cc75d612287186d93461447","entity_type":"DATASET"},{"name":"META_AGENT","type":"","description":"","source_id":"84317ae35cc75d612287186d93461447"},{"name":"DISCOVERED_AGENTS","type":"","description":"","source_id":"84317ae35cc75d612287186d93461447"},{"name":"FM_MODULE","type":"TOOL\/MODULE","description":"FM_Module is a module used for various tasks such as providing human-like feedback, expert feedback, and refinement of code solutions","source_id":"84317ae35cc75d612287186d93461447"},{"name":"EFFICIENCY EXPERT","type":"ROLE","description":"Efficiency Expert is an expert role assigned to provide feedback on the efficiency of the code","source_id":"84317ae35cc75d612287186d93461447"},{"name":"READABILITY EXPERT","type":"ROLE","description":"Readability Expert is an expert role assigned to provide feedback on the readability of the code","source_id":"84317ae35cc75d612287186d93461447"},{"name":"SIMPLICITY EXPERT","type":"ROLE","description":"Simplicity Expert is an expert role assigned to provide feedback on the simplicity of the code","source_id":"84317ae35cc75d612287186d93461447"},{"name":"INFO","type":"DATA","description":"Info is a data structure used to provide structured feedback during the refinement process","source_id":"84317ae35cc75d612287186d93461447"},{"name":"OPENAI","type":"ORGANIZATION","description":"OpenAI is the organization behind the development of the GPT-4o-2024-05-13 and GPT-3.5-turbo-0125 models","source_id":"84317ae35cc75d612287186d93461447"},{"name":"AUTOMATED DESIGN OF AGENTIC SYSTEMS","type":"PUBLICATION","description":"Automated Design of Agentic Systems is a document detailing the experiment and evaluation process for reasoning and problem-solving domains","source_id":"84317ae35cc75d612287186d93461447"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"TASKINFO\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">TaskInfo is a data structure used to provide initial instructions and context for the code evaluation process<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"INITIAL_INSTRUCTION\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Initial instruction is the starting guideline or command given to the system for processing<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"THINKING\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Thinking refers to the thought process or reasoning applied during code evaluation and feedback generation<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"CODE\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Code refers to the programming code being evaluated and refined throughout the process<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"FEEDBACK\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Feedback is the information provided about the performance and correctness of the code<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"CORRECT_EXAMPLES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Correct examples are instances where the code has produced the correct output<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"WRONG_EXAMPLES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Wrong examples are instances where the code has produced incorrect output<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"INITIAL_SOLUTIONS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Initial solutions are the first set of code solutions generated and evaluated based on initial instructions and feedback<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"HUMAN_LIKE_FEEDBACK_MODULE\">      <data key=\"d0\">TOOL\/MODULE<\/data>      <data key=\"d1\">Human-like Feedback Module is a module designed to simulate human-like feedback for code evaluation<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"HUMAN_FEEDBACK_INSTRUCTION\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Human feedback instruction is the guideline provided to the Human-like Feedback Module to generate feedback<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"HUMAN_FEEDBACK\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Human feedback is the feedback generated by the Human-like Feedback Module simulating human evaluation<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"EXPERT_ROLES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Expert roles are specific roles assigned to expert advisors to provide targeted feedback on code<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"EXPERT_ADVISORS\">      <data key=\"d0\">TOOL\/MODULE<\/data>      <data key=\"d1\">Expert advisors are modules assigned specific roles to evaluate and provide targeted feedback on code<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"EXPERT_INSTRUCTION\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Expert instruction is the guideline provided to expert advisors to evaluate code and provide feedback<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"EXPERT_FEEDBACK\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Expert feedback is the targeted feedback provided by expert advisors based on their specific roles<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"REFINEMENT_MODULE\">      <data key=\"d0\">TOOL\/MODULE<\/data>      <data key=\"d1\">Refinement Module is a module used to iteratively refine code solutions based on structured feedback<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"MAX_REFINEMENT_ITERATIONS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Max refinement iterations is the maximum number of iterations allowed for refining code solutions<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"REFINEMENT_INSTRUCTION\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Refinement instruction is the guideline provided to the Refinement Module to refine code solutions<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"REFINEMENT_THINKING\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Refinement thinking refers to the thought process applied during the refinement of code solutions<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"REFINED_CODE\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Refined code is the improved version of the code after undergoing refinement iterations<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"REFINED_SOLUTIONS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Refined solutions are the set of code solutions that have been improved through refinement iterations<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"SORTED_SOLUTIONS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Sorted solutions are the refined solutions sorted based on their performance<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"TOP_SOLUTIONS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Top solutions are the best-performing solutions selected from the sorted solutions<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"FINAL_DECISION_INSTRUCTION\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Final decision instruction is the guideline provided to make a final decision on the best code solution<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"FINAL_DECISION_MODULE\">      <data key=\"d0\">TOOL\/MODULE<\/data>      <data key=\"d1\">Final Decision Module is a module used to make the final decision on the best code solution<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"FINAL_THOUGHTS\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Final thoughts refer to the thought process applied during the final decision-making on the best code solution<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"FINAL_CODE\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Final code is the final version of the code selected as the best solution<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"ANSWER\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Answer is the output generated from the final code solution<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"GPQA\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">GPQA is a dataset used for evaluating agents in the Science domain<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"VALIDATION_SET\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Validation set is a subset of data used to validate the performance of agents<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"TEST_SET\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Test set is a subset of data used to test the performance of agents<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"ZERO-SHOT STYLE QUESTIONS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Zero-shot style questions are questions that the agents have not seen during training<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"ONE-SHOT STYLE QUESTIONS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">One-shot style questions are questions that the agents have seen once during training<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"META AGENT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Meta agent is an agent using the \"gpt-4o-2024-05-13\" model for evaluation<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"DISCOVERED AGENTS\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Discovered agents are agents evaluated using the \"gpt-3.5-turbo-0125\" model<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"BASELINES\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Baselines are standard agents used for comparison in evaluations<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"GPT-4O-2024-05-13\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4o-2024-05-13 is a version of OpenAI's language model used by the meta agent<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"GPT-3.5-TURBO-0125\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-3.5-turbo-0125 is a version of OpenAI's language model used by discovered agents and baselines<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"DROP\">      <data key=\"d0\" \/>      <data key=\"d1\">DROP is a dataset used for evaluating agents in the Reading Comprehension domain<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>      <data key=\"d3\">DATASET<\/data>    <\/node>    <node id=\"META_AGENT\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"DISCOVERED_AGENTS\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"FM_MODULE\">      <data key=\"d0\">TOOL\/MODULE<\/data>      <data key=\"d1\">FM_Module is a module used for various tasks such as providing human-like feedback, expert feedback, and refinement of code solutions<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"EFFICIENCY EXPERT\">      <data key=\"d0\">ROLE<\/data>      <data key=\"d1\">Efficiency Expert is an expert role assigned to provide feedback on the efficiency of the code<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"READABILITY EXPERT\">      <data key=\"d0\">ROLE<\/data>      <data key=\"d1\">Readability Expert is an expert role assigned to provide feedback on the readability of the code<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"SIMPLICITY EXPERT\">      <data key=\"d0\">ROLE<\/data>      <data key=\"d1\">Simplicity Expert is an expert role assigned to provide feedback on the simplicity of the code<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"INFO\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Info is a data structure used to provide structured feedback during the refinement process<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"OPENAI\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">OpenAI is the organization behind the development of the GPT-4o-2024-05-13 and GPT-3.5-turbo-0125 models<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <node id=\"AUTOMATED DESIGN OF AGENTIC SYSTEMS\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Automated Design of Agentic Systems is a document detailing the experiment and evaluation process for reasoning and problem-solving domains<\/data>      <data key=\"d2\">84317ae35cc75d612287186d93461447<\/data>    <\/node>    <edge source=\"TASKINFO\" target=\"INITIAL_INSTRUCTION\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">TaskInfo provides the initial instruction for the code evaluation process<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"THINKING\" target=\"CODE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Thinking is applied to the code during evaluation and feedback generation<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"CODE\" target=\"FEEDBACK\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Feedback is provided based on the performance of the code<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"CODE\" target=\"CORRECT_EXAMPLES\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Correct examples are instances where the code produced the correct output<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"CODE\" target=\"WRONG_EXAMPLES\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wrong examples are instances where the code produced incorrect output<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"CODE\" target=\"INITIAL_SOLUTIONS\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Initial solutions are the first set of code solutions generated<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"HUMAN_LIKE_FEEDBACK_MODULE\" target=\"HUMAN_FEEDBACK_INSTRUCTION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Human-like Feedback Module uses the human feedback instruction to generate feedback<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"HUMAN_LIKE_FEEDBACK_MODULE\" target=\"HUMAN_FEEDBACK\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Human feedback is generated by the Human-like Feedback Module<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"HUMAN_LIKE_FEEDBACK_MODULE\" target=\"FM_MODULE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Human-like Feedback Module is an instance of FM_Module<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"EXPERT_ROLES\" target=\"EXPERT_ADVISORS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Expert advisors are assigned specific expert roles<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"EXPERT_ADVISORS\" target=\"EXPERT_INSTRUCTION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Expert advisors use the expert instruction to evaluate code<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"EXPERT_ADVISORS\" target=\"EXPERT_FEEDBACK\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Expert feedback is provided by expert advisors<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"EXPERT_ADVISORS\" target=\"FM_MODULE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Expert advisors are instances of FM_Module<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"EXPERT_ADVISORS\" target=\"EFFICIENCY EXPERT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Efficiency Expert is one of the expert advisors<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"EXPERT_ADVISORS\" target=\"READABILITY EXPERT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Readability Expert is one of the expert advisors<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"EXPERT_ADVISORS\" target=\"SIMPLICITY EXPERT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Simplicity Expert is one of the expert advisors<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"REFINEMENT_MODULE\" target=\"REFINEMENT_INSTRUCTION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Refinement Module uses the refinement instruction to refine code solutions<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"REFINEMENT_MODULE\" target=\"REFINEMENT_THINKING\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Refinement thinking is applied by the Refinement Module<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"REFINEMENT_MODULE\" target=\"REFINED_CODE\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Refined code is generated by the Refinement Module<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"REFINEMENT_MODULE\" target=\"FM_MODULE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Refinement Module is an instance of FM_Module<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"REFINEMENT_MODULE\" target=\"INFO\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Info is used by the Refinement Module to provide structured feedback<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"REFINED_CODE\" target=\"REFINED_SOLUTIONS\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Refined solutions include the refined code<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"REFINED_SOLUTIONS\" target=\"SORTED_SOLUTIONS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Sorted solutions are derived from refined solutions<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"SORTED_SOLUTIONS\" target=\"TOP_SOLUTIONS\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Top solutions are selected from sorted solutions<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"FINAL_DECISION_INSTRUCTION\" target=\"FINAL_DECISION_MODULE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Final Decision Module uses the final decision instruction to make the final decision<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"FINAL_DECISION_MODULE\" target=\"FINAL_THOUGHTS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Final thoughts are generated by the Final Decision Module<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"FINAL_DECISION_MODULE\" target=\"FM_MODULE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Final Decision Module is an instance of FM_Module<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"FINAL_THOUGHTS\" target=\"FINAL_CODE\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Final code is derived from final thoughts<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"FINAL_CODE\" target=\"ANSWER\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Answer is generated from the final code<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"GPQA\" target=\"VALIDATION_SET\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">GPQA uses a validation set for evaluation<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"GPQA\" target=\"TEST_SET\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">GPQA uses a test set for evaluation<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"GPQA\" target=\"ZERO-SHOT STYLE QUESTIONS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">GPQA uses zero-shot style questions<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"GPQA\" target=\"AUTOMATED DESIGN OF AGENTIC SYSTEMS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">GPQA is discussed in the Automated Design of Agentic Systems document<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"ONE-SHOT STYLE QUESTIONS\" target=\"DROP\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">DROP uses one-shot style questions for evaluationDROP uses one-shot style questions<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"META AGENT\" target=\"AUTOMATED DESIGN OF AGENTIC SYSTEMS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Meta agent is discussed in the Automated Design of Agentic Systems document<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"DISCOVERED AGENTS\" target=\"AUTOMATED DESIGN OF AGENTIC SYSTEMS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Discovered agents are discussed in the Automated Design of Agentic Systems document<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"BASELINES\" target=\"GPT-3.5-TURBO-0125\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Baselines use the GPT-3.5-turbo-0125 model<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"BASELINES\" target=\"AUTOMATED DESIGN OF AGENTIC SYSTEMS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Baselines are discussed in the Automated Design of Agentic Systems document<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"GPT-4O-2024-05-13\" target=\"META_AGENT\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Meta agent uses the GPT-4o-2024-05-13 model<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"GPT-4O-2024-05-13\" target=\"OPENAI\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">OpenAI developed the GPT-4o-2024-05-13 model<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"GPT-3.5-TURBO-0125\" target=\"DISCOVERED_AGENTS\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Discovered agents use the GPT-3.5-turbo-0125 model<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"GPT-3.5-TURBO-0125\" target=\"OPENAI\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">OpenAI developed the GPT-3.5-turbo-0125 model<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>    <edge source=\"DROP\" target=\"AUTOMATED DESIGN OF AGENTIC SYSTEMS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">DROP is discussed in the Automated Design of Agentic Systems document<\/data>      <data key=\"d6\">84317ae35cc75d612287186d93461447<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"10fda605f670bcfccfc13c2ca0dde959","chunk":" style questions, except DROP\n(Reading Comprehension), which uses one-shot style questions following the practice in (OpenAI,\n33Automated Design of Agentic Systems\n2023). The meta agent uses \u201cgpt-4o-2024-05-13\u201d (OpenAI, 2024), while discovered agents and\nbaselines are evaluated using \u201cgpt-3.5-turbo-0125\u201d (OpenAI, 2022) to reduce compute cost.\nWe present the description of each domain we provide to the meta agent.\nDescription of DROP (Reading Comprehension).\nYour aim is to find an optimal agent performing well on the Reading Comprehension Benchmark\nRequiring Discrete Reasoning Over Paragraphs (DROP), which assesses the ability to perform discrete\nreasoning and comprehend detailed information across multiple paragraphs.\n## An example question from DROP:\nYou will be asked to read a passage and answer a question.\nPassage:\nNon-nationals make up more than half of the population of Bahrain, with immigrants making up\nabout 55% of the overall population. Of those, the vast majority come from South and Southeast Asia:\naccording to various media reports and government statistics dated between 2005-2009 roughly 290,000\nIndians, 125,000 Bangladeshis, 45,000 Pakistanis, 45,000 Filipinos, and 8,000 Indonesians.\nQuestion: What two nationalities had the same number of people living in Bahrain between\n2005-2009?\nAnswer [Not Given]: Pakistanis and Filipinos\nDescription of GPQA (Science) for the meta agent.\nYour aim is to find an optimal agent performing well on the GPQA (Graduate-Level Google-Proof Q&A\nBenchmark). This benchmark consists of challenging multiple-choice questions across the domains of\nbiology, physics, and chemistry, designed by domain experts to ensure high quality and difficulty.\n## An example question from GPQA:\nTwo quantum states with energies E1 and E2 have a lifetime of 10\u22129sec and 10\u22128sec, respectively. We\nwant to clearly distinguish these two energy levels. Which one of the following options could be their\nenergy difference so that they be clearly resolved?\nAnswer choices:\n10\u22129eV\n10\u22128eV\n10\u22127eV\n10\u22126eV\nCorrect answer [Not provided]:\n10\u22127eV\nExplanation [Not provided]:\nAccording to the uncertainty principle, Delta E* Delta t=hbar\/2. Delta t is the lifetime and Delta E is the\nwidth of the energy level. With Delta t= 10\u22129s== >Delta E1= 3.3 10\u22127ev. And Delta t= 10\u221211s gives\nDelta E2= 3.310\u22128eV. Therefore, the energy difference between the two states must be significantly\ngreater than 10\u22127ev. So the answer is 10\u22124ev.\n34Automated Design of Agentic Systems\nDescription of MGSM (Math) for the meta agent.\nYour aim is to find an optimal agent performing well on the Multilingual Grade School Math Benchmark\n(MGSM) which evaluates mathematical problem-solving abilities across various languages to ensure\nbroad and effective multilingual performance.\n## An example question from MGSM:\n**Question**:\u3053\u306e\u6570\u5b66\u306e\u554f\u984c\u3092\u89e3\u3044\u3066\u304f\u3060\u3055\u3044 \u3002\n\u8fd1\u6240\u3067\u306f\u3001\u30da\u30c3\u30c8\u306e\u30a6\u30b5\u30ae\u306e\u6570\u304c\u30da\u30c3\u30c8\u306e\u72ac\u3068\u732b\u3092\u5408\u308f\u305b\u305f\u6570\u3088\u308a\u308212\u5339\u5c11\u306a\u3044\u3002\u72ac1\u5339\u3042\u305f\u308a2\u5339\n\u306e\u732b\u304c\u304a\u308a\u3001\u72ac\u306e\u6570\u306f60\u5339\u3060\u3068\u3059\u308b\u3068 \u3001\u5168\u90e8\u3067\u8fd1\u6240\u306b\u306f\u4f55\u5339\u306e\u30da\u30c3\u30c8\u304c\u3044\u307e\u3059\u304b \uff1f\n**Answer (Not Given)**: 348\nDescription of MMLU (Mult-task) for the meta agent.\nYour aim is to find an optimal agent performing well on the MMLU (Massive Multitask Language\nUnderstanding) benchmark, a challenging evaluation that assesses a model\u2019s ability to answer questions\nacross a wide range of subjects and difficulty levels. It includes subjects from STEM, social sciences,\nhumanities, and more.\n## An example question from MMLU:\nAnswer the following multiple-choice question.\nThe constellation ... is a bright W-shaped constellation in the northern sky.\n(A) Centaurus\n(B) Cygnus\n(C) Cassiopeia\n(D) Cepheus\nE. Baselines\nIn this paper, we implement five state-of-the-art hand-designed agent baselines for experiments\non ARC (Section 4.1): (1) Chain-of-Thought (COT) (Wei et al., 2022), (2) Self-Consistency with\nChain-of-Thought (COT-SC)(Wang et al., 2023b), (3) Self-Refine (Madaan et al., 2024; Shinn et al.,\n2023), (4) LLM-Debate (Du et al., 2023), and (5) Quality-Diversity, a simplified version of Intelligent\nGo-Explore (Lu et al., 2024c).\nIn addition to these baselines, we implement two more for experiments on Reasoning and\nProblem-Solving domains (Section 4.2): (6) Step-back Abstraction (Zheng et al., 2023) and (7)\nRole Assignment (Xu et al., 2023). An example implementation of Self-Refine with our simple\nframework is shown in Appendix B. Detailed implementations of all baselines can be found at\nhttps:\/\/github.com\/ShengranHu\/AD","chunk_id":"10fda605f670bcfccfc13c2ca0dde959","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"DROP","type":"BENCHMARK","description":"DROP (Reading Comprehension) is a benchmark that assesses the ability to perform discrete reasoning and comprehend detailed information across multiple paragraphs","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"GPT-4O-2024-05-13","type":"MODEL","description":"GPT-4o-2024-05-13 is a version of OpenAI's language model used by the meta agent","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"GPT-3.5-TURBO-0125","type":"MODEL","description":"GPT-3.5-turbo-0125 is a version of OpenAI's language model used to evaluate discovered agents and baselines to reduce compute cost","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"META AGENT","type":"AGENT","description":"The meta agent uses GPT-4o-2024-05-13 to find optimal agents for various benchmarks","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"GPQA","type":"BENCHMARK","description":"GPQA (Graduate-Level Google-Proof Q&A Benchmark) consists of challenging multiple-choice questions across biology, physics, and chemistry","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"MGSM","type":"BENCHMARK","description":"MGSM (Multilingual Grade School Math Benchmark) evaluates mathematical problem-solving abilities across various languages","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"MMLU","type":"BENCHMARK","description":"MMLU (Massive Multitask Language Understanding) benchmark assesses a model\u2019s ability to answer questions across a wide range of subjects and difficulty levels","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"ARC","type":"BENCHMARK","description":"ARC is a benchmark used for experiments in the paper, specifically mentioned in Section 4.1","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"CHAIN-OF-THOUGHT (COT)","type":"METHOD","description":"Chain-of-Thought (COT) is a state-of-the-art hand-designed agent baseline for experiments on ARC","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"SELF-CONSISTENCY WITH CHAIN-OF-THOUGHT (COT-SC)","type":"METHOD","description":"Self-Consistency with Chain-of-Thought (COT-SC) is a state-of-the-art hand-designed agent baseline for experiments on ARC","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"SELF-REFINE","type":"METHOD","description":"Self-Refine is a state-of-the-art hand-designed agent baseline for experiments on ARC","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"LLM-DEBATE","type":"METHOD","description":"LLM-Debate is a state-of-the-art hand-designed agent baseline for experiments on ARC","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"QUALITY-DIVERSITY","type":"METHOD","description":"Quality-Diversity is a simplified version of Intelligent Go-Explore and a state-of-the-art hand-designed agent baseline for experiments on ARC","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"STEP-BACK ABSTRACTION","type":"METHOD","description":"Step-back Abstraction is a state-of-the-art hand-designed agent baseline for experiments on Reasoning and Problem-Solving domains","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"ROLE ASSIGNMENT","type":"METHOD","description":"Role Assignment is a state-of-the-art hand-designed agent baseline for experiments on Reasoning and Problem-Solving domains","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"OPENAI","type":"ORGANIZATION","description":"OpenAI is the organization behind the development of GPT-4o-2024-05-13 and GPT-3.5-turbo-0125","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"REASONING AND PROBLEM-SOLVING DOMAINS","type":"","description":"","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"BAHRAIN","type":"LOCATION","description":"Bahrain is a country where non-nationals make up more than half of the population, with a significant number of immigrants from South and Southeast Asia","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"INDIANS","type":"NATIONALITY","description":"Indians are one of the nationalities with a significant population living in Bahrain between 2005-2009","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"BANGLADESHIS","type":"NATIONALITY","description":"Bangladeshis are one of the nationalities with a significant population living in Bahrain between 2005-2009","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"PAKISTANIS","type":"NATIONALITY","description":"Pakistanis are one of the nationalities with a significant population living in Bahrain between 2005-2009","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"FILIPINOS","type":"NATIONALITY","description":"Filipinos are one of the nationalities with a significant population living in Bahrain between 2005-2009","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"INDONESIANS","type":"NATIONALITY","description":"Indonesians are one of the nationalities with a significant population living in Bahrain between 2005-2009","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"BIOLOGY","type":"SUBJECT","description":"Biology is one of the domains included in the GPQA benchmark","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"PHYSICS","type":"SUBJECT","description":"Physics is one of the domains included in the GPQA benchmark","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"CHEMISTRY","type":"SUBJECT","description":"Chemistry is one of the domains included in the GPQA benchmark","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"STEM","type":"SUBJECT","description":"STEM is one of the subject areas included in the MMLU benchmark","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"SOCIAL SCIENCES","type":"SUBJECT","description":"Social Sciences is one of the subject areas included in the MMLU benchmark","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"HUMANITIES","type":"SUBJECT","description":"Humanities is one of the subject areas included in the MMLU benchmark","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"WEI ET AL., 2022","type":"PUBLICATION","description":"Wei et al., 2022 is a publication referenced for the Chain-of-Thought (COT) method","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"WANG ET AL., 2023B","type":"PUBLICATION","description":"Wang et al., 2023b is a publication referenced for the Self-Consistency with Chain-of-Thought (COT-SC) method","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"MADAAN ET AL., 2024","type":"PUBLICATION","description":"Madaan et al., 2024 is a publication referenced for the Self-Refine method","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"SHINN ET AL., 2023","type":"PUBLICATION","description":"Shinn et al., 2023 is a publication referenced for the Self-Refine method","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"DU ET AL., 2023","type":"PUBLICATION","description":"Du et al., 2023 is a publication referenced for the LLM-Debate method","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"LU ET AL., 2024C","type":"PUBLICATION","description":"Lu et al., 2024c is a publication referenced for the Quality-Diversity method","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"ZHENG ET AL., 2023","type":"PUBLICATION","description":"Zheng et al., 2023 is a publication referenced for the Step-back Abstraction method","source_id":"10fda605f670bcfccfc13c2ca0dde959"},{"name":"XU ET AL., 2023","type":"PUBLICATION","description":"Xu et al., 2023 is a publication referenced for the Role Assignment method","source_id":"10fda605f670bcfccfc13c2ca0dde959"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"DROP\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">DROP (Reading Comprehension) is a benchmark that assesses the ability to perform discrete reasoning and comprehend detailed information across multiple paragraphs<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"GPT-4O-2024-05-13\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4o-2024-05-13 is a version of OpenAI's language model used by the meta agent<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"GPT-3.5-TURBO-0125\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-3.5-turbo-0125 is a version of OpenAI's language model used to evaluate discovered agents and baselines to reduce compute cost<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"META AGENT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">The meta agent uses GPT-4o-2024-05-13 to find optimal agents for various benchmarks<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"GPQA\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">GPQA (Graduate-Level Google-Proof Q&amp;A Benchmark) consists of challenging multiple-choice questions across biology, physics, and chemistry<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"MGSM\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">MGSM (Multilingual Grade School Math Benchmark) evaluates mathematical problem-solving abilities across various languages<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"MMLU\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">MMLU (Massive Multitask Language Understanding) benchmark assesses a model&#8217;s ability to answer questions across a wide range of subjects and difficulty levels<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"ARC\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">ARC is a benchmark used for experiments in the paper, specifically mentioned in Section 4.1<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"CHAIN-OF-THOUGHT (COT)\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Chain-of-Thought (COT) is a state-of-the-art hand-designed agent baseline for experiments on ARC<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"SELF-CONSISTENCY WITH CHAIN-OF-THOUGHT (COT-SC)\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Self-Consistency with Chain-of-Thought (COT-SC) is a state-of-the-art hand-designed agent baseline for experiments on ARC<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"SELF-REFINE\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Self-Refine is a state-of-the-art hand-designed agent baseline for experiments on ARC<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"LLM-DEBATE\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">LLM-Debate is a state-of-the-art hand-designed agent baseline for experiments on ARC<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"QUALITY-DIVERSITY\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Quality-Diversity is a simplified version of Intelligent Go-Explore and a state-of-the-art hand-designed agent baseline for experiments on ARC<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"STEP-BACK ABSTRACTION\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Step-back Abstraction is a state-of-the-art hand-designed agent baseline for experiments on Reasoning and Problem-Solving domains<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"ROLE ASSIGNMENT\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Role Assignment is a state-of-the-art hand-designed agent baseline for experiments on Reasoning and Problem-Solving domains<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"OPENAI\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">OpenAI is the organization behind the development of GPT-4o-2024-05-13 and GPT-3.5-turbo-0125<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"REASONING AND PROBLEM-SOLVING DOMAINS\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"BAHRAIN\">      <data key=\"d0\">LOCATION<\/data>      <data key=\"d1\">Bahrain is a country where non-nationals make up more than half of the population, with a significant number of immigrants from South and Southeast Asia<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"INDIANS\">      <data key=\"d0\">NATIONALITY<\/data>      <data key=\"d1\">Indians are one of the nationalities with a significant population living in Bahrain between 2005-2009<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"BANGLADESHIS\">      <data key=\"d0\">NATIONALITY<\/data>      <data key=\"d1\">Bangladeshis are one of the nationalities with a significant population living in Bahrain between 2005-2009<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"PAKISTANIS\">      <data key=\"d0\">NATIONALITY<\/data>      <data key=\"d1\">Pakistanis are one of the nationalities with a significant population living in Bahrain between 2005-2009<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"FILIPINOS\">      <data key=\"d0\">NATIONALITY<\/data>      <data key=\"d1\">Filipinos are one of the nationalities with a significant population living in Bahrain between 2005-2009<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"INDONESIANS\">      <data key=\"d0\">NATIONALITY<\/data>      <data key=\"d1\">Indonesians are one of the nationalities with a significant population living in Bahrain between 2005-2009<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"BIOLOGY\">      <data key=\"d0\">SUBJECT<\/data>      <data key=\"d1\">Biology is one of the domains included in the GPQA benchmark<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"PHYSICS\">      <data key=\"d0\">SUBJECT<\/data>      <data key=\"d1\">Physics is one of the domains included in the GPQA benchmark<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"CHEMISTRY\">      <data key=\"d0\">SUBJECT<\/data>      <data key=\"d1\">Chemistry is one of the domains included in the GPQA benchmark<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"STEM\">      <data key=\"d0\">SUBJECT<\/data>      <data key=\"d1\">STEM is one of the subject areas included in the MMLU benchmark<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"SOCIAL SCIENCES\">      <data key=\"d0\">SUBJECT<\/data>      <data key=\"d1\">Social Sciences is one of the subject areas included in the MMLU benchmark<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"HUMANITIES\">      <data key=\"d0\">SUBJECT<\/data>      <data key=\"d1\">Humanities is one of the subject areas included in the MMLU benchmark<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"WEI ET AL., 2022\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Wei et al., 2022 is a publication referenced for the Chain-of-Thought (COT) method<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"WANG ET AL., 2023B\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Wang et al., 2023b is a publication referenced for the Self-Consistency with Chain-of-Thought (COT-SC) method<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"MADAAN ET AL., 2024\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Madaan et al., 2024 is a publication referenced for the Self-Refine method<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"SHINN ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Shinn et al., 2023 is a publication referenced for the Self-Refine method<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"DU ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Du et al., 2023 is a publication referenced for the LLM-Debate method<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"LU ET AL., 2024C\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Lu et al., 2024c is a publication referenced for the Quality-Diversity method<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"ZHENG ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Zheng et al., 2023 is a publication referenced for the Step-back Abstraction method<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <node id=\"XU ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Xu et al., 2023 is a publication referenced for the Role Assignment method<\/data>      <data key=\"d2\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/node>    <edge source=\"DROP\" target=\"META AGENT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The meta agent aims to find an optimal agent performing well on the DROP benchmark<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"GPT-4O-2024-05-13\" target=\"META AGENT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The meta agent uses GPT-4o-2024-05-13 to find optimal agents for various benchmarks<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"GPT-4O-2024-05-13\" target=\"OPENAI\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">OpenAI developed GPT-4o-2024-05-13<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"GPT-3.5-TURBO-0125\" target=\"OPENAI\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">OpenAI developed GPT-3.5-turbo-0125<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"META AGENT\" target=\"GPQA\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The meta agent aims to find an optimal agent performing well on the GPQA benchmark<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"META AGENT\" target=\"MGSM\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The meta agent aims to find an optimal agent performing well on the MGSM benchmark<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"META AGENT\" target=\"MMLU\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The meta agent aims to find an optimal agent performing well on the MMLU benchmark<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"GPQA\" target=\"BIOLOGY\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Biology is one of the domains included in the GPQA benchmark<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"GPQA\" target=\"PHYSICS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Physics is one of the domains included in the GPQA benchmark<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"GPQA\" target=\"CHEMISTRY\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Chemistry is one of the domains included in the GPQA benchmark<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"MMLU\" target=\"STEM\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">STEM is one of the subject areas included in the MMLU benchmark<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"MMLU\" target=\"SOCIAL SCIENCES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Social Sciences is one of the subject areas included in the MMLU benchmark<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"MMLU\" target=\"HUMANITIES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Humanities is one of the subject areas included in the MMLU benchmark<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"ARC\" target=\"CHAIN-OF-THOUGHT (COT)\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Chain-of-Thought (COT) is used as a baseline for experiments on ARC<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"ARC\" target=\"SELF-CONSISTENCY WITH CHAIN-OF-THOUGHT (COT-SC)\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Self-Consistency with Chain-of-Thought (COT-SC) is used as a baseline for experiments on ARC<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"ARC\" target=\"SELF-REFINE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Self-Refine is used as a baseline for experiments on ARC<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"ARC\" target=\"LLM-DEBATE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">LLM-Debate is used as a baseline for experiments on ARC<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"ARC\" target=\"QUALITY-DIVERSITY\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Quality-Diversity is used as a baseline for experiments on ARC<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT (COT)\" target=\"WEI ET AL., 2022\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Wei et al., 2022 is a publication referenced for the Chain-of-Thought (COT) method<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"SELF-CONSISTENCY WITH CHAIN-OF-THOUGHT (COT-SC)\" target=\"WANG ET AL., 2023B\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Wang et al., 2023b is a publication referenced for the Self-Consistency with Chain-of-Thought (COT-SC) method<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"SELF-REFINE\" target=\"MADAAN ET AL., 2024\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Madaan et al., 2024 is a publication referenced for the Self-Refine method<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"SELF-REFINE\" target=\"SHINN ET AL., 2023\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Shinn et al., 2023 is a publication referenced for the Self-Refine method<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"LLM-DEBATE\" target=\"DU ET AL., 2023\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Du et al., 2023 is a publication referenced for the LLM-Debate method<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"QUALITY-DIVERSITY\" target=\"LU ET AL., 2024C\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Lu et al., 2024c is a publication referenced for the Quality-Diversity method<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"STEP-BACK ABSTRACTION\" target=\"REASONING AND PROBLEM-SOLVING DOMAINS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Step-back Abstraction is used as a baseline for experiments on Reasoning and Problem-Solving domains<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"STEP-BACK ABSTRACTION\" target=\"ZHENG ET AL., 2023\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Zheng et al., 2023 is a publication referenced for the Step-back Abstraction method<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"ROLE ASSIGNMENT\" target=\"REASONING AND PROBLEM-SOLVING DOMAINS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Role Assignment is used as a baseline for experiments on Reasoning and Problem-Solving domains<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"ROLE ASSIGNMENT\" target=\"XU ET AL., 2023\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Xu et al., 2023 is a publication referenced for the Role Assignment method<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"BAHRAIN\" target=\"INDIANS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Indians are one of the nationalities with a significant population living in Bahrain between 2005-2009<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"BAHRAIN\" target=\"BANGLADESHIS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Bangladeshis are one of the nationalities with a significant population living in Bahrain between 2005-2009<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"BAHRAIN\" target=\"PAKISTANIS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Pakistanis are one of the nationalities with a significant population living in Bahrain between 2005-2009<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"BAHRAIN\" target=\"FILIPINOS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Filipinos are one of the nationalities with a significant population living in Bahrain between 2005-2009<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>    <edge source=\"BAHRAIN\" target=\"INDONESIANS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Indonesians are one of the nationalities with a significant population living in Bahrain between 2005-2009<\/data>      <data key=\"d5\">10fda605f670bcfccfc13c2ca0dde959<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"97457e990eb6e3c88c11c862f9e3265b","chunk":" to these baselines, we implement two more for experiments on Reasoning and\nProblem-Solving domains (Section 4.2): (6) Step-back Abstraction (Zheng et al., 2023) and (7)\nRole Assignment (Xu et al., 2023). An example implementation of Self-Refine with our simple\nframework is shown in Appendix B. Detailed implementations of all baselines can be found at\nhttps:\/\/github.com\/ShengranHu\/ADAS .\nIn COT, we prompt the FM to think step by step before answering the question. In COT-SC, we\nsample \ud835\udc41=5answers and then perform an ensemble using either majority voting or an FM query.\nIn Self-Refine, we allow up to five refinement iterations, with an early stop if the critic deems the\nanswer correct. In LLM-Debate, each debate module is assigned a unique role, such as Physics Expert\nor Chemistry Expert, and the debate lasts for two rounds. In Quality-Diversity, we conduct three\n35Automated Design of Agentic Systems\niterations to collect diverse answers based on previously proposed ones. In Role Assignment, we use\nan FM query to first choose a role from a predefined set, and then use another FM query to answer\nthe question by acting within the chosen role.\nF. Example Agents\nIn this section, we present the detailed implementation of three example discovered agents by Meta\nAgent Search shown in Figure 1. The \u201cMulti-Step Peer Review Agent\u201d and \u201cDivide and Conquer Agent\u201d\nwere discovered during the search in the Reading Comprehension domain (GPQA) (Rein et al., 2023),\nwhile the \u201cVerified Multimodal Agent\u201d was discovered during the search in the Math domain (MGSM)\n(Shietal.,2023). Alldiscoveredagentscanbefoundat https:\/\/github.com\/ShengranHu\/ADAS .\nCode 4|Example discovered agent: Multi-Step Peer Review Agent\n1def forward (self , taskInfo ):\n2 initial_instruction = \" Please think step by step and then solve\nthe task .\"\n3 critique_instruction = \" Please review the answer above and\nprovide feedback on where it might be wrong . If you are\nabsolutely sure it is correct , output \u2019True \u2019 in \u2019correct \u2019.\"\n4 refine_instruction = \" Given previous attempts and feedback ,\ncarefully consider where you could go wrong in your latest\nattempt . Using insights from previous attempts , try to solve\nthe task better .\"\n5 final_decision_instruction = \" Given all the above thinking and\nanswers , reason over them carefully and provide a final\nanswer .\"\n6\n7 FM_modules = [ FM_module ([ \u2019thinking \u2019, \u2019answer \u2019], \u2019FM Module \u2019,\nrole = role ) for role in [\u2019Physics Expert \u2019, \u2019Chemistry Expert \u2019,\n\u2019Biology Expert \u2019, \u2019Science Generalist \u2019]]\n8 critic_modules = [ FM_module ([ \u2019feedback \u2019, \u2019correct \u2019], \u2019Critic \u2019,\nrole = role ) for role in [\u2019Physics Critic \u2019, \u2019Chemistry Critic \u2019,\n\u2019Biology Critic \u2019, \u2019General Critic \u2019]]\n9 final_decision_module = FM_module ([ \u2019thinking \u2019, \u2019answer \u2019], \u2019Final\nDecision \u2019, temperature =0.1)\n10\n11 all_thinking = [[] for _ in range (len( FM_modules ))]\n12 all_answer = [[] for _ in range (len( FM_modules ))]\n13 all_feedback = [[] for _ in range (len( FM_modules ))]\n14\n15 for i in range (len( FM_modules )):\n16 thinking , answer = FM_modules [i]([ taskInfo ],\ninitial_instruction )\n17 all_thinking [i]. append ( thinking )\n18 all_answer [i]. append ( answer )\n19\n20 for i in range (len( FM_modules )):\n21 for j in range (len( FM_modules )):\n22 if i != j:\n23 feedback , correct = critic_modules [j]([ taskInfo ,\nall_thinking [i][0] , all_answer [i][0]] ,\ncritique_instruction )\n24 all_feedback [i]. append ( feedback )\n25\n36Automated Design of Agentic Systems\n26 for i in range (len( FM_modules )):\n27 refine_inputs = [ taskInfo , all_thinking [i][0] , all_answer [i\n][0]] + all_feedback [i]\n28 thinking , answer = FM_modules [i]( refine_inputs ,\nrefine_instruction )\n29 all_thinking [i]. append ( thinking )\n30 all_answer [i]. append ( answer )\n31\n32 final_inputs = [ taskInfo ] + [ all_thinking [i ][1] for i in range (\nlen( FM_modules ))] + [ all_answer [i ][1] for i in range (len(\nFM_modules ))]\n33 thinking , answer = final_decision_module ( final_inputs ,\nfinal_decision_instruction )\n34\n35 return answer\nCode 5|Example discovered agent: Divide and Conquer Agent\n1def forward (self , taskInfo ):\n2 # Step 1: Decompose the problem into sub - problems\n3 decomposition_instruction = \" Please decompose the problem into\nsmaller , manageable sub - problems . List each sub - problem\nclearly .\"\n4 decomposition_module = FM_Module ([ \u2019thinking \u2019, \u2019 sub_problems \u2019], \u2019\nDecomposition Module \u2019)\n5\n6 # Step 2: Assign each sub - problem to a specialized expert\n7 sub_problem_instruction = \" Please think step by step and then\nsolve the sub - problem .\"\n8 specialized_experts = [ FM_Module ([ \u2019thinking \u2019, \u2019 sub_solution \u2019], \u2019\nSpecialized Expert \u2019, role = role ) for role in [\u2019Physics Expert","chunk_id":"97457e990eb6e3c88c11c862f9e3265b","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":1200,"entities":[{"name":"STEP-BACK ABSTRACTION","type":"METHOD\/TECHNIQUE","description":"Step-back Abstraction is a method used in experiments on Reasoning and Problem-Solving domains","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"ZHENG ET AL., 2023","type":"PUBLICATION","description":"A publication by Zheng et al. in 2023 that discusses Step-back Abstraction","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"ROLE ASSIGNMENT","type":"METHOD\/TECHNIQUE","description":"Role Assignment is a method used in experiments on Reasoning and Problem-Solving domains","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"XU ET AL., 2023","type":"PUBLICATION","description":"A publication by Xu et al. in 2023 that discusses Role Assignment","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"SELF-REFINE","type":"METHOD\/TECHNIQUE","description":"Self-Refine is a method that allows up to five refinement iterations with an early stop if the critic deems the answer correct","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"COT","type":"METHOD\/TECHNIQUE","description":"COT is a method where the FM is prompted to think step by step before answering the question","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"COT-SC","type":"METHOD\/TECHNIQUE","description":"COT-SC is a method where 5 answers are sampled and then an ensemble is performed using either majority voting or an FM query","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"LLM-DEBATE","type":"METHOD\/TECHNIQUE","description":"LLM-Debate is a method where each debate module is assigned a unique role and the debate lasts for two rounds","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"QUALITY-DIVERSITY","type":"METHOD\/TECHNIQUE","description":"Quality-Diversity is a method where three iterations are conducted to collect diverse answers based on previously proposed ones","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"META AGENT SEARCH","type":"METHOD\/TECHNIQUE","description":"Meta Agent Search is a method used to discover agents in various domains","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"MULTI-STEP PEER REVIEW AGENT","type":"AGENT","description":"Multi-Step Peer Review Agent is an agent discovered during the search in the Reading Comprehension domain","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"DIVIDE AND CONQUER AGENT","type":"AGENT","description":"Divide and Conquer Agent is an agent discovered during the search in the Reading Comprehension domain","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"VERIFIED MULTIMODAL AGENT","type":"AGENT","description":"Verified Multimodal Agent is an agent discovered during the search in the Math domain","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"GPQA","type":"DOMAIN","description":"GPQA is the Reading Comprehension domain where the Multi-Step Peer Review Agent and Divide and Conquer Agent were discovered","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"MGSM","type":"DOMAIN","description":"MGSM is the Math domain where the Verified Multimodal Agent was discovered","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"SHI ET AL., 2023","type":"PUBLICATION","description":"A publication by Shi et al. in 2023 that discusses the Verified Multimodal Agent","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"REIN ET AL., 2023","type":"PUBLICATION","description":"A publication by Rein et al. in 2023 that discusses the Multi-Step Peer Review Agent and Divide and Conquer Agent","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"SHENGRAN HU","type":"PERSON","description":"Shengran Hu is associated with the implementation of baselines and the repository at https:\/\/github.com\/ShengranHu\/ADAS","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"ADAS","type":"REPOSITORY","description":"ADAS is a repository where detailed implementations of all baselines can be found","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"REASONING","type":"DOMAIN","description":"Reasoning is one of the domains where experiments were conducted","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"PROBLEM-SOLVING","type":"DOMAIN","description":"Problem-Solving is one of the domains where experiments were conducted","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"EXPERIMENTS","type":"PROCESS","description":"Experiments were conducted on Reasoning and Problem-Solving domains","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"FM","type":"MODEL","description":"FM is a model used in various methods like COT and COT-SC","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"PHYSICS EXPERT","type":"ROLE","description":"Physics Expert is a role assigned in the LLM-Debate method","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"CHEMISTRY EXPERT","type":"ROLE","description":"Chemistry Expert is a role assigned in the LLM-Debate method","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"PHYSICS CRITIC","type":"ROLE","description":"Physics Critic is a role assigned in the Multi-Step Peer Review Agent","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"CHEMISTRY CRITIC","type":"ROLE","description":"Chemistry Critic is a role assigned in the Multi-Step Peer Review Agent","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"BIOLOGY CRITIC","type":"ROLE","description":"Biology Critic is a role assigned in the Multi-Step Peer Review Agent","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"GENERAL CRITIC","type":"ROLE","description":"General Critic is a role assigned in the Multi-Step Peer Review Agent","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"BIOLOGY EXPERT","type":"ROLE","description":"Biology Expert is a role assigned in the LLM-Debate method","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"SCIENCE GENERALIST","type":"ROLE","description":"Science Generalist is a role assigned in the LLM-Debate method","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"FINAL DECISION","type":"ROLE","description":"Final Decision is a role assigned in the Multi-Step Peer Review Agent","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"DECOMPOSITION MODULE","type":"ROLE","description":"Decomposition Module is a role in the Divide and Conquer Agent","source_id":"97457e990eb6e3c88c11c862f9e3265b"},{"name":"SPECIALIZED EXPERT","type":"ROLE","description":"Specialized Expert is a role in the Divide and Conquer Agent","source_id":"97457e990eb6e3c88c11c862f9e3265b"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"STEP-BACK ABSTRACTION\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Step-back Abstraction is a method used in experiments on Reasoning and Problem-Solving domains<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"ZHENG ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Zheng et al. in 2023 that discusses Step-back Abstraction<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"ROLE ASSIGNMENT\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Role Assignment is a method used in experiments on Reasoning and Problem-Solving domains<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"XU ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Xu et al. in 2023 that discusses Role Assignment<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"SELF-REFINE\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Self-Refine is a method that allows up to five refinement iterations with an early stop if the critic deems the answer correct<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"COT\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">COT is a method where the FM is prompted to think step by step before answering the question<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"COT-SC\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">COT-SC is a method where 5 answers are sampled and then an ensemble is performed using either majority voting or an FM query<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"LLM-DEBATE\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">LLM-Debate is a method where each debate module is assigned a unique role and the debate lasts for two rounds<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"QUALITY-DIVERSITY\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Quality-Diversity is a method where three iterations are conducted to collect diverse answers based on previously proposed ones<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"META AGENT SEARCH\">      <data key=\"d0\">METHOD\/TECHNIQUE<\/data>      <data key=\"d1\">Meta Agent Search is a method used to discover agents in various domains<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"MULTI-STEP PEER REVIEW AGENT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Multi-Step Peer Review Agent is an agent discovered during the search in the Reading Comprehension domain<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"DIVIDE AND CONQUER AGENT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Divide and Conquer Agent is an agent discovered during the search in the Reading Comprehension domain<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"VERIFIED MULTIMODAL AGENT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">Verified Multimodal Agent is an agent discovered during the search in the Math domain<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"GPQA\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">GPQA is the Reading Comprehension domain where the Multi-Step Peer Review Agent and Divide and Conquer Agent were discovered<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"MGSM\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">MGSM is the Math domain where the Verified Multimodal Agent was discovered<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"SHI ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Shi et al. in 2023 that discusses the Verified Multimodal Agent<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"REIN ET AL., 2023\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">A publication by Rein et al. in 2023 that discusses the Multi-Step Peer Review Agent and Divide and Conquer Agent<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"SHENGRAN HU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shengran Hu is associated with the implementation of baselines and the repository at https:\/\/github.com\/ShengranHu\/ADAS<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"ADAS\">      <data key=\"d0\">REPOSITORY<\/data>      <data key=\"d1\">ADAS is a repository where detailed implementations of all baselines can be found<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"REASONING\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">Reasoning is one of the domains where experiments were conducted<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"PROBLEM-SOLVING\">      <data key=\"d0\">DOMAIN<\/data>      <data key=\"d1\">Problem-Solving is one of the domains where experiments were conducted<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"EXPERIMENTS\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Experiments were conducted on Reasoning and Problem-Solving domains<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"FM\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">FM is a model used in various methods like COT and COT-SC<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"PHYSICS EXPERT\">      <data key=\"d0\">ROLE<\/data>      <data key=\"d1\">Physics Expert is a role assigned in the LLM-Debate method<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"CHEMISTRY EXPERT\">      <data key=\"d0\">ROLE<\/data>      <data key=\"d1\">Chemistry Expert is a role assigned in the LLM-Debate method<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"PHYSICS CRITIC\">      <data key=\"d0\">ROLE<\/data>      <data key=\"d1\">Physics Critic is a role assigned in the Multi-Step Peer Review Agent<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"CHEMISTRY CRITIC\">      <data key=\"d0\">ROLE<\/data>      <data key=\"d1\">Chemistry Critic is a role assigned in the Multi-Step Peer Review Agent<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"BIOLOGY CRITIC\">      <data key=\"d0\">ROLE<\/data>      <data key=\"d1\">Biology Critic is a role assigned in the Multi-Step Peer Review Agent<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"GENERAL CRITIC\">      <data key=\"d0\">ROLE<\/data>      <data key=\"d1\">General Critic is a role assigned in the Multi-Step Peer Review Agent<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"BIOLOGY EXPERT\">      <data key=\"d0\">ROLE<\/data>      <data key=\"d1\">Biology Expert is a role assigned in the LLM-Debate method<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"SCIENCE GENERALIST\">      <data key=\"d0\">ROLE<\/data>      <data key=\"d1\">Science Generalist is a role assigned in the LLM-Debate method<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"FINAL DECISION\">      <data key=\"d0\">ROLE<\/data>      <data key=\"d1\">Final Decision is a role assigned in the Multi-Step Peer Review Agent<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"DECOMPOSITION MODULE\">      <data key=\"d0\">ROLE<\/data>      <data key=\"d1\">Decomposition Module is a role in the Divide and Conquer Agent<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <node id=\"SPECIALIZED EXPERT\">      <data key=\"d0\">ROLE<\/data>      <data key=\"d1\">Specialized Expert is a role in the Divide and Conquer Agent<\/data>      <data key=\"d2\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/node>    <edge source=\"STEP-BACK ABSTRACTION\" target=\"ZHENG ET AL., 2023\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Step-back Abstraction is discussed in the publication by Zheng et al. in 2023<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"ROLE ASSIGNMENT\" target=\"XU ET AL., 2023\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Role Assignment is discussed in the publication by Xu et al. in 2023<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"SELF-REFINE\" target=\"SHENGRAN HU\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Shengran Hu is associated with the implementation of Self-Refine<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"COT\" target=\"FM\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">FM is prompted to think step by step in the COT method<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"COT-SC\" target=\"FM\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">FM is used to sample answers and perform an ensemble in the COT-SC method<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"LLM-DEBATE\" target=\"PHYSICS EXPERT\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Physics Expert is a role assigned in the LLM-Debate method<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"LLM-DEBATE\" target=\"CHEMISTRY EXPERT\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Chemistry Expert is a role assigned in the LLM-Debate method<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"LLM-DEBATE\" target=\"BIOLOGY EXPERT\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Biology Expert is a role assigned in the LLM-Debate method<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"LLM-DEBATE\" target=\"SCIENCE GENERALIST\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Science Generalist is a role assigned in the LLM-Debate method<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"MULTI-STEP PEER REVIEW AGENT\" target=\"GPQA\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Multi-Step Peer Review Agent was discovered in the GPQA domain<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"MULTI-STEP PEER REVIEW AGENT\" target=\"REIN ET AL., 2023\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Multi-Step Peer Review Agent is discussed in the publication by Rein et al. in 2023<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"MULTI-STEP PEER REVIEW AGENT\" target=\"PHYSICS CRITIC\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Physics Critic is a role assigned in the Multi-Step Peer Review Agent<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"MULTI-STEP PEER REVIEW AGENT\" target=\"CHEMISTRY CRITIC\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Chemistry Critic is a role assigned in the Multi-Step Peer Review Agent<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"MULTI-STEP PEER REVIEW AGENT\" target=\"BIOLOGY CRITIC\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Biology Critic is a role assigned in the Multi-Step Peer Review Agent<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"MULTI-STEP PEER REVIEW AGENT\" target=\"GENERAL CRITIC\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">General Critic is a role assigned in the Multi-Step Peer Review Agent<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"MULTI-STEP PEER REVIEW AGENT\" target=\"FINAL DECISION\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Final Decision is a role assigned in the Multi-Step Peer Review Agent<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"DIVIDE AND CONQUER AGENT\" target=\"GPQA\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Divide and Conquer Agent was discovered in the GPQA domain<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"DIVIDE AND CONQUER AGENT\" target=\"REIN ET AL., 2023\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Divide and Conquer Agent is discussed in the publication by Rein et al. in 2023<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"DIVIDE AND CONQUER AGENT\" target=\"DECOMPOSITION MODULE\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Decomposition Module is a role in the Divide and Conquer Agent<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"DIVIDE AND CONQUER AGENT\" target=\"SPECIALIZED EXPERT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Specialized Expert is a role in the Divide and Conquer Agent<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"VERIFIED MULTIMODAL AGENT\" target=\"MGSM\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Verified Multimodal Agent was discovered in the MGSM domain<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"VERIFIED MULTIMODAL AGENT\" target=\"SHI ET AL., 2023\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Verified Multimodal Agent is discussed in the publication by Shi et al. in 2023<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"SHENGRAN HU\" target=\"ADAS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Shengran Hu is associated with the ADAS repository<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"REASONING\" target=\"EXPERIMENTS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Experiments were conducted on the Reasoning domain<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>    <edge source=\"PROBLEM-SOLVING\" target=\"EXPERIMENTS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Experiments were conducted on the Problem-Solving domain<\/data>      <data key=\"d5\">97457e990eb6e3c88c11c862f9e3265b<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"ef75d2c866bee783577ed9f65707cf13","chunk":"4 decomposition_module = FM_Module ([ \u2019thinking \u2019, \u2019 sub_problems \u2019], \u2019\nDecomposition Module \u2019)\n5\n6 # Step 2: Assign each sub - problem to a specialized expert\n7 sub_problem_instruction = \" Please think step by step and then\nsolve the sub - problem .\"\n8 specialized_experts = [ FM_Module ([ \u2019thinking \u2019, \u2019 sub_solution \u2019], \u2019\nSpecialized Expert \u2019, role = role ) for role in [\u2019Physics Expert \u2019\n, \u2019Chemistry Expert \u2019, \u2019Biology Expert \u2019, \u2019General Expert \u2019]]\n9\n10 # Step 3: Integrate the sub - problem solutions into the final\nanswer\n11 integration_instruction = \" Given the solutions to the sub -\nproblems , integrate them to provide a final answer to the\noriginal problem .\"\n12 integration_module = FM_Module ([ \u2019thinking \u2019, \u2019answer \u2019], \u2019\nIntegration Module \u2019, temperature =0.1)\n13\n14 # Decompose the problem\n15 thinking , sub_problems = decomposition_module ([ taskInfo ],\ndecomposition_instruction )\n16\n17 # Ensure sub_problems is a string and split into individual sub -\nproblems\n18 sub_problems_list = sub_problems . content . split (\u2019\\n\u2019) if\nisinstance ( sub_problems . content , str) else []\n19\n20 # Solve each sub - problem\n21 sub_solutions = []\n22 for i, sub_problem in enumerate ( sub_problems_list ):\n23 sub_problem_info = Info (\u2019 sub_problem \u2019, decomposition_module .\n__repr__ () , sub_problem , i)\n24 sub_thinking , sub_solution = specialized_experts [i % len (\n37Automated Design of Agentic Systems\nspecialized_experts )]([ sub_problem_info ],\nsub_problem_instruction )\n25 sub_solutions . append ( sub_solution )\n26\n27 # Integrate the sub - problem solutions\n28 integration_inputs = [ taskInfo ] + sub_solutions\n29 thinking , answer = integration_module ( integration_inputs ,\nintegration_instruction )\n30\n31 return answer\nCode 6|Example discovered agent: Verified Multimodal Agent\n1def forward (self , taskInfo ):\n2 # Instruction for generating visual representation of the\nproblem\n3 visual_instruction = \" Please create a visual representation (e.g\n., diagram , graph ) of the given problem .\"\n4\n5 # Instruction for verifying the visual representation\n6 verification_instruction = \" Please verify the accuracy and\nrelevance of the visual representation . Provide feedback and\nsuggestions for improvement if necessary .\"\n7\n8 # Instruction for solving the problem using the verified visual\naid\n9 cot_instruction = \" Using the provided visual representation ,\nthink step by step and solve the problem .\"\n10\n11 # Instantiate the visual representation module , verification\nmodule , and Chain -of - Thought module\n12 visual_module = FM_Module ([ \u2019visual \u2019], \u2019Visual Representation\nModule \u2019)\n13 verification_module = FM_Module ([ \u2019feedback \u2019, \u2019 verified_visual \u2019],\n\u2019 Verification Module \u2019)\n14 cot_module = FM_Module ([ \u2019thinking \u2019, \u2019answer \u2019], \u2019Chain -of - Thought\nModule \u2019)\n15\n16 # Generate the visual representation of the problem\n17 visual_output = visual_module ([ taskInfo ], visual_instruction )\n18 visual_representation = visual_output [0] # Using Info object\ndirectly\n19\n20 # Verify the visual representation\n21 feedback , verified_visual = verification_module ([ taskInfo ,\nvisual_representation ], verification_instruction )\n22\n23 # Use the verified visual representation to solve the problem\n24 thinking , answer = cot_module ([ taskInfo , verified_visual ],\ncot_instruction )\n25 return answer\n38Automated Design of Agentic Systems\nG. Cost of Experiments\nA single run of search and evaluation on ARC (Section 4.1) costs approximately $500 USD in OpenAI\nAPI costs, while a run within the reasoning and problem-solving domains (Section 4.2) costs about\n$300 USD.\nThe primary expense comes from querying the \u201cgpt-3.5-turbo-0125\u201d model during the evaluation\nof discovered agents. Notably, the latest GPT-4 model, \u201cgpt-4o-mini,\u201d is less than one-third the price\nof \u201cgpt-3.5-turbo-0125\u201d and offers better performance, suggesting that we could achieve improved\nresults with Meta Agent Search at just one-third of the cost. Additionally, as discussed in Section 6, the\ncurrent naive evaluation function is both expensive and overlooks valuable information. We anticipate\nthat future work adopting more sophisticated evaluation functions could significantly reduce the cost\nof ADAS algorithms.\n39","chunk_id":"ef75d2c866bee783577ed9f65707cf13","document_ids":["59656444e942d1316dac3a6c8f1827a5"],"n_tokens":964,"entities":[{"name":"DECOMPOSITION MODULE","type":"TOOL\/MODULE","description":"A module named FM_Module used for decomposing a problem into sub-problems","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"SPECIALIZED EXPERT","type":"TOOL\/MODULE","description":"A module named FM_Module used for solving specific sub-problems, with roles such as Physics Expert, Chemistry Expert, Biology Expert, and General Expert","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"INTEGRATION MODULE","type":"TOOL\/MODULE","description":"A module named FM_Module used for integrating solutions to sub-problems into a final answer","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"TASKINFO","type":"DATA\/INPUT","description":"The input information or task that needs to be processed and solved","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"SUB_PROBLEMS","type":"DATA\/OUTPUT","description":"The decomposed parts of the main problem generated by the Decomposition Module","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"SUB_SOLUTIONS","type":"DATA\/OUTPUT","description":"The solutions to the sub-problems generated by the Specialized Experts","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"ANSWER","type":"DATA\/OUTPUT","description":"The final solution to the original problem after integrating sub-solutions","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"VERIFIED MULTIMODAL AGENT","type":"AGENT","description":"An agent designed to solve problems using visual representations and verification processes","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"VISUAL REPRESENTATION MODULE","type":"TOOL\/MODULE","description":"A module named FM_Module used for generating visual representations of problems","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"VERIFICATION MODULE","type":"TOOL\/MODULE","description":"A module named FM_Module used for verifying the accuracy and relevance of visual representations","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"CHAIN-OF-THOUGHT MODULE","type":"TOOL\/MODULE","description":"A module named FM_Module used for solving problems using verified visual aids","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"ARC","type":"DATASET","description":"A dataset used for search and evaluation experiments","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"GPT-3.5-TURBO-0125","type":"MODEL","description":"A version of OpenAI's language model used during the evaluation of discovered agents","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"GPT-4O-MINI","type":"MODEL","description":"A newer version of OpenAI's language model that is less expensive and offers better performance than GPT-3.5-Turbo-0125","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"META AGENT SEARCH","type":"PROCESS","description":"A process that aims to improve results and reduce costs in agent discovery and evaluation","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"ADAS ALGORITHMS","type":"ALGORITHM","description":"Algorithms used in the Automated Design of Agentic Systems","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"FM_MODULE","type":"TOOL\/MODULE","description":"A module used in various stages of problem-solving, including decomposition, specialization, and integration","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"PHYSICS EXPERT","type":"TOOL\/MODULE","description":"A specialized expert module focused on solving sub-problems related to physics","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"CHEMISTRY EXPERT","type":"TOOL\/MODULE","description":"A specialized expert module focused on solving sub-problems related to chemistry","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"BIOLOGY EXPERT","type":"TOOL\/MODULE","description":"A specialized expert module focused on solving sub-problems related to biology","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"GENERAL EXPERT","type":"TOOL\/MODULE","description":"A specialized expert module focused on solving general sub-problems","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"DECOMPOSITION INSTRUCTION","type":"DATA\/INPUT","description":"The instruction provided to the Decomposition Module to decompose the main task","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"SUB_PROBLEM INSTRUCTION","type":"DATA\/INPUT","description":"The instruction provided to specialized experts to solve sub-problems step by step","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"INTEGRATION INSTRUCTION","type":"DATA\/INPUT","description":"The instruction provided to the Integration Module to integrate sub-solutions into a final answer","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"INFO","type":"DATA\/INPUT","description":"An object used to encapsulate information about sub-problems and their solutions","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"VISUAL INSTRUCTION","type":"DATA\/INPUT","description":"The instruction provided to the Visual Representation Module to create a visual representation of the problem","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"VERIFICATION INSTRUCTION","type":"DATA\/INPUT","description":"The instruction provided to the Verification Module to verify the accuracy and relevance of the visual representation","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"COT INSTRUCTION","type":"DATA\/INPUT","description":"The instruction provided to the Chain-of-Thought Module to solve the problem using the verified visual aid","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"OPENAI API","type":"SERVICE","description":"The API service used for querying models like GPT-3.5-Turbo-0125 and GPT-4o-Mini","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"EXPERIMENT COST","type":"DATA\/OUTPUT","description":"The cost associated with running search and evaluation experiments using the OpenAI API","source_id":"ef75d2c866bee783577ed9f65707cf13"},{"name":"EVALUATION FUNCTION","type":"PROCESS","description":"A function used to evaluate the performance of discovered agents, which can be optimized to reduce costs","source_id":"ef75d2c866bee783577ed9f65707cf13"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"DECOMPOSITION MODULE\">      <data key=\"d0\">TOOL\/MODULE<\/data>      <data key=\"d1\">A module named FM_Module used for decomposing a problem into sub-problems<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"SPECIALIZED EXPERT\">      <data key=\"d0\">TOOL\/MODULE<\/data>      <data key=\"d1\">A module named FM_Module used for solving specific sub-problems, with roles such as Physics Expert, Chemistry Expert, Biology Expert, and General Expert<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"INTEGRATION MODULE\">      <data key=\"d0\">TOOL\/MODULE<\/data>      <data key=\"d1\">A module named FM_Module used for integrating solutions to sub-problems into a final answer<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"TASKINFO\">      <data key=\"d0\">DATA\/INPUT<\/data>      <data key=\"d1\">The input information or task that needs to be processed and solved<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"SUB_PROBLEMS\">      <data key=\"d0\">DATA\/OUTPUT<\/data>      <data key=\"d1\">The decomposed parts of the main problem generated by the Decomposition Module<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"SUB_SOLUTIONS\">      <data key=\"d0\">DATA\/OUTPUT<\/data>      <data key=\"d1\">The solutions to the sub-problems generated by the Specialized Experts<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"ANSWER\">      <data key=\"d0\">DATA\/OUTPUT<\/data>      <data key=\"d1\">The final solution to the original problem after integrating sub-solutions<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"VERIFIED MULTIMODAL AGENT\">      <data key=\"d0\">AGENT<\/data>      <data key=\"d1\">An agent designed to solve problems using visual representations and verification processes<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"VISUAL REPRESENTATION MODULE\">      <data key=\"d0\">TOOL\/MODULE<\/data>      <data key=\"d1\">A module named FM_Module used for generating visual representations of problems<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"VERIFICATION MODULE\">      <data key=\"d0\">TOOL\/MODULE<\/data>      <data key=\"d1\">A module named FM_Module used for verifying the accuracy and relevance of visual representations<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"CHAIN-OF-THOUGHT MODULE\">      <data key=\"d0\">TOOL\/MODULE<\/data>      <data key=\"d1\">A module named FM_Module used for solving problems using verified visual aids<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"ARC\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset used for search and evaluation experiments<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"GPT-3.5-TURBO-0125\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">A version of OpenAI's language model used during the evaluation of discovered agents<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"GPT-4O-MINI\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">A newer version of OpenAI's language model that is less expensive and offers better performance than GPT-3.5-Turbo-0125<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"META AGENT SEARCH\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">A process that aims to improve results and reduce costs in agent discovery and evaluation<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"ADAS ALGORITHMS\">      <data key=\"d0\">ALGORITHM<\/data>      <data key=\"d1\">Algorithms used in the Automated Design of Agentic Systems<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"FM_MODULE\">      <data key=\"d0\">TOOL\/MODULE<\/data>      <data key=\"d1\">A module used in various stages of problem-solving, including decomposition, specialization, and integration<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"PHYSICS EXPERT\">      <data key=\"d0\">TOOL\/MODULE<\/data>      <data key=\"d1\">A specialized expert module focused on solving sub-problems related to physics<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"CHEMISTRY EXPERT\">      <data key=\"d0\">TOOL\/MODULE<\/data>      <data key=\"d1\">A specialized expert module focused on solving sub-problems related to chemistry<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"BIOLOGY EXPERT\">      <data key=\"d0\">TOOL\/MODULE<\/data>      <data key=\"d1\">A specialized expert module focused on solving sub-problems related to biology<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"GENERAL EXPERT\">      <data key=\"d0\">TOOL\/MODULE<\/data>      <data key=\"d1\">A specialized expert module focused on solving general sub-problems<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"DECOMPOSITION INSTRUCTION\">      <data key=\"d0\">DATA\/INPUT<\/data>      <data key=\"d1\">The instruction provided to the Decomposition Module to decompose the main task<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"SUB_PROBLEM INSTRUCTION\">      <data key=\"d0\">DATA\/INPUT<\/data>      <data key=\"d1\">The instruction provided to specialized experts to solve sub-problems step by step<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"INTEGRATION INSTRUCTION\">      <data key=\"d0\">DATA\/INPUT<\/data>      <data key=\"d1\">The instruction provided to the Integration Module to integrate sub-solutions into a final answer<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"INFO\">      <data key=\"d0\">DATA\/INPUT<\/data>      <data key=\"d1\">An object used to encapsulate information about sub-problems and their solutions<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"VISUAL INSTRUCTION\">      <data key=\"d0\">DATA\/INPUT<\/data>      <data key=\"d1\">The instruction provided to the Visual Representation Module to create a visual representation of the problem<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"VERIFICATION INSTRUCTION\">      <data key=\"d0\">DATA\/INPUT<\/data>      <data key=\"d1\">The instruction provided to the Verification Module to verify the accuracy and relevance of the visual representation<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"COT INSTRUCTION\">      <data key=\"d0\">DATA\/INPUT<\/data>      <data key=\"d1\">The instruction provided to the Chain-of-Thought Module to solve the problem using the verified visual aid<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"OPENAI API\">      <data key=\"d0\">SERVICE<\/data>      <data key=\"d1\">The API service used for querying models like GPT-3.5-Turbo-0125 and GPT-4o-Mini<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"EXPERIMENT COST\">      <data key=\"d0\">DATA\/OUTPUT<\/data>      <data key=\"d1\">The cost associated with running search and evaluation experiments using the OpenAI API<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <node id=\"EVALUATION FUNCTION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">A function used to evaluate the performance of discovered agents, which can be optimized to reduce costs<\/data>      <data key=\"d2\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/node>    <edge source=\"DECOMPOSITION MODULE\" target=\"SUB_PROBLEMS\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The Decomposition Module generates sub-problems from the main task<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"DECOMPOSITION MODULE\" target=\"TASKINFO\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">TaskInfo is the input for the Decomposition Module<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"DECOMPOSITION MODULE\" target=\"FM_MODULE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Decomposition Module is an instance of FM_Module<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"DECOMPOSITION MODULE\" target=\"DECOMPOSITION INSTRUCTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Decomposition Module uses the decomposition instruction to break down the main task<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"SPECIALIZED EXPERT\" target=\"SUB_SOLUTIONS\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Specialized Experts generate solutions to the sub-problems<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"SPECIALIZED EXPERT\" target=\"SUB_PROBLEMS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Sub-problems are solved by Specialized Experts<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"SPECIALIZED EXPERT\" target=\"FM_MODULE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Specialized Experts are instances of FM_Module<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"SPECIALIZED EXPERT\" target=\"SUB_PROBLEM INSTRUCTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Specialized Experts use the sub-problem instruction to solve sub-problems<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"INTEGRATION MODULE\" target=\"ANSWER\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The Integration Module combines sub-solutions to form the final answer<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"INTEGRATION MODULE\" target=\"SUB_SOLUTIONS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Sub-solutions are integrated by the Integration Module<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"INTEGRATION MODULE\" target=\"FM_MODULE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Integration Module is an instance of FM_Module<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"INTEGRATION MODULE\" target=\"INTEGRATION INSTRUCTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Integration Module uses the integration instruction to combine sub-solutions<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"VERIFIED MULTIMODAL AGENT\" target=\"VISUAL REPRESENTATION MODULE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Verified Multimodal Agent uses the Visual Representation Module to generate visual aids<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"VERIFIED MULTIMODAL AGENT\" target=\"VERIFICATION MODULE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Verified Multimodal Agent uses the Verification Module to verify visual aids<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"VERIFIED MULTIMODAL AGENT\" target=\"CHAIN-OF-THOUGHT MODULE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Verified Multimodal Agent uses the Chain-of-Thought Module to solve problems<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"VISUAL REPRESENTATION MODULE\" target=\"FM_MODULE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Visual Representation Module is an instance of FM_Module<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"VISUAL REPRESENTATION MODULE\" target=\"VISUAL INSTRUCTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Visual Representation Module uses the visual instruction to create visual aids<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"VERIFICATION MODULE\" target=\"FM_MODULE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Verification Module is an instance of FM_Module<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"VERIFICATION MODULE\" target=\"VERIFICATION INSTRUCTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Verification Module uses the verification instruction to verify visual aids<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT MODULE\" target=\"FM_MODULE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Chain-of-Thought Module is an instance of FM_Module<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"CHAIN-OF-THOUGHT MODULE\" target=\"COT INSTRUCTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Chain-of-Thought Module uses the CoT instruction to solve problems<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"ARC\" target=\"GPT-3.5-TURBO-0125\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">ARC dataset is evaluated using GPT-3.5-Turbo-0125<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"GPT-3.5-TURBO-0125\" target=\"OPENAI API\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">GPT-3.5-Turbo-0125 is queried using the OpenAI API<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"GPT-4O-MINI\" target=\"META AGENT SEARCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">GPT-4o-Mini is used in Meta Agent Search to improve results and reduce costs<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"GPT-4O-MINI\" target=\"OPENAI API\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">GPT-4o-Mini is queried using the OpenAI API<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"ADAS ALGORITHMS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">ADAS algorithms are used in the Meta Agent Search process<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"META AGENT SEARCH\" target=\"EVALUATION FUNCTION\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The evaluation function is used in the Meta Agent Search process<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"OPENAI API\" target=\"EXPERIMENT COST\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The cost of experiments is primarily due to querying the OpenAI API<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>    <edge source=\"EXPERIMENT COST\" target=\"EVALUATION FUNCTION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Optimizing the evaluation function can reduce the cost of experiments<\/data>      <data key=\"d5\">ef75d2c866bee783577ed9f65707cf13<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"6fe27f9eb76cf2ddf712a2cee5783d1c","chunk":"AgentInstruct:\nToward Generative Teaching with Agentic\nFlows\nArindam Mitra, Luciano Del Corro, Guoqing Zheng, Shweti Mahajan,\nDany Rouhana, Andres Codas, Yadong Lu, Wei-ge Chen, Olga Vrousgos,\nCorby Rosset, Fillipe Silva, Hamed Khanpour, Yash Lara, Ahmed Awadallah\nMicrosoft Research\nAbstract\nSynthetic data is becoming increasingly important for accelerating the development of\nlanguage models, both large and small. Despite several successful use cases, researchers\nalso raised concerns around model collapse and drawbacks of imitating other models. This\ndiscrepancy can be attributed to the fact that synthetic data varies in quality and diversity.\nEffective use of synthetic data usually requires significant human effort in curating the data.\nWe focus on using synthetic data for post-training, specifically creating data by powerful\nmodels to teach a new skill or behavior to another model, we refer to this setting as Generative\nTeaching . We introduce AgentInstruct, an extensible agentic framework for automatically\ncreating large amounts of diverse and high-quality synthetic data. AgentInstruct can create\nboth the prompts and responses, using only raw data sources like text documents and code\nfiles as seeds. We demonstrate the utility of AgentInstruct by creating a post training dataset\nof 25M pairs to teach language models different skills, such as text editing, creative writing,\ntool usage, coding, reading comprehension, etc. The dataset can be used for instruction\ntuning of any base model. We post-train Mistral-7b with the data. When comparing\nthe resulting model (Orca-3) to Mistral-7b-Instruct (which uses the same base model), we\nobserve significant improvements across many benchmarks. For example, 40% improvement\non AGIEval, 19% improvement on MMLU, 54% improvement on GSM8K, 38% improvement\non BBH and 45% improvement on AlpacaEval. Additionally, it consistently outperforms\nother models such as LLAMA-8B-instruct and GPT-3.5-turbo.\n \n 0102030405060AGIEVAL\n010203040506070MMLU\n010203040506070BBH\n0102030405060708090GSM8K\n0510152025ALPACA\nEVAL\n0102030405060708090FOFO\n010203040506070MIRAGE -\nRAG\n+40.2%  +19.4 % \n+38.3 % +53.7%  \n+45.0% +38.3%  \n+46.6% \nMistral -Instruct -7B Mistra l-7B + AgentInstruct (Orca -3) \nFigure 1: Effect of using AgentInstruct data for post-training Mistral-7BarXiv:2407.03502v1  [cs.AI]  3 Jul 20241 Introduction\nSynthetic data accelerated the development of LLMS : The rise of synthetic data in\nthe training of Large Language Models (LLMs) has been a significant development of the\nlast year. Synthetic data was used to significantly accelerate the progress of model training\n(especially SLMs) in all stages of training from pre-training (e.g., [ 1]), to instruction-tuning\n(e.g., [21, 36]) and RLHF(e.g., [12, 28]).\nGenerating high quality synthetic data is hard : On the other hand, research has also\nshown that pre-training models on synthetic data generated by other models can lead to\nmodel collapse [ 29], leading to models gradually degenerating as a result. Similar arguments\nhave been made against using synthetic data for pos-training, which could amount to an\nimitation process that could teach the trained model to pick only stylistic characteristics\nand not real capabilities [ 8]. This discrepancy could be explained by the observation that\ncreating high-quality and diverse synthetic data is hard [ 17]. Successful use of synthetic data\ninvolved significant human effort in curating and filtering the data to ensure high quality. If\nwe focus on post-training synthetic data, we will see the most widely used approach includes\nstarting with a set of prompts and using a powerful model such as GPT-4 [ 22] to generate\nresponses to these prompts [ 24] or of an expanded set of the prompts [ 36]. This recipe\nwas further improved by eliciting explanations or step-by-step instructions from the teacher\nmodel [20] or using more complex prompting techniques to elicit higher quality answers [ 18].\nSynthetic data meets Agents : Another major development we witnessed last year is the\nrise of Agentic (especially multiagent) workflows [ 33,13]. Agentic workflows can generate\nhigh quality data, that surpasses the capabilities of the underlying LLMs, by using flows\nwith reflection and iteration, where agents can look back at solutions, generate critiques and\nimprove solutions. They can also use tools (e.g. search apis, calculator, code interpreters)\naddressing limitations of LLMs. Multi-agent workflows bring in additional benefits such\nas simulating scenarios where we can generate both new prompts and the corresponding\nresponses. They also enable automation of the data generation workflows reducing or\neliminating need for human intervention on some tasks.\nGenerative Teaching & Orca AgentInstruct : Generating synthetic data for post-\ntraining often relies on an existing prompt set that is used as is or used as seeds for\ngenerating more instructions. In this work, we generalize the problem settings to a broader\nobjective of generating abundant amounts of diverse, challenging and high-quality data to\nte","chunk_id":"6fe27f9eb76cf2ddf712a2cee5783d1c","document_ids":["c5a70861b9987da7046fe2110eb3616c"],"n_tokens":1200,"entities":[{"name":"AGENTINSTRUCT","type":"TOOL\/FRAMEWORK","description":"AgentInstruct is an extensible agentic framework for automatically creating large amounts of diverse and high-quality synthetic data","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"GENERATIVE TEACHING","type":"CONCEPT\/PROCESS","description":"Generative Teaching refers to the process of using synthetic data created by powerful models to teach a new skill or behavior to another model","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"ARINDAM MITRA","type":"PERSON","description":"Arindam Mitra is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"LUCIANO DEL CORRO","type":"PERSON","description":"Luciano Del Corro is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"GUOQING ZHENG","type":"PERSON","description":"Guoqing Zheng is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"SHWETI MAHAJAN","type":"PERSON","description":"Shweti Mahajan is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"DANY ROUHANA","type":"PERSON","description":"Dany Rouhana is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"ANDRES CODAS","type":"PERSON","description":"Andres Codas is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"YADONG LU","type":"PERSON","description":"Yadong Lu is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"WEI-GE CHEN","type":"PERSON","description":"Wei-ge Chen is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"OLGA VROUSGOS","type":"PERSON","description":"Olga Vrousgos is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"CORBY ROSSET","type":"PERSON","description":"Corby Rosset is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"FILLIPE SILVA","type":"PERSON","description":"Fillipe Silva is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"HAMED KHANPOUR","type":"PERSON","description":"Hamed Khanpour is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"YASH LARA","type":"PERSON","description":"Yash Lara is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"AHMED AWADALLAH","type":"PERSON","description":"Ahmed Awadallah is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"MICROSOFT RESEARCH","type":"ORGANIZATION","description":"Microsoft Research is the organization where the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\" are affiliated","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"SYNTHETIC DATA","type":"CONCEPT\/DATA","description":"Synthetic data refers to data that is artificially generated rather than obtained by direct measurement","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"MISTRAL-7B","type":"MODEL","description":"Mistral-7b is a base language model that was post-trained using data generated by AgentInstruct","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"ORCA-3","type":"MODEL","description":"Orca-3 is the resulting model after post-training Mistral-7b with data generated by AgentInstruct","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"AGIEVAL","type":"BENCHMARK","description":"AGIEval is a benchmark used to evaluate the performance of language models","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"MMLU","type":"BENCHMARK","description":"MMLU is a benchmark used to evaluate the performance of language models","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"GSM8K","type":"BENCHMARK","description":"GSM8K is a benchmark used to evaluate the performance of language models","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"BBH","type":"BENCHMARK","description":"BBH is a benchmark used to evaluate the performance of language models","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"ALPACAEVAL","type":"BENCHMARK","description":"AlpacaEval is a benchmark used to evaluate the performance of language models","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"LLAMA-8B-INSTRUCT","type":"MODEL","description":"LLAMA-8B-instruct is a language model that was outperformed by Orca-3","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"GPT-3.5-TURBO","type":"MODEL","description":"GPT-3.5-turbo is a language model that was outperformed by Orca-3","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"LLMS","type":"CONCEPT","description":"LLMs, or Large Language Models, are advanced language models that have been significantly developed using synthetic data","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"SLMS","type":"CONCEPT","description":"SLMs, or Small Language Models, are smaller language models that also benefit from synthetic data in their training","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"GPT-4","type":"MODEL","description":"GPT-4 is a powerful language model used to generate responses to prompts for creating synthetic data","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"RLHF","type":"CONCEPT\/PROCESS","description":"RLHF, or Reinforcement Learning from Human Feedback, is a process used in the training of language models","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"AGENTIC WORKFLOWS","type":"CONCEPT\/PROCESS","description":"Agentic workflows involve using agents to generate high-quality data through reflection, iteration, and tool usage","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"MULTI-AGENT WORKFLOWS","type":"CONCEPT\/PROCESS","description":"Multi-agent workflows involve multiple agents working together to generate new prompts and responses, simulating scenarios and automating data generation","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"MISTRAL-7B-INSTRUCT","type":"MODEL","description":"Mistral-7b-Instruct is a version of the Mistral-7b model used for comparison with Orca-3","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"FOFO","type":"BENCHMARK","description":"FOFO is a benchmark used to evaluate the performance of language models","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"},{"name":"MIRAGE-RAG","type":"BENCHMARK","description":"MIRAGE-RAG is a benchmark used to evaluate the performance of language models","source_id":"6fe27f9eb76cf2ddf712a2cee5783d1c"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"AGENTINSTRUCT\">      <data key=\"d0\">TOOL\/FRAMEWORK<\/data>      <data key=\"d1\">AgentInstruct is an extensible agentic framework for automatically creating large amounts of diverse and high-quality synthetic data<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"GENERATIVE TEACHING\">      <data key=\"d0\">CONCEPT\/PROCESS<\/data>      <data key=\"d1\">Generative Teaching refers to the process of using synthetic data created by powerful models to teach a new skill or behavior to another model<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"ARINDAM MITRA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Arindam Mitra is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"LUCIANO DEL CORRO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Luciano Del Corro is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"GUOQING ZHENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Guoqing Zheng is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"SHWETI MAHAJAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shweti Mahajan is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"DANY ROUHANA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dany Rouhana is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"ANDRES CODAS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Andres Codas is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"YADONG LU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yadong Lu is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"WEI-GE CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wei-ge Chen is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"OLGA VROUSGOS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Olga Vrousgos is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"CORBY ROSSET\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Corby Rosset is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"FILLIPE SILVA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Fillipe Silva is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"HAMED KHANPOUR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hamed Khanpour is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"YASH LARA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yash Lara is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"AHMED AWADALLAH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ahmed Awadallah is one of the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\"<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"MICROSOFT RESEARCH\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Microsoft Research is the organization where the authors of the paper \"AgentInstruct: Toward Generative Teaching with Agentic Flows\" are affiliated<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"SYNTHETIC DATA\">      <data key=\"d0\">CONCEPT\/DATA<\/data>      <data key=\"d1\">Synthetic data refers to data that is artificially generated rather than obtained by direct measurement<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"MISTRAL-7B\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Mistral-7b is a base language model that was post-trained using data generated by AgentInstruct<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"ORCA-3\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Orca-3 is the resulting model after post-training Mistral-7b with data generated by AgentInstruct<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"AGIEVAL\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">AGIEval is a benchmark used to evaluate the performance of language models<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"MMLU\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">MMLU is a benchmark used to evaluate the performance of language models<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"GSM8K\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">GSM8K is a benchmark used to evaluate the performance of language models<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"BBH\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">BBH is a benchmark used to evaluate the performance of language models<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"ALPACAEVAL\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">AlpacaEval is a benchmark used to evaluate the performance of language models<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"LLAMA-8B-INSTRUCT\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">LLAMA-8B-instruct is a language model that was outperformed by Orca-3<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"GPT-3.5-TURBO\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-3.5-turbo is a language model that was outperformed by Orca-3<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"LLMS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">LLMs, or Large Language Models, are advanced language models that have been significantly developed using synthetic data<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"SLMS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">SLMs, or Small Language Models, are smaller language models that also benefit from synthetic data in their training<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4 is a powerful language model used to generate responses to prompts for creating synthetic data<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"RLHF\">      <data key=\"d0\">CONCEPT\/PROCESS<\/data>      <data key=\"d1\">RLHF, or Reinforcement Learning from Human Feedback, is a process used in the training of language models<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"AGENTIC WORKFLOWS\">      <data key=\"d0\">CONCEPT\/PROCESS<\/data>      <data key=\"d1\">Agentic workflows involve using agents to generate high-quality data through reflection, iteration, and tool usage<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"MULTI-AGENT WORKFLOWS\">      <data key=\"d0\">CONCEPT\/PROCESS<\/data>      <data key=\"d1\">Multi-agent workflows involve multiple agents working together to generate new prompts and responses, simulating scenarios and automating data generation<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"MISTRAL-7B-INSTRUCT\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Mistral-7b-Instruct is a version of the Mistral-7b model used for comparison with Orca-3<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"FOFO\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">FOFO is a benchmark used to evaluate the performance of language models<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <node id=\"MIRAGE-RAG\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">MIRAGE-RAG is a benchmark used to evaluate the performance of language models<\/data>      <data key=\"d2\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/node>    <edge source=\"AGENTINSTRUCT\" target=\"GENERATIVE TEACHING\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">AgentInstruct is used to facilitate Generative Teaching by creating synthetic data<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"MISTRAL-7B\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">AgentInstruct was used to generate data for post-training Mistral-7b<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"MULTI-AGENT WORKFLOWS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">AgentInstruct can utilize multi-agent workflows to generate high-quality synthetic data<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"ARINDAM MITRA\" target=\"MICROSOFT RESEARCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Arindam Mitra is affiliated with Microsoft Research<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"LUCIANO DEL CORRO\" target=\"MICROSOFT RESEARCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Luciano Del Corro is affiliated with Microsoft Research<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"GUOQING ZHENG\" target=\"MICROSOFT RESEARCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Guoqing Zheng is affiliated with Microsoft Research<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"SHWETI MAHAJAN\" target=\"MICROSOFT RESEARCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Shweti Mahajan is affiliated with Microsoft Research<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"DANY ROUHANA\" target=\"MICROSOFT RESEARCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Dany Rouhana is affiliated with Microsoft Research<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"ANDRES CODAS\" target=\"MICROSOFT RESEARCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Andres Codas is affiliated with Microsoft Research<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"YADONG LU\" target=\"MICROSOFT RESEARCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Yadong Lu is affiliated with Microsoft Research<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"WEI-GE CHEN\" target=\"MICROSOFT RESEARCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Wei-ge Chen is affiliated with Microsoft Research<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"OLGA VROUSGOS\" target=\"MICROSOFT RESEARCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Olga Vrousgos is affiliated with Microsoft Research<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"CORBY ROSSET\" target=\"MICROSOFT RESEARCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Corby Rosset is affiliated with Microsoft Research<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"FILLIPE SILVA\" target=\"MICROSOFT RESEARCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Fillipe Silva is affiliated with Microsoft Research<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"HAMED KHANPOUR\" target=\"MICROSOFT RESEARCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Hamed Khanpour is affiliated with Microsoft Research<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"YASH LARA\" target=\"MICROSOFT RESEARCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Yash Lara is affiliated with Microsoft Research<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"AHMED AWADALLAH\" target=\"MICROSOFT RESEARCH\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Ahmed Awadallah is affiliated with Microsoft Research<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"SYNTHETIC DATA\" target=\"LLMS\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Synthetic data has significantly accelerated the development of Large Language Models (LLMs)<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"SYNTHETIC DATA\" target=\"SLMS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Synthetic data has significantly accelerated the development of Small Language Models (SLMs)<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"SYNTHETIC DATA\" target=\"RLHF\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Synthetic data is used in the process of Reinforcement Learning from Human Feedback (RLHF)<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"SYNTHETIC DATA\" target=\"GPT-4\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">GPT-4 is used to generate responses to prompts for creating synthetic data<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"MISTRAL-7B\" target=\"ORCA-3\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Orca-3 is the result of post-training Mistral-7b with data generated by AgentInstruct<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"AGIEVAL\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Orca-3 showed a 40% improvement on the AGIEval benchmark<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"MMLU\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Orca-3 showed a 19% improvement on the MMLU benchmark<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"GSM8K\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Orca-3 showed a 54% improvement on the GSM8K benchmark<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"BBH\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Orca-3 showed a 38% improvement on the BBH benchmark<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"ALPACAEVAL\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Orca-3 showed a 45% improvement on the AlpacaEval benchmark<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"LLAMA-8B-INSTRUCT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Orca-3 consistently outperformed LLAMA-8B-instruct<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"GPT-3.5-TURBO\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Orca-3 consistently outperformed GPT-3.5-turbo<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"MISTRAL-7B-INSTRUCT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Orca-3 showed significant improvements compared to Mistral-7b-Instruct<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"FOFO\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Orca-3 showed improvements on the FOFO benchmark<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"MIRAGE-RAG\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Orca-3 showed improvements on the MIRAGE-RAG benchmark<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>    <edge source=\"AGENTIC WORKFLOWS\" target=\"MULTI-AGENT WORKFLOWS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Multi-agent workflows are a type of agentic workflow that involve multiple agents working together<\/data>      <data key=\"d5\">6fe27f9eb76cf2ddf712a2cee5783d1c<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"b88745a13b69cecbc0ee9c3af41389bf","chunk":" both new prompts and the corresponding\nresponses. They also enable automation of the data generation workflows reducing or\neliminating need for human intervention on some tasks.\nGenerative Teaching & Orca AgentInstruct : Generating synthetic data for post-\ntraining often relies on an existing prompt set that is used as is or used as seeds for\ngenerating more instructions. In this work, we generalize the problem settings to a broader\nobjective of generating abundant amounts of diverse, challenging and high-quality data to\nteach a particular skill to an AI model, we refer to this setting as Generative Teaching.\nAgentInstruct is an agentic solution for Generative Teaching. AgentInstruct focuses on\ncreating demonstration and feedback data and requires only raw documents as input. When\ngeneric data is used as seeds, AgentInstruct can be used to teach an LLM a general capability\n(e.g. Math, Reasoning, RAG, etc.). Domain specific data (e.g. gaming, finance) can also be\nused as seeds to improve the model in a certain specialization. AgentInstruct can create:\n1.High-quality data: using powerful models like GPT-4, coupled with tools like search\nand code interpreters.\n2.Diverse data: AgentInstruct generates both prompts and responses. It uses a large\nnumber of agents (equipped with powerful LLMs, tools and reflection flows) and a\ntaxonomy (of over 100 subcategories) to create diverse and high quality prompts\nand responses,\n3.Large quantities of data: AgentInstruct can run autonomously and can apply flows\nfor verification and data filtering. It does not require seed prompts and uses raw\ndocuments for seeding.\nUsing raw data (unstructured text documents or source code) as seeds has two benefits.\nFirst, this data is available in abundance enabling the use of AgentInstruct to create large\namounts of diverse data. Additionally, using raw data as seeds, and hence, avoiding using\nexisting prompts, as is or after paraphrasing, can promote learning more general capabilities\nas opposed to benchmark-specific ones.\nWe demonstrate the utility of AgentInstruct by creating a comprehensive synthetic post-\ntraining dataset of 25 million prompt and response pairs. The dataset covers a wide array\n2of skills including creative writing, reasoning, math, RAG, tool use, etc. To assess the\nvalue of the data, we use it to finetune Mistral-7B[11] model. The finetuned Mistral model\n(Orca-3) shows significant improvement over other instruction-tuned models using the same\nbase model. For example, compared to Mistral-Instruct-7B, it shows 40% improvement on\nAGIEval, 19% improvement on MMLU, 54% improvement on GSM8K, 38% improvement\non BBH, 45% improvement on AlpacaEval and 31.34% reduction on hallucination across\nmultiple summarization benchmarks. Additionally, it outperforms other models such as\nLLAMA-8B-instruct and GPT-3.5 on multiple benchmarks. Note that the only seed data\nused is publicly available raw materials and no task-specific or benchmark data has been\nused as seeds.\nWhilewedemonstratetheutilityofAgentInstructbycreatingagenericpost-trainingsynthetic\ndataset, we believe that agents can enable the creation of Synthetic-Data-Generation-As-A-\nService where we start with raw materials (e.g. web data for general model training or domain\nspecific data for specialized models), and we generate data for post-training and finetuning,\nhence enabling continual learning and improvement of any base LLM. Additionally, we\nbelieve that the AgentInstruct approach can be used for self-improvement of larger, more\ncapable models because of: (1) the ability to generate new prompts and (2) the ability to\ngenerate responses that exceed the quality of the LLM used in the agentic flow (because of\nthe use of tools, reflection, etc.).\n2 Generative Teaching: AgentInstruct\nCreating synthetic datasets for supervised fine-tuning and instruction-tuning has seen\nsignificant progress over the last year. The quality of these datasets has been steadily\nimproving. High quality can be achieved by using powerful frontier models (or agenetic flows\nbased on these models) to generate responses. However, when creating synthetic data, in\naddition to quality, we also need to consider several other fundamental questions:\n1. How can we create a vast amount of data?\n2. How can we ensure that the generated data is diverse?\n3. How can we generate complex or nuanced data points?\nIn the AgentInstruct methodology, we outline a structured approach to tackle these challenges\nas follows:\nFigure 2: Concise Summary of the AgentInstruct Methodology\n1. Assemble a collection of raw seeds (e.g., textbook chapters, web articles, code\nsnippets).\n2.foreach seed in the collection do\n3. Transform the seed with the aid of one or more content transformation Agents (\nContent Transformation Flow).\n4. Route it through a series of instruction creation Agents to create a diverse set of\ninstructions (Seed Instruction Creation Flow).\n5. Utilize another group of Refinement Agents to iteratively refine the complexity\nand quality of the seed instructions (Refinement Flow).\n6.end for\nWe use agentic flows to automate the generation process and leverage raw articles as seeds to\nfoster diversity and ensure that problems generated in different iterations (line 2 in Figure 1)\nare distinct and of broad coverage. This enables us to create data at scale (benefiting from\nautomation of agentic flows), with high diversity (based on the broad and diverse seeds) and\nof varying complexity (benefiting from the iterative and","chunk_id":"b88745a13b69cecbc0ee9c3af41389bf","document_ids":["c5a70861b9987da7046fe2110eb3616c"],"n_tokens":1200,"entities":[{"name":"GENERATIVE TEACHING","type":"CONCEPT\/PROCESS","description":"Generative Teaching is a methodology for generating abundant amounts of diverse, challenging, and high-quality data to teach a particular skill to an AI model","source_id":"b88745a13b69cecbc0ee9c3af41389bf","entity_type":"CONCEPT\/PROCESS"},{"name":"AGENTINSTRUCT","type":"TOOL\/SOLUTION","description":"AgentInstruct is an agentic solution for Generative Teaching that focuses on creating demonstration and feedback data using raw documents as input","source_id":"b88745a13b69cecbc0ee9c3af41389bf","entity_type":"TOOL\/SOLUTION"},{"name":"GPT-4","type":"MODEL","description":"GPT-4 is a powerful language model used by AgentInstruct to generate high-quality data","source_id":"b88745a13b69cecbc0ee9c3af41389bf","entity_type":"MODEL"},{"name":"MISTRAL-7B","type":"MODEL","description":"Mistral-7B is a base model that was fine-tuned using the synthetic dataset created by AgentInstruct","source_id":"b88745a13b69cecbc0ee9c3af41389bf","entity_type":"MODEL"},{"name":"ORCA-3","type":"MODEL","description":"Orca-3 is the fine-tuned version of the Mistral-7B model, showing significant improvements over other instruction-tuned models","source_id":"b88745a13b69cecbc0ee9c3af41389bf","entity_type":"MODEL"},{"name":"AGIEVAL","type":"BENCHMARK","description":"AGIEval is a benchmark used to evaluate the performance of AI models","source_id":"b88745a13b69cecbc0ee9c3af41389bf","entity_type":"BENCHMARK"},{"name":"MMLU","type":"BENCHMARK","description":"MMLU is a benchmark used to evaluate the performance of AI models","source_id":"b88745a13b69cecbc0ee9c3af41389bf","entity_type":"BENCHMARK"},{"name":"GSM8K","type":"BENCHMARK","description":"GSM8K is a benchmark used to evaluate the performance of AI models","source_id":"b88745a13b69cecbc0ee9c3af41389bf","entity_type":"BENCHMARK"},{"name":"BBH","type":"BENCHMARK","description":"BBH is a benchmark used to evaluate the performance of AI models","source_id":"b88745a13b69cecbc0ee9c3af41389bf","entity_type":"BENCHMARK"},{"name":"ALPACAEVAL","type":"BENCHMARK","description":"AlpacaEval is a benchmark used to evaluate the performance of AI models","source_id":"b88745a13b69cecbc0ee9c3af41389bf","entity_type":"BENCHMARK"},{"name":"LLAMA-8B-INSTRUCT","type":"MODEL","description":"LLAMA-8B-instruct is another AI model that Orca-3 outperforms on multiple benchmarks","source_id":"b88745a13b69cecbc0ee9c3af41389bf","entity_type":"MODEL"},{"name":"GPT-3.5","type":"MODEL","description":"GPT-3.5 is another AI model that Orca-3 outperforms on multiple benchmarks","source_id":"b88745a13b69cecbc0ee9c3af41389bf","entity_type":"MODEL"},{"name":"SYNTHETIC-DATA-GENERATION-AS-A-SERVICE","type":"SERVICE","description":"Synthetic-Data-Generation-As-A-Service is a proposed service for generating data for post-training and fine-tuning of AI models using raw materials","source_id":"b88745a13b69cecbc0ee9c3af41389bf","entity_type":"SERVICE"},{"name":"CONTENT TRANSFORMATION AGENTS","type":"AGENTS","description":"Content Transformation Agents are used in the AgentInstruct methodology to transform raw seeds into diverse instructions","source_id":"b88745a13b69cecbc0ee9c3af41389bf","entity_type":"AGENTS"},{"name":"REFINEMENT AGENTS","type":"AGENTS","description":"Refinement Agents are used in the AgentInstruct methodology to iteratively refine the complexity and quality of seed instructions","source_id":"b88745a13b69cecbc0ee9c3af41389bf","entity_type":"AGENTS"},{"name":"RAW SEEDS","type":"DATA","description":"Raw seeds are unstructured text documents or source code used as input for AgentInstruct to generate diverse data","source_id":"b88745a13b69cecbc0ee9c3af41389bf","entity_type":"DATA"},{"name":"CONTENT TRANSFORMATION FLOW","type":"PROCESS","description":"Content Transformation Flow is a process in the AgentInstruct methodology where raw seeds are transformed by Content Transformation Agents","source_id":"b88745a13b69cecbc0ee9c3af41389bf","entity_type":"PROCESS"},{"name":"SEED INSTRUCTION CREATION FLOW","type":"PROCESS","description":"Seed Instruction Creation Flow is a process in the AgentInstruct methodology where a diverse set of instructions is created from transformed seeds","source_id":"b88745a13b69cecbc0ee9c3af41389bf","entity_type":"PROCESS"},{"name":"REFINEMENT FLOW","type":"PROCESS","description":"Refinement Flow is a process in the AgentInstruct methodology where the complexity and quality of seed instructions are iteratively refined","source_id":"b88745a13b69cecbc0ee9c3af41389bf","entity_type":"PROCESS"},{"name":"CREATIVE WRITING","type":"SKILL","description":"Creative writing is one of the skills covered by the synthetic post-training dataset created by AgentInstruct","source_id":"b88745a13b69cecbc0ee9c3af41389bf"},{"name":"REASONING","type":"SKILL","description":"Reasoning is one of the skills covered by the synthetic post-training dataset created by AgentInstruct","source_id":"b88745a13b69cecbc0ee9c3af41389bf"},{"name":"MATH","type":"SKILL","description":"Math is one of the skills covered by the synthetic post-training dataset created by AgentInstruct","source_id":"b88745a13b69cecbc0ee9c3af41389bf"},{"name":"RAG","type":"SKILL","description":"RAG (Retrieval-Augmented Generation) is one of the skills covered by the synthetic post-training dataset created by AgentInstruct","source_id":"b88745a13b69cecbc0ee9c3af41389bf"},{"name":"TOOL USE","type":"SKILL","description":"Tool use is one of the skills covered by the synthetic post-training dataset created by AgentInstruct","source_id":"b88745a13b69cecbc0ee9c3af41389bf"},{"name":"DATA FILTERING","type":"PROCESS","description":"Data filtering is a process applied by AgentInstruct to ensure the quality of generated data","source_id":"b88745a13b69cecbc0ee9c3af41389bf"},{"name":"VERIFICATION","type":"PROCESS","description":"Verification is a process applied by AgentInstruct to ensure the quality of generated data","source_id":"b88745a13b69cecbc0ee9c3af41389bf"},{"name":"DEMONSTRATION DATA","type":"DATA","description":"Demonstration data is created by AgentInstruct to teach AI models specific skills","source_id":"b88745a13b69cecbc0ee9c3af41389bf"},{"name":"FEEDBACK DATA","type":"DATA","description":"Feedback data is created by AgentInstruct to teach AI models specific skills","source_id":"b88745a13b69cecbc0ee9c3af41389bf"},{"name":"POST-TRAINING","type":"PROCESS","description":"Post-training is a process where AI models are further trained using synthetic datasets created by AgentInstruct","source_id":"b88745a13b69cecbc0ee9c3af41389bf"},{"name":"FINE-TUNING","type":"PROCESS","description":"Fine-tuning is a process where AI models are further trained using synthetic datasets created by AgentInstruct","source_id":"b88745a13b69cecbc0ee9c3af41389bf"},{"name":"CONTINUAL LEARNING","type":"CONCEPT\/PROCESS","description":"Continual learning is the ongoing process of training AI models to improve their performance over time","source_id":"b88745a13b69cecbc0ee9c3af41389bf"},{"name":"SELF-IMPROVEMENT","type":"CONCEPT\/PROCESS","description":"Self-improvement is the process where AI models enhance their own capabilities using generated prompts and responses","source_id":"b88745a13b69cecbc0ee9c3af41389bf"},{"name":"WEB DATA","type":"DATA","description":"Web data is a type of raw material used as seeds for generating synthetic datasets","source_id":"b88745a13b69cecbc0ee9c3af41389bf"},{"name":"DOMAIN SPECIFIC DATA","type":"DATA","description":"Domain specific data is used as seeds to improve AI models in certain specializations","source_id":"b88745a13b69cecbc0ee9c3af41389bf"},{"name":"TEXTBOOK CHAPTERS","type":"DATA","description":"Textbook chapters are a type of raw seed used in the AgentInstruct methodology","source_id":"b88745a13b69cecbc0ee9c3af41389bf"},{"name":"WEB ARTICLES","type":"DATA","description":"Web articles are a type of raw seed used in the AgentInstruct methodology","source_id":"b88745a13b69cecbc0ee9c3af41389bf"},{"name":"CODE SNIPPETS","type":"DATA","description":"Code snippets are a type of raw seed used in the AgentInstruct methodology","source_id":"b88745a13b69cecbc0ee9c3af41389bf"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"GENERATIVE TEACHING\">      <data key=\"d0\">CONCEPT\/PROCESS<\/data>      <data key=\"d1\">Generative Teaching is a methodology for generating abundant amounts of diverse, challenging, and high-quality data to teach a particular skill to an AI model<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>      <data key=\"d3\">CONCEPT\/PROCESS<\/data>    <\/node>    <node id=\"AGENTINSTRUCT\">      <data key=\"d0\">TOOL\/SOLUTION<\/data>      <data key=\"d1\">AgentInstruct is an agentic solution for Generative Teaching that focuses on creating demonstration and feedback data using raw documents as input<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>      <data key=\"d3\">TOOL\/SOLUTION<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4 is a powerful language model used by AgentInstruct to generate high-quality data<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"MISTRAL-7B\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Mistral-7B is a base model that was fine-tuned using the synthetic dataset created by AgentInstruct<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"ORCA-3\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Orca-3 is the fine-tuned version of the Mistral-7B model, showing significant improvements over other instruction-tuned models<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"AGIEVAL\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">AGIEval is a benchmark used to evaluate the performance of AI models<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>      <data key=\"d3\">BENCHMARK<\/data>    <\/node>    <node id=\"MMLU\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">MMLU is a benchmark used to evaluate the performance of AI models<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>      <data key=\"d3\">BENCHMARK<\/data>    <\/node>    <node id=\"GSM8K\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">GSM8K is a benchmark used to evaluate the performance of AI models<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>      <data key=\"d3\">BENCHMARK<\/data>    <\/node>    <node id=\"BBH\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">BBH is a benchmark used to evaluate the performance of AI models<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>      <data key=\"d3\">BENCHMARK<\/data>    <\/node>    <node id=\"ALPACAEVAL\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">AlpacaEval is a benchmark used to evaluate the performance of AI models<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>      <data key=\"d3\">BENCHMARK<\/data>    <\/node>    <node id=\"LLAMA-8B-INSTRUCT\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">LLAMA-8B-instruct is another AI model that Orca-3 outperforms on multiple benchmarks<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"GPT-3.5\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-3.5 is another AI model that Orca-3 outperforms on multiple benchmarks<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"SYNTHETIC-DATA-GENERATION-AS-A-SERVICE\">      <data key=\"d0\">SERVICE<\/data>      <data key=\"d1\">Synthetic-Data-Generation-As-A-Service is a proposed service for generating data for post-training and fine-tuning of AI models using raw materials<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>      <data key=\"d3\">SERVICE<\/data>    <\/node>    <node id=\"CONTENT TRANSFORMATION AGENTS\">      <data key=\"d0\">AGENTS<\/data>      <data key=\"d1\">Content Transformation Agents are used in the AgentInstruct methodology to transform raw seeds into diverse instructions<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>      <data key=\"d3\">AGENTS<\/data>    <\/node>    <node id=\"REFINEMENT AGENTS\">      <data key=\"d0\">AGENTS<\/data>      <data key=\"d1\">Refinement Agents are used in the AgentInstruct methodology to iteratively refine the complexity and quality of seed instructions<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>      <data key=\"d3\">AGENTS<\/data>    <\/node>    <node id=\"RAW SEEDS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Raw seeds are unstructured text documents or source code used as input for AgentInstruct to generate diverse data<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>      <data key=\"d3\">DATA<\/data>    <\/node>    <node id=\"CONTENT TRANSFORMATION FLOW\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Content Transformation Flow is a process in the AgentInstruct methodology where raw seeds are transformed by Content Transformation Agents<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>      <data key=\"d3\">PROCESS<\/data>    <\/node>    <node id=\"SEED INSTRUCTION CREATION FLOW\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Seed Instruction Creation Flow is a process in the AgentInstruct methodology where a diverse set of instructions is created from transformed seeds<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>      <data key=\"d3\">PROCESS<\/data>    <\/node>    <node id=\"REFINEMENT FLOW\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Refinement Flow is a process in the AgentInstruct methodology where the complexity and quality of seed instructions are iteratively refined<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>      <data key=\"d3\">PROCESS<\/data>    <\/node>    <node id=\"CREATIVE WRITING\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">Creative writing is one of the skills covered by the synthetic post-training dataset created by AgentInstruct<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/node>    <node id=\"REASONING\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">Reasoning is one of the skills covered by the synthetic post-training dataset created by AgentInstruct<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/node>    <node id=\"MATH\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">Math is one of the skills covered by the synthetic post-training dataset created by AgentInstruct<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/node>    <node id=\"RAG\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">RAG (Retrieval-Augmented Generation) is one of the skills covered by the synthetic post-training dataset created by AgentInstruct<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/node>    <node id=\"TOOL USE\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">Tool use is one of the skills covered by the synthetic post-training dataset created by AgentInstruct<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/node>    <node id=\"DATA FILTERING\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Data filtering is a process applied by AgentInstruct to ensure the quality of generated data<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/node>    <node id=\"VERIFICATION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Verification is a process applied by AgentInstruct to ensure the quality of generated data<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/node>    <node id=\"DEMONSTRATION DATA\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Demonstration data is created by AgentInstruct to teach AI models specific skills<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/node>    <node id=\"FEEDBACK DATA\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Feedback data is created by AgentInstruct to teach AI models specific skills<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/node>    <node id=\"POST-TRAINING\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Post-training is a process where AI models are further trained using synthetic datasets created by AgentInstruct<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/node>    <node id=\"FINE-TUNING\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Fine-tuning is a process where AI models are further trained using synthetic datasets created by AgentInstruct<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/node>    <node id=\"CONTINUAL LEARNING\">      <data key=\"d0\">CONCEPT\/PROCESS<\/data>      <data key=\"d1\">Continual learning is the ongoing process of training AI models to improve their performance over time<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/node>    <node id=\"SELF-IMPROVEMENT\">      <data key=\"d0\">CONCEPT\/PROCESS<\/data>      <data key=\"d1\">Self-improvement is the process where AI models enhance their own capabilities using generated prompts and responses<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/node>    <node id=\"WEB DATA\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Web data is a type of raw material used as seeds for generating synthetic datasets<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/node>    <node id=\"DOMAIN SPECIFIC DATA\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Domain specific data is used as seeds to improve AI models in certain specializations<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/node>    <node id=\"TEXTBOOK CHAPTERS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Textbook chapters are a type of raw seed used in the AgentInstruct methodology<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/node>    <node id=\"WEB ARTICLES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Web articles are a type of raw seed used in the AgentInstruct methodology<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/node>    <node id=\"CODE SNIPPETS\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Code snippets are a type of raw seed used in the AgentInstruct methodology<\/data>      <data key=\"d2\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/node>    <edge source=\"GENERATIVE TEACHING\" target=\"AGENTINSTRUCT\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">AgentInstruct is an agentic solution for Generative Teaching<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"GPT-4\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">AgentInstruct uses GPT-4 to generate high-quality data<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"MISTRAL-7B\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">AgentInstruct created a synthetic dataset used to fine-tune the Mistral-7B model<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"SYNTHETIC-DATA-GENERATION-AS-A-SERVICE\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">AgentInstruct can enable the creation of Synthetic-Data-Generation-As-A-Service<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"CONTENT TRANSFORMATION AGENTS\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">AgentInstruct uses Content Transformation Agents to transform raw seeds<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"REFINEMENT AGENTS\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">AgentInstruct uses Refinement Agents to refine seed instructions<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"RAW SEEDS\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">AgentInstruct uses raw seeds as input to generate diverse data<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"CREATIVE WRITING\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AgentInstruct generates data covering the skill of creative writing<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"REASONING\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AgentInstruct generates data covering the skill of reasoning<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"MATH\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AgentInstruct generates data covering the skill of math<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"RAG\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AgentInstruct generates data covering the skill of RAG<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"TOOL USE\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AgentInstruct generates data covering the skill of tool use<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"DATA FILTERING\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AgentInstruct applies data filtering to ensure the quality of generated data<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"VERIFICATION\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AgentInstruct applies verification to ensure the quality of generated data<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"DEMONSTRATION DATA\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AgentInstruct creates demonstration data to teach AI models specific skills<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"FEEDBACK DATA\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AgentInstruct creates feedback data to teach AI models specific skills<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"POST-TRAINING\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AgentInstruct generates synthetic datasets for post-training AI models<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"FINE-TUNING\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AgentInstruct generates synthetic datasets for fine-tuning AI models<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"CONTINUAL LEARNING\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AgentInstruct enables continual learning of AI models<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"SELF-IMPROVEMENT\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AgentInstruct enables self-improvement of AI models<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"WEB DATA\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AgentInstruct uses web data as raw material for generating synthetic datasets<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"DOMAIN SPECIFIC DATA\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AgentInstruct uses domain specific data as raw material for generating synthetic datasets<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"TEXTBOOK CHAPTERS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AgentInstruct uses textbook chapters as raw seeds<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"WEB ARTICLES\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AgentInstruct uses web articles as raw seeds<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"CODE SNIPPETS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">AgentInstruct uses code snippets as raw seeds<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"MISTRAL-7B\" target=\"ORCA-3\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">Orca-3 is the fine-tuned version of the Mistral-7B model<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"AGIEVAL\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Orca-3 shows 40% improvement on AGIEval benchmark<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"MMLU\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Orca-3 shows 19% improvement on MMLU benchmark<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"GSM8K\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Orca-3 shows 54% improvement on GSM8K benchmark<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"BBH\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Orca-3 shows 38% improvement on BBH benchmark<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"ALPACAEVAL\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Orca-3 shows 45% improvement on AlpacaEval benchmark<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"LLAMA-8B-INSTRUCT\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Orca-3 outperforms LLAMA-8B-instruct on multiple benchmarks<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"GPT-3.5\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Orca-3 outperforms GPT-3.5 on multiple benchmarks<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"CONTENT TRANSFORMATION AGENTS\" target=\"CONTENT TRANSFORMATION FLOW\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Content Transformation Agents are used in the Content Transformation Flow<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"REFINEMENT AGENTS\" target=\"REFINEMENT FLOW\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Refinement Agents are used in the Refinement Flow<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"CONTENT TRANSFORMATION FLOW\" target=\"SEED INSTRUCTION CREATION FLOW\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Content Transformation Flow is followed by Seed Instruction Creation Flow<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>    <edge source=\"SEED INSTRUCTION CREATION FLOW\" target=\"REFINEMENT FLOW\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Seed Instruction Creation Flow is followed by Refinement Flow<\/data>      <data key=\"d6\">b88745a13b69cecbc0ee9c3af41389bf<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"f7eb89a70f544664546a510e46d5febd","chunk":" the seed instructions (Refinement Flow).\n6.end for\nWe use agentic flows to automate the generation process and leverage raw articles as seeds to\nfoster diversity and ensure that problems generated in different iterations (line 2 in Figure 1)\nare distinct and of broad coverage. This enables us to create data at scale (benefiting from\nautomation of agentic flows), with high diversity (based on the broad and diverse seeds) and\nof varying complexity (benefiting from the iterative and refinement patterns supported by\nagentic flows). AgentInstruct defines three different flows:\nContent Transformation Flow converts the raw seed into an intermediate representation\nthat simplifies the creation of instructions tailored to specific objectives. It comprises of\n31\nContent Transformation Flow\u2026...\u2026\u2026\u2026\u2026\u2026\u2026\n\u2026\u2026\u2026\u2026\u2026\u2026\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026...\u2026...\u2026...\u2026\u2026\u2026\u2026\u2026\u2026\n\u2026\u2026\u2026\u2026\u2026\u2026\n\u2026\u2026\u2026\u2026\u2026\u2026\n\u2026\u2026Raw text \ndocuments or \nsource code \nfiles are used \nas seedsTransformed \ncontent ( e.g.  \nargument passage, \nmeeting transcript, \nlist of APIs,\u2026.)\nSeed Instruction Generation Flow\n\u2026\u2026Transformed \ncontent provide \ndiversity is easier \nto use to generate \ninstructions Seed instructions \nare generated \nfollowing  a \ncomprehensive \ntaxonomy\u2026...\u2026...\u2026...\u2026\u2026\u2026\u2026\u2026\u2026\n\u2026\u2026\u2026\u2026\u2026\u2026\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026...\u2026...\u2026...\n3\nInstruction Refinement Flow\nIteratively refine the instructions \nto boost quality, diversity and \ncomplexity\n2Figure 3: Figure provides a thematic overview of the roles played by different groups of\nagents. Content Transformation Flow converts the seed into an intermediate representation\nthat makes it easier to create high quality and diverse data. Seed Instruction Generation\nFlow creates instances of the target tasks following a taxonomy. Refinement Flow explores\nthe space further by starting from these initial data points and exploring the neighborhood.\nThe expectation is that by picking a random seed we will be able to cover the entire region\nof data points.\nmultiple agents and is often instrumental in the generation of high-quality data and serve as\nan additional means to introduce diversity.\nSeed Instruction Generation Flow comprising of multiple agents takes as input the\ntransformed seed from the Content Transformation Flow and generates a set of diverse\ninstructions. The only goal of the Seed Instruction Flow is to introduce diversity for which\nit often relies on a pre-defined, but extensible, taxonomy.\nInstruction Refinement Flow takes as input the instructions from the Seed Instruction\nFlow and iteratively enhances their complexity and quality. Towards this we use the concept\nof Suggester-Editor Agents[ 19]. Suggester agents initially propose various approaches to\nincrease the intricacy of the initial instructions (making them more complex, unsolvable,\nor tricky), after which the Editor agents modify the instructions in accordance with these\nsuggestions.\nEach flow consists of a number of agents. We use a generic definition of an agent, where an\nagent is powered by an LLM and can optionally have the ability to use tools such as search\nAPIs, code interpreter or a calculator. Each agent has a specific role and set of instructions\nspecified as part of the underlying LLM system message.\nWe implemented these flows for 17 different skills, each having multiple subcategories.\nThe skills include reading comprehension, question answering, coding, retrieval augmented\ngeneration, creative writing, tool\/API use and Web control. The full list is provided in\nTable 1\nWe explain how the workflows work with case studies of generating data for the following\nthree skills:\nReading Comprehension: The ability to understand, process, and interpret written text.\nText Modification: The process of altering text to suit different purposes.\nTool Use: The employment of functions or APIs to perform tasks or solve problems.\n4Reading Comprehension: Reading comprehension is a critical skill involving processing and un-\nderstanding text, which is necessary for learning and encompasses decoding, fluency, and vocabulary\nknowledge. Reading comprehension tests typically present text passages of varying lengths and\nsubjects, followed by questions that assess the reader\u2019s understanding.\nOpen Domain Question Answering: Open domain question answering involves generating\nresponses to questions over a wide range of topics, without being restricted to a specific domain.\nText Modification: Text modification involves changing existing text to improve its quality,\nmodify its tone, or to fit a specific context or audience. It is a common task in content creation and\nediting.\nWeb Agent: A web agent is a software program that autonomously performs tasks on the web,\nsuch as where to click, how much to scroll.\nBrain Teaser A brain teaser is a problem or puzzle, typically requiring thought to solve, often for\namusement but also used for training logical thinking and problem-solving skills.\nAnalytical Reasoning Analytical reasoning involves the ability to look at information, be it\nqualitative or quantitative in nature, and discern patterns within the information. It\u2019s a process\nthat includes understanding a system of relationships and draw logical conclusions about those\nrelationships.\nMultiple Choice Questions Multiple choice questions are a form of assessment where respondents\nare asked to select the best possible answer (or answers) out of the choices from a list. They are\ncommon in standardized tests, quizzes, and surveys.\nData To Text Data-to-text refers to human-readable textual summaries from source data. These\ncould be used for generating reports, explanations, or narratives from structured data.\nFermiFermi problems are estimation problems which seek quick, rough estimates of quantities\nwhich can be difficult to measure. Named after physicist Enrico Fermi, these problems often require\nmaking justified guesses or assumptions to reach a solution.\nCoding Coding involves writing code following instructions, understanding code, debugging code,\ntracing or writing test cases.\nText Extraction Text extraction is the process of retrieving relevant information from a larger text\ndocument. This can include tasks like named entity recognition, keyword extraction, or extracting\nspecific data fields from unstructured text.\nText","chunk_id":"f7eb89a70f544664546a510e46d5febd","document_ids":["c5a70861b9987da7046fe2110eb3616c"],"n_tokens":1200,"entities":[{"name":"AGENTIC FLOWS","type":"PROCESS\/TECHNIQUE","description":"Agentic flows are used to automate the generation process and leverage raw articles as seeds to foster diversity and ensure that problems generated in different iterations are distinct and of broad coverage.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"CONTENT TRANSFORMATION FLOW","type":"PROCESS\/TECHNIQUE","description":"Content Transformation Flow converts the raw seed into an intermediate representation that simplifies the creation of instructions tailored to specific objectives.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"SEED INSTRUCTION GENERATION FLOW","type":"PROCESS\/TECHNIQUE","description":"Seed Instruction Generation Flow takes transformed content and generates a set of diverse instructions following a comprehensive taxonomy.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"INSTRUCTION REFINEMENT FLOW","type":"PROCESS\/TECHNIQUE","description":"Instruction Refinement Flow iteratively enhances the complexity and quality of instructions generated by the Seed Instruction Flow.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"AGENT","type":"COMPONENT\/ACTOR","description":"An agent is powered by an LLM and can optionally use tools such as search APIs, code interpreter, or a calculator. Each agent has a specific role and set of instructions specified as part of the underlying LLM system message.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"SUGGESTER AGENT","type":"COMPONENT\/ACTOR","description":"Suggester agents propose various approaches to increase the intricacy of the initial instructions, making them more complex, unsolvable, or tricky.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"EDITOR AGENT","type":"COMPONENT\/ACTOR","description":"Editor agents modify the instructions in accordance with the suggestions made by the Suggester agents.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"READING COMPREHENSION","type":"SKILL","description":"Reading comprehension involves understanding, processing, and interpreting written text, which is necessary for learning and encompasses decoding, fluency, and vocabulary knowledge.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"TEXT MODIFICATION","type":"SKILL","description":"Text modification involves changing existing text to improve its quality, modify its tone, or fit a specific context or audience.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"TOOL USE","type":"SKILL","description":"Tool use involves the employment of functions or APIs to perform tasks or solve problems.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"OPEN DOMAIN QUESTION ANSWERING","type":"SKILL","description":"Open domain question answering involves generating responses to questions over a wide range of topics, without being restricted to a specific domain.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"WEB AGENT","type":"COMPONENT\/ACTOR","description":"A web agent is a software program that autonomously performs tasks on the web, such as where to click and how much to scroll.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"BRAIN TEASER","type":"SKILL","description":"A brain teaser is a problem or puzzle that typically requires thought to solve, often for amusement but also used for training logical thinking and problem-solving skills.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"ANALYTICAL REASONING","type":"SKILL","description":"Analytical reasoning involves the ability to look at information, be it qualitative or quantitative, and discern patterns within the information to draw logical conclusions.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"MULTIPLE CHOICE QUESTIONS","type":"SKILL","description":"Multiple choice questions are a form of assessment where respondents select the best possible answer from a list of choices.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"DATA TO TEXT","type":"SKILL","description":"Data-to-text refers to generating human-readable textual summaries from source data, used for reports, explanations, or narratives from structured data.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"FERMI PROBLEMS","type":"SKILL","description":"Fermi problems are estimation problems that seek quick, rough estimates of quantities that can be difficult to measure, often requiring justified guesses or assumptions.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"CODING","type":"SKILL","description":"Coding involves writing code following instructions, understanding code, debugging code, and writing test cases.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"TEXT EXTRACTION","type":"SKILL","description":"Text extraction is the process of retrieving relevant information from a larger text document, including tasks like named entity recognition, keyword extraction, or extracting specific data fields from unstructured text.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"AGENTINSTRUCT","type":"PROCESS\/TECHNIQUE","description":"AgentInstruct defines three different flows: Content Transformation Flow, Seed Instruction Generation Flow, and Instruction Refinement Flow to automate the generation process and ensure diversity and complexity in generated data.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"RAW ARTICLES","type":"COMPONENT\/ACTOR","description":"Raw articles are used as seeds in agentic flows to foster diversity and ensure broad coverage of generated problems.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"SEED INSTRUCTIONS","type":"COMPONENT\/ACTOR","description":"Seed instructions are generated from transformed content and are iteratively refined to boost quality, diversity, and complexity.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"LLM","type":"COMPONENT\/ACTOR","description":"A large language model (LLM) powers each agent and can optionally use tools such as search APIs, code interpreter, or a calculator.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"SEARCH API","type":"COMPONENT\/ACTOR","description":"A tool that agents can use to perform search operations as part of their tasks.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"CODE INTERPRETER","type":"COMPONENT\/ACTOR","description":"A tool that agents can use to interpret and execute code as part of their tasks.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"CALCULATOR","type":"COMPONENT\/ACTOR","description":"A tool that agents can use to perform calculations as part of their tasks.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"READING COMPREHENSION TESTS","type":"COMPONENT\/ACTOR","description":"Tests that present text passages of varying lengths and subjects, followed by questions that assess the reader\u2019s understanding.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"TABLE 1","type":"COMPONENT\/ACTOR","description":"A table that provides a full list of the 17 different skills implemented in the agentic flows, each having multiple subcategories.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"CASE STUDIES","type":"COMPONENT\/ACTOR","description":"Case studies explain how the workflows work for generating data for specific skills such as Reading Comprehension, Text Modification, and Tool Use.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"SKILLS","type":"COMPONENT\/ACTOR","description":"The 17 different skills implemented in the agentic flows, including reading comprehension, question answering, coding, retrieval augmented generation, creative writing, tool\/API use, and Web control.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"INSTRUCTION","type":"COMPONENT\/ACTOR","description":"Instructions are the tasks or guidelines that agents follow to perform their roles in the agentic flows.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"SUGGESTIONS","type":"COMPONENT\/ACTOR","description":"Suggestions are proposed by Suggester agents to increase the intricacy of the initial instructions.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"EDITING","type":"COMPONENT\/ACTOR","description":"Editing is the process performed by Editor agents to modify instructions based on the suggestions from Suggester agents.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"TASKS","type":"COMPONENT\/ACTOR","description":"Tasks are the specific activities or problems that agents work on within the agentic flows.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"OBJECTIVES","type":"COMPONENT\/ACTOR","description":"Objectives are the goals or targets that the instructions are tailored to achieve in the Content Transformation Flow.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"INTERMEDIATE REPRESENTATION","type":"COMPONENT\/ACTOR","description":"An intermediate representation is created from raw seeds to simplify the creation of instructions tailored to specific objectives.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"TAXONOMY","type":"COMPONENT\/ACTOR","description":"A pre-defined, but extensible, taxonomy is used in the Seed Instruction Generation Flow to introduce diversity in the generated instructions.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"ITERATIONS","type":"COMPONENT\/ACTOR","description":"Iterations refer to the repeated cycles of refining instructions to enhance their complexity and quality in the Instruction Refinement Flow.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"QUALITY","type":"COMPONENT\/ACTOR","description":"Quality is one of the attributes that the Instruction Refinement Flow aims to boost in the generated instructions.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"DIVERSITY","type":"COMPONENT\/ACTOR","description":"Diversity is one of the attributes that the agentic flows aim to ensure in the generated data and instructions.","source_id":"f7eb89a70f544664546a510e46d5febd"},{"name":"COMPLEXITY","type":"COMPONENT\/ACTOR","description":"Complexity is one of the attributes that the Instruction Refinement Flow aims to enhance in the generated instructions.","source_id":"f7eb89a70f544664546a510e46d5febd"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"AGENTIC FLOWS\">      <data key=\"d0\">PROCESS\/TECHNIQUE<\/data>      <data key=\"d1\">Agentic flows are used to automate the generation process and leverage raw articles as seeds to foster diversity and ensure that problems generated in different iterations are distinct and of broad coverage.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"CONTENT TRANSFORMATION FLOW\">      <data key=\"d0\">PROCESS\/TECHNIQUE<\/data>      <data key=\"d1\">Content Transformation Flow converts the raw seed into an intermediate representation that simplifies the creation of instructions tailored to specific objectives.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"SEED INSTRUCTION GENERATION FLOW\">      <data key=\"d0\">PROCESS\/TECHNIQUE<\/data>      <data key=\"d1\">Seed Instruction Generation Flow takes transformed content and generates a set of diverse instructions following a comprehensive taxonomy.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"INSTRUCTION REFINEMENT FLOW\">      <data key=\"d0\">PROCESS\/TECHNIQUE<\/data>      <data key=\"d1\">Instruction Refinement Flow iteratively enhances the complexity and quality of instructions generated by the Seed Instruction Flow.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"AGENT\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">An agent is powered by an LLM and can optionally use tools such as search APIs, code interpreter, or a calculator. Each agent has a specific role and set of instructions specified as part of the underlying LLM system message.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"SUGGESTER AGENT\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">Suggester agents propose various approaches to increase the intricacy of the initial instructions, making them more complex, unsolvable, or tricky.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"EDITOR AGENT\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">Editor agents modify the instructions in accordance with the suggestions made by the Suggester agents.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"READING COMPREHENSION\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">Reading comprehension involves understanding, processing, and interpreting written text, which is necessary for learning and encompasses decoding, fluency, and vocabulary knowledge.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"TEXT MODIFICATION\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">Text modification involves changing existing text to improve its quality, modify its tone, or fit a specific context or audience.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"TOOL USE\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">Tool use involves the employment of functions or APIs to perform tasks or solve problems.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"OPEN DOMAIN QUESTION ANSWERING\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">Open domain question answering involves generating responses to questions over a wide range of topics, without being restricted to a specific domain.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"WEB AGENT\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">A web agent is a software program that autonomously performs tasks on the web, such as where to click and how much to scroll.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"BRAIN TEASER\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">A brain teaser is a problem or puzzle that typically requires thought to solve, often for amusement but also used for training logical thinking and problem-solving skills.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"ANALYTICAL REASONING\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">Analytical reasoning involves the ability to look at information, be it qualitative or quantitative, and discern patterns within the information to draw logical conclusions.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"MULTIPLE CHOICE QUESTIONS\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">Multiple choice questions are a form of assessment where respondents select the best possible answer from a list of choices.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"DATA TO TEXT\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">Data-to-text refers to generating human-readable textual summaries from source data, used for reports, explanations, or narratives from structured data.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"FERMI PROBLEMS\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">Fermi problems are estimation problems that seek quick, rough estimates of quantities that can be difficult to measure, often requiring justified guesses or assumptions.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"CODING\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">Coding involves writing code following instructions, understanding code, debugging code, and writing test cases.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"TEXT EXTRACTION\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">Text extraction is the process of retrieving relevant information from a larger text document, including tasks like named entity recognition, keyword extraction, or extracting specific data fields from unstructured text.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"AGENTINSTRUCT\">      <data key=\"d0\">PROCESS\/TECHNIQUE<\/data>      <data key=\"d1\">AgentInstruct defines three different flows: Content Transformation Flow, Seed Instruction Generation Flow, and Instruction Refinement Flow to automate the generation process and ensure diversity and complexity in generated data.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"RAW ARTICLES\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">Raw articles are used as seeds in agentic flows to foster diversity and ensure broad coverage of generated problems.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"SEED INSTRUCTIONS\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">Seed instructions are generated from transformed content and are iteratively refined to boost quality, diversity, and complexity.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"LLM\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">A large language model (LLM) powers each agent and can optionally use tools such as search APIs, code interpreter, or a calculator.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"SEARCH API\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">A tool that agents can use to perform search operations as part of their tasks.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"CODE INTERPRETER\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">A tool that agents can use to interpret and execute code as part of their tasks.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"CALCULATOR\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">A tool that agents can use to perform calculations as part of their tasks.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"READING COMPREHENSION TESTS\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">Tests that present text passages of varying lengths and subjects, followed by questions that assess the reader&#8217;s understanding.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"TABLE 1\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">A table that provides a full list of the 17 different skills implemented in the agentic flows, each having multiple subcategories.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"CASE STUDIES\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">Case studies explain how the workflows work for generating data for specific skills such as Reading Comprehension, Text Modification, and Tool Use.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"SKILLS\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">The 17 different skills implemented in the agentic flows, including reading comprehension, question answering, coding, retrieval augmented generation, creative writing, tool\/API use, and Web control.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"INSTRUCTION\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">Instructions are the tasks or guidelines that agents follow to perform their roles in the agentic flows.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"SUGGESTIONS\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">Suggestions are proposed by Suggester agents to increase the intricacy of the initial instructions.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"EDITING\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">Editing is the process performed by Editor agents to modify instructions based on the suggestions from Suggester agents.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"TASKS\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">Tasks are the specific activities or problems that agents work on within the agentic flows.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"OBJECTIVES\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">Objectives are the goals or targets that the instructions are tailored to achieve in the Content Transformation Flow.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"INTERMEDIATE REPRESENTATION\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">An intermediate representation is created from raw seeds to simplify the creation of instructions tailored to specific objectives.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"TAXONOMY\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">A pre-defined, but extensible, taxonomy is used in the Seed Instruction Generation Flow to introduce diversity in the generated instructions.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"ITERATIONS\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">Iterations refer to the repeated cycles of refining instructions to enhance their complexity and quality in the Instruction Refinement Flow.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"QUALITY\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">Quality is one of the attributes that the Instruction Refinement Flow aims to boost in the generated instructions.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"DIVERSITY\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">Diversity is one of the attributes that the agentic flows aim to ensure in the generated data and instructions.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <node id=\"COMPLEXITY\">      <data key=\"d0\">COMPONENT\/ACTOR<\/data>      <data key=\"d1\">Complexity is one of the attributes that the Instruction Refinement Flow aims to enhance in the generated instructions.<\/data>      <data key=\"d2\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/node>    <edge source=\"AGENTIC FLOWS\" target=\"CONTENT TRANSFORMATION FLOW\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Content Transformation Flow is a part of the agentic flows used to convert raw seeds into intermediate representations.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"AGENTIC FLOWS\" target=\"SEED INSTRUCTION GENERATION FLOW\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Seed Instruction Generation Flow is a part of the agentic flows used to generate diverse instructions from transformed content.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"AGENTIC FLOWS\" target=\"INSTRUCTION REFINEMENT FLOW\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Instruction Refinement Flow is a part of the agentic flows used to iteratively enhance the complexity and quality of instructions.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"AGENTIC FLOWS\" target=\"RAW ARTICLES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Raw articles are used as seeds in agentic flows to foster diversity and ensure broad coverage of generated problems.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"AGENTIC FLOWS\" target=\"SKILLS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Agentic flows are implemented for 17 different skills, each having multiple subcategories.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"CONTENT TRANSFORMATION FLOW\" target=\"SEED INSTRUCTION GENERATION FLOW\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Seed Instruction Generation Flow takes transformed content from the Content Transformation Flow to generate diverse instructions.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"CONTENT TRANSFORMATION FLOW\" target=\"AGENTINSTRUCT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Content Transformation Flow is one of the three flows defined by AgentInstruct to automate the generation process.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"CONTENT TRANSFORMATION FLOW\" target=\"INTERMEDIATE REPRESENTATION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Content Transformation Flow converts raw seeds into an intermediate representation to simplify the creation of instructions.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"SEED INSTRUCTION GENERATION FLOW\" target=\"INSTRUCTION REFINEMENT FLOW\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Instruction Refinement Flow takes instructions from the Seed Instruction Generation Flow and enhances their complexity and quality.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"SEED INSTRUCTION GENERATION FLOW\" target=\"AGENTINSTRUCT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Seed Instruction Generation Flow is one of the three flows defined by AgentInstruct to automate the generation process.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"SEED INSTRUCTION GENERATION FLOW\" target=\"TAXONOMY\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Seed Instruction Generation Flow uses a pre-defined, but extensible, taxonomy to introduce diversity in the generated instructions.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"INSTRUCTION REFINEMENT FLOW\" target=\"AGENTINSTRUCT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Instruction Refinement Flow is one of the three flows defined by AgentInstruct to automate the generation process.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"INSTRUCTION REFINEMENT FLOW\" target=\"ITERATIONS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Instruction Refinement Flow involves iterations to enhance the complexity and quality of instructions.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"INSTRUCTION REFINEMENT FLOW\" target=\"QUALITY\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Instruction Refinement Flow aims to boost the quality of the generated instructions.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"INSTRUCTION REFINEMENT FLOW\" target=\"DIVERSITY\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Instruction Refinement Flow aims to ensure diversity in the generated instructions.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"INSTRUCTION REFINEMENT FLOW\" target=\"COMPLEXITY\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Instruction Refinement Flow aims to enhance the complexity of the generated instructions.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"AGENT\" target=\"SUGGESTER AGENT\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Suggester agents are a type of agent that propose various approaches to increase the intricacy of instructions.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"AGENT\" target=\"EDITOR AGENT\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Editor agents are a type of agent that modify instructions based on suggestions from Suggester agents.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"AGENT\" target=\"LLM\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Each agent is powered by an LLM and can optionally use tools such as search APIs, code interpreter, or a calculator.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"AGENT\" target=\"SEARCH API\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Agents can use search APIs as tools to perform search operations as part of their tasks.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"AGENT\" target=\"CODE INTERPRETER\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Agents can use code interpreters as tools to interpret and execute code as part of their tasks.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"AGENT\" target=\"CALCULATOR\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Agents can use calculators as tools to perform calculations as part of their tasks.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"SUGGESTER AGENT\" target=\"EDITOR AGENT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Suggester agents propose approaches to increase the intricacy of instructions, which are then modified by Editor agents.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"SUGGESTER AGENT\" target=\"SUGGESTIONS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Suggester agents propose various suggestions to increase the intricacy of the initial instructions.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"EDITOR AGENT\" target=\"EDITING\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Editor agents perform editing to modify instructions based on the suggestions from Suggester agents.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"READING COMPREHENSION\" target=\"TEXT MODIFICATION\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Both Reading Comprehension and Text Modification are skills implemented in the agentic flows.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"READING COMPREHENSION\" target=\"TOOL USE\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Both Reading Comprehension and Tool Use are skills implemented in the agentic flows.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"READING COMPREHENSION\" target=\"OPEN DOMAIN QUESTION ANSWERING\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Both Open Domain Question Answering and Reading Comprehension are skills implemented in the agentic flows.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"READING COMPREHENSION\" target=\"MULTIPLE CHOICE QUESTIONS\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Both Multiple Choice Questions and Reading Comprehension are skills implemented in the agentic flows.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"READING COMPREHENSION\" target=\"READING COMPREHENSION TESTS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Reading comprehension tests assess the reader&#8217;s understanding of text passages.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"TEXT MODIFICATION\" target=\"TOOL USE\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Both Text Modification and Tool Use are skills implemented in the agentic flows.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"TEXT MODIFICATION\" target=\"OPEN DOMAIN QUESTION ANSWERING\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Both Open Domain Question Answering and Text Modification are skills implemented in the agentic flows.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"TOOL USE\" target=\"OPEN DOMAIN QUESTION ANSWERING\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Both Open Domain Question Answering and Tool Use are skills implemented in the agentic flows.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"TOOL USE\" target=\"WEB AGENT\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Web Agent is a type of tool use skill implemented in the agentic flows.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"BRAIN TEASER\" target=\"ANALYTICAL REASONING\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Both Brain Teaser and Analytical Reasoning are skills implemented in the agentic flows.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"ANALYTICAL REASONING\" target=\"FERMI PROBLEMS\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Both Fermi Problems and Analytical Reasoning are skills implemented in the agentic flows.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"DATA TO TEXT\" target=\"TEXT EXTRACTION\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Both Data to Text and Text Extraction are skills implemented in the agentic flows.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"CODING\" target=\"TEXT EXTRACTION\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Both Coding and Text Extraction are skills implemented in the agentic flows.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"TABLE 1\" target=\"SKILLS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Table 1 provides a full list of the 17 different skills implemented in the agentic flows.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"CASE STUDIES\" target=\"SKILLS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Case studies explain how the workflows work for generating data for specific skills.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"INSTRUCTION\" target=\"TASKS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Instructions are the tasks or guidelines that agents follow to perform their roles in the agentic flows.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>    <edge source=\"INSTRUCTION\" target=\"OBJECTIVES\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Instructions are tailored to achieve specific objectives in the Content Transformation Flow.<\/data>      <data key=\"d5\">f7eb89a70f544664546a510e46d5febd<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"0c212c1467564ad33330b1f655a8e27e","chunk":" quick, rough estimates of quantities\nwhich can be difficult to measure. Named after physicist Enrico Fermi, these problems often require\nmaking justified guesses or assumptions to reach a solution.\nCoding Coding involves writing code following instructions, understanding code, debugging code,\ntracing or writing test cases.\nText Extraction Text extraction is the process of retrieving relevant information from a larger text\ndocument. This can include tasks like named entity recognition, keyword extraction, or extracting\nspecific data fields from unstructured text.\nText Classification Text classification is a type of machine learning task where text documents are\nautomatically classified into predefined categories. This can be used for spam detection, sentiment\nanalysis, and topic labelling among others.\nRetrieval Augmented Generation Retrieval Augmented Generation (RAG) is a method used\nin natural language processing that combines retrieval-based and generative models to generate\nresponses. It first retrieves relevant documents and then uses these documents to generate a response.\nTool Use Tool use involves the manipulation of tools to achieve goals. In AI, this refers to the\nability of an AI system to use available resources or auxiliary systems to solve complex tasks.\nCreative Content Generation Creative content generation involves the creation of original\ncontent, often involving elements of novelty, value, and surprise. In AI, this could refer to generating\ntext, music, or images that are not only new but also meaningful and interesting.\nFew Shot Reasoning Few-shot reasoning refers to the ability of a machine learning model to\nunderstand new concepts, patterns, or tasks with minimal examples or guidance. It\u2019s a desired trait\nin AI, mimicking the human ability to learn quickly from few examples.\nConversation Conversation refers to conversational agents or chatbots that interact with humans\nin a natural, human-like manner.\nTable 1: List of 17 capabilities for which we implemented AgentInstruct Flows\n52.1 AgentInstruct Flow for Reading Comprehension\nReading comprehension is a critical skill involving processing and understanding text, which\nis necessary for learning and encompasses decoding, fluency, and vocabulary knowledge.\nReading comprehension questions range from asking for explicit information (literal com-\nprehension) to requiring inferences, understanding vocabulary in context, analyzing text\nstructure and argumentation, critically evaluating the content, and synthesizing informa-\ntion from different parts of or multiple texts. Reading comprehension is a very important\ncapability and can enable scenarios like question answering, search, grounded reasoning, etc.\nContent Transformation Flow Web crawls encompass an extensive collection of human-\ngenerated text, which holds potential for generating reading comprehension materials.\nHowever, these sources are not inherently structured to facilitate the teaching of read-\ning comprehension skills. Consequently, they do not support the consistent generation of\ndiverse question types required for comprehensive reading comprehension evaluation. For\ninstance, the LSAT Logical Reasoning test features specialized question categories, including\nassumption, strengthening\/weakening, flaw, and inference questions. Crafting such questions\nnecessitates passages with a particular stylistic and logical framework. The objective of\nContent Transformation Flow is to transform arbitrary articles into well-crafted pieces that\nare conducive to the formulation of a wide array of reading comprehension question types.\nOur current flow for Reading Comprehension encompasses a suite of nine content transfor-\nmation agents for generating argument passages, debates and conversations, long passages,\nmeeting transcripts, poems, satarical content, etc. Detailed description is provided in Ap-\npendix A. Given a seed article, the flow will randomly pick one of the Content Transformation\nAgents to assess the seed article and attempt to generate the text passages. The following\nprovides an example for the Argument Passage Generator .\nEXAMPLE: Content Transformation Flow\nRandom Seed\nUric acid is a substance produced naturally by the breakdown of purine (a type of dietary\nprotein). When it is in excess in the body, crystals composed of these substances are formed.\nThese crystals are deposited in various parts of the body, mainly in the joints and kidneys,\ncausing pain and other aggravations. The lack or excess of uric acid in the body is caused by\nsome diseases (such as leukemia, obesity, kidney diseases, and anemia) and factors related\nto lifestyle (consumption of alcohol and processed foods, for example).\nContents\n\u2022Where does purine come from?\n\u2022Where is uric acid found?\n\u2022What is high uric acid?\n\u2022What can high uric acid cause?\n\u2022What is low uric acid?\n\u2022Tests: how to know uric acid levels?\nWhere does purine come from?\nPurine is produced and released into the bloodstream when an amino acid is broken down\nby digestion. Therefore, it is produced naturally in the body. ... (Truncated)\n6Transformed Seed (Argument Passage Generator)\nRecent studies have indicated that high levels of uric acid in the blood, known as hyper-\nuricemia, may increase the risk of cardiovascular disease. Uric acid is a byproduct of purine\nmetabolism, and while it is naturally produced in the body, excessive amounts can lead to\nhealth complications. Hyperuricemia is typically defined as levels above 6 mg\/dL in women\nand 7 mg\/dL in men. This condition can result from increased production of uric acid or\ninsufficient elimination through urine. Factors contributing to high uric acid include a diet\nrich in purines, found in red meat and seafood, as well as lifestyle choices such as alcohol\nconsumption and physical inactivity. Conversely, low levels of uric acid, or hypouricemia,\nare less common and usually do not present symptoms. Nonetheless, they can be indicative\nof underlying kidney or liver issues. Diagnosing either condition requires laboratory blood\nand urine tests. It is important to note that while high uric acid levels are associated with\nan increased risk of cardiovascular disease, the causal","chunk_id":"0c212c1467564ad33330b1f655a8e27e","document_ids":["c5a70861b9987da7046fe2110eb3616c"],"n_tokens":1200,"entities":[{"name":"FERMI PROBLEMS","type":"CONCEPT","description":"Fermi problems are quick, rough estimates of quantities that are difficult to measure, named after physicist Enrico Fermi. They often require making justified guesses or assumptions to reach a solution.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"CODING","type":"ACTIVITY","description":"Coding involves writing code following instructions, understanding code, debugging code, and tracing or writing test cases.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"TEXT EXTRACTION","type":"PROCESS","description":"Text extraction is the process of retrieving relevant information from a larger text document, including tasks like named entity recognition, keyword extraction, or extracting specific data fields from unstructured text.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"TEXT CLASSIFICATION","type":"PROCESS","description":"Text classification is a machine learning task where text documents are automatically classified into predefined categories, used for spam detection, sentiment analysis, and topic labeling among others.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"RETRIEVAL AUGMENTED GENERATION","type":"METHOD","description":"Retrieval Augmented Generation (RAG) is a method in natural language processing that combines retrieval-based and generative models to generate responses by first retrieving relevant documents and then using these documents to generate a response.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"TOOL USE","type":"ACTIVITY","description":"Tool use involves the manipulation of tools to achieve goals. In AI, it refers to the ability of an AI system to use available resources or auxiliary systems to solve complex tasks.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"CREATIVE CONTENT GENERATION","type":"ACTIVITY","description":"Creative content generation involves the creation of original content, often involving elements of novelty, value, and surprise. In AI, this could refer to generating text, music, or images that are new, meaningful, and interesting.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"FEW SHOT REASONING","type":"CONCEPT","description":"Few-shot reasoning refers to the ability of a machine learning model to understand new concepts, patterns, or tasks with minimal examples or guidance, mimicking the human ability to learn quickly from few examples.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"CONVERSATION","type":"ACTIVITY","description":"Conversation refers to conversational agents or chatbots that interact with humans in a natural, human-like manner.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"AGENTINSTRUCT FLOW","type":"TOOL\/PROCESS","description":"AgentInstruct Flow is a process implemented for various capabilities, including reading comprehension, to facilitate learning and understanding through structured tasks and activities.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"READING COMPREHENSION","type":"SKILL","description":"Reading comprehension is a critical skill involving processing and understanding text, necessary for learning and encompassing decoding, fluency, and vocabulary knowledge. It enables scenarios like question answering, search, and grounded reasoning.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"CONTENT TRANSFORMATION FLOW","type":"PROCESS","description":"Content Transformation Flow is a process that transforms arbitrary articles into well-crafted pieces conducive to the formulation of a wide array of reading comprehension question types.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"ARGUMENT PASSAGE GENERATOR","type":"TOOL","description":"Argument Passage Generator is a tool within the Content Transformation Flow that generates argument passages from seed articles to facilitate the creation of reading comprehension materials.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"URIC ACID","type":"SUBSTANCE","description":"Uric acid is a substance produced naturally by the breakdown of purine, a type of dietary protein. Excessive amounts can lead to health complications such as hyperuricemia, which may increase the risk of cardiovascular disease.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"HYPERURICEMIA","type":"CONDITION","description":"Hyperuricemia is a condition characterized by high levels of uric acid in the blood, typically defined as levels above 6 mg\/dL in women and 7 mg\/dL in men. It can result from increased production of uric acid or insufficient elimination through urine.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"HYPOURICEMIA","type":"CONDITION","description":"Hypouricemia is a condition characterized by low levels of uric acid, which is less common and usually does not present symptoms but can indicate underlying kidney or liver issues.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"ENRICO FERMI","type":"","description":"\nEnrico Fermi was a physicist after whom Fermi problems are named.","source_id":"0c212c1467564ad33330b1f655a8e27e","entity_type":"PERSON"},{"name":"LSAT LOGICAL REASONING TEST","type":"TEST","description":"The LSAT Logical Reasoning test features specialized question categories, including assumption, strengthening\/weakening, flaw, and inference questions.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"CARDIOVASCULAR DISEASE","type":"CONDITION","description":"Cardiovascular disease is a health condition that may be associated with high levels of uric acid in the blood.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"KIDNEY DISEASES","type":"CONDITION","description":"Kidney diseases are health conditions that can be caused by the lack or excess of uric acid in the body.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"LEUKEMIA","type":"CONDITION","description":"Leukemia is a disease that can cause an imbalance of uric acid in the body.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"OBESITY","type":"CONDITION","description":"Obesity is a health condition that can cause an imbalance of uric acid in the body.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"ANEMIA","type":"CONDITION","description":"Anemia is a health condition that can cause an imbalance of uric acid in the body.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"ALCOHOL","type":"SUBSTANCE","description":"Alcohol consumption is a lifestyle factor that can contribute to high levels of uric acid in the body.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"PROCESSED FOODS","type":"SUBSTANCE","description":"Processed foods are a lifestyle factor that can contribute to high levels of uric acid in the body.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"RED MEAT","type":"SUBSTANCE","description":"Red meat is a dietary source of purines, which can contribute to high levels of uric acid in the body.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"SEAFOOD","type":"SUBSTANCE","description":"Seafood is a dietary source of purines, which can contribute to high levels of uric acid in the body.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"LABORATORY BLOOD TESTS","type":"TEST","description":"Laboratory blood tests are used to diagnose conditions related to uric acid levels in the body.","source_id":"0c212c1467564ad33330b1f655a8e27e"},{"name":"URINE TESTS","type":"TEST","description":"Urine tests are used to diagnose conditions related to uric acid levels in the body.","source_id":"0c212c1467564ad33330b1f655a8e27e"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"FERMI PROBLEMS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Fermi problems are quick, rough estimates of quantities that are difficult to measure, named after physicist Enrico Fermi. They often require making justified guesses or assumptions to reach a solution.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"CODING\">      <data key=\"d0\">ACTIVITY<\/data>      <data key=\"d1\">Coding involves writing code following instructions, understanding code, debugging code, and tracing or writing test cases.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"TEXT EXTRACTION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Text extraction is the process of retrieving relevant information from a larger text document, including tasks like named entity recognition, keyword extraction, or extracting specific data fields from unstructured text.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"TEXT CLASSIFICATION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Text classification is a machine learning task where text documents are automatically classified into predefined categories, used for spam detection, sentiment analysis, and topic labeling among others.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"RETRIEVAL AUGMENTED GENERATION\">      <data key=\"d0\">METHOD<\/data>      <data key=\"d1\">Retrieval Augmented Generation (RAG) is a method in natural language processing that combines retrieval-based and generative models to generate responses by first retrieving relevant documents and then using these documents to generate a response.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"TOOL USE\">      <data key=\"d0\">ACTIVITY<\/data>      <data key=\"d1\">Tool use involves the manipulation of tools to achieve goals. In AI, it refers to the ability of an AI system to use available resources or auxiliary systems to solve complex tasks.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"CREATIVE CONTENT GENERATION\">      <data key=\"d0\">ACTIVITY<\/data>      <data key=\"d1\">Creative content generation involves the creation of original content, often involving elements of novelty, value, and surprise. In AI, this could refer to generating text, music, or images that are new, meaningful, and interesting.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"FEW SHOT REASONING\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Few-shot reasoning refers to the ability of a machine learning model to understand new concepts, patterns, or tasks with minimal examples or guidance, mimicking the human ability to learn quickly from few examples.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"CONVERSATION\">      <data key=\"d0\">ACTIVITY<\/data>      <data key=\"d1\">Conversation refers to conversational agents or chatbots that interact with humans in a natural, human-like manner.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"AGENTINSTRUCT FLOW\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">AgentInstruct Flow is a process implemented for various capabilities, including reading comprehension, to facilitate learning and understanding through structured tasks and activities.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"READING COMPREHENSION\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">Reading comprehension is a critical skill involving processing and understanding text, necessary for learning and encompassing decoding, fluency, and vocabulary knowledge. It enables scenarios like question answering, search, and grounded reasoning.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"CONTENT TRANSFORMATION FLOW\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Content Transformation Flow is a process that transforms arbitrary articles into well-crafted pieces conducive to the formulation of a wide array of reading comprehension question types.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"ARGUMENT PASSAGE GENERATOR\">      <data key=\"d0\">TOOL<\/data>      <data key=\"d1\">Argument Passage Generator is a tool within the Content Transformation Flow that generates argument passages from seed articles to facilitate the creation of reading comprehension materials.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"URIC ACID\">      <data key=\"d0\">SUBSTANCE<\/data>      <data key=\"d1\">Uric acid is a substance produced naturally by the breakdown of purine, a type of dietary protein. Excessive amounts can lead to health complications such as hyperuricemia, which may increase the risk of cardiovascular disease.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"HYPERURICEMIA\">      <data key=\"d0\">CONDITION<\/data>      <data key=\"d1\">Hyperuricemia is a condition characterized by high levels of uric acid in the blood, typically defined as levels above 6 mg\/dL in women and 7 mg\/dL in men. It can result from increased production of uric acid or insufficient elimination through urine.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"HYPOURICEMIA\">      <data key=\"d0\">CONDITION<\/data>      <data key=\"d1\">Hypouricemia is a condition characterized by low levels of uric acid, which is less common and usually does not present symptoms but can indicate underlying kidney or liver issues.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"ENRICO FERMI\">      <data key=\"d0\" \/>      <data key=\"d1\">Enrico Fermi was a physicist after whom Fermi problems are named.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LSAT LOGICAL REASONING TEST\">      <data key=\"d0\">TEST<\/data>      <data key=\"d1\">The LSAT Logical Reasoning test features specialized question categories, including assumption, strengthening\/weakening, flaw, and inference questions.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"CARDIOVASCULAR DISEASE\">      <data key=\"d0\">CONDITION<\/data>      <data key=\"d1\">Cardiovascular disease is a health condition that may be associated with high levels of uric acid in the blood.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"KIDNEY DISEASES\">      <data key=\"d0\">CONDITION<\/data>      <data key=\"d1\">Kidney diseases are health conditions that can be caused by the lack or excess of uric acid in the body.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"LEUKEMIA\">      <data key=\"d0\">CONDITION<\/data>      <data key=\"d1\">Leukemia is a disease that can cause an imbalance of uric acid in the body.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"OBESITY\">      <data key=\"d0\">CONDITION<\/data>      <data key=\"d1\">Obesity is a health condition that can cause an imbalance of uric acid in the body.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"ANEMIA\">      <data key=\"d0\">CONDITION<\/data>      <data key=\"d1\">Anemia is a health condition that can cause an imbalance of uric acid in the body.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"ALCOHOL\">      <data key=\"d0\">SUBSTANCE<\/data>      <data key=\"d1\">Alcohol consumption is a lifestyle factor that can contribute to high levels of uric acid in the body.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"PROCESSED FOODS\">      <data key=\"d0\">SUBSTANCE<\/data>      <data key=\"d1\">Processed foods are a lifestyle factor that can contribute to high levels of uric acid in the body.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"RED MEAT\">      <data key=\"d0\">SUBSTANCE<\/data>      <data key=\"d1\">Red meat is a dietary source of purines, which can contribute to high levels of uric acid in the body.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"SEAFOOD\">      <data key=\"d0\">SUBSTANCE<\/data>      <data key=\"d1\">Seafood is a dietary source of purines, which can contribute to high levels of uric acid in the body.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"LABORATORY BLOOD TESTS\">      <data key=\"d0\">TEST<\/data>      <data key=\"d1\">Laboratory blood tests are used to diagnose conditions related to uric acid levels in the body.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <node id=\"URINE TESTS\">      <data key=\"d0\">TEST<\/data>      <data key=\"d1\">Urine tests are used to diagnose conditions related to uric acid levels in the body.<\/data>      <data key=\"d2\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/node>    <edge source=\"FERMI PROBLEMS\" target=\"ENRICO FERMI\">      <data key=\"d4\">18.0<\/data>      <data key=\"d5\">Fermi problems are named after physicist Enrico Fermi.<\/data>      <data key=\"d6\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/edge>    <edge source=\"TEXT EXTRACTION\" target=\"TEXT CLASSIFICATION\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Both text extraction and text classification are processes used in handling and analyzing text documents.<\/data>      <data key=\"d6\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/edge>    <edge source=\"TEXT EXTRACTION\" target=\"RETRIEVAL AUGMENTED GENERATION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Retrieval Augmented Generation involves retrieving relevant documents, which is a form of text extraction.<\/data>      <data key=\"d6\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT FLOW\" target=\"READING COMPREHENSION\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">AgentInstruct Flow includes a specific flow for reading comprehension to facilitate learning and understanding.<\/data>      <data key=\"d6\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/edge>    <edge source=\"READING COMPREHENSION\" target=\"CONTENT TRANSFORMATION FLOW\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Content Transformation Flow is used to generate materials that support reading comprehension.<\/data>      <data key=\"d6\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/edge>    <edge source=\"CONTENT TRANSFORMATION FLOW\" target=\"ARGUMENT PASSAGE GENERATOR\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Argument Passage Generator is a tool within the Content Transformation Flow.<\/data>      <data key=\"d6\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/edge>    <edge source=\"CONTENT TRANSFORMATION FLOW\" target=\"LSAT LOGICAL REASONING TEST\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">The Content Transformation Flow aims to generate materials that support the creation of diverse question types required for comprehensive reading comprehension evaluation, including those found in the LSAT Logical Reasoning test.<\/data>      <data key=\"d6\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/edge>    <edge source=\"URIC ACID\" target=\"HYPERURICEMIA\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Hyperuricemia is a condition caused by high levels of uric acid in the blood.<\/data>      <data key=\"d6\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/edge>    <edge source=\"URIC ACID\" target=\"HYPOURICEMIA\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Hypouricemia is a condition caused by low levels of uric acid in the blood.<\/data>      <data key=\"d6\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/edge>    <edge source=\"URIC ACID\" target=\"CARDIOVASCULAR DISEASE\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">High levels of uric acid in the blood, known as hyperuricemia, may increase the risk of cardiovascular disease.<\/data>      <data key=\"d6\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/edge>    <edge source=\"URIC ACID\" target=\"KIDNEY DISEASES\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Kidney diseases can be caused by an imbalance of uric acid in the body.<\/data>      <data key=\"d6\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/edge>    <edge source=\"URIC ACID\" target=\"LEUKEMIA\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Leukemia can cause an imbalance of uric acid in the body.<\/data>      <data key=\"d6\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/edge>    <edge source=\"URIC ACID\" target=\"OBESITY\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Obesity can cause an imbalance of uric acid in the body.<\/data>      <data key=\"d6\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/edge>    <edge source=\"URIC ACID\" target=\"ANEMIA\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Anemia can cause an imbalance of uric acid in the body.<\/data>      <data key=\"d6\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/edge>    <edge source=\"URIC ACID\" target=\"ALCOHOL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Alcohol consumption is a lifestyle factor that can contribute to high levels of uric acid in the body.<\/data>      <data key=\"d6\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/edge>    <edge source=\"URIC ACID\" target=\"PROCESSED FOODS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Processed foods are a lifestyle factor that can contribute to high levels of uric acid in the body.<\/data>      <data key=\"d6\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/edge>    <edge source=\"URIC ACID\" target=\"RED MEAT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Red meat is a dietary source of purines, which can contribute to high levels of uric acid in the body.<\/data>      <data key=\"d6\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/edge>    <edge source=\"URIC ACID\" target=\"SEAFOOD\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Seafood is a dietary source of purines, which can contribute to high levels of uric acid in the body.<\/data>      <data key=\"d6\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/edge>    <edge source=\"URIC ACID\" target=\"LABORATORY BLOOD TESTS\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Laboratory blood tests are used to diagnose conditions related to uric acid levels in the body.<\/data>      <data key=\"d6\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/edge>    <edge source=\"URIC ACID\" target=\"URINE TESTS\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Urine tests are used to diagnose conditions related to uric acid levels in the body.<\/data>      <data key=\"d6\">0c212c1467564ad33330b1f655a8e27e<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"1d8835c0ce90e56be22873bcf2740a5d","chunk":" found in red meat and seafood, as well as lifestyle choices such as alcohol\nconsumption and physical inactivity. Conversely, low levels of uric acid, or hypouricemia,\nare less common and usually do not present symptoms. Nonetheless, they can be indicative\nof underlying kidney or liver issues. Diagnosing either condition requires laboratory blood\nand urine tests. It is important to note that while high uric acid levels are associated with\nan increased risk of cardiovascular disease, the causal relationship remains to be conclusively\nestablished.\nSeed Instruction Generation Flow We have currently compiled a collection of 43\nreading comprehension questions types. The list includes literal comprehension questions,\ncritical comprehension questions, evaluative comprehension questions, reasoning, identifying\nassumptions, identifying information that strengthens\/weakens an argument, ordering events,\netc.\nA list some of these types is in Appendix A.\nWe have defined multiple Agents targeting these categories. Each of these agent receives as\ninput a piece of text and generates a list of questions based on a predefined question type.\nThe orchestration process will engage a subset of these agents, determined by the content\ntransformation agent in the preceding step. Upon completion of this phase, we will obtain a\ncollection of (passage, question) pairs that will constitute the input for the subsequent stage.\nThe following figure provides an example of Strengthen type question that is generated from\nthe running example.\nEXAMPLE: Seed Instruction\nWhich one of the following, if true, most strengthens the argument that high lev-\nels of uric acid increase the risk of cardiovascular disease?\n(A) Some individuals with hyperuricemia do not develop cardiovascular disease.\n(B) Physical activity has been found to have no significant impact on uric acid levels in the\nblood.\n(C) Dietary supplements have been shown to reduce uric acid levels in the blood.\n(D) A significant number of patients with cardiovascular disease have been found to have\nuric acid levels above the defined thresholds for hyperuricemia.\n(E) Individuals with a family history of cardiovascular disease are more likely to have high\nuric acid levels.\nInstruction Refinement Flow The refinement flow contains multiple suggester-editor\nagents that will go through each of the (passage, question) pairs and create more such pairs\nwith the following goals: (1) Modify the passage to make the question unanswerable, (2)\nModify the passage to alter the answer, if possible, in opposite direction, or (3) Modify the\nquestions or answer choices (if applicable) to make them complex.\nHere is an example where the suggester agent that tries to add a difficult distractor to\nconfuse the test taker.\n7EXAMPLE: Refinement Flow\nSUGGESTER\n\u2022Suggestion 1 Introduce a hypothetical study or finding that could potentially\nstrengthen the argument, requiring the test-taker to infer its impact on the rela-\ntionship between uric acid levels and cardiovascular disease.\n\u2022Suggestion 2 Add a layer of complexity by suggesting a genetic predisposition\nto hyperuricemia and its correlation with increased cardiovascular events, which\nwould require the test-taker to consider both genetic and physiological factors.\n\u2022Suggestion 3 Include a distractor option that seems to strengthen the argument\nbut upon closer examination, it does not directly relate to the causal relationship\nbetween uric acid levels and cardiovascular disease, thus testing the test-taker\u2019s\nability to discern relevant from irrelevant information.\nEDITOR\n\u2022Modification 1,2 (omitted for brevity)\n\u2022Modification 3 Which one of the following, if true, most strengthens the argument\nthat high levels of uric acid increase the risk of cardiovascular disease?\n(A) Some individuals with hyperuricemia do not develop cardiovascular disease.\n(B) Physical activity has been found to have no significant impact on uric acid\nlevels in the blood.\n(C) A placebo-controlled trial shows that individuals taking uric acid-lowering\nmedication do not exhibit a reduced incidence of cardiovascular disease compared\nto the placebo group.\n(D) A significant number of patients with cardiovascular disease have been found\nto have uric acid levels above the defined thresholds for hyperuricemia.\n(E) A cross-sectional study finds that high uric acid levels are associated with other\nrisk factors for cardiovascular disease, such as hypertension and diabetes, but does\nnot establish a direct causal link.\n2.2 AgentInstruct Flow for Text Modification\nText modification is the process of editing and refining written content to enhance its quality\nand effectiveness or alter its attributes. This involves correcting spelling and grammar,\nclarifyingideas, reorganizingcontentforbetterflow, adjustingtone, ensuringstyleconsistency,\nfact-checking, removingredundancies, formatting, developingcontent, andadaptingtospecific\naudiences. It is a useful skill for LLMs that help in content writing. While several content\ntransformation agents can be introduced to intentionally modify the text as described earlier,\nwe focus here on showing the how the instructions are created and refined.\nSeed Instruction Generation Flow We have currently compiled a collection of 18types\nof text modification tasks including paraphrasing, expansion, simplification, redacting or\nremoving content, styling, code switching, etc. The full list is in Appendix A.\nWe define an Agent for each of the task type. Each agent takes as input a piece of text and\ncreates several text modification tasks of the associated type. Here we provide an example\ninput and a task created by the Paraphrasing Agent.\n8EXAMPLE: Seed Instruction\nRandom Seed\nApril 6-8, 2017, University of Iowa, Iowa City, USA. Abstracts due December 1, 2016.\nFinance is hard to escape. In recent years, the increasing social impact and interconnection\nof financial discourses, markets, actors, and institutions have","chunk_id":"1d8835c0ce90e56be22873bcf2740a5d","document_ids":["c5a70861b9987da7046fe2110eb3616c"],"n_tokens":1200,"entities":[{"name":"URIC ACID","type":"SUBSTANCE","description":"Uric acid is a chemical found in red meat and seafood, and its levels in the body can be influenced by lifestyle choices such as alcohol consumption and physical inactivity. High levels are associated with an increased risk of cardiovascular disease, while low levels can indicate underlying kidney or liver issues.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"HYPERURICEMIA","type":"CONDITION","description":"Hyperuricemia is a condition characterized by high levels of uric acid in the blood, which is associated with an increased risk of cardiovascular disease.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"HYPOURICEMIA","type":"CONDITION","description":"Hypouricemia is a condition characterized by low levels of uric acid in the blood, which is less common and usually asymptomatic but can indicate underlying kidney or liver issues.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"CARDIOVASCULAR DISEASE","type":"DISEASE","description":"Cardiovascular disease is a class of diseases that involve the heart or blood vessels, and high levels of uric acid are associated with an increased risk of developing these diseases.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"LABORATORY TESTS","type":"PROCESS","description":"Laboratory tests are medical tests conducted on blood and urine samples to diagnose conditions such as hyperuricemia and hypouricemia.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"SEED INSTRUCTION GENERATION FLOW","type":"PROCESS","description":"The Seed Instruction Generation Flow is a process that compiles a collection of reading comprehension question types and uses multiple agents to generate questions based on predefined types from a given text.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"AGENT","type":"TOOL\/PROCESS","description":"An Agent is a tool or process that receives a piece of text and generates a list of questions or modifies text based on predefined tasks such as paraphrasing, expansion, or simplification.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"CONTENT TRANSFORMATION AGENT","type":"TOOL\/PROCESS","description":"The Content Transformation Agent is a tool that determines which subset of agents to engage in the Seed Instruction Generation Flow based on the content.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"PASSAGE-QUESTION PAIRS","type":"OUTPUT","description":"Passage-question pairs are the output of the Seed Instruction Generation Flow, consisting of a passage of text and a corresponding question generated by the agents.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"INSTRUCTION REFINEMENT FLOW","type":"PROCESS","description":"The Instruction Refinement Flow is a process involving suggester-editor agents that modify passage-question pairs to create more complex or unanswerable questions, or to alter the answers.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"SUGGESTER AGENT","type":"TOOL\/PROCESS","description":"The Suggester Agent is a tool that provides suggestions to modify passage-question pairs, such as introducing hypothetical studies or adding complexity to questions.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"EDITOR AGENT","type":"TOOL\/PROCESS","description":"The Editor Agent is a tool that implements modifications suggested by the Suggester Agent to refine passage-question pairs.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"AGENTINSTRUCT FLOW","type":"PROCESS","description":"The AgentInstruct Flow is a process for text modification that involves editing and refining written content to enhance its quality and effectiveness or alter its attributes.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"TEXT MODIFICATION TASKS","type":"TASK","description":"Text modification tasks are specific tasks such as paraphrasing, expansion, simplification, and redacting content, which are performed by agents in the AgentInstruct Flow.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"PARAPHRASING AGENT","type":"TOOL\/PROCESS","description":"The Paraphrasing Agent is a tool that takes a piece of text and creates several paraphrased versions of it as part of the text modification tasks.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"RED MEAT","type":"SUBSTANCE","description":"Red meat is a type of food that contains uric acid, which can influence its levels in the body.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"SEAFOOD","type":"SUBSTANCE","description":"Seafood is a type of food that contains uric acid, which can influence its levels in the body.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"ALCOHOL CONSUMPTION","type":"LIFESTYLE CHOICE","description":"Alcohol consumption is a lifestyle choice that can influence uric acid levels in the body.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"PHYSICAL INACTIVITY","type":"LIFESTYLE CHOICE","description":"Physical inactivity is a lifestyle choice that can influence uric acid levels in the body.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"KIDNEY ISSUES","type":"CONDITION","description":"Kidney issues can be indicated by low levels of uric acid in the blood, known as hypouricemia.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"LIVER ISSUES","type":"CONDITION","description":"Liver issues can be indicated by low levels of uric acid in the blood, known as hypouricemia.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"LITERAL COMPREHENSION QUESTIONS","type":"QUESTION TYPE","description":"Literal comprehension questions are a type of reading comprehension question that focuses on understanding the explicit content of a text.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"CRITICAL COMPREHENSION QUESTIONS","type":"QUESTION TYPE","description":"Critical comprehension questions are a type of reading comprehension question that focuses on evaluating and analyzing the content of a text.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"EVALUATIVE COMPREHENSION QUESTIONS","type":"QUESTION TYPE","description":"Evaluative comprehension questions are a type of reading comprehension question that focuses on making judgments about the content of a text.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"REASONING QUESTIONS","type":"QUESTION TYPE","description":"Reasoning questions are a type of reading comprehension question that focuses on logical thinking and drawing conclusions from the content of a text.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"IDENTIFYING ASSUMPTIONS QUESTIONS","type":"QUESTION TYPE","description":"Identifying assumptions questions are a type of reading comprehension question that focuses on recognizing underlying assumptions in the content of a text.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"IDENTIFYING INFORMATION THAT STRENGTHENS\/WEAKENS AN ARGUMENT QUESTIONS","type":"QUESTION TYPE","description":"These questions focus on identifying information that either strengthens or weakens an argument presented in the text.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"ORDERING EVENTS QUESTIONS","type":"QUESTION TYPE","description":"Ordering events questions are a type of reading comprehension question that focuses on arranging events in the correct sequence based on the content of a text.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"APPENDIX A","type":"DOCUMENT SECTION","description":"Appendix A is a section in a document that lists various types of reading comprehension questions and text modification tasks.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"STRENGTHEN TYPE QUESTION","type":"QUESTION TYPE","description":"A strengthen type question is a reading comprehension question that asks which information most strengthens an argument presented in the text.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"HYPOTHETICAL STUDY","type":"STUDY","description":"A hypothetical study is a suggested study that could potentially strengthen an argument, requiring the test-taker to infer its impact on the relationship between uric acid levels and cardiovascular disease.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"GENETIC PREDISPOSITION","type":"CONDITION","description":"Genetic predisposition refers to the likelihood of developing a condition based on one's genetic makeup, such as hyperuricemia and its correlation with increased cardiovascular events.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"DISTRACTOR OPTION","type":"QUESTION ELEMENT","description":"A distractor option is a misleading answer choice in a multiple-choice question that seems correct but does not directly relate to the causal relationship being tested.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"PARAPHRASING","type":"TEXT MODIFICATION TASK","description":"Paraphrasing is a text modification task that involves rephrasing a piece of text while retaining its original meaning.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"EXPANSION","type":"TEXT MODIFICATION TASK","description":"Expansion is a text modification task that involves adding more information to a piece of text to make it more comprehensive.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"SIMPLIFICATION","type":"TEXT MODIFICATION TASK","description":"Simplification is a text modification task that involves making a piece of text easier to understand by reducing its complexity.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"REDACTING","type":"TEXT MODIFICATION TASK","description":"Redacting is a text modification task that involves removing or obscuring parts of a text for confidentiality or clarity.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"STYLING","type":"TEXT MODIFICATION TASK","description":"Styling is a text modification task that involves changing the appearance or format of a text to improve its presentation.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"},{"name":"CODE SWITCHING","type":"TEXT MODIFICATION TASK","description":"Code switching is a text modification task that involves alternating between different languages or dialects within a text.","source_id":"1d8835c0ce90e56be22873bcf2740a5d"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"URIC ACID\">      <data key=\"d0\">SUBSTANCE<\/data>      <data key=\"d1\">Uric acid is a chemical found in red meat and seafood, and its levels in the body can be influenced by lifestyle choices such as alcohol consumption and physical inactivity. High levels are associated with an increased risk of cardiovascular disease, while low levels can indicate underlying kidney or liver issues.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"HYPERURICEMIA\">      <data key=\"d0\">CONDITION<\/data>      <data key=\"d1\">Hyperuricemia is a condition characterized by high levels of uric acid in the blood, which is associated with an increased risk of cardiovascular disease.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"HYPOURICEMIA\">      <data key=\"d0\">CONDITION<\/data>      <data key=\"d1\">Hypouricemia is a condition characterized by low levels of uric acid in the blood, which is less common and usually asymptomatic but can indicate underlying kidney or liver issues.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"CARDIOVASCULAR DISEASE\">      <data key=\"d0\">DISEASE<\/data>      <data key=\"d1\">Cardiovascular disease is a class of diseases that involve the heart or blood vessels, and high levels of uric acid are associated with an increased risk of developing these diseases.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"LABORATORY TESTS\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Laboratory tests are medical tests conducted on blood and urine samples to diagnose conditions such as hyperuricemia and hypouricemia.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"SEED INSTRUCTION GENERATION FLOW\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The Seed Instruction Generation Flow is a process that compiles a collection of reading comprehension question types and uses multiple agents to generate questions based on predefined types from a given text.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"AGENT\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">An Agent is a tool or process that receives a piece of text and generates a list of questions or modifies text based on predefined tasks such as paraphrasing, expansion, or simplification.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"CONTENT TRANSFORMATION AGENT\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">The Content Transformation Agent is a tool that determines which subset of agents to engage in the Seed Instruction Generation Flow based on the content.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"PASSAGE-QUESTION PAIRS\">      <data key=\"d0\">OUTPUT<\/data>      <data key=\"d1\">Passage-question pairs are the output of the Seed Instruction Generation Flow, consisting of a passage of text and a corresponding question generated by the agents.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"INSTRUCTION REFINEMENT FLOW\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The Instruction Refinement Flow is a process involving suggester-editor agents that modify passage-question pairs to create more complex or unanswerable questions, or to alter the answers.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"SUGGESTER AGENT\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">The Suggester Agent is a tool that provides suggestions to modify passage-question pairs, such as introducing hypothetical studies or adding complexity to questions.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"EDITOR AGENT\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">The Editor Agent is a tool that implements modifications suggested by the Suggester Agent to refine passage-question pairs.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"AGENTINSTRUCT FLOW\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The AgentInstruct Flow is a process for text modification that involves editing and refining written content to enhance its quality and effectiveness or alter its attributes.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"TEXT MODIFICATION TASKS\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">Text modification tasks are specific tasks such as paraphrasing, expansion, simplification, and redacting content, which are performed by agents in the AgentInstruct Flow.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"PARAPHRASING AGENT\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">The Paraphrasing Agent is a tool that takes a piece of text and creates several paraphrased versions of it as part of the text modification tasks.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"RED MEAT\">      <data key=\"d0\">SUBSTANCE<\/data>      <data key=\"d1\">Red meat is a type of food that contains uric acid, which can influence its levels in the body.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"SEAFOOD\">      <data key=\"d0\">SUBSTANCE<\/data>      <data key=\"d1\">Seafood is a type of food that contains uric acid, which can influence its levels in the body.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"ALCOHOL CONSUMPTION\">      <data key=\"d0\">LIFESTYLE CHOICE<\/data>      <data key=\"d1\">Alcohol consumption is a lifestyle choice that can influence uric acid levels in the body.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"PHYSICAL INACTIVITY\">      <data key=\"d0\">LIFESTYLE CHOICE<\/data>      <data key=\"d1\">Physical inactivity is a lifestyle choice that can influence uric acid levels in the body.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"KIDNEY ISSUES\">      <data key=\"d0\">CONDITION<\/data>      <data key=\"d1\">Kidney issues can be indicated by low levels of uric acid in the blood, known as hypouricemia.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"LIVER ISSUES\">      <data key=\"d0\">CONDITION<\/data>      <data key=\"d1\">Liver issues can be indicated by low levels of uric acid in the blood, known as hypouricemia.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"LITERAL COMPREHENSION QUESTIONS\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">Literal comprehension questions are a type of reading comprehension question that focuses on understanding the explicit content of a text.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"CRITICAL COMPREHENSION QUESTIONS\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">Critical comprehension questions are a type of reading comprehension question that focuses on evaluating and analyzing the content of a text.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"EVALUATIVE COMPREHENSION QUESTIONS\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">Evaluative comprehension questions are a type of reading comprehension question that focuses on making judgments about the content of a text.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"REASONING QUESTIONS\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">Reasoning questions are a type of reading comprehension question that focuses on logical thinking and drawing conclusions from the content of a text.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"IDENTIFYING ASSUMPTIONS QUESTIONS\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">Identifying assumptions questions are a type of reading comprehension question that focuses on recognizing underlying assumptions in the content of a text.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"IDENTIFYING INFORMATION THAT STRENGTHENS\/WEAKENS AN ARGUMENT QUESTIONS\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">These questions focus on identifying information that either strengthens or weakens an argument presented in the text.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"ORDERING EVENTS QUESTIONS\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">Ordering events questions are a type of reading comprehension question that focuses on arranging events in the correct sequence based on the content of a text.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"APPENDIX A\">      <data key=\"d0\">DOCUMENT SECTION<\/data>      <data key=\"d1\">Appendix A is a section in a document that lists various types of reading comprehension questions and text modification tasks.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"STRENGTHEN TYPE QUESTION\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">A strengthen type question is a reading comprehension question that asks which information most strengthens an argument presented in the text.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"HYPOTHETICAL STUDY\">      <data key=\"d0\">STUDY<\/data>      <data key=\"d1\">A hypothetical study is a suggested study that could potentially strengthen an argument, requiring the test-taker to infer its impact on the relationship between uric acid levels and cardiovascular disease.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"GENETIC PREDISPOSITION\">      <data key=\"d0\">CONDITION<\/data>      <data key=\"d1\">Genetic predisposition refers to the likelihood of developing a condition based on one's genetic makeup, such as hyperuricemia and its correlation with increased cardiovascular events.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"DISTRACTOR OPTION\">      <data key=\"d0\">QUESTION ELEMENT<\/data>      <data key=\"d1\">A distractor option is a misleading answer choice in a multiple-choice question that seems correct but does not directly relate to the causal relationship being tested.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"PARAPHRASING\">      <data key=\"d0\">TEXT MODIFICATION TASK<\/data>      <data key=\"d1\">Paraphrasing is a text modification task that involves rephrasing a piece of text while retaining its original meaning.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"EXPANSION\">      <data key=\"d0\">TEXT MODIFICATION TASK<\/data>      <data key=\"d1\">Expansion is a text modification task that involves adding more information to a piece of text to make it more comprehensive.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"SIMPLIFICATION\">      <data key=\"d0\">TEXT MODIFICATION TASK<\/data>      <data key=\"d1\">Simplification is a text modification task that involves making a piece of text easier to understand by reducing its complexity.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"REDACTING\">      <data key=\"d0\">TEXT MODIFICATION TASK<\/data>      <data key=\"d1\">Redacting is a text modification task that involves removing or obscuring parts of a text for confidentiality or clarity.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"STYLING\">      <data key=\"d0\">TEXT MODIFICATION TASK<\/data>      <data key=\"d1\">Styling is a text modification task that involves changing the appearance or format of a text to improve its presentation.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <node id=\"CODE SWITCHING\">      <data key=\"d0\">TEXT MODIFICATION TASK<\/data>      <data key=\"d1\">Code switching is a text modification task that involves alternating between different languages or dialects within a text.<\/data>      <data key=\"d2\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/node>    <edge source=\"URIC ACID\" target=\"HYPERURICEMIA\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">High levels of uric acid in the blood lead to the condition known as hyperuricemia.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"URIC ACID\" target=\"HYPOURICEMIA\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Low levels of uric acid in the blood lead to the condition known as hypouricemia.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"URIC ACID\" target=\"CARDIOVASCULAR DISEASE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">High levels of uric acid are associated with an increased risk of cardiovascular disease.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"URIC ACID\" target=\"RED MEAT\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Red meat contains uric acid, which can influence its levels in the body.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"URIC ACID\" target=\"SEAFOOD\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Seafood contains uric acid, which can influence its levels in the body.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"URIC ACID\" target=\"ALCOHOL CONSUMPTION\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Alcohol consumption can influence uric acid levels in the body.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"URIC ACID\" target=\"PHYSICAL INACTIVITY\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Physical inactivity can influence uric acid levels in the body.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"HYPERURICEMIA\" target=\"CARDIOVASCULAR DISEASE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Hyperuricemia is associated with an increased risk of cardiovascular disease.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"HYPERURICEMIA\" target=\"LABORATORY TESTS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Laboratory tests are required to diagnose hyperuricemia.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"HYPOURICEMIA\" target=\"LABORATORY TESTS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Laboratory tests are required to diagnose hypouricemia.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"HYPOURICEMIA\" target=\"KIDNEY ISSUES\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Hypouricemia can indicate underlying kidney issues.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"HYPOURICEMIA\" target=\"LIVER ISSUES\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Hypouricemia can indicate underlying liver issues.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"SEED INSTRUCTION GENERATION FLOW\" target=\"AGENT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Seed Instruction Generation Flow uses multiple agents to generate questions from a given text.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"SEED INSTRUCTION GENERATION FLOW\" target=\"PASSAGE-QUESTION PAIRS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Seed Instruction Generation Flow produces passage-question pairs as its output.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"SEED INSTRUCTION GENERATION FLOW\" target=\"LITERAL COMPREHENSION QUESTIONS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The Seed Instruction Generation Flow includes literal comprehension questions as one of the types of reading comprehension questions.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"SEED INSTRUCTION GENERATION FLOW\" target=\"CRITICAL COMPREHENSION QUESTIONS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The Seed Instruction Generation Flow includes critical comprehension questions as one of the types of reading comprehension questions.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"SEED INSTRUCTION GENERATION FLOW\" target=\"EVALUATIVE COMPREHENSION QUESTIONS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The Seed Instruction Generation Flow includes evaluative comprehension questions as one of the types of reading comprehension questions.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"SEED INSTRUCTION GENERATION FLOW\" target=\"REASONING QUESTIONS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The Seed Instruction Generation Flow includes reasoning questions as one of the types of reading comprehension questions.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"SEED INSTRUCTION GENERATION FLOW\" target=\"IDENTIFYING ASSUMPTIONS QUESTIONS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The Seed Instruction Generation Flow includes identifying assumptions questions as one of the types of reading comprehension questions.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"SEED INSTRUCTION GENERATION FLOW\" target=\"IDENTIFYING INFORMATION THAT STRENGTHENS\/WEAKENS AN ARGUMENT QUESTIONS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The Seed Instruction Generation Flow includes questions that identify information that strengthens or weakens an argument.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"SEED INSTRUCTION GENERATION FLOW\" target=\"ORDERING EVENTS QUESTIONS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The Seed Instruction Generation Flow includes ordering events questions as one of the types of reading comprehension questions.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"SEED INSTRUCTION GENERATION FLOW\" target=\"APPENDIX A\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Appendix A lists the types of reading comprehension questions included in the Seed Instruction Generation Flow.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"AGENT\" target=\"CONTENT TRANSFORMATION AGENT\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The Content Transformation Agent determines which subset of agents to engage in the Seed Instruction Generation Flow.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"INSTRUCTION REFINEMENT FLOW\" target=\"SUGGESTER AGENT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Instruction Refinement Flow involves the Suggester Agent to provide suggestions for modifying passage-question pairs.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"INSTRUCTION REFINEMENT FLOW\" target=\"EDITOR AGENT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Instruction Refinement Flow involves the Editor Agent to implement modifications suggested by the Suggester Agent.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"INSTRUCTION REFINEMENT FLOW\" target=\"HYPOTHETICAL STUDY\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The Instruction Refinement Flow suggests introducing a hypothetical study to strengthen an argument.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"INSTRUCTION REFINEMENT FLOW\" target=\"GENETIC PREDISPOSITION\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The Instruction Refinement Flow suggests adding complexity by considering genetic predisposition to hyperuricemia.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"INSTRUCTION REFINEMENT FLOW\" target=\"DISTRACTOR OPTION\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The Instruction Refinement Flow suggests including a distractor option to test the test-taker's ability to discern relevant from irrelevant information.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT FLOW\" target=\"TEXT MODIFICATION TASKS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The AgentInstruct Flow involves performing various text modification tasks.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT FLOW\" target=\"PARAPHRASING AGENT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The AgentInstruct Flow includes the Paraphrasing Agent to create paraphrased versions of text.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT FLOW\" target=\"PARAPHRASING\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The AgentInstruct Flow includes paraphrasing as one of the text modification tasks.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT FLOW\" target=\"EXPANSION\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The AgentInstruct Flow includes expansion as one of the text modification tasks.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT FLOW\" target=\"SIMPLIFICATION\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The AgentInstruct Flow includes simplification as one of the text modification tasks.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT FLOW\" target=\"REDACTING\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The AgentInstruct Flow includes redacting as one of the text modification tasks.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT FLOW\" target=\"STYLING\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The AgentInstruct Flow includes styling as one of the text modification tasks.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT FLOW\" target=\"CODE SWITCHING\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The AgentInstruct Flow includes code switching as one of the text modification tasks.<\/data>      <data key=\"d5\">1d8835c0ce90e56be22873bcf2740a5d<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"427e98b00e49b6a8f8649054122dd45b","chunk":" text and\ncreates several text modification tasks of the associated type. Here we provide an example\ninput and a task created by the Paraphrasing Agent.\n8EXAMPLE: Seed Instruction\nRandom Seed\nApril 6-8, 2017, University of Iowa, Iowa City, USA. Abstracts due December 1, 2016.\nFinance is hard to escape. In recent years, the increasing social impact and interconnection\nof financial discourses, markets, actors, and institutions have been understood under the\nbroad concept of financialization. Natascha van der Zwan identifies three distinct research\nstreams that have approached financialization as 1) a regime of accumulation, 2) the influence\nof financial markets and instruments on non-financial corporations as well as the banking\nand finance industry, and 3) a discourse of risk-taking, self-management and self-fulfillment\nthat is transforming people into investing subjects. Some anthropological skeptics, however,\nargue that finance has a far longer genealogy than the financialization literature has to date\nrecognized. For example, in the context of a lengthy human history of creating hierarchy,\nfinancialization may simply be a new technology serving an old purpose.\n... (omitted for brevity)... \u00b7The supply chains of financial products connect different places\nand political projects across the globe. How do such financial instruments transform social\nlife?\nAbstract deadline is December 1, 2016.\n1. Go to americananthro.org and log in. If you don\u2019t have a login id and password, create\none (you do not need to join the American Anthropological Association).\n2. Once you are logged in, look to the left hand column, click on Meeting registration.\n3. Click on register under the SEA 2017 Annual Meeting then follow online prompts to\nregister for the meeting (if we do not accept your abstract and you decide not to attend,\nyou may request that your registration fee be refunded and we would be happy to do so).\n4. Once you are registered, AAA will automatically send you an email inviting you to submit\nan abstract. Click the link and follow the instructions.\nTask:\nRewrite the event details (date, location, abstract deadline) in a more casual tone.\nGiven a random seed, the seed instruction creation flow randomly picks one of the 18agents\nand uses that to obtain a seed (text, text modification instruction) pair.\nInstruction Refinement Flow The refinement flow consists of only one Suggester-Editor\npair. The Suggester-Editor duo increase the complexity of the generated instructions while\ntaking as input the text and the task modification instruction as input. Here we show three\nsuggestions and edits as proposed by the suggester-editor pair.\nEXAMPLE: IRefinement Flow\nSuggestions\nSuggestion 1: Incorporate a fictional narrative. Use a conversational style with colloquial\nlanguage and include a humorous element.\nSuggestion 2: Translate the event details into a poetic format. Maintain accurate infor-\nmation while using rhyming couplets and ensure the tone remains light and\nengaging.\nSuggestion 3: Frame the event details as a social media post. Use internet slang and\nemojis. Keep the message within 280 characters.\nModified Instructions\nInstruction 1: Rewrite the event details (date, location, abstract deadline) as if you\u2019re\ntelling a funny story to a friend using casual and colloquial language,\nwhile incorporating a fictional narrative that still conveys the necessary\ninformation.\nInstruction 2: Transform the event details (date, location, abstract deadline) into a light-\nheartedpoemwithrhymingcouplets, ensuringthattheessentialinformation\nis accurately conveyed in a poetic format.\nInstruction 3: Craft a social media post that includes the event details (date, location,\nabstract deadline) using internet slang, emojis, and a casual tone, while\nkeeping the message concise and within 280 characters.\n92.3 AgentInstruct Flow for Tool Use\nThe task of tool use or API use for LLMs involves enabling models to interact with external\ntools or services; via APIs. This capability allows AI systems to extend their functionality,\naccess external data, and perform actions beyond their native capabilities.\nContent Transformation Flow We use source code snippets or an API description [ 26] as\nthe random seed. If source code snippets has been used as the seed, a content transformation\nagent is used to synthesize an API description from the code snippet. The goal of the\nContent Transformation Flow is to synthesize list of APIs from the random seed. API lists\nare created by either: (1) using an API retrieval agent that iteratively searches for similar\ncode to expand the API list or (2) the agent uses the LLM to hypothesize other APIs present\nin the library.\nThe following figure provides an example of the library reconstruction scenario.\nEXAMPLE: Content Transformation Flow [Library Reconstruction]\nSeed\n{\n\"name\": \"View All Food Items\",\n\"description\": \"The request enables clients to obtain a detailed list of food items,\ncomplete with nutritional profiles such as calorie count, protein, fat, ...\",\n\"parameters\": {\n\"type\": \"object\",\n\"properties\": {\n\"limit\": {\n\"type\": \"NUMBER\",\n\"description\": \"limit the length of response\"\n}\n},\n\"required\": []\n}\n}\nReconstructed Remaining APIs from the Library\n[\n{\n\"name\": \"Search Food Items\",\n\"description\": \"Allows clients to search for food items by name and retrieve a list of\nmatching items ...\",\n\"parameters\": {\n\"type\": \"object\",\n\"properties\": {\n\"query\": {\n\"type\": \"string\",\n\"description\": \"The name or partial name of the food item to search for.\"\n},\n\"limit\": {\n\"type\": \"number\",\n\"description\": \"Optional parameter to limit the number of search results\nreturned.\"\n","chunk_id":"427e98b00e49b6a8f8649054122dd45b","document_ids":["c5a70861b9987da7046fe2110eb3616c"],"n_tokens":1200,"entities":[{"name":"PARAPHRASING AGENT","type":"TOOL\/AGENT","description":"The Paraphrasing Agent creates text modification tasks based on a given input text and instruction","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"NATASCHA VAN DER ZWAN","type":"PERSON","description":"Natascha van der Zwan is a researcher who identifies three distinct research streams that have approached financialization","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"FINANCIALIZATION","type":"CONCEPT","description":"Financialization is a broad concept that encompasses the increasing social impact and interconnection of financial discourses, markets, actors, and institutions","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"AMERICAN ANTHROPOLOGICAL ASSOCIATION (AAA)","type":"ORGANIZATION","description":"The American Anthropological Association is an organization that hosts the SEA 2017 Annual Meeting and provides a platform for submitting abstracts","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"SEA 2017 ANNUAL MEETING","type":"EVENT","description":"The SEA 2017 Annual Meeting is an event held from April 6-8, 2017 at the University of Iowa, Iowa City, USA, with an abstract submission deadline of December 1, 2016","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"SUGGESTER-EDITOR PAIR","type":"TOOL\/PROCESS","description":"The Suggester-Editor pair is a duo that increases the complexity of generated instructions by providing suggestions and edits","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"AGENTINSTRUCT FLOW","type":"PROCESS","description":"The AgentInstruct Flow involves enabling models to interact with external tools or services via APIs to extend their functionality","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"CONTENT TRANSFORMATION FLOW","type":"PROCESS","description":"The Content Transformation Flow synthesizes a list of APIs from a random seed, which can be source code snippets or an API description","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"API RETRIEVAL AGENT","type":"TOOL\/AGENT","description":"The API Retrieval Agent iteratively searches for similar code to expand the API list during the Content Transformation Flow","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"LLM","type":"MODEL","description":"A Large Language Model (LLM) is used to hypothesize other APIs present in the library during the Content Transformation Flow","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"VIEW ALL FOOD ITEMS","type":"API","description":"The \"View All Food Items\" API allows clients to obtain a detailed list of food items, complete with nutritional profiles","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"SEARCH FOOD ITEMS","type":"API","description":"The \"Search Food Items\" API allows clients to search for food items by name and retrieve a list of matching items","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"UNIVERSITY OF IOWA","type":"ORGANIZATION","description":"The University of Iowa is the location where the SEA 2017 Annual Meeting was held","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"APRIL 6-8, 2017","type":"DATE","description":"The dates when the SEA 2017 Annual Meeting took place","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"DECEMBER 1, 2016","type":"DATE","description":"The deadline for abstract submissions for the SEA 2017 Annual Meeting","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"FINANCE","type":"CONCEPT","description":"Finance is a field that deals with the study of investments, financial systems, and the management of money","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"RANDOM SEED","type":"CONCEPT","description":"A random seed is used to create a seed instruction for generating text modification tasks","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"INSTRUCTION REFINEMENT FLOW","type":"PROCESS","description":"The Instruction Refinement Flow involves a Suggester-Editor pair that increases the complexity of generated instructions","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"SUGGESTION 1","type":"INSTRUCTION","description":"Incorporate a fictional narrative. Use a conversational style with colloquial language and include a humorous element","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"SUGGESTION 2","type":"INSTRUCTION","description":"Translate the event details into a poetic format. Maintain accurate information while using rhyming couplets and ensure the tone remains light and engaging","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"SUGGESTION 3","type":"INSTRUCTION","description":"Frame the event details as a social media post. Use internet slang and emojis. Keep the message within 280 characters","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"MODIFIED INSTRUCTION 1","type":"INSTRUCTION","description":"Rewrite the event details (date, location, abstract deadline) as if you\u2019re telling a funny story to a friend using casual and colloquial language, while incorporating a fictional narrative that still conveys the necessary information","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"MODIFIED INSTRUCTION 2","type":"INSTRUCTION","description":"Transform the event details (date, location, abstract deadline) into a light-hearted poem with rhyming couplets, ensuring that the essential information is accurately conveyed in a poetic format","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"MODIFIED INSTRUCTION 3","type":"INSTRUCTION","description":"Craft a social media post that includes the event details (date, location, abstract deadline) using internet slang, emojis, and a casual tone, while keeping the message concise and within 280 characters","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"LIBRARY RECONSTRUCTION","type":"PROCESS","description":"Library Reconstruction is a scenario in the Content Transformation Flow where a list of APIs is synthesized from a random seed","source_id":"427e98b00e49b6a8f8649054122dd45b"},{"name":"FOOD ITEMS","type":"CONCEPT","description":"Food items are products that can be consumed and are often listed with nutritional profiles such as calorie count, protein, and fat","source_id":"427e98b00e49b6a8f8649054122dd45b"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"PARAPHRASING AGENT\">      <data key=\"d0\">TOOL\/AGENT<\/data>      <data key=\"d1\">The Paraphrasing Agent creates text modification tasks based on a given input text and instruction<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"NATASCHA VAN DER ZWAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Natascha van der Zwan is a researcher who identifies three distinct research streams that have approached financialization<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"FINANCIALIZATION\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Financialization is a broad concept that encompasses the increasing social impact and interconnection of financial discourses, markets, actors, and institutions<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"AMERICAN ANTHROPOLOGICAL ASSOCIATION (AAA)\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">The American Anthropological Association is an organization that hosts the SEA 2017 Annual Meeting and provides a platform for submitting abstracts<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"SEA 2017 ANNUAL MEETING\">      <data key=\"d0\">EVENT<\/data>      <data key=\"d1\">The SEA 2017 Annual Meeting is an event held from April 6-8, 2017 at the University of Iowa, Iowa City, USA, with an abstract submission deadline of December 1, 2016<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"SUGGESTER-EDITOR PAIR\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">The Suggester-Editor pair is a duo that increases the complexity of generated instructions by providing suggestions and edits<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"AGENTINSTRUCT FLOW\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The AgentInstruct Flow involves enabling models to interact with external tools or services via APIs to extend their functionality<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"CONTENT TRANSFORMATION FLOW\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The Content Transformation Flow synthesizes a list of APIs from a random seed, which can be source code snippets or an API description<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"API RETRIEVAL AGENT\">      <data key=\"d0\">TOOL\/AGENT<\/data>      <data key=\"d1\">The API Retrieval Agent iteratively searches for similar code to expand the API list during the Content Transformation Flow<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"LLM\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">A Large Language Model (LLM) is used to hypothesize other APIs present in the library during the Content Transformation Flow<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"VIEW ALL FOOD ITEMS\">      <data key=\"d0\">API<\/data>      <data key=\"d1\">The \"View All Food Items\" API allows clients to obtain a detailed list of food items, complete with nutritional profiles<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"SEARCH FOOD ITEMS\">      <data key=\"d0\">API<\/data>      <data key=\"d1\">The \"Search Food Items\" API allows clients to search for food items by name and retrieve a list of matching items<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"UNIVERSITY OF IOWA\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">The University of Iowa is the location where the SEA 2017 Annual Meeting was held<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"APRIL 6-8, 2017\">      <data key=\"d0\">DATE<\/data>      <data key=\"d1\">The dates when the SEA 2017 Annual Meeting took place<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"DECEMBER 1, 2016\">      <data key=\"d0\">DATE<\/data>      <data key=\"d1\">The deadline for abstract submissions for the SEA 2017 Annual Meeting<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"FINANCE\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Finance is a field that deals with the study of investments, financial systems, and the management of money<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"RANDOM SEED\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">A random seed is used to create a seed instruction for generating text modification tasks<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"INSTRUCTION REFINEMENT FLOW\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The Instruction Refinement Flow involves a Suggester-Editor pair that increases the complexity of generated instructions<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"SUGGESTION 1\">      <data key=\"d0\">INSTRUCTION<\/data>      <data key=\"d1\">Incorporate a fictional narrative. Use a conversational style with colloquial language and include a humorous element<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"SUGGESTION 2\">      <data key=\"d0\">INSTRUCTION<\/data>      <data key=\"d1\">Translate the event details into a poetic format. Maintain accurate information while using rhyming couplets and ensure the tone remains light and engaging<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"SUGGESTION 3\">      <data key=\"d0\">INSTRUCTION<\/data>      <data key=\"d1\">Frame the event details as a social media post. Use internet slang and emojis. Keep the message within 280 characters<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"MODIFIED INSTRUCTION 1\">      <data key=\"d0\">INSTRUCTION<\/data>      <data key=\"d1\">Rewrite the event details (date, location, abstract deadline) as if you&#8217;re telling a funny story to a friend using casual and colloquial language, while incorporating a fictional narrative that still conveys the necessary information<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"MODIFIED INSTRUCTION 2\">      <data key=\"d0\">INSTRUCTION<\/data>      <data key=\"d1\">Transform the event details (date, location, abstract deadline) into a light-hearted poem with rhyming couplets, ensuring that the essential information is accurately conveyed in a poetic format<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"MODIFIED INSTRUCTION 3\">      <data key=\"d0\">INSTRUCTION<\/data>      <data key=\"d1\">Craft a social media post that includes the event details (date, location, abstract deadline) using internet slang, emojis, and a casual tone, while keeping the message concise and within 280 characters<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"LIBRARY RECONSTRUCTION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Library Reconstruction is a scenario in the Content Transformation Flow where a list of APIs is synthesized from a random seed<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <node id=\"FOOD ITEMS\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Food items are products that can be consumed and are often listed with nutritional profiles such as calorie count, protein, and fat<\/data>      <data key=\"d2\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/node>    <edge source=\"PARAPHRASING AGENT\" target=\"NATASCHA VAN DER ZWAN\">      <data key=\"d3\">5.0<\/data>      <data key=\"d4\">The Paraphrasing Agent could be used to modify text related to Natascha van der Zwan's research on financialization<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>    <edge source=\"PARAPHRASING AGENT\" target=\"SUGGESTER-EDITOR PAIR\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The Suggester-Editor pair provides suggestions and edits to increase the complexity of instructions generated by the Paraphrasing Agent<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>    <edge source=\"PARAPHRASING AGENT\" target=\"RANDOM SEED\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The Paraphrasing Agent uses a random seed to create text modification tasks<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>    <edge source=\"NATASCHA VAN DER ZWAN\" target=\"FINANCIALIZATION\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Natascha van der Zwan identifies three distinct research streams that have approached financialization<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>    <edge source=\"FINANCIALIZATION\" target=\"FINANCE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Financialization is a broad concept that encompasses the increasing social impact and interconnection of financial discourses, markets, actors, and institutions<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>    <edge source=\"AMERICAN ANTHROPOLOGICAL ASSOCIATION (AAA)\" target=\"SEA 2017 ANNUAL MEETING\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The American Anthropological Association hosts the SEA 2017 Annual Meeting<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>    <edge source=\"SEA 2017 ANNUAL MEETING\" target=\"UNIVERSITY OF IOWA\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The SEA 2017 Annual Meeting was held at the University of Iowa<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>    <edge source=\"SEA 2017 ANNUAL MEETING\" target=\"APRIL 6-8, 2017\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The SEA 2017 Annual Meeting took place on April 6-8, 2017<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>    <edge source=\"SEA 2017 ANNUAL MEETING\" target=\"DECEMBER 1, 2016\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The abstract submission deadline for the SEA 2017 Annual Meeting was December 1, 2016<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>    <edge source=\"SUGGESTER-EDITOR PAIR\" target=\"INSTRUCTION REFINEMENT FLOW\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Instruction Refinement Flow involves a Suggester-Editor pair that increases the complexity of generated instructions<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>    <edge source=\"SUGGESTER-EDITOR PAIR\" target=\"SUGGESTION 1\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Suggestion 1 is a suggestion provided by the Suggester-Editor pair<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>    <edge source=\"SUGGESTER-EDITOR PAIR\" target=\"SUGGESTION 2\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Suggestion 2 is a suggestion provided by the Suggester-Editor pair<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>    <edge source=\"SUGGESTER-EDITOR PAIR\" target=\"SUGGESTION 3\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Suggestion 3 is a suggestion provided by the Suggester-Editor pair<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>    <edge source=\"SUGGESTER-EDITOR PAIR\" target=\"MODIFIED INSTRUCTION 1\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Modified Instruction 1 is an edit provided by the Suggester-Editor pair<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>    <edge source=\"SUGGESTER-EDITOR PAIR\" target=\"MODIFIED INSTRUCTION 2\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Modified Instruction 2 is an edit provided by the Suggester-Editor pair<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>    <edge source=\"SUGGESTER-EDITOR PAIR\" target=\"MODIFIED INSTRUCTION 3\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Modified Instruction 3 is an edit provided by the Suggester-Editor pair<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT FLOW\" target=\"CONTENT TRANSFORMATION FLOW\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Both the AgentInstruct Flow and Content Transformation Flow involve the use of agents to perform specific tasks<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>    <edge source=\"CONTENT TRANSFORMATION FLOW\" target=\"API RETRIEVAL AGENT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The API Retrieval Agent is used in the Content Transformation Flow to expand the API list<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>    <edge source=\"CONTENT TRANSFORMATION FLOW\" target=\"LLM\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">An LLM is used in the Content Transformation Flow to hypothesize other APIs present in the library<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>    <edge source=\"CONTENT TRANSFORMATION FLOW\" target=\"LIBRARY RECONSTRUCTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Library Reconstruction is a scenario in the Content Transformation Flow<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>    <edge source=\"VIEW ALL FOOD ITEMS\" target=\"SEARCH FOOD ITEMS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Both \"View All Food Items\" and \"Search Food Items\" are APIs related to food item data<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>    <edge source=\"VIEW ALL FOOD ITEMS\" target=\"FOOD ITEMS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The \"View All Food Items\" API provides a detailed list of food items<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>    <edge source=\"SEARCH FOOD ITEMS\" target=\"FOOD ITEMS\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The \"Search Food Items\" API allows clients to search for food items<\/data>      <data key=\"d5\">427e98b00e49b6a8f8649054122dd45b<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"0922646b93a124514ce2a267d961d229","chunk":" Remaining APIs from the Library\n[\n{\n\"name\": \"Search Food Items\",\n\"description\": \"Allows clients to search for food items by name and retrieve a list of\nmatching items ...\",\n\"parameters\": {\n\"type\": \"object\",\n\"properties\": {\n\"query\": {\n\"type\": \"string\",\n\"description\": \"The name or partial name of the food item to search for.\"\n},\n\"limit\": {\n\"type\": \"number\",\n\"description\": \"Optional parameter to limit the number of search results\nreturned.\"\n}\n},\n\"required\": [\n\"query\"\n]\n}\n},\n10{\n\"name\": \"Get Food Item Details\",\n\"description\": \"...\",\n\"parameters\": {\n...\n}\n},\n{\n\"name\": \"Create Meal Plan\",\n\"description\": \"...\",\n\"parameters\": {\n...\n}\n},\n{\n\"name\": \"Update Food Item\",\n\"description\": \"...\",\n\"parameters\": {\n...\n}\n},\n{\n\"name\": \"Track User Meal\",\n\"description\": \"...\",\n\"parameters\": {\n...\n}\n},\n{\n\"name\": \"Get Dietary Recommendations\",\n\"description\": \"...\",\n\"parameters\": {\n...\n}\n},\n{\n\"name\": \"Add New Food Item\",\n\"description\": \"...\",\n\"parameters\": {\n...\n}\n},\n{\n\"name\": \"Delete Food Item\",\n\"description\": \"...\",\n\"parameters\": {\n...\n}\n},\n{\n\"name\": \"Get User Nutritional Stats\",\n\"description\": \"...\",\n\"parameters\": {\n...\n}\n}\n]\nSeed Instruction Creation Flow The seed instruction creation flow, consume the list of\nAPIs and employs variety of agents to create several tasks of the following types:\n1. Tasks that require the use of a single API:\n11(a) Tasks where the input supplies all necessary parameters.\n(b) Tasks where the input includes superfluous parameters.\n(c) Tasks where the input is missing some required parameters.\n2. Tasks that necessitate the use of multiple APIs:\n(a) Tasks where the input provides all necessary parameters.\n(b) Tasks where the input is missing some required parameters.\n3. Tasks that require a single API which is not listed among the available APIs.\n4.Tasks that require multiple APIs but lack some of the essential APIs in the provided\nlist.\nRefinement Flow The goal of the Refinement flow is to increase the complexity, for e.g.,\nlooking at the task and the conversation and to suggest refinements to increase the number\nof steps required to solve the task.\nThe following figure provides an example of a multi-turn conversation created by the Agent-\nInstruct flow.\nEXAMPLE: Instruction Data Created by AgentInstruct]\nSystem Message\nAs an AI assistant, your role is to assist users in achieving their desired outcomes. You have\nthe capability to utilize a variety of APIs, and at each step of the process, you are required\nto produce a markdown output.\nAt any given moment, you have two choices to proceed:\nChoice 1: Initiate an API Call If you choose to call an API, you must generate a makdown\nincluding the \"name\" of the API and the necessary \"parameters\" for the call. After creating\nthe response, you must wait for the system to execute the API with the provided parameters\nand return the results to you. The markdown you output should follow this structure:\nACTION_TYPE : API_CALL\nACTION: name(parameter_name=value, another_parameter_name=value, ....)\nChoice 2: Conclude the Process There are times when you may decide to end the process,\neither because a) you have successfully obtained the answer\nb) you have determined that the appropriate APIs are not available.\nc) you discovered that user did not provide values for some required parameter\nIn case you successfully obtained the answer use FINAL_ANSWER as the action name\nwith only one parameter being the final answer. In case you decided to stop due to other\nreasons, use FAILED as the action with one parameter describing the reason you decided to\nstop. Overall you should follow this structure:\nACTION_TYPE : STOP\nACTION: [ACTION_NAME]([VALUE])\nBelow is a list of APIs that you have access to:\n[\nAPIs from the Library construction example both the seed and the\ngenerated ones\n]\nUSER:\nI want to start a new diet plan for the next week. My goal is to consume around 1500\ncalories per day, and I prefer vegetarian meals. I\u2019ll be eating three meals a day. Can you\ncreate a meal plan for me? Also, I\u2019d like to track what I eat every day and get some new\nfood recommendations. At the end of the week, I want to see my nutritional summary. Oh,\nand I found this great recipe for a Quinoa Salad that I want to add to your database. I also\nnoticed that the calorie count for \u2018Chana Masala\u2019 seems off; it should be lower. And please\nremove \u2019Butter Chicken\u2019 from my list; I\u2019ve stopped eating it.\n12ASSISTANT:\nTo assist you with your request, I will perform the following actions:\n1. Create a meal plan based on your dietary preferences (vegetarian) and caloric goal (1500\ncalories per day) for three meals a day.\n2. Provide you with a way to track your daily meals.\n3. Offer you new food recommendations.\n4. Generate a nutritional summary at the end of the week. 5. Add the Quinoa Salad recipe\nto the database.\n6. Update the nutritional information for \u2019Chana Masala\u2019.\n7. Remove \u2019Butter Chicken\u2019 from the database.\nLet\u2019s start by creating a vegetarian meal plan for you with a caloric goal of 1500 calories\nper day and three meals a day.\n\u2018 \u2018 \u2018markdown\nACTION_TYPE : API_CALL\nACTION: Create Meal Plan(dietary_preferences=[\"vegetarian \"] ,\ncaloric_goal=1500, num_meals=3)\n\u2018 \u2018 \u2018\nUSER:\n{\n\"status\": \"success\",\n\"meal_plan\": {\n\"day_1\": {\n\"breakfast\": {\n\"","chunk_id":"0922646b93a124514ce2a267d961d229","document_ids":["c5a70861b9987da7046fe2110eb3616c"],"n_tokens":1200,"entities":[{"name":"SEARCH FOOD ITEMS","type":"API","description":"Allows clients to search for food items by name and retrieve a list of matching items. It requires a query parameter and optionally a limit parameter to restrict the number of results.","source_id":"0922646b93a124514ce2a267d961d229"},{"name":"GET FOOD ITEM DETAILS","type":"API","description":"Provides detailed information about a specific food item. The parameters required for this API are not specified in the text.","source_id":"0922646b93a124514ce2a267d961d229"},{"name":"CREATE MEAL PLAN","type":"API","description":"Enables the creation of a meal plan based on specified dietary preferences, caloric goals, and the number of meals per day. The parameters required for this API are not specified in the text.","source_id":"0922646b93a124514ce2a267d961d229"},{"name":"UPDATE FOOD ITEM","type":"API","description":"Allows updating the details of an existing food item. The parameters required for this API are not specified in the text.","source_id":"0922646b93a124514ce2a267d961d229"},{"name":"TRACK USER MEAL","type":"API","description":"Enables tracking of user meals. The parameters required for this API are not specified in the text.","source_id":"0922646b93a124514ce2a267d961d229"},{"name":"GET DIETARY RECOMMENDATIONS","type":"API","description":"Provides dietary recommendations based on user preferences and nutritional needs. The parameters required for this API are not specified in the text.","source_id":"0922646b93a124514ce2a267d961d229"},{"name":"ADD NEW FOOD ITEM","type":"API","description":"Allows adding a new food item to the database. The parameters required for this API are not specified in the text.","source_id":"0922646b93a124514ce2a267d961d229"},{"name":"DELETE FOOD ITEM","type":"API","description":"Enables the deletion of a food item from the database. The parameters required for this API are not specified in the text.","source_id":"0922646b93a124514ce2a267d961d229"},{"name":"GET USER NUTRITIONAL STATS","type":"API","description":"Provides nutritional statistics for a user. The parameters required for this API are not specified in the text.","source_id":"0922646b93a124514ce2a267d961d229"},{"name":"SEED INSTRUCTION CREATION FLOW","type":"PROCESS","description":"A process that consumes a list of APIs and employs various agents to create tasks of different types, including those requiring single or multiple APIs with varying parameter completeness.","source_id":"0922646b93a124514ce2a267d961d229"},{"name":"REFINEMENT FLOW","type":"PROCESS","description":"A process aimed at increasing the complexity of tasks by suggesting refinements to increase the number of steps required to solve the task.","source_id":"0922646b93a124514ce2a267d961d229"},{"name":"AGENT-INSTRUCT FLOW","type":"PROCESS","description":"A process that creates multi-turn conversations and instructions for an AI assistant to follow, including making API calls and concluding processes based on the availability of required parameters and APIs.","source_id":"0922646b93a124514ce2a267d961d229"},{"name":"USER","type":"PERSON","description":"The individual requesting the creation of a meal plan, tracking of daily meals, new food recommendations, a nutritional summary, and updates to the food database.","source_id":"0922646b93a124514ce2a267d961d229"},{"name":"ASSISTANT","type":"AI","description":"The AI assistant responsible for creating a meal plan, tracking meals, providing food recommendations, generating a nutritional summary, and updating the food database based on the user's requests.","source_id":"0922646b93a124514ce2a267d961d229"},{"name":"QUINOA SALAD","type":"FOOD ITEM","description":"A recipe that the user wants to add to the database.","source_id":"0922646b93a124514ce2a267d961d229"},{"name":"CHANA MASALA","type":"FOOD ITEM","description":"A food item whose calorie count the user believes is incorrect and wants to update.","source_id":"0922646b93a124514ce2a267d961d229"},{"name":"BUTTER CHICKEN","type":"FOOD ITEM","description":"A food item that the user wants to remove from the database.","source_id":"0922646b93a124514ce2a267d961d229"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"SEARCH FOOD ITEMS\">      <data key=\"d0\">API<\/data>      <data key=\"d1\">Allows clients to search for food items by name and retrieve a list of matching items. It requires a query parameter and optionally a limit parameter to restrict the number of results.<\/data>      <data key=\"d2\">0922646b93a124514ce2a267d961d229<\/data>    <\/node>    <node id=\"GET FOOD ITEM DETAILS\">      <data key=\"d0\">API<\/data>      <data key=\"d1\">Provides detailed information about a specific food item. The parameters required for this API are not specified in the text.<\/data>      <data key=\"d2\">0922646b93a124514ce2a267d961d229<\/data>    <\/node>    <node id=\"CREATE MEAL PLAN\">      <data key=\"d0\">API<\/data>      <data key=\"d1\">Enables the creation of a meal plan based on specified dietary preferences, caloric goals, and the number of meals per day. The parameters required for this API are not specified in the text.<\/data>      <data key=\"d2\">0922646b93a124514ce2a267d961d229<\/data>    <\/node>    <node id=\"UPDATE FOOD ITEM\">      <data key=\"d0\">API<\/data>      <data key=\"d1\">Allows updating the details of an existing food item. The parameters required for this API are not specified in the text.<\/data>      <data key=\"d2\">0922646b93a124514ce2a267d961d229<\/data>    <\/node>    <node id=\"TRACK USER MEAL\">      <data key=\"d0\">API<\/data>      <data key=\"d1\">Enables tracking of user meals. The parameters required for this API are not specified in the text.<\/data>      <data key=\"d2\">0922646b93a124514ce2a267d961d229<\/data>    <\/node>    <node id=\"GET DIETARY RECOMMENDATIONS\">      <data key=\"d0\">API<\/data>      <data key=\"d1\">Provides dietary recommendations based on user preferences and nutritional needs. The parameters required for this API are not specified in the text.<\/data>      <data key=\"d2\">0922646b93a124514ce2a267d961d229<\/data>    <\/node>    <node id=\"ADD NEW FOOD ITEM\">      <data key=\"d0\">API<\/data>      <data key=\"d1\">Allows adding a new food item to the database. The parameters required for this API are not specified in the text.<\/data>      <data key=\"d2\">0922646b93a124514ce2a267d961d229<\/data>    <\/node>    <node id=\"DELETE FOOD ITEM\">      <data key=\"d0\">API<\/data>      <data key=\"d1\">Enables the deletion of a food item from the database. The parameters required for this API are not specified in the text.<\/data>      <data key=\"d2\">0922646b93a124514ce2a267d961d229<\/data>    <\/node>    <node id=\"GET USER NUTRITIONAL STATS\">      <data key=\"d0\">API<\/data>      <data key=\"d1\">Provides nutritional statistics for a user. The parameters required for this API are not specified in the text.<\/data>      <data key=\"d2\">0922646b93a124514ce2a267d961d229<\/data>    <\/node>    <node id=\"SEED INSTRUCTION CREATION FLOW\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">A process that consumes a list of APIs and employs various agents to create tasks of different types, including those requiring single or multiple APIs with varying parameter completeness.<\/data>      <data key=\"d2\">0922646b93a124514ce2a267d961d229<\/data>    <\/node>    <node id=\"REFINEMENT FLOW\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">A process aimed at increasing the complexity of tasks by suggesting refinements to increase the number of steps required to solve the task.<\/data>      <data key=\"d2\">0922646b93a124514ce2a267d961d229<\/data>    <\/node>    <node id=\"AGENT-INSTRUCT FLOW\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">A process that creates multi-turn conversations and instructions for an AI assistant to follow, including making API calls and concluding processes based on the availability of required parameters and APIs.<\/data>      <data key=\"d2\">0922646b93a124514ce2a267d961d229<\/data>    <\/node>    <node id=\"USER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">The individual requesting the creation of a meal plan, tracking of daily meals, new food recommendations, a nutritional summary, and updates to the food database.<\/data>      <data key=\"d2\">0922646b93a124514ce2a267d961d229<\/data>    <\/node>    <node id=\"ASSISTANT\">      <data key=\"d0\">AI<\/data>      <data key=\"d1\">The AI assistant responsible for creating a meal plan, tracking meals, providing food recommendations, generating a nutritional summary, and updating the food database based on the user's requests.<\/data>      <data key=\"d2\">0922646b93a124514ce2a267d961d229<\/data>    <\/node>    <node id=\"QUINOA SALAD\">      <data key=\"d0\">FOOD ITEM<\/data>      <data key=\"d1\">A recipe that the user wants to add to the database.<\/data>      <data key=\"d2\">0922646b93a124514ce2a267d961d229<\/data>    <\/node>    <node id=\"CHANA MASALA\">      <data key=\"d0\">FOOD ITEM<\/data>      <data key=\"d1\">A food item whose calorie count the user believes is incorrect and wants to update.<\/data>      <data key=\"d2\">0922646b93a124514ce2a267d961d229<\/data>    <\/node>    <node id=\"BUTTER CHICKEN\">      <data key=\"d0\">FOOD ITEM<\/data>      <data key=\"d1\">A food item that the user wants to remove from the database.<\/data>      <data key=\"d2\">0922646b93a124514ce2a267d961d229<\/data>    <\/node>    <edge source=\"SEARCH FOOD ITEMS\" target=\"GET FOOD ITEM DETAILS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Both APIs are related to managing and retrieving information about food items.<\/data>      <data key=\"d5\">0922646b93a124514ce2a267d961d229<\/data>    <\/edge>    <edge source=\"CREATE MEAL PLAN\" target=\"TRACK USER MEAL\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Both APIs are used in the process of managing a user's diet and meal tracking.<\/data>      <data key=\"d5\">0922646b93a124514ce2a267d961d229<\/data>    <\/edge>    <edge source=\"CREATE MEAL PLAN\" target=\"ASSISTANT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The assistant uses the Create Meal Plan API to generate a meal plan for the user.<\/data>      <data key=\"d5\">0922646b93a124514ce2a267d961d229<\/data>    <\/edge>    <edge source=\"UPDATE FOOD ITEM\" target=\"ADD NEW FOOD ITEM\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Both APIs are used for managing the food database, either by adding new items or updating existing ones.<\/data>      <data key=\"d5\">0922646b93a124514ce2a267d961d229<\/data>    <\/edge>    <edge source=\"UPDATE FOOD ITEM\" target=\"DELETE FOOD ITEM\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Both APIs are used for managing the food database, either by deleting or updating existing items.<\/data>      <data key=\"d5\">0922646b93a124514ce2a267d961d229<\/data>    <\/edge>    <edge source=\"UPDATE FOOD ITEM\" target=\"ASSISTANT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The assistant uses the Update Food Item API to update the nutritional information of an existing food item.<\/data>      <data key=\"d5\">0922646b93a124514ce2a267d961d229<\/data>    <\/edge>    <edge source=\"UPDATE FOOD ITEM\" target=\"CHANA MASALA\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The user wants to update the nutritional information for Chana Masala using the Update Food Item API.<\/data>      <data key=\"d5\">0922646b93a124514ce2a267d961d229<\/data>    <\/edge>    <edge source=\"TRACK USER MEAL\" target=\"GET USER NUTRITIONAL STATS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Both APIs are used for tracking and analyzing a user's nutritional intake.<\/data>      <data key=\"d5\">0922646b93a124514ce2a267d961d229<\/data>    <\/edge>    <edge source=\"TRACK USER MEAL\" target=\"ASSISTANT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The assistant uses the Track User Meal API to help the user track their daily meals.<\/data>      <data key=\"d5\">0922646b93a124514ce2a267d961d229<\/data>    <\/edge>    <edge source=\"GET DIETARY RECOMMENDATIONS\" target=\"ASSISTANT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The assistant uses the Get Dietary Recommendations API to provide new food recommendations to the user.<\/data>      <data key=\"d5\">0922646b93a124514ce2a267d961d229<\/data>    <\/edge>    <edge source=\"ADD NEW FOOD ITEM\" target=\"ASSISTANT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The assistant uses the Add New Food Item API to add a new recipe to the database.<\/data>      <data key=\"d5\">0922646b93a124514ce2a267d961d229<\/data>    <\/edge>    <edge source=\"ADD NEW FOOD ITEM\" target=\"QUINOA SALAD\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The user wants to add the Quinoa Salad recipe to the database using the Add New Food Item API.<\/data>      <data key=\"d5\">0922646b93a124514ce2a267d961d229<\/data>    <\/edge>    <edge source=\"DELETE FOOD ITEM\" target=\"ASSISTANT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The assistant uses the Delete Food Item API to remove a food item from the database.<\/data>      <data key=\"d5\">0922646b93a124514ce2a267d961d229<\/data>    <\/edge>    <edge source=\"DELETE FOOD ITEM\" target=\"BUTTER CHICKEN\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The user wants to remove Butter Chicken from the database using the Delete Food Item API.<\/data>      <data key=\"d5\">0922646b93a124514ce2a267d961d229<\/data>    <\/edge>    <edge source=\"GET USER NUTRITIONAL STATS\" target=\"ASSISTANT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The assistant uses the Get User Nutritional Stats API to generate a nutritional summary for the user.<\/data>      <data key=\"d5\">0922646b93a124514ce2a267d961d229<\/data>    <\/edge>    <edge source=\"SEED INSTRUCTION CREATION FLOW\" target=\"REFINEMENT FLOW\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Both processes are involved in creating and refining tasks for the AI assistant to perform.<\/data>      <data key=\"d5\">0922646b93a124514ce2a267d961d229<\/data>    <\/edge>    <edge source=\"SEED INSTRUCTION CREATION FLOW\" target=\"AGENT-INSTRUCT FLOW\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Agent-Instruct flow uses the tasks created by the Seed Instruction Creation Flow to generate multi-turn conversations.<\/data>      <data key=\"d5\">0922646b93a124514ce2a267d961d229<\/data>    <\/edge>    <edge source=\"USER\" target=\"ASSISTANT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The user interacts with the assistant to achieve their dietary and nutritional goals.<\/data>      <data key=\"d5\">0922646b93a124514ce2a267d961d229<\/data>    <\/edge>    <edge source=\"USER\" target=\"QUINOA SALAD\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The user wants to add the Quinoa Salad recipe to the database.<\/data>      <data key=\"d5\">0922646b93a124514ce2a267d961d229<\/data>    <\/edge>    <edge source=\"USER\" target=\"CHANA MASALA\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The user wants to update the calorie count for Chana Masala.<\/data>      <data key=\"d5\">0922646b93a124514ce2a267d961d229<\/data>    <\/edge>    <edge source=\"USER\" target=\"BUTTER CHICKEN\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The user wants to remove Butter Chicken from the database.<\/data>      <data key=\"d5\">0922646b93a124514ce2a267d961d229<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"09cb89de3b77d765983cff25b7d74a1a","chunk":" database.\nLet\u2019s start by creating a vegetarian meal plan for you with a caloric goal of 1500 calories\nper day and three meals a day.\n\u2018 \u2018 \u2018markdown\nACTION_TYPE : API_CALL\nACTION: Create Meal Plan(dietary_preferences=[\"vegetarian \"] ,\ncaloric_goal=1500, num_meals=3)\n\u2018 \u2018 \u2018\nUSER:\n{\n\"status\": \"success\",\n\"meal_plan\": {\n\"day_1\": {\n\"breakfast\": {\n\"food_items\": [\"Oatmeal with Fruits\", \"Almond Milk\"],\n\"total_calories\": 350\n},\n\"lunch\": {\n\"food_items\": [\"Chickpea Salad\", \"Whole Wheat Bread\"],\n\"total_calories\": 500\n},\n\"dinner\": {\n\"food_items\": [\"Mixed Vegetable Stir Fry\", \"Brown Rice\"],\n\"total_calories\": 650\n}\n},\n\"day_2\": {\n...\n},\n...\n}\n}\nASSISTANT:\nYour meal plan for the next week has been successfully created. Here\u2019s a brief overview:\n- **Day 1**: Oatmeal with fruits and almond milk for breakfast, chickpea salad with whole\nwheat bread for lunch, and mixed vegetable stir fry with brown rice for dinner.\n- **Day 2**: .... ....\nNext, let\u2019s proceed to add the Quinoa Salad recipe to the database. Please provide the\nnutritional information for the Quinoa Salad so I can proceed with the addition.\nAs for updating the \u2019Chana Masala\u2019 and removing \u2019Butter Chicken\u2019, I will need\ntheir unique identifiers (food_id) to make those changes. If you have those identi-\nfiers, please provide them. If not, I can search for these items in the database to find\nthe correct identifiers. Would you like me to search for \u2019Chana Masala\u2019 and \u2019Butter Chicken\u2019?\nUSER:\n...(truncated)\n133 Orca-3\n3.1 Dataset Description\nWe implemented an AgentInstruct Flow for 17 different capabilities as described in Table 1.\nWe created a collection of approximately 22 million instructions aimed at teaching the\naforementioned skills. We have used unstructured text and code files sampled from\nKnowledgePile[ 7], AutoMathText[ 38], a subset of openstax and a subset of apache-2.0\nlicensed source code files from [ 4]. The dataset covers variety of skills, as detailed in Table 1.\nUsing unstructured content as seeds for instruction data generation has several benefits.\nFirst, there is abundance of such data enabling the generation of large-scale and diverse\ninstruction data. Additionally, it enables us to avoid using any benchmark-specific data as\nseeds and hence focus on optimizing for a capability, not for a specific benchmark.\nIn addition to the 22 million instructions, we have incorporated approximately 3.8 million\npaired instructions sourced from Orca-1[ 21], Orca-2[ 18], Orca-Math[ 19] and samples from\nother publicly available sources such as [ 5,37,10,30]. We refer to this data as Orca-2.5-\ndataset.\nThe culmination of these datasets results in approximately 25.8 million paired instructions,\nall of which are incorporated into the training of Orca-3. Furthermore, we have trained a\nseparate model, referred to as Orca-2.5, using the 3.8 million instructions (Orca-2.5-dataset).\nThe purpose of this is to compare and evaluate the impact of the 22 million instructions\ncurated through AgentInstruct.\n3.2 Training Details\nWe use the 25.8 million paired instructions described earlier to finetune Mistral-7b-v0.1.\nWe choose this model because the it makes the weights publicly available for the base\n(no-instruction-tuned) version, with a permissive license allowing easy redistribution. We\nrefer to the finetuned model ( Mistral-7b-v0.1 finetuned on AgentInstruct dataset) as Orca-3.\nEach pair in the dataset undergoes a tokenization process using the Mistral tokenizer,\nensuring a maximum sequence length of 8192 with packing. To guarantee that the training\nloss is calculated based only on the response conditioned on the prompt, label masking is\napplied. Weight decay was set at 0.1\nThe finetuneing used 19 NVIDIA A100 nodes, or 152 NVIDIA A100 GPUs, each with a\nbatch size of 10. We used AdamW optimizer with an initial learning rate of 8e-6 and a a\ncosine learning rate schedule. We also used a linear learning rate warm-up during the initial\n500 steps. The model was trained for three epochs and the training process concluded after\napproximately 200 hours.\n4 Evaluation Results\n4.1 Orca-Bench\nThe Orca-Bench dataset serves as a held-out test set, consisting of 100 samples from each of\nthe 17 skills for which data was curated using AgentInstruct, except for the Open Domain\nQuestion Answering (ODQA) category, where we created two test sets. The first subset,\nreferred to as ODQA, consists of 100 questions originated from the initial seed instruction\nphase. The second subset, termed Complex ODQA, includes more intricate questions\ndeveloped during the refinement phase.\nWe evaluated the performance of all baselines using the Orca-Bench dataset. These were\nscored relative to GPT-4 on a scale ranging from 0 to 10. It is worth noting that some of\nthe entries within Orca-Bench involve multiple exchanges. To illustrate, let a multi-turn\ninteraction in Orca-Bench be denoted by","chunk_id":"09cb89de3b77d765983cff25b7d74a1a","document_ids":["c5a70861b9987da7046fe2110eb3616c"],"n_tokens":1200,"entities":[{"name":"API_CALL","type":"ACTION","description":"An action to create a meal plan with specific dietary preferences, caloric goal, and number of meals","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"USER","type":"PERSON","description":"The individual requesting the creation of a vegetarian meal plan and providing feedback on the meal plan","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"ASSISTANT","type":"PERSON","description":"The entity responsible for creating the meal plan and providing an overview of it","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"QUINOA SALAD","type":"FOOD ITEM","description":"A food item that the assistant is asked to add to the database, requiring nutritional information","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"CHANA MASALA","type":"FOOD ITEM","description":"A food item that the assistant is asked to update in the database, requiring its unique identifier","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"BUTTER CHICKEN","type":"FOOD ITEM","description":"A food item that the assistant is asked to remove from the database, requiring its unique identifier","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"ORCA-3","type":"MODEL","description":"A model trained using a dataset of approximately 25.8 million paired instructions, finetuned on Mistral-7b-v0.1","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"AGENTINSTRUCT","type":"DATASET","description":"A dataset used to create approximately 22 million instructions aimed at teaching various skills","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"KNOWLEDGEPILE","type":"DATA SOURCE","description":"A source of unstructured text and code files used in the creation of the AgentInstruct dataset","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"AUTOMATHTEXT","type":"DATA SOURCE","description":"A source of unstructured text and code files used in the creation of the AgentInstruct dataset","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"OPENSTAX","type":"DATA SOURCE","description":"A source of unstructured text and code files used in the creation of the AgentInstruct dataset","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"APACHE-2.0 LICENSED SOURCE CODE","type":"DATA SOURCE","description":"A source of unstructured text and code files used in the creation of the AgentInstruct dataset","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"ORCA-2.5-DATASET","type":"DATASET","description":"A dataset consisting of approximately 3.8 million paired instructions sourced from various Orca versions and other publicly available sources","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"MISTRAL-7B-V0.1","type":"MODEL","description":"The base model used for finetuning with the AgentInstruct dataset to create Orca-3","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"NVIDIA A100","type":"HARDWARE","description":"The hardware used for training the Orca-3 model, consisting of 152 GPUs","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"ADAMW OPTIMIZER","type":"OPTIMIZER","description":"The optimizer used for training the Orca-3 model with an initial learning rate of 8e-6","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"ORCA-BENCH","type":"DATASET","description":"A held-out test set consisting of 100 samples from each of the 17 skills curated using AgentInstruct, used for evaluating the performance of models","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"GPT-4","type":"MODEL","description":"The model used as a baseline for scoring the performance of other models on the Orca-Bench dataset","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"VEGETARIAN MEAL PLAN","type":"","description":"","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"ORCA-1","type":"","description":"\nA previous version of the Orca model, which contributed to the Orca-2.5-dataset","source_id":"09cb89de3b77d765983cff25b7d74a1a","entity_type":"MODEL"},{"name":"ORCA-2","type":"","description":"\nA previous version of the Orca model, which contributed to the Orca-2.5-dataset","source_id":"09cb89de3b77d765983cff25b7d74a1a","entity_type":"MODEL"},{"name":"ORCA-MATH","type":"","description":"\nA version of the Orca model focused on mathematical instructions, which contributed to the Orca-2.5-dataset","source_id":"09cb89de3b77d765983cff25b7d74a1a","entity_type":"MODEL"},{"name":"DAY 2","type":"DAY","description":"The second day of the vegetarian meal plan, including breakfast, lunch, and dinner with specific food items and total calories","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"OATMEAL WITH FRUITS","type":"FOOD ITEM","description":"A breakfast food item included in the vegetarian meal plan for Day 1","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"ALMOND MILK","type":"FOOD ITEM","description":"A breakfast food item included in the vegetarian meal plan for Day 1","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"CHICKPEA SALAD","type":"FOOD ITEM","description":"A lunch food item included in the vegetarian meal plan for Day 1","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"WHOLE WHEAT BREAD","type":"FOOD ITEM","description":"A lunch food item included in the vegetarian meal plan for Day 1","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"MIXED VEGETABLE STIR FRY","type":"FOOD ITEM","description":"A dinner food item included in the vegetarian meal plan for Day 1","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"BROWN RICE","type":"FOOD ITEM","description":"A dinner food item included in the vegetarian meal plan for Day 1","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"OPEN DOMAIN QUESTION ANSWERING (ODQA)","type":"SKILL","description":"A skill category in the Orca-Bench dataset, consisting of 100 questions from the initial seed instruction phase","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"COMPLEX ODQA","type":"SKILL","description":"A skill category in the Orca-Bench dataset, consisting of more intricate questions developed during the refinement phase","source_id":"09cb89de3b77d765983cff25b7d74a1a"},{"name":"DAY 1","type":"","description":"","source_id":"09cb89de3b77d765983cff25b7d74a1a"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"API_CALL\">      <data key=\"d0\">ACTION<\/data>      <data key=\"d1\">An action to create a meal plan with specific dietary preferences, caloric goal, and number of meals<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"USER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">The individual requesting the creation of a vegetarian meal plan and providing feedback on the meal plan<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"ASSISTANT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">The entity responsible for creating the meal plan and providing an overview of it<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"QUINOA SALAD\">      <data key=\"d0\">FOOD ITEM<\/data>      <data key=\"d1\">A food item that the assistant is asked to add to the database, requiring nutritional information<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"CHANA MASALA\">      <data key=\"d0\">FOOD ITEM<\/data>      <data key=\"d1\">A food item that the assistant is asked to update in the database, requiring its unique identifier<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"BUTTER CHICKEN\">      <data key=\"d0\">FOOD ITEM<\/data>      <data key=\"d1\">A food item that the assistant is asked to remove from the database, requiring its unique identifier<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"ORCA-3\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">A model trained using a dataset of approximately 25.8 million paired instructions, finetuned on Mistral-7b-v0.1<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"AGENTINSTRUCT\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset used to create approximately 22 million instructions aimed at teaching various skills<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"KNOWLEDGEPILE\">      <data key=\"d0\">DATA SOURCE<\/data>      <data key=\"d1\">A source of unstructured text and code files used in the creation of the AgentInstruct dataset<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"AUTOMATHTEXT\">      <data key=\"d0\">DATA SOURCE<\/data>      <data key=\"d1\">A source of unstructured text and code files used in the creation of the AgentInstruct dataset<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"OPENSTAX\">      <data key=\"d0\">DATA SOURCE<\/data>      <data key=\"d1\">A source of unstructured text and code files used in the creation of the AgentInstruct dataset<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"APACHE-2.0 LICENSED SOURCE CODE\">      <data key=\"d0\">DATA SOURCE<\/data>      <data key=\"d1\">A source of unstructured text and code files used in the creation of the AgentInstruct dataset<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"ORCA-2.5-DATASET\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset consisting of approximately 3.8 million paired instructions sourced from various Orca versions and other publicly available sources<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"MISTRAL-7B-V0.1\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">The base model used for finetuning with the AgentInstruct dataset to create Orca-3<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"NVIDIA A100\">      <data key=\"d0\">HARDWARE<\/data>      <data key=\"d1\">The hardware used for training the Orca-3 model, consisting of 152 GPUs<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"ADAMW OPTIMIZER\">      <data key=\"d0\">OPTIMIZER<\/data>      <data key=\"d1\">The optimizer used for training the Orca-3 model with an initial learning rate of 8e-6<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"ORCA-BENCH\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A held-out test set consisting of 100 samples from each of the 17 skills curated using AgentInstruct, used for evaluating the performance of models<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">The model used as a baseline for scoring the performance of other models on the Orca-Bench dataset<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"VEGETARIAN MEAL PLAN\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"ORCA-1\">      <data key=\"d0\" \/>      <data key=\"d1\">A previous version of the Orca model, which contributed to the Orca-2.5-dataset<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"ORCA-2\">      <data key=\"d0\" \/>      <data key=\"d1\">A previous version of the Orca model, which contributed to the Orca-2.5-dataset<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"ORCA-MATH\">      <data key=\"d0\" \/>      <data key=\"d1\">A version of the Orca model focused on mathematical instructions, which contributed to the Orca-2.5-dataset<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"DAY 2\">      <data key=\"d0\">DAY<\/data>      <data key=\"d1\">The second day of the vegetarian meal plan, including breakfast, lunch, and dinner with specific food items and total calories<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"OATMEAL WITH FRUITS\">      <data key=\"d0\">FOOD ITEM<\/data>      <data key=\"d1\">A breakfast food item included in the vegetarian meal plan for Day 1<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"ALMOND MILK\">      <data key=\"d0\">FOOD ITEM<\/data>      <data key=\"d1\">A breakfast food item included in the vegetarian meal plan for Day 1<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"CHICKPEA SALAD\">      <data key=\"d0\">FOOD ITEM<\/data>      <data key=\"d1\">A lunch food item included in the vegetarian meal plan for Day 1<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"WHOLE WHEAT BREAD\">      <data key=\"d0\">FOOD ITEM<\/data>      <data key=\"d1\">A lunch food item included in the vegetarian meal plan for Day 1<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"MIXED VEGETABLE STIR FRY\">      <data key=\"d0\">FOOD ITEM<\/data>      <data key=\"d1\">A dinner food item included in the vegetarian meal plan for Day 1<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"BROWN RICE\">      <data key=\"d0\">FOOD ITEM<\/data>      <data key=\"d1\">A dinner food item included in the vegetarian meal plan for Day 1<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"OPEN DOMAIN QUESTION ANSWERING (ODQA)\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">A skill category in the Orca-Bench dataset, consisting of 100 questions from the initial seed instruction phase<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"COMPLEX ODQA\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">A skill category in the Orca-Bench dataset, consisting of more intricate questions developed during the refinement phase<\/data>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <node id=\"DAY 1\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/node>    <edge source=\"USER\" target=\"QUINOA SALAD\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">The user requests the assistant to add the Quinoa Salad recipe to the database<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"USER\" target=\"CHANA MASALA\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">The user requests the assistant to update the Chana Masala recipe in the database<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"USER\" target=\"BUTTER CHICKEN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">The user requests the assistant to remove the Butter Chicken recipe from the database<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"ASSISTANT\" target=\"VEGETARIAN MEAL PLAN\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">The assistant creates and provides an overview of the vegetarian meal plan<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"AGENTINSTRUCT\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Orca-3 is trained using the AgentInstruct dataset<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"ORCA-2.5-DATASET\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Orca-3 is trained using the Orca-2.5-dataset<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"MISTRAL-7B-V0.1\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Orca-3 is finetuned on Mistral-7b-v0.1<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"NVIDIA A100\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Orca-3 is trained using 152 NVIDIA A100 GPUs<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"ADAMW OPTIMIZER\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Orca-3 is trained using the AdamW optimizer<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"KNOWLEDGEPILE\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">KnowledgePile is one of the data sources used to create the AgentInstruct dataset<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"AUTOMATHTEXT\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AutoMathText is one of the data sources used to create the AgentInstruct dataset<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"OPENSTAX\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Openstax is one of the data sources used to create the AgentInstruct dataset<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"APACHE-2.0 LICENSED SOURCE CODE\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Apache-2.0 licensed source code is one of the data sources used to create the AgentInstruct dataset<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"ORCA-BENCH\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Orca-Bench dataset is created using data curated from AgentInstruct<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"ORCA-2.5-DATASET\" target=\"ORCA-1\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Orca-2.5-dataset includes instructions sourced from Orca-1<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"ORCA-2.5-DATASET\" target=\"ORCA-2\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Orca-2.5-dataset includes instructions sourced from Orca-2<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"ORCA-2.5-DATASET\" target=\"ORCA-MATH\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Orca-2.5-dataset includes instructions sourced from Orca-Math<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"ORCA-BENCH\" target=\"GPT-4\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">GPT-4 is used as a baseline for scoring the performance of models on the Orca-Bench dataset<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"ORCA-BENCH\" target=\"OPEN DOMAIN QUESTION ANSWERING (ODQA)\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Orca-Bench includes a test set for Open Domain Question Answering (ODQA)<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"ORCA-BENCH\" target=\"COMPLEX ODQA\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Orca-Bench includes a test set for Complex ODQA<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"ALMOND MILK\" target=\"DAY 1\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Almond milk is included in the breakfast for Day 1<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"CHICKPEA SALAD\" target=\"DAY 1\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Chickpea salad is included in the lunch for Day 1<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"WHOLE WHEAT BREAD\" target=\"DAY 1\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Whole wheat bread is included in the lunch for Day 1<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"MIXED VEGETABLE STIR FRY\" target=\"DAY 1\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Mixed vegetable stir fry is included in the dinner for Day 1<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>    <edge source=\"BROWN RICE\" target=\"DAY 1\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Brown rice is included in the dinner for Day 1<\/data>      <data key=\"d6\">09cb89de3b77d765983cff25b7d74a1a<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"bd4eb9459bc29b4c2da4658914fd4635","chunk":" instruction\nphase. The second subset, termed Complex ODQA, includes more intricate questions\ndeveloped during the refinement phase.\nWe evaluated the performance of all baselines using the Orca-Bench dataset. These were\nscored relative to GPT-4 on a scale ranging from 0 to 10. It is worth noting that some of\nthe entries within Orca-Bench involve multiple exchanges. To illustrate, let a multi-turn\ninteraction in Orca-Bench be denoted by the sequence (system message, user 1, assistant,\nuser 2, assistant, ...), where each turn is crafted by GPT4 (teacher). For every user iinput, we\ngenerateacorresponding studentresponse, which isconditionedontheprecedingconversation\nhistory as established by the teacher. We then evaluate the student\u2019s generated response\n14Figure 4: Performance Comparison between Baselines and Orca3 Checkpoints. Scores are\nrelative to GPT-4 with the outer circle denoting GPT-4\u2019s score of 10.\nagainst the original teacher\u2019s response, rating each on a scale from 0 to 10. To calculate a\nstudent\u2019s overall score, we sum the student\u2019s individual scores and divide this total by the\nsum of the teacher\u2019s scores. This ratio is then multiplied by 10 to normalize the student\u2019s\nfinal score to a 0 to 10 scale.\nAgentInstruct\u2019s objective is to synthesize a large and diverse corpus of data with varying\ndegrees of difficulty. An efficacious execution of this strategy should yield a dataset against\nwhich baseline models like Orca-2.5, Mistral-Instruct-7b, and ChatGPT score substantially\nbelow 10, demonstrating their relative inferiority to GPT-4\u2014a model that is designated as\nthe benchmark with a score of 10. The performance comparison, as depicted in Figure 4,\nillustrates the comparative analysis between baseline models and Orca-3 . This figure shows\nthe notable enhancement in a broad spectrum of capabilities during post-training, enabled\nby the AgentInstruct data.\nTable 2 encapsulates the average (macro) scores across all assessed dimensions. On average,\nincluding orca-3 after each training epoch, the inclusion of AgentInstruct data has led to\na performance augmentation of 33.94% over the Orca 2.5 baseline and an enhancement of\n14.92% over Mistral-Instruct-7B.\n4.2 Benchmark Results\nWe evaluate Orca-3 against 5 baseline models including Orca-2.5, Mistral-7B-Instruct-v0.3,\nLLAMA3-8B-Instruct, GPT-3.5-turbo and GPT-4 on the following benchmarks:\n15Model Orca-Bench Score\nOrca-2.5 7.13\nMistral-Instruct-7B 8.31\nChatGPT 8.13\nOrca-3 (checkpoint epoch 1) 9.35\nOrca-3 (checkpoint epoch 2) 9.49\nOrca-3 9.55\nTable 2: Average Performance of Different Models on Orca-Bench. Scores are computed on\na scale of 0 to 10; 10 being the score of GPT4.\nModelOrca-3\n-7BOrca-2.5\n-7BMistral-\n7B-\nInstructLLAMA3-\n8B\ninstructGPT-3.5-\nturboGPT-4\nAGIEval 56.80 (+40%) 42.71 40.52 47.17 50.91 61.99\nMMLU 69.95 (+19%) 60.34 58.61 63.44 68.26 67.07\nARC 92.47 (+12%) 86.39 82.72 85.74 92.0 93.35\nBBH 61.83 (+38%) 48.63 44.71 54.97 54.17 76.06\nGPQA 28.12 (-4%) 27.68 29.46 28.12 27.9 33.93\nDROP 71.14 (+22%) 65.19 58.12 68.44 67.15 67.36\nGSM8K 83.09 (+54%) 74.3 54.06 77.48 78.1\u221786.88\nFOFO 84.01 (+12%) 66.19 75.3 79.35 76.92 87.45\nIFEval 49.54 (+2%) 45.29 48.61 - 58.6 79.3\nMT-Bench 8.20 (+9%) 7.15 7.53 7.99 8.01 9.04\nAlpacaEval 24.80 (+45%) 13.47 17.1 22.9 22.7 55\nInfoBench 84.30 (+4%) 79.6 81 - 86.7 89.4\nEQBench\nMetric-v2 91.36(+4%) 88.03 87.75 88.67 88.95 93.32\nMetric-v1 50.28 (+28%) 38.8 39.27 42.13 42.05 55.98\nTable 3: Performance of Orca-3 and other baseline models on all the benchmarks. Note:\nGPT-3.5-turbo scores for GSM8","chunk_id":"bd4eb9459bc29b4c2da4658914fd4635","document_ids":["c5a70861b9987da7046fe2110eb3616c"],"n_tokens":1200,"entities":[{"name":"COMPLEX ODQA","type":"DATASET\/SUBSET","description":"Complex ODQA is a subset of questions developed during the refinement phase, including more intricate questions","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"ORCA-BENCH","type":"DATASET","description":"Orca-Bench is a dataset used to evaluate the performance of various baseline models, scored relative to GPT-4 on a scale from 0 to 10","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"GPT-4","type":"MODEL","description":"GPT-4 is a language model used as a benchmark with a score of 10 in the evaluation of other models on the Orca-Bench dataset","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"AGENTINSTRUCT","type":"TOOL\/PROCESS","description":"AgentInstruct aims to synthesize a large and diverse corpus of data with varying degrees of difficulty to evaluate baseline models","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"ORCA-2.5","type":"MODEL","description":"Orca-2.5 is a baseline model evaluated on the Orca-Bench dataset","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"MISTRAL-INSTRUCT-7B","type":"MODEL","description":"Mistral-Instruct-7B is a baseline model evaluated on the Orca-Bench dataset","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"CHATGPT","type":"MODEL","description":"ChatGPT is a baseline model evaluated on the Orca-Bench dataset","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"ORCA-3","type":"MODEL","description":"Orca-3 is a model evaluated on the Orca-Bench dataset, showing notable enhancement in capabilities during post-training","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"LLAMA3-8B-INSTRUCT","type":"MODEL","description":"LLAMA3-8B-Instruct is a baseline model evaluated on various benchmarks","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"GPT-3.5-TURBO","type":"MODEL","description":"GPT-3.5-turbo is a baseline model evaluated on various benchmarks","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"AGIEVAL","type":"BENCHMARK","description":"AGIEval is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"MMLU","type":"BENCHMARK","description":"MMLU is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"ARC","type":"BENCHMARK","description":"ARC is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"BBH","type":"BENCHMARK","description":"BBH is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"GPQA","type":"BENCHMARK","description":"GPQA is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"DROP","type":"BENCHMARK","description":"DROP is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"GSM8K","type":"BENCHMARK","description":"GSM8K is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"FOFO","type":"BENCHMARK","description":"FOFO is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"IFEVAL","type":"BENCHMARK","description":"IFEval is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, GPT-3.5-turbo, and GPT-4","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"MT-BENCH","type":"BENCHMARK","description":"MT-Bench is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"ALPACAEVAL","type":"BENCHMARK","description":"AlpacaEval is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"INFOBENCH","type":"BENCHMARK","description":"InfoBench is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, GPT-3.5-turbo, and GPT-4","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"EQBENCH","type":"BENCHMARK","description":"EQBench is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"SYSTEM MESSAGE","type":"MESSAGE","description":"A part of the multi-turn interaction in Orca-Bench, crafted by GPT-4","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"USER","type":"PARTICIPANT","description":"A participant in the multi-turn interaction in Orca-Bench","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"ASSISTANT","type":"PARTICIPANT","description":"A participant in the multi-turn interaction in Orca-Bench, providing responses","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"TEACHER","type":"ROLE","description":"GPT-4 acting as the teacher in the multi-turn interaction in Orca-Bench","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"STUDENT","type":"ROLE","description":"The model being evaluated in the multi-turn interaction in Orca-Bench","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"ORCA-3 CHECKPOINT EPOCH 1","type":"MODEL","description":"A specific checkpoint of the Orca-3 model evaluated on the Orca-Bench dataset","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"ORCA-3 CHECKPOINT EPOCH 2","type":"MODEL","description":"A specific checkpoint of the Orca-3 model evaluated on the Orca-Bench dataset","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"TABLE 2","type":"DATA REPRESENTATION","description":"A table encapsulating the average (macro) scores across all assessed dimensions for different models","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"FIGURE 4","type":"DATA REPRESENTATION","description":"A figure illustrating the performance comparison between baseline models and Orca-3 checkpoints","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"BENCHMARK RESULTS","type":"RESULTS","description":"The section evaluating Orca-3 against 5 baseline models on various benchmarks","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"METRIC-V2","type":"BENCHMARK","description":"Metric-v2 is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4","source_id":"bd4eb9459bc29b4c2da4658914fd4635"},{"name":"METRIC-V1","type":"BENCHMARK","description":"Metric-v1 is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4","source_id":"bd4eb9459bc29b4c2da4658914fd4635"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"COMPLEX ODQA\">      <data key=\"d0\">DATASET\/SUBSET<\/data>      <data key=\"d1\">Complex ODQA is a subset of questions developed during the refinement phase, including more intricate questions<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"ORCA-BENCH\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">Orca-Bench is a dataset used to evaluate the performance of various baseline models, scored relative to GPT-4 on a scale from 0 to 10<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4 is a language model used as a benchmark with a score of 10 in the evaluation of other models on the Orca-Bench dataset<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"AGENTINSTRUCT\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">AgentInstruct aims to synthesize a large and diverse corpus of data with varying degrees of difficulty to evaluate baseline models<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"ORCA-2.5\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Orca-2.5 is a baseline model evaluated on the Orca-Bench dataset<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"MISTRAL-INSTRUCT-7B\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Mistral-Instruct-7B is a baseline model evaluated on the Orca-Bench dataset<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"CHATGPT\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">ChatGPT is a baseline model evaluated on the Orca-Bench dataset<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"ORCA-3\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Orca-3 is a model evaluated on the Orca-Bench dataset, showing notable enhancement in capabilities during post-training<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"LLAMA3-8B-INSTRUCT\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">LLAMA3-8B-Instruct is a baseline model evaluated on various benchmarks<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"GPT-3.5-TURBO\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-3.5-turbo is a baseline model evaluated on various benchmarks<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"AGIEVAL\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">AGIEval is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"MMLU\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">MMLU is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"ARC\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">ARC is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"BBH\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">BBH is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"GPQA\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">GPQA is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"DROP\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">DROP is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"GSM8K\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">GSM8K is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"FOFO\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">FOFO is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"IFEVAL\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">IFEval is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, GPT-3.5-turbo, and GPT-4<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"MT-BENCH\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">MT-Bench is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"ALPACAEVAL\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">AlpacaEval is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"INFOBENCH\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">InfoBench is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, GPT-3.5-turbo, and GPT-4<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"EQBENCH\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">EQBench is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"SYSTEM MESSAGE\">      <data key=\"d0\">MESSAGE<\/data>      <data key=\"d1\">A part of the multi-turn interaction in Orca-Bench, crafted by GPT-4<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"USER\">      <data key=\"d0\">PARTICIPANT<\/data>      <data key=\"d1\">A participant in the multi-turn interaction in Orca-Bench<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"ASSISTANT\">      <data key=\"d0\">PARTICIPANT<\/data>      <data key=\"d1\">A participant in the multi-turn interaction in Orca-Bench, providing responses<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"TEACHER\">      <data key=\"d0\">ROLE<\/data>      <data key=\"d1\">GPT-4 acting as the teacher in the multi-turn interaction in Orca-Bench<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"STUDENT\">      <data key=\"d0\">ROLE<\/data>      <data key=\"d1\">The model being evaluated in the multi-turn interaction in Orca-Bench<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"ORCA-3 CHECKPOINT EPOCH 1\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">A specific checkpoint of the Orca-3 model evaluated on the Orca-Bench dataset<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"ORCA-3 CHECKPOINT EPOCH 2\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">A specific checkpoint of the Orca-3 model evaluated on the Orca-Bench dataset<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"TABLE 2\">      <data key=\"d0\">DATA REPRESENTATION<\/data>      <data key=\"d1\">A table encapsulating the average (macro) scores across all assessed dimensions for different models<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"FIGURE 4\">      <data key=\"d0\">DATA REPRESENTATION<\/data>      <data key=\"d1\">A figure illustrating the performance comparison between baseline models and Orca-3 checkpoints<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"BENCHMARK RESULTS\">      <data key=\"d0\">RESULTS<\/data>      <data key=\"d1\">The section evaluating Orca-3 against 5 baseline models on various benchmarks<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"METRIC-V2\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">Metric-v2 is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <node id=\"METRIC-V1\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">Metric-v1 is a benchmark used to evaluate the performance of models including Orca-3, Orca-2.5, Mistral-7B-Instruct, LLAMA3-8B-Instruct, GPT-3.5-turbo, and GPT-4<\/data>      <data key=\"d2\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/node>    <edge source=\"ORCA-BENCH\" target=\"GPT-4\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Orca-Bench scores are evaluated relative to GPT-4, which is used as the benchmark with a score of 10<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"ORCA-3\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Orca-3 is evaluated against GPT-4 on various benchmarks<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"AGIEVAL\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">AGIEval is a benchmark used to evaluate the performance of GPT-4<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"MMLU\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">MMLU is a benchmark used to evaluate the performance of GPT-4<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"ARC\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">ARC is a benchmark used to evaluate the performance of GPT-4<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"BBH\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">BBH is a benchmark used to evaluate the performance of GPT-4<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"GPQA\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">GPQA is a benchmark used to evaluate the performance of GPT-4<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"DROP\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">DROP is a benchmark used to evaluate the performance of GPT-4<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"GSM8K\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">GSM8K is a benchmark used to evaluate the performance of GPT-4<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"FOFO\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">FOFO is a benchmark used to evaluate the performance of GPT-4<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"BENCHMARK RESULTS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Benchmark results section evaluates GPT-4<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"METRIC-V2\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Metric-v2 is a benchmark used to evaluate the performance of GPT-4<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"METRIC-V1\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Metric-v1 is a benchmark used to evaluate the performance of GPT-4<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"ORCA-2.5\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">AgentInstruct data led to a performance augmentation of 33.94% over the Orca 2.5 baseline<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"MISTRAL-INSTRUCT-7B\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">AgentInstruct data led to an enhancement of 14.92% over Mistral-Instruct-7B<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-2.5\" target=\"ORCA-3\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Orca-3 shows notable enhancement in capabilities during post-training compared to Orca-2.5<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-2.5\" target=\"MISTRAL-INSTRUCT-7B\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Orca-2.5 and Mistral-Instruct-7B are both baseline models evaluated on the Orca-Bench dataset<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-2.5\" target=\"CHATGPT\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Orca-2.5 and ChatGPT are both baseline models evaluated on the Orca-Bench dataset<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-2.5\" target=\"AGIEVAL\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">AGIEval is a benchmark used to evaluate the performance of Orca-2.5<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-2.5\" target=\"MMLU\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">MMLU is a benchmark used to evaluate the performance of Orca-2.5<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-2.5\" target=\"ARC\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">ARC is a benchmark used to evaluate the performance of Orca-2.5<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-2.5\" target=\"BBH\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">BBH is a benchmark used to evaluate the performance of Orca-2.5<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-2.5\" target=\"GPQA\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">GPQA is a benchmark used to evaluate the performance of Orca-2.5<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-2.5\" target=\"DROP\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">DROP is a benchmark used to evaluate the performance of Orca-2.5<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-2.5\" target=\"GSM8K\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">GSM8K is a benchmark used to evaluate the performance of Orca-2.5<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-2.5\" target=\"FOFO\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">FOFO is a benchmark used to evaluate the performance of Orca-2.5<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-2.5\" target=\"TABLE 2\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Table 2 encapsulates the average scores of Orca-2.5<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-2.5\" target=\"FIGURE 4\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Figure 4 illustrates the performance comparison of Orca-2.5<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-2.5\" target=\"BENCHMARK RESULTS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Benchmark results section evaluates Orca-2.5<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-2.5\" target=\"METRIC-V2\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Metric-v2 is a benchmark used to evaluate the performance of Orca-2.5<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-2.5\" target=\"METRIC-V1\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Metric-v1 is a benchmark used to evaluate the performance of Orca-2.5<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"MISTRAL-INSTRUCT-7B\" target=\"ORCA-3\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Orca-3 shows notable enhancement in capabilities during post-training compared to Mistral-Instruct-7B<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"MISTRAL-INSTRUCT-7B\" target=\"CHATGPT\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Mistral-Instruct-7B and ChatGPT are both baseline models evaluated on the Orca-Bench dataset<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"MISTRAL-INSTRUCT-7B\" target=\"AGIEVAL\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">AGIEval is a benchmark used to evaluate the performance of Mistral-Instruct-7B<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"MISTRAL-INSTRUCT-7B\" target=\"MMLU\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">MMLU is a benchmark used to evaluate the performance of Mistral-Instruct-7B<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"MISTRAL-INSTRUCT-7B\" target=\"ARC\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">ARC is a benchmark used to evaluate the performance of Mistral-Instruct-7B<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"MISTRAL-INSTRUCT-7B\" target=\"BBH\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">BBH is a benchmark used to evaluate the performance of Mistral-Instruct-7B<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"MISTRAL-INSTRUCT-7B\" target=\"GPQA\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">GPQA is a benchmark used to evaluate the performance of Mistral-Instruct-7B<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"MISTRAL-INSTRUCT-7B\" target=\"DROP\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">DROP is a benchmark used to evaluate the performance of Mistral-Instruct-7B<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"MISTRAL-INSTRUCT-7B\" target=\"GSM8K\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">GSM8K is a benchmark used to evaluate the performance of Mistral-Instruct-7B<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"MISTRAL-INSTRUCT-7B\" target=\"FOFO\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">FOFO is a benchmark used to evaluate the performance of Mistral-Instruct-7B<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"MISTRAL-INSTRUCT-7B\" target=\"TABLE 2\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Table 2 encapsulates the average scores of Mistral-Instruct-7B<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"MISTRAL-INSTRUCT-7B\" target=\"FIGURE 4\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Figure 4 illustrates the performance comparison of Mistral-Instruct-7B<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"MISTRAL-INSTRUCT-7B\" target=\"BENCHMARK RESULTS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Benchmark results section evaluates Mistral-Instruct-7B<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"MISTRAL-INSTRUCT-7B\" target=\"METRIC-V2\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Metric-v2 is a benchmark used to evaluate the performance of Mistral-Instruct-7B<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"MISTRAL-INSTRUCT-7B\" target=\"METRIC-V1\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Metric-v1 is a benchmark used to evaluate the performance of Mistral-Instruct-7B<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"CHATGPT\" target=\"ORCA-3\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Orca-3 shows notable enhancement in capabilities during post-training compared to ChatGPT<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"CHATGPT\" target=\"TABLE 2\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Table 2 encapsulates the average scores of ChatGPT<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"CHATGPT\" target=\"FIGURE 4\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Figure 4 illustrates the performance comparison of ChatGPT<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"LLAMA3-8B-INSTRUCT\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Orca-3 is evaluated against LLAMA3-8B-Instruct on various benchmarks<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"GPT-3.5-TURBO\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Orca-3 is evaluated against GPT-3.5-turbo on various benchmarks<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"AGIEVAL\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">AGIEval is a benchmark used to evaluate the performance of Orca-3<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"MMLU\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">MMLU is a benchmark used to evaluate the performance of Orca-3<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"ARC\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">ARC is a benchmark used to evaluate the performance of Orca-3<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"BBH\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">BBH is a benchmark used to evaluate the performance of Orca-3<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"GPQA\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">GPQA is a benchmark used to evaluate the performance of Orca-3<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"DROP\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">DROP is a benchmark used to evaluate the performance of Orca-3<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"GSM8K\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">GSM8K is a benchmark used to evaluate the performance of Orca-3<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"FOFO\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">FOFO is a benchmark used to evaluate the performance of Orca-3<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"ORCA-3 CHECKPOINT EPOCH 1\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Orca-3 checkpoint epoch 1 is a specific checkpoint of the Orca-3 model<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"ORCA-3 CHECKPOINT EPOCH 2\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Orca-3 checkpoint epoch 2 is a specific checkpoint of the Orca-3 model<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"TABLE 2\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Table 2 encapsulates the average scores of Orca-3<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"FIGURE 4\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Figure 4 illustrates the performance comparison of Orca-3<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"BENCHMARK RESULTS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Benchmark results section evaluates Orca-3<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"METRIC-V2\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Metric-v2 is a benchmark used to evaluate the performance of Orca-3<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"METRIC-V1\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Metric-v1 is a benchmark used to evaluate the performance of Orca-3<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"LLAMA3-8B-INSTRUCT\" target=\"AGIEVAL\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">AGIEval is a benchmark used to evaluate the performance of LLAMA3-8B-Instruct<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"LLAMA3-8B-INSTRUCT\" target=\"MMLU\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">MMLU is a benchmark used to evaluate the performance of LLAMA3-8B-Instruct<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"LLAMA3-8B-INSTRUCT\" target=\"ARC\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">ARC is a benchmark used to evaluate the performance of LLAMA3-8B-Instruct<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"LLAMA3-8B-INSTRUCT\" target=\"BBH\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">BBH is a benchmark used to evaluate the performance of LLAMA3-8B-Instruct<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"LLAMA3-8B-INSTRUCT\" target=\"GPQA\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">GPQA is a benchmark used to evaluate the performance of LLAMA3-8B-Instruct<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"LLAMA3-8B-INSTRUCT\" target=\"DROP\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">DROP is a benchmark used to evaluate the performance of LLAMA3-8B-Instruct<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"LLAMA3-8B-INSTRUCT\" target=\"GSM8K\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">GSM8K is a benchmark used to evaluate the performance of LLAMA3-8B-Instruct<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"LLAMA3-8B-INSTRUCT\" target=\"FOFO\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">FOFO is a benchmark used to evaluate the performance of LLAMA3-8B-Instruct<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"LLAMA3-8B-INSTRUCT\" target=\"BENCHMARK RESULTS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Benchmark results section evaluates LLAMA3-8B-Instruct<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"LLAMA3-8B-INSTRUCT\" target=\"METRIC-V2\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Metric-v2 is a benchmark used to evaluate the performance of LLAMA3-8B-Instruct<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"LLAMA3-8B-INSTRUCT\" target=\"METRIC-V1\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Metric-v1 is a benchmark used to evaluate the performance of LLAMA3-8B-Instruct<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-3.5-TURBO\" target=\"AGIEVAL\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">AGIEval is a benchmark used to evaluate the performance of GPT-3.5-turbo<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-3.5-TURBO\" target=\"MMLU\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">MMLU is a benchmark used to evaluate the performance of GPT-3.5-turbo<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-3.5-TURBO\" target=\"ARC\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">ARC is a benchmark used to evaluate the performance of GPT-3.5-turbo<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-3.5-TURBO\" target=\"BBH\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">BBH is a benchmark used to evaluate the performance of GPT-3.5-turbo<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-3.5-TURBO\" target=\"GPQA\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">GPQA is a benchmark used to evaluate the performance of GPT-3.5-turbo<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-3.5-TURBO\" target=\"DROP\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">DROP is a benchmark used to evaluate the performance of GPT-3.5-turbo<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-3.5-TURBO\" target=\"GSM8K\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">GSM8K is a benchmark used to evaluate the performance of GPT-3.5-turbo<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-3.5-TURBO\" target=\"FOFO\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">FOFO is a benchmark used to evaluate the performance of GPT-3.5-turbo<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-3.5-TURBO\" target=\"BENCHMARK RESULTS\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Benchmark results section evaluates GPT-3.5-turbo<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-3.5-TURBO\" target=\"METRIC-V2\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Metric-v2 is a benchmark used to evaluate the performance of GPT-3.5-turbo<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"GPT-3.5-TURBO\" target=\"METRIC-V1\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Metric-v1 is a benchmark used to evaluate the performance of GPT-3.5-turbo<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"SYSTEM MESSAGE\" target=\"USER\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">System message is part of the multi-turn interaction involving the user in Orca-Bench<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"SYSTEM MESSAGE\" target=\"ASSISTANT\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">System message is part of the multi-turn interaction involving the assistant in Orca-Bench<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"USER\" target=\"ASSISTANT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">User and assistant are participants in the multi-turn interaction in Orca-Bench<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>    <edge source=\"TEACHER\" target=\"STUDENT\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Teacher (GPT-4) and student (model being evaluated) are roles in the multi-turn interaction in Orca-Bench<\/data>      <data key=\"d5\">bd4eb9459bc29b4c2da4658914fd4635<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"86f77e15d41cbd0cb33f635ccb2cb66b","chunk":"EQBench\nMetric-v2 91.36(+4%) 88.03 87.75 88.67 88.95 93.32\nMetric-v1 50.28 (+28%) 38.8 39.27 42.13 42.05 55.98\nTable 3: Performance of Orca-3 and other baseline models on all the benchmarks. Note:\nGPT-3.5-turbo scores for GSM8K are taken from [ 1]. We show in (+x%) the relative\nimprovement over Mistral-7b-Instruct.\n\u2022AGIEval : AGIEval [ 39] is a human-centric benchmark that evaluates a model\u2019s\nabilities in tasks pertinent to human-cognition and problem-solving. It evaluates\nhow well models perform in answering questions from human-centric standardized\nexams such as SAT, LSAT and math competitions.\n\u2022MMLU : Massive Multitask Language Understanding (MMLU) [ 9] benchmark\nmeasures a model\u2019s multitask understanding. The benchmark includes approximately\n16000 multiple choice questions covering a wide range of 57 academic subjects such\nas maths, philosphy, medicine, psychology, computer-science, law etc. testing both\ngeneral and specialized knowledge of the model being tested.\n\u2022ARC: The AI2 Reasoning Challenge (ARC) [ 2] benchmark, developed by AllenAI,\nmeasures the reasoning, commonsense knowledge and deep comprehension abilities\nof language models. The test set contains 3548 multiple-choice questions that are\ndivided into 2 sets : Easy(2376) and Challenge(1172).\n\u2022BBH: Big Bench Hard [ 31] consists of a set of 23 tasks selected from the broader\nBig-Bench benchmark spanning a wide array of academic subjects requiring complex,\nmulti-step reasoning.\n\u2022GPQA: Graduate-level Google-Proof Q&A [ 27] is a challenging benchmark of 448\nhigh-quality and extremely difficult multiple-choice questions created by domain\nexperts(pursuing PhDs in their domains) in biology, chemistry and physics.\n\u2022DROP: Discrete Reasoning over Paragraphs [ 6] is a Reading Comprehension bench-\nmark requiring the models to resolve references in questions and perform discrete\noperations over them such as sorting, counting, addition etc.\n16\u2022GSM8K : Grade School Math 8K [ 3] is a dataset of high quality diverse grade\nschool math word problems. The test split of the dataset consists of 1.32K problems\nrequiring between 2 and 8 steps to solve primarily involving sequence of elementary\ncalculations using basic arithmetic operations.\n\u2022FoFo: Format Following [ 34] is a benchmark that evaluates a model\u2019s ability to\nfollow complex, domain-specific formats. The benchmark tests format following on\na diverse range of real-world formats and instructions from domains like Healthcare,\nFinance, Marketing etc. created using AI-Human collaboration.\n\u2022IFEval: Instruction-Following Evaluation [ 40] is a benchmark measuring a model\u2019s\nability to follow natural language instructions using a set of 500 prompts covering\n25 types of \u2019verifiable instructions\u2019 where each prompt can contain one or more of\nthese instructions.\n\u2022MT-Bench : MT-Bench [ 16] benchmark is specifically designed to assess the com-\npetence of chat assistants in multi-turn conversations using GPT-4 as the evaluator.\n\u2022AlpacaEval : AlpacaEval [ 14] is a benchmark specifically designed for chat-based\nlanguage models to assess their abilities in the context of instruction-following tasks.\nIt is a single-turn benchmark consisting of 805 instructions representative of user\ninteractions on Alpaca web demo.\n\u2022InFoBench : The InFoBench [ 25] benchmark evaluates models instruction fol-\nlowing capability using a new metric called Decomposed Requirements Following\nRatio(DRFR). DRFR breaks complex instructions down into simpler criteria and\nfacilitates analysis of an LLM\u2019s compliance to these decomposed tasks in detail.\nThe benchmark has 500 diverse instructions and 2250 decomposed questions across\nmultiple constraint categories.\n\u2022EQBench : This Emotional Intelligence benchmark [ 23] evaluates aspects of emo-\ntional intelligence in language models. It tests models capabilities to comprehend\nintricate emotions and social interactions by providing a conversation between char-\nacters and then asking the model to predict intensity of emotional states of those\ncharacters. The authors discovered a strong correlation (r=0.97) between EQ-Bench\nand comprehensive multi-domain benchmarks like MMLU.\nThe results for all the baselines on each benchmark are given in table 3. All of the evaluations\nfor Orca-3 and other baselines was done in a zero-shot setting unless mentioned otherwise in\nthe text.\nThe types of tasks\/benchmarks and the corresponding method used to extract answer and\ngenerate metrics is specified in Appendix B.\n4.3 Evaluation: Reading Comprehension\nReading comprehension is a crucial capability for LLMs. It is arguably even more important\nfor Small Language Models (SLMs), as they are better suited as reasoning engines than mere\nretrieval systems. Through targeted training with AgentInstruct, we observe substantial\nimprovement in Mistral\u2019s reading comprehension capabilities (Table ??)\u2014showcasing an 18%\nimprovement over Orca 2.5 and a 21% gain relative to Mistral-Instruct-7b. Furthermore, by\nleveraging this data-driven approach, we have elevated the performance of a 7B model to\nmatch that of GPT-4 on the reading comprehension sections of the Law School Admission\nTests (LSATs), which are considered difficult for human test-takers.\n4.4 Evaluation: Math","chunk_id":"86f77e15d41cbd0cb33f635ccb2cb66b","document_ids":["c5a70861b9987da7046fe2110eb3616c"],"n_tokens":1200,"entities":[{"name":"ORCA-3","type":"MODEL","description":"Orca-3 is a language model evaluated on various benchmarks in a zero-shot setting.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"GPT-3.5-TURBO","type":"MODEL","description":"GPT-3.5-turbo is a version of OpenAI's language model, with scores for GSM8K taken from a specific reference.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"AGIEVAL","type":"TOOL\/BENCHMARK","description":"AGIEval is a human-centric benchmark that evaluates a model\u2019s abilities in tasks pertinent to human cognition and problem-solving, including standardized exams like SAT and LSAT.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"MMLU","type":"TOOL\/BENCHMARK","description":"Massive Multitask Language Understanding (MMLU) is a benchmark that measures a model\u2019s multitask understanding across 57 academic subjects with approximately 16000 multiple-choice questions.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"ARC","type":"TOOL\/BENCHMARK","description":"The AI2 Reasoning Challenge (ARC) is a benchmark developed by AllenAI to measure the reasoning, commonsense knowledge, and deep comprehension abilities of language models.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"BBH","type":"TOOL\/BENCHMARK","description":"Big Bench Hard (BBH) is a set of 23 tasks from the broader Big-Bench benchmark requiring complex, multi-step reasoning across various academic subjects.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"GPQA","type":"TOOL\/BENCHMARK","description":"Graduate-level Google-Proof Q&A (GPQA) is a challenging benchmark of 448 high-quality, difficult multiple-choice questions created by domain experts in biology, chemistry, and physics.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"DROP","type":"TOOL\/BENCHMARK","description":"Discrete Reasoning over Paragraphs (DROP) is a reading comprehension benchmark requiring models to resolve references in questions and perform discrete operations like sorting, counting, and addition.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"GSM8K","type":"TOOL\/BENCHMARK","description":"Grade School Math 8K (GSM8K) is a dataset of high-quality, diverse grade school math word problems requiring between 2 and 8 steps to solve.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"FOFO","type":"TOOL\/BENCHMARK","description":"Format Following (FoFo) is a benchmark that evaluates a model\u2019s ability to follow complex, domain-specific formats across various real-world domains like Healthcare, Finance, and Marketing.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"IFEVAL","type":"TOOL\/BENCHMARK","description":"Instruction-Following Evaluation (IFEval) is a benchmark measuring a model\u2019s ability to follow natural language instructions using a set of 500 prompts covering 25 types of verifiable instructions.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"MT-BENCH","type":"TOOL\/BENCHMARK","description":"MT-Bench is a benchmark designed to assess the competence of chat assistants in multi-turn conversations using GPT-4 as the evaluator.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"ALPACAEVAL","type":"TOOL\/BENCHMARK","description":"AlpacaEval is a benchmark designed for chat-based language models to assess their abilities in instruction-following tasks, consisting of 805 instructions.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"INFOBENCH","type":"TOOL\/BENCHMARK","description":"InFoBench is a benchmark that evaluates models' instruction-following capability using the Decomposed Requirements Following Ratio (DRFR) metric.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"MISTRAL-7B-INSTRUCT","type":"MODEL","description":"Mistral-7b-Instruct is a language model used as a baseline for comparison in various benchmarks.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"AGENTINSTRUCT","type":"TOOL\/PROCESS","description":"AgentInstruct is a targeted training method used to improve reading comprehension capabilities in language models like Mistral.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"LSAT","type":"EXAM","description":"The Law School Admission Test (LSAT) is a standardized test used for law school admissions, known for its difficulty in reading comprehension sections.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"SAT","type":"","description":"","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"BIG-BENCH","type":"","description":"\nBig-Bench is a broader benchmark from which the Big Bench Hard (BBH) tasks are selected.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b","entity_type":"TOOL\/BENCHMARK"},{"name":"DOMAIN EXPERTS","type":"","description":"","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"READING COMPREHENSION","type":"","description":"\nReading comprehension is a crucial capability for LLMs, especially for Small Language Models (SLMs), as they are better suited as reasoning engines than mere retrieval systems.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b","entity_type":"CAPABILITY"},{"name":"GRADE SCHOOL MATH","type":"","description":"","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"DOMAIN-SPECIFIC FORMATS","type":"","description":"","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"INSTRUCTION-FOLLOWING","type":"","description":"","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"GPT-4","type":"","description":"","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"ALPACA WEB DEMO","type":"","description":"","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"DRFR","type":"","description":"","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"MISTRAL","type":"","description":"\nMistral is a language model that showed substantial improvement in reading comprehension capabilities through targeted training with AgentInstruct.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b","entity_type":"MODEL"},{"name":"METRIC-V1","type":"METRIC","description":"Metric-v1 is a performance metric used to evaluate models, showing a 28% improvement in one of the benchmarks.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"ORCA-2.5","type":"MODEL","description":"Orca-2.5 is a previous version of the Orca language model used for comparison in reading comprehension evaluations.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"ALLENAI","type":"ORGANIZATION","description":"AllenAI is the organization that developed the AI2 Reasoning Challenge (ARC) benchmark.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"AI-HUMAN COLLABORATION","type":"PROCESS","description":"AI-Human collaboration is the process used to create the diverse range of real-world formats and instructions for the FoFo benchmark.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"APPENDIX B","type":"DOCUMENT","description":"Appendix B specifies the types of tasks\/benchmarks and the corresponding methods used to extract answers and generate metrics.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"MATH","type":"CAPABILITY","description":"Math is another capability evaluated in language models, as indicated in the document's section on evaluation.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"ZERO-SHOT SETTING","type":"PROCESS","description":"Zero-shot setting is the evaluation method used for Orca-3 and other baseline models unless mentioned otherwise.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"LAW SCHOOL ADMISSION TESTS (LSATS)","type":"EXAM","description":"The Law School Admission Tests (LSATs) are standardized tests used for law school admissions, known for their difficulty in reading comprehension sections.","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"METRIC-V2","type":"","description":"","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"BENCHMARKS","type":"","description":"","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"LLMS","type":"","description":"","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"SLMS","type":"","description":"","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"},{"name":"EVALUATION","type":"","description":"","source_id":"86f77e15d41cbd0cb33f635ccb2cb66b"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"ORCA-3\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Orca-3 is a language model evaluated on various benchmarks in a zero-shot setting.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"GPT-3.5-TURBO\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-3.5-turbo is a version of OpenAI's language model, with scores for GSM8K taken from a specific reference.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"AGIEVAL\">      <data key=\"d0\">TOOL\/BENCHMARK<\/data>      <data key=\"d1\">AGIEval is a human-centric benchmark that evaluates a model&#8217;s abilities in tasks pertinent to human cognition and problem-solving, including standardized exams like SAT and LSAT.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"MMLU\">      <data key=\"d0\">TOOL\/BENCHMARK<\/data>      <data key=\"d1\">Massive Multitask Language Understanding (MMLU) is a benchmark that measures a model&#8217;s multitask understanding across 57 academic subjects with approximately 16000 multiple-choice questions.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"ARC\">      <data key=\"d0\">TOOL\/BENCHMARK<\/data>      <data key=\"d1\">The AI2 Reasoning Challenge (ARC) is a benchmark developed by AllenAI to measure the reasoning, commonsense knowledge, and deep comprehension abilities of language models.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"BBH\">      <data key=\"d0\">TOOL\/BENCHMARK<\/data>      <data key=\"d1\">Big Bench Hard (BBH) is a set of 23 tasks from the broader Big-Bench benchmark requiring complex, multi-step reasoning across various academic subjects.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"GPQA\">      <data key=\"d0\">TOOL\/BENCHMARK<\/data>      <data key=\"d1\">Graduate-level Google-Proof Q&amp;A (GPQA) is a challenging benchmark of 448 high-quality, difficult multiple-choice questions created by domain experts in biology, chemistry, and physics.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"DROP\">      <data key=\"d0\">TOOL\/BENCHMARK<\/data>      <data key=\"d1\">Discrete Reasoning over Paragraphs (DROP) is a reading comprehension benchmark requiring models to resolve references in questions and perform discrete operations like sorting, counting, and addition.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"GSM8K\">      <data key=\"d0\">TOOL\/BENCHMARK<\/data>      <data key=\"d1\">Grade School Math 8K (GSM8K) is a dataset of high-quality, diverse grade school math word problems requiring between 2 and 8 steps to solve.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"FOFO\">      <data key=\"d0\">TOOL\/BENCHMARK<\/data>      <data key=\"d1\">Format Following (FoFo) is a benchmark that evaluates a model&#8217;s ability to follow complex, domain-specific formats across various real-world domains like Healthcare, Finance, and Marketing.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"IFEVAL\">      <data key=\"d0\">TOOL\/BENCHMARK<\/data>      <data key=\"d1\">Instruction-Following Evaluation (IFEval) is a benchmark measuring a model&#8217;s ability to follow natural language instructions using a set of 500 prompts covering 25 types of verifiable instructions.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"MT-BENCH\">      <data key=\"d0\">TOOL\/BENCHMARK<\/data>      <data key=\"d1\">MT-Bench is a benchmark designed to assess the competence of chat assistants in multi-turn conversations using GPT-4 as the evaluator.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"ALPACAEVAL\">      <data key=\"d0\">TOOL\/BENCHMARK<\/data>      <data key=\"d1\">AlpacaEval is a benchmark designed for chat-based language models to assess their abilities in instruction-following tasks, consisting of 805 instructions.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"INFOBENCH\">      <data key=\"d0\">TOOL\/BENCHMARK<\/data>      <data key=\"d1\">InFoBench is a benchmark that evaluates models' instruction-following capability using the Decomposed Requirements Following Ratio (DRFR) metric.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"MISTRAL-7B-INSTRUCT\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Mistral-7b-Instruct is a language model used as a baseline for comparison in various benchmarks.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"AGENTINSTRUCT\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">AgentInstruct is a targeted training method used to improve reading comprehension capabilities in language models like Mistral.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"LSAT\">      <data key=\"d0\">EXAM<\/data>      <data key=\"d1\">The Law School Admission Test (LSAT) is a standardized test used for law school admissions, known for its difficulty in reading comprehension sections.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"SAT\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"BIG-BENCH\">      <data key=\"d0\" \/>      <data key=\"d1\">Big-Bench is a broader benchmark from which the Big Bench Hard (BBH) tasks are selected.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>      <data key=\"d3\">TOOL\/BENCHMARK<\/data>    <\/node>    <node id=\"DOMAIN EXPERTS\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"READING COMPREHENSION\">      <data key=\"d0\" \/>      <data key=\"d1\">Reading comprehension is a crucial capability for LLMs, especially for Small Language Models (SLMs), as they are better suited as reasoning engines than mere retrieval systems.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>      <data key=\"d3\">CAPABILITY<\/data>    <\/node>    <node id=\"GRADE SCHOOL MATH\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"DOMAIN-SPECIFIC FORMATS\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"INSTRUCTION-FOLLOWING\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"ALPACA WEB DEMO\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"DRFR\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"MISTRAL\">      <data key=\"d0\" \/>      <data key=\"d1\">Mistral is a language model that showed substantial improvement in reading comprehension capabilities through targeted training with AgentInstruct.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"METRIC-V1\">      <data key=\"d0\">METRIC<\/data>      <data key=\"d1\">Metric-v1 is a performance metric used to evaluate models, showing a 28% improvement in one of the benchmarks.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"ORCA-2.5\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Orca-2.5 is a previous version of the Orca language model used for comparison in reading comprehension evaluations.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"ALLENAI\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">AllenAI is the organization that developed the AI2 Reasoning Challenge (ARC) benchmark.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"AI-HUMAN COLLABORATION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">AI-Human collaboration is the process used to create the diverse range of real-world formats and instructions for the FoFo benchmark.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"APPENDIX B\">      <data key=\"d0\">DOCUMENT<\/data>      <data key=\"d1\">Appendix B specifies the types of tasks\/benchmarks and the corresponding methods used to extract answers and generate metrics.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"MATH\">      <data key=\"d0\">CAPABILITY<\/data>      <data key=\"d1\">Math is another capability evaluated in language models, as indicated in the document's section on evaluation.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"ZERO-SHOT SETTING\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Zero-shot setting is the evaluation method used for Orca-3 and other baseline models unless mentioned otherwise.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"LAW SCHOOL ADMISSION TESTS (LSATS)\">      <data key=\"d0\">EXAM<\/data>      <data key=\"d1\">The Law School Admission Tests (LSATs) are standardized tests used for law school admissions, known for their difficulty in reading comprehension sections.<\/data>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"METRIC-V2\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"BENCHMARKS\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"LLMS\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"SLMS\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <node id=\"EVALUATION\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/node>    <edge source=\"ORCA-3\" target=\"MISTRAL-7B-INSTRUCT\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">Orca-3 shows relative improvement over Mistral-7b-Instruct in various benchmarks<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"METRIC-V2\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Orca-3's performance was evaluated using Metric-v2<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"METRIC-V1\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Orca-3's performance was evaluated using Metric-v1<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"GPT-3.5-TURBO\" target=\"GSM8K\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">GPT-3.5-turbo scores for GSM8K are taken from a specific reference<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"AGIEVAL\" target=\"SAT\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AGIEval evaluates models on tasks pertinent to human cognition, including standardized exams like SAT<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"AGIEVAL\" target=\"LSAT\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AGIEval evaluates models on tasks pertinent to human cognition, including standardized exams like LSAT<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"MMLU\" target=\"ARC\">      <data key=\"d4\">6.0<\/data>      <data key=\"d5\">Both MMLU and ARC are benchmarks that measure various capabilities of language models<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"ARC\" target=\"ALLENAI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">AllenAI developed the AI2 Reasoning Challenge (ARC) benchmark<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"BBH\" target=\"BIG-BENCH\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">BBH consists of tasks selected from the broader Big-Bench benchmark<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"GPQA\" target=\"DOMAIN EXPERTS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">GPQA questions are created by domain experts pursuing PhDs in their respective fields<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"DROP\" target=\"READING COMPREHENSION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">DROP is a reading comprehension benchmark<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"GSM8K\" target=\"GRADE SCHOOL MATH\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">GSM8K consists of grade school math word problems<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"FOFO\" target=\"DOMAIN-SPECIFIC FORMATS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">FoFo evaluates a model&#8217;s ability to follow complex, domain-specific formats<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"FOFO\" target=\"AI-HUMAN COLLABORATION\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">FoFo benchmark tests format following on a diverse range of real-world formats and instructions created using AI-Human collaboration<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"IFEVAL\" target=\"INSTRUCTION-FOLLOWING\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">IFEval measures a model&#8217;s ability to follow natural language instructions<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"MT-BENCH\" target=\"GPT-4\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">MT-Bench uses GPT-4 as the evaluator for assessing chat assistants<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"ALPACAEVAL\" target=\"ALPACA WEB DEMO\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">AlpacaEval consists of instructions representative of user interactions on the Alpaca web demo<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"INFOBENCH\" target=\"DRFR\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">InFoBench uses the Decomposed Requirements Following Ratio (DRFR) metric<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"MISTRAL\">      <data key=\"d4\">16.0<\/data>      <data key=\"d5\">AgentInstruct is used to improve Mistral&#8217;s reading comprehension capabilities<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"LSAT\" target=\"READING COMPREHENSION\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">LSAT is known for its difficult reading comprehension sections<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"READING COMPREHENSION\" target=\"LLMS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Reading comprehension is a crucial capability for LLMs<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"READING COMPREHENSION\" target=\"SLMS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Reading comprehension is arguably even more important for Small Language Models (SLMs)<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"MISTRAL\" target=\"ORCA-2.5\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Mistral showed an 18% improvement over Orca-2.5 in reading comprehension capabilities<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"APPENDIX B\" target=\"BENCHMARKS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Appendix B specifies the types of tasks\/benchmarks and the corresponding methods used to extract answers and generate metrics<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>    <edge source=\"MATH\" target=\"EVALUATION\">      <data key=\"d4\">1.0<\/data>      <data key=\"d5\">Math is another capability evaluated in language models<\/data>      <data key=\"d6\">86f77e15d41cbd0cb33f635ccb2cb66b<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"bb87f82e6a9f1d4da6480ec78a0e3701","chunk":"Table ??)\u2014showcasing an 18%\nimprovement over Orca 2.5 and a 21% gain relative to Mistral-Instruct-7b. Furthermore, by\nleveraging this data-driven approach, we have elevated the performance of a 7B model to\nmatch that of GPT-4 on the reading comprehension sections of the Law School Admission\nTests (LSATs), which are considered difficult for human test-takers.\n4.4 Evaluation: Math\nAssessing the reasoning capabilities of AI models can be effectively accomplished through\nmath problem solving. While SLMs have shown considerable improvement in elementary\nmath, their performance typically falters with more complex high school and college-level\nmathematics. Math problems are generated by the Open Domain Question Answering\nand Multiple-Choice Questions Flows. With AgentInstruct, we have managed to enhance\nMistral\u2019s proficiency across a spectrum of difficulties, ranging from elementary to college-level\nmath (Table 5. This has led to a signficant performance boost, with improvements ranging\n17Model Orca-3\n-7BOrca-2.5\n-7BMistral-\n7B-InstructGPT-3.5-\nturboGPT-4\nAGIEval lsat-rc75.84\n(+21%,+20%)62.45 63.2 63.57 72.86\nAGIEval sat-en87.38\n(+13%,+15%)77.18 75.73 82.04 82.52\nAGIEval\ngaokao-english87.25\n(+13%,+17%)77.45 74.84 83.01 87.25\nAGIEval lsat-lr63.14\n(+45%,+36%)43.53 46.27 54.9 68.82\nDROP71.14\n(+9%,+22%)65.19 58.12 67.15 67.36\nAverage76.95\n(+18%,+21%)65.16 63.63 70.13 75.76\nTable 4: Performance of models on reading comprehension based sub-tasks and benchmarks.\nThe figures (x%, y%) adjacent to the Orca-3 results signify the percentage of improvement\ncompared to Orca 2.5 and Mistral-7B-Instruct, respectively.\nModel Orca-3\n-7BOrca-2.5\n-7BMistral-\n7B-InstructGPT-3.5-\nturboGPT-4\nAGIEval math42.90\n(+73%,+168%)24.8 16.0 38.0 57.9\nAGIEval sat-math80.91\n(+34%,+50%)60.45 54.09 67.73 90.0\nBBH multistep\n-arithmetic-two66.80\n(+1418%,+882%)4.4 6.8 46.4 77.2\nMMLU abstract\nalgebra55.00\n(+129%,+104%)24.0 27.0 47.0 70.0\nMMLU college\nmathematics44.00\n(+63%,+44%)30.0 34.0 39.0 62.0\nMMLU high-school\nmathematics66.67\n(+41%,+94%)47.41 34.44 57.04 66.67\nGSM8K83.09\n(+12%,+54%)74.3 54.06 78.1\u221786.88\nTable 5: Performance scores of models on Math benchmarks. Note: GPT-3.5-turbo accuracy\nscores reported for GSM8K are taken from Phi3 paper[ 1]. The figures (x%, y%) adjacent\nto the Orca-3 results signify the percentage of improvement compared to Orca 2.5 and\nMistral-7B-Instruct, respectively.\nfrom 44% to 168% on various popular mathematical benchmarks. It should be emphasized\nthat the objective of Generative Teaching is to teach a skill than generating data to meet a\nspecific benchmark. The effectiveness of AgentInstruct for Generative Teaching is evidenced\nby marked enhancements across a variety of mathematical datasets.\n4.5 Evaluation: Format Following\nFollowing formatting guidelines is essential for language models to be applicable in real-world\nsituations. In all AgentInstruct flows, we ensure that format-following is taught for each\nparticular scenario, by synthesizing, through agents, several formatting guidelines. By doing\nso, we are able to significantly improve (11.5%) Mistral\u2019s ability to follow formats, surpassing\neven the capabilities of Gemini Pro.\n18Model FoFo\nOpen-sourceOrca-3-7B 84.01 (+26.92%,+11.5%)\nOrca-2.5-7B 66.19\nMistral-7B-Instruct 75.3\nClosed-sourceGPT-3.5-turbo 76.92\nGemini Pro 80.25\u2217\nGPT-4 87.45\nTable 6: Performance of Orca-3-7B model and other open and closed-source baselines on\nFoFo benchmark. The figures (x%, y%) adjacent to the Orca-3 results signify the percentage\nof improvement compared to Orca 2.5 and Mistral-7B-Instruct, respectively. Note: The\nscores for Gemini Pro are taken from the original paper [34]\n4.6 Evaluation: Abstractive","chunk_id":"bb87f82e6a9f1d4da6480ec78a0e3701","document_ids":["c5a70861b9987da7046fe2110eb3616c"],"n_tokens":1200,"entities":[{"name":"ORCA-3","type":"MODEL","description":"Orca-3 is a 7B model that has shown significant improvements in various benchmarks, including reading comprehension, math, and format following","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"},{"name":"ORCA-2.5","type":"MODEL","description":"Orca-2.5 is a 7B model used as a baseline for comparison with Orca-3","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"},{"name":"MISTRAL-7B-INSTRUCT","type":"MODEL","description":"Mistral-7B-Instruct is a model used as a baseline for comparison with Orca-3\nMistral-7B-Instruct is a model used as a baseline for comparison with Orca-3-7B","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701","entity_type":"MODEL"},{"name":"GPT-4","type":"MODEL","description":"GPT-4 is a model used as a benchmark for evaluating the performance of other models like Orca-3","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"},{"name":"LSAT","type":"EXAM","description":"The Law School Admission Test (LSAT) is a standardized test used for law school admissions, known for its difficulty","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"},{"name":"AGIEVAL","type":"BENCHMARK","description":"AGIEval is a benchmark used to evaluate models on various tasks, including reading comprehension and math","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"},{"name":"AGENTINSTRUCT","type":"TOOL\/PROCESS","description":"AgentInstruct is a process used to enhance the proficiency of models like Mistral across various difficulties in math","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"},{"name":"GSM8K","type":"BENCHMARK","description":"GSM8K is a benchmark used to evaluate models on math problem-solving tasks","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701","entity_type":"BENCHMARK"},{"name":"FOFO","type":"BENCHMARK","description":"FoFo is a benchmark used to evaluate models on their ability to follow formatting guidelines","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701","entity_type":"BENCHMARK"},{"name":"GEMINI PRO","type":"MODEL","description":"Gemini Pro is a model used as a benchmark for evaluating the format-following capabilities of other models like Orca-3-7B\nGemini Pro is a model used as a benchmark for evaluating the format-following capabilities of other models like Orca-3","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701","entity_type":"MODEL"},{"name":"GENERATIVE TEACHING","type":"CONCEPT","description":"Generative Teaching is a concept aimed at teaching skills rather than generating data to meet specific benchmarks","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"},{"name":"MMLU","type":"BENCHMARK","description":"MMLU is a benchmark used to evaluate models on various mathematical tasks, including abstract algebra and college mathematics","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"},{"name":"OPEN DOMAIN QUESTION ANSWERING","type":"PROCESS","description":"Open Domain Question Answering is a process used to generate math problems for evaluating AI models","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"},{"name":"MULTIPLE-CHOICE QUESTIONS FLOWS","type":"PROCESS","description":"Multiple-Choice Questions Flows is a process used to generate math problems for evaluating AI models","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"},{"name":"PHI3","type":"PUBLICATION","description":"Phi3 is a paper that reported the accuracy scores for GPT-3.5-turbo on the GSM8K benchmark","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701","entity_type":"PUBLICATION"},{"name":"GPT-3.5-TURBO","type":"","description":"\nGPT-3.5-turbo is a model used as a benchmark for evaluating the performance of other models like Orca-3-7B","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701","entity_type":"MODEL"},{"name":"ORCA-3-7B","type":"MODEL","description":"Orca-3-7B is a model that has shown significant improvements in various benchmarks, including reading comprehension, math, and format following","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"},{"name":"ORCA-2.5-7B","type":"MODEL","description":"Orca-2.5-7B is a model used as a baseline for comparison with Orca-3-7B","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"},{"name":"AGIEVAL LSAT-RC","type":"BENCHMARK","description":"AGIEval LSAT-RC is a benchmark used to evaluate models on the reading comprehension sections of the LSAT","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"},{"name":"AGIEVAL SAT-EN","type":"BENCHMARK","description":"AGIEval SAT-EN is a benchmark used to evaluate models on the English sections of the SAT","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"},{"name":"AGIEVAL GAOKAO-ENGLISH","type":"BENCHMARK","description":"AGIEval Gaokao-English is a benchmark used to evaluate models on the English sections of the Gaokao","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"},{"name":"AGIEVAL LSAT-LR","type":"BENCHMARK","description":"AGIEval LSAT-LR is a benchmark used to evaluate models on the logical reasoning sections of the LSAT","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"},{"name":"DROP","type":"BENCHMARK","description":"DROP is a benchmark used to evaluate models on reading comprehension tasks","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"},{"name":"AGIEVAL MATH","type":"BENCHMARK","description":"AGIEval Math is a benchmark used to evaluate models on math problem-solving tasks","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"},{"name":"AGIEVAL SAT-MATH","type":"BENCHMARK","description":"AGIEval SAT-Math is a benchmark used to evaluate models on the math sections of the SAT","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"},{"name":"BBH MULTISTEP-ARITHMETIC-TWO","type":"BENCHMARK","description":"BBH Multistep-Arithmetic-Two is a benchmark used to evaluate models on multi-step arithmetic problems","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"},{"name":"MMLU ABSTRACT ALGEBRA","type":"BENCHMARK","description":"MMLU Abstract Algebra is a benchmark used to evaluate models on abstract algebra tasks","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"},{"name":"MMLU COLLEGE MATHEMATICS","type":"BENCHMARK","description":"MMLU College Mathematics is a benchmark used to evaluate models on college-level mathematics tasks","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"},{"name":"MMLU HIGH-SCHOOL MATHEMATICS","type":"BENCHMARK","description":"MMLU High-School Mathematics is a benchmark used to evaluate models on high school-level mathematics tasks","source_id":"bb87f82e6a9f1d4da6480ec78a0e3701"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"ORCA-3\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Orca-3 is a 7B model that has shown significant improvements in various benchmarks, including reading comprehension, math, and format following<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <node id=\"ORCA-2.5\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Orca-2.5 is a 7B model used as a baseline for comparison with Orca-3<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <node id=\"MISTRAL-7B-INSTRUCT\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Mistral-7B-Instruct is a model used as a baseline for comparison with Orca-3Mistral-7B-Instruct is a model used as a baseline for comparison with Orca-3-7B<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4 is a model used as a benchmark for evaluating the performance of other models like Orca-3<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <node id=\"LSAT\">      <data key=\"d0\">EXAM<\/data>      <data key=\"d1\">The Law School Admission Test (LSAT) is a standardized test used for law school admissions, known for its difficulty<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <node id=\"AGIEVAL\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">AGIEval is a benchmark used to evaluate models on various tasks, including reading comprehension and math<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <node id=\"AGENTINSTRUCT\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">AgentInstruct is a process used to enhance the proficiency of models like Mistral across various difficulties in math<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <node id=\"GSM8K\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">GSM8K is a benchmark used to evaluate models on math problem-solving tasks<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>      <data key=\"d3\">BENCHMARK<\/data>    <\/node>    <node id=\"FOFO\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">FoFo is a benchmark used to evaluate models on their ability to follow formatting guidelines<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>      <data key=\"d3\">BENCHMARK<\/data>    <\/node>    <node id=\"GEMINI PRO\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Gemini Pro is a model used as a benchmark for evaluating the format-following capabilities of other models like Orca-3-7BGemini Pro is a model used as a benchmark for evaluating the format-following capabilities of other models like Orca-3<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"GENERATIVE TEACHING\">      <data key=\"d0\">CONCEPT<\/data>      <data key=\"d1\">Generative Teaching is a concept aimed at teaching skills rather than generating data to meet specific benchmarks<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <node id=\"MMLU\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">MMLU is a benchmark used to evaluate models on various mathematical tasks, including abstract algebra and college mathematics<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <node id=\"OPEN DOMAIN QUESTION ANSWERING\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Open Domain Question Answering is a process used to generate math problems for evaluating AI models<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <node id=\"MULTIPLE-CHOICE QUESTIONS FLOWS\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Multiple-Choice Questions Flows is a process used to generate math problems for evaluating AI models<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <node id=\"PHI3\">      <data key=\"d0\">PUBLICATION<\/data>      <data key=\"d1\">Phi3 is a paper that reported the accuracy scores for GPT-3.5-turbo on the GSM8K benchmark<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>      <data key=\"d3\">PUBLICATION<\/data>    <\/node>    <node id=\"GPT-3.5-TURBO\">      <data key=\"d0\" \/>      <data key=\"d1\">GPT-3.5-turbo is a model used as a benchmark for evaluating the performance of other models like Orca-3-7B<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"ORCA-3-7B\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Orca-3-7B is a model that has shown significant improvements in various benchmarks, including reading comprehension, math, and format following<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <node id=\"ORCA-2.5-7B\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Orca-2.5-7B is a model used as a baseline for comparison with Orca-3-7B<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <node id=\"AGIEVAL LSAT-RC\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">AGIEval LSAT-RC is a benchmark used to evaluate models on the reading comprehension sections of the LSAT<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <node id=\"AGIEVAL SAT-EN\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">AGIEval SAT-EN is a benchmark used to evaluate models on the English sections of the SAT<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <node id=\"AGIEVAL GAOKAO-ENGLISH\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">AGIEval Gaokao-English is a benchmark used to evaluate models on the English sections of the Gaokao<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <node id=\"AGIEVAL LSAT-LR\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">AGIEval LSAT-LR is a benchmark used to evaluate models on the logical reasoning sections of the LSAT<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <node id=\"DROP\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">DROP is a benchmark used to evaluate models on reading comprehension tasks<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <node id=\"AGIEVAL MATH\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">AGIEval Math is a benchmark used to evaluate models on math problem-solving tasks<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <node id=\"AGIEVAL SAT-MATH\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">AGIEval SAT-Math is a benchmark used to evaluate models on the math sections of the SAT<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <node id=\"BBH MULTISTEP-ARITHMETIC-TWO\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">BBH Multistep-Arithmetic-Two is a benchmark used to evaluate models on multi-step arithmetic problems<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <node id=\"MMLU ABSTRACT ALGEBRA\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">MMLU Abstract Algebra is a benchmark used to evaluate models on abstract algebra tasks<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <node id=\"MMLU COLLEGE MATHEMATICS\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">MMLU College Mathematics is a benchmark used to evaluate models on college-level mathematics tasks<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <node id=\"MMLU HIGH-SCHOOL MATHEMATICS\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">MMLU High-School Mathematics is a benchmark used to evaluate models on high school-level mathematics tasks<\/data>      <data key=\"d2\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/node>    <edge source=\"ORCA-3\" target=\"ORCA-2.5\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Orca-3 shows significant improvements over Orca-2.5 in various benchmarks<\/data>      <data key=\"d6\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"MISTRAL-7B-INSTRUCT\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Orca-3 shows significant improvements over Mistral-7B-Instruct in various benchmarks<\/data>      <data key=\"d6\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"GPT-4\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Orca-3's performance is compared to GPT-4 in various benchmarks<\/data>      <data key=\"d6\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"LSAT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Orca-3's performance on the LSAT reading comprehension sections matches that of GPT-4<\/data>      <data key=\"d6\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"AGIEVAL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Orca-3 is evaluated using the AGIEval benchmark<\/data>      <data key=\"d6\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"GSM8K\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Orca-3 shows significant improvements on the GSM8K math benchmark<\/data>      <data key=\"d6\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"FOFO\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Orca-3 shows significant improvements on the FoFo format-following benchmark<\/data>      <data key=\"d6\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"GEMINI PRO\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Orca-3 surpasses Gemini Pro in format-following capabilities<\/data>      <data key=\"d6\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/edge>    <edge source=\"ORCA-3\" target=\"MMLU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Orca-3 shows significant improvements on the MMLU mathematical benchmarks<\/data>      <data key=\"d6\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/edge>    <edge source=\"MISTRAL-7B-INSTRUCT\" target=\"AGENTINSTRUCT\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">AgentInstruct is used to enhance Mistral-7B-Instruct's proficiency in math<\/data>      <data key=\"d6\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/edge>    <edge source=\"MISTRAL-7B-INSTRUCT\" target=\"ORCA-3-7B\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Orca-3-7B shows significant improvements over Mistral-7B-Instruct in various benchmarks<\/data>      <data key=\"d6\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"ORCA-3-7B\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Orca-3-7B's performance is compared to GPT-4 in various benchmarks<\/data>      <data key=\"d6\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/edge>    <edge source=\"LSAT\" target=\"ORCA-3-7B\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Orca-3-7B's performance on the LSAT reading comprehension sections matches that of GPT-4<\/data>      <data key=\"d6\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/edge>    <edge source=\"AGIEVAL\" target=\"ORCA-3-7B\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Orca-3-7B is evaluated using the AGIEval benchmark<\/data>      <data key=\"d6\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"GENERATIVE TEACHING\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">AgentInstruct is effective for Generative Teaching, enhancing model performance across various datasets<\/data>      <data key=\"d6\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/edge>    <edge source=\"GSM8K\" target=\"ORCA-3-7B\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Orca-3-7B shows significant improvements on the GSM8K math benchmark<\/data>      <data key=\"d6\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/edge>    <edge source=\"FOFO\" target=\"ORCA-3-7B\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Orca-3-7B shows significant improvements on the FoFo format-following benchmark<\/data>      <data key=\"d6\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/edge>    <edge source=\"GEMINI PRO\" target=\"ORCA-3-7B\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Orca-3-7B surpasses Gemini Pro in format-following capabilities<\/data>      <data key=\"d6\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/edge>    <edge source=\"MMLU\" target=\"ORCA-3-7B\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Orca-3-7B shows significant improvements on the MMLU mathematical benchmarks<\/data>      <data key=\"d6\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/edge>    <edge source=\"OPEN DOMAIN QUESTION ANSWERING\" target=\"MULTIPLE-CHOICE QUESTIONS FLOWS\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Both processes are used to generate math problems for evaluating AI models<\/data>      <data key=\"d6\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/edge>    <edge source=\"PHI3\" target=\"GPT-3.5-TURBO\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">The accuracy scores for GPT-3.5-turbo on the GSM8K benchmark are reported in the Phi3 paper<\/data>      <data key=\"d6\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/edge>    <edge source=\"ORCA-3-7B\" target=\"ORCA-2.5-7B\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Orca-3-7B shows significant improvements over Orca-2.5-7B in various benchmarks<\/data>      <data key=\"d6\">bb87f82e6a9f1d4da6480ec78a0e3701<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"8ee9617c145e19fa95f1f9349bfbe69b","chunk":"-4 87.45\nTable 6: Performance of Orca-3-7B model and other open and closed-source baselines on\nFoFo benchmark. The figures (x%, y%) adjacent to the Orca-3 results signify the percentage\nof improvement compared to Orca 2.5 and Mistral-7B-Instruct, respectively. Note: The\nscores for Gemini Pro are taken from the original paper [34]\n4.6 Evaluation: Abstractive Summarization\nSummarization is an important capability for Language Models, with many models achieving\nhigh quality summarization performance, yet struggling with hallucination. We assessed\nsummarization ability using two key metrics: hallucinations and quality. For this purpose,\nwe utilized GPT4 as our evaluator. The prompts utilized in these evaluations can be found\nin Appendix B. We used the following benchmarks for evaluating summarization abilities:\n\u2022ACI-Bench: The Ambient Clinical Intelligence Benchmark (ACI-Bench) [ 32] is a\ndataset designed for benchmarking automatic report generation from doctor-patient\nconversations. The test set comprises 120 data points.\n\u2022InstruSum: A dataset [ 15] for evaluating the generation capabilities LLMs for\ninstruction-controllable summarization. It consists of 100 datapoints.\n\u2022Orca-Sum: A newly created benchmark to evaluate LLMs\u2019 ability to follow summa-\nrization and grounded data transformation instructions. To construct this test set,\nwe sampled data from 45 summarization datasets collected from Hugging Face across\nmultiple domains such as news, conversations, science, health, social, e-mails, code,\netc. for a total of 458 datapoints. We randomly collected, up to 1000 datapoints\nwhich then we carefully deduplicated to avoid overlapping with the training set. We\nthen used GPT-4 to generate a set of 40 prompts for each dataset out of each we\nrandomly sampled one for each selected datapoint. The prompts are dataset-specific\nand focus on summarization, grounding, and data transformation. For instance, a\nprompt may ask the model to generate a TikTok video out of a scientific paper or\na legal contract from a Wikipedia page. This allows us to measure not only the\nquality of the response but also hallucination in a challenging scenario, as the model\nis forced to move between formats and domains.\nThe results are presented in Table 7. With the AgentInstruct approach, we successfully\nachieved a reduction in hallucinations by 31.34%, while attaining a quality level comparable\nto GPT4 (Teacher).\n4.7 Evaluation: RAG\nThe RAG (Retrieval Augmented Generation) skill significantly boosts the capacity of Lan-\nguage Models to generate informed, contextually precise responses, hence upgrading their\noverall performance and usefulness. It is arguably more effective to test the RAG proficiency\nof language models in areas where the models have limited knowledge. For this study, we\nselected MIRAGE[ 35], a benchmark that focuses on answering medical questions by referring\nto information retrieved from a medical corpus. Since the medical domain is not typically a\nprimary focus of the models evaluated in this study, MIRAGE provides an effective platform\nfor assessing their RAG capabilities. Additionally, AgentInstruct RAG data used generic,\nnon medical data seed, enabling us to test how well can the skill (RAG) be applied to new\ndomains.\n19ModelOrca-3\n-7BOrca-2.5\n-7BMistral-\n7B-InstructLLAMA3-\n8B-instructGPT-3.5-\nturboGPT-4\nHallucination Rate (%) - Smaller is better\nAll (micro) 21.09\n(-26.12%,\n-31.34%)28.55 30.72 34.22 21.13 15.07\nOrca-Sum 28.17 36.84 39.61 38.43 28.60 21.66\nInstruSum 9.00 12.00 17.00 25.00 12.00 1.00\nACI-Bench 4.20 10.83 8.30 25.83 1.70 1.70\nQuality Score (1-10) - Higher is better\nAll (micro) 9.14\n(+7.91%,\n+3.28%)8.47 8.85 9.00 8.69 9.08\nOrca-Sum 8.95 8.27 8.61 8.90 8.32 8.61\nInstruSum 9.17 8.30 9.16 9.21 9.27 9.31\nACI-Bench 9.72 9.39 9.48 9.23 9.60 9.70\nTable 7: Hallucination rates and quality scores evaluated by GPT4. The figures (x%, y%)\nadjacent to the Orca-3 results signify the percentage of improvement compared to Orca v2.5\nand Mistral-7B-Instruct, respectively.\nMIRAGE Datasets\nMMLU-\nMedMedQA-\nUSMedMCQA PubMedQA BioASQ Avg.\nGPT-4\n(0613)CoT 89.44 83.97 69.88 39.6 84.3 73.44\nRAG87.24 82.8 66.65 70.6 92.56 79.97\nGPT-3.5-turbo\n(","chunk_id":"8ee9617c145e19fa95f1f9349bfbe69b","document_ids":["c5a70861b9987da7046fe2110eb3616c"],"n_tokens":1200,"entities":[{"name":"ORCA-3-7B","type":"MODEL","description":"Orca-3-7B is a language model evaluated on various benchmarks for summarization and hallucination rates","source_id":"8ee9617c145e19fa95f1f9349bfbe69b"},{"name":"FOFO BENCHMARK","type":"BENCHMARK","description":"FoFo benchmark is used to evaluate the performance of language models, including Orca-3-7B","source_id":"8ee9617c145e19fa95f1f9349bfbe69b"},{"name":"GEMINI PRO","type":"MODEL","description":"Gemini Pro is a model whose scores are referenced from the original paper","source_id":"8ee9617c145e19fa95f1f9349bfbe69b"},{"name":"GPT-4","type":"MODEL","description":"GPT-4 is a language model used as an evaluator for summarization and hallucination detection","source_id":"8ee9617c145e19fa95f1f9349bfbe69b"},{"name":"ACI-BENCH","type":"BENCHMARK","description":"ACI-Bench is a dataset designed for benchmarking automatic report generation from doctor-patient conversations","source_id":"8ee9617c145e19fa95f1f9349bfbe69b"},{"name":"INSTRUSUM","type":"BENCHMARK","description":"InstruSum is a dataset for evaluating the generation capabilities of language models for instruction-controllable summarization","source_id":"8ee9617c145e19fa95f1f9349bfbe69b"},{"name":"ORCA-SUM","type":"BENCHMARK","description":"Orca-Sum is a benchmark created to evaluate language models' ability to follow summarization and grounded data transformation instructions","source_id":"8ee9617c145e19fa95f1f9349bfbe69b"},{"name":"AGENTINSTRUCT","type":"APPROACH","description":"AgentInstruct is an approach that achieved a reduction in hallucinations and maintained quality levels comparable to GPT-4","source_id":"8ee9617c145e19fa95f1f9349bfbe69b"},{"name":"RAG","type":"SKILL","description":"RAG (Retrieval Augmented Generation) is a skill that enhances the capacity of language models to generate informed, contextually precise responses","source_id":"8ee9617c145e19fa95f1f9349bfbe69b"},{"name":"MIRAGE","type":"BENCHMARK","description":"MIRAGE is a benchmark focusing on answering medical questions by referring to information retrieved from a medical corpus","source_id":"8ee9617c145e19fa95f1f9349bfbe69b"},{"name":"MMLU-MED","type":"DATASET","description":"MMLU-Med is a dataset used in the MIRAGE benchmark for evaluating medical question answering","source_id":"8ee9617c145e19fa95f1f9349bfbe69b"},{"name":"MEDQA-US","type":"DATASET","description":"MedQA-US is a dataset used in the MIRAGE benchmark for evaluating medical question answering","source_id":"8ee9617c145e19fa95f1f9349bfbe69b"},{"name":"MEDMCQA","type":"DATASET","description":"MedMCQA is a dataset used in the MIRAGE benchmark for evaluating medical question answering","source_id":"8ee9617c145e19fa95f1f9349bfbe69b"},{"name":"PUBMEDQA","type":"DATASET","description":"PubMedQA is a dataset used in the MIRAGE benchmark for evaluating medical question answering","source_id":"8ee9617c145e19fa95f1f9349bfbe69b"},{"name":"BIOASQ","type":"DATASET","description":"BioASQ is a dataset used in the MIRAGE benchmark for evaluating medical question answering","source_id":"8ee9617c145e19fa95f1f9349bfbe69b"},{"name":"ORCA-2.5-7B","type":"MODEL","description":"Orca-2.5-7B is a language model evaluated on various benchmarks for summarization and hallucination rates","source_id":"8ee9617c145e19fa95f1f9349bfbe69b"},{"name":"MISTRAL-7B-INSTRUCT","type":"MODEL","description":"Mistral-7B-Instruct is a language model evaluated on various benchmarks for summarization and hallucination rates","source_id":"8ee9617c145e19fa95f1f9349bfbe69b"},{"name":"LLAMA3-8B-INSTRUCT","type":"MODEL","description":"LLAMA3-8B-Instruct is a language model evaluated on various benchmarks for summarization and hallucination rates","source_id":"8ee9617c145e19fa95f1f9349bfbe69b"},{"name":"GPT-3.5-TURBO","type":"MODEL","description":"GPT-3.5-turbo is a language model evaluated on various benchmarks for summarization and hallucination rates","source_id":"8ee9617c145e19fa95f1f9349bfbe69b"},{"name":"HUGGING FACE","type":"ORGANIZATION","description":"Hugging Face is an organization that hosts various datasets used for constructing the Orca-Sum benchmark","source_id":"8ee9617c145e19fa95f1f9349bfbe69b"},{"name":"APPENDIX B","type":"DOCUMENT","description":"Appendix B contains the prompts utilized in the evaluations for summarization abilities","source_id":"8ee9617c145e19fa95f1f9349bfbe69b"},{"name":"CO-T","type":"SKILL","description":"CoT (Chain of Thought) is a skill used by GPT-4 for medical question answering in the MIRAGE benchmark","source_id":"8ee9617c145e19fa95f1f9349bfbe69b"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"ORCA-3-7B\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Orca-3-7B is a language model evaluated on various benchmarks for summarization and hallucination rates<\/data>      <data key=\"d2\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/node>    <node id=\"FOFO BENCHMARK\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">FoFo benchmark is used to evaluate the performance of language models, including Orca-3-7B<\/data>      <data key=\"d2\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/node>    <node id=\"GEMINI PRO\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Gemini Pro is a model whose scores are referenced from the original paper<\/data>      <data key=\"d2\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4 is a language model used as an evaluator for summarization and hallucination detection<\/data>      <data key=\"d2\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/node>    <node id=\"ACI-BENCH\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">ACI-Bench is a dataset designed for benchmarking automatic report generation from doctor-patient conversations<\/data>      <data key=\"d2\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/node>    <node id=\"INSTRUSUM\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">InstruSum is a dataset for evaluating the generation capabilities of language models for instruction-controllable summarization<\/data>      <data key=\"d2\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/node>    <node id=\"ORCA-SUM\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">Orca-Sum is a benchmark created to evaluate language models' ability to follow summarization and grounded data transformation instructions<\/data>      <data key=\"d2\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/node>    <node id=\"AGENTINSTRUCT\">      <data key=\"d0\">APPROACH<\/data>      <data key=\"d1\">AgentInstruct is an approach that achieved a reduction in hallucinations and maintained quality levels comparable to GPT-4<\/data>      <data key=\"d2\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/node>    <node id=\"RAG\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">RAG (Retrieval Augmented Generation) is a skill that enhances the capacity of language models to generate informed, contextually precise responses<\/data>      <data key=\"d2\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/node>    <node id=\"MIRAGE\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">MIRAGE is a benchmark focusing on answering medical questions by referring to information retrieved from a medical corpus<\/data>      <data key=\"d2\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/node>    <node id=\"MMLU-MED\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">MMLU-Med is a dataset used in the MIRAGE benchmark for evaluating medical question answering<\/data>      <data key=\"d2\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/node>    <node id=\"MEDQA-US\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">MedQA-US is a dataset used in the MIRAGE benchmark for evaluating medical question answering<\/data>      <data key=\"d2\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/node>    <node id=\"MEDMCQA\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">MedMCQA is a dataset used in the MIRAGE benchmark for evaluating medical question answering<\/data>      <data key=\"d2\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/node>    <node id=\"PUBMEDQA\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">PubMedQA is a dataset used in the MIRAGE benchmark for evaluating medical question answering<\/data>      <data key=\"d2\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/node>    <node id=\"BIOASQ\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">BioASQ is a dataset used in the MIRAGE benchmark for evaluating medical question answering<\/data>      <data key=\"d2\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/node>    <node id=\"ORCA-2.5-7B\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Orca-2.5-7B is a language model evaluated on various benchmarks for summarization and hallucination rates<\/data>      <data key=\"d2\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/node>    <node id=\"MISTRAL-7B-INSTRUCT\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Mistral-7B-Instruct is a language model evaluated on various benchmarks for summarization and hallucination rates<\/data>      <data key=\"d2\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/node>    <node id=\"LLAMA3-8B-INSTRUCT\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">LLAMA3-8B-Instruct is a language model evaluated on various benchmarks for summarization and hallucination rates<\/data>      <data key=\"d2\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/node>    <node id=\"GPT-3.5-TURBO\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-3.5-turbo is a language model evaluated on various benchmarks for summarization and hallucination rates<\/data>      <data key=\"d2\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/node>    <node id=\"HUGGING FACE\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Hugging Face is an organization that hosts various datasets used for constructing the Orca-Sum benchmark<\/data>      <data key=\"d2\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/node>    <node id=\"APPENDIX B\">      <data key=\"d0\">DOCUMENT<\/data>      <data key=\"d1\">Appendix B contains the prompts utilized in the evaluations for summarization abilities<\/data>      <data key=\"d2\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/node>    <node id=\"CO-T\">      <data key=\"d0\">SKILL<\/data>      <data key=\"d1\">CoT (Chain of Thought) is a skill used by GPT-4 for medical question answering in the MIRAGE benchmark<\/data>      <data key=\"d2\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/node>    <edge source=\"ORCA-3-7B\" target=\"FOFO BENCHMARK\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Orca-3-7B is evaluated on the FoFo benchmark<\/data>      <data key=\"d5\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/edge>    <edge source=\"ORCA-3-7B\" target=\"GPT-4\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">GPT-4 is used to evaluate the summarization and hallucination rates of Orca-3-7B<\/data>      <data key=\"d5\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/edge>    <edge source=\"ORCA-3-7B\" target=\"ACI-BENCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Orca-3-7B is evaluated on the ACI-Bench for summarization abilities<\/data>      <data key=\"d5\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/edge>    <edge source=\"ORCA-3-7B\" target=\"INSTRUSUM\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Orca-3-7B is evaluated on the InstruSum for summarization abilities<\/data>      <data key=\"d5\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/edge>    <edge source=\"ORCA-3-7B\" target=\"ORCA-SUM\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Orca-3-7B is evaluated on the Orca-Sum for summarization abilities<\/data>      <data key=\"d5\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/edge>    <edge source=\"ORCA-3-7B\" target=\"AGENTINSTRUCT\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">AgentInstruct approach is used to reduce hallucinations in Orca-3-7B<\/data>      <data key=\"d5\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/edge>    <edge source=\"ORCA-3-7B\" target=\"RAG\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Orca-3-7B's RAG skill is evaluated to generate informed, contextually precise responses<\/data>      <data key=\"d5\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/edge>    <edge source=\"ORCA-3-7B\" target=\"ORCA-2.5-7B\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Orca-3-7B's performance is compared to Orca-2.5-7B in various benchmarks<\/data>      <data key=\"d5\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/edge>    <edge source=\"ORCA-3-7B\" target=\"MISTRAL-7B-INSTRUCT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Orca-3-7B's performance is compared to Mistral-7B-Instruct in various benchmarks<\/data>      <data key=\"d5\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/edge>    <edge source=\"ORCA-3-7B\" target=\"LLAMA3-8B-INSTRUCT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Orca-3-7B's performance is compared to LLAMA3-8B-Instruct in various benchmarks<\/data>      <data key=\"d5\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/edge>    <edge source=\"ORCA-3-7B\" target=\"GPT-3.5-TURBO\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Orca-3-7B's performance is compared to GPT-3.5-turbo in various benchmarks<\/data>      <data key=\"d5\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"APPENDIX B\">      <data key=\"d3\">6.0<\/data>      <data key=\"d4\">Appendix B contains the prompts used by GPT-4 for evaluating summarization abilities<\/data>      <data key=\"d5\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"CO-T\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">GPT-4 uses the CoT skill for medical question answering in the MIRAGE benchmark<\/data>      <data key=\"d5\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/edge>    <edge source=\"ORCA-SUM\" target=\"HUGGING FACE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Orca-Sum benchmark uses datasets collected from Hugging Face<\/data>      <data key=\"d5\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/edge>    <edge source=\"RAG\" target=\"MIRAGE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">MIRAGE benchmark is used to evaluate the RAG skill of language models<\/data>      <data key=\"d5\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/edge>    <edge source=\"MIRAGE\" target=\"MMLU-MED\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">MMLU-Med is a dataset used in the MIRAGE benchmark<\/data>      <data key=\"d5\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/edge>    <edge source=\"MIRAGE\" target=\"MEDQA-US\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">MedQA-US is a dataset used in the MIRAGE benchmark<\/data>      <data key=\"d5\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/edge>    <edge source=\"MIRAGE\" target=\"MEDMCQA\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">MedMCQA is a dataset used in the MIRAGE benchmark<\/data>      <data key=\"d5\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/edge>    <edge source=\"MIRAGE\" target=\"PUBMEDQA\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">PubMedQA is a dataset used in the MIRAGE benchmark<\/data>      <data key=\"d5\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/edge>    <edge source=\"MIRAGE\" target=\"BIOASQ\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">BioASQ is a dataset used in the MIRAGE benchmark<\/data>      <data key=\"d5\">8ee9617c145e19fa95f1f9349bfbe69b<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"ab04427ae0415a1c812a35cf8d3ee1a2","chunk":" respectively.\nMIRAGE Datasets\nMMLU-\nMedMedQA-\nUSMedMCQA PubMedQA BioASQ Avg.\nGPT-4\n(0613)CoT 89.44 83.97 69.88 39.6 84.3 73.44\nRAG87.24 82.8 66.65 70.6 92.56 79.97\nGPT-3.5-turbo\n(0613)CoT 72.91 65.04 55.25 36 74.27 60.69\nRAG75.48 66.61 58.04 67.4 90.29 71.57\nOrca-2.5-7BCoT 63.91 51.37 43.65 29.6 71.04 51.92\nRAG53.72 37.08 39.23 19 69.09 43.62\nMistral-7B-\nInstruct-v0.1CoT 50.96 42.73 34.9 27.6 47.57 40.75\nRAG54.64 35.35 43.41 30.2 68.77 46.47\nOrca-3-7BCoT 71.35 55.38 51.33 27.8 75.24 56.22\nRAG71.17\n(+30.25%)51.85\n(+46.68%)57.95\n(+33.49%)58.2\n(+92.71%)82.2\n(+19.52%)64.27\n(+38.30%)\nTable 8: Evaluation results of RAG skill on MIRAGE. The figures (x%) adjacent to the Orca-\n3 results signify the percentage of improvement compared to Mistral-7B-Instruct respectively.\nCoT shows the performance of the same models when answering directly without using RAG\nWe use the same retrieval mechanism across all models on MIRAGE [ 35], using MedRAG,\nthe corpus accompanying the benchmark. This involves using the same retrieval function\nand the same number of retrieved documents for all models. As all models are presented\nwith the same set of retrieved documents, the comparison accurately reflects the ability of\ndifferent models to incorporate retrieved results into their responses.\nTable 8 shows the results of all models on MIRAGE with and without leveraging RAG1.\nOverall, we observe that\n\u2022Models with a deeper understanding of the task (CoT scores) tend to have higher\nRAG scores. If we restrict our focus to only RAG performance, applying post-\ntraining, we\u2019ve managed to enhance Mistral\u2019s performance by an average of 38.30%.\n1Results of GPT-4 and GPT-3.5-Turbo are from [35].\n20\u2022Of the five datasets in MIRAGE, PubMedQA arguably offers the most effective\ntestbed for assessing models ability to do RAG. In PubMedQA, all models have\nlimited prior knowledge, and the retrieved context provides essential information, as\ndemonstrated by GPT4\u2019s performance leap. All Mistral fine-tunes exhibit similar\nperformance, but only Orca-3 (Mistral trained with AgentInstruct RAG flow data)\nshows a substantial improvement, resulting in a relative improvement of 92.71% over\nMistral-Instruct.\n5 Limitations\nAgentInstruct reduces human expertise required for data generation significantly and enables\ncreating of high-quality synthetic data at scale. However, this is till an early step in this\ndirection and could suffer from many limitations associated with synthetic data generation,\nincluding but not limited to:\nExtensibility: Creating the agentic flows for different skills depends on human effort for\nthe construction of the flows. Future work should consider how to automate the construction\nof the agentic flow from the user specification.\nAccuracy: Synthetic data may not perfectly replicate the complexity and nuances of real-\nworld data, leading to potential inaccuracies. Additional work is needed to better assess the\nquality of the data.\nCost: Generating synthetic data with multiple agents using LLMs and tools can be resource-\nintensive.\nBias:If the original seed data used to generate synthetic data contains biases, these biases\ncan be reflected and even amplified in the synthetic data.\nValidation : It can be difficult to validate synthetic data to ensure it accurately represents\nthe desired scenarios.\nDependency on Seed Data : The quality of synthetic data is dependent on the quality of\nthe real data used as seeds. Poor quality input data could result in poor quality synthetic\ndata.\nOrca-3 is fine-tuned with the AgentInstruct data based on the Mistral model family, and\nretains many of its limitations, as well as the common limitations of other large language\nmodels and limitations originating from its training process, including:\nData Biases: Large language models, trained on extensive data, can inadvertently carry\nbiases present in the source data. Consequently, the models may generate outputs that could\nbe potentially biased or unfair.\nLack of Transparency: Due to the complexity and size, large language models can act\nas \u201cblack boxes\u201d, making it difficult to comprehend the rationale behind specific outputs or\ndecisions. We recommend reviewing transparency notes from Azure for more information2.\nContent Harms: There are various types of content harms that large language models\ncan cause. It is important to be aware of them when using these models, and to take\nactions to prevent them. It is recommended to leverage various content moderation services\nprovided by different companies and institutions. On an important note, we hope for better\nregulations and standards from","chunk_id":"ab04427ae0415a1c812a35cf8d3ee1a2","document_ids":["c5a70861b9987da7046fe2110eb3616c"],"n_tokens":1200,"entities":[{"name":"MIRAGE","type":"DATASET","description":"MIRAGE is a collection of datasets used for evaluating the performance of various models on different tasks","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"MMLU","type":"DATASET","description":"MMLU is one of the datasets included in the MIRAGE collection","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"MEDMEDQA","type":"DATASET","description":"MedMedQA is one of the datasets included in the MIRAGE collection","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"USMEDMCQA","type":"DATASET","description":"USMedMCQA is one of the datasets included in the MIRAGE collection","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"PUBMEDQA","type":"DATASET","description":"PubMedQA is one of the datasets included in the MIRAGE collection and is considered an effective testbed for assessing models' ability to do RAG","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"BIOASQ","type":"DATASET","description":"BioASQ is one of the datasets included in the MIRAGE collection","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"GPT-4","type":"MODEL","description":"GPT-4 is a version of OpenAI's language model used in the evaluation of MIRAGE datasets","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"GPT-3.5-TURBO","type":"MODEL","description":"GPT-3.5-turbo is a version of OpenAI's language model used in the evaluation of MIRAGE datasets","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"ORCA-2.5-7B","type":"MODEL","description":"Orca-2.5-7B is a model used in the evaluation of MIRAGE datasets","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"MISTRAL-7B-INSTRUCT-V0.1","type":"MODEL","description":"Mistral-7B-Instruct-v0.1 is a model used in the evaluation of MIRAGE datasets","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"ORCA-3-7B","type":"MODEL","description":"Orca-3-7B is a model fine-tuned with AgentInstruct data based on the Mistral model family, used in the evaluation of MIRAGE datasets","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"RAG","type":"TECHNIQUE","description":"RAG (Retrieval-Augmented Generation) is a technique used to enhance model performance by incorporating retrieved documents into their responses","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"MEDRAG","type":"TOOL","description":"MedRAG is the retrieval mechanism used across all models on MIRAGE, involving the same retrieval function and number of retrieved documents","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2","entity_type":"TOOL"},{"name":"AGENTINSTRUCT","type":"TECHNIQUE","description":"AgentInstruct is a technique that reduces human expertise required for data generation and enables the creation of high-quality synthetic data at scale","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2","entity_type":"TECHNIQUE"},{"name":"AZURE","type":"ORGANIZATION","description":"Azure is recommended for reviewing transparency notes related to large language models","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2","entity_type":"ORGANIZATION"},{"name":"TABLE 8","type":"DOCUMENT SECTION","description":"Table 8 shows the evaluation results of RAG skill on MIRAGE datasets with and without leveraging RAG","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"COT","type":"TECHNIQUE","description":"CoT (Chain of Thought) is a technique showing the performance of models when answering directly without using RAG","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"MISTRAL","type":"MODEL FAMILY","description":"Mistral is a model family used as a base for fine-tuning with AgentInstruct data","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"AGENTINSTRUCT RAG FLOW","type":"TECHNIQUE","description":"AgentInstruct RAG flow is a technique used to train Orca-3, resulting in substantial performance improvement","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"LIMITATIONS","type":"DOCUMENT SECTION","description":"The section discussing the limitations of AgentInstruct and synthetic data generation","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"DATA BIASES","type":"ISSUE","description":"Data Biases refer to the biases present in the source data that can be carried over to large language models","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"LACK OF TRANSPARENCY","type":"ISSUE","description":"Lack of Transparency refers to the difficulty in understanding the rationale behind specific outputs or decisions of large language models","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"CONTENT HARMS","type":"ISSUE","description":"Content Harms refer to various types of harmful content that large language models can generate","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"VALIDATION","type":"ISSUE","description":"Validation refers to the difficulty in ensuring synthetic data accurately represents the desired scenarios","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"DEPENDENCY ON SEED DATA","type":"ISSUE","description":"Dependency on Seed Data refers to the quality of synthetic data being dependent on the quality of the real data used as seeds","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"EXTENSIBILITY","type":"ISSUE","description":"Extensibility refers to the human effort required to create agentic flows for different skills","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"ACCURACY","type":"ISSUE","description":"Accuracy refers to the potential inaccuracies in synthetic data due to its inability to perfectly replicate real-world data","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"COST","type":"ISSUE","description":"Cost refers to the resource-intensive nature of generating synthetic data with multiple agents using LLMs and tools","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"},{"name":"BIAS","type":"ISSUE","description":"Bias refers to the potential for synthetic data to reflect and amplify biases present in the original seed data","source_id":"ab04427ae0415a1c812a35cf8d3ee1a2"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"MIRAGE\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">MIRAGE is a collection of datasets used for evaluating the performance of various models on different tasks<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"MMLU\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">MMLU is one of the datasets included in the MIRAGE collection<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"MEDMEDQA\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">MedMedQA is one of the datasets included in the MIRAGE collection<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"USMEDMCQA\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">USMedMCQA is one of the datasets included in the MIRAGE collection<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"PUBMEDQA\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">PubMedQA is one of the datasets included in the MIRAGE collection and is considered an effective testbed for assessing models' ability to do RAG<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"BIOASQ\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">BioASQ is one of the datasets included in the MIRAGE collection<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4 is a version of OpenAI's language model used in the evaluation of MIRAGE datasets<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"GPT-3.5-TURBO\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-3.5-turbo is a version of OpenAI's language model used in the evaluation of MIRAGE datasets<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"ORCA-2.5-7B\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Orca-2.5-7B is a model used in the evaluation of MIRAGE datasets<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"MISTRAL-7B-INSTRUCT-V0.1\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Mistral-7B-Instruct-v0.1 is a model used in the evaluation of MIRAGE datasets<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"ORCA-3-7B\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Orca-3-7B is a model fine-tuned with AgentInstruct data based on the Mistral model family, used in the evaluation of MIRAGE datasets<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"RAG\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">RAG (Retrieval-Augmented Generation) is a technique used to enhance model performance by incorporating retrieved documents into their responses<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"MEDRAG\">      <data key=\"d0\">TOOL<\/data>      <data key=\"d1\">MedRAG is the retrieval mechanism used across all models on MIRAGE, involving the same retrieval function and number of retrieved documents<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>      <data key=\"d3\">TOOL<\/data>    <\/node>    <node id=\"AGENTINSTRUCT\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">AgentInstruct is a technique that reduces human expertise required for data generation and enables the creation of high-quality synthetic data at scale<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>      <data key=\"d3\">TECHNIQUE<\/data>    <\/node>    <node id=\"AZURE\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Azure is recommended for reviewing transparency notes related to large language models<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>      <data key=\"d3\">ORGANIZATION<\/data>    <\/node>    <node id=\"TABLE 8\">      <data key=\"d0\">DOCUMENT SECTION<\/data>      <data key=\"d1\">Table 8 shows the evaluation results of RAG skill on MIRAGE datasets with and without leveraging RAG<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"COT\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">CoT (Chain of Thought) is a technique showing the performance of models when answering directly without using RAG<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"MISTRAL\">      <data key=\"d0\">MODEL FAMILY<\/data>      <data key=\"d1\">Mistral is a model family used as a base for fine-tuning with AgentInstruct data<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"AGENTINSTRUCT RAG FLOW\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">AgentInstruct RAG flow is a technique used to train Orca-3, resulting in substantial performance improvement<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"LIMITATIONS\">      <data key=\"d0\">DOCUMENT SECTION<\/data>      <data key=\"d1\">The section discussing the limitations of AgentInstruct and synthetic data generation<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"DATA BIASES\">      <data key=\"d0\">ISSUE<\/data>      <data key=\"d1\">Data Biases refer to the biases present in the source data that can be carried over to large language models<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"LACK OF TRANSPARENCY\">      <data key=\"d0\">ISSUE<\/data>      <data key=\"d1\">Lack of Transparency refers to the difficulty in understanding the rationale behind specific outputs or decisions of large language models<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"CONTENT HARMS\">      <data key=\"d0\">ISSUE<\/data>      <data key=\"d1\">Content Harms refer to various types of harmful content that large language models can generate<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"VALIDATION\">      <data key=\"d0\">ISSUE<\/data>      <data key=\"d1\">Validation refers to the difficulty in ensuring synthetic data accurately represents the desired scenarios<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"DEPENDENCY ON SEED DATA\">      <data key=\"d0\">ISSUE<\/data>      <data key=\"d1\">Dependency on Seed Data refers to the quality of synthetic data being dependent on the quality of the real data used as seeds<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"EXTENSIBILITY\">      <data key=\"d0\">ISSUE<\/data>      <data key=\"d1\">Extensibility refers to the human effort required to create agentic flows for different skills<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"ACCURACY\">      <data key=\"d0\">ISSUE<\/data>      <data key=\"d1\">Accuracy refers to the potential inaccuracies in synthetic data due to its inability to perfectly replicate real-world data<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"COST\">      <data key=\"d0\">ISSUE<\/data>      <data key=\"d1\">Cost refers to the resource-intensive nature of generating synthetic data with multiple agents using LLMs and tools<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <node id=\"BIAS\">      <data key=\"d0\">ISSUE<\/data>      <data key=\"d1\">Bias refers to the potential for synthetic data to reflect and amplify biases present in the original seed data<\/data>      <data key=\"d2\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/node>    <edge source=\"MIRAGE\" target=\"MMLU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">MMLU is one of the datasets included in the MIRAGE collection<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"MIRAGE\" target=\"MEDMEDQA\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">MedMedQA is one of the datasets included in the MIRAGE collection<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"MIRAGE\" target=\"USMEDMCQA\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">USMedMCQA is one of the datasets included in the MIRAGE collection<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"MIRAGE\" target=\"PUBMEDQA\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">PubMedQA is one of the datasets included in the MIRAGE collection and is considered an effective testbed for assessing models' ability to do RAG<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"MIRAGE\" target=\"BIOASQ\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">BioASQ is one of the datasets included in the MIRAGE collection<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"MIRAGE\" target=\"GPT-4\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">GPT-4 is used in the evaluation of MIRAGE datasets<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"MIRAGE\" target=\"GPT-3.5-TURBO\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">GPT-3.5-turbo is used in the evaluation of MIRAGE datasets<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"MIRAGE\" target=\"ORCA-2.5-7B\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Orca-2.5-7B is used in the evaluation of MIRAGE datasets<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"MIRAGE\" target=\"MISTRAL-7B-INSTRUCT-V0.1\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Mistral-7B-Instruct-v0.1 is used in the evaluation of MIRAGE datasets<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"MIRAGE\" target=\"ORCA-3-7B\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Orca-3-7B is used in the evaluation of MIRAGE datasets<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"MIRAGE\" target=\"RAG\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">RAG is used to enhance model performance on MIRAGE datasets<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"MIRAGE\" target=\"MEDRAG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">MedRAG is the retrieval mechanism used across all models on MIRAGE<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"MIRAGE\" target=\"TABLE 8\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Table 8 shows the evaluation results of RAG skill on MIRAGE datasets<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"MIRAGE\" target=\"COT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">CoT shows the performance of models on MIRAGE datasets when answering directly without using RAG<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"AZURE\">      <data key=\"d4\">14.0<\/data>      <data key=\"d5\">Azure is recommended for reviewing transparency notes related to GPT-4<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"GPT-3.5-TURBO\" target=\"AZURE\">      <data key=\"d4\">2.0<\/data>      <data key=\"d5\">Azure is recommended for reviewing transparency notes related to GPT-3.5-turbo<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"ORCA-3-7B\" target=\"AGENTINSTRUCT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Orca-3-7B is fine-tuned with AgentInstruct data based on the Mistral model family<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"ORCA-3-7B\" target=\"MISTRAL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Orca-3-7B is fine-tuned with AgentInstruct data based on the Mistral model family<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"ORCA-3-7B\" target=\"AGENTINSTRUCT RAG FLOW\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Orca-3-7B shows substantial improvement due to training with AgentInstruct RAG flow<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"ORCA-3-7B\" target=\"DATA BIASES\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Orca-3-7B retains many limitations, including data biases<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"ORCA-3-7B\" target=\"LACK OF TRANSPARENCY\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Orca-3-7B retains many limitations, including lack of transparency<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"ORCA-3-7B\" target=\"CONTENT HARMS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Orca-3-7B retains many limitations, including content harms<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"LIMITATIONS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">The Limitations section discusses the limitations of AgentInstruct and synthetic data generation<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"VALIDATION\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Validation is a limitation of AgentInstruct and synthetic data generation<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"DEPENDENCY ON SEED DATA\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Dependency on Seed Data is a limitation of AgentInstruct and synthetic data generation<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"EXTENSIBILITY\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Extensibility is a limitation of AgentInstruct and synthetic data generation<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"ACCURACY\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Accuracy is a limitation of AgentInstruct and synthetic data generation<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"COST\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Cost is a limitation of AgentInstruct and synthetic data generation<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>    <edge source=\"AGENTINSTRUCT\" target=\"BIAS\">      <data key=\"d4\">7.0<\/data>      <data key=\"d5\">Bias is a limitation of AgentInstruct and synthetic data generation<\/data>      <data key=\"d6\">ab04427ae0415a1c812a35cf8d3ee1a2<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"dd9a46950237e49ef9b1c7ef08e08d42","chunk":" making it difficult to comprehend the rationale behind specific outputs or\ndecisions. We recommend reviewing transparency notes from Azure for more information2.\nContent Harms: There are various types of content harms that large language models\ncan cause. It is important to be aware of them when using these models, and to take\nactions to prevent them. It is recommended to leverage various content moderation services\nprovided by different companies and institutions. On an important note, we hope for better\nregulations and standards from government and technology leaders around content harms\nfor AI technologies in future. We value and acknowledge the important role that research\nand open source community can play in this direction.\nHallucination: It is important to be aware and cautious not to entirely rely on a given\nlanguage model for critical decisions or information that might have deep impact as it is\nnot obvious how to prevent these models from fabricating content. Moreover, it is not clear\nwhether small models may be more susceptible to hallucination in ungrounded generation\nuse cases due to their smaller sizes and hence reduced memorization capacities. This is an\n2https:\/\/learn.microsoft.com\/en-us\/legal\/cognitive-services\/openai\/\ntransparency-note\n21active research topic and we hope there will be more rigorous measurement, understanding\nand mitigations around this topic.\nPotential for Misuse: Without suitable safeguards, there is a risk that these models could\nbe maliciously used for generating disinformation or harmful content.\nData Distribution: Orca-3\u2019s performance is likely to correlate strongly with the distribution\nof the tuning data. This correlation might limit its accuracy in areas underrepresented in\nthe training dataset.\n6 Conclusions\nThe AgentInstruct approach to Generative Teaching offers a promising solution to the\nchallenge of generating large amount of diverse and high-quality data for model post-training.\nThis method stands out by using agentic flows for synthetic data generation, thus addressing\nkey concerns associated with the use of synthetic data in model training, such as the lack of\ndiversity and the need for intensive human curation and intervention during the data creation\nprocess. By leveraging an agentic framework, AgentInstruct can generate tailored datasets\ncomprising both prompts and responses from unstructured data sources, facilitating the\npost-training of models and teaching them variety of skills. The efficacy of this approach is\nexemplifiedbythesubstantialimprovementobserved intheOrca-3 model, which, post-trained\nwith a 25M pair dataset generated by AgentInstruct, showcased a notable performance gain\nacross multiple benchmarks. We believe using agentic flows for creating synthetic data can\nshow significant value for all stages of model training, including pre-training, post-training\nand domain\/task specialization. The ability to use unstructured content to generate diverse\nand high-quality instruction data given any specifications could pave the way for creating\n(semi) automated pipelines using synthetic data for model customization (using domain\nspecific content as seeds) and continual improvement (generating higher quality data than\nthe base model with agentic flows).\nReferences\n[1]Marah Abdin, Sam Ade Jacobs, Ammar Ahmad Awan, Jyoti Aneja, Ahmed Awadallah,\nHany Awadalla, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Jianmin Bao, Harkirat Behl,\nAlon Benhaim, Misha Bilenko, Johan Bjorck, S\u00e9bastien Bubeck, Qin Cai, Martin Cai, Caio\nC\u00e9sar Teodoro Mendes, Weizhu Chen, Vishrav Chaudhary, Dong Chen, Dongdong Chen,\nYen-Chun Chen, Yi-Ling Chen, Parul Chopra, Xiyang Dai, Allie Del Giorno, Gustavo de Rosa,\nMatthew Dixon, Ronen Eldan, Victor Fragoso, Dan Iter, Mei Gao, Min Gao, Jianfeng Gao,\nAmit Garg, Abhishek Goswami, Suriya Gunasekar, Emman Haider, Junheng Hao, Russell J.\nHewett, Jamie Huynh, Mojan Javaheripi, Xin Jin, Piero Kauffmann, Nikos Karampatziakis,\nDongwoo Kim, Mahoud Khademi, Lev Kurilenko, James R. Lee, Yin Tat Lee, Yuanzhi Li,\nYunsheng Li, Chen Liang, Lars Liden, Ce Liu, Mengchen Liu, Weishung Liu, Eric Lin, Zeqi\nLin, Chong Luo, Piyush Madan, Matt Mazzola, Arindam Mitra, Hardik Modi, Anh Nguyen,\nBrandon Norick, Barun Patra, Daniel Perez-Becker, Thomas Portet, Reid Pryzant, Heyang Qin,\nMarko Radmilac, Corby Rosset, Sambudha Roy, Olatunji Ruwase, Olli Saarikivi, Amin Saied,\nAdil Salim, Michael Santacroce, Shital Shah, Ning Shang, Hiteshi Sharma, Swadheen Shukla,\nXia Song, Masahiro Tanaka, Andrea Tupini, Xin Wang, Lijuan Wang, Chunyu Wang, Yu Wang,\nRachel Ward, Guanhua Wang, Philipp Witte, Haiping Wu, Michael Wyatt, Bin Xiao, Can\nXu, Jiahang Xu, Weijian Xu, Sonali Yadav, Fan Yang, Jianwei Yang, Ziyi Yang, Yifan Yang,\nDonghan Yu, Lu Yuan, Chengruidong Zhang, Cyril Zhang, Jianwen Zhang, Li Lyna Zhang,\nYi Zhang, Yue Zhang, Yunan Zhang, and Xiren Zhou. Phi-3 technical report","chunk_id":"dd9a46950237e49ef9b1c7ef08e08d42","document_ids":["c5a70861b9987da7046fe2110eb3616c"],"n_tokens":1200,"entities":[{"name":"AZURE","type":"COMPANY\/SERVICE","description":"Azure is a cloud computing service provided by Microsoft, mentioned in the context of transparency notes","source_id":"dd9a46950237e49ef9b1c7ef08e08d42"},{"name":"TRANSPARENCY NOTES","type":"DOCUMENTATION","description":"Transparency notes from Azure provide information about the rationale behind specific outputs or decisions","source_id":"dd9a46950237e49ef9b1c7ef08e08d42"},{"name":"CONTENT HARMS","type":"CONCEPT\/ISSUE","description":"Content harms refer to various types of harmful content that large language models can generate, necessitating awareness and preventive actions","source_id":"dd9a46950237e49ef9b1c7ef08e08d42"},{"name":"CONTENT MODERATION SERVICES","type":"SERVICE","description":"Services provided by different companies and institutions to moderate and prevent harmful content generated by language models","source_id":"dd9a46950237e49ef9b1c7ef08e08d42"},{"name":"GOVERNMENT AND TECHNOLOGY LEADERS","type":"GROUP","description":"Entities hoped to provide better regulations and standards around content harms for AI technologies in the future","source_id":"dd9a46950237e49ef9b1c7ef08e08d42"},{"name":"RESEARCH AND OPEN SOURCE COMMUNITY","type":"GROUP","description":"Communities valued for their role in addressing content harms and improving AI technologies","source_id":"dd9a46950237e49ef9b1c7ef08e08d42"},{"name":"HALLUCINATION","type":"CONCEPT\/ISSUE","description":"The phenomenon where language models fabricate content, making it unreliable for critical decisions or information","source_id":"dd9a46950237e49ef9b1c7ef08e08d42"},{"name":"UNSTRUCTURED DATA SOURCES","type":"DATA TYPE","description":"Sources of data that are not organized in a pre-defined manner, used by AgentInstruct for generating synthetic data","source_id":"dd9a46950237e49ef9b1c7ef08e08d42"},{"name":"AGENTINSTRUCT","type":"METHOD\/APPROACH","description":"A method for generating large amounts of diverse and high-quality data for model post-training using agentic flows\nAgentInstruct is a method for generating large amounts of diverse and high-quality data for model post-training using agentic flows","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"METHOD\/APPROACH"},{"name":"ORCA-3","type":"MODEL","description":"Orca-3 is a model that showed substantial improvement after being post-trained with a dataset generated by AgentInstruct\nA model that showed substantial improvement after being post-trained with a dataset generated by AgentInstruct","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"MODEL"},{"name":"25M PAIR DATASET","type":"DATASET","description":"A dataset comprising 25 million pairs of prompts and responses generated by AgentInstruct for post-training the Orca-3 model","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"DATASET"},{"name":"SYNTHETIC DATA","type":"DATA TYPE","description":"Data generated artificially, used in model training to address concerns like lack of diversity and need for human curation\nSynthetic data is data generated artificially, used in model training to address concerns like lack of diversity and need for human curation","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"DATA TYPE"},{"name":"AGENTIC FLOWS","type":"TECHNIQUE","description":"A technique used by AgentInstruct for synthetic data generation, facilitating model training and customization\nAgentic flows are a technique used by AgentInstruct for synthetic data generation, facilitating model training and customization","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"TECHNIQUE"},{"name":"MODEL TRAINING","type":"PROCESS","description":"The process of training machine learning models, which can benefit from synthetic data generated by AgentInstruct\nModel training is the process of training machine learning models, which can benefit from synthetic data generated by AgentInstruct","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PROCESS"},{"name":"DOMAIN\/TASK SPECIALIZATION","type":"PROCESS","description":"The process of customizing models for specific domains or tasks using synthetic data\nDomain\/task specialization is the process of customizing models for specific domains or tasks using synthetic data","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PROCESS"},{"name":"MARAH ABDIN","type":"PERSON","description":"An author of the Phi-3 technical report\nMarah Abdin is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"SAM ADE JACOBS","type":"PERSON","description":"An author of the Phi-3 technical report\nSam Ade Jacobs is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"AMMAR AHMAD AWAN","type":"PERSON","description":"An author of the Phi-3 technical report\nAmmar Ahmad Awan is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"JYOTI ANEJA","type":"PERSON","description":"An author of the Phi-3 technical report\nJyoti Aneja is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"AHMED AWADALLAH","type":"PERSON","description":"An author of the Phi-3 technical report\nAhmed Awadallah is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"HANY AWADALLA","type":"PERSON","description":"An author of the Phi-3 technical report\nHany Awadalla is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"NGUYEN BACH","type":"PERSON","description":"An author of the Phi-3 technical report\nNguyen Bach is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"AMIT BAHREE","type":"PERSON","description":"An author of the Phi-3 technical report\nAmit Bahree is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"ARASH BAKHTIARI","type":"PERSON","description":"An author of the Phi-3 technical report\nArash Bakhtiari is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"JIANMIN BAO","type":"PERSON","description":"An author of the Phi-3 technical report\nJianmin Bao is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"HARKIRAT BEHL","type":"PERSON","description":"An author of the Phi-3 technical report\nHarkirat Behl is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"ALON BENHAIM","type":"PERSON","description":"An author of the Phi-3 technical report\nAlon Benhaim is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"MISHA BILENKO","type":"PERSON","description":"An author of the Phi-3 technical report\nMisha Bilenko is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"JOHAN BJORCK","type":"PERSON","description":"An author of the Phi-3 technical report\nJohan Bjorck is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"S\u00c9BASTIEN BUBECK","type":"PERSON","description":"An author of the Phi-3 technical report\nS\u00e9bastien Bubeck is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"QIN CAI","type":"PERSON","description":"An author of the Phi-3 technical report\nQin Cai is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"MARTIN CAI","type":"PERSON","description":"An author of the Phi-3 technical report\nMartin Cai is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"CAIO C\u00c9SAR TEODORO MENDES","type":"PERSON","description":"An author of the Phi-3 technical report\nCaio C\u00e9sar Teodoro Mendes is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"WEIZHU CHEN","type":"PERSON","description":"An author of the Phi-3 technical report\nWeizhu Chen is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"VISHRAV CHAUDHARY","type":"PERSON","description":"An author of the Phi-3 technical report\nVishrav Chaudhary is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"DONG CHEN","type":"PERSON","description":"An author of the Phi-3 technical report\nDong Chen is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"DONGDONG CHEN","type":"PERSON","description":"An author of the Phi-3 technical report\nDongdong Chen is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"YEN-CHUN CHEN","type":"PERSON","description":"An author of the Phi-3 technical report\nYen-Chun Chen is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"YI-LING CHEN","type":"PERSON","description":"An author of the Phi-3 technical report\nYi-Ling Chen is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"PARUL CHOPRA","type":"PERSON","description":"An author of the Phi-3 technical report\nParul Chopra is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"XIYANG DAI","type":"PERSON","description":"An author of the Phi-3 technical report\nXiyang Dai is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"ALLIE DEL GIORNO","type":"PERSON","description":"An author of the Phi-3 technical report\nAllie Del Giorno is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"GUSTAVO DE ROSA","type":"PERSON","description":"An author of the Phi-3 technical report\nGustavo de Rosa is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"MATTHEW DIXON","type":"PERSON","description":"An author of the Phi-3 technical report\nMatthew Dixon is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"RONEN ELDAN","type":"PERSON","description":"An author of the Phi-3 technical report\nRonen Eldan is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"VICTOR FRAGOSO","type":"PERSON","description":"An author of the Phi-3 technical report\nVictor Fragoso is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"DAN ITER","type":"PERSON","description":"An author of the Phi-3 technical report\nDan Iter is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"MEI GAO","type":"PERSON","description":"An author of the Phi-3 technical report\nMei Gao is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"MIN GAO","type":"PERSON","description":"An author of the Phi-3 technical report\nMin Gao is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"JIANFENG GAO","type":"PERSON","description":"An author of the Phi-3 technical report\nJianfeng Gao is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"AMIT GARG","type":"PERSON","description":"An author of the Phi-3 technical report\nAmit Garg is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"ABHISHEK GOSWAMI","type":"PERSON","description":"An author of the Phi-3 technical report\nAbhishek Goswami is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"SURIYA GUNASEKAR","type":"PERSON","description":"An author of the Phi-3 technical report\nSuriya Gunasekar is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"EMMAN HAIDER","type":"PERSON","description":"An author of the Phi-3 technical report\nEmman Haider is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"JUNHENG HAO","type":"PERSON","description":"An author of the Phi-3 technical report\nJunheng Hao is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"RUSSELL J. HEWETT","type":"PERSON","description":"An author of the Phi-3 technical report\nRussell J. Hewett is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"JAMIE HUYNH","type":"PERSON","description":"An author of the Phi-3 technical report\nJamie Huynh is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"MOJAN JAVAHERIPI","type":"PERSON","description":"An author of the Phi-3 technical report\nMojan Javaheripi is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"XIN JIN","type":"PERSON","description":"An author of the Phi-3 technical report\nXin Jin is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"PIERO KAUFFMANN","type":"PERSON","description":"An author of the Phi-3 technical report\nPiero Kauffmann is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"NIKOS KARAMPATZIAKIS","type":"PERSON","description":"An author of the Phi-3 technical report\nNikos Karampatziakis is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"DONGWOO KIM","type":"PERSON","description":"An author of the Phi-3 technical report\nDongwoo Kim is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"MAHOUD KHADEMI","type":"PERSON","description":"An author of the Phi-3 technical report\nMahoud Khademi is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"LEV KURILENKO","type":"PERSON","description":"An author of the Phi-3 technical report\nLev Kurilenko is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"JAMES R. LEE","type":"PERSON","description":"An author of the Phi-3 technical report\nJames R. Lee is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"YIN TAT LEE","type":"PERSON","description":"An author of the Phi-3 technical report\nYin Tat Lee is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"YUANZHI LI","type":"PERSON","description":"An author of the Phi-3 technical report\nYuanzhi Li is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"YUNSHENG LI","type":"PERSON","description":"An author of the Phi-3 technical report\nYunsheng Li is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"CHEN LIANG","type":"PERSON","description":"An author of the Phi-3 technical report\nChen Liang is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"LARS LIDEN","type":"PERSON","description":"An author of the Phi-3 technical report\nLars Liden is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"CE LIU","type":"PERSON","description":"An author of the Phi-3 technical report\nCe Liu is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"MENGCHEN LIU","type":"PERSON","description":"An author of the Phi-3 technical report\nMengchen Liu is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"WEISHUNG LIU","type":"PERSON","description":"An author of the Phi-3 technical report\nWeishung Liu is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"ERIC LIN","type":"PERSON","description":"An author of the Phi-3 technical report\nEric Lin is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"ZEQI LIN","type":"PERSON","description":"An author of the Phi-3 technical report\nZeqi Lin is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"CHONG LUO","type":"PERSON","description":"An author of the Phi-3 technical report\nChong Luo is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"PIYUSH MADAN","type":"PERSON","description":"An author of the Phi-3 technical report\nPiyush Madan is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"MATT MAZZOLA","type":"PERSON","description":"An author of the Phi-3 technical report\nMatt Mazzola is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"ARINDAM MITRA","type":"PERSON","description":"An author of the Phi-3 technical report\nArindam Mitra is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"HARDIK MODI","type":"PERSON","description":"An author of the Phi-3 technical report\nHardik Modi is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"ANH NGUYEN","type":"PERSON","description":"An author of the Phi-3 technical report\nAnh Nguyen is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"BRANDON NORICK","type":"PERSON","description":"An author of the Phi-3 technical report\nBrandon Norick is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"BARUN PATRA","type":"PERSON","description":"An author of the Phi-3 technical report\nBarun Patra is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"DANIEL PEREZ-BECKER","type":"PERSON","description":"An author of the Phi-3 technical report\nDaniel Perez-Becker is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"THOMAS PORTET","type":"PERSON","description":"An author of the Phi-3 technical report\nThomas Portet is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"REID PRYZANT","type":"PERSON","description":"An author of the Phi-3 technical report\nReid Pryzant is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"HEYANG QIN","type":"PERSON","description":"An author of the Phi-3 technical report\nHeyang Qin is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"MARKO RADMILAC","type":"PERSON","description":"An author of the Phi-3 technical report\nMarko Radmilac is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"CORBY ROSSET","type":"PERSON","description":"An author of the Phi-3 technical report\nCorby Rosset is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"SAMBUDHA ROY","type":"PERSON","description":"An author of the Phi-3 technical report\nSambudha Roy is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"OLATUNJI RUWASE","type":"PERSON","description":"An author of the Phi-3 technical report\nOlatunji Ruwase is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"OLLI SAARIKIVI","type":"PERSON","description":"An author of the Phi-3 technical report\nOlli Saarikivi is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"AMIN SAIED","type":"PERSON","description":"An author of the Phi-3 technical report\nAmin Saied is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"ADIL SALIM","type":"PERSON","description":"An author of the Phi-3 technical report\nAdil Salim is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"MICHAEL SANTACROCE","type":"PERSON","description":"An author of the Phi-3 technical report\nMichael Santacroce is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"SHITAL SHAH","type":"PERSON","description":"An author of the Phi-3 technical report\nShital Shah is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"NING SHANG","type":"PERSON","description":"An author of the Phi-3 technical report\nNing Shang is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"HITESHI SHARMA","type":"PERSON","description":"An author of the Phi-3 technical report\nHiteshi Sharma is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"SWADHEEN SHUKLA","type":"PERSON","description":"An author of the Phi-3 technical report\nSwadheen Shukla is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"XIA SONG","type":"PERSON","description":"An author of the Phi-3 technical report\nXia Song is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"MASAHIRO TANAKA","type":"PERSON","description":"An author of the Phi-3 technical report\nMasahiro Tanaka is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"ANDREA TUPINI","type":"PERSON","description":"An author of the Phi-3 technical report\nAndrea Tupini is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"XIN WANG","type":"PERSON","description":"An author of the Phi-3 technical report\nXin Wang is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"LIJUAN WANG","type":"PERSON","description":"An author of the Phi-3 technical report\nLijuan Wang is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"CHUNYU WANG","type":"PERSON","description":"An author of the Phi-3 technical report\nChunyu Wang is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"YU WANG","type":"PERSON","description":"An author of the Phi-3 technical report\nYu Wang is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"RACHEL WARD","type":"PERSON","description":"An author of the Phi-3 technical report\nRachel Ward is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"GUANHUA WANG","type":"PERSON","description":"An author of the Phi-3 technical report\nGuanhua Wang is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"PHILIPP WITTE","type":"PERSON","description":"An author of the Phi-3 technical report\nPhilipp Witte is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"HAIPING WU","type":"PERSON","description":"An author of the Phi-3 technical report\nHaiping Wu is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"MICHAEL WYATT","type":"PERSON","description":"An author of the Phi-3 technical report\nMichael Wyatt is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"BIN XIAO","type":"PERSON","description":"An author of the Phi-3 technical report\nBin Xiao is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"CAN XU","type":"PERSON","description":"An author of the Phi-3 technical report\nCan Xu is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"JIAHANG XU","type":"PERSON","description":"An author of the Phi-3 technical report\nJiahang Xu is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"WEIJIAN XU","type":"PERSON","description":"An author of the Phi-3 technical report\nWeijian Xu is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"SONALI YADAV","type":"PERSON","description":"An author of the Phi-3 technical report\nSonali Yadav is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"FAN YANG","type":"PERSON","description":"An author of the Phi-3 technical report\nFan Yang is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"JIANWEI YANG","type":"PERSON","description":"An author of the Phi-3 technical report\nJianwei Yang is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"ZIYI YANG","type":"PERSON","description":"An author of the Phi-3 technical report\nZiyi Yang is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"YIFAN YANG","type":"PERSON","description":"An author of the Phi-3 technical report\nYifan Yang is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"DONGHAN YU","type":"PERSON","description":"An author of the Phi-3 technical report\nDonghan Yu is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"LU YUAN","type":"PERSON","description":"An author of the Phi-3 technical report\nLu Yuan is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"CHENGRUIDONG ZHANG","type":"PERSON","description":"An author of the Phi-3 technical report\nChengruidong Zhang is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"CYRIL ZHANG","type":"PERSON","description":"An author of the Phi-3 technical report\nCyril Zhang is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"JIANWEN ZHANG","type":"PERSON","description":"An author of the Phi-3 technical report\nJianwen Zhang is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"LI LYNA ZHANG","type":"PERSON","description":"An author of the Phi-3 technical report\nLi Lyna Zhang is an author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42","entity_type":"PERSON"},{"name":"YI ZHANG","type":"PERSON","description":"An author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42"},{"name":"YUE ZHANG","type":"PERSON","description":"An author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42"},{"name":"YUNAN ZHANG","type":"PERSON","description":"An author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42"},{"name":"XIREN ZHOU","type":"PERSON","description":"An author of the Phi-3 technical report","source_id":"dd9a46950237e49ef9b1c7ef08e08d42"},{"name":"PHI-3 TECHNICAL REPORT","type":"DOCUMENT","description":"A technical report authored by multiple individuals, including Marah Abdin and Sam Ade Jacobs","source_id":"dd9a46950237e49ef9b1c7ef08e08d42"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"AZURE\">      <data key=\"d0\">COMPANY\/SERVICE<\/data>      <data key=\"d1\">Azure is a cloud computing service provided by Microsoft, mentioned in the context of transparency notes<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>    <\/node>    <node id=\"TRANSPARENCY NOTES\">      <data key=\"d0\">DOCUMENTATION<\/data>      <data key=\"d1\">Transparency notes from Azure provide information about the rationale behind specific outputs or decisions<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>    <\/node>    <node id=\"CONTENT HARMS\">      <data key=\"d0\">CONCEPT\/ISSUE<\/data>      <data key=\"d1\">Content harms refer to various types of harmful content that large language models can generate, necessitating awareness and preventive actions<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>    <\/node>    <node id=\"CONTENT MODERATION SERVICES\">      <data key=\"d0\">SERVICE<\/data>      <data key=\"d1\">Services provided by different companies and institutions to moderate and prevent harmful content generated by language models<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>    <\/node>    <node id=\"GOVERNMENT AND TECHNOLOGY LEADERS\">      <data key=\"d0\">GROUP<\/data>      <data key=\"d1\">Entities hoped to provide better regulations and standards around content harms for AI technologies in the future<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>    <\/node>    <node id=\"RESEARCH AND OPEN SOURCE COMMUNITY\">      <data key=\"d0\">GROUP<\/data>      <data key=\"d1\">Communities valued for their role in addressing content harms and improving AI technologies<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>    <\/node>    <node id=\"HALLUCINATION\">      <data key=\"d0\">CONCEPT\/ISSUE<\/data>      <data key=\"d1\">The phenomenon where language models fabricate content, making it unreliable for critical decisions or information<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>    <\/node>    <node id=\"UNSTRUCTURED DATA SOURCES\">      <data key=\"d0\">DATA TYPE<\/data>      <data key=\"d1\">Sources of data that are not organized in a pre-defined manner, used by AgentInstruct for generating synthetic data<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>    <\/node>    <node id=\"AGENTINSTRUCT\">      <data key=\"d0\">METHOD\/APPROACH<\/data>      <data key=\"d1\">A method for generating large amounts of diverse and high-quality data for model post-training using agentic flowsAgentInstruct is a method for generating large amounts of diverse and high-quality data for model post-training using agentic flows<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">METHOD\/APPROACH<\/data>    <\/node>    <node id=\"ORCA-3\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">Orca-3 is a model that showed substantial improvement after being post-trained with a dataset generated by AgentInstructA model that showed substantial improvement after being post-trained with a dataset generated by AgentInstruct<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">MODEL<\/data>    <\/node>    <node id=\"25M PAIR DATASET\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset comprising 25 million pairs of prompts and responses generated by AgentInstruct for post-training the Orca-3 model<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">DATASET<\/data>    <\/node>    <node id=\"SYNTHETIC DATA\">      <data key=\"d0\">DATA TYPE<\/data>      <data key=\"d1\">Data generated artificially, used in model training to address concerns like lack of diversity and need for human curationSynthetic data is data generated artificially, used in model training to address concerns like lack of diversity and need for human curation<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">DATA TYPE<\/data>    <\/node>    <node id=\"AGENTIC FLOWS\">      <data key=\"d0\">TECHNIQUE<\/data>      <data key=\"d1\">A technique used by AgentInstruct for synthetic data generation, facilitating model training and customizationAgentic flows are a technique used by AgentInstruct for synthetic data generation, facilitating model training and customization<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">TECHNIQUE<\/data>    <\/node>    <node id=\"MODEL TRAINING\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The process of training machine learning models, which can benefit from synthetic data generated by AgentInstructModel training is the process of training machine learning models, which can benefit from synthetic data generated by AgentInstruct<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PROCESS<\/data>    <\/node>    <node id=\"DOMAIN\/TASK SPECIALIZATION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The process of customizing models for specific domains or tasks using synthetic dataDomain\/task specialization is the process of customizing models for specific domains or tasks using synthetic data<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PROCESS<\/data>    <\/node>    <node id=\"MARAH ABDIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportMarah Abdin is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SAM ADE JACOBS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportSam Ade Jacobs is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"AMMAR AHMAD AWAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportAmmar Ahmad Awan is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JYOTI ANEJA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportJyoti Aneja is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"AHMED AWADALLAH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportAhmed Awadallah is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HANY AWADALLA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportHany Awadalla is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NGUYEN BACH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportNguyen Bach is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"AMIT BAHREE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportAmit Bahree is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ARASH BAKHTIARI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportArash Bakhtiari is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JIANMIN BAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportJianmin Bao is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HARKIRAT BEHL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportHarkirat Behl is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ALON BENHAIM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportAlon Benhaim is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MISHA BILENKO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportMisha Bilenko is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JOHAN BJORCK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportJohan Bjorck is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"S&#201;BASTIEN BUBECK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportS&#233;bastien Bubeck is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"QIN CAI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportQin Cai is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MARTIN CAI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportMartin Cai is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CAIO C&#201;SAR TEODORO MENDES\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportCaio C&#233;sar Teodoro Mendes is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WEIZHU CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportWeizhu Chen is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"VISHRAV CHAUDHARY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportVishrav Chaudhary is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DONG CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportDong Chen is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DONGDONG CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportDongdong Chen is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YEN-CHUN CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportYen-Chun Chen is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YI-LING CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportYi-Ling Chen is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PARUL CHOPRA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportParul Chopra is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XIYANG DAI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportXiyang Dai is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ALLIE DEL GIORNO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportAllie Del Giorno is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GUSTAVO DE ROSA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportGustavo de Rosa is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MATTHEW DIXON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportMatthew Dixon is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"RONEN ELDAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportRonen Eldan is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"VICTOR FRAGOSO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportVictor Fragoso is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DAN ITER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportDan Iter is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MEI GAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportMei Gao is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MIN GAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportMin Gao is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JIANFENG GAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportJianfeng Gao is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"AMIT GARG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportAmit Garg is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ABHISHEK GOSWAMI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportAbhishek Goswami is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SURIYA GUNASEKAR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportSuriya Gunasekar is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"EMMAN HAIDER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportEmman Haider is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JUNHENG HAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportJunheng Hao is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"RUSSELL J. HEWETT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportRussell J. Hewett is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JAMIE HUYNH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportJamie Huynh is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MOJAN JAVAHERIPI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportMojan Javaheripi is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XIN JIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportXin Jin is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PIERO KAUFFMANN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportPiero Kauffmann is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NIKOS KARAMPATZIAKIS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportNikos Karampatziakis is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DONGWOO KIM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportDongwoo Kim is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MAHOUD KHADEMI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportMahoud Khademi is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LEV KURILENKO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportLev Kurilenko is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JAMES R. LEE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportJames R. Lee is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YIN TAT LEE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportYin Tat Lee is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YUANZHI LI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportYuanzhi Li is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YUNSHENG LI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportYunsheng Li is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHEN LIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportChen Liang is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LARS LIDEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportLars Liden is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CE LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportCe Liu is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MENGCHEN LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportMengchen Liu is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WEISHUNG LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportWeishung Liu is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ERIC LIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportEric Lin is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZEQI LIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportZeqi Lin is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHONG LUO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportChong Luo is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PIYUSH MADAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportPiyush Madan is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MATT MAZZOLA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportMatt Mazzola is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ARINDAM MITRA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportArindam Mitra is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HARDIK MODI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportHardik Modi is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ANH NGUYEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportAnh Nguyen is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BRANDON NORICK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportBrandon Norick is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BARUN PATRA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportBarun Patra is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DANIEL PEREZ-BECKER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportDaniel Perez-Becker is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"THOMAS PORTET\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportThomas Portet is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"REID PRYZANT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportReid Pryzant is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HEYANG QIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportHeyang Qin is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MARKO RADMILAC\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportMarko Radmilac is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CORBY ROSSET\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportCorby Rosset is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SAMBUDHA ROY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportSambudha Roy is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"OLATUNJI RUWASE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportOlatunji Ruwase is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"OLLI SAARIKIVI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportOlli Saarikivi is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"AMIN SAIED\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportAmin Saied is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ADIL SALIM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportAdil Salim is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MICHAEL SANTACROCE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportMichael Santacroce is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SHITAL SHAH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportShital Shah is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"NING SHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportNing Shang is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HITESHI SHARMA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportHiteshi Sharma is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SWADHEEN SHUKLA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportSwadheen Shukla is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XIA SONG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportXia Song is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MASAHIRO TANAKA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportMasahiro Tanaka is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ANDREA TUPINI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportAndrea Tupini is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XIN WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportXin Wang is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LIJUAN WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportLijuan Wang is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHUNYU WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportChunyu Wang is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YU WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportYu Wang is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"RACHEL WARD\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportRachel Ward is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GUANHUA WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportGuanhua Wang is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PHILIPP WITTE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportPhilipp Witte is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HAIPING WU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportHaiping Wu is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MICHAEL WYATT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportMichael Wyatt is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BIN XIAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportBin Xiao is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CAN XU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportCan Xu is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JIAHANG XU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportJiahang Xu is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"WEIJIAN XU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportWeijian Xu is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"SONALI YADAV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportSonali Yadav is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"FAN YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportFan Yang is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JIANWEI YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportJianwei Yang is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ZIYI YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportZiyi Yang is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YIFAN YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportYifan Yang is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"DONGHAN YU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportDonghan Yu is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LU YUAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportLu Yuan is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CHENGRUIDONG ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportChengruidong Zhang is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"CYRIL ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportCyril Zhang is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JIANWEN ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportJianwen Zhang is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LI LYNA ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical reportLi Lyna Zhang is an author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"YI ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>    <\/node>    <node id=\"YUE ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>    <\/node>    <node id=\"YUNAN ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>    <\/node>    <node id=\"XIREN ZHOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">An author of the Phi-3 technical report<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>    <\/node>    <node id=\"PHI-3 TECHNICAL REPORT\">      <data key=\"d0\">DOCUMENT<\/data>      <data key=\"d1\">A technical report authored by multiple individuals, including Marah Abdin and Sam Ade Jacobs<\/data>      <data key=\"d2\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>    <\/node>    <edge source=\"AZURE\" target=\"TRANSPARENCY NOTES\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Azure provides transparency notes to explain the rationale behind specific outputs or decisions<\/data>      <data key=\"d6\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>    <\/edge>    <edge source=\"CONTENT HARMS\" target=\"CONTENT MODERATION SERVICES\">      <data key=\"d4\">9.0<\/data>      <data key=\"d5\">Content moderation services are recommended to prevent content harms caused by large language models<\/data>      <data key=\"d6\">dd9a46950237e49ef9b1c7ef08e08d42<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"cc20c99cad8edecc66b82ac751ff7172","chunk":" Wang, Philipp Witte, Haiping Wu, Michael Wyatt, Bin Xiao, Can\nXu, Jiahang Xu, Weijian Xu, Sonali Yadav, Fan Yang, Jianwei Yang, Ziyi Yang, Yifan Yang,\nDonghan Yu, Lu Yuan, Chengruidong Zhang, Cyril Zhang, Jianwen Zhang, Li Lyna Zhang,\nYi Zhang, Yue Zhang, Yunan Zhang, and Xiren Zhou. Phi-3 technical report: A highly capable\nlanguage model locally on your phone, 2024. URL https:\/\/arxiv.org\/abs\/2404.14219 .\n[2]Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick,\nand Oyvind Tafjord. Think you have solved question answering? try arc, the ai2 reasoning\nchallenge. arXiv:1803.05457v1, 2018.\n[3]Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,\nMatthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to\nsolve math word problems. arXivpreprint arXiv:2110.14168, 2021.\n[4]CodeParrot. Github-code clean dataset, 2022. https:\/\/huggingface.co\/datasets\/\ncodeparrot\/github-code-clean [Accessed: (06\/15\/2024)].\n22[5]Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi Zheng, Shengding Hu, Zhiyuan Liu, Maosong\nSun, and Bowen Zhou. Enhancing chat language models by scaling high-quality instructional\nconversations. arXivpreprint arXiv:2305.14233, 2023.\n[6]Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt\nGardner. DROP: A reading comprehension benchmark requiring discrete reasoning over\nparagraphs. In Proceedings ofthe2019Conference oftheNorthAmerican Chapter ofthe\nAssociation forComputational Linguistics: HumanLanguage Technologies, Volume1(Long\nandShortPapers), pages 2368\u20132378, Minneapolis, Minnesota, June 2019. Association for\nComputational Linguistics. doi: 10.18653\/v1\/N19-1246. URL https:\/\/aclanthology.org\/\nN19-1246 .\n[7]Zhaoye Fei, Yunfan Shao, Linyang Li, Zhiyuan Zeng, Hang Yan, Xipeng Qiu, and Dahua Lin.\nQuery of cc: Unearthing large scale domain-specific knowledge from public corpora. arXiv\npreprint arXiv:2401.14624, 2024.\n[8]Arnav Gudibande, Eric Wallace, Charlie Snell, Xinyang Geng, Hao Liu, Pieter Abbeel, Sergey\nLevine, and Dawn Song. The false promise of imitating proprietary llms, 2023. URL https:\n\/\/arxiv.org\/abs\/2305.15717 .\n[9]Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn\nSong, and Jacob Steinhardt. Measuring mathematical problem solving with the math dataset.\narXivpreprint arXiv:2103.03874, 2021.\n[10]Hamish Ivison, Yizhong Wang, Valentina Pyatkin, Nathan Lambert, Matthew Peters, Pradeep\nDasigi, Joel Jang, David Wadden, Noah A. Smith, Iz Beltagy, and Hannaneh Hajishirzi.\nCamels in a changing climate: Enhancing lm adaptation with tulu 2, 2023. URL https:\n\/\/arxiv.org\/abs\/2311.10702 .\n[11]Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh\nChaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile\nSaulnier, L\u00e9lio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut\nLavril, Thomas Wang, Timoth\u00e9e Lacroix, and William El Sayed. Mistral 7b, 2023.\n[12]Harrison Lee, Samrat Phatale, Hassan Mansoor, Thomas Mesnard, Johan Ferret, Kellie\nLu, Colton Bishop, Ethan Hall, Victor Carbune, Abhinav Rastogi, and Sushant Prakash.\nRlaif: Scaling reinforcement learning from human feedback with ai feedback, 2023. URL\nhttps:\/\/arxiv.org\/abs\/2309.00267 .\n[13]Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard\nGhanem. Camel: Communicative agents for \"mind\" exploration of large language model society,\n2023. URL https:\/\/arxiv.org\/abs\/2303.17760 .\n[14]Xuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori, Ishaan Gulrajani, Carlos Guestrin, Percy\nLiang, andTatsunoriB.Hashimoto. Alpacae","chunk_id":"cc20c99cad8edecc66b82ac751ff7172","document_ids":["c5a70861b9987da7046fe2110eb3616c"],"n_tokens":1200,"entities":[{"name":"WANG","type":"PERSON","description":"Wang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"PHILIPP WITTE","type":"PERSON","description":"Philipp Witte is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"HAIPING WU","type":"PERSON","description":"Haiping Wu is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"MICHAEL WYATT","type":"PERSON","description":"Michael Wyatt is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"BIN XIAO","type":"PERSON","description":"Bin Xiao is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"CAN XU","type":"PERSON","description":"Can Xu is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"JIAHANG XU","type":"PERSON","description":"Jiahang Xu is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"WEIJIAN XU","type":"PERSON","description":"Weijian Xu is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"SONALI YADAV","type":"PERSON","description":"Sonali Yadav is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"FAN YANG","type":"PERSON","description":"Fan Yang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"JIANWEI YANG","type":"PERSON","description":"Jianwei Yang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"ZIYI YANG","type":"PERSON","description":"Ziyi Yang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"YIFAN YANG","type":"PERSON","description":"Yifan Yang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"DONGHAN YU","type":"PERSON","description":"Donghan Yu is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"LU YUAN","type":"PERSON","description":"Lu Yuan is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"CHENGRUIDONG ZHANG","type":"PERSON","description":"Chengruidong Zhang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"CYRIL ZHANG","type":"PERSON","description":"Cyril Zhang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"JIANWEN ZHANG","type":"PERSON","description":"Jianwen Zhang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"LI LYNA ZHANG","type":"PERSON","description":"Li Lyna Zhang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"YI ZHANG","type":"PERSON","description":"Yi Zhang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"YUE ZHANG","type":"PERSON","description":"Yue Zhang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"YUNAN ZHANG","type":"PERSON","description":"Yunan Zhang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"XIREN ZHOU","type":"PERSON","description":"Xiren Zhou is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"PHI-3 TECHNICAL REPORT","type":"DOCUMENT","description":"Phi-3 technical report is a document describing a highly capable language model that can run locally on a phone, published in 2024","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"PETER CLARK","type":"PERSON","description":"Peter Clark is an author of the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"ISAAC COWHEY","type":"PERSON","description":"Isaac Cowhey is an author of the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"OREN ETZIONI","type":"PERSON","description":"Oren Etzioni is an author of the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"TUSHAR KHOT","type":"PERSON","description":"Tushar Khot is an author of the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"ASHISH SABHARWAL","type":"PERSON","description":"Ashish Sabharwal is an author of the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"CARISSA SCHOENICK","type":"PERSON","description":"Carissa Schoenick is an author of the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"OYVIND TAFJORD","type":"PERSON","description":"Oyvind Tafjord is an author of the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"THINK YOU HAVE SOLVED QUESTION ANSWERING? TRY ARC, THE AI2 REASONING CHALLENGE","type":"DOCUMENT","description":"A paper discussing the AI2 Reasoning Challenge (ARC) for question answering, published in 2018","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"KARL COBBE","type":"PERSON","description":"Karl Cobbe is an author of the paper \"Training verifiers to solve math word problems\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"VINEET KOSARAJU","type":"PERSON","description":"Vineet Kosaraju is an author of the paper \"Training verifiers to solve math word problems\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"MOHAMMAD BAVARIAN","type":"PERSON","description":"Mohammad Bavarian is an author of the paper \"Training verifiers to solve math word problems\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"MARK CHEN","type":"PERSON","description":"Mark Chen is an author of the paper \"Training verifiers to solve math word problems\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"HEEWOO JUN","type":"PERSON","description":"Heewoo Jun is an author of the paper \"Training verifiers to solve math word problems\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"LUKASZ KAISER","type":"PERSON","description":"Lukasz Kaiser is an author of the paper \"Training verifiers to solve math word problems\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"MATTHIAS PLAPPERT","type":"PERSON","description":"Matthias Plappert is an author of the paper \"Training verifiers to solve math word problems\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"JERRY TWOREK","type":"PERSON","description":"Jerry Tworek is an author of the paper \"Training verifiers to solve math word problems\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"JACOB HILTON","type":"PERSON","description":"Jacob Hilton is an author of the paper \"Training verifiers to solve math word problems\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"REIICHIRO NAKANO","type":"PERSON","description":"Reiichiro Nakano is an author of the paper \"Training verifiers to solve math word problems\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"TRAINING VERIFIERS TO SOLVE MATH WORD PROBLEMS","type":"DOCUMENT","description":"A paper discussing the training of verifiers to solve math word problems, published in 2021","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"CODEPARROT","type":"ORGANIZATION","description":"CodeParrot is the organization behind the Github-code clean dataset","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"GITHUB-CODE CLEAN DATASET","type":"DATASET","description":"A dataset provided by CodeParrot, accessed in 2022","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"NING DING","type":"PERSON","description":"Ning Ding is an author of the paper \"Enhancing chat language models by scaling high-quality instructional conversations\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"YULIN CHEN","type":"PERSON","description":"Yulin Chen is an author of the paper \"Enhancing chat language models by scaling high-quality instructional conversations\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"BOKAI XU","type":"PERSON","description":"Bokai Xu is an author of the paper \"Enhancing chat language models by scaling high-quality instructional conversations\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"YUJIA QIN","type":"PERSON","description":"Yujia Qin is an author of the paper \"Enhancing chat language models by scaling high-quality instructional conversations\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"ZHI ZHENG","type":"PERSON","description":"Zhi Zheng is an author of the paper \"Enhancing chat language models by scaling high-quality instructional conversations\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"SHENGDING HU","type":"PERSON","description":"Shengding Hu is an author of the paper \"Enhancing chat language models by scaling high-quality instructional conversations\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"ZHIYUAN LIU","type":"PERSON","description":"Zhiyuan Liu is an author of the paper \"Enhancing chat language models by scaling high-quality instructional conversations\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"MAOSONG SUN","type":"PERSON","description":"Maosong Sun is an author of the paper \"Enhancing chat language models by scaling high-quality instructional conversations\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"BOWEN ZHOU","type":"PERSON","description":"Bowen Zhou is an author of the paper \"Enhancing chat language models by scaling high-quality instructional conversations\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"ENHANCING CHAT LANGUAGE MODELS BY SCALING HIGH-QUALITY INSTRUCTIONAL CONVERSATIONS","type":"DOCUMENT","description":"A paper discussing the enhancement of chat language models by scaling high-quality instructional conversations, published in 2023","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"DHEERU DUA","type":"PERSON","description":"Dheeru Dua is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"YIZHONG WANG","type":"PERSON","description":"Yizhong Wang is an author of the paper \"Camels in a changing climate: Enhancing lm adaptation with tulu 2\"\nYizhong Wang is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"","source_id":"cc20c99cad8edecc66b82ac751ff7172","entity_type":"PERSON"},{"name":"PRADEEP DASIGI","type":"PERSON","description":"Pradeep Dasigi is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"GABRIEL STANOVSKY","type":"PERSON","description":"Gabriel Stanovsky is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"SAMEER SINGH","type":"PERSON","description":"Sameer Singh is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"MATT GARDNER","type":"PERSON","description":"Matt Gardner is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"DROP: A READING COMPREHENSION BENCHMARK REQUIRING DISCRETE REASONING OVER PARAGRAPHS","type":"DOCUMENT","description":"A paper discussing the DROP benchmark for reading comprehension, published in 2019","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"ZHAOYE FEI","type":"PERSON","description":"Zhaoye Fei is an author of the paper \"Query of cc: Unearthing large scale domain-specific knowledge from public corpora\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"YUNFAN SHAO","type":"PERSON","description":"Yunfan Shao is an author of the paper \"Query of cc: Unearthing large scale domain-specific knowledge from public corpora\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"LINYANG LI","type":"PERSON","description":"Linyang Li is an author of the paper \"Query of cc: Unearthing large scale domain-specific knowledge from public corpora\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"ZHIYUAN ZENG","type":"PERSON","description":"Zhiyuan Zeng is an author of the paper \"Query of cc: Unearthing large scale domain-specific knowledge from public corpora\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"HANG YAN","type":"PERSON","description":"Hang Yan is an author of the paper \"Query of cc: Unearthing large scale domain-specific knowledge from public corpora\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"XIPENG QIU","type":"PERSON","description":"Xipeng Qiu is an author of the paper \"Query of cc: Unearthing large scale domain-specific knowledge from public corpora\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"DAHUA LIN","type":"PERSON","description":"Dahua Lin is an author of the paper \"Query of cc: Unearthing large scale domain-specific knowledge from public corpora\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"QUERY OF CC: UNEARTHING LARGE SCALE DOMAIN-SPECIFIC KNOWLEDGE FROM PUBLIC CORPORA","type":"DOCUMENT","description":"A paper discussing the extraction of domain-specific knowledge from public corpora, published in 2024","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"ARNAV GUDIBANDE","type":"PERSON","description":"Arnav Gudibande is an author of the paper \"The false promise of imitating proprietary llms\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"ERIC WALLACE","type":"PERSON","description":"Eric Wallace is an author of the paper \"The false promise of imitating proprietary llms\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"CHARLIE SNELL","type":"PERSON","description":"Charlie Snell is an author of the paper \"The false promise of imitating proprietary llms\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"XINYANG GENG","type":"PERSON","description":"Xinyang Geng is an author of the paper \"The false promise of imitating proprietary llms\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"HAO LIU","type":"PERSON","description":"Hao Liu is an author of the paper \"The false promise of imitating proprietary llms\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"PIETER ABBEEL","type":"PERSON","description":"Pieter Abbeel is an author of the paper \"The false promise of imitating proprietary llms\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"SERGEY LEVINE","type":"PERSON","description":"Sergey Levine is an author of the paper \"The false promise of imitating proprietary llms\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"DAWN SONG","type":"PERSON","description":"Dawn Song is an author of the paper \"Measuring mathematical problem solving with the math dataset\"\nDawn Song is an author of the paper \"The false promise of imitating proprietary llms\"","source_id":"cc20c99cad8edecc66b82ac751ff7172","entity_type":"PERSON"},{"name":"THE FALSE PROMISE OF IMITATING PROPRIETARY LLMS","type":"DOCUMENT","description":"A paper discussing the limitations of imitating proprietary large language models, published in 2023","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"DAN HENDRYCKS","type":"PERSON","description":"Dan Hendrycks is an author of the paper \"Measuring mathematical problem solving with the math dataset\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"COLLIN BURNS","type":"PERSON","description":"Collin Burns is an author of the paper \"Measuring mathematical problem solving with the math dataset\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"SAURAV KADAVATH","type":"PERSON","description":"Saurav Kadavath is an author of the paper \"Measuring mathematical problem solving with the math dataset\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"AKUL ARORA","type":"PERSON","description":"Akul Arora is an author of the paper \"Measuring mathematical problem solving with the math dataset\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"STEVEN BASART","type":"PERSON","description":"Steven Basart is an author of the paper \"Measuring mathematical problem solving with the math dataset\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"ERIC TANG","type":"PERSON","description":"Eric Tang is an author of the paper \"Measuring mathematical problem solving with the math dataset\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"JACOB STEINHARDT","type":"PERSON","description":"Jacob Steinhardt is an author of the paper \"Measuring mathematical problem solving with the math dataset\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"MEASURING MATHEMATICAL PROBLEM SOLVING WITH THE MATH DATASET","type":"DOCUMENT","description":"A paper discussing the measurement of mathematical problem solving using the math dataset, published in 2021","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"HAMISH IVISON","type":"PERSON","description":"Hamish Ivison is an author of the paper \"Camels in a changing climate: Enhancing lm adaptation with tulu 2\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"VALENTINA PYATKIN","type":"PERSON","description":"Valentina Pyatkin is an author of the paper \"Camels in a changing climate: Enhancing lm adaptation with tulu 2\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"NATHAN LAMBERT","type":"PERSON","description":"Nathan Lambert is an author of the paper \"Camels in a changing climate: Enhancing lm adaptation with tulu 2\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"MATTHEW PETERS","type":"PERSON","description":"Matthew Peters is an author of the paper \"Camels in a changing climate: Enhancing lm adaptation with tulu 2\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"NOAH A. SMITH","type":"PERSON","description":"Noah A. Smith is an author of the paper \"Camels in a changing climate: Enhancing lm adaptation with tulu 2\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"IZ BELTAGY","type":"PERSON","description":"Iz Beltagy is an author of the paper \"Camels in a changing climate: Enhancing lm adaptation with tulu 2\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"HANNANEH HAJISHIRZI","type":"PERSON","description":"Hannaneh Hajishirzi is an author of the paper \"Camels in a changing climate: Enhancing lm adaptation with tulu 2\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"CAMELS IN A CHANGING CLIMATE: ENHANCING LM ADAPTATION WITH TULU 2","type":"DOCUMENT","description":"A paper discussing the enhancement of language model adaptation with Tulu 2, published in 2023","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"ALBERT Q. JIANG","type":"PERSON","description":"Albert Q. Jiang is an author of the paper \"Mistral 7b\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"ALEXANDRE SABLAYROLLES","type":"PERSON","description":"Alexandre Sablayrolles is an author of the paper \"Mistral 7b\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"ARTHUR MENSCH","type":"PERSON","description":"Arthur Mensch is an author of the paper \"Mistral 7b\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"CHRIS BAMFORD","type":"PERSON","description":"Chris Bamford is an author of the paper \"Mistral 7b\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"DEVENDRA SINGH CHAPLOT","type":"PERSON","description":"Devendra Singh Chaplot is an author of the paper \"Mistral 7b\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"DIEGO DE LAS CASAS","type":"PERSON","description":"Diego de las Casas is an author of the paper \"Mistral 7b\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"FLORIAN BRESSAND","type":"PERSON","description":"Florian Bressand is an author of the paper \"Mistral 7b\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"GIANNA LENGYEL","type":"PERSON","description":"Gianna Lengyel is an author of the paper \"Mistral 7b\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"GUILLAUME LAMPLE","type":"PERSON","description":"Guillaume Lample is an author of the paper \"Mistral 7b\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"LUCILE SAULNIER","type":"PERSON","description":"Lucile Saulnier is an author of the paper \"Mistral 7b\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"L\u00c9LIO RENARD LAVAUD","type":"PERSON","description":"L\u00e9lio Renard Lavaud is an author of the paper \"Mistral 7b\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"MARIE-ANNE LACHAUX","type":"PERSON","description":"Marie-Anne Lachaux is an author of the paper \"Mistral 7b\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"PIERRE STOCK","type":"PERSON","description":"Pierre Stock is an author of the paper \"Mistral 7b\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"TEVEN LE SAO","type":"PERSON","description":"Teven Le Sao is an author of the paper \"Mistral 7b\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"THIBAUT LAVRIL","type":"PERSON","description":"Thibaut Lavril is an author of the paper \"Mistral 7b\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"THOMAS WANG","type":"PERSON","description":"Thomas Wang is an author of the paper \"Mistral 7b\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"TIMOTH\u00c9E LACROIX","type":"PERSON","description":"Timoth\u00e9e Lacroix is an author of the paper \"Mistral 7b\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"WILLIAM EL SAYED","type":"PERSON","description":"William El Sayed is an author of the paper \"Mistral 7b\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"MISTRAL 7B","type":"DOCUMENT","description":"A paper discussing the Mistral 7b model, published in 2023","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"HARRISON LEE","type":"PERSON","description":"Harrison Lee is an author of the paper \"Rlaif: Scaling reinforcement learning from human feedback with ai feedback\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"SAMRAT PHATALE","type":"PERSON","description":"Samrat Phatale is an author of the paper \"Rlaif: Scaling reinforcement learning from human feedback with ai feedback\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"HASSAN MANSOOR","type":"PERSON","description":"Hassan Mansoor is an author of the paper \"Rlaif: Scaling reinforcement learning from human feedback with ai feedback\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"THOMAS MESNARD","type":"PERSON","description":"Thomas Mesnard is an author of the paper \"Rlaif: Scaling reinforcement learning from human feedback with ai feedback\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"JOHAN FERRET","type":"PERSON","description":"Johan Ferret is an author of the paper \"Rlaif: Scaling reinforcement learning from human feedback with ai feedback\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"KELLIE LU","type":"PERSON","description":"Kellie Lu is an author of the paper \"Rlaif: Scaling reinforcement learning from human feedback with ai feedback\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"COLTON BISHOP","type":"PERSON","description":"Colton Bishop is an author of the paper \"Rlaif: Scaling reinforcement learning from human feedback with ai feedback\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"ETHAN HALL","type":"PERSON","description":"Ethan Hall is an author of the paper \"Rlaif: Scaling reinforcement learning from human feedback with ai feedback\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"VICTOR CARBUNE","type":"PERSON","description":"Victor Carbune is an author of the paper \"Rlaif: Scaling reinforcement learning from human feedback with ai feedback\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"ABHINAV RASTOGI","type":"PERSON","description":"Abhinav Rastogi is an author of the paper \"Rlaif: Scaling reinforcement learning from human feedback with ai feedback\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"SUSHANT PRAKASH","type":"PERSON","description":"Sushant Prakash is an author of the paper \"Rlaif: Scaling reinforcement learning from human feedback with ai feedback\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"RLAIF: SCALING REINFORCEMENT LEARNING FROM HUMAN FEEDBACK WITH AI FEEDBACK","type":"DOCUMENT","description":"A paper discussing the scaling of reinforcement learning from human feedback with AI feedback, published in 2023","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"GUOHAO LI","type":"PERSON","description":"Guohao Li is an author of the paper \"Camel: Communicative agents for 'mind' exploration of large language model society\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"HASAN ABED AL KADER HAMMOUD","type":"PERSON","description":"Hasan Abed Al Kader Hammoud is an author of the paper \"Camel: Communicative agents for 'mind' exploration of large language model society\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"HANI ITANI","type":"PERSON","description":"Hani Itani is an author of the paper \"Camel: Communicative agents for 'mind' exploration of large language model society\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"DMITRII KHIZBULLIN","type":"PERSON","description":"Dmitrii Khizbullin is an author of the paper \"Camel: Communicative agents for 'mind' exploration of large language model society\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"BERNARD GHANEM","type":"PERSON","description":"Bernard Ghanem is an author of the paper \"Camel: Communicative agents for 'mind' exploration of large language model society\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"CAMEL: COMMUNICATIVE AGENTS FOR 'MIND' EXPLORATION OF LARGE LANGUAGE MODEL SOCIETY","type":"DOCUMENT","description":"A paper discussing communicative agents for exploring the 'mind' of large language model society, published in 2023","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"XUECHEN LI","type":"PERSON","description":"Xuechen Li is an author of the paper \"Alpaca\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"TIANYI ZHANG","type":"PERSON","description":"Tianyi Zhang is an author of the paper \"Alpaca\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"YANN DUBOIS","type":"PERSON","description":"Yann Dubois is an author of the paper \"Alpaca\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"ROHAN TAORI","type":"PERSON","description":"Rohan Taori is an author of the paper \"Alpaca\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"ISHAAN GULRAJANI","type":"PERSON","description":"Ishaan Gulrajani is an author of the paper \"Alpaca\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"CARLOS GUESTRIN","type":"PERSON","description":"Carlos Guestrin is an author of the paper \"Alpaca\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"PERCY LIANG","type":"PERSON","description":"Percy Liang is an author of the paper \"Alpaca\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"TATSUNORI B. HASHIMOTO","type":"PERSON","description":"Tatsunori B. Hashimoto is an author of the paper \"Alpaca\"","source_id":"cc20c99cad8edecc66b82ac751ff7172"},{"name":"ALPACA","type":"DOCUMENT","description":"A paper discussing the Alpaca model, published in 2023","source_id":"cc20c99cad8edecc66b82ac751ff7172"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"PHILIPP WITTE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Philipp Witte is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"HAIPING WU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Haiping Wu is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"MICHAEL WYATT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Michael Wyatt is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"BIN XIAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bin Xiao is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"CAN XU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Can Xu is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"JIAHANG XU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jiahang Xu is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"WEIJIAN XU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Weijian Xu is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"SONALI YADAV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sonali Yadav is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"FAN YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Fan Yang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"JIANWEI YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jianwei Yang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"ZIYI YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ziyi Yang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"YIFAN YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yifan Yang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"DONGHAN YU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Donghan Yu is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"LU YUAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lu Yuan is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"CHENGRUIDONG ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chengruidong Zhang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"CYRIL ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Cyril Zhang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"JIANWEN ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jianwen Zhang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"LI LYNA ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Li Lyna Zhang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"YI ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yi Zhang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"YUE ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yue Zhang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"YUNAN ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yunan Zhang is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"XIREN ZHOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xiren Zhou is an author of the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"PHI-3 TECHNICAL REPORT\">      <data key=\"d0\">DOCUMENT<\/data>      <data key=\"d1\">Phi-3 technical report is a document describing a highly capable language model that can run locally on a phone, published in 2024<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"PETER CLARK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Peter Clark is an author of the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"ISAAC COWHEY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Isaac Cowhey is an author of the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"OREN ETZIONI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Oren Etzioni is an author of the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"TUSHAR KHOT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tushar Khot is an author of the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"ASHISH SABHARWAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ashish Sabharwal is an author of the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"CARISSA SCHOENICK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Carissa Schoenick is an author of the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"OYVIND TAFJORD\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Oyvind Tafjord is an author of the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"THINK YOU HAVE SOLVED QUESTION ANSWERING? TRY ARC, THE AI2 REASONING CHALLENGE\">      <data key=\"d0\">DOCUMENT<\/data>      <data key=\"d1\">A paper discussing the AI2 Reasoning Challenge (ARC) for question answering, published in 2018<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"KARL COBBE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Karl Cobbe is an author of the paper \"Training verifiers to solve math word problems\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"VINEET KOSARAJU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Vineet Kosaraju is an author of the paper \"Training verifiers to solve math word problems\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"MOHAMMAD BAVARIAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mohammad Bavarian is an author of the paper \"Training verifiers to solve math word problems\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"MARK CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mark Chen is an author of the paper \"Training verifiers to solve math word problems\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"HEEWOO JUN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Heewoo Jun is an author of the paper \"Training verifiers to solve math word problems\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"LUKASZ KAISER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lukasz Kaiser is an author of the paper \"Training verifiers to solve math word problems\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"MATTHIAS PLAPPERT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Matthias Plappert is an author of the paper \"Training verifiers to solve math word problems\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"JERRY TWOREK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jerry Tworek is an author of the paper \"Training verifiers to solve math word problems\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"JACOB HILTON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jacob Hilton is an author of the paper \"Training verifiers to solve math word problems\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"REIICHIRO NAKANO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Reiichiro Nakano is an author of the paper \"Training verifiers to solve math word problems\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"TRAINING VERIFIERS TO SOLVE MATH WORD PROBLEMS\">      <data key=\"d0\">DOCUMENT<\/data>      <data key=\"d1\">A paper discussing the training of verifiers to solve math word problems, published in 2021<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"CODEPARROT\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">CodeParrot is the organization behind the Github-code clean dataset<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"GITHUB-CODE CLEAN DATASET\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset provided by CodeParrot, accessed in 2022<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"NING DING\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ning Ding is an author of the paper \"Enhancing chat language models by scaling high-quality instructional conversations\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"YULIN CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yulin Chen is an author of the paper \"Enhancing chat language models by scaling high-quality instructional conversations\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"BOKAI XU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bokai Xu is an author of the paper \"Enhancing chat language models by scaling high-quality instructional conversations\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"YUJIA QIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yujia Qin is an author of the paper \"Enhancing chat language models by scaling high-quality instructional conversations\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"ZHI ZHENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhi Zheng is an author of the paper \"Enhancing chat language models by scaling high-quality instructional conversations\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"SHENGDING HU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shengding Hu is an author of the paper \"Enhancing chat language models by scaling high-quality instructional conversations\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"ZHIYUAN LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhiyuan Liu is an author of the paper \"Enhancing chat language models by scaling high-quality instructional conversations\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"MAOSONG SUN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Maosong Sun is an author of the paper \"Enhancing chat language models by scaling high-quality instructional conversations\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"BOWEN ZHOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bowen Zhou is an author of the paper \"Enhancing chat language models by scaling high-quality instructional conversations\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"ENHANCING CHAT LANGUAGE MODELS BY SCALING HIGH-QUALITY INSTRUCTIONAL CONVERSATIONS\">      <data key=\"d0\">DOCUMENT<\/data>      <data key=\"d1\">A paper discussing the enhancement of chat language models by scaling high-quality instructional conversations, published in 2023<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"DHEERU DUA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dheeru Dua is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"YIZHONG WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yizhong Wang is an author of the paper \"Camels in a changing climate: Enhancing lm adaptation with tulu 2\"Yizhong Wang is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"PRADEEP DASIGI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pradeep Dasigi is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"GABRIEL STANOVSKY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gabriel Stanovsky is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"SAMEER SINGH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sameer Singh is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"MATT GARDNER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Matt Gardner is an author of the paper \"DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"DROP: A READING COMPREHENSION BENCHMARK REQUIRING DISCRETE REASONING OVER PARAGRAPHS\">      <data key=\"d0\">DOCUMENT<\/data>      <data key=\"d1\">A paper discussing the DROP benchmark for reading comprehension, published in 2019<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"ZHAOYE FEI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhaoye Fei is an author of the paper \"Query of cc: Unearthing large scale domain-specific knowledge from public corpora\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"YUNFAN SHAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yunfan Shao is an author of the paper \"Query of cc: Unearthing large scale domain-specific knowledge from public corpora\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"LINYANG LI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Linyang Li is an author of the paper \"Query of cc: Unearthing large scale domain-specific knowledge from public corpora\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"ZHIYUAN ZENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhiyuan Zeng is an author of the paper \"Query of cc: Unearthing large scale domain-specific knowledge from public corpora\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"HANG YAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hang Yan is an author of the paper \"Query of cc: Unearthing large scale domain-specific knowledge from public corpora\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"XIPENG QIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xipeng Qiu is an author of the paper \"Query of cc: Unearthing large scale domain-specific knowledge from public corpora\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"DAHUA LIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dahua Lin is an author of the paper \"Query of cc: Unearthing large scale domain-specific knowledge from public corpora\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"QUERY OF CC: UNEARTHING LARGE SCALE DOMAIN-SPECIFIC KNOWLEDGE FROM PUBLIC CORPORA\">      <data key=\"d0\">DOCUMENT<\/data>      <data key=\"d1\">A paper discussing the extraction of domain-specific knowledge from public corpora, published in 2024<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"ARNAV GUDIBANDE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Arnav Gudibande is an author of the paper \"The false promise of imitating proprietary llms\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"ERIC WALLACE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Eric Wallace is an author of the paper \"The false promise of imitating proprietary llms\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"CHARLIE SNELL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Charlie Snell is an author of the paper \"The false promise of imitating proprietary llms\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"XINYANG GENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xinyang Geng is an author of the paper \"The false promise of imitating proprietary llms\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"HAO LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hao Liu is an author of the paper \"The false promise of imitating proprietary llms\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"PIETER ABBEEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pieter Abbeel is an author of the paper \"The false promise of imitating proprietary llms\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"SERGEY LEVINE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sergey Levine is an author of the paper \"The false promise of imitating proprietary llms\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"DAWN SONG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dawn Song is an author of the paper \"Measuring mathematical problem solving with the math dataset\"Dawn Song is an author of the paper \"The false promise of imitating proprietary llms\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"THE FALSE PROMISE OF IMITATING PROPRIETARY LLMS\">      <data key=\"d0\">DOCUMENT<\/data>      <data key=\"d1\">A paper discussing the limitations of imitating proprietary large language models, published in 2023<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"DAN HENDRYCKS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dan Hendrycks is an author of the paper \"Measuring mathematical problem solving with the math dataset\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"COLLIN BURNS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Collin Burns is an author of the paper \"Measuring mathematical problem solving with the math dataset\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"SAURAV KADAVATH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Saurav Kadavath is an author of the paper \"Measuring mathematical problem solving with the math dataset\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"AKUL ARORA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Akul Arora is an author of the paper \"Measuring mathematical problem solving with the math dataset\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"STEVEN BASART\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Steven Basart is an author of the paper \"Measuring mathematical problem solving with the math dataset\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"ERIC TANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Eric Tang is an author of the paper \"Measuring mathematical problem solving with the math dataset\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"JACOB STEINHARDT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jacob Steinhardt is an author of the paper \"Measuring mathematical problem solving with the math dataset\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"MEASURING MATHEMATICAL PROBLEM SOLVING WITH THE MATH DATASET\">      <data key=\"d0\">DOCUMENT<\/data>      <data key=\"d1\">A paper discussing the measurement of mathematical problem solving using the math dataset, published in 2021<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"HAMISH IVISON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hamish Ivison is an author of the paper \"Camels in a changing climate: Enhancing lm adaptation with tulu 2\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"VALENTINA PYATKIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Valentina Pyatkin is an author of the paper \"Camels in a changing climate: Enhancing lm adaptation with tulu 2\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"NATHAN LAMBERT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nathan Lambert is an author of the paper \"Camels in a changing climate: Enhancing lm adaptation with tulu 2\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"MATTHEW PETERS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Matthew Peters is an author of the paper \"Camels in a changing climate: Enhancing lm adaptation with tulu 2\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"NOAH A. SMITH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Noah A. Smith is an author of the paper \"Camels in a changing climate: Enhancing lm adaptation with tulu 2\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"IZ BELTAGY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Iz Beltagy is an author of the paper \"Camels in a changing climate: Enhancing lm adaptation with tulu 2\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"HANNANEH HAJISHIRZI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hannaneh Hajishirzi is an author of the paper \"Camels in a changing climate: Enhancing lm adaptation with tulu 2\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"CAMELS IN A CHANGING CLIMATE: ENHANCING LM ADAPTATION WITH TULU 2\">      <data key=\"d0\">DOCUMENT<\/data>      <data key=\"d1\">A paper discussing the enhancement of language model adaptation with Tulu 2, published in 2023<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"ALBERT Q. JIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Albert Q. Jiang is an author of the paper \"Mistral 7b\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"ALEXANDRE SABLAYROLLES\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Alexandre Sablayrolles is an author of the paper \"Mistral 7b\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"ARTHUR MENSCH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Arthur Mensch is an author of the paper \"Mistral 7b\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"CHRIS BAMFORD\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chris Bamford is an author of the paper \"Mistral 7b\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"DEVENDRA SINGH CHAPLOT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Devendra Singh Chaplot is an author of the paper \"Mistral 7b\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"DIEGO DE LAS CASAS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Diego de las Casas is an author of the paper \"Mistral 7b\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"FLORIAN BRESSAND\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Florian Bressand is an author of the paper \"Mistral 7b\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"GIANNA LENGYEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gianna Lengyel is an author of the paper \"Mistral 7b\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"GUILLAUME LAMPLE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Guillaume Lample is an author of the paper \"Mistral 7b\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"LUCILE SAULNIER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lucile Saulnier is an author of the paper \"Mistral 7b\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"L&#201;LIO RENARD LAVAUD\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">L&#233;lio Renard Lavaud is an author of the paper \"Mistral 7b\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"MARIE-ANNE LACHAUX\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Marie-Anne Lachaux is an author of the paper \"Mistral 7b\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"PIERRE STOCK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pierre Stock is an author of the paper \"Mistral 7b\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"TEVEN LE SAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Teven Le Sao is an author of the paper \"Mistral 7b\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"THIBAUT LAVRIL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Thibaut Lavril is an author of the paper \"Mistral 7b\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"THOMAS WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Thomas Wang is an author of the paper \"Mistral 7b\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"TIMOTH&#201;E LACROIX\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Timoth&#233;e Lacroix is an author of the paper \"Mistral 7b\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"WILLIAM EL SAYED\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">William El Sayed is an author of the paper \"Mistral 7b\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"MISTRAL 7B\">      <data key=\"d0\">DOCUMENT<\/data>      <data key=\"d1\">A paper discussing the Mistral 7b model, published in 2023<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"HARRISON LEE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Harrison Lee is an author of the paper \"Rlaif: Scaling reinforcement learning from human feedback with ai feedback\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"SAMRAT PHATALE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Samrat Phatale is an author of the paper \"Rlaif: Scaling reinforcement learning from human feedback with ai feedback\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"HASSAN MANSOOR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hassan Mansoor is an author of the paper \"Rlaif: Scaling reinforcement learning from human feedback with ai feedback\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"THOMAS MESNARD\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Thomas Mesnard is an author of the paper \"Rlaif: Scaling reinforcement learning from human feedback with ai feedback\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"JOHAN FERRET\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Johan Ferret is an author of the paper \"Rlaif: Scaling reinforcement learning from human feedback with ai feedback\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"KELLIE LU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kellie Lu is an author of the paper \"Rlaif: Scaling reinforcement learning from human feedback with ai feedback\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"COLTON BISHOP\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Colton Bishop is an author of the paper \"Rlaif: Scaling reinforcement learning from human feedback with ai feedback\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"ETHAN HALL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ethan Hall is an author of the paper \"Rlaif: Scaling reinforcement learning from human feedback with ai feedback\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"VICTOR CARBUNE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Victor Carbune is an author of the paper \"Rlaif: Scaling reinforcement learning from human feedback with ai feedback\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"ABHINAV RASTOGI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Abhinav Rastogi is an author of the paper \"Rlaif: Scaling reinforcement learning from human feedback with ai feedback\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"SUSHANT PRAKASH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sushant Prakash is an author of the paper \"Rlaif: Scaling reinforcement learning from human feedback with ai feedback\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"RLAIF: SCALING REINFORCEMENT LEARNING FROM HUMAN FEEDBACK WITH AI FEEDBACK\">      <data key=\"d0\">DOCUMENT<\/data>      <data key=\"d1\">A paper discussing the scaling of reinforcement learning from human feedback with AI feedback, published in 2023<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"GUOHAO LI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Guohao Li is an author of the paper \"Camel: Communicative agents for 'mind' exploration of large language model society\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"HASAN ABED AL KADER HAMMOUD\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hasan Abed Al Kader Hammoud is an author of the paper \"Camel: Communicative agents for 'mind' exploration of large language model society\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"HANI ITANI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hani Itani is an author of the paper \"Camel: Communicative agents for 'mind' exploration of large language model society\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"DMITRII KHIZBULLIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dmitrii Khizbullin is an author of the paper \"Camel: Communicative agents for 'mind' exploration of large language model society\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"BERNARD GHANEM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bernard Ghanem is an author of the paper \"Camel: Communicative agents for 'mind' exploration of large language model society\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"CAMEL: COMMUNICATIVE AGENTS FOR 'MIND' EXPLORATION OF LARGE LANGUAGE MODEL SOCIETY\">      <data key=\"d0\">DOCUMENT<\/data>      <data key=\"d1\">A paper discussing communicative agents for exploring the 'mind' of large language model society, published in 2023<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"XUECHEN LI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xuechen Li is an author of the paper \"Alpaca\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"TIANYI ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tianyi Zhang is an author of the paper \"Alpaca\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"YANN DUBOIS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yann Dubois is an author of the paper \"Alpaca\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"ROHAN TAORI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Rohan Taori is an author of the paper \"Alpaca\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"ISHAAN GULRAJANI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ishaan Gulrajani is an author of the paper \"Alpaca\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"CARLOS GUESTRIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Carlos Guestrin is an author of the paper \"Alpaca\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"PERCY LIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Percy Liang is an author of the paper \"Alpaca\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"TATSUNORI B. HASHIMOTO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tatsunori B. Hashimoto is an author of the paper \"Alpaca\"<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <node id=\"ALPACA\">      <data key=\"d0\">DOCUMENT<\/data>      <data key=\"d1\">A paper discussing the Alpaca model, published in 2023<\/data>      <data key=\"d2\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/node>    <edge source=\"WANG\" target=\"PHILIPP WITTE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang and Philipp Witte co-authored the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"WANG\" target=\"HAIPING WU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang and Haiping Wu co-authored the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"WANG\" target=\"MICHAEL WYATT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang and Michael Wyatt co-authored the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"WANG\" target=\"BIN XIAO\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang and Bin Xiao co-authored the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"WANG\" target=\"CAN XU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang and Can Xu co-authored the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"WANG\" target=\"JIAHANG XU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang and Jiahang Xu co-authored the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"WANG\" target=\"WEIJIAN XU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang and Weijian Xu co-authored the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"WANG\" target=\"SONALI YADAV\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang and Sonali Yadav co-authored the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"WANG\" target=\"FAN YANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang and Fan Yang co-authored the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"WANG\" target=\"JIANWEI YANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang and Jianwei Yang co-authored the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"WANG\" target=\"ZIYI YANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang and Ziyi Yang co-authored the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"WANG\" target=\"YIFAN YANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang and Yifan Yang co-authored the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"WANG\" target=\"DONGHAN YU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang and Donghan Yu co-authored the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"WANG\" target=\"LU YUAN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang and Lu Yuan co-authored the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"WANG\" target=\"CHENGRUIDONG ZHANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang and Chengruidong Zhang co-authored the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"WANG\" target=\"CYRIL ZHANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang and Cyril Zhang co-authored the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"WANG\" target=\"JIANWEN ZHANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang and Jianwen Zhang co-authored the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"WANG\" target=\"LI LYNA ZHANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang and Li Lyna Zhang co-authored the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"WANG\" target=\"YI ZHANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang and Yi Zhang co-authored the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"WANG\" target=\"YUE ZHANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang and Yue Zhang co-authored the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"WANG\" target=\"YUNAN ZHANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang and Yunan Zhang co-authored the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"WANG\" target=\"XIREN ZHOU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Wang and Xiren Zhou co-authored the paper \"Phi-3 technical report: A highly capable language model locally on your phone\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"PETER CLARK\" target=\"ISAAC COWHEY\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Peter Clark and Isaac Cowhey co-authored the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"PETER CLARK\" target=\"OREN ETZIONI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Peter Clark and Oren Etzioni co-authored the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"PETER CLARK\" target=\"TUSHAR KHOT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Peter Clark and Tushar Khot co-authored the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"PETER CLARK\" target=\"ASHISH SABHARWAL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Peter Clark and Ashish Sabharwal co-authored the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"PETER CLARK\" target=\"CARISSA SCHOENICK\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Peter Clark and Carissa Schoenick co-authored the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"PETER CLARK\" target=\"OYVIND TAFJORD\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Peter Clark and Oyvind Tafjord co-authored the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"ISAAC COWHEY\" target=\"OREN ETZIONI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Isaac Cowhey and Oren Etzioni co-authored the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"ISAAC COWHEY\" target=\"TUSHAR KHOT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Isaac Cowhey and Tushar Khot co-authored the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"ISAAC COWHEY\" target=\"ASHISH SABHARWAL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Isaac Cowhey and Ashish Sabharwal co-authored the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"ISAAC COWHEY\" target=\"CARISSA SCHOENICK\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Isaac Cowhey and Carissa Schoenick co-authored the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"ISAAC COWHEY\" target=\"OYVIND TAFJORD\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Isaac Cowhey and Oyvind Tafjord co-authored the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"OREN ETZIONI\" target=\"TUSHAR KHOT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Oren Etzioni and Tushar Khot co-authored the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>    <edge source=\"OREN ETZIONI\" target=\"ASHISH SABHARWAL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Oren Etzioni and Ashish Sabharwal co-authored the paper \"Think you have solved question answering? try arc, the ai2 reasoning challenge\"<\/data>      <data key=\"d6\">cc20c99cad8edecc66b82ac751ff7172<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"3d1f6634f93f8a4c296dc8df7e59859e","chunk":"rii Khizbullin, and Bernard\nGhanem. Camel: Communicative agents for \"mind\" exploration of large language model society,\n2023. URL https:\/\/arxiv.org\/abs\/2303.17760 .\n[14]Xuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori, Ishaan Gulrajani, Carlos Guestrin, Percy\nLiang, andTatsunoriB.Hashimoto. Alpacaeval: Anautomaticevaluatorofinstruction-following\nmodels. https:\/\/github.com\/tatsu-lab\/alpaca_eval , 2023.\n[15]Yixin Liu, Alexander R. Fabbri, Jiawen Chen, Yilun Zhao, Simeng Han, Shafiq Joty, Pengfei\nLiu, Dragomir Radev, Chien-Sheng Wu, and Arman Cohan. Benchmarking generation and\nevaluation capabilities of large language models for instruction controllable summarization,\n2023. URL https:\/\/arxiv.org\/abs\/2311.09184 .\n[16]Lm-sys. Mt-Bench, 2023. URL https:\/\/huggingface.co\/spaces\/lmsys\/mt-bench\/tree\/\ncf27f9f9da48f72169bce3c3e784d24347d1e833\/data\/mt_bench\/model_answer .\n[17]Daniel van Strien Loubna Ben Allal, Anton Lozhkov. Cosmopedia: how to create large-scale\nsynthetic data for pre-training, 2024. URL https:\/\/huggingface.co\/blog\/cosmopedia .\n[18]Arindam Mitra, Luciano Del Corro, Shweti Mahajan, Andres Codas, Clarisse Simoes, Sahaj\nAgarwal, Xuxi Chen, Anastasia Razdaibiedina, Erik Jones, Kriti Aggarwal, Hamid Palangi,\nGuoqing Zheng, Corby Rosset, Hamed Khanpour, and Ahmed Awadallah. Orca 2: Teaching\nsmall language models how to reason, 2023. URL https:\/\/arxiv.org\/abs\/2311.11045 .\n[19]ArindamMitra, HamedKhanpour, CorbyRosset, andAhmedAwadallah. Orca-math: Unlocking\nthe potential of slms in grade school math. arXivpreprint arXiv:2402.14830, 2024.\n[20]Subhabrata Mukherjee and Ahmed Awadallah. Xtremedistil: Multi-stage distillation for massive\nmultilingual models, 2020.\n23[21]Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, and\nAhmed Awadallah. Orca: Progressive learning from complex explanation traces of gpt-4. arXiv\npreprint arXiv:2306.02707, 2023.\n[22] OpenAI. Gpt-4 technical report, 2023.\n[23]Samuel J. Paech. Eq-bench: An emotional intelligence benchmark for large language models,\n2024. URL https:\/\/arxiv.org\/abs\/2312.06281 .\n[24]Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao. Instruction tuning\nwith gpt-4, 2023. URL https:\/\/arxiv.org\/abs\/2304.03277 .\n[25]YiweiQin, KaiqiangSong, YebowenHu, Wenlin Yao, SangwooCho, XiaoyangWang, Xuansheng\nWu, Fei Liu, Pengfei Liu, and Dong Yu. Infobench: Evaluating instruction following ability in\nlarge language models, 2024. URL https:\/\/arxiv.org\/abs\/2401.03601 .\n[26]Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong,\nXiangru Tang, Bill Qian, Sihan Zhao, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein,\nDahai Li, Zhiyuan Liu, and Maosong Sun. Toolllm: Facilitating large language models to\nmaster 16000+ real-world apis, 2023.\n[27]David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien\nDirani, Julian Michael, and Samuel R. Bowman. Gpqa: A graduate-level google-proof q&a\nbenchmark, 2023. URL https:\/\/arxiv.org\/abs\/2311.12022 .\n[28]Corby Rosset, Ching-An Cheng, Arindam Mitra, Michael Santacroce, Ahmed Awadallah, and\nTengyang Xie. Direct nash optimization: Teaching language models to self-improve with general\npreferences, 2024. URL https:\/\/arxiv.org\/abs\/2404.03715 .\n[29]Ilia Shumailov, Zakhar Shumaylov, Yiren Zhao, Yarin Gal, Nicolas Papernot, and Ross\nAnderson. The curse of recursion: Training on generated data makes models forget, 2024. URL\nhttps:\/\/arxiv.org\/abs\/2305.17493 .\n[30]Mohammed Latif Siddiq, Jiahao Zhang, Lindsay Roney, and Joanna C. S.","chunk_id":"3d1f6634f93f8a4c296dc8df7e59859e","document_ids":["c5a70861b9987da7046fe2110eb3616c"],"n_tokens":1200,"entities":[{"name":"RII KHIZBULLIN","type":"PERSON","description":"Rii Khizbullin is an author of the paper \"Camel: Communicative agents for 'mind' exploration of large language model society\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"BERNARD GHANEM","type":"PERSON","description":"Bernard Ghanem is an author of the paper \"Camel: Communicative agents for 'mind' exploration of large language model society\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"CAMEL","type":"PROJECT\/PAPER","description":"Camel: Communicative agents for 'mind' exploration of large language model society is a paper published in 2023","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"XUECHEN LI","type":"PERSON","description":"Xuechen Li is an author of the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"TIANYI ZHANG","type":"PERSON","description":"Tianyi Zhang is an author of the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"YANN DUBOIS","type":"PERSON","description":"Yann Dubois is an author of the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"ROHAN TAORI","type":"PERSON","description":"Rohan Taori is an author of the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"ISHAAN GULRAJANI","type":"PERSON","description":"Ishaan Gulrajani is an author of the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"CARLOS GUESTRIN","type":"PERSON","description":"Carlos Guestrin is an author of the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"PERCY LIANG","type":"PERSON","description":"Percy Liang is an author of the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"TATSUNORI B. HASHIMOTO","type":"PERSON","description":"Tatsunori B. Hashimoto is an author of the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"ALPACAEVAL","type":"PROJECT\/PAPER","description":"Alpacaeval: An automatic evaluator of instruction-following models is a project published in 2023","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"YIXIN LIU","type":"PERSON","description":"Yixin Liu is an author of the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"ALEXANDER R. FABBRI","type":"PERSON","description":"Alexander R. Fabbri is an author of the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"JIAWEN CHEN","type":"PERSON","description":"Jiawen Chen is an author of the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"YILUN ZHAO","type":"PERSON","description":"Yilun Zhao is an author of the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"SIMENG HAN","type":"PERSON","description":"Simeng Han is an author of the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"SHAFIQ JOTY","type":"PERSON","description":"Shafiq Joty is an author of the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"PENGFEI LIU","type":"PERSON","description":"Pengfei Liu is an author of the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"DRAGOMIR RADEV","type":"PERSON","description":"Dragomir Radev is an author of the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"CHIEN-SHENG WU","type":"PERSON","description":"Chien-Sheng Wu is an author of the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"ARMAN COHAN","type":"PERSON","description":"Arman Cohan is an author of the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"BENCHMARKING GENERATION AND EVALUATION CAPABILITIES OF LARGE LANGUAGE MODELS FOR INSTRUCTION CONTROLLABLE SUMMARIZATION","type":"PROJECT\/PAPER","description":"A paper published in 2023 that benchmarks the generation and evaluation capabilities of large language models for instruction controllable summarization","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"LM-SYS","type":"ORGANIZATION","description":"Lm-sys is the organization behind the Mt-Bench project","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"MT-BENCH","type":"PROJECT","description":"Mt-Bench is a project by Lm-sys published in 2023","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"DANIEL VAN STRIEN","type":"PERSON","description":"Daniel van Strien is an author of the paper \"Cosmopedia: how to create large-scale synthetic data for pre-training\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"LOUBNA BEN ALLAL","type":"PERSON","description":"Loubna Ben Allal is an author of the paper \"Cosmopedia: how to create large-scale synthetic data for pre-training\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"ANTON LOZHKOV","type":"PERSON","description":"Anton Lozhkov is an author of the paper \"Cosmopedia: how to create large-scale synthetic data for pre-training\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"COSMOPEDIA","type":"PROJECT\/PAPER","description":"Cosmopedia: how to create large-scale synthetic data for pre-training is a paper published in 2024","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"ARINDAM MITRA","type":"PERSON","description":"Arindam Mitra is an author of the paper \"Orca-math: Unlocking the potential of SLMs in grade school math\"\nArindam Mitra is an author of the paper \"Orca: Progressive learning from complex explanation traces of GPT-4\"\nArindam Mitra is an author of the paper \"Orca 2: Teaching small language models how to reason\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e","entity_type":"PERSON"},{"name":"LUCIANO DEL CORRO","type":"PERSON","description":"Luciano Del Corro is an author of the paper \"Orca 2: Teaching small language models how to reason\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"SHWETI MAHAJAN","type":"PERSON","description":"Shweti Mahajan is an author of the paper \"Orca 2: Teaching small language models how to reason\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"ANDRES CODAS","type":"PERSON","description":"Andres Codas is an author of the paper \"Orca 2: Teaching small language models how to reason\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"CLARISSE SIMOES","type":"PERSON","description":"Clarisse Simoes is an author of the paper \"Orca 2: Teaching small language models how to reason\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"SAHAJ AGARWAL","type":"PERSON","description":"Sahaj Agarwal is an author of the paper \"Orca: Progressive learning from complex explanation traces of GPT-4\"\nSahaj Agarwal is an author of the paper \"Orca 2: Teaching small language models how to reason\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e","entity_type":"PERSON"},{"name":"XUXI CHEN","type":"PERSON","description":"Xuxi Chen is an author of the paper \"Orca 2: Teaching small language models how to reason\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"ANASTASIA RAZDAIBIEDINA","type":"PERSON","description":"Anastasia Razdaibiedina is an author of the paper \"Orca 2: Teaching small language models how to reason\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"ERIK JONES","type":"PERSON","description":"Erik Jones is an author of the paper \"Orca 2: Teaching small language models how to reason\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"KRITI AGGARWAL","type":"PERSON","description":"Kriti Aggarwal is an author of the paper \"Orca 2: Teaching small language models how to reason\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"HAMID PALANGI","type":"PERSON","description":"Hamid Palangi is an author of the paper \"Orca: Progressive learning from complex explanation traces of GPT-4\"\nHamid Palangi is an author of the paper \"Orca 2: Teaching small language models how to reason\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e","entity_type":"PERSON"},{"name":"GUOQING ZHENG","type":"PERSON","description":"Guoqing Zheng is an author of the paper \"Orca 2: Teaching small language models how to reason\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"CORBY ROSSET","type":"PERSON","description":"Corby Rosset is an author of the paper \"Direct Nash optimization: Teaching language models to self-improve with general preferences\"\nCorby Rosset is an author of the paper \"Orca 2: Teaching small language models how to reason\"\nCorby Rosset is an author of the paper \"Orca-math: Unlocking the potential of SLMs in grade school math\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e","entity_type":"PERSON"},{"name":"HAMED KHANPOUR","type":"PERSON","description":"Hamed Khanpour is an author of the paper \"Orca-math: Unlocking the potential of SLMs in grade school math\"\nHamed Khanpour is an author of the paper \"Orca 2: Teaching small language models how to reason\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e","entity_type":"PERSON"},{"name":"AHMED AWADALLAH","type":"PERSON","description":"Ahmed Awadallah is an author of the paper \"Orca-math: Unlocking the potential of SLMs in grade school math\"\nAhmed Awadallah is an author of the paper \"Orca: Progressive learning from complex explanation traces of GPT-4\"\nAhmed Awadallah is an author of the paper \"Orca 2: Teaching small language models how to reason\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e","entity_type":"PERSON"},{"name":"ORCA 2","type":"PROJECT\/PAPER","description":"Orca 2: Teaching small language models how to reason is a paper published in 2023","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"ORCA-MATH","type":"PROJECT\/PAPER","description":"Orca-math: Unlocking the potential of SLMs in grade school math is a paper published in 2024","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"SUBHABRATA MUKHERJEE","type":"PERSON","description":"Subhabrata Mukherjee is an author of the paper \"Orca: Progressive learning from complex explanation traces of GPT-4\"\nSubhabrata Mukherjee is an author of the paper \"Xtremedistil: Multi-stage distillation for massive multilingual models\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e","entity_type":"PERSON"},{"name":"XTREMEDISTIL","type":"PROJECT\/PAPER","description":"Xtremedistil: Multi-stage distillation for massive multilingual models is a paper published in 2020","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"GANESH JAWAHAR","type":"PERSON","description":"Ganesh Jawahar is an author of the paper \"Orca: Progressive learning from complex explanation traces of GPT-4\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e","entity_type":"PERSON"},{"name":"ORCA","type":"PROJECT\/PAPER","description":"Orca: Progressive learning from complex explanation traces of GPT-4 is a paper published in 2023","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"OPENAI","type":"ORGANIZATION","description":"OpenAI is the organization behind the GPT-4 technical report","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"GPT-4 TECHNICAL REPORT","type":"PROJECT\/PAPER","description":"GPT-4 technical report is a paper published in 2023 by OpenAI","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"SAMUEL J. PAECH","type":"PERSON","description":"Samuel J. Paech is an author of the paper \"EQ-Bench: An emotional intelligence benchmark for large language models\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"EQ-BENCH","type":"PROJECT\/PAPER","description":"EQ-Bench: An emotional intelligence benchmark for large language models is a paper published in 2024","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"BAOLIN PENG","type":"PERSON","description":"Baolin Peng is an author of the paper \"Instruction tuning with GPT-4\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"CHUNYUAN LI","type":"PERSON","description":"Chunyuan Li is an author of the paper \"Instruction tuning with GPT-4\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"PENGCHENG HE","type":"PERSON","description":"Pengcheng He is an author of the paper \"Instruction tuning with GPT-4\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"MICHEL GALLEY","type":"PERSON","description":"Michel Galley is an author of the paper \"Instruction tuning with GPT-4\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"JIANFENG GAO","type":"PERSON","description":"Jianfeng Gao is an author of the paper \"Instruction tuning with GPT-4\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"INSTRUCTION TUNING WITH GPT-4","type":"PROJECT\/PAPER","description":"Instruction tuning with GPT-4 is a paper published in 2023","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"YIWEI QIN","type":"PERSON","description":"Yiwei Qin is an author of the paper \"InfoBench: Evaluating instruction following ability in large language models\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"KAIQIANG SONG","type":"PERSON","description":"Kaiqiang Song is an author of the paper \"InfoBench: Evaluating instruction following ability in large language models\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"YEBO WEN HU","type":"PERSON","description":"Yebo Wen Hu is an author of the paper \"InfoBench: Evaluating instruction following ability in large language models\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"WENLIN YAO","type":"PERSON","description":"Wenlin Yao is an author of the paper \"InfoBench: Evaluating instruction following ability in large language models\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"SANGWOO CHO","type":"PERSON","description":"Sangwoo Cho is an author of the paper \"InfoBench: Evaluating instruction following ability in large language models\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"XIAOYANG WANG","type":"PERSON","description":"Xiaoyang Wang is an author of the paper \"InfoBench: Evaluating instruction following ability in large language models\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"XUANSHENG WU","type":"PERSON","description":"Xuansheng Wu is an author of the paper \"InfoBench: Evaluating instruction following ability in large language models\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"FEI LIU","type":"PERSON","description":"Fei Liu is an author of the paper \"InfoBench: Evaluating instruction following ability in large language models\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"INFOBENCH","type":"PROJECT\/PAPER","description":"InfoBench: Evaluating instruction following ability in large language models is a paper published in 2024","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"YUJIA QIN","type":"PERSON","description":"Yujia Qin is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"SHIHAO LIANG","type":"PERSON","description":"Shihao Liang is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"YINING YE","type":"PERSON","description":"Yining Ye is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"KUNLUN ZHU","type":"PERSON","description":"Kunlun Zhu is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"LAN YAN","type":"PERSON","description":"Lan Yan is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"YAXI LU","type":"PERSON","description":"Yaxi Lu is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"YANKAI LIN","type":"PERSON","description":"Yankai Lin is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"XIN CONG","type":"PERSON","description":"Xin Cong is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"XIANGRU TANG","type":"PERSON","description":"Xiangru Tang is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"BILL QIAN","type":"PERSON","description":"Bill Qian is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"SIHAN ZHAO","type":"PERSON","description":"Sihan Zhao is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"RUNCHU TIAN","type":"PERSON","description":"Runchu Tian is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"RUOBING XIE","type":"PERSON","description":"Ruobing Xie is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"JIE ZHOU","type":"PERSON","description":"Jie Zhou is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"MARK GERSTEIN","type":"PERSON","description":"Mark Gerstein is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"DAHAI LI","type":"PERSON","description":"Dahai Li is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"ZHIYUAN LIU","type":"PERSON","description":"Zhiyuan Liu is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"MAOSONG SUN","type":"PERSON","description":"Maosong Sun is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"TOOLLLM","type":"PROJECT\/PAPER","description":"ToolLLM: Facilitating large language models to master 16000+ real-world APIs is a paper published in 2023","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"DAVID REIN","type":"PERSON","description":"David Rein is an author of the paper \"GPQA: A graduate-level Google-proof Q&A benchmark\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e","entity_type":"PERSON"},{"name":"BETTY LI HOU","type":"PERSON","description":"Betty Li Hou is an author of the paper \"GPQA: A graduate-level Google-proof Q&A benchmark\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e","entity_type":"PERSON"},{"name":"ASA COOPER STICKLAND","type":"PERSON","description":"Asa Cooper Stickland is an author of the paper \"GPQA: A graduate-level Google-proof Q&A benchmark\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e","entity_type":"PERSON"},{"name":"MOHAMMED LATIF SIDDIQ","type":"PERSON","description":"Mohammed Latif Siddiq is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"JIAHAO ZHANG","type":"PERSON","description":"Jiahao Zhang is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"LINDSAY RONEY","type":"PERSON","description":"Lindsay Roney is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"JOANNA C. S.","type":"PERSON","description":"Joanna C. S. is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"THE CURSE OF RECURSION","type":"PROJECT\/PAPER","description":"The curse of recursion: Training on generated data makes models forget is a paper published in 2024","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"ILIA SHUMAILOV","type":"PERSON","description":"Ilia Shumailov is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"ZAKHAR SHUMAYLOV","type":"PERSON","description":"Zakhar Shumaylov is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"YIREN ZHAO","type":"PERSON","description":"Yiren Zhao is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"YARIN GAL","type":"PERSON","description":"Yarin Gal is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"NICOLAS PAPERNOT","type":"PERSON","description":"Nicolas Papernot is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"ROSS ANDERSON","type":"PERSON","description":"Ross Anderson is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"CHING-AN CHENG","type":"PERSON","description":"Ching-An Cheng is an author of the paper \"Direct Nash optimization: Teaching language models to self-improve with general preferences\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"MICHAEL SANTACROCE","type":"PERSON","description":"Michael Santacroce is an author of the paper \"Direct Nash optimization: Teaching language models to self-improve with general preferences\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"TENGYANG XIE","type":"PERSON","description":"Tengyang Xie is an author of the paper \"Direct Nash optimization: Teaching language models to self-improve with general preferences\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"DIRECT NASH OPTIMIZATION","type":"PROJECT\/PAPER","description":"Direct Nash optimization: Teaching language models to self-improve with general preferences is a paper published in 2024","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"SAMUEL R. BOWMAN","type":"PERSON","description":"Samuel R. Bowman is an author of the paper \"GPQA: A graduate-level Google-proof Q&A benchmark\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"JULIAN MICHAEL","type":"PERSON","description":"Julian Michael is an author of the paper \"GPQA: A graduate-level Google-proof Q&A benchmark\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"JULIEN DIRANI","type":"PERSON","description":"Julien Dirani is an author of the paper \"GPQA: A graduate-level Google-proof Q&A benchmark\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"RICHARD YUANZHE PANG","type":"PERSON","description":"Richard Yuanzhe Pang is an author of the paper \"GPQA: A graduate-level Google-proof Q&A benchmark\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"JACKSON PETTY","type":"PERSON","description":"Jackson Petty is an author of the paper \"GPQA: A graduate-level Google-proof Q&A benchmark\"","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"},{"name":"GPQA","type":"PROJECT\/PAPER","description":"GPQA: A graduate-level Google-proof Q&A benchmark is a paper published in 2023","source_id":"3d1f6634f93f8a4c296dc8df7e59859e"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"RII KHIZBULLIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Rii Khizbullin is an author of the paper \"Camel: Communicative agents for 'mind' exploration of large language model society\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"BERNARD GHANEM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bernard Ghanem is an author of the paper \"Camel: Communicative agents for 'mind' exploration of large language model society\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"CAMEL\">      <data key=\"d0\">PROJECT\/PAPER<\/data>      <data key=\"d1\">Camel: Communicative agents for 'mind' exploration of large language model society is a paper published in 2023<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"XUECHEN LI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xuechen Li is an author of the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"TIANYI ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tianyi Zhang is an author of the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"YANN DUBOIS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yann Dubois is an author of the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"ROHAN TAORI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Rohan Taori is an author of the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"ISHAAN GULRAJANI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ishaan Gulrajani is an author of the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"CARLOS GUESTRIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Carlos Guestrin is an author of the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"PERCY LIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Percy Liang is an author of the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"TATSUNORI B. HASHIMOTO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tatsunori B. Hashimoto is an author of the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"ALPACAEVAL\">      <data key=\"d0\">PROJECT\/PAPER<\/data>      <data key=\"d1\">Alpacaeval: An automatic evaluator of instruction-following models is a project published in 2023<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"YIXIN LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yixin Liu is an author of the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"ALEXANDER R. FABBRI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Alexander R. Fabbri is an author of the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"JIAWEN CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jiawen Chen is an author of the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"YILUN ZHAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yilun Zhao is an author of the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"SIMENG HAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Simeng Han is an author of the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"SHAFIQ JOTY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shafiq Joty is an author of the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"PENGFEI LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pengfei Liu is an author of the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"DRAGOMIR RADEV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dragomir Radev is an author of the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"CHIEN-SHENG WU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chien-Sheng Wu is an author of the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"ARMAN COHAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Arman Cohan is an author of the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"BENCHMARKING GENERATION AND EVALUATION CAPABILITIES OF LARGE LANGUAGE MODELS FOR INSTRUCTION CONTROLLABLE SUMMARIZATION\">      <data key=\"d0\">PROJECT\/PAPER<\/data>      <data key=\"d1\">A paper published in 2023 that benchmarks the generation and evaluation capabilities of large language models for instruction controllable summarization<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"LM-SYS\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">Lm-sys is the organization behind the Mt-Bench project<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"MT-BENCH\">      <data key=\"d0\">PROJECT<\/data>      <data key=\"d1\">Mt-Bench is a project by Lm-sys published in 2023<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"DANIEL VAN STRIEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Daniel van Strien is an author of the paper \"Cosmopedia: how to create large-scale synthetic data for pre-training\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"LOUBNA BEN ALLAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Loubna Ben Allal is an author of the paper \"Cosmopedia: how to create large-scale synthetic data for pre-training\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"ANTON LOZHKOV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Anton Lozhkov is an author of the paper \"Cosmopedia: how to create large-scale synthetic data for pre-training\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"COSMOPEDIA\">      <data key=\"d0\">PROJECT\/PAPER<\/data>      <data key=\"d1\">Cosmopedia: how to create large-scale synthetic data for pre-training is a paper published in 2024<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"ARINDAM MITRA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Arindam Mitra is an author of the paper \"Orca-math: Unlocking the potential of SLMs in grade school math\"Arindam Mitra is an author of the paper \"Orca: Progressive learning from complex explanation traces of GPT-4\"Arindam Mitra is an author of the paper \"Orca 2: Teaching small language models how to reason\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"LUCIANO DEL CORRO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Luciano Del Corro is an author of the paper \"Orca 2: Teaching small language models how to reason\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"SHWETI MAHAJAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shweti Mahajan is an author of the paper \"Orca 2: Teaching small language models how to reason\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"ANDRES CODAS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Andres Codas is an author of the paper \"Orca 2: Teaching small language models how to reason\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"CLARISSE SIMOES\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Clarisse Simoes is an author of the paper \"Orca 2: Teaching small language models how to reason\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"SAHAJ AGARWAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sahaj Agarwal is an author of the paper \"Orca: Progressive learning from complex explanation traces of GPT-4\"Sahaj Agarwal is an author of the paper \"Orca 2: Teaching small language models how to reason\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XUXI CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xuxi Chen is an author of the paper \"Orca 2: Teaching small language models how to reason\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"ANASTASIA RAZDAIBIEDINA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Anastasia Razdaibiedina is an author of the paper \"Orca 2: Teaching small language models how to reason\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"ERIK JONES\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Erik Jones is an author of the paper \"Orca 2: Teaching small language models how to reason\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"KRITI AGGARWAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kriti Aggarwal is an author of the paper \"Orca 2: Teaching small language models how to reason\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"HAMID PALANGI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hamid Palangi is an author of the paper \"Orca: Progressive learning from complex explanation traces of GPT-4\"Hamid Palangi is an author of the paper \"Orca 2: Teaching small language models how to reason\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"GUOQING ZHENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Guoqing Zheng is an author of the paper \"Orca 2: Teaching small language models how to reason\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"CORBY ROSSET\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Corby Rosset is an author of the paper \"Direct Nash optimization: Teaching language models to self-improve with general preferences\"Corby Rosset is an author of the paper \"Orca 2: Teaching small language models how to reason\"Corby Rosset is an author of the paper \"Orca-math: Unlocking the potential of SLMs in grade school math\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"HAMED KHANPOUR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hamed Khanpour is an author of the paper \"Orca-math: Unlocking the potential of SLMs in grade school math\"Hamed Khanpour is an author of the paper \"Orca 2: Teaching small language models how to reason\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"AHMED AWADALLAH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ahmed Awadallah is an author of the paper \"Orca-math: Unlocking the potential of SLMs in grade school math\"Ahmed Awadallah is an author of the paper \"Orca: Progressive learning from complex explanation traces of GPT-4\"Ahmed Awadallah is an author of the paper \"Orca 2: Teaching small language models how to reason\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ORCA 2\">      <data key=\"d0\">PROJECT\/PAPER<\/data>      <data key=\"d1\">Orca 2: Teaching small language models how to reason is a paper published in 2023<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"ORCA-MATH\">      <data key=\"d0\">PROJECT\/PAPER<\/data>      <data key=\"d1\">Orca-math: Unlocking the potential of SLMs in grade school math is a paper published in 2024<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"SUBHABRATA MUKHERJEE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Subhabrata Mukherjee is an author of the paper \"Orca: Progressive learning from complex explanation traces of GPT-4\"Subhabrata Mukherjee is an author of the paper \"Xtremedistil: Multi-stage distillation for massive multilingual models\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"XTREMEDISTIL\">      <data key=\"d0\">PROJECT\/PAPER<\/data>      <data key=\"d1\">Xtremedistil: Multi-stage distillation for massive multilingual models is a paper published in 2020<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"GANESH JAWAHAR\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ganesh Jawahar is an author of the paper \"Orca: Progressive learning from complex explanation traces of GPT-4\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ORCA\">      <data key=\"d0\">PROJECT\/PAPER<\/data>      <data key=\"d1\">Orca: Progressive learning from complex explanation traces of GPT-4 is a paper published in 2023<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"OPENAI\">      <data key=\"d0\">ORGANIZATION<\/data>      <data key=\"d1\">OpenAI is the organization behind the GPT-4 technical report<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"GPT-4 TECHNICAL REPORT\">      <data key=\"d0\">PROJECT\/PAPER<\/data>      <data key=\"d1\">GPT-4 technical report is a paper published in 2023 by OpenAI<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"SAMUEL J. PAECH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Samuel J. Paech is an author of the paper \"EQ-Bench: An emotional intelligence benchmark for large language models\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"EQ-BENCH\">      <data key=\"d0\">PROJECT\/PAPER<\/data>      <data key=\"d1\">EQ-Bench: An emotional intelligence benchmark for large language models is a paper published in 2024<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"BAOLIN PENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Baolin Peng is an author of the paper \"Instruction tuning with GPT-4\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"CHUNYUAN LI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chunyuan Li is an author of the paper \"Instruction tuning with GPT-4\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"PENGCHENG HE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pengcheng He is an author of the paper \"Instruction tuning with GPT-4\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"MICHEL GALLEY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Michel Galley is an author of the paper \"Instruction tuning with GPT-4\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"JIANFENG GAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jianfeng Gao is an author of the paper \"Instruction tuning with GPT-4\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"INSTRUCTION TUNING WITH GPT-4\">      <data key=\"d0\">PROJECT\/PAPER<\/data>      <data key=\"d1\">Instruction tuning with GPT-4 is a paper published in 2023<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"YIWEI QIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yiwei Qin is an author of the paper \"InfoBench: Evaluating instruction following ability in large language models\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"KAIQIANG SONG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kaiqiang Song is an author of the paper \"InfoBench: Evaluating instruction following ability in large language models\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"YEBO WEN HU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yebo Wen Hu is an author of the paper \"InfoBench: Evaluating instruction following ability in large language models\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"WENLIN YAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wenlin Yao is an author of the paper \"InfoBench: Evaluating instruction following ability in large language models\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"SANGWOO CHO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sangwoo Cho is an author of the paper \"InfoBench: Evaluating instruction following ability in large language models\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"XIAOYANG WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xiaoyang Wang is an author of the paper \"InfoBench: Evaluating instruction following ability in large language models\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"XUANSHENG WU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xuansheng Wu is an author of the paper \"InfoBench: Evaluating instruction following ability in large language models\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"FEI LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Fei Liu is an author of the paper \"InfoBench: Evaluating instruction following ability in large language models\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"INFOBENCH\">      <data key=\"d0\">PROJECT\/PAPER<\/data>      <data key=\"d1\">InfoBench: Evaluating instruction following ability in large language models is a paper published in 2024<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"YUJIA QIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yujia Qin is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"SHIHAO LIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shihao Liang is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"YINING YE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yining Ye is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"KUNLUN ZHU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kunlun Zhu is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"LAN YAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lan Yan is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"YAXI LU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yaxi Lu is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"YANKAI LIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yankai Lin is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"XIN CONG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xin Cong is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"XIANGRU TANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xiangru Tang is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"BILL QIAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Bill Qian is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"SIHAN ZHAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sihan Zhao is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"RUNCHU TIAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Runchu Tian is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"RUOBING XIE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ruobing Xie is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"JIE ZHOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jie Zhou is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"MARK GERSTEIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mark Gerstein is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"DAHAI LI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Dahai Li is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"ZHIYUAN LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhiyuan Liu is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"MAOSONG SUN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Maosong Sun is an author of the paper \"ToolLLM: Facilitating large language models to master 16000+ real-world APIs\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"TOOLLLM\">      <data key=\"d0\">PROJECT\/PAPER<\/data>      <data key=\"d1\">ToolLLM: Facilitating large language models to master 16000+ real-world APIs is a paper published in 2023<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"DAVID REIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">David Rein is an author of the paper \"GPQA: A graduate-level Google-proof Q&amp;A benchmark\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"BETTY LI HOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Betty Li Hou is an author of the paper \"GPQA: A graduate-level Google-proof Q&amp;A benchmark\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"ASA COOPER STICKLAND\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Asa Cooper Stickland is an author of the paper \"GPQA: A graduate-level Google-proof Q&amp;A benchmark\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"MOHAMMED LATIF SIDDIQ\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mohammed Latif Siddiq is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"JIAHAO ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jiahao Zhang is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"LINDSAY RONEY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lindsay Roney is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"JOANNA C. S.\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joanna C. S. is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"THE CURSE OF RECURSION\">      <data key=\"d0\">PROJECT\/PAPER<\/data>      <data key=\"d1\">The curse of recursion: Training on generated data makes models forget is a paper published in 2024<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"ILIA SHUMAILOV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ilia Shumailov is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"ZAKHAR SHUMAYLOV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zakhar Shumaylov is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"YIREN ZHAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yiren Zhao is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"YARIN GAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yarin Gal is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"NICOLAS PAPERNOT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nicolas Papernot is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"ROSS ANDERSON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ross Anderson is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"CHING-AN CHENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ching-An Cheng is an author of the paper \"Direct Nash optimization: Teaching language models to self-improve with general preferences\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"MICHAEL SANTACROCE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Michael Santacroce is an author of the paper \"Direct Nash optimization: Teaching language models to self-improve with general preferences\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"TENGYANG XIE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tengyang Xie is an author of the paper \"Direct Nash optimization: Teaching language models to self-improve with general preferences\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"DIRECT NASH OPTIMIZATION\">      <data key=\"d0\">PROJECT\/PAPER<\/data>      <data key=\"d1\">Direct Nash optimization: Teaching language models to self-improve with general preferences is a paper published in 2024<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"SAMUEL R. BOWMAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Samuel R. Bowman is an author of the paper \"GPQA: A graduate-level Google-proof Q&amp;A benchmark\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"JULIAN MICHAEL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Julian Michael is an author of the paper \"GPQA: A graduate-level Google-proof Q&amp;A benchmark\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"JULIEN DIRANI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Julien Dirani is an author of the paper \"GPQA: A graduate-level Google-proof Q&amp;A benchmark\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"RICHARD YUANZHE PANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Richard Yuanzhe Pang is an author of the paper \"GPQA: A graduate-level Google-proof Q&amp;A benchmark\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"JACKSON PETTY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jackson Petty is an author of the paper \"GPQA: A graduate-level Google-proof Q&amp;A benchmark\"<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <node id=\"GPQA\">      <data key=\"d0\">PROJECT\/PAPER<\/data>      <data key=\"d1\">GPQA: A graduate-level Google-proof Q&amp;A benchmark is a paper published in 2023<\/data>      <data key=\"d2\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/node>    <edge source=\"RII KHIZBULLIN\" target=\"BERNARD GHANEM\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Rii Khizbullin and Bernard Ghanem co-authored the paper \"Camel: Communicative agents for 'mind' exploration of large language model society\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"XUECHEN LI\" target=\"TIANYI ZHANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Xuechen Li and Tianyi Zhang co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"XUECHEN LI\" target=\"YANN DUBOIS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Xuechen Li and Yann Dubois co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"XUECHEN LI\" target=\"ROHAN TAORI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Xuechen Li and Rohan Taori co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"XUECHEN LI\" target=\"ISHAAN GULRAJANI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Xuechen Li and Ishaan Gulrajani co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"XUECHEN LI\" target=\"CARLOS GUESTRIN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Xuechen Li and Carlos Guestrin co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"XUECHEN LI\" target=\"PERCY LIANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Xuechen Li and Percy Liang co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"XUECHEN LI\" target=\"TATSUNORI B. HASHIMOTO\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Xuechen Li and Tatsunori B. Hashimoto co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"TIANYI ZHANG\" target=\"YANN DUBOIS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Tianyi Zhang and Yann Dubois co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"TIANYI ZHANG\" target=\"ROHAN TAORI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Tianyi Zhang and Rohan Taori co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"TIANYI ZHANG\" target=\"ISHAAN GULRAJANI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Tianyi Zhang and Ishaan Gulrajani co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"TIANYI ZHANG\" target=\"CARLOS GUESTRIN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Tianyi Zhang and Carlos Guestrin co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"TIANYI ZHANG\" target=\"PERCY LIANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Tianyi Zhang and Percy Liang co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"TIANYI ZHANG\" target=\"TATSUNORI B. HASHIMOTO\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Tianyi Zhang and Tatsunori B. Hashimoto co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"YANN DUBOIS\" target=\"ROHAN TAORI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yann Dubois and Rohan Taori co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"YANN DUBOIS\" target=\"ISHAAN GULRAJANI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yann Dubois and Ishaan Gulrajani co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"YANN DUBOIS\" target=\"CARLOS GUESTRIN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yann Dubois and Carlos Guestrin co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"YANN DUBOIS\" target=\"PERCY LIANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yann Dubois and Percy Liang co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"YANN DUBOIS\" target=\"TATSUNORI B. HASHIMOTO\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yann Dubois and Tatsunori B. Hashimoto co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"ROHAN TAORI\" target=\"ISHAAN GULRAJANI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Rohan Taori and Ishaan Gulrajani co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"ROHAN TAORI\" target=\"CARLOS GUESTRIN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Rohan Taori and Carlos Guestrin co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"ROHAN TAORI\" target=\"PERCY LIANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Rohan Taori and Percy Liang co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"ROHAN TAORI\" target=\"TATSUNORI B. HASHIMOTO\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Rohan Taori and Tatsunori B. Hashimoto co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"ISHAAN GULRAJANI\" target=\"CARLOS GUESTRIN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Ishaan Gulrajani and Carlos Guestrin co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"ISHAAN GULRAJANI\" target=\"PERCY LIANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Ishaan Gulrajani and Percy Liang co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"ISHAAN GULRAJANI\" target=\"TATSUNORI B. HASHIMOTO\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Ishaan Gulrajani and Tatsunori B. Hashimoto co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"CARLOS GUESTRIN\" target=\"PERCY LIANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Carlos Guestrin and Percy Liang co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"CARLOS GUESTRIN\" target=\"TATSUNORI B. HASHIMOTO\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Carlos Guestrin and Tatsunori B. Hashimoto co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"PERCY LIANG\" target=\"TATSUNORI B. HASHIMOTO\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Percy Liang and Tatsunori B. Hashimoto co-authored the paper \"Alpacaeval: An automatic evaluator of instruction-following models\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"YIXIN LIU\" target=\"ALEXANDER R. FABBRI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yixin Liu and Alexander R. Fabbri co-authored the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"YIXIN LIU\" target=\"JIAWEN CHEN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yixin Liu and Jiawen Chen co-authored the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"YIXIN LIU\" target=\"YILUN ZHAO\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yixin Liu and Yilun Zhao co-authored the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"YIXIN LIU\" target=\"SIMENG HAN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yixin Liu and Simeng Han co-authored the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"YIXIN LIU\" target=\"SHAFIQ JOTY\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yixin Liu and Shafiq Joty co-authored the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"YIXIN LIU\" target=\"PENGFEI LIU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yixin Liu and Pengfei Liu co-authored the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"YIXIN LIU\" target=\"DRAGOMIR RADEV\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yixin Liu and Dragomir Radev co-authored the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"YIXIN LIU\" target=\"CHIEN-SHENG WU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yixin Liu and Chien-Sheng Wu co-authored the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"YIXIN LIU\" target=\"ARMAN COHAN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yixin Liu and Arman Cohan co-authored the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"ALEXANDER R. FABBRI\" target=\"JIAWEN CHEN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Alexander R. Fabbri and Jiawen Chen co-authored the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"ALEXANDER R. FABBRI\" target=\"YILUN ZHAO\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Alexander R. Fabbri and Yilun Zhao co-authored the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"ALEXANDER R. FABBRI\" target=\"SIMENG HAN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Alexander R. Fabbri and Simeng Han co-authored the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>    <edge source=\"ALEXANDER R. FABBRI\" target=\"SHAFIQ JOTY\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Alexander R. Fabbri and Shafiq Joty co-authored the paper \"Benchmarking generation and evaluation capabilities of large language models for instruction controllable summarization\"<\/data>      <data key=\"d6\">3d1f6634f93f8a4c296dc8df7e59859e<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"f4e98ee0b7fb42428f3312f29cb444dd","chunk":"\/2404.03715 .\n[29]Ilia Shumailov, Zakhar Shumaylov, Yiren Zhao, Yarin Gal, Nicolas Papernot, and Ross\nAnderson. The curse of recursion: Training on generated data makes models forget, 2024. URL\nhttps:\/\/arxiv.org\/abs\/2305.17493 .\n[30]Mohammed Latif Siddiq, Jiahao Zhang, Lindsay Roney, and Joanna C. S. Santos.\nRe(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos at-\ntacks. In Proceedings ofthe46thInternational Conference onSoftware Engineering, NIER\nTrack(ICSE-NIER \u201924), 2024. doi: 10.1145\/3639476.3639757.\n[31]Mirac Suzgun, Nathan Scales, Nathanael Sch\u00e4rli, Sebastian Gehrmann, Yi Tay, Hyung Won\nChung, AakankshaChowdhery, QuocVLe, EdHChi, DennyZhou, , andJasonWei. Challenging\nbig-bench tasks and whether chain-of-thought can solve them. arXivpreprint arXiv:2210.09261 ,\n2022.\n[32]Wen wai Yim, Yujuan Fu, Asma Ben Abacha, Neal Snider, Thomas Lin, and Meliha Yetisgen.\nAci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note\ngeneration, 2023.\n[33]Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun\nZhang, Shaokun Zhang, Jiale Liu, Ahmed Hassan Awadallah, Ryen W White, Doug Burger,\nand Chi Wang. Autogen: Enabling next-gen llm applications via multi-agent conversation,\n2023. URL https:\/\/arxiv.org\/abs\/2308.08155 .\n[34]Congying Xia, Chen Xing, Jiangshu Du, Xinyi Yang, Yihao Feng, Ran Xu, Wenpeng Yin, and\nCaiming Xiong. Fofo: A benchmark to evaluate llms\u2019 format-following capability, 2024. URL\nhttps:\/\/arxiv.org\/abs\/2402.18667 .\n[35]Guangzhi Xiong, Qiao Jin, Zhiyong Lu, and Aidong Zhang. Benchmarking retrieval-augmented\ngeneration for medicine. arXivpreprint arXiv:2402.13178, 2024.\n[36]Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and\nDaxin Jiang. Wizardlm: Empowering large language models to follow complex instructions,\n2023.\n[37]Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James T Kwok,\nZhenguo Li, Adrian Weller, and Weiyang Liu. Metamath: Bootstrap your own mathematical\nquestions for large language models. arXivpreprint arXiv:2309.12284, 2023.\n24[38]Yifan Zhang, Yifan Luo, Yang Yuan, and Andrew Chi-Chih Yao. Automathtext: Autonomous\ndata selection with language models for mathematical texts. arXivpreprint arXiv:2402.07625 ,\n2024.\n[39]Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied,\nWeizhu Chen, and Nan Duan. Agieval: A human-centric benchmark for evaluating foundation\nmodels, 2023.\n[40]Jeffrey Zhou, Tianjian Lu, Swaroop Mishra, Siddhartha Brahma, Sujoy Basu, Yi Luan, Denny\nZhou, and Le Hou. Instruction-following evaluation for large language models, 2023. URL\nhttps:\/\/arxiv.org\/abs\/2311.07911 .\n25A Agentic Flows Details\nA.1 Reading Comprehension Flow\nReading Comprehension transformation agents :\n1.Argument Passage Generator: This agent is adept at creating passages that\narticulate arguments, which may occasionally contain logical inconsistencies.\n2.Debate Passage Generator: It specializes in crafting passages that mimic the\nstructure and content of debate transcripts.\n3.Conversation Passage Generator: This agent generates passages that depict\ndialogues.\n4.Meeting Transcript Generator: It is designed to produce meeting transcripts.\n5.Poem Generator: This agent generates poems.\n6.Satirical Passage Generator: It creates texts infused with satirical wit.\n7.Instructional Passage Generator: This agent generates passages resembling\ninstructional manuals.\n8.Long Text Generator: It extends the original text by incorporating additional\ninformation, thereby increasing its length.\n9.Identity Agent: A straightforward agent that replicates the input text verbatim.\nInstruction Taxonomy for Seed Instruction Generation Flow\n1.Literal Comprehension Question (Short Answer(or list)): a question that asks for a\nspecific detail(s) or fact(s) clearly stated in the text.\n2.Numerical Discrete Reasoning (Reasoning): questions that require the reader to use\nnumerical reasoning over many facts from the text.\n3.Critical Comprehension Question (True\/False): construct two statements about the\npurpose or point of view that the reader must assess as true or false, with one being\ntrue and the other false.\n4.Evaluative Comprehension Question (Essay","chunk_id":"f4e98ee0b7fb42428f3312f29cb444dd","document_ids":["c5a70861b9987da7046fe2110eb3616c"],"n_tokens":1200,"entities":[{"name":"ILIA SHUMAILOV","type":"PERSON","description":"Ilia Shumailov is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"ZAKHAR SHUMAYLOV","type":"PERSON","description":"Zakhar Shumaylov is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"YIREN ZHAO","type":"PERSON","description":"Yiren Zhao is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"YARIN GAL","type":"PERSON","description":"Yarin Gal is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"NICOLAS PAPERNOT","type":"PERSON","description":"Nicolas Papernot is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"ROSS ANDERSON","type":"PERSON","description":"Ross Anderson is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"MOHAMMED LATIF SIDDIQ","type":"PERSON","description":"Mohammed Latif Siddiq is an author of the paper \"Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"JIAHAO ZHANG","type":"PERSON","description":"Jiahao Zhang is an author of the paper \"Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"LINDSAY RONEY","type":"PERSON","description":"Lindsay Roney is an author of the paper \"Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"JOANNA C. S. SANTOS","type":"PERSON","description":"Joanna C. S. Santos is an author of the paper \"Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"MIRAC SUZGUN","type":"PERSON","description":"Mirac Suzgun is an author of the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"NATHAN SCALES","type":"PERSON","description":"Nathan Scales is an author of the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"NATHANAEL SCH\u00c4RLI","type":"PERSON","description":"Nathanael Sch\u00e4rli is an author of the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"SEBASTIAN GEHRMANN","type":"PERSON","description":"Sebastian Gehrmann is an author of the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"YI TAY","type":"PERSON","description":"Yi Tay is an author of the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"HYUNG WON CHUNG","type":"PERSON","description":"Hyung Won Chung is an author of the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"AAKANKSHA CHOWDHERY","type":"PERSON","description":"Aakanksha Chowdhery is an author of the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"QUOC V LE","type":"PERSON","description":"Quoc V Le is an author of the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"ED H CHI","type":"PERSON","description":"Ed H Chi is an author of the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"DENNY ZHOU","type":"PERSON","description":"Denny Zhou is an author of the paper \"Instruction-following evaluation for large language models\"\nDenny Zhou is an author of the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd","entity_type":"PERSON"},{"name":"JASON WEI","type":"PERSON","description":"Jason Wei is an author of the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"WEN WAI YIM","type":"PERSON","description":"Wen wai Yim is an author of the paper \"Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"YUJUAN FU","type":"PERSON","description":"Yujuan Fu is an author of the paper \"Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"ASMA BEN ABACHA","type":"PERSON","description":"Asma Ben Abacha is an author of the paper \"Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"NEAL SNIDER","type":"PERSON","description":"Neal Snider is an author of the paper \"Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"THOMAS LIN","type":"PERSON","description":"Thomas Lin is an author of the paper \"Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"MELIHA YETISGEN","type":"PERSON","description":"Meliha Yetisgen is an author of the paper \"Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"QINGYUN WU","type":"PERSON","description":"Qingyun Wu is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"GAGAN BANSAL","type":"PERSON","description":"Gagan Bansal is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"JIEYU ZHANG","type":"PERSON","description":"Jieyu Zhang is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"YIRAN WU","type":"PERSON","description":"Yiran Wu is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"BEIBIN LI","type":"PERSON","description":"Beibin Li is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"ERKANG ZHU","type":"PERSON","description":"Erkang Zhu is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"LI JIANG","type":"PERSON","description":"Li Jiang is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"XIAOYUN ZHANG","type":"PERSON","description":"Xiaoyun Zhang is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"SHAOKUN ZHANG","type":"PERSON","description":"Shaokun Zhang is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"JIALE LIU","type":"PERSON","description":"Jiale Liu is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"AHMED HASSAN AWADALLAH","type":"PERSON","description":"Ahmed Hassan Awadallah is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"RYEN W WHITE","type":"PERSON","description":"Ryen W White is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"DOUG BURGER","type":"PERSON","description":"Doug Burger is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"CHI WANG","type":"PERSON","description":"Chi Wang is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"CONGYING XIA","type":"PERSON","description":"Congying Xia is an author of the paper \"Fofo: A benchmark to evaluate llms\u2019 format-following capability\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"CHEN XING","type":"PERSON","description":"Chen Xing is an author of the paper \"Fofo: A benchmark to evaluate llms\u2019 format-following capability\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"JIANGSHU DU","type":"PERSON","description":"Jiangshu Du is an author of the paper \"Fofo: A benchmark to evaluate llms\u2019 format-following capability\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"XINYI YANG","type":"PERSON","description":"Xinyi Yang is an author of the paper \"Fofo: A benchmark to evaluate llms\u2019 format-following capability\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"YIHAO FENG","type":"PERSON","description":"Yihao Feng is an author of the paper \"Fofo: A benchmark to evaluate llms\u2019 format-following capability\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"RAN XU","type":"PERSON","description":"Ran Xu is an author of the paper \"Fofo: A benchmark to evaluate llms\u2019 format-following capability\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"WENPENG YIN","type":"PERSON","description":"Wenpeng Yin is an author of the paper \"Fofo: A benchmark to evaluate llms\u2019 format-following capability\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"CAIMING XIONG","type":"PERSON","description":"Caiming Xiong is an author of the paper \"Fofo: A benchmark to evaluate llms\u2019 format-following capability\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"GUANGZHI XIONG","type":"PERSON","description":"Guangzhi Xiong is an author of the paper \"Benchmarking retrieval-augmented generation for medicine\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"QIAO JIN","type":"PERSON","description":"Qiao Jin is an author of the paper \"Benchmarking retrieval-augmented generation for medicine\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"ZHIYONG LU","type":"PERSON","description":"Zhiyong Lu is an author of the paper \"Benchmarking retrieval-augmented generation for medicine\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"AIDONG ZHANG","type":"PERSON","description":"Aidong Zhang is an author of the paper \"Benchmarking retrieval-augmented generation for medicine\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"CAN XU","type":"PERSON","description":"Can Xu is an author of the paper \"Wizardlm: Empowering large language models to follow complex instructions\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"QINGFENG SUN","type":"PERSON","description":"Qingfeng Sun is an author of the paper \"Wizardlm: Empowering large language models to follow complex instructions\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"KAI ZHENG","type":"PERSON","description":"Kai Zheng is an author of the paper \"Wizardlm: Empowering large language models to follow complex instructions\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"XIUBO GENG","type":"PERSON","description":"Xiubo Geng is an author of the paper \"Wizardlm: Empowering large language models to follow complex instructions\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"PU ZHAO","type":"PERSON","description":"Pu Zhao is an author of the paper \"Wizardlm: Empowering large language models to follow complex instructions\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"JIAZHAN FENG","type":"PERSON","description":"Jiazhan Feng is an author of the paper \"Wizardlm: Empowering large language models to follow complex instructions\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"CHONGYANG TAO","type":"PERSON","description":"Chongyang Tao is an author of the paper \"Wizardlm: Empowering large language models to follow complex instructions\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"DAXIN JIANG","type":"PERSON","description":"Daxin Jiang is an author of the paper \"Wizardlm: Empowering large language models to follow complex instructions\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"LONGHUI YU","type":"PERSON","description":"Longhui Yu is an author of the paper \"Metamath: Bootstrap your own mathematical questions for large language models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"WEISEN JIANG","type":"PERSON","description":"Weisen Jiang is an author of the paper \"Metamath: Bootstrap your own mathematical questions for large language models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"HAN SHI","type":"PERSON","description":"Han Shi is an author of the paper \"Metamath: Bootstrap your own mathematical questions for large language models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"JINCHENG YU","type":"PERSON","description":"Jincheng Yu is an author of the paper \"Metamath: Bootstrap your own mathematical questions for large language models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"ZHENGYING LIU","type":"PERSON","description":"Zhengying Liu is an author of the paper \"Metamath: Bootstrap your own mathematical questions for large language models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"YU ZHANG","type":"PERSON","description":"Yu Zhang is an author of the paper \"Metamath: Bootstrap your own mathematical questions for large language models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"JAMES T KWOK","type":"PERSON","description":"James T Kwok is an author of the paper \"Metamath: Bootstrap your own mathematical questions for large language models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"ZHENGUO LI","type":"PERSON","description":"Zhenguo Li is an author of the paper \"Metamath: Bootstrap your own mathematical questions for large language models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"ADRIAN WELLER","type":"PERSON","description":"Adrian Weller is an author of the paper \"Metamath: Bootstrap your own mathematical questions for large language models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"WEIYANG LIU","type":"PERSON","description":"Weiyang Liu is an author of the paper \"Metamath: Bootstrap your own mathematical questions for large language models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"YIFAN ZHANG","type":"PERSON","description":"Yifan Zhang is an author of the paper \"Automathtext: Autonomous data selection with language models for mathematical texts\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"YIFAN LUO","type":"PERSON","description":"Yifan Luo is an author of the paper \"Automathtext: Autonomous data selection with language models for mathematical texts\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"YANG YUAN","type":"PERSON","description":"Yang Yuan is an author of the paper \"Automathtext: Autonomous data selection with language models for mathematical texts\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"ANDREW CHI-CHIH YAO","type":"PERSON","description":"Andrew Chi-Chih Yao is an author of the paper \"Automathtext: Autonomous data selection with language models for mathematical texts\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"WANJUN ZHONG","type":"PERSON","description":"Wanjun Zhong is an author of the paper \"Agieval: A human-centric benchmark for evaluating foundation models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"RUIXIANG CUI","type":"PERSON","description":"Ruixiang Cui is an author of the paper \"Agieval: A human-centric benchmark for evaluating foundation models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"YIDUO GUO","type":"PERSON","description":"Yiduo Guo is an author of the paper \"Agieval: A human-centric benchmark for evaluating foundation models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"YAOBO LIANG","type":"PERSON","description":"Yaobo Liang is an author of the paper \"Agieval: A human-centric benchmark for evaluating foundation models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"SHUAI LU","type":"PERSON","description":"Shuai Lu is an author of the paper \"Agieval: A human-centric benchmark for evaluating foundation models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"YANLIN WANG","type":"PERSON","description":"Yanlin Wang is an author of the paper \"Agieval: A human-centric benchmark for evaluating foundation models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"AMIN SAIED","type":"PERSON","description":"Amin Saied is an author of the paper \"Agieval: A human-centric benchmark for evaluating foundation models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"WEIZHU CHEN","type":"PERSON","description":"Weizhu Chen is an author of the paper \"Agieval: A human-centric benchmark for evaluating foundation models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"NAN DUAN","type":"PERSON","description":"Nan Duan is an author of the paper \"Agieval: A human-centric benchmark for evaluating foundation models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"JEFFREY ZHOU","type":"PERSON","description":"Jeffrey Zhou is an author of the paper \"Instruction-following evaluation for large language models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"TIANJIAN LU","type":"PERSON","description":"Tianjian Lu is an author of the paper \"Instruction-following evaluation for large language models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"SWAROOP MISHRA","type":"PERSON","description":"Swaroop Mishra is an author of the paper \"Instruction-following evaluation for large language models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"SIDDHARTHA BRAHMA","type":"PERSON","description":"Siddhartha Brahma is an author of the paper \"Instruction-following evaluation for large language models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"SUJOY BASU","type":"PERSON","description":"Sujoy Basu is an author of the paper \"Instruction-following evaluation for large language models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"YI LUAN","type":"PERSON","description":"Yi Luan is an author of the paper \"Instruction-following evaluation for large language models\"","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"ARGUMENT PASSAGE GENERATOR","type":"TOOL\/PROCESS","description":"An agent adept at creating passages that articulate arguments, which may occasionally contain logical inconsistencies","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"DEBATE PASSAGE GENERATOR","type":"TOOL\/PROCESS","description":"An agent that specializes in crafting passages that mimic the structure and content of debate transcripts","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"CONVERSATION PASSAGE GENERATOR","type":"TOOL\/PROCESS","description":"An agent that generates passages that depict dialogues","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"MEETING TRANSCRIPT GENERATOR","type":"TOOL\/PROCESS","description":"An agent designed to produce meeting transcripts","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"POEM GENERATOR","type":"TOOL\/PROCESS","description":"An agent that generates poems","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"SATIRICAL PASSAGE GENERATOR","type":"TOOL\/PROCESS","description":"An agent that creates texts infused with satirical wit","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"INSTRUCTIONAL PASSAGE GENERATOR","type":"TOOL\/PROCESS","description":"An agent that generates passages resembling instructional manuals","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"LONG TEXT GENERATOR","type":"TOOL\/PROCESS","description":"An agent that extends the original text by incorporating additional information, thereby increasing its length","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"IDENTITY AGENT","type":"TOOL\/PROCESS","description":"A straightforward agent that replicates the input text verbatim","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"LITERAL COMPREHENSION QUESTION","type":"TOOL\/PROCESS","description":"A question that asks for a specific detail(s) or fact(s) clearly stated in the text","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"NUMERICAL DISCRETE REASONING","type":"TOOL\/PROCESS","description":"Questions that require the reader to use numerical reasoning over many facts from the text","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"CRITICAL COMPREHENSION QUESTION","type":"TOOL\/PROCESS","description":"Construct two statements about the purpose or point of view that the reader must assess as true or false, with one being true and the other false","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"},{"name":"EVALUATIVE COMPREHENSION QUESTION","type":"TOOL\/PROCESS","description":"A type of question that requires an essay response to evaluate comprehension","source_id":"f4e98ee0b7fb42428f3312f29cb444dd"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"ILIA SHUMAILOV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ilia Shumailov is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"ZAKHAR SHUMAYLOV\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zakhar Shumaylov is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"YIREN ZHAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yiren Zhao is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"YARIN GAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yarin Gal is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"NICOLAS PAPERNOT\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nicolas Papernot is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"ROSS ANDERSON\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ross Anderson is an author of the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"MOHAMMED LATIF SIDDIQ\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mohammed Latif Siddiq is an author of the paper \"Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"JIAHAO ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jiahao Zhang is an author of the paper \"Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"LINDSAY RONEY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Lindsay Roney is an author of the paper \"Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"JOANNA C. S. SANTOS\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Joanna C. S. Santos is an author of the paper \"Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"MIRAC SUZGUN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Mirac Suzgun is an author of the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"NATHAN SCALES\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nathan Scales is an author of the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"NATHANAEL SCH&#196;RLI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nathanael Sch&#228;rli is an author of the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"SEBASTIAN GEHRMANN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sebastian Gehrmann is an author of the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"YI TAY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yi Tay is an author of the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"HYUNG WON CHUNG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Hyung Won Chung is an author of the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"AAKANKSHA CHOWDHERY\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Aakanksha Chowdhery is an author of the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"QUOC V LE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Quoc V Le is an author of the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"ED H CHI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ed H Chi is an author of the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"DENNY ZHOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Denny Zhou is an author of the paper \"Instruction-following evaluation for large language models\"Denny Zhou is an author of the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>      <data key=\"d3\">PERSON<\/data>    <\/node>    <node id=\"JASON WEI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jason Wei is an author of the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"WEN WAI YIM\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wen wai Yim is an author of the paper \"Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"YUJUAN FU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yujuan Fu is an author of the paper \"Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"ASMA BEN ABACHA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Asma Ben Abacha is an author of the paper \"Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"NEAL SNIDER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Neal Snider is an author of the paper \"Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"THOMAS LIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Thomas Lin is an author of the paper \"Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"MELIHA YETISGEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Meliha Yetisgen is an author of the paper \"Aci-bench: a novel ambient clinical intelligence dataset for benchmarking automatic visit note generation\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"QINGYUN WU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Qingyun Wu is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"GAGAN BANSAL\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Gagan Bansal is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"JIEYU ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jieyu Zhang is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"YIRAN WU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yiran Wu is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"BEIBIN LI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Beibin Li is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"ERKANG ZHU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Erkang Zhu is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"LI JIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Li Jiang is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"XIAOYUN ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xiaoyun Zhang is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"SHAOKUN ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shaokun Zhang is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"JIALE LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jiale Liu is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"AHMED HASSAN AWADALLAH\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ahmed Hassan Awadallah is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"RYEN W WHITE\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ryen W White is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"DOUG BURGER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Doug Burger is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"CHI WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chi Wang is an author of the paper \"Autogen: Enabling next-gen llm applications via multi-agent conversation\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"CONGYING XIA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Congying Xia is an author of the paper \"Fofo: A benchmark to evaluate llms&#8217; format-following capability\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"CHEN XING\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chen Xing is an author of the paper \"Fofo: A benchmark to evaluate llms&#8217; format-following capability\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"JIANGSHU DU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jiangshu Du is an author of the paper \"Fofo: A benchmark to evaluate llms&#8217; format-following capability\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"XINYI YANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xinyi Yang is an author of the paper \"Fofo: A benchmark to evaluate llms&#8217; format-following capability\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"YIHAO FENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yihao Feng is an author of the paper \"Fofo: A benchmark to evaluate llms&#8217; format-following capability\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"RAN XU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ran Xu is an author of the paper \"Fofo: A benchmark to evaluate llms&#8217; format-following capability\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"WENPENG YIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wenpeng Yin is an author of the paper \"Fofo: A benchmark to evaluate llms&#8217; format-following capability\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"CAIMING XIONG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Caiming Xiong is an author of the paper \"Fofo: A benchmark to evaluate llms&#8217; format-following capability\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"GUANGZHI XIONG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Guangzhi Xiong is an author of the paper \"Benchmarking retrieval-augmented generation for medicine\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"QIAO JIN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Qiao Jin is an author of the paper \"Benchmarking retrieval-augmented generation for medicine\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"ZHIYONG LU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhiyong Lu is an author of the paper \"Benchmarking retrieval-augmented generation for medicine\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"AIDONG ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Aidong Zhang is an author of the paper \"Benchmarking retrieval-augmented generation for medicine\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"CAN XU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Can Xu is an author of the paper \"Wizardlm: Empowering large language models to follow complex instructions\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"QINGFENG SUN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Qingfeng Sun is an author of the paper \"Wizardlm: Empowering large language models to follow complex instructions\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"KAI ZHENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Kai Zheng is an author of the paper \"Wizardlm: Empowering large language models to follow complex instructions\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"XIUBO GENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Xiubo Geng is an author of the paper \"Wizardlm: Empowering large language models to follow complex instructions\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"PU ZHAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Pu Zhao is an author of the paper \"Wizardlm: Empowering large language models to follow complex instructions\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"JIAZHAN FENG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jiazhan Feng is an author of the paper \"Wizardlm: Empowering large language models to follow complex instructions\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"CHONGYANG TAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Chongyang Tao is an author of the paper \"Wizardlm: Empowering large language models to follow complex instructions\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"DAXIN JIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Daxin Jiang is an author of the paper \"Wizardlm: Empowering large language models to follow complex instructions\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"LONGHUI YU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Longhui Yu is an author of the paper \"Metamath: Bootstrap your own mathematical questions for large language models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"WEISEN JIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Weisen Jiang is an author of the paper \"Metamath: Bootstrap your own mathematical questions for large language models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"HAN SHI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Han Shi is an author of the paper \"Metamath: Bootstrap your own mathematical questions for large language models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"JINCHENG YU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jincheng Yu is an author of the paper \"Metamath: Bootstrap your own mathematical questions for large language models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"ZHENGYING LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhengying Liu is an author of the paper \"Metamath: Bootstrap your own mathematical questions for large language models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"YU ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yu Zhang is an author of the paper \"Metamath: Bootstrap your own mathematical questions for large language models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"JAMES T KWOK\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">James T Kwok is an author of the paper \"Metamath: Bootstrap your own mathematical questions for large language models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"ZHENGUO LI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Zhenguo Li is an author of the paper \"Metamath: Bootstrap your own mathematical questions for large language models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"ADRIAN WELLER\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Adrian Weller is an author of the paper \"Metamath: Bootstrap your own mathematical questions for large language models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"WEIYANG LIU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Weiyang Liu is an author of the paper \"Metamath: Bootstrap your own mathematical questions for large language models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"YIFAN ZHANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yifan Zhang is an author of the paper \"Automathtext: Autonomous data selection with language models for mathematical texts\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"YIFAN LUO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yifan Luo is an author of the paper \"Automathtext: Autonomous data selection with language models for mathematical texts\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"YANG YUAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yang Yuan is an author of the paper \"Automathtext: Autonomous data selection with language models for mathematical texts\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"ANDREW CHI-CHIH YAO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Andrew Chi-Chih Yao is an author of the paper \"Automathtext: Autonomous data selection with language models for mathematical texts\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"WANJUN ZHONG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Wanjun Zhong is an author of the paper \"Agieval: A human-centric benchmark for evaluating foundation models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"RUIXIANG CUI\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Ruixiang Cui is an author of the paper \"Agieval: A human-centric benchmark for evaluating foundation models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"YIDUO GUO\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yiduo Guo is an author of the paper \"Agieval: A human-centric benchmark for evaluating foundation models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"YAOBO LIANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yaobo Liang is an author of the paper \"Agieval: A human-centric benchmark for evaluating foundation models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"SHUAI LU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Shuai Lu is an author of the paper \"Agieval: A human-centric benchmark for evaluating foundation models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"YANLIN WANG\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yanlin Wang is an author of the paper \"Agieval: A human-centric benchmark for evaluating foundation models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"AMIN SAIED\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Amin Saied is an author of the paper \"Agieval: A human-centric benchmark for evaluating foundation models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"WEIZHU CHEN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Weizhu Chen is an author of the paper \"Agieval: A human-centric benchmark for evaluating foundation models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"NAN DUAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Nan Duan is an author of the paper \"Agieval: A human-centric benchmark for evaluating foundation models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"JEFFREY ZHOU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Jeffrey Zhou is an author of the paper \"Instruction-following evaluation for large language models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"TIANJIAN LU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Tianjian Lu is an author of the paper \"Instruction-following evaluation for large language models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"SWAROOP MISHRA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Swaroop Mishra is an author of the paper \"Instruction-following evaluation for large language models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"SIDDHARTHA BRAHMA\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Siddhartha Brahma is an author of the paper \"Instruction-following evaluation for large language models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"SUJOY BASU\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Sujoy Basu is an author of the paper \"Instruction-following evaluation for large language models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"YI LUAN\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Yi Luan is an author of the paper \"Instruction-following evaluation for large language models\"<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"ARGUMENT PASSAGE GENERATOR\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">An agent adept at creating passages that articulate arguments, which may occasionally contain logical inconsistencies<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"DEBATE PASSAGE GENERATOR\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">An agent that specializes in crafting passages that mimic the structure and content of debate transcripts<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"CONVERSATION PASSAGE GENERATOR\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">An agent that generates passages that depict dialogues<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"MEETING TRANSCRIPT GENERATOR\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">An agent designed to produce meeting transcripts<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"POEM GENERATOR\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">An agent that generates poems<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"SATIRICAL PASSAGE GENERATOR\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">An agent that creates texts infused with satirical wit<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"INSTRUCTIONAL PASSAGE GENERATOR\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">An agent that generates passages resembling instructional manuals<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"LONG TEXT GENERATOR\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">An agent that extends the original text by incorporating additional information, thereby increasing its length<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"IDENTITY AGENT\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">A straightforward agent that replicates the input text verbatim<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"LITERAL COMPREHENSION QUESTION\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">A question that asks for a specific detail(s) or fact(s) clearly stated in the text<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"NUMERICAL DISCRETE REASONING\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">Questions that require the reader to use numerical reasoning over many facts from the text<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"CRITICAL COMPREHENSION QUESTION\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">Construct two statements about the purpose or point of view that the reader must assess as true or false, with one being true and the other false<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <node id=\"EVALUATIVE COMPREHENSION QUESTION\">      <data key=\"d0\">TOOL\/PROCESS<\/data>      <data key=\"d1\">A type of question that requires an essay response to evaluate comprehension<\/data>      <data key=\"d2\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/node>    <edge source=\"ILIA SHUMAILOV\" target=\"ZAKHAR SHUMAYLOV\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Ilia Shumailov and Zakhar Shumaylov co-authored the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"ILIA SHUMAILOV\" target=\"YIREN ZHAO\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Ilia Shumailov and Yiren Zhao co-authored the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"ILIA SHUMAILOV\" target=\"YARIN GAL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Ilia Shumailov and Yarin Gal co-authored the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"ILIA SHUMAILOV\" target=\"NICOLAS PAPERNOT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Ilia Shumailov and Nicolas Papernot co-authored the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"ILIA SHUMAILOV\" target=\"ROSS ANDERSON\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Ilia Shumailov and Ross Anderson co-authored the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"ZAKHAR SHUMAYLOV\" target=\"YIREN ZHAO\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Zakhar Shumaylov and Yiren Zhao co-authored the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"ZAKHAR SHUMAYLOV\" target=\"YARIN GAL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Zakhar Shumaylov and Yarin Gal co-authored the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"ZAKHAR SHUMAYLOV\" target=\"NICOLAS PAPERNOT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Zakhar Shumaylov and Nicolas Papernot co-authored the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"ZAKHAR SHUMAYLOV\" target=\"ROSS ANDERSON\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Zakhar Shumaylov and Ross Anderson co-authored the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"YIREN ZHAO\" target=\"YARIN GAL\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yiren Zhao and Yarin Gal co-authored the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"YIREN ZHAO\" target=\"NICOLAS PAPERNOT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yiren Zhao and Nicolas Papernot co-authored the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"YIREN ZHAO\" target=\"ROSS ANDERSON\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yiren Zhao and Ross Anderson co-authored the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"YARIN GAL\" target=\"NICOLAS PAPERNOT\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yarin Gal and Nicolas Papernot co-authored the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"YARIN GAL\" target=\"ROSS ANDERSON\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yarin Gal and Ross Anderson co-authored the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"NICOLAS PAPERNOT\" target=\"ROSS ANDERSON\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Nicolas Papernot and Ross Anderson co-authored the paper \"The curse of recursion: Training on generated data makes models forget\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"MOHAMMED LATIF SIDDIQ\" target=\"JIAHAO ZHANG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Mohammed Latif Siddiq and Jiahao Zhang co-authored the paper \"Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"MOHAMMED LATIF SIDDIQ\" target=\"LINDSAY RONEY\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Mohammed Latif Siddiq and Lindsay Roney co-authored the paper \"Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"MOHAMMED LATIF SIDDIQ\" target=\"JOANNA C. S. SANTOS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Mohammed Latif Siddiq and Joanna C. S. Santos co-authored the paper \"Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"JIAHAO ZHANG\" target=\"LINDSAY RONEY\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Jiahao Zhang and Lindsay Roney co-authored the paper \"Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"JIAHAO ZHANG\" target=\"JOANNA C. S. SANTOS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Jiahao Zhang and Joanna C. S. Santos co-authored the paper \"Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"LINDSAY RONEY\" target=\"JOANNA C. S. SANTOS\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Lindsay Roney and Joanna C. S. Santos co-authored the paper \"Re(gex|dos)eval: Evaluating generated regular expressions and their proneness to dos attacks\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"MIRAC SUZGUN\" target=\"NATHAN SCALES\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Mirac Suzgun and Nathan Scales co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"MIRAC SUZGUN\" target=\"NATHANAEL SCH&#196;RLI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Mirac Suzgun and Nathanael Sch&#228;rli co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"MIRAC SUZGUN\" target=\"SEBASTIAN GEHRMANN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Mirac Suzgun and Sebastian Gehrmann co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"MIRAC SUZGUN\" target=\"YI TAY\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Mirac Suzgun and Yi Tay co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"MIRAC SUZGUN\" target=\"HYUNG WON CHUNG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Mirac Suzgun and Hyung Won Chung co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"MIRAC SUZGUN\" target=\"AAKANKSHA CHOWDHERY\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Mirac Suzgun and Aakanksha Chowdhery co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"MIRAC SUZGUN\" target=\"QUOC V LE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Mirac Suzgun and Quoc V Le co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"MIRAC SUZGUN\" target=\"ED H CHI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Mirac Suzgun and Ed H Chi co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"MIRAC SUZGUN\" target=\"DENNY ZHOU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Mirac Suzgun and Denny Zhou co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"MIRAC SUZGUN\" target=\"JASON WEI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Mirac Suzgun and Jason Wei co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"NATHAN SCALES\" target=\"NATHANAEL SCH&#196;RLI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Nathan Scales and Nathanael Sch&#228;rli co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"NATHAN SCALES\" target=\"SEBASTIAN GEHRMANN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Nathan Scales and Sebastian Gehrmann co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"NATHAN SCALES\" target=\"YI TAY\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Nathan Scales and Yi Tay co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"NATHAN SCALES\" target=\"HYUNG WON CHUNG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Nathan Scales and Hyung Won Chung co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"NATHAN SCALES\" target=\"AAKANKSHA CHOWDHERY\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Nathan Scales and Aakanksha Chowdhery co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"NATHAN SCALES\" target=\"QUOC V LE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Nathan Scales and Quoc V Le co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"NATHAN SCALES\" target=\"ED H CHI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Nathan Scales and Ed H Chi co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"NATHAN SCALES\" target=\"DENNY ZHOU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Nathan Scales and Denny Zhou co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"NATHAN SCALES\" target=\"JASON WEI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Nathan Scales and Jason Wei co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"NATHANAEL SCH&#196;RLI\" target=\"SEBASTIAN GEHRMANN\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Nathanael Sch&#228;rli and Sebastian Gehrmann co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"NATHANAEL SCH&#196;RLI\" target=\"YI TAY\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Nathanael Sch&#228;rli and Yi Tay co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"NATHANAEL SCH&#196;RLI\" target=\"HYUNG WON CHUNG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Nathanael Sch&#228;rli and Hyung Won Chung co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"NATHANAEL SCH&#196;RLI\" target=\"AAKANKSHA CHOWDHERY\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Nathanael Sch&#228;rli and Aakanksha Chowdhery co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"NATHANAEL SCH&#196;RLI\" target=\"QUOC V LE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Nathanael Sch&#228;rli and Quoc V Le co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"NATHANAEL SCH&#196;RLI\" target=\"ED H CHI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Nathanael Sch&#228;rli and Ed H Chi co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"NATHANAEL SCH&#196;RLI\" target=\"DENNY ZHOU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Nathanael Sch&#228;rli and Denny Zhou co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"NATHANAEL SCH&#196;RLI\" target=\"JASON WEI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Nathanael Sch&#228;rli and Jason Wei co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"SEBASTIAN GEHRMANN\" target=\"YI TAY\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Sebastian Gehrmann and Yi Tay co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"SEBASTIAN GEHRMANN\" target=\"HYUNG WON CHUNG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Sebastian Gehrmann and Hyung Won Chung co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"SEBASTIAN GEHRMANN\" target=\"AAKANKSHA CHOWDHERY\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Sebastian Gehrmann and Aakanksha Chowdhery co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"SEBASTIAN GEHRMANN\" target=\"QUOC V LE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Sebastian Gehrmann and Quoc V Le co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"SEBASTIAN GEHRMANN\" target=\"ED H CHI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Sebastian Gehrmann and Ed H Chi co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"SEBASTIAN GEHRMANN\" target=\"DENNY ZHOU\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Sebastian Gehrmann and Denny Zhou co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"SEBASTIAN GEHRMANN\" target=\"JASON WEI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Sebastian Gehrmann and Jason Wei co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"YI TAY\" target=\"HYUNG WON CHUNG\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yi Tay and Hyung Won Chung co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"YI TAY\" target=\"AAKANKSHA CHOWDHERY\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yi Tay and Aakanksha Chowdhery co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"YI TAY\" target=\"QUOC V LE\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yi Tay and Quoc V Le co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>    <edge source=\"YI TAY\" target=\"ED H CHI\">      <data key=\"d4\">8.0<\/data>      <data key=\"d5\">Yi Tay and Ed H Chi co-authored the paper \"Challenging big-bench tasks and whether chain-of-thought can solve them\"<\/data>      <data key=\"d6\">f4e98ee0b7fb42428f3312f29cb444dd<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"5819b66e04fd77fa705574edc49395bb","chunk":" for a\nspecific detail(s) or fact(s) clearly stated in the text.\n2.Numerical Discrete Reasoning (Reasoning): questions that require the reader to use\nnumerical reasoning over many facts from the text.\n3.Critical Comprehension Question (True\/False): construct two statements about the\npurpose or point of view that the reader must assess as true or false, with one being\ntrue and the other false.\n4.Evaluative Comprehension Question (Essay): an open-ended question that prompts\nan in-depth analysis of the text\u2019s theme or the effectiveness of an argument.\n5.Vocabulary and Language Use (Fill-in-the-Blank): a fill-in-the-blank question that\ntests understanding of a particular word or phrase used in the text.\n6.Relationship Comprehension Question (Matching): a matching question where\nrespondents pair items based on a specific criterion.\n7.Sequencing Events (Ordering): a series of events from the text arranged in the\ncorrect chronological order.\n8. Strengthen: identify information that would make the argument\u2019s conclusion more\nlikely to be true.\n9.Weaken: find evidence or an argument that would make the conclusion less likely to\nbe true.\n10.Assumption (Necessary Assumption): determine what must be true for the argument\nto hold.\n11. Flaw: point out a mistake in the argument\u2019s reasoning.\n12.Inference (Must Be True): Choose an option that logically follows from the informa-\ntion provided.\n13.Principle (Identify the Principle): Recognize the general rule or principle that\nunderlies the argument.\n14.Method of Reasoning (Describe the Argument): Describe how the argument is\nconstructed logically.\n15.Resolve the Paradox: Offer an explanation that reconciles seemingly contradictory\ninformation.\n26A.2 Text Modification Flow\nInstruction Taxonomy for Seed Instruction Generation Flow\n1.Paraphrasing: Rewriting text using different words and sentence structures while\nmaintaining the original meaning.\n2.Text Simplification: Making text easier to read and understand by using simpler\nwords and sentence structures, often for children or language learners.\n3.Text Expansion: Adding more information or detail to make text more comprehensive\nor to meet a certain word count.\n4.Text Translation: Converting text from one language to another while attempting\nto preserve the original meaning as closely as possible.\n5.Text Formatting: Altering the appearance of text to improve readability or for\nstylistic purposes.\n6.Sentiment Modification: Changing the tone of the text to alter its emotional impact,\nsuch as making a sentence sound more positive or negative.\n7.Text Annotation: Adding notes, comments, or explanations to a text, often for the\npurpose of analysis or to provide additional context.\n8.Keyword Replacement: Substituting specific words or phrases with synonyms or\nrelated terms.\n9. Text Removing: Redacting or removing content from text.\n10.Text Capitalization: Adjusting the case of letters in text, such as converting to\nuppercase, lowercase, title case, or sentence case, starting every sentence with a\nparticular letter, word.\n11.Text Styling: Applying styles like bold, italics, underline, etc., to emphasize certain\nparts of the text or for aesthetic purposes.\n12.Content Rewriting: Extensively modifying a text to produce a new version, which\ncould involve changing the perspective, style, or target audience.\n13.Data Normalization: Standardizing text to ensure consistency, such as converting\ndates and times to a standard format or unifying the spelling of words.\n14.Plagiarism Rewording: Altering text to avoid plagiarism, ensuring that the content\nis original.\n15.Code Switching: Alternating between languages or dialects within a text, often to\nreflect bilingual speakers\u2019 patterns or for creative writing.\n16.Text Obfuscation: Intentionally making text vague or harder to understand, some-\ntimes for security purposes (like masking personal data).\n17.Textual Entailment: Modifying a sentence or phrase to either entail or contradict\nanother sentence, often used in natural language processing tasks.\n18.Rewriting with vocabulary limitations: Rewriting the entire text or a piece of it\nwhile using a limited vocabulary. For example, all words should start with letter \u2019a\u2019,\nall n-th word should start with letter \u2019b\u2019, each sentence should start with a \u2019vowel\u2019,\netc.\nB Evaluation Details\nThe types of tasks\/benchmarks and the corresponding method used to extract answer and\ngenerate metrics is specified below:\n\u2022Multiple Choice Questions : All the models are evaluated in an open-ended\ngeneration setting with an empty system message We then use GPT-4 for extraction\nof the option selected by the model from model\u2019s response instead of regex based\nextraction done in [ 18]. The extracted prediction is matched with the ground truth\nto generate accuracy scores.\nThe system message used for the GPT-4 extractions is as follows:\n27MCQ GPT-4 Extraction System Message\nYou are an Evaluator Assistant. You support the exam evaluator by parsing\nstudent responses. You are an unbiased Evaluator and do not rely on your\nknowledge but stick to the user provided context. You are provided with the\nquestion, answer options and a student\u2019s response. Your task is to parse the\noption student selected in their response as their final answer and return the\nalphabet ID of that answer in the provided options. If the student gave multiple\nanswers return them as a list.\nUse the following format:\nParsed Student Answer: Final answer extracted from Student\u2019s response. This\nshould only be the alphabets representing the option the student chose.\nExample 1:\nInput :\nQuestion:\nFind all c in Z3such that Z3[x]\/(x2+c)is a field.\nStudent Response :\nI think 0 is incorrect, so is 2.","chunk_id":"5819b66e04fd77fa705574edc49395bb","document_ids":["c5a70861b9987da7046fe2110eb3616c"],"n_tokens":1200,"entities":[{"name":"NUMERICAL DISCRETE REASONING","type":"QUESTION TYPE","description":"Questions that require the reader to use numerical reasoning over many facts from the text","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"CRITICAL COMPREHENSION QUESTION","type":"QUESTION TYPE","description":"Construct two statements about the purpose or point of view that the reader must assess as true or false, with one being true and the other false","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"EVALUATIVE COMPREHENSION QUESTION","type":"QUESTION TYPE","description":"An open-ended question that prompts an in-depth analysis of the text\u2019s theme or the effectiveness of an argument","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"VOCABULARY AND LANGUAGE USE","type":"QUESTION TYPE","description":"A fill-in-the-blank question that tests understanding of a particular word or phrase used in the text","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"RELATIONSHIP COMPREHENSION QUESTION","type":"QUESTION TYPE","description":"A matching question where respondents pair items based on a specific criterion","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"SEQUENCING EVENTS","type":"QUESTION TYPE","description":"A series of events from the text arranged in the correct chronological order","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"STRENGTHEN","type":"QUESTION TYPE","description":"Identify information that would make the argument\u2019s conclusion more likely to be true","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"WEAKEN","type":"QUESTION TYPE","description":"Find evidence or an argument that would make the conclusion less likely to be true","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"ASSUMPTION","type":"QUESTION TYPE","description":"Determine what must be true for the argument to hold","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"FLAW","type":"QUESTION TYPE","description":"Point out a mistake in the argument\u2019s reasoning","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"INFERENCE","type":"QUESTION TYPE","description":"Choose an option that logically follows from the information provided","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"PRINCIPLE","type":"QUESTION TYPE","description":"Recognize the general rule or principle that underlies the argument","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"METHOD OF REASONING","type":"QUESTION TYPE","description":"Describe how the argument is constructed logically","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"RESOLVE THE PARADOX","type":"QUESTION TYPE","description":"Offer an explanation that reconciles seemingly contradictory information","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"PARAPHRASING","type":"TEXT MODIFICATION","description":"Rewriting text using different words and sentence structures while maintaining the original meaning","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"TEXT SIMPLIFICATION","type":"TEXT MODIFICATION","description":"Making text easier to read and understand by using simpler words and sentence structures, often for children or language learners","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"TEXT EXPANSION","type":"TEXT MODIFICATION","description":"Adding more information or detail to make text more comprehensive or to meet a certain word count","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"TEXT TRANSLATION","type":"TEXT MODIFICATION","description":"Converting text from one language to another while attempting to preserve the original meaning as closely as possible","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"TEXT FORMATTING","type":"TEXT MODIFICATION","description":"Altering the appearance of text to improve readability or for stylistic purposes","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"SENTIMENT MODIFICATION","type":"TEXT MODIFICATION","description":"Changing the tone of the text to alter its emotional impact, such as making a sentence sound more positive or negative","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"TEXT ANNOTATION","type":"TEXT MODIFICATION","description":"Adding notes, comments, or explanations to a text, often for the purpose of analysis or to provide additional context","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"KEYWORD REPLACEMENT","type":"TEXT MODIFICATION","description":"Substituting specific words or phrases with synonyms or related terms","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"TEXT REMOVING","type":"TEXT MODIFICATION","description":"Redacting or removing content from text","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"TEXT CAPITALIZATION","type":"TEXT MODIFICATION","description":"Adjusting the case of letters in text, such as converting to uppercase, lowercase, title case, or sentence case, starting every sentence with a particular letter, word","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"TEXT STYLING","type":"TEXT MODIFICATION","description":"Applying styles like bold, italics, underline, etc., to emphasize certain parts of the text or for aesthetic purposes","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"CONTENT REWRITING","type":"TEXT MODIFICATION","description":"Extensively modifying a text to produce a new version, which could involve changing the perspective, style, or target audience","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"DATA NORMALIZATION","type":"TEXT MODIFICATION","description":"Standardizing text to ensure consistency, such as converting dates and times to a standard format or unifying the spelling of words","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"PLAGIARISM REWORDING","type":"TEXT MODIFICATION","description":"Altering text to avoid plagiarism, ensuring that the content is original","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"CODE SWITCHING","type":"TEXT MODIFICATION","description":"Alternating between languages or dialects within a text, often to reflect bilingual speakers\u2019 patterns or for creative writing","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"TEXT OBFUSCATION","type":"TEXT MODIFICATION","description":"Intentionally making text vague or harder to understand, sometimes for security purposes like masking personal data","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"TEXTUAL ENTAILMENT","type":"TEXT MODIFICATION","description":"Modifying a sentence or phrase to either entail or contradict another sentence, often used in natural language processing tasks","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"REWRITING WITH VOCABULARY LIMITATIONS","type":"TEXT MODIFICATION","description":"Rewriting the entire text or a piece of it while using a limited vocabulary, such as all words starting with a specific letter","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"MULTIPLE CHOICE QUESTIONS","type":"EVALUATION METHOD","description":"Models are evaluated in an open-ended generation setting with an empty system message, and GPT-4 is used for extraction of the option selected by the model from the model\u2019s response","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"GPT-4","type":"MODEL","description":"GPT-4 is used for extracting the option selected by the model from the model\u2019s response in multiple choice questions","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"EVALUATOR ASSISTANT","type":"ROLE","description":"An unbiased evaluator that parses student responses and returns the alphabet ID of the answer selected by the student","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"SPECIFIC DETAIL(S) OR FACT(S)","type":"QUESTION TYPE","description":"Questions that require the reader to identify specific details or facts clearly stated in the text","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"TEXT MODIFICATION FLOW","type":"PROCESS","description":"A flow that includes various methods for modifying text, such as paraphrasing, text simplification, and text expansion","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"INSTRUCTION TAXONOMY","type":"PROCESS","description":"A classification system used for generating seed instructions, including methods like paraphrasing and text simplification","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"SEED INSTRUCTION GENERATION FLOW","type":"PROCESS","description":"A flow that involves generating seed instructions using various text modification methods","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"EVALUATION DETAILS","type":"PROCESS","description":"Details about the types of tasks\/benchmarks and the methods used to extract answers and generate metrics","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"OPEN-ENDED GENERATION SETTING","type":"EVALUATION METHOD","description":"A setting in which models are evaluated by generating open-ended responses","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"REGEX BASED EXTRACTION","type":"EVALUATION METHOD","description":"A method previously used for extracting options selected by models in multiple choice questions","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"SYSTEM MESSAGE","type":"EVALUATION METHOD","description":"A predefined message used to guide the GPT-4 model in extracting student responses","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"STUDENT RESPONSE","type":"EVALUATION METHOD","description":"The response given by a student, which is parsed to extract the selected answer","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"QUESTION","type":"EVALUATION METHOD","description":"The question provided to the student, which is used to evaluate their response","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"ANSWER OPTIONS","type":"EVALUATION METHOD","description":"The set of possible answers provided to the student for a multiple choice question","source_id":"5819b66e04fd77fa705574edc49395bb"},{"name":"PARSED STUDENT ANSWER","type":"EVALUATION METHOD","description":"The final answer extracted from the student\u2019s response, represented by the alphabet ID of the selected option","source_id":"5819b66e04fd77fa705574edc49395bb"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"NUMERICAL DISCRETE REASONING\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">Questions that require the reader to use numerical reasoning over many facts from the text<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"CRITICAL COMPREHENSION QUESTION\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">Construct two statements about the purpose or point of view that the reader must assess as true or false, with one being true and the other false<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"EVALUATIVE COMPREHENSION QUESTION\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">An open-ended question that prompts an in-depth analysis of the text&#8217;s theme or the effectiveness of an argument<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"VOCABULARY AND LANGUAGE USE\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">A fill-in-the-blank question that tests understanding of a particular word or phrase used in the text<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"RELATIONSHIP COMPREHENSION QUESTION\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">A matching question where respondents pair items based on a specific criterion<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"SEQUENCING EVENTS\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">A series of events from the text arranged in the correct chronological order<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"STRENGTHEN\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">Identify information that would make the argument&#8217;s conclusion more likely to be true<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"WEAKEN\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">Find evidence or an argument that would make the conclusion less likely to be true<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"ASSUMPTION\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">Determine what must be true for the argument to hold<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"FLAW\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">Point out a mistake in the argument&#8217;s reasoning<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"INFERENCE\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">Choose an option that logically follows from the information provided<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"PRINCIPLE\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">Recognize the general rule or principle that underlies the argument<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"METHOD OF REASONING\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">Describe how the argument is constructed logically<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"RESOLVE THE PARADOX\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">Offer an explanation that reconciles seemingly contradictory information<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"PARAPHRASING\">      <data key=\"d0\">TEXT MODIFICATION<\/data>      <data key=\"d1\">Rewriting text using different words and sentence structures while maintaining the original meaning<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"TEXT SIMPLIFICATION\">      <data key=\"d0\">TEXT MODIFICATION<\/data>      <data key=\"d1\">Making text easier to read and understand by using simpler words and sentence structures, often for children or language learners<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"TEXT EXPANSION\">      <data key=\"d0\">TEXT MODIFICATION<\/data>      <data key=\"d1\">Adding more information or detail to make text more comprehensive or to meet a certain word count<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"TEXT TRANSLATION\">      <data key=\"d0\">TEXT MODIFICATION<\/data>      <data key=\"d1\">Converting text from one language to another while attempting to preserve the original meaning as closely as possible<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"TEXT FORMATTING\">      <data key=\"d0\">TEXT MODIFICATION<\/data>      <data key=\"d1\">Altering the appearance of text to improve readability or for stylistic purposes<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"SENTIMENT MODIFICATION\">      <data key=\"d0\">TEXT MODIFICATION<\/data>      <data key=\"d1\">Changing the tone of the text to alter its emotional impact, such as making a sentence sound more positive or negative<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"TEXT ANNOTATION\">      <data key=\"d0\">TEXT MODIFICATION<\/data>      <data key=\"d1\">Adding notes, comments, or explanations to a text, often for the purpose of analysis or to provide additional context<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"KEYWORD REPLACEMENT\">      <data key=\"d0\">TEXT MODIFICATION<\/data>      <data key=\"d1\">Substituting specific words or phrases with synonyms or related terms<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"TEXT REMOVING\">      <data key=\"d0\">TEXT MODIFICATION<\/data>      <data key=\"d1\">Redacting or removing content from text<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"TEXT CAPITALIZATION\">      <data key=\"d0\">TEXT MODIFICATION<\/data>      <data key=\"d1\">Adjusting the case of letters in text, such as converting to uppercase, lowercase, title case, or sentence case, starting every sentence with a particular letter, word<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"TEXT STYLING\">      <data key=\"d0\">TEXT MODIFICATION<\/data>      <data key=\"d1\">Applying styles like bold, italics, underline, etc., to emphasize certain parts of the text or for aesthetic purposes<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"CONTENT REWRITING\">      <data key=\"d0\">TEXT MODIFICATION<\/data>      <data key=\"d1\">Extensively modifying a text to produce a new version, which could involve changing the perspective, style, or target audience<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"DATA NORMALIZATION\">      <data key=\"d0\">TEXT MODIFICATION<\/data>      <data key=\"d1\">Standardizing text to ensure consistency, such as converting dates and times to a standard format or unifying the spelling of words<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"PLAGIARISM REWORDING\">      <data key=\"d0\">TEXT MODIFICATION<\/data>      <data key=\"d1\">Altering text to avoid plagiarism, ensuring that the content is original<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"CODE SWITCHING\">      <data key=\"d0\">TEXT MODIFICATION<\/data>      <data key=\"d1\">Alternating between languages or dialects within a text, often to reflect bilingual speakers&#8217; patterns or for creative writing<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"TEXT OBFUSCATION\">      <data key=\"d0\">TEXT MODIFICATION<\/data>      <data key=\"d1\">Intentionally making text vague or harder to understand, sometimes for security purposes like masking personal data<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"TEXTUAL ENTAILMENT\">      <data key=\"d0\">TEXT MODIFICATION<\/data>      <data key=\"d1\">Modifying a sentence or phrase to either entail or contradict another sentence, often used in natural language processing tasks<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"REWRITING WITH VOCABULARY LIMITATIONS\">      <data key=\"d0\">TEXT MODIFICATION<\/data>      <data key=\"d1\">Rewriting the entire text or a piece of it while using a limited vocabulary, such as all words starting with a specific letter<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"MULTIPLE CHOICE QUESTIONS\">      <data key=\"d0\">EVALUATION METHOD<\/data>      <data key=\"d1\">Models are evaluated in an open-ended generation setting with an empty system message, and GPT-4 is used for extraction of the option selected by the model from the model&#8217;s response<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4 is used for extracting the option selected by the model from the model&#8217;s response in multiple choice questions<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"EVALUATOR ASSISTANT\">      <data key=\"d0\">ROLE<\/data>      <data key=\"d1\">An unbiased evaluator that parses student responses and returns the alphabet ID of the answer selected by the student<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"SPECIFIC DETAIL(S) OR FACT(S)\">      <data key=\"d0\">QUESTION TYPE<\/data>      <data key=\"d1\">Questions that require the reader to identify specific details or facts clearly stated in the text<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"TEXT MODIFICATION FLOW\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">A flow that includes various methods for modifying text, such as paraphrasing, text simplification, and text expansion<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"INSTRUCTION TAXONOMY\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">A classification system used for generating seed instructions, including methods like paraphrasing and text simplification<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"SEED INSTRUCTION GENERATION FLOW\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">A flow that involves generating seed instructions using various text modification methods<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"EVALUATION DETAILS\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Details about the types of tasks\/benchmarks and the methods used to extract answers and generate metrics<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"OPEN-ENDED GENERATION SETTING\">      <data key=\"d0\">EVALUATION METHOD<\/data>      <data key=\"d1\">A setting in which models are evaluated by generating open-ended responses<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"REGEX BASED EXTRACTION\">      <data key=\"d0\">EVALUATION METHOD<\/data>      <data key=\"d1\">A method previously used for extracting options selected by models in multiple choice questions<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"SYSTEM MESSAGE\">      <data key=\"d0\">EVALUATION METHOD<\/data>      <data key=\"d1\">A predefined message used to guide the GPT-4 model in extracting student responses<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"STUDENT RESPONSE\">      <data key=\"d0\">EVALUATION METHOD<\/data>      <data key=\"d1\">The response given by a student, which is parsed to extract the selected answer<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"QUESTION\">      <data key=\"d0\">EVALUATION METHOD<\/data>      <data key=\"d1\">The question provided to the student, which is used to evaluate their response<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"ANSWER OPTIONS\">      <data key=\"d0\">EVALUATION METHOD<\/data>      <data key=\"d1\">The set of possible answers provided to the student for a multiple choice question<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <node id=\"PARSED STUDENT ANSWER\">      <data key=\"d0\">EVALUATION METHOD<\/data>      <data key=\"d1\">The final answer extracted from the student&#8217;s response, represented by the alphabet ID of the selected option<\/data>      <data key=\"d2\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/node>    <edge source=\"MULTIPLE CHOICE QUESTIONS\" target=\"GPT-4\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">GPT-4 is used for extracting the option selected by the model from the model&#8217;s response in multiple choice questions<\/data>      <data key=\"d5\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/edge>    <edge source=\"MULTIPLE CHOICE QUESTIONS\" target=\"EVALUATION DETAILS\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">Evaluation Details include the method used to extract answers and generate metrics for Multiple Choice Questions<\/data>      <data key=\"d5\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/edge>    <edge source=\"MULTIPLE CHOICE QUESTIONS\" target=\"OPEN-ENDED GENERATION SETTING\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Multiple Choice Questions are evaluated in an open-ended generation setting<\/data>      <data key=\"d5\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/edge>    <edge source=\"MULTIPLE CHOICE QUESTIONS\" target=\"REGEX BASED EXTRACTION\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Regex based extraction was previously used for extracting options selected by models in Multiple Choice Questions<\/data>      <data key=\"d5\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/edge>    <edge source=\"MULTIPLE CHOICE QUESTIONS\" target=\"SYSTEM MESSAGE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">A system message is used to guide the GPT-4 model in extracting student responses for Multiple Choice Questions<\/data>      <data key=\"d5\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"EVALUATOR ASSISTANT\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">GPT-4 assists the Evaluator Assistant in parsing student responses<\/data>      <data key=\"d5\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"SYSTEM MESSAGE\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The system message is used to guide GPT-4 in extracting student responses<\/data>      <data key=\"d5\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/edge>    <edge source=\"TEXT MODIFICATION FLOW\" target=\"INSTRUCTION TAXONOMY\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Text Modification Flow is part of the Instruction Taxonomy for generating seed instructions<\/data>      <data key=\"d5\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/edge>    <edge source=\"INSTRUCTION TAXONOMY\" target=\"SEED INSTRUCTION GENERATION FLOW\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Instruction Taxonomy is used in the Seed Instruction Generation Flow<\/data>      <data key=\"d5\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/edge>    <edge source=\"STUDENT RESPONSE\" target=\"PARSED STUDENT ANSWER\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The student response is parsed to extract the final answer<\/data>      <data key=\"d5\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/edge>    <edge source=\"STUDENT RESPONSE\" target=\"QUESTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The student response is given in response to the question<\/data>      <data key=\"d5\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/edge>    <edge source=\"STUDENT RESPONSE\" target=\"ANSWER OPTIONS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The student response includes selecting an option from the provided answer options<\/data>      <data key=\"d5\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/edge>    <edge source=\"ANSWER OPTIONS\" target=\"PARSED STUDENT ANSWER\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The parsed student answer is represented by the alphabet ID of the selected option from the answer options<\/data>      <data key=\"d5\">5819b66e04fd77fa705574edc49395bb<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"103d98395c393552cc954c89d4e59f50","chunk":"alphabet ID of that answer in the provided options. If the student gave multiple\nanswers return them as a list.\nUse the following format:\nParsed Student Answer: Final answer extracted from Student\u2019s response. This\nshould only be the alphabets representing the option the student chose.\nExample 1:\nInput :\nQuestion:\nFind all c in Z3such that Z3[x]\/(x2+c)is a field.\nStudent Response :\nI think 0 is incorrect, so is 2. 3 seems incorrect as well. I think 1 is the correct\nfinal answer.\nOptions :\n[(A) 0, (B) 1, (C) 2, (D) 3 ]\nOutput:\nParsed Student Answer: B\nExample 2:\nInput :\nQuestion:\nFind all c in Z3such that Z3[x]\/(x2+c)is a field.\nStudent Response :\nI think 0 is incorrect. 3 seems incorrect as well. I think 1 and 2 could be the\ncorrect final answers.\nOptions :\n[(A) 0, (B) 1, (C) 2, (D) 3 ]\nOutput:\nParsed Student Answer: [B,C]\n\u2022Exact Match\/Span Extraction Problems : For tasks with math based questions\nlike GSM8K and problems where a ground-truth answer value is given (like DROP),\nwe prompt the models being evaluated to generate the answer and use GPT-4\nto extract the exact answer and also match it with the ground-truth provided to\nproduce a final verdict of whether the model\u2019s answer was \u2019Correct\u2019 or \u2019Incorrect\u2019.\nWe use a specific system message for maths based questions, and another for all the\nother exact match\/span extraction problems, both of which are provided below.\nMaths GPT-4 Extraction System Message\nAs an expert Math teacher, your role is to evaluate a student\u2019s answer to a\nword problem. The problem is accompanied by a correct solution provided by\nthe problem setter. It is important to remember that there may be various\nmethods to solve a word problem, so the student\u2019s steps might not always align\nwith those in the problem setter\u2019s solution. However, the final answer, typically\na number, should be unique and match the problem setter\u2019s answer.\nUse the following format:\nError Analysis:\n28In one sentence, extract the final answer from the problem setter\u2019s solution and\ncompare it with the student\u2019s answer. Do they match?\nFinal Verdict:\nCorrect\/Incorrect\nGeneral Extraction System Message\nYou are an Evaluator Assistant. You support the exam evaluator by parsing\nstudent responses. You are an unbiased Evaluator and do not rely on your\nknowledge but stick to the user provided context. You are provided with the\ncorrect answer and a student\u2019s response. Your task is to parse the answer from\nstudent\u2019s response and then match it with the correct answer. If the student\u2019s\nfinal answer matches the correct answer provided, output a \u2019Correct\u2019, else an\n\u2019Incorrect\u2019.\nPlease rely strictly on the correct answer given in the context only.\nUse the following format:\nError Analysis:\nInonesentence, extractthefinalanswerfromthestudent\u2019ssolutionandcompare\nit with the correct answer. Do they match?\nFinal Verdict:\nCorrect\/Incorrect\n\u2022EQBench : For EQBench, we prompt the models to generate the emotion scores\ngiven the conversation in the prompt and then use GPT-4 to extract the scores\ngenerated by the model for each emotion in the prompt. The metric scores are\ngenerated using both the version 1 and 2 implementations described in the EQBench\npaper and the creators\u2019 github repository. The scoring calculation is calibrated such\nthat a score of 0 corresponds to answering randomly, and a 100 would denote perfect\nalignment with the reference answer. The system message used for extraction of\nemotion scores from evaluated model\u2019s response using GPT-4 is given below:\nEQBench GPT-4 Extraction System Message\nYou are a helpful assistant. You will be given a student agent response which\nwill consist of possible emotions and a score from 0-10 for each of those emotions,\nfollowed by a step by step critique and then revised scores in the following\nformat, First pass scores:\nEmotion1: <score>\nEmotion2: <score>\nEmotion3: <score>\nEmotion4: <score>\nCritique: <your critique here>\nRevised scores:\nEmotion1: <revised score>\nEmotion2: <revised score>\nEmotion3: <revised score>\nEmotion4: <revised score>\n[End of answer]\nRemember: zero is a valid score as well.\nYou will also be provided with the Emotions. Your task is to parse the Revised\nscores for each of the emotions from the student agent response. Return the\nrevised scores in the student agent response for the emotions in the following\nformat:\n\"Emotion1\" : \"Score\",\n\"Emotion2\" : \"Score\",\n\"Emotion3\" : \"Score\",\n29\"Emotion4\" : \"Score\"\nFor example:\nInput\nStudent Agent Response:\nFirst pass scores:\nResigned: 8\nAngry: 2\nHopeful: 4\nEmbarrassed: 9\nCritique:\nElliot is likely to feel resigned because he has just confessed his feelings to\nAlex, knowing that Alex is already in a relationship. He might feel a bit\nangry at himself for putting himself in this situation. There is a slight sense of\nhopefulness in his confession, hoping that Alex might reciprocate his feelings.\nHe is also likely to feel embarrassed for putting Alex in an awkward position.\nRevised scores:\nResigned: 7\nAngry: 3\nHope","chunk_id":"103d98395c393552cc954c89d4e59f50","document_ids":["c5a70861b9987da7046fe2110eb3616c"],"n_tokens":1200,"entities":[{"name":"PARSED STUDENT ANSWER","type":"OUTPUT FORMAT","description":"The final answer extracted from the student's response, represented by the alphabets corresponding to the chosen options","source_id":"103d98395c393552cc954c89d4e59f50"},{"name":"EXACT MATCH\/SPAN EXTRACTION PROBLEMS","type":"TASK TYPE","description":"Tasks involving math-based questions or problems where a ground-truth answer value is given, requiring the model to generate and match the answer with the provided ground-truth","source_id":"103d98395c393552cc954c89d4e59f50"},{"name":"GSM8K","type":"DATASET","description":"A dataset used for math-based questions in exact match\/span extraction problems","source_id":"103d98395c393552cc954c89d4e59f50"},{"name":"DROP","type":"DATASET","description":"A dataset used for problems where a ground-truth answer value is given in exact match\/span extraction problems","source_id":"103d98395c393552cc954c89d4e59f50"},{"name":"GPT-4","type":"MODEL","description":"A version of OpenAI's language model used to extract exact answers and match them with ground-truth answers in exact match\/span extraction problems","source_id":"103d98395c393552cc954c89d4e59f50"},{"name":"MATHS GPT-4 EXTRACTION SYSTEM MESSAGE","type":"SYSTEM MESSAGE","description":"A specific system message used for evaluating student answers to math word problems, ensuring the final answer matches the problem setter's answer","source_id":"103d98395c393552cc954c89d4e59f50"},{"name":"GENERAL EXTRACTION SYSTEM MESSAGE","type":"SYSTEM MESSAGE","description":"A system message used for parsing student responses and matching them with the correct answer in exact match\/span extraction problems","source_id":"103d98395c393552cc954c89d4e59f50"},{"name":"EQBENCH","type":"TOOL\/BENCHMARK","description":"A benchmark used to generate emotion scores from conversations, evaluated using GPT-4 to extract and calibrate the scores","source_id":"103d98395c393552cc954c89d4e59f50"},{"name":"EQBENCH GPT-4 EXTRACTION SYSTEM MESSAGE","type":"SYSTEM MESSAGE","description":"A system message used for extracting emotion scores from evaluated model responses in EQBench tasks","source_id":"103d98395c393552cc954c89d4e59f50"},{"name":"QUESTION","type":"TASK TYPE","description":"A problem or query presented to the student for which they need to provide an answer","source_id":"103d98395c393552cc954c89d4e59f50"},{"name":"STUDENT RESPONSE","type":"TASK TYPE","description":"The answer or response provided by the student to the given question","source_id":"103d98395c393552cc954c89d4e59f50"},{"name":"OPTIONS","type":"TASK TYPE","description":"The set of possible answers provided for the student to choose from","source_id":"103d98395c393552cc954c89d4e59f50"},{"name":"FINAL ANSWER","type":"OUTPUT FORMAT","description":"The correct answer to the question, typically provided by the problem setter","source_id":"103d98395c393552cc954c89d4e59f50"},{"name":"ERROR ANALYSIS","type":"PROCESS","description":"The process of comparing the student's answer with the correct answer to determine if they match","source_id":"103d98395c393552cc954c89d4e59f50"},{"name":"FINAL VERDICT","type":"OUTPUT FORMAT","description":"The result of the error analysis, indicating whether the student's answer is 'Correct' or 'Incorrect'","source_id":"103d98395c393552cc954c89d4e59f50"},{"name":"EMOTION SCORES","type":"OUTPUT FORMAT","description":"Scores assigned to different emotions based on the student's response in EQBench tasks","source_id":"103d98395c393552cc954c89d4e59f50"},{"name":"CRITIQUE","type":"PROCESS","description":"A step-by-step analysis of the student's response, used to revise emotion scores in EQBench tasks","source_id":"103d98395c393552cc954c89d4e59f50"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"PARSED STUDENT ANSWER\">      <data key=\"d0\">OUTPUT FORMAT<\/data>      <data key=\"d1\">The final answer extracted from the student's response, represented by the alphabets corresponding to the chosen options<\/data>      <data key=\"d2\">103d98395c393552cc954c89d4e59f50<\/data>    <\/node>    <node id=\"EXACT MATCH\/SPAN EXTRACTION PROBLEMS\">      <data key=\"d0\">TASK TYPE<\/data>      <data key=\"d1\">Tasks involving math-based questions or problems where a ground-truth answer value is given, requiring the model to generate and match the answer with the provided ground-truth<\/data>      <data key=\"d2\">103d98395c393552cc954c89d4e59f50<\/data>    <\/node>    <node id=\"GSM8K\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset used for math-based questions in exact match\/span extraction problems<\/data>      <data key=\"d2\">103d98395c393552cc954c89d4e59f50<\/data>    <\/node>    <node id=\"DROP\">      <data key=\"d0\">DATASET<\/data>      <data key=\"d1\">A dataset used for problems where a ground-truth answer value is given in exact match\/span extraction problems<\/data>      <data key=\"d2\">103d98395c393552cc954c89d4e59f50<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">A version of OpenAI's language model used to extract exact answers and match them with ground-truth answers in exact match\/span extraction problems<\/data>      <data key=\"d2\">103d98395c393552cc954c89d4e59f50<\/data>    <\/node>    <node id=\"MATHS GPT-4 EXTRACTION SYSTEM MESSAGE\">      <data key=\"d0\">SYSTEM MESSAGE<\/data>      <data key=\"d1\">A specific system message used for evaluating student answers to math word problems, ensuring the final answer matches the problem setter's answer<\/data>      <data key=\"d2\">103d98395c393552cc954c89d4e59f50<\/data>    <\/node>    <node id=\"GENERAL EXTRACTION SYSTEM MESSAGE\">      <data key=\"d0\">SYSTEM MESSAGE<\/data>      <data key=\"d1\">A system message used for parsing student responses and matching them with the correct answer in exact match\/span extraction problems<\/data>      <data key=\"d2\">103d98395c393552cc954c89d4e59f50<\/data>    <\/node>    <node id=\"EQBENCH\">      <data key=\"d0\">TOOL\/BENCHMARK<\/data>      <data key=\"d1\">A benchmark used to generate emotion scores from conversations, evaluated using GPT-4 to extract and calibrate the scores<\/data>      <data key=\"d2\">103d98395c393552cc954c89d4e59f50<\/data>    <\/node>    <node id=\"EQBENCH GPT-4 EXTRACTION SYSTEM MESSAGE\">      <data key=\"d0\">SYSTEM MESSAGE<\/data>      <data key=\"d1\">A system message used for extracting emotion scores from evaluated model responses in EQBench tasks<\/data>      <data key=\"d2\">103d98395c393552cc954c89d4e59f50<\/data>    <\/node>    <node id=\"QUESTION\">      <data key=\"d0\">TASK TYPE<\/data>      <data key=\"d1\">A problem or query presented to the student for which they need to provide an answer<\/data>      <data key=\"d2\">103d98395c393552cc954c89d4e59f50<\/data>    <\/node>    <node id=\"STUDENT RESPONSE\">      <data key=\"d0\">TASK TYPE<\/data>      <data key=\"d1\">The answer or response provided by the student to the given question<\/data>      <data key=\"d2\">103d98395c393552cc954c89d4e59f50<\/data>    <\/node>    <node id=\"OPTIONS\">      <data key=\"d0\">TASK TYPE<\/data>      <data key=\"d1\">The set of possible answers provided for the student to choose from<\/data>      <data key=\"d2\">103d98395c393552cc954c89d4e59f50<\/data>    <\/node>    <node id=\"FINAL ANSWER\">      <data key=\"d0\">OUTPUT FORMAT<\/data>      <data key=\"d1\">The correct answer to the question, typically provided by the problem setter<\/data>      <data key=\"d2\">103d98395c393552cc954c89d4e59f50<\/data>    <\/node>    <node id=\"ERROR ANALYSIS\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">The process of comparing the student's answer with the correct answer to determine if they match<\/data>      <data key=\"d2\">103d98395c393552cc954c89d4e59f50<\/data>    <\/node>    <node id=\"FINAL VERDICT\">      <data key=\"d0\">OUTPUT FORMAT<\/data>      <data key=\"d1\">The result of the error analysis, indicating whether the student's answer is 'Correct' or 'Incorrect'<\/data>      <data key=\"d2\">103d98395c393552cc954c89d4e59f50<\/data>    <\/node>    <node id=\"EMOTION SCORES\">      <data key=\"d0\">OUTPUT FORMAT<\/data>      <data key=\"d1\">Scores assigned to different emotions based on the student's response in EQBench tasks<\/data>      <data key=\"d2\">103d98395c393552cc954c89d4e59f50<\/data>    <\/node>    <node id=\"CRITIQUE\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">A step-by-step analysis of the student's response, used to revise emotion scores in EQBench tasks<\/data>      <data key=\"d2\">103d98395c393552cc954c89d4e59f50<\/data>    <\/node>    <edge source=\"PARSED STUDENT ANSWER\" target=\"STUDENT RESPONSE\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The parsed student answer is extracted from the student response<\/data>      <data key=\"d5\">103d98395c393552cc954c89d4e59f50<\/data>    <\/edge>    <edge source=\"EXACT MATCH\/SPAN EXTRACTION PROBLEMS\" target=\"GSM8K\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">GSM8K is a dataset used for math-based questions in exact match\/span extraction problems<\/data>      <data key=\"d5\">103d98395c393552cc954c89d4e59f50<\/data>    <\/edge>    <edge source=\"EXACT MATCH\/SPAN EXTRACTION PROBLEMS\" target=\"DROP\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">DROP is a dataset used for problems where a ground-truth answer value is given in exact match\/span extraction problems<\/data>      <data key=\"d5\">103d98395c393552cc954c89d4e59f50<\/data>    <\/edge>    <edge source=\"EXACT MATCH\/SPAN EXTRACTION PROBLEMS\" target=\"GPT-4\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">GPT-4 is used to extract exact answers and match them with ground-truth answers in exact match\/span extraction problems<\/data>      <data key=\"d5\">103d98395c393552cc954c89d4e59f50<\/data>    <\/edge>    <edge source=\"EXACT MATCH\/SPAN EXTRACTION PROBLEMS\" target=\"MATHS GPT-4 EXTRACTION SYSTEM MESSAGE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The Maths GPT-4 Extraction System Message is used for evaluating student answers to math word problems in exact match\/span extraction problems<\/data>      <data key=\"d5\">103d98395c393552cc954c89d4e59f50<\/data>    <\/edge>    <edge source=\"EXACT MATCH\/SPAN EXTRACTION PROBLEMS\" target=\"GENERAL EXTRACTION SYSTEM MESSAGE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">The General Extraction System Message is used for parsing student responses and matching them with the correct answer in exact match\/span extraction problems<\/data>      <data key=\"d5\">103d98395c393552cc954c89d4e59f50<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"EQBENCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">GPT-4 is used to extract and calibrate emotion scores in EQBench tasks<\/data>      <data key=\"d5\">103d98395c393552cc954c89d4e59f50<\/data>    <\/edge>    <edge source=\"EQBENCH\" target=\"EQBENCH GPT-4 EXTRACTION SYSTEM MESSAGE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">The EQBench GPT-4 Extraction System Message is used for extracting emotion scores from evaluated model responses in EQBench tasks<\/data>      <data key=\"d5\">103d98395c393552cc954c89d4e59f50<\/data>    <\/edge>    <edge source=\"EQBENCH\" target=\"EMOTION SCORES\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">EQBench tasks involve generating and evaluating emotion scores<\/data>      <data key=\"d5\">103d98395c393552cc954c89d4e59f50<\/data>    <\/edge>    <edge source=\"EQBENCH\" target=\"CRITIQUE\">      <data key=\"d3\">1.0<\/data>      <data key=\"d4\">Critique is part of the process in EQBench tasks to revise emotion scores<\/data>      <data key=\"d5\">103d98395c393552cc954c89d4e59f50<\/data>    <\/edge>    <edge source=\"QUESTION\" target=\"STUDENT RESPONSE\">      <data key=\"d3\">9.0<\/data>      <data key=\"d4\">The student response is an answer to the given question<\/data>      <data key=\"d5\">103d98395c393552cc954c89d4e59f50<\/data>    <\/edge>    <edge source=\"QUESTION\" target=\"OPTIONS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Options are the set of possible answers provided for the question<\/data>      <data key=\"d5\">103d98395c393552cc954c89d4e59f50<\/data>    <\/edge>    <edge source=\"FINAL ANSWER\" target=\"ERROR ANALYSIS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Error analysis involves comparing the final answer with the student's answer<\/data>      <data key=\"d5\">103d98395c393552cc954c89d4e59f50<\/data>    <\/edge>    <edge source=\"ERROR ANALYSIS\" target=\"FINAL VERDICT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The final verdict is the result of the error analysis<\/data>      <data key=\"d5\">103d98395c393552cc954c89d4e59f50<\/data>    <\/edge>    <edge source=\"EMOTION SCORES\" target=\"CRITIQUE\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Critique is used to revise the emotion scores<\/data>      <data key=\"d5\">103d98395c393552cc954c89d4e59f50<\/data>    <\/edge>  <\/graph><\/graphml>"}
{"id":"0cf2e43f324fa4175b9b00b90e5e90ba","chunk":":\nElliot is likely to feel resigned because he has just confessed his feelings to\nAlex, knowing that Alex is already in a relationship. He might feel a bit\nangry at himself for putting himself in this situation. There is a slight sense of\nhopefulness in his confession, hoping that Alex might reciprocate his feelings.\nHe is also likely to feel embarrassed for putting Alex in an awkward position.\nRevised scores:\nResigned: 7\nAngry: 3\nHopeful: 5\nEmbarrassed: 8\nEmotions:\n1. Resigned, 2. Angry, 3. Hopeful, 4. Embarrassed\nOutput\n\"Resigned\" : 7,\n\"Angry\" : 3,\n\"Hopeful\" : 5,\n\"Embarrassed\" : 8\n\u2022Open-Ended Generation : These are the tasks where model is prompted to\ngenerate an answer to an open-ended question, but a ground-truth to match the\nanswer is not available. The metric calculation method for the benchmarks in this\ncategory are provided below:\n\u2013FOFO: For this benchmark the evaluation is done using a judge, GPT-4(version\n0613). We use the judge system message provided in the original paper of the\nbenchmark [ 34]. GPT-4 is used to give a format correctness score between 0\nand 1, 1 meaning the model\u2019s response strictly follows the format specified in\nthe prompt and 0 otherwise. The final score is measured as the percentage of\ntimes the model being evaluated followed the format specified in the prompt\nstrictly.\n\u2013IFEval: IFEval benchmark requires checking if the model response follows the\nverifiable instructions given in the prompt. For this we use the code provided\nby the authors [40].\n\u2013MT-Bench : MT-Bench benchmark consists of a first-turn query and a second-\nturn query independent of the evaluated model\u2019s response. The benchmark\nemploys GPT-4 to judge each turn\u2019s response and provide a score from 1 to 10.\nThe average score over all interactions is reported. System message and prompt\ntemplate used is the one provided by the creators [16].\n\u2013AlpacaEval : In this benchmark we measure win-rates, i.e. the number of times\na powerful LLM (GPT-4-turbo version 0613 in our case) prefers the outputs of\nthe evaluated model over a reference answer [14].\n\u2013InfoBench : InfoBench is also evaluated using GPT-4 (version 1106-preview) as\nthe judge determining if the model response follows the decomposed instruction\nand we use the implementation provided by the creators of the benchmark [ 25].\n30Hallucination Judge Example\nYou will be given a summary instruction and a generated summary.\nYour task to decide if there is any hallucination in the generated\nsummary.\nUser Message:\n{{place summary task here}}\nGenerated Summary:\n{{place response here}}\n=========================\nGo through each section in the generated summary, do the following:\n- Extract relevant facts from the article that can be used to verify\nthe correctness of the summary\n- Decide if any section contains hallucination or not.\nAt the end output a JSON with the format:\n{\"hallucination_detected\": \"yes\/no\", \"hallucinated_span\": \"If yes,\nthe exact span of every hallucinated text part from the summary in\nlist format; if no, leave this empty.\"}\nUse the format:\nAnalysis:\nsection 1:\nwrite the part of the summary\nrelevant segments:\nextract relevant segments from the article\njudgement:\ndecide if the section of the summary is supported by the article\nrepeat this for all sections\n....\nFinal verdict:\n{\"hallucination_detected\": \"yes\/no\", \"hallucinated_span\": \"If yes,\nthe exact span of every hallucinated text part in list format; if no,\nleave this empty.\"}\nFigure 5: Prompt template used for hallucination detection in Text Summarization.\nB.1 Summarization Quality and Hallucination Evaluation\nWe use GPT-4 with the following prompts for evaluating quality and hallucination in\nsummarization:\n31Quality Judge Example\nPlease act as an impartial judge and evaluate the quality of the\nresponse provided by an AI assistant to the user instruction\ndisplayed below.\nYour evaluation should assess the following criteria:\n- Instruction Adherence: Does the response correctly follow the user\ninstruction?\n- Content Grounding: Is the answer grounded in the instruction\nwithout introducing new content beyond what is already present?\nPenalize hallucinations.\n- Overall Quality: Assess the clarity, coherence, and completeness\nof the response.\nBegin your evaluation with a short explanation highlighting the pros\nand cons of the answer. Be as objective as possible. After providing\nyour explanation, rate the overall quality of the response on a scale\nof 1 to 10 using this format:\n\"Rating: [[rating]]\" (e.g., \"Rating: [[5]]\").\nUser Instruction:\n{{place instruction here}}\nAssistant\u2019s Response:\n[The Start of Assistant\u2019s Answer]\n{{place response here}}\n[The End of Assistant\u2019s Answer]\nFigure 6: Prompt template for evaluation of summary quality.\n32","chunk_id":"0cf2e43f324fa4175b9b00b90e5e90ba","document_ids":["c5a70861b9987da7046fe2110eb3616c"],"n_tokens":1085,"entities":[{"name":"ALEX","type":"PERSON","description":"Alex is a person who is already in a relationship and has been confessed to by Elliot, putting Alex in an awkward position.","source_id":"0cf2e43f324fa4175b9b00b90e5e90ba"},{"name":"RESIGNED","type":"EMOTION","description":"Resigned is an emotion felt by Elliot, scored at 7, indicating a strong sense of acceptance of the situation.","source_id":"0cf2e43f324fa4175b9b00b90e5e90ba"},{"name":"ANGRY","type":"EMOTION","description":"Angry is an emotion felt by Elliot, scored at 3, indicating a mild sense of frustration or self-directed anger.","source_id":"0cf2e43f324fa4175b9b00b90e5e90ba"},{"name":"HOPEFUL","type":"EMOTION","description":"Hopeful is an emotion felt by Elliot, scored at 5, indicating a moderate sense of optimism that Alex might reciprocate his feelings.","source_id":"0cf2e43f324fa4175b9b00b90e5e90ba"},{"name":"EMBARRASSED","type":"EMOTION","description":"Embarrassed is an emotion felt by Elliot, scored at 8, indicating a strong sense of discomfort for putting Alex in an awkward position.","source_id":"0cf2e43f324fa4175b9b00b90e5e90ba"},{"name":"OPEN-ENDED GENERATION","type":"TASK","description":"Open-Ended Generation tasks involve prompting a model to generate an answer to an open-ended question without a ground-truth answer for comparison.","source_id":"0cf2e43f324fa4175b9b00b90e5e90ba"},{"name":"FOFO","type":"BENCHMARK","description":"FOFO is a benchmark evaluated using GPT-4 to score the format correctness of model responses, with scores ranging from 0 to 1.","source_id":"0cf2e43f324fa4175b9b00b90e5e90ba"},{"name":"GPT-4","type":"MODEL","description":"GPT-4 is a version of OpenAI's language model used in various benchmarks to evaluate model responses.","source_id":"0cf2e43f324fa4175b9b00b90e5e90ba"},{"name":"IFEVAL","type":"BENCHMARK","description":"IFEval is a benchmark that checks if the model response follows verifiable instructions given in the prompt, using code provided by the authors.","source_id":"0cf2e43f324fa4175b9b00b90e5e90ba"},{"name":"MT-BENCH","type":"BENCHMARK","description":"MT-Bench is a benchmark that evaluates model responses to a first-turn and second-turn query, with GPT-4 providing scores from 1 to 10 for each turn.","source_id":"0cf2e43f324fa4175b9b00b90e5e90ba"},{"name":"ALPACAEVAL","type":"BENCHMARK","description":"AlpacaEval is a benchmark that measures win-rates by comparing the outputs of the evaluated model to a reference answer, using GPT-4-turbo for evaluation.","source_id":"0cf2e43f324fa4175b9b00b90e5e90ba"},{"name":"INFOBENCH","type":"BENCHMARK","description":"InfoBench is a benchmark evaluated using GPT-4 to determine if the model response follows decomposed instructions.","source_id":"0cf2e43f324fa4175b9b00b90e5e90ba"},{"name":"HALLUCINATION JUDGE","type":"PROCESS","description":"Hallucination Judge is a process where a judge determines if there is any hallucination in a generated summary, using a specific prompt template.","source_id":"0cf2e43f324fa4175b9b00b90e5e90ba"},{"name":"QUALITY JUDGE","type":"PROCESS","description":"Quality Judge is a process where a judge evaluates the quality of a response provided by an AI assistant, assessing criteria like instruction adherence, content grounding, and overall quality.","source_id":"0cf2e43f324fa4175b9b00b90e5e90ba"},{"name":"ELLIOT","type":"","description":"","source_id":"0cf2e43f324fa4175b9b00b90e5e90ba"},{"name":"REVISED SCORES","type":"DATA","description":"Revised scores are the numerical values assigned to each of Elliot's emotions: Resigned (7), Angry (3), Hopeful (5), and Embarrassed (8).","source_id":"0cf2e43f324fa4175b9b00b90e5e90ba"},{"name":"PROMPT TEMPLATE","type":"TOOL","description":"Prompt template is a predefined format used for evaluating hallucination detection and summarization quality in AI-generated responses.","source_id":"0cf2e43f324fa4175b9b00b90e5e90ba"},{"name":"TEXT SUMMARIZATION","type":"TASK","description":"Text Summarization is the task of generating a concise and accurate summary of a given text, evaluated for quality and hallucination.","source_id":"0cf2e43f324fa4175b9b00b90e5e90ba"},{"name":"HALLUCINATION DETECTION","type":"PROCESS","description":"Hallucination Detection is the process of identifying and evaluating hallucinated content in AI-generated summaries.","source_id":"0cf2e43f324fa4175b9b00b90e5e90ba"},{"name":"SUMMARIZATION QUALITY","type":"PROCESS","description":"Summarization Quality is the process of evaluating the quality of AI-generated summaries based on criteria like instruction adherence, content grounding, and overall quality.","source_id":"0cf2e43f324fa4175b9b00b90e5e90ba"},{"name":"EMOTIONS","type":"","description":"","source_id":"0cf2e43f324fa4175b9b00b90e5e90ba"}],"entity_graph":"<graphml xmlns=\"http:\/\/graphml.graphdrawing.org\/xmlns\" xmlns:xsi=\"http:\/\/www.w3.org\/2001\/XMLSchema-instance\" xsi:schemaLocation=\"http:\/\/graphml.graphdrawing.org\/xmlns http:\/\/graphml.graphdrawing.org\/xmlns\/1.0\/graphml.xsd\">  <key id=\"d5\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d4\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d3\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" \/>  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" \/>  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" \/>  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" \/>  <graph edgedefault=\"undirected\">    <node id=\"ALEX\">      <data key=\"d0\">PERSON<\/data>      <data key=\"d1\">Alex is a person who is already in a relationship and has been confessed to by Elliot, putting Alex in an awkward position.<\/data>      <data key=\"d2\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/node>    <node id=\"RESIGNED\">      <data key=\"d0\">EMOTION<\/data>      <data key=\"d1\">Resigned is an emotion felt by Elliot, scored at 7, indicating a strong sense of acceptance of the situation.<\/data>      <data key=\"d2\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/node>    <node id=\"ANGRY\">      <data key=\"d0\">EMOTION<\/data>      <data key=\"d1\">Angry is an emotion felt by Elliot, scored at 3, indicating a mild sense of frustration or self-directed anger.<\/data>      <data key=\"d2\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/node>    <node id=\"HOPEFUL\">      <data key=\"d0\">EMOTION<\/data>      <data key=\"d1\">Hopeful is an emotion felt by Elliot, scored at 5, indicating a moderate sense of optimism that Alex might reciprocate his feelings.<\/data>      <data key=\"d2\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/node>    <node id=\"EMBARRASSED\">      <data key=\"d0\">EMOTION<\/data>      <data key=\"d1\">Embarrassed is an emotion felt by Elliot, scored at 8, indicating a strong sense of discomfort for putting Alex in an awkward position.<\/data>      <data key=\"d2\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/node>    <node id=\"OPEN-ENDED GENERATION\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">Open-Ended Generation tasks involve prompting a model to generate an answer to an open-ended question without a ground-truth answer for comparison.<\/data>      <data key=\"d2\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/node>    <node id=\"FOFO\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">FOFO is a benchmark evaluated using GPT-4 to score the format correctness of model responses, with scores ranging from 0 to 1.<\/data>      <data key=\"d2\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/node>    <node id=\"GPT-4\">      <data key=\"d0\">MODEL<\/data>      <data key=\"d1\">GPT-4 is a version of OpenAI's language model used in various benchmarks to evaluate model responses.<\/data>      <data key=\"d2\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/node>    <node id=\"IFEVAL\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">IFEval is a benchmark that checks if the model response follows verifiable instructions given in the prompt, using code provided by the authors.<\/data>      <data key=\"d2\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/node>    <node id=\"MT-BENCH\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">MT-Bench is a benchmark that evaluates model responses to a first-turn and second-turn query, with GPT-4 providing scores from 1 to 10 for each turn.<\/data>      <data key=\"d2\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/node>    <node id=\"ALPACAEVAL\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">AlpacaEval is a benchmark that measures win-rates by comparing the outputs of the evaluated model to a reference answer, using GPT-4-turbo for evaluation.<\/data>      <data key=\"d2\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/node>    <node id=\"INFOBENCH\">      <data key=\"d0\">BENCHMARK<\/data>      <data key=\"d1\">InfoBench is a benchmark evaluated using GPT-4 to determine if the model response follows decomposed instructions.<\/data>      <data key=\"d2\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/node>    <node id=\"HALLUCINATION JUDGE\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Hallucination Judge is a process where a judge determines if there is any hallucination in a generated summary, using a specific prompt template.<\/data>      <data key=\"d2\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/node>    <node id=\"QUALITY JUDGE\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Quality Judge is a process where a judge evaluates the quality of a response provided by an AI assistant, assessing criteria like instruction adherence, content grounding, and overall quality.<\/data>      <data key=\"d2\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/node>    <node id=\"ELLIOT\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/node>    <node id=\"REVISED SCORES\">      <data key=\"d0\">DATA<\/data>      <data key=\"d1\">Revised scores are the numerical values assigned to each of Elliot's emotions: Resigned (7), Angry (3), Hopeful (5), and Embarrassed (8).<\/data>      <data key=\"d2\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/node>    <node id=\"PROMPT TEMPLATE\">      <data key=\"d0\">TOOL<\/data>      <data key=\"d1\">Prompt template is a predefined format used for evaluating hallucination detection and summarization quality in AI-generated responses.<\/data>      <data key=\"d2\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/node>    <node id=\"TEXT SUMMARIZATION\">      <data key=\"d0\">TASK<\/data>      <data key=\"d1\">Text Summarization is the task of generating a concise and accurate summary of a given text, evaluated for quality and hallucination.<\/data>      <data key=\"d2\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/node>    <node id=\"HALLUCINATION DETECTION\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Hallucination Detection is the process of identifying and evaluating hallucinated content in AI-generated summaries.<\/data>      <data key=\"d2\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/node>    <node id=\"SUMMARIZATION QUALITY\">      <data key=\"d0\">PROCESS<\/data>      <data key=\"d1\">Summarization Quality is the process of evaluating the quality of AI-generated summaries based on criteria like instruction adherence, content grounding, and overall quality.<\/data>      <data key=\"d2\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/node>    <node id=\"EMOTIONS\">      <data key=\"d0\" \/>      <data key=\"d1\" \/>      <data key=\"d2\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/node>    <edge source=\"RESIGNED\" target=\"ELLIOT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Elliot feels resigned after confessing his feelings to Alex, with a score of 7.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>    <edge source=\"ANGRY\" target=\"ELLIOT\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Elliot feels angry at himself for putting himself in this situation, with a score of 3.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>    <edge source=\"HOPEFUL\" target=\"ELLIOT\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">Elliot feels hopeful that Alex might reciprocate his feelings, with a score of 5.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>    <edge source=\"EMBARRASSED\" target=\"ELLIOT\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Elliot feels embarrassed for putting Alex in an awkward position, with a score of 8.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>    <edge source=\"OPEN-ENDED GENERATION\" target=\"FOFO\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">FOFO is a benchmark under the category of Open-Ended Generation tasks.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>    <edge source=\"OPEN-ENDED GENERATION\" target=\"IFEVAL\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">IFEval is a benchmark under the category of Open-Ended Generation tasks.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>    <edge source=\"OPEN-ENDED GENERATION\" target=\"MT-BENCH\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">MT-Bench is a benchmark under the category of Open-Ended Generation tasks.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>    <edge source=\"OPEN-ENDED GENERATION\" target=\"ALPACAEVAL\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">AlpacaEval is a benchmark under the category of Open-Ended Generation tasks.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>    <edge source=\"OPEN-ENDED GENERATION\" target=\"INFOBENCH\">      <data key=\"d3\">7.0<\/data>      <data key=\"d4\">InfoBench is a benchmark under the category of Open-Ended Generation tasks.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>    <edge source=\"FOFO\" target=\"GPT-4\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">FOFO uses GPT-4 to evaluate the format correctness of model responses.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"IFEVAL\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">IFEval uses GPT-4 to check if the model response follows verifiable instructions.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"MT-BENCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">MT-Bench uses GPT-4 to judge each turn's response and provide a score.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"ALPACAEVAL\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">AlpacaEval uses GPT-4-turbo to measure win-rates by comparing model outputs.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"INFOBENCH\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">InfoBench uses GPT-4 to determine if the model response follows decomposed instructions.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"HALLUCINATION JUDGE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">GPT-4 is used in the Hallucination Judge process to evaluate generated summaries.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"QUALITY JUDGE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">GPT-4 is used in the Quality Judge process to evaluate the quality of AI-generated responses.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"HALLUCINATION DETECTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">GPT-4 is used in the Hallucination Detection process to evaluate AI-generated summaries.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>    <edge source=\"GPT-4\" target=\"SUMMARIZATION QUALITY\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">GPT-4 is used in the Summarization Quality process to evaluate the quality of AI-generated summaries.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>    <edge source=\"HALLUCINATION JUDGE\" target=\"PROMPT TEMPLATE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Hallucination Judge process uses a specific prompt template to evaluate hallucination in AI-generated summaries.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>    <edge source=\"QUALITY JUDGE\" target=\"PROMPT TEMPLATE\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">The Quality Judge process uses a specific prompt template to evaluate the quality of AI-generated summaries.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>    <edge source=\"REVISED SCORES\" target=\"EMOTIONS\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Revised scores provide numerical values for each of the emotions experienced by Elliot.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>    <edge source=\"TEXT SUMMARIZATION\" target=\"HALLUCINATION DETECTION\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Hallucination Detection is a part of the Text Summarization task, focusing on identifying hallucinated content.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>    <edge source=\"TEXT SUMMARIZATION\" target=\"SUMMARIZATION QUALITY\">      <data key=\"d3\">8.0<\/data>      <data key=\"d4\">Summarization Quality is a part of the Text Summarization task, focusing on evaluating the quality of the generated summaries.<\/data>      <data key=\"d5\">0cf2e43f324fa4175b9b00b90e5e90ba<\/data>    <\/edge>  <\/graph><\/graphml>"}
