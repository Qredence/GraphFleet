{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the knowledge graph with `yfiles-jupyter-graphs`\n",
    "\n",
    "This notebook is a partial copy of [local_search.ipynb](../../local_search.ipynb) that shows how to use `yfiles-jupyter-graphs` to add interactive graph visualizations of the parquet files  and how to visualize the result context of `graphrag` queries (see at the end of this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Microsoft Corporation.\n",
    "# Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "from graphrag.query.context_builder.entity_extraction import EntityVectorStoreKey\n",
    "from graphrag.query.indexer_adapters import (\n",
    "    read_indexer_covariates,\n",
    "    read_indexer_entities,\n",
    "    read_indexer_relationships,\n",
    "    read_indexer_reports,\n",
    "    read_indexer_text_units,\n",
    ")\n",
    "from graphrag.query.input.loaders.dfs import (\n",
    "    store_entity_semantic_embeddings,\n",
    ")\n",
    "from graphrag.query.llm.oai.chat_openai import ChatOpenAI\n",
    "from graphrag.query.llm.oai.embedding import OpenAIEmbedding\n",
    "from graphrag.query.llm.oai.typing import OpenaiApiType\n",
    "from graphrag.query.structured_search.local_search.mixed_context import (\n",
    "    LocalSearchMixedContext,\n",
    ")\n",
    "from graphrag.query.structured_search.local_search.search import LocalSearch\n",
    "from graphrag.vector_stores.lancedb import LanceDBVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Search Example\n",
    "\n",
    "Local search method generates answers by combining relevant data from the AI-extracted knowledge-graph with text chunks of the raw documents. This method is suitable for questions that require an understanding of specific entities mentioned in the documents (e.g. What are the healing properties of chamomile?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load text units and graph data tables as context for local search\n",
    "\n",
    "- In this test we first load indexing outputs from parquet files to dataframes, then convert these dataframes into collections of data objects aligning with the knowledge model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tables to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"../output/usage_ai/artifacts\"\n",
    "LANCEDB_URI = f\"{INPUT_DIR}/lancedb\"\n",
    "\n",
    "COMMUNITY_REPORT_TABLE = \"create_final_community_reports\"\n",
    "ENTITY_TABLE = \"create_final_nodes\"\n",
    "ENTITY_EMBEDDING_TABLE = \"create_final_entities\"\n",
    "RELATIONSHIP_TABLE = \"create_final_relationships\"\n",
    "COVARIATE_TABLE = \"create_final_covariates\"\n",
    "TEXT_UNIT_TABLE = \"create_final_text_units\"\n",
    "COMMUNITY_LEVEL = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read nodes table to get community and degree data\n",
    "entity_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_TABLE}.parquet\")\n",
    "entity_embedding_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_EMBEDDING_TABLE}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_df = pd.read_parquet(f\"{INPUT_DIR}/{RELATIONSHIP_TABLE}.parquet\")\n",
    "relationships = read_indexer_relationships(relationship_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing nodes and relationships with `yfiles-jupyter-graphs`\n",
    "\n",
    "`yfiles-jupyter-graphs` is a graph visualization extension that provides interactive and customizable visualizations for structured node and relationship data.\n",
    "\n",
    "In this case, we use it to provide an interactive visualization for the knowledge graph of the [local_search.ipynb](../../local_search.ipynb) sample by passing node and relationship lists converted from the given parquet files. The requirements for the input data is an `id` attribute for the nodes and `start`/`end` properties for the relationships that correspond to the node ids. Additional attributes can be added in the `properties` of each node/relationship dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install yfiles_jupyter_graphs --quiet\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "def handle_nan_inf(obj):\n",
    "    if isinstance(obj, float):\n",
    "        if np.isnan(obj):\n",
    "            return \"NaN\"\n",
    "        elif np.isinf(obj):\n",
    "            return \"Infinity\" if obj > 0 else \"-Infinity\"\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: handle_nan_inf(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [handle_nan_inf(i) for i in obj]\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return handle_nan_inf(obj.tolist())\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# converts the entities dataframe to a list of dicts for yfiles-jupyter-graphs\n",
    "def convert_entities_to_dicts(df):\n",
    "    \"\"\"Convert the entities dataframe to a list of dicts for yfiles-jupyter-graphs.\"\"\"\n",
    "    nodes_dict = {}\n",
    "    for _, row in df.iterrows():\n",
    "        # Create a dictionary for each row and collect unique nodes\n",
    "        node_id = row[\"title\"]\n",
    "        if node_id not in nodes_dict:\n",
    "            nodes_dict[node_id] = {\n",
    "                \"id\": node_id,\n",
    "                \"properties\": row.to_dict(),\n",
    "            }\n",
    "    return list(nodes_dict.values())\n",
    "\n",
    "# converts the relationships dataframe to a list of dicts for yfiles-jupyter-graphs\n",
    "def convert_relationships_to_dicts(df):\n",
    "    \"\"\"Convert the relationships dataframe to a list of dicts for yfiles-jupyter-graphs.\"\"\"\n",
    "    relationships = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Create a dictionary for each row\n",
    "        relationships.append({\n",
    "            \"start\": row[\"source\"],\n",
    "            \"end\": row[\"target\"],\n",
    "            \"properties\": row.to_dict(),\n",
    "        })\n",
    "    return relationships\n",
    "\n",
    "w = GraphWidget()\n",
    "w.directed = True\n",
    "\n",
    "# Convert entities, handle NaN/Inf, and use NumpyEncoder\n",
    "converted_nodes = json.loads(json.dumps(convert_entities_to_dicts(entity_df), cls=NumpyEncoder))\n",
    "converted_nodes = handle_nan_inf(converted_nodes)\n",
    "w.nodes = converted_nodes\n",
    "\n",
    "# Convert relationships, handle NaN/Inf, and use NumpyEncoder\n",
    "converted_edges = json.loads(json.dumps(convert_relationships_to_dicts(relationship_df), cls=NumpyEncoder))\n",
    "converted_edges = handle_nan_inf(converted_edges)\n",
    "w.edges = converted_edges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure data-driven visualization\n",
    "\n",
    "The additional properties can be used to configure the visualization for different use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show title on the node\n",
    "w.node_label_mapping = \"title\"\n",
    "\n",
    "\n",
    "# map community to a color\n",
    "def community_to_color(community):\n",
    "    \"\"\"Map a community to a color.\"\"\"\n",
    "    colors = [\n",
    "        \"crimson\",\n",
    "        \"darkorange\",\n",
    "        \"indigo\",\n",
    "        \"cornflowerblue\",\n",
    "        \"cyan\",\n",
    "        \"teal\",\n",
    "        \"green\",\n",
    "    ]\n",
    "    return (\n",
    "        colors[int(community) % len(colors)] if community is not None else \"lightgray\"\n",
    "    )\n",
    "\n",
    "\n",
    "def edge_to_source_community(edge):\n",
    "    \"\"\"Get the community of the source node of an edge.\"\"\"\n",
    "    source_node = next(\n",
    "        (entry for entry in w.nodes if entry[\"properties\"][\"title\"] == edge[\"start\"]),\n",
    "        None,\n",
    "    )\n",
    "    source_node_community = source_node[\"properties\"][\"community\"]\n",
    "    return source_node_community if source_node_community is not None else None\n",
    "\n",
    "\n",
    "w.node_color_mapping = lambda node: community_to_color(node[\"properties\"][\"community\"])\n",
    "w.edge_color_mapping = lambda edge: community_to_color(edge_to_source_community(edge))\n",
    "# map size data to a reasonable factor\n",
    "w.node_scale_factor_mapping = lambda node: 0.5 + (float(node[\"properties\"].get(\"size\", 0)) * 1.5 / 20 if node[\"properties\"].get(\"size\") not in ['NaN', None] else 0)\n",
    "# use weight for edge thickness\n",
    "w.edge_thickness_factor_mapping = \"weight\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic layouts\n",
    "\n",
    "The widget provides different automatic layouts that serve different purposes: `Circular`, `Hierarchic`, `Organic (interactiv or static)`, `Orthogonal`, `Radial`, `Tree`, `Geo-spatial`.\n",
    "\n",
    "For the knowledge graph, this sample uses the `Circular` layout, though `Hierarchic` or `Organic` are also suitable choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the circular layout for this visualization. For larger graphs, the default organic layout is often preferrable.\n",
    "w.organic_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a388bc237ea1430796c8513aa298832b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='800px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the result context of `graphrag` queries\n",
    "\n",
    "The result context of `graphrag` queries allow to inspect the context graph of the request. This data can similarly be visualized as graph with `yfiles-jupyter-graphs`.\n",
    "\n",
    "## Making the request\n",
    "\n",
    "The following cell recreates the sample queries from [local_search.ipynb](../../local_search.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup (see also ../../local_search.ipynb)\n",
    "entities = read_indexer_entities(entity_df, entity_embedding_df, COMMUNITY_LEVEL)\n",
    "\n",
    "description_embedding_store = LanceDBVectorStore(\n",
    "    collection_name=\"entity_description_embeddings\",\n",
    ")\n",
    "description_embedding_store.connect(db_uri=LANCEDB_URI)\n",
    "entity_description_embeddings = store_entity_semantic_embeddings(\n",
    "    entities=entities, vectorstore=description_embedding_store\n",
    ")\n",
    "covariate_df = pd.read_parquet(f\"{INPUT_DIR}/{COVARIATE_TABLE}.parquet\")\n",
    "claims = read_indexer_covariates(covariate_df)\n",
    "covariates = {\"claims\": claims}\n",
    "report_df = pd.read_parquet(f\"{INPUT_DIR}/{COMMUNITY_REPORT_TABLE}.parquet\")\n",
    "reports = read_indexer_reports(report_df, entity_df, COMMUNITY_LEVEL)\n",
    "text_unit_df = pd.read_parquet(f\"{INPUT_DIR}/{TEXT_UNIT_TABLE}.parquet\")\n",
    "text_units = read_indexer_text_units(text_unit_df)\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "api_key = os.environ[\"GRAPHRAG_API_KEY\"]\n",
    "llm_model = os.environ[\"GRAPHRAG_LLM_MODEL\"]\n",
    "embedding_model = os.environ[\"GRAPHRAG_EMBEDDING_MODEL\"]\n",
    "api_base = os.environ[\"GRAPHRAG_API_BASE\"]\n",
    "api_version = os.environ[\"GRAPHRAG_API_VERSION\"]  # Add this line\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=api_key,\n",
    "    model=llm_model,\n",
    "    api_type=OpenaiApiType.AzureOpenAI,  # OpenaiApiType.OpenAI or OpenaiApiType.AzureOpenAI\n",
    "    api_base=api_base,\n",
    "    api_version=api_version,  # Add this line\n",
    "    max_retries=20,\n",
    ")\n",
    "\n",
    "token_encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "text_embedder = OpenAIEmbedding(\n",
    "    api_key=api_key,\n",
    "    api_base=api_base,\n",
    "    api_version=api_version,  # Add this line\n",
    "    api_type=OpenaiApiType.AzureOpenAI,\n",
    "    model=embedding_model,\n",
    "    deployment_name=embedding_model,\n",
    "    max_retries=20,\n",
    ")\n",
    "\n",
    "context_builder = LocalSearchMixedContext(\n",
    "    community_reports=reports,\n",
    "    text_units=text_units,\n",
    "    entities=entities,\n",
    "    relationships=relationships,\n",
    "    covariates=covariates,\n",
    "    entity_text_embeddings=description_embedding_store,\n",
    "    embedding_vectorstore_key=EntityVectorStoreKey.ID,  # if the vectorstore uses entity title as ids, set this to EntityVectorStoreKey.TITLE\n",
    "    text_embedder=text_embedder,\n",
    "    token_encoder=token_encoder,\n",
    ")\n",
    "\n",
    "local_context_params = {\n",
    "    \"text_unit_prop\": 0.5,\n",
    "    \"community_prop\": 0.1,\n",
    "    \"conversation_history_max_turns\": 5,\n",
    "    \"conversation_history_user_turns_only\": True,\n",
    "    \"top_k_mapped_entities\": 10,\n",
    "    \"top_k_relationships\": 10,\n",
    "    \"include_entity_rank\": True,\n",
    "    \"include_relationship_weight\": True,\n",
    "    \"include_community_rank\": False,\n",
    "    \"return_candidate_context\": False,\n",
    "    \"embedding_vectorstore_key\": EntityVectorStoreKey.ID,  # set this to EntityVectorStoreKey.TITLE if the vectorstore uses entity title as ids\n",
    "    \"max_tokens\": 12_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 5000)\n",
    "}\n",
    "\n",
    "llm_params = {\n",
    "    \"max_tokens\": 2_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 1000=1500)\n",
    "    \"temperature\": 0.0,\n",
    "}\n",
    "\n",
    "search_engine = LocalSearch(\n",
    "    llm=llm,\n",
    "    context_builder=context_builder,\n",
    "    token_encoder=token_encoder,\n",
    "    llm_params=llm_params,\n",
    "    context_builder_params=local_context_params,\n",
    "    response_type=\"multiple paragraphs\",  # free form text describing the response type and format, can be anything, e.g. prioritized list, single paragraph, multiple paragraphs, multiple-page report\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run local search on sample queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Prompts for Self-Reflecting\n",
      "\n",
      "Self-reflecting prompts are designed to encourage introspection and personal growth by guiding individuals to think deeply about their experiences, thoughts, and emotions. These prompts can be particularly useful in various contexts, such as personal development, therapy, and coaching. Below, we explore the concept of self-reflecting prompts, their significance, and some techniques used to create effective prompts.\n",
      "\n",
      "## Understanding Self-Reflecting Prompts\n",
      "\n",
      "A prompt, in the context of Generative AI and personal development, is a set of instructions or questions provided to guide the output of a model or the thoughts of an individual. Self-reflecting prompts are specifically crafted to elicit introspective responses, helping individuals to explore their inner world and gain insights into their behavior, motivations, and feelings [Data: Entities (243, 163)].\n",
      "\n",
      "## Techniques for Crafting Self-Reflecting Prompts\n",
      "\n",
      "### Prompt Engineering\n",
      "\n",
      "Prompt Engineering is a critical technique in designing effective self-reflecting prompts. It involves the careful construction and refinement of prompts to ensure they elicit meaningful and relevant responses. This process can include the use of specific language, context, and examples to guide the individual's reflection [Data: Entities (163, 275); Relationships (174, 216)].\n",
      "\n",
      "### Conversational Prompt Engineering\n",
      "\n",
      "Conversational Prompt Engineering is particularly useful for real-time interactions, such as therapy sessions or coaching conversations. This technique involves designing prompts that facilitate a natural and engaging dialogue, encouraging individuals to open up and reflect more deeply on their experiences [Data: Entities (264); Relationships (204)].\n",
      "\n",
      "### Prompt-Based Learning\n",
      "\n",
      "Prompt-Based Learning, also known as Prompt Learning, is a technique where the model or individual learns from the prompts provided, improving their ability to generate accurate and insightful responses over time. This iterative process is essential for refining self-reflecting prompts to better suit the needs of the individual [Data: Entities (266); Relationships (206, 293)].\n",
      "\n",
      "## Examples and Exemplars\n",
      "\n",
      "Examples, also known as exemplars or shots, are demonstrations used in prompts to guide the individual in completing a task. In the context of self-reflecting prompts, exemplars can be used to illustrate how to approach a reflective question, providing a model for the individual to follow. This technique is fundamental in helping individuals understand the depth and nature of the reflection expected [Data: Entities (245, 276); Relationships (184, 213)].\n",
      "\n",
      "## Importance of Context Window\n",
      "\n",
      "The 'Context Window' refers to the range of information processed by the individual or model in response to a prompt. In self-reflecting prompts, the context window is crucial for ensuring that the individual can effectively interpret and respond to the prompt, taking into account their personal experiences and current state of mind [Data: Entities (248); Relationships (187, 378)].\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Self-reflecting prompts are a powerful tool for personal growth and introspection. By leveraging techniques such as Prompt Engineering, Conversational Prompt Engineering, and Prompt-Based Learning, these prompts can be crafted to elicit deep and meaningful reflections. The use of examples and a well-defined context window further enhances the effectiveness of these prompts, guiding individuals on their journey of self-discovery and personal development.\n",
      "\n",
      "Understanding and utilizing these techniques can significantly improve the quality of self-reflection, leading to greater self-awareness and personal growth.\n"
     ]
    }
   ],
   "source": [
    "result = await search_engine.asearch(\"Tell me about Prompts for Self Reflecting\")\n",
    "print(result.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Prompt Optimization\n",
      "\n",
      "Prompt optimization is a critical aspect of prompt engineering, focusing on refining prompts to enhance the performance of large language models (LLMs). This process involves improving prompts with respect to a scoring function, which is usually defined over a dataset. The goal is to maximize the effectiveness of the prompts in guiding the LLMs to produce desired outputs.\n",
      "\n",
      "## Key Techniques and Metrics\n",
      "\n",
      "Several techniques are employed in prompt optimization, including Meta Prompting and AutoPrompt. These methods involve automatically optimizing prompts to guide AI models effectively. The iterative nature of these techniques underscores the importance of continuous refinement to achieve the best possible performance from LLMs [Data: Prompt Engineering and Its Techniques (23); Entities (401, 591); Relationships (217, 218, 246)].\n",
      "\n",
      "Performance metrics such as F1 Score, Recall, and Precision are essential in evaluating the effectiveness of prompts. These metrics help in assessing how well the prompts elicit the desired responses from LLMs. For instance, the F1 Score is used to measure the balance between precision and recall, ensuring that the prompts are both accurate and comprehensive in their outputs [Data: Prompt Engineering and Its Techniques (23); Relationships (236, 237, 238)].\n",
      "\n",
      "## Applications and Impact\n",
      "\n",
      "Prompt optimization has significant applications across various fields, including healthcare, software engineering, and education. In healthcare, techniques like Automated Prompt Engineering are used to enhance medical services and improve the training of medical professionals. In software engineering, prompt optimization techniques such as Automated Program Repair and Software Testing with LLMs are employed to improve software development processes, making them more efficient and effective [Data: Prompt Engineering and Its Techniques (23); Entities (597, 600, 609, 607); Relationships (254, 257, 266, 264, 265)].\n",
      "\n",
      "In educational settings, prompt optimization is leveraged to enhance teaching and learning experiences. By using optimized prompts, educators can improve the effectiveness of their teaching methods, providing better learning experiences for students. This highlights the role of prompt optimization in developing more interactive and engaging learning environments [Data: Prompt Engineering and Its Techniques (23); Entities (610); Relationships (267)].\n",
      "\n",
      "## Challenges and Future Directions\n",
      "\n",
      "One of the challenges in prompt optimization is ensuring fairness and security in the application of LLMs. Techniques are reviewed to address issues related to the fairness of LLMs and to ensure the safe and secure application of prompt engineering methods. Organizations like Rebuff AI have developed security measures such as self-hardening prompt injection detectors to improve the security of AI systems [Data: Prompt Engineering and Its Techniques (23); Entities (611, 625); Relationships (268, 277, 282)].\n",
      "\n",
      "The field of prompt optimization is continuously evolving, with ongoing efforts to provide a comprehensive classification and terminology for various techniques. Standardizing terminology is crucial for facilitating communication and collaboration among researchers and practitioners in prompt engineering. This ensures consistency and clarity in the field, accommodating future techniques and advancements [Data: Prompt Engineering and Its Techniques (23); Entities (619, 620, 622); Relationships (275, 276, 278)].\n",
      "\n",
      "In summary, prompt optimization is a vital component of prompt engineering, aimed at refining prompts to enhance the performance of LLMs. Through various techniques and performance metrics, prompt optimization has significant applications across multiple fields, contributing to advancements in healthcare, software engineering, and education. The continuous evolution of this field highlights the importance of ongoing research and standardization efforts to address emerging challenges and improve the effectiveness of LLMs.\n"
     ]
    }
   ],
   "source": [
    "question = \"Tell me about Prompt Optimization\"\n",
    "result = await search_engine.asearch(question)\n",
    "print(result.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the context data used to generate the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>entity</th>\n",
       "      <th>description</th>\n",
       "      <th>number of relationships</th>\n",
       "      <th>in_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>587</td>\n",
       "      <td>\"OPTIMIZATION\"</td>\n",
       "      <td>\"Optimization\" in the context of prompt engine...</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>318</td>\n",
       "      <td>\"PROMPT MINING\"</td>\n",
       "      <td>\"Prompt Mining\" involves techniques to discove...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>267</td>\n",
       "      <td>\"PROMPT TUNING\"</td>\n",
       "      <td>\"Prompt Tuning\" is a technique for parameter-e...</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>164</td>\n",
       "      <td>\"PROMPT ENGINEERING\"</td>\n",
       "      <td>\"Prompt Engineering\" is a subdomain of artific...</td>\n",
       "      <td>86</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>243</td>\n",
       "      <td>\"PROMPT\"</td>\n",
       "      <td>A prompt is a set of instructions provided to ...</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                entity  \\\n",
       "0  587        \"OPTIMIZATION\"   \n",
       "1  318       \"PROMPT MINING\"   \n",
       "2  267       \"PROMPT TUNING\"   \n",
       "3  164  \"PROMPT ENGINEERING\"   \n",
       "4  243              \"PROMPT\"   \n",
       "\n",
       "                                         description number of relationships  \\\n",
       "0  \"Optimization\" in the context of prompt engine...                       6   \n",
       "1  \"Prompt Mining\" involves techniques to discove...                       1   \n",
       "2  \"Prompt Tuning\" is a technique for parameter-e...                       4   \n",
       "3  \"Prompt Engineering\" is a subdomain of artific...                      86   \n",
       "4  A prompt is a set of instructions provided to ...                       4   \n",
       "\n",
       "   in_context  \n",
       "0        True  \n",
       "1        True  \n",
       "2        True  \n",
       "3        True  \n",
       "4        True  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.context_data[\"entities\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>description</th>\n",
       "      <th>weight</th>\n",
       "      <th>rank</th>\n",
       "      <th>links</th>\n",
       "      <th>in_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>296</td>\n",
       "      <td>\"PROMPT ENGINEERING\"</td>\n",
       "      <td>\"OPTIMIZATION\"</td>\n",
       "      <td>\"Optimization is a key aspect of Prompt Engine...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>291</td>\n",
       "      <td>\"PROMPT ENGINEERING\"</td>\n",
       "      <td>\"PROMPT\"</td>\n",
       "      <td>\"Prompt Engineering\" involves the design and r...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>294</td>\n",
       "      <td>\"PROMPT ENGINEERING\"</td>\n",
       "      <td>\"PROMPT TUNING\"</td>\n",
       "      <td>\"Prompt Tuning is a specific technique within ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>174</td>\n",
       "      <td>\"PROMPTING\"</td>\n",
       "      <td>\"PROMPT ENGINEERING\"</td>\n",
       "      <td>\"Prompt Engineering\" involves designing and re...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>295</td>\n",
       "      <td>\"PROMPT ENGINEERING\"</td>\n",
       "      <td>\"FEW-SHOT PROMPTING\"</td>\n",
       "      <td>\"Few-Shot Prompting is a specific technique us...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                source                target  \\\n",
       "0  296  \"PROMPT ENGINEERING\"        \"OPTIMIZATION\"   \n",
       "1  291  \"PROMPT ENGINEERING\"              \"PROMPT\"   \n",
       "2  294  \"PROMPT ENGINEERING\"       \"PROMPT TUNING\"   \n",
       "3  174           \"PROMPTING\"  \"PROMPT ENGINEERING\"   \n",
       "4  295  \"PROMPT ENGINEERING\"  \"FEW-SHOT PROMPTING\"   \n",
       "\n",
       "                                         description weight rank links  \\\n",
       "0  \"Optimization is a key aspect of Prompt Engine...    1.0   92     2   \n",
       "1  \"Prompt Engineering\" involves the design and r...    2.0   90     1   \n",
       "2  \"Prompt Tuning is a specific technique within ...    1.0   90     2   \n",
       "3  \"Prompt Engineering\" involves designing and re...    2.0  129     2   \n",
       "4  \"Few-Shot Prompting is a specific technique us...    1.0   97     2   \n",
       "\n",
       "   in_context  \n",
       "0        True  \n",
       "1        True  \n",
       "2        True  \n",
       "3        True  \n",
       "4        True  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.context_data[\"relationships\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the result context as graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06e6fa39a1a4add91bdbe9fe1cdbb8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='700px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Helper function to visualize the result context with `yfiles-jupyter-graphs`.\n",
    "\n",
    "The dataframes are converted into supported nodes and relationships lists and then passed to yfiles-jupyter-graphs.\n",
    "Additionally, some values are mapped to visualization properties.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def show_graph(result):\n",
    "    \"\"\"Visualize the result context with yfiles-jupyter-graphs.\"\"\"\n",
    "    from yfiles_jupyter_graphs import GraphWidget\n",
    "\n",
    "    if (\n",
    "        \"entities\" not in result.context_data\n",
    "        or \"relationships\" not in result.context_data\n",
    "    ):\n",
    "        msg = \"The passed results do not contain 'entities' or 'relationships'\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    # converts the entities dataframe to a list of dicts for yfiles-jupyter-graphs\n",
    "    def convert_entities_to_dicts(df):\n",
    "        \"\"\"Convert the entities dataframe to a list of dicts for yfiles-jupyter-graphs.\"\"\"\n",
    "        nodes_dict = {}\n",
    "        for _, row in df.iterrows():\n",
    "            # Create a dictionary for each row and collect unique nodes\n",
    "            node_id = row[\"entity\"]\n",
    "            if node_id not in nodes_dict:\n",
    "                nodes_dict[node_id] = {\n",
    "                    \"id\": node_id,\n",
    "                    \"properties\": row.to_dict(),\n",
    "                }\n",
    "        return list(nodes_dict.values())\n",
    "\n",
    "    # converts the relationships dataframe to a list of dicts for yfiles-jupyter-graphs\n",
    "    def convert_relationships_to_dicts(df):\n",
    "        \"\"\"Convert the relationships dataframe to a list of dicts for yfiles-jupyter-graphs.\"\"\"\n",
    "        relationships = []\n",
    "        for _, row in df.iterrows():\n",
    "            # Create a dictionary for each row\n",
    "            relationships.append({\n",
    "                \"start\": row[\"source\"],\n",
    "                \"end\": row[\"target\"],\n",
    "                \"properties\": row.to_dict(),\n",
    "            })\n",
    "        return relationships\n",
    "\n",
    "    w = GraphWidget()\n",
    "    # use the converted data to visualize the graph\n",
    "    w.nodes = convert_entities_to_dicts(result.context_data[\"entities\"])\n",
    "    w.edges = convert_relationships_to_dicts(result.context_data[\"relationships\"])\n",
    "    w.directed = True\n",
    "    # show title on the node\n",
    "    w.node_label_mapping = \"entity\"\n",
    "    # use weight for edge thickness\n",
    "    w.edge_thickness_factor_mapping = \"weight\"\n",
    "    display(w)\n",
    "\n",
    "\n",
    "show_graph(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
